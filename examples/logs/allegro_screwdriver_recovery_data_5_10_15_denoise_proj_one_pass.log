[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]

Trial 1
Loaded trajectory sampler
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
1 turn
Sampling time 5.098747083044145
tensor([ 1.5497e-01,  6.1007e-01,  5.7076e-01,  6.1106e-01, -1.1513e-01,
         5.4013e-01,  8.8512e-01,  9.3454e-01,  1.2569e+00,  2.2909e-01,
         2.3290e-01,  1.2085e+00,  5.5207e-05,  1.3631e-02, -4.8130e-02,
         4.4650e-01], device='cuda:1')
Original likelihood: -107.05027770996094
Adjusted likelihood: -107.05027770996094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.823505648004357
Current ori: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Middle force: tensor([0.5787, 0.5693, 1.1468, 0.5579, 1.1098, 0.6485, 0.5337, 0.5207, 0.5460,
        0.5341, 0.5538, 0.5290], device='cuda:1')
Thumb force: tensor([0.8617, 0.8266, 0.7522, 1.0034, 0.9702, 0.6565, 0.5239, 0.8831, 0.5828,
        0.5901, 0.5732, 0.5677], device='cuda:1')
Index force: tensor([0.5962, 0.6005, 0.5573, 0.5693, 0.7994, 0.5242, 0.9919, 0.9173, 0.5698,
        0.5646, 0.5311, 0.5697], device='cuda:1')
Storing NORMAL transition: reward=0.0015 (scaled=0.0015), steps=1
Reward stats updated: mean 0.0000 -> 0.0015, std: 0.0000
Collected 1 transitions for RL
tensor([ 0.2621,  0.6668,  0.4216,  0.6578, -0.2035,  0.4751,  0.8895,  1.0461,
         1.2528,  0.2570,  0.2226,  1.1533,  0.0055,  0.0208, -0.0499, -0.8571],
       device='cuda:1')
Original likelihood: -210.02740478515625
Adjusted likelihood: -210.02740478515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.8472, -2.9790, -3.2101, -3.4150, -3.6378, -3.9064, -3.9076, -4.0981,
        -4.2687, -4.3188, -4.4635, -4.5082, -4.6319, -5.3445, -6.6040, -9.8130],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8472, -2.9790, -3.2101, -3.4150, -3.6378, -3.9064, -3.9076, -4.0981,
        -4.2687, -4.3188, -4.4635, -4.5082, -4.6319, -5.3445, -6.6040, -9.8130],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.4971
1 mode projection succeeded
New goal: tensor([ 0.0639,  0.5784,  0.5214,  0.6166, -0.0811,  0.5086,  0.8489,  0.9110,
         1.2114,  0.3545,  0.2835,  1.1290,  0.0028,  0.0145,  1.1529],
       device='cuda:1')
tensor([[0.0065]], device='cuda:1') tensor([[0.0080]], device='cuda:1') tensor([[0.0107]], device='cuda:1')
Original likelihood: -183.59214782714844
Adjusted likelihood: -183.59214782714844
Likelihood residual: 0.0
Original likelihood: -113.54788208007812
Adjusted likelihood: -113.54788208007812
Likelihood residual: 0.0
{'index': 113.54788208007812, 'thumb_middle': 183.59214782714844}
Current yaw: tensor([ 0.0055,  0.0208, -0.0499], device='cuda:1')
2 index
tensor([ 0.2621,  0.6668,  0.4216,  0.6578, -0.2035,  0.4751,  0.8895,  1.0461,
         1.2528,  0.2570,  0.2226,  1.1533,  0.0055,  0.0208, -0.0499, -0.8571],
       device='cuda:1')
Solve time for step 1 10.979801889043301
Current ori: tensor([ 0.0055,  0.0208, -0.0499], device='cuda:1')
Middle force: tensor([0.5664, 0.5491, 0.5802, 0.6097], device='cuda:1')
Thumb force: tensor([0.5578, 0.5991, 0.5568, 0.5457], device='cuda:1')
tensor([ 0.1434,  0.5448,  0.4601,  0.6011, -0.1547,  0.5375,  0.9232,  0.9870,
         1.2296,  0.3213,  0.2778,  1.0950, -0.0031,  0.0073, -0.0532, -1.6127],
       device='cuda:1')
Solve time for step 2 4.330040341999847
Current ori: tensor([-0.0031,  0.0073, -0.0532], device='cuda:1')
Middle force: tensor([0.5246, 0.5404, 0.5107], device='cuda:1')
Thumb force: tensor([0.5659, 0.5842, 0.5682], device='cuda:1')
tensor([ 1.2282e-01,  5.2917e-01,  4.6907e-01,  5.9397e-01, -1.4066e-01,
         5.4834e-01,  9.2405e-01,  9.7139e-01,  1.2195e+00,  3.3712e-01,
         2.7063e-01,  1.0848e+00, -1.1159e-02, -1.7239e-03, -7.3191e-02,
        -2.0331e+00], device='cuda:1')
Solve time for step 3 4.308226589986589
Current ori: tensor([-0.0112, -0.0017, -0.0732], device='cuda:1')
Middle force: tensor([0.6111, 0.5653], device='cuda:1')
Thumb force: tensor([0.5390, 0.5258], device='cuda:1')
tensor([ 0.1205,  0.5259,  0.4714,  0.5905, -0.1319,  0.5558,  0.9227,  0.9694,
         1.2223,  0.3295,  0.2529,  1.0969, -0.0130, -0.0082, -0.0748, -2.3504],
       device='cuda:1')
Solve time for step 4 4.404673092009034
Current ori: tensor([-0.0130, -0.0082, -0.0748], device='cuda:1')
Middle force: tensor([0.5500], device='cuda:1')
Thumb force: tensor([0.5449], device='cuda:1')
Storing RECOVERY transition: reward=0.0156 (scaled=0.0156), steps=1
Reward stats updated: mean 0.0015 -> 0.0085, std: 0.0070
Collected 2 transitions for RL
Original likelihood: -118.9090347290039
Adjusted likelihood: -118.9090347290039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0130, -0.0059, -0.0652], device='cuda:1')
3 turn
Sampling time 5.181395423016511
tensor([ 0.0690,  0.5861,  0.5161,  0.6141, -0.1352,  0.5566,  0.9211,  0.9649,
         1.2147,  0.3404,  0.2635,  1.0920, -0.0130, -0.0059, -0.0652, -2.4432],
       device='cuda:1')
Original likelihood: -119.78660583496094
Adjusted likelihood: -119.78660583496094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.83814753202023
Current ori: tensor([-0.0130, -0.0059, -0.0652], device='cuda:1')
Middle force: tensor([0.5854, 0.7291, 1.3369, 1.3459, 1.9023, 0.5709, 0.5790, 0.5511, 1.0713,
        0.8224, 0.7407, 0.5610], device='cuda:1')
Thumb force: tensor([0.5981, 1.1596, 0.5390, 1.1588, 1.1481, 0.6095, 1.0742, 0.6062, 1.6240,
        0.5942, 0.5372, 0.5728], device='cuda:1')
Index force: tensor([0.6090, 0.9697, 0.7867, 0.7667, 0.7206, 0.5525, 0.5413, 0.6234, 0.5941,
        0.5646, 0.5611, 0.6431], device='cuda:1')
Storing NORMAL transition: reward=0.0041 (scaled=0.0041), steps=1
Reward stats updated: mean 0.0085 -> 0.0070, std: 0.0061
Collected 3 transitions for RL
tensor([-0.0193,  0.6241,  0.3745,  0.6269, -0.1970,  0.5830,  0.8599,  0.8646,
         1.3007,  0.2887,  0.2837,  1.0594, -0.0213,  0.0470, -0.0716, -2.5853],
       device='cuda:1')
Original likelihood: -163.2103271484375
Adjusted likelihood: -163.2103271484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.3376, -3.4949, -3.6800, -3.7577, -3.9016, -3.9674, -4.4714, -4.5253,
        -4.5472, -4.6003, -4.7775, -4.9818, -5.5486, -6.0050, -7.0363, -7.7439],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.3376, -3.4949, -3.6800, -3.7577, -3.9016, -3.9674, -4.4714, -4.5253,
        -4.5472, -4.6003, -4.7775, -4.9818, -5.5486, -6.0050, -7.0363, -7.7439],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.7735
1 mode projection succeeded
New goal: tensor([ 0.0486,  0.6010,  0.4938,  0.5792, -0.0934,  0.4713,  0.9130,  0.9416,
         1.2562,  0.3235,  0.2201,  1.1691, -0.0030,  0.0127, -0.0090],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -117.57513427734375
Adjusted likelihood: -117.57513427734375
Likelihood residual: 0.0
Original likelihood: -93.2900390625
Adjusted likelihood: -93.2900390625
Likelihood residual: 0.0
{'index': 93.2900390625, 'thumb_middle': 117.57513427734375}
Current yaw: tensor([-0.0213,  0.0470, -0.0716], device='cuda:1')
4 index
tensor([-0.0193,  0.6241,  0.3745,  0.6269, -0.1970,  0.5830,  0.8599,  0.8646,
         1.3007,  0.2887,  0.2837,  1.0594, -0.0213,  0.0470, -0.0716, -2.5853],
       device='cuda:1')
Solve time for step 1 11.606883849017322
Current ori: tensor([-0.0213,  0.0470, -0.0716], device='cuda:1')
Middle force: tensor([0.5650, 0.6016, 0.5620, 0.5161], device='cuda:1')
Thumb force: tensor([0.6055, 0.6140, 0.6082, 0.5000], device='cuda:1')
tensor([ 0.0804,  0.5437,  0.4231,  0.5650, -0.1825,  0.5507,  0.9060,  0.9114,
         1.2824,  0.2990,  0.2598,  1.1058, -0.0085,  0.0318, -0.1118, -3.5309],
       device='cuda:1')
Solve time for step 2 4.476670225034468
Current ori: tensor([-0.0085,  0.0318, -0.1118], device='cuda:1')
Middle force: tensor([0.5926, 0.6057, 0.5426], device='cuda:1')
Thumb force: tensor([0.6099, 0.5440, 0.5456], device='cuda:1')
tensor([ 9.1003e-02,  5.4070e-01,  4.3867e-01,  5.5900e-01, -1.7391e-01,
         5.3587e-01,  9.3496e-01,  9.3931e-01,  1.2804e+00,  2.8811e-01,
         2.2263e-01,  1.1691e+00,  2.3460e-03,  2.0490e-02, -1.1931e-01,
        -4.2505e+00], device='cuda:1')
Solve time for step 3 4.26686603599228
Current ori: tensor([ 0.0023,  0.0205, -0.1193], device='cuda:1')
Middle force: tensor([0.5460, 0.5201], device='cuda:1')
Thumb force: tensor([0.6213, 0.5338], device='cuda:1')
tensor([ 9.8368e-02,  5.4154e-01,  4.4515e-01,  5.5812e-01, -1.5502e-01,
         5.4829e-01,  9.3472e-01,  9.3485e-01,  1.2584e+00,  3.0951e-01,
         2.0939e-01,  1.1837e+00, -2.9771e-04,  7.2894e-03, -1.2210e-01,
        -4.7774e+00], device='cuda:1')
Solve time for step 4 4.627068511967082
Current ori: tensor([-0.0003,  0.0073, -0.1221], device='cuda:1')
Middle force: tensor([0.5375], device='cuda:1')
Thumb force: tensor([0.5391], device='cuda:1')
Storing RECOVERY transition: reward=0.0343 (scaled=0.0343), steps=1
Reward stats updated: mean 0.0070 -> 0.0138, std: 0.0130
Collected 4 transitions for RL
Original likelihood: -70.76702880859375
Adjusted likelihood: -70.76702880859375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0011,  0.0095, -0.1034], device='cuda:1')
5 turn
Sampling time 5.0358157610171475
tensor([ 4.6091e-02,  6.0442e-01,  4.8727e-01,  5.7680e-01, -1.5682e-01,
         5.5340e-01,  9.2748e-01,  9.2462e-01,  1.2559e+00,  3.1198e-01,
         2.1340e-01,  1.1855e+00, -1.0694e-03,  9.4719e-03, -1.0345e-01,
        -4.9129e+00], device='cuda:1')
Original likelihood: -70.82574462890625
Adjusted likelihood: -70.82574462890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.298059246968478
Current ori: tensor([-0.0011,  0.0095, -0.1034], device='cuda:1')
Middle force: tensor([0.5998, 0.5650, 0.5831, 1.1753, 1.2911, 0.5009, 0.5061, 0.7798, 0.5069,
        0.9032, 0.5896, 0.5794], device='cuda:1')
Thumb force: tensor([0.9949, 0.5679, 0.5751, 1.2339, 0.5600, 0.5496, 0.5296, 0.7228, 0.5461,
        1.1638, 0.5515, 0.5647], device='cuda:1')
Index force: tensor([0.9099, 0.4780, 0.7948, 0.5420, 0.5790, 0.5272, 0.8485, 0.5500, 0.5375,
        0.5556, 0.5690, 0.6027], device='cuda:1')
Storing NORMAL transition: reward=0.0002 (scaled=0.0002), steps=1
Reward stats updated: mean 0.0138 -> 0.0111, std: 0.0128
Collected 5 transitions for RL
tensor([ 0.0768,  0.6893,  0.4194,  0.5056, -0.1439,  0.5064,  1.0335,  0.8550,
         1.3359,  0.3262,  0.0772,  1.1248, -0.0242, -0.0079, -0.1042, -4.9211],
       device='cuda:1')
Original likelihood: -149.28433227539062
Adjusted likelihood: -149.28433227539062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6519)
State is out of distribution
Final likelihood: tensor([-3.2096, -3.2759, -3.3867, -3.7948, -3.8640, -3.9159, -4.8683, -4.8989,
        -4.9651, -5.5278, -6.5425, -6.6100, -7.0710, -7.6150, -7.7779, -8.7176],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2096, -3.2759, -3.3867, -3.7948, -3.8640, -3.9159, -4.8683, -4.8989,
        -4.9651, -5.5278, -6.5425, -6.6100, -7.0710, -7.6150, -7.7779, -8.7176],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.3776
1 mode projection succeeded
New goal: tensor([ 4.3053e-02,  5.9850e-01,  5.0710e-01,  5.5070e-01, -8.0096e-02,
         4.8306e-01,  8.8986e-01,  9.0857e-01,  1.2900e+00,  2.7034e-01,
         2.0954e-01,  1.1530e+00,  2.4844e-04,  1.2521e-02, -1.2599e+00],
       device='cuda:1')
tensor([[0.0041]], device='cuda:1') tensor([[0.0042]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -45.04304885864258
Adjusted likelihood: -45.04304885864258
Likelihood residual: 0.0
Original likelihood: -138.24905395507812
Adjusted likelihood: -138.24905395507812
Likelihood residual: 0.0
{'index': 138.24905395507812, 'thumb_middle': 45.04304885864258}
Current yaw: tensor([-0.0242, -0.0079, -0.1042], device='cuda:1')
6 thumb_middle
tensor([ 0.0768,  0.6893,  0.4194,  0.5056, -0.1439,  0.5064,  1.0335,  0.8550,
         1.3359,  0.3262,  0.0772,  1.1248, -0.0242, -0.0079, -0.1042, -4.9211],
       device='cuda:1')
Solve time for step 1 9.317812541965395
Current ori: tensor([-0.0242, -0.0079, -0.1042], device='cuda:1')
Index force: tensor([0.5441, 0.5578, 0.5699, 0.5752], device='cuda:1')
tensor([ 0.0445,  0.6212,  0.4857,  0.5315, -0.1716,  0.4623,  0.8766,  0.8656,
         1.2468,  0.2480,  0.1231,  1.1272, -0.0079,  0.0100, -0.1042, -4.9336],
       device='cuda:1')
Solve time for step 2 3.746544110996183
Current ori: tensor([-0.0079,  0.0100, -0.1042], device='cuda:1')
Index force: tensor([0.5477, 0.5610, 0.5656], device='cuda:1')
tensor([ 3.2448e-02,  5.9254e-01,  5.0268e-01,  5.5495e-01, -1.8480e-01,
         4.6244e-01,  8.5635e-01,  8.9473e-01,  1.2559e+00,  2.4858e-01,
         1.2202e-01,  1.1280e+00,  3.9847e-04,  1.7514e-02, -1.0422e-01,
        -4.9395e+00], device='cuda:1')
Solve time for step 3 3.6856185519718565
Current ori: tensor([ 0.0004,  0.0175, -0.1042], device='cuda:1')
Index force: tensor([0.5518, 0.5567], device='cuda:1')
tensor([ 3.9232e-02,  6.0470e-01,  4.9266e-01,  5.5344e-01, -1.7855e-01,
         4.6331e-01,  8.6512e-01,  8.8513e-01,  1.2549e+00,  2.5733e-01,
         1.1502e-01,  1.1199e+00, -2.5224e-03,  1.3551e-02, -1.0422e-01,
        -4.9348e+00], device='cuda:1')
Solve time for step 4 3.499698089028243
Current ori: tensor([-0.0025,  0.0136, -0.1042], device='cuda:1')
Index force: tensor([0.5505], device='cuda:1')
Storing RECOVERY transition: reward=-0.0011 (scaled=-0.0011), steps=1
Reward stats updated: mean 0.0111 -> 0.0091, std: 0.0125
Collected 6 transitions for RL
Original likelihood: -72.63258361816406
Adjusted likelihood: -72.63258361816406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0022,  0.0249, -0.1031], device='cuda:1')
7 turn
Sampling time 5.063118126010522
tensor([ 1.7450e-02,  5.8226e-01,  5.0266e-01,  5.5664e-01, -1.2377e-01,
         5.1385e-01,  8.7611e-01,  9.0725e-01,  1.3351e+00,  2.5213e-01,
         1.8410e-01,  1.1576e+00,  2.1890e-03,  2.4913e-02, -1.0308e-01,
        -4.9699e+00], device='cuda:1')
Original likelihood: -71.63915252685547
Adjusted likelihood: -71.63915252685547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.287525536026806
Current ori: tensor([ 0.0022,  0.0249, -0.1031], device='cuda:1')
Middle force: tensor([0.5202, 0.5103, 0.5031, 1.4561, 0.7122, 0.5168, 0.5793, 0.7887, 0.8154,
        0.5678, 0.6785, 0.6241], device='cuda:1')
Thumb force: tensor([1.2578, 0.8319, 1.2385, 0.6140, 0.5098, 0.9215, 1.1506, 1.2006, 0.5769,
        0.5702, 0.5661, 0.6135], device='cuda:1')
Index force: tensor([0.5784, 0.7807, 0.6649, 0.7274, 0.5529, 0.6137, 0.6501, 0.6029, 0.5582,
        0.5877, 0.8813, 0.5944], device='cuda:1')
Storing NORMAL transition: reward=0.1087 (scaled=0.1087), steps=1
Reward stats updated: mean 0.0091 -> 0.0233, std: 0.0367
Collected 7 transitions for RL
tensor([ 0.0230,  0.5491,  0.5473,  0.5699, -0.1228,  0.4916,  0.8800,  0.9853,
         1.3402,  0.2816,  0.2065,  1.0591,  0.0065,  0.0232, -0.2119, -4.8930],
       device='cuda:1')
Original likelihood: -57.47109603881836
Adjusted likelihood: -57.47109603881836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.130508084024768
Current ori: tensor([ 0.0065,  0.0232, -0.2119], device='cuda:1')
Middle force: tensor([0.5089, 0.5024, 1.4280, 0.7066, 0.5144, 0.5712, 0.7799, 0.8034, 0.5589,
        0.6731, 0.6180], device='cuda:1')
Thumb force: tensor([0.8158, 1.2153, 0.6064, 0.5086, 0.9074, 1.1380, 1.1806, 0.5731, 0.5630,
        0.5610, 0.6089], device='cuda:1')
Index force: tensor([0.7663, 0.6668, 0.7120, 0.5487, 0.6134, 0.6407, 0.5977, 0.5554, 0.5851,
        0.8704, 0.5904], device='cuda:1')
Storing NORMAL transition: reward=0.0001 (scaled=0.0001), steps=1
Reward stats updated: mean 0.0233 -> 0.0204, std: 0.0352
Collected 8 transitions for RL
tensor([-1.2562e-02,  5.1425e-01,  5.9730e-01,  5.0524e-01, -1.3179e-01,
         4.9634e-01,  8.7311e-01,  9.6388e-01,  1.3243e+00,  2.2079e-01,
         2.3008e-01,  1.0092e+00,  2.7521e-03,  3.0421e-02, -2.1238e-01,
        -5.0219e+00], device='cuda:1')
Original likelihood: -110.20437622070312
Adjusted likelihood: -110.20437622070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.8685873359791
Current ori: tensor([ 0.0028,  0.0304, -0.2124], device='cuda:1')
Middle force: tensor([0.5063, 0.7525, 1.7780, 0.5427, 0.6469, 0.5081, 0.8435, 1.1722, 0.5405,
        0.5312], device='cuda:1')
Thumb force: tensor([0.5223, 0.5281, 1.5838, 0.5016, 0.6370, 0.5349, 0.5113, 1.0862, 1.2581,
        0.6176], device='cuda:1')
Index force: tensor([0.7510, 0.5018, 0.5425, 0.5503, 0.5824, 0.6293, 0.5039, 0.5288, 0.5311,
        0.5485], device='cuda:1')
Storing NORMAL transition: reward=-0.0668 (scaled=-0.0668), steps=1
Reward stats updated: mean 0.0204 -> 0.0107, std: 0.0431
Collected 9 transitions for RL
tensor([ 0.1431,  0.5621,  0.6156,  0.5410, -0.0595,  0.6189,  0.8152,  0.9212,
         1.2588,  0.1818,  0.3021,  0.9455, -0.0154, -0.0289, -0.1456, -6.2251],
       device='cuda:1')
Original likelihood: -136.92364501953125
Adjusted likelihood: -136.92364501953125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.2985531450249255
Current ori: tensor([-0.0154, -0.0289, -0.1456], device='cuda:1')
Middle force: tensor([0.6228, 0.5347, 0.5633, 0.9807, 0.5725, 0.5136, 0.5218, 0.5752, 0.7205],
       device='cuda:1')
Thumb force: tensor([0.5797, 0.5413, 0.5024, 0.5211, 0.5325, 0.7622, 0.9247, 1.0621, 1.1774],
       device='cuda:1')
Index force: tensor([0.5474, 0.5533, 0.5761, 0.5332, 0.6493, 0.5206, 0.5533, 0.5828, 0.5572],
       device='cuda:1')
Storing NORMAL transition: reward=0.1389 (scaled=0.1389), steps=1
Reward stats updated: mean 0.0107 -> 0.0235, std: 0.0561
Collected 10 transitions for RL
tensor([ 1.2318e-01,  4.2889e-01,  6.7775e-01,  8.3028e-01, -1.0346e-01,
         5.9751e-01,  7.3163e-01,  1.0906e+00,  1.3562e+00,  2.4049e-01,
         3.4678e-01,  7.5085e-01,  2.6255e-02,  4.6370e-04, -2.8435e-01,
        -6.1668e+00], device='cuda:1')
Original likelihood: -141.19105529785156
Adjusted likelihood: -141.19105529785156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 5.157406387035735
Current ori: tensor([ 0.0263,  0.0005, -0.2843], device='cuda:1')
Middle force: tensor([1.5988, 0.5516, 0.5298, 0.5281, 0.5658, 0.5110, 0.5196, 0.5240],
       device='cuda:1')
Thumb force: tensor([1.4463, 0.5157, 0.5476, 0.5432, 0.5745, 0.5194, 0.5690, 0.5448],
       device='cuda:1')
Index force: tensor([0.5344, 0.5418, 0.5312, 0.5008, 0.5853, 0.5305, 0.6505, 0.5544],
       device='cuda:1')
Storing NORMAL transition: reward=0.0822 (scaled=0.0822), steps=1
Reward stats updated: mean 0.0235 -> 0.0289, std: 0.0561
Collected 11 transitions for RL
tensor([ 1.2578e-01,  4.4213e-01,  6.7411e-01,  8.0264e-01, -9.9745e-02,
         5.7174e-01,  7.8883e-01,  1.0583e+00,  1.4094e+00,  1.8776e-01,
         3.3140e-01,  6.8944e-01,  2.0312e-02, -2.5076e-03, -3.6637e-01,
        -6.1036e+00], device='cuda:1')
Original likelihood: -138.14083862304688
Adjusted likelihood: -138.14083862304688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 4.560549172980245
Current ori: tensor([ 0.0203, -0.0025, -0.3664], device='cuda:1')
Middle force: tensor([0.5476, 0.5273, 0.5251, 0.5610, 0.5094, 0.5182, 0.5226],
       device='cuda:1')
Thumb force: tensor([0.5145, 0.5449, 0.5414, 0.5716, 0.5183, 0.5643, 0.5422],
       device='cuda:1')
Index force: tensor([0.5378, 0.5292, 0.5006, 0.5817, 0.5280, 0.6424, 0.5503],
       device='cuda:1')
Storing NORMAL transition: reward=0.0311 (scaled=0.0311), steps=1
Reward stats updated: mean 0.0289 -> 0.0291, std: 0.0537
Collected 12 transitions for RL
tensor([ 0.1084,  0.4512,  0.6620,  0.7683, -0.1116,  0.5597,  0.8054,  1.0283,
         1.4447,  0.1425,  0.3509,  0.6228,  0.0140,  0.0066, -0.3972, -6.1138],
       device='cuda:1')
Original likelihood: -145.26815795898438
Adjusted likelihood: -145.26815795898438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9951)
Solve time for step 7 4.324153546011075
Current ori: tensor([ 0.0140,  0.0066, -0.3972], device='cuda:1')
Middle force: tensor([0.5248, 0.5225, 0.5566, 0.5083, 0.5167, 0.5212], device='cuda:1')
Thumb force: tensor([0.5415, 0.5387, 0.5686, 0.5167, 0.5590, 0.5391], device='cuda:1')
Index force: tensor([0.5260, 0.5004, 0.5781, 0.5260, 0.6370, 0.5473], device='cuda:1')
Storing NORMAL transition: reward=-0.0313 (scaled=-0.0313), steps=1
Reward stats updated: mean 0.0291 -> 0.0244, std: 0.0540
Collected 13 transitions for RL
tensor([ 0.0924,  0.4529,  0.6641,  0.7321, -0.1198,  0.5846,  0.7657,  1.0126,
         1.4586,  0.1925,  0.3110,  0.6376,  0.0097,  0.0137, -0.3660, -6.2250],
       device='cuda:1')
Original likelihood: -141.64598083496094
Adjusted likelihood: -141.64598083496094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 8 4.800749447953422
Current ori: tensor([ 0.0097,  0.0137, -0.3660], device='cuda:1')
Middle force: tensor([0.7154, 0.7538, 0.5338, 0.5548, 0.5887], device='cuda:1')
Thumb force: tensor([1.0879, 0.5540, 0.5456, 0.6198, 0.5919], device='cuda:1')
Index force: tensor([0.5753, 0.5411, 0.5648, 0.8085, 0.5680], device='cuda:1')
Storing NORMAL transition: reward=0.0391 (scaled=0.0391), steps=1
Reward stats updated: mean 0.0244 -> 0.0255, std: 0.0522
Collected 14 transitions for RL
tensor([ 4.6888e-02,  4.8171e-01,  6.1218e-01,  6.7117e-01, -1.5393e-01,
         6.0238e-01,  6.8256e-01,  1.0684e+00,  1.5000e+00,  1.7981e-01,
         3.1661e-01,  5.7549e-01, -2.7755e-03,  3.9374e-02, -4.0808e-01,
        -6.2490e+00], device='cuda:1')
Original likelihood: -194.90489196777344
Adjusted likelihood: -194.90489196777344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.6097,  -2.7223,  -3.1783,  -3.2270,  -3.2965,  -3.5133,  -3.5681,
         -3.5793,  -3.8014,  -3.8930,  -3.9439,  -4.3456,  -4.3590,  -5.2899,
         -6.6087, -15.8802], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.6097,  -2.7223,  -3.1783,  -3.2270,  -3.2965,  -3.5133,  -3.5681,
         -3.5793,  -3.8014,  -3.8930,  -3.9439,  -4.3456,  -4.3590,  -5.2899,
         -6.6087, -15.8802], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.6135
1 mode projection succeeded
New goal: tensor([ 0.0601,  0.5023,  0.5387,  0.7786, -0.0265,  0.5985,  0.6609,  0.9070,
         1.2427,  0.4137,  0.3515,  0.8289, -0.0117,  0.0059, -1.2233],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -58.456878662109375
Adjusted likelihood: -58.456878662109375
Likelihood residual: 0.0
Original likelihood: -143.0003204345703
Adjusted likelihood: -143.0003204345703
Likelihood residual: 0.0
{'index': 143.0003204345703, 'thumb_middle': 58.456878662109375}
Current yaw: tensor([-0.0028,  0.0394, -0.4081], device='cuda:1')
8 thumb_middle
tensor([ 4.6888e-02,  4.8171e-01,  6.1218e-01,  6.7117e-01, -1.5393e-01,
         6.0238e-01,  6.8256e-01,  1.0684e+00,  1.5000e+00,  1.7981e-01,
         3.1661e-01,  5.7549e-01, -2.7755e-03,  3.9374e-02, -4.0808e-01,
        -6.2490e+00], device='cuda:1')
Solve time for step 1 9.2832297529676
Current ori: tensor([-0.0028,  0.0394, -0.4081], device='cuda:1')
Index force: tensor([0.5532, 0.6045, 0.6038, 0.5794], device='cuda:1')
tensor([ 0.0592,  0.5251,  0.5350,  0.7280, -0.1655,  0.5743,  0.6223,  0.9072,
         1.2581,  0.3636,  0.2942,  0.7641, -0.0079,  0.0323, -0.4081, -6.2203],
       device='cuda:1')
Solve time for step 2 3.892253433994483
Current ori: tensor([-0.0079,  0.0323, -0.4081], device='cuda:1')
Index force: tensor([0.5968, 0.5976, 0.5742], device='cuda:1')
tensor([ 0.0683,  0.5284,  0.5295,  0.7467, -0.1571,  0.5818,  0.6237,  0.8864,
         1.2285,  0.3955,  0.2906,  0.7955, -0.0070,  0.0271, -0.4081, -6.2039],
       device='cuda:1')
Solve time for step 3 3.5846948850085028
Current ori: tensor([-0.0070,  0.0271, -0.4081], device='cuda:1')
Index force: tensor([0.5871, 0.5660], device='cuda:1')
tensor([ 8.8075e-02,  5.1720e-01,  5.4721e-01,  7.8010e-01, -1.4187e-01,
         5.9020e-01,  6.2715e-01,  8.8206e-01,  1.2154e+00,  4.0330e-01,
         2.8769e-01,  8.0093e-01, -9.7928e-04,  1.6180e-02, -4.0808e-01,
        -6.1635e+00], device='cuda:1')
Solve time for step 4 3.5477559120045044
Current ori: tensor([-0.0010,  0.0162, -0.4081], device='cuda:1')
Index force: tensor([0.5675], device='cuda:1')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0008), steps=8
Reward stats updated: mean 0.0255 -> 0.0238, std: 0.0508
Collected 15 transitions for RL
Original likelihood: -81.95751953125
Adjusted likelihood: -81.95751953125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0012,  0.0180, -0.4114], device='cuda:1')
9 turn
Sampling time 5.223552049021237
tensor([ 8.4300e-02,  5.1178e-01,  5.4774e-01,  7.8704e-01, -8.5506e-02,
         6.3704e-01,  6.6956e-01,  9.0511e-01,  1.2667e+00,  4.1397e-01,
         3.4690e-01,  8.3846e-01,  1.2043e-03,  1.7995e-02, -4.1137e-01,
        -6.1690e+00], device='cuda:1')
Original likelihood: -85.31058502197266
Adjusted likelihood: -85.31058502197266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.96376366802724
Current ori: tensor([ 0.0012,  0.0180, -0.4114], device='cuda:1')
Middle force: tensor([0.8616, 1.1405, 0.7430, 0.5015, 1.2131, 0.5734, 0.8228, 0.9324, 0.5865,
        1.0106, 0.5340, 0.6076], device='cuda:1')
Thumb force: tensor([0.5486, 1.6318, 0.9608, 0.5973, 0.5685, 0.5911, 0.5657, 0.5674, 0.6040,
        0.5851, 0.5784, 0.5676], device='cuda:1')
Index force: tensor([0.5111, 0.5242, 0.8438, 0.5092, 0.5688, 0.5976, 0.5349, 0.5333, 0.5940,
        0.5518, 0.7572, 0.5637], device='cuda:1')
Storing NORMAL transition: reward=-0.0403 (scaled=-0.0403), steps=1
Reward stats updated: mean 0.0238 -> 0.0198, std: 0.0516
Collected 16 transitions for RL
tensor([ 9.3768e-02,  5.6903e-01,  5.1839e-01,  6.8430e-01,  3.9375e-02,
         7.5063e-01,  6.6991e-01,  8.9848e-01,  1.2197e+00,  3.6854e-01,
         1.4279e-01,  7.3688e-01,  2.7877e-03, -8.5944e-02, -3.7739e-01,
        -5.7782e+00], device='cuda:1')
Original likelihood: -200.4114227294922
Adjusted likelihood: -200.4114227294922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.7314,  -5.1069,  -5.1814,  -5.2654,  -5.6163,  -6.5815,  -8.8742,
         -9.0178,  -9.0918,  -9.1616, -10.8145, -11.4612, -11.7635, -12.9923,
        -14.5730, -20.0785], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.7314,  -5.1069,  -5.1814,  -5.2654,  -5.6163,  -6.5815,  -8.8742,
         -9.0178,  -9.0918,  -9.1616, -10.8145, -11.4612, -11.7635, -12.9923,
        -14.5730, -20.0785], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.3945
1 mode projection succeeded
New goal: tensor([ 0.0716,  0.4527,  0.6521,  0.7033, -0.0728,  0.5775,  0.9025,  0.7667,
         1.2418,  0.5639,  0.3059,  0.8279, -0.0191, -0.0133, -0.0648],
       device='cuda:1')
tensor([[0.0184]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -191.94302368164062
Adjusted likelihood: -191.94302368164062
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 191.94302368164062}
Current yaw: tensor([ 0.0028, -0.0859, -0.3774], device='cuda:1')
10 thumb_middle
tensor([ 9.3768e-02,  5.6903e-01,  5.1839e-01,  6.8430e-01,  3.9375e-02,
         7.5063e-01,  6.6991e-01,  8.9848e-01,  1.2197e+00,  3.6854e-01,
         1.4279e-01,  7.3688e-01,  2.7877e-03, -8.5944e-02, -3.7739e-01,
        -5.7782e+00], device='cuda:1')
Solve time for step 1 9.485115716001019
Current ori: tensor([ 0.0028, -0.0859, -0.3774], device='cuda:1')
Index force: tensor([0.6258, 0.5863, 0.5012, 0.6153], device='cuda:1')
tensor([ 8.6834e-02,  5.5483e-01,  5.8076e-01,  6.1322e-01, -9.3075e-02,
         6.3426e-01,  8.6390e-01,  7.9255e-01,  1.1896e+00,  5.2084e-01,
         1.8887e-01,  7.7167e-01,  1.1964e-03, -9.1179e-02, -3.8040e-01,
        -5.6459e+00], device='cuda:1')
Solve time for step 2 4.020654994994402
Current ori: tensor([ 0.0012, -0.0912, -0.3804], device='cuda:1')
Index force: tensor([0.6382, 0.5985, 0.5503], device='cuda:1')
tensor([ 8.5679e-02,  5.5733e-01,  6.6600e-01,  6.7020e-01, -8.4792e-02,
         6.3306e-01,  9.0723e-01,  7.7609e-01,  1.1826e+00,  5.6051e-01,
         1.8218e-01,  7.7051e-01, -2.9469e-03, -1.9565e-01, -3.8668e-01,
        -5.1088e+00], device='cuda:1')
Solve time for step 3 3.8593904260196723
Current ori: tensor([-0.0029, -0.1957, -0.3867], device='cuda:1')
Index force: tensor([0.5016, 0.5021], device='cuda:1')
tensor([ 7.5307e-02,  5.7833e-01,  6.7925e-01,  6.8501e-01, -2.2031e-02,
         6.8487e-01,  9.2276e-01,  7.5590e-01,  1.1490e+00,  5.7719e-01,
         1.0739e-01,  7.3496e-01,  1.9207e-04, -2.8786e-01, -4.5919e-01,
        -4.6431e+00], device='cuda:1')
Solve time for step 4 3.593462929013185
Current ori: tensor([ 1.9207e-04, -2.8786e-01, -4.5919e-01], device='cuda:1')
Index force: tensor([0.5025], device='cuda:1')
Storing RECOVERY transition: reward=0.1110 (scaled=0.1110), steps=1
Reward stats updated: mean 0.0198 -> 0.0252, std: 0.0545
Collected 17 transitions for RL
Original likelihood: -399.7471923828125
Adjusted likelihood: -399.7471923828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-141.1308, -198.7275, -204.0320, -205.2267, -235.8822, -238.0448,
        -247.2071, -310.3657, -413.9254, -470.8984, -543.2321, -563.0527,
        -576.5648, -598.5777, -644.9005, -684.3683], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([-141.1308, -198.7275, -204.0320, -205.2267, -235.8822, -238.0448,
        -247.2071, -310.3657, -413.9254, -470.8984, -543.2321, -563.0527,
        -576.5648, -598.5777, -644.9005, -684.3683], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -392.2585
1 mode projection failed, trying anyway
New goal: tensor([ 0.1263,  0.4626,  0.6884,  0.6299,  0.0210,  0.5798,  0.7741,  0.8858,
         1.3072,  0.2781,  0.1090,  1.0871,  0.0117, -0.1310,  0.7295],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0081]], device='cuda:1') tensor([[0.0117]], device='cuda:1')
Original likelihood: -318.8072204589844
Adjusted likelihood: -318.8072204589844
Likelihood residual: 0.0
Original likelihood: -241.06979370117188
Adjusted likelihood: -241.06979370117188
Likelihood residual: 0.0
{'index': 241.06979370117188, 'thumb_middle': 318.8072204589844}
Current yaw: tensor([ 0.0257, -0.2555, -0.5616], device='cuda:1')
11 index
tensor([ 0.0567,  0.6270,  0.6906,  0.7077,  0.1212,  0.8027,  0.9466,  0.7364,
         1.2018,  0.5601,  0.1608,  0.6944,  0.0257, -0.2555, -0.5616, -3.1885],
       device='cuda:1')
Solve time for step 1 11.48057998996228
Current ori: tensor([ 0.0257, -0.2555, -0.5616], device='cuda:1')
Middle force: tensor([0.5796, 0.5043, 0.5440, 0.5993], device='cuda:1')
Thumb force: tensor([0.5375, 0.5107, 0.6072, 0.5529], device='cuda:1')
tensor([ 0.1160,  0.5399,  0.7029,  0.6413,  0.1150,  0.8613,  0.9223,  0.8941,
         1.2675,  0.3367,  0.0442,  0.9279,  0.1091, -0.2920, -0.6679, -1.3233],
       device='cuda:1')
Solve time for step 2 4.42217537201941
Current ori: tensor([ 0.1091, -0.2920, -0.6679], device='cuda:1')
Middle force: tensor([0.5039, 0.5399, 0.5993], device='cuda:1')
Thumb force: tensor([0.5097, 0.6055, 0.5478], device='cuda:1')
tensor([ 0.1378,  0.5342,  0.7153,  0.6357,  0.0959,  0.8972,  0.9321,  0.9154,
         1.3169,  0.2474,  0.1011,  0.9719,  0.2098, -0.3437, -0.7894, -0.7479],
       device='cuda:1')
Solve time for step 3 4.4005964460084215
Current ori: tensor([ 0.2098, -0.3437, -0.7894], device='cuda:1')
Middle force: tensor([0.5355, 0.5992], device='cuda:1')
Thumb force: tensor([0.5952, 0.5402], device='cuda:1')
tensor([ 0.1849,  0.5812,  0.7766,  0.6584,  0.0934,  1.0023,  0.9501,  0.8808,
         1.3140,  0.2871,  0.2114,  0.9554,  0.2521, -0.3130, -0.9171, -1.4253],
       device='cuda:1')
Solve time for step 4 4.183791165007278
Current ori: tensor([ 0.2521, -0.3130, -0.9171], device='cuda:1')
Middle force: tensor([0.6017], device='cuda:1')
Thumb force: tensor([0.5396], device='cuda:1')
Storing RECOVERY transition: reward=0.1029 (scaled=0.1029), steps=1
Reward stats updated: mean 0.0252 -> 0.0295, std: 0.0558
Collected 18 transitions for RL
Original likelihood: -1226.04296875
Adjusted likelihood: -1226.04296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 2
Loaded trajectory sampler
Current yaw: tensor([ 0.0006,  0.0140, -0.0473], device='cuda:1')
Current yaw: tensor([ 0.0006,  0.0140, -0.0473], device='cuda:1')
1 turn
Sampling time 5.061293184990063
tensor([ 1.4674e-01,  5.9892e-01,  5.8000e-01,  6.0703e-01, -1.2247e-01,
         5.4605e-01,  8.8914e-01,  9.4267e-01,  1.2294e+00,  2.9369e-01,
         2.4729e-01,  1.1782e+00,  6.3643e-04,  1.4027e-02, -4.7310e-02,
         2.2975e-01], device='cuda:1')
Original likelihood: -106.90033721923828
Adjusted likelihood: -106.90033721923828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.890381009026896
Current ori: tensor([ 0.0006,  0.0140, -0.0473], device='cuda:1')
Middle force: tensor([0.5900, 0.5046, 1.4837, 0.5611, 0.5517, 0.5609, 0.4759, 0.5603, 0.5264,
        1.9982, 0.7747, 0.6028], device='cuda:1')
Thumb force: tensor([0.6371, 0.9958, 1.9336, 0.7784, 1.1038, 0.5758, 0.6492, 0.7715, 2.0246,
        0.5549, 0.5548, 0.6030], device='cuda:1')
Index force: tensor([0.5390, 0.9663, 0.5619, 0.5533, 0.6332, 0.5705, 0.6423, 0.8936, 0.6275,
        0.6322, 0.5162, 0.5606], device='cuda:1')
Storing NORMAL transition: reward=-0.0015 (scaled=-0.0015), steps=1
Reward stats updated: mean 0.0295 -> 0.0279, std: 0.0548
Collected 19 transitions for RL
tensor([ 0.1925,  0.6100,  0.5840,  0.6667, -0.1462,  0.6046,  0.8230,  0.8496,
         1.2044,  0.2311,  0.1992,  1.2259,  0.0026, -0.0184, -0.0460,  0.4341],
       device='cuda:1')
Original likelihood: -188.13096618652344
Adjusted likelihood: -188.13096618652344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.4623, -3.5336, -3.6300, -3.8983, -3.9350, -4.0291, -4.0441, -4.0660,
        -4.1498, -4.1991, -4.3550, -4.9413, -5.3192, -5.5104, -5.9539, -6.4388],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.4623, -3.5336, -3.6300, -3.8983, -3.9350, -4.0291, -4.0441, -4.0660,
        -4.1498, -4.1991, -4.3550, -4.9413, -5.3192, -5.5104, -5.9539, -6.4388],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.4666
1 mode projection succeeded
New goal: tensor([ 0.0396,  0.5367,  0.5412,  0.6485, -0.0564,  0.5214,  0.8117,  0.8568,
         1.2742,  0.3040,  0.2118,  1.1708,  0.0041,  0.0145, -1.4633],
       device='cuda:1')
tensor([[0.0059]], device='cuda:1') tensor([[0.0090]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -101.43962097167969
Adjusted likelihood: -101.43962097167969
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 101.43962097167969}
Current yaw: tensor([ 0.0026, -0.0184, -0.0460], device='cuda:1')
2 thumb_middle
tensor([ 0.1925,  0.6100,  0.5840,  0.6667, -0.1462,  0.6046,  0.8230,  0.8496,
         1.2044,  0.2311,  0.1992,  1.2259,  0.0026, -0.0184, -0.0460,  0.4341],
       device='cuda:1')
Solve time for step 1 9.267799688037485
Current ori: tensor([ 0.0026, -0.0184, -0.0460], device='cuda:1')
Index force: tensor([0.5392, 0.6205, 0.5001, 0.6141], device='cuda:1')
tensor([ 0.1862,  0.6032,  0.5861,  0.6661, -0.1285,  0.5287,  0.7958,  0.8444,
         1.2103,  0.2713,  0.1189,  1.1432,  0.0037, -0.0143, -0.0460,  0.4279],
       device='cuda:1')
Solve time for step 2 3.8907134429900907
Current ori: tensor([ 0.0037, -0.0143, -0.0460], device='cuda:1')
Index force: tensor([0.6432, 0.6173, 0.6172], device='cuda:1')
tensor([ 0.1409,  0.5902,  0.5648,  0.6480, -0.1524,  0.5098,  0.7835,  0.8391,
         1.2352,  0.2837,  0.1223,  1.1378,  0.0041,  0.0114, -0.0460,  0.3607],
       device='cuda:1')
Solve time for step 3 3.6728165770182386
Current ori: tensor([ 0.0041,  0.0114, -0.0460], device='cuda:1')
Index force: tensor([0.6098, 0.6124], device='cuda:1')
tensor([ 0.0923,  0.5732,  0.5435,  0.6382, -0.1858,  0.4911,  0.7693,  0.8292,
         1.2551,  0.2897,  0.1391,  1.1442,  0.0077,  0.0393, -0.0460,  0.2863],
       device='cuda:1')
Solve time for step 4 3.5877786349738017
Current ori: tensor([ 0.0077,  0.0393, -0.0460], device='cuda:1')
Index force: tensor([0.5890], device='cuda:1')
Storing RECOVERY transition: reward=-0.0019 (scaled=-0.0019), steps=1
Reward stats updated: mean 0.0279 -> 0.0264, std: 0.0538
Collected 20 transitions for RL
Original likelihood: -177.31234741210938
Adjusted likelihood: -177.31234741210938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.8878, -3.1643, -3.2102, -3.8078, -3.9857, -3.9977, -4.0350, -4.0812,
        -4.3818, -4.3920, -4.3947, -4.4004, -5.1572, -5.2085, -5.2944, -6.0866],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8878, -3.1643, -3.2102, -3.8078, -3.9857, -3.9977, -4.0350, -4.0812,
        -4.3818, -4.3920, -4.3947, -4.4004, -5.1572, -5.2085, -5.2944, -6.0866],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.2803
1 mode projection succeeded
New goal: tensor([ 0.0666,  0.5616,  0.5707,  0.5685, -0.0822,  0.5287,  0.8424,  0.8698,
         1.2500,  0.3590,  0.2041,  1.1952,  0.0042,  0.0138,  0.9486],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -122.54144287109375
Adjusted likelihood: -122.54144287109375
Likelihood residual: 0.0
Original likelihood: -81.48306274414062
Adjusted likelihood: -81.48306274414062
Likelihood residual: 0.0
{'index': 81.48306274414062, 'thumb_middle': 122.54144287109375}
Current yaw: tensor([ 0.0134,  0.0469, -0.0460], device='cuda:1')
3 index
tensor([ 0.0757,  0.5549,  0.5462,  0.6517, -0.1259,  0.5280,  0.8026,  0.8500,
         1.3239,  0.3158,  0.2022,  1.1733,  0.0134,  0.0469, -0.0460,  0.3232],
       device='cuda:1')
Solve time for step 1 11.015140308008995
Current ori: tensor([ 0.0134,  0.0469, -0.0460], device='cuda:1')
Middle force: tensor([0.5887, 0.5624, 0.5102, 0.5382], device='cuda:1')
Thumb force: tensor([0.5063, 0.5885, 0.5293, 0.5325], device='cuda:1')
tensor([ 0.1083,  0.5018,  0.5208,  0.5603, -0.0979,  0.5188,  0.8330,  0.8666,
         1.2883,  0.3537,  0.1901,  1.1964,  0.0177,  0.0267, -0.0817,  0.4420],
       device='cuda:1')
Solve time for step 2 4.442500551987905
Current ori: tensor([ 0.0177,  0.0267, -0.0817], device='cuda:1')
Middle force: tensor([0.5597, 0.5090, 0.5348], device='cuda:1')
Thumb force: tensor([0.5812, 0.5278, 0.5310], device='cuda:1')
tensor([ 0.1108,  0.5046,  0.5202,  0.5507, -0.0928,  0.5244,  0.8304,  0.8634,
         1.2857,  0.3556,  0.1863,  1.1969,  0.0159,  0.0236, -0.0825,  0.4072],
       device='cuda:1')
Solve time for step 3 4.3061150389839895
Current ori: tensor([ 0.0159,  0.0236, -0.0825], device='cuda:1')
Middle force: tensor([0.5347, 0.5539], device='cuda:1')
Thumb force: tensor([0.6126, 0.5829], device='cuda:1')
tensor([ 0.1117,  0.5039,  0.5198,  0.5469, -0.0884,  0.5430,  0.8144,  0.8406,
         1.2936,  0.3512,  0.1813,  1.1760,  0.0059,  0.0222, -0.0910,  0.3238],
       device='cuda:1')
Solve time for step 4 4.411024774017278
Current ori: tensor([ 0.0059,  0.0222, -0.0910], device='cuda:1')
Middle force: tensor([0.5518], device='cuda:1')
Thumb force: tensor([0.5754], device='cuda:1')
Storing RECOVERY transition: reward=0.0563 (scaled=0.0563), steps=1
Reward stats updated: mean 0.0264 -> 0.0278, std: 0.0529
Collected 21 transitions for RL
Original likelihood: -53.28019714355469
Adjusted likelihood: -53.28019714355469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0082,  0.0241, -0.1027], device='cuda:1')
4 turn
Sampling time 5.096551400027238
tensor([ 0.0598,  0.5636,  0.5636,  0.5661, -0.0965,  0.5372,  0.8240,  0.8509,
         1.2923,  0.3569,  0.1830,  1.1806,  0.0082,  0.0241, -0.1027,  0.3120],
       device='cuda:1')
Original likelihood: -53.31568908691406
Adjusted likelihood: -53.31568908691406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.650283086986747
Current ori: tensor([ 0.0082,  0.0241, -0.1027], device='cuda:1')
Middle force: tensor([1.3322, 0.5152, 0.5015, 0.5162, 0.5901, 0.6076, 1.0798, 0.5432, 0.4936,
        0.5568, 0.5584, 0.5592], device='cuda:1')
Thumb force: tensor([1.9489, 1.9664, 1.4215, 0.5555, 1.1133, 0.7784, 1.5169, 0.6110, 0.5452,
        1.0210, 0.5698, 0.9424], device='cuda:1')
Index force: tensor([0.5692, 0.8549, 0.8074, 0.6667, 0.5767, 0.5648, 0.5901, 0.6327, 0.8063,
        0.5592, 0.7233, 0.5721], device='cuda:1')
Storing NORMAL transition: reward=0.2108 (scaled=0.2108), steps=1
Reward stats updated: mean 0.0278 -> 0.0361, std: 0.0642
Collected 22 transitions for RL
tensor([ 0.0771,  0.5510,  0.5656,  0.6288, -0.0874,  0.4782,  0.8481,  1.0155,
         1.3681,  0.3052,  0.1628,  1.0516,  0.0165,  0.0151, -0.3137,  0.5955],
       device='cuda:1')
Original likelihood: -74.0039291381836
Adjusted likelihood: -74.0039291381836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.071622012008447
Current ori: tensor([ 0.0165,  0.0151, -0.3137], device='cuda:1')
Middle force: tensor([0.5130, 0.5009, 0.5146, 0.5927, 0.6082, 1.0239, 0.7949, 0.7921, 0.6145,
        0.7366, 0.6064], device='cuda:1')
Thumb force: tensor([1.8684, 1.3549, 0.5372, 1.0773, 0.7680, 1.4283, 0.5777, 0.6936, 0.6696,
        0.5398, 0.5695], device='cuda:1')
Index force: tensor([0.8288, 0.7765, 0.6652, 0.5715, 0.5563, 0.5853, 0.5246, 0.5811, 0.5670,
        0.5003, 0.6215], device='cuda:1')
Storing NORMAL transition: reward=0.0718 (scaled=0.0718), steps=1
Reward stats updated: mean 0.0361 -> 0.0377, std: 0.0632
Collected 23 transitions for RL
tensor([ 0.0508,  0.5119,  0.5721,  0.6684, -0.1603,  0.4779,  0.7291,  1.0348,
         1.5000,  0.1611,  0.2181,  0.9150,  0.0213,  0.0750, -0.3977, -0.2721],
       device='cuda:1')
Original likelihood: -295.66156005859375
Adjusted likelihood: -295.66156005859375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.5627,  -3.8735,  -4.6900,  -4.8140,  -5.0632,  -5.3473,  -5.6824,
         -5.9207,  -6.9120,  -6.9798,  -7.0997,  -7.5629,  -7.7528,  -8.0472,
         -8.7499, -10.5115], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.5627,  -3.8735,  -4.6900,  -4.8140,  -5.0632,  -5.3473,  -5.6824,
         -5.9207,  -6.9120,  -6.9798,  -7.0997,  -7.5629,  -7.7528,  -8.0472,
         -8.7499, -10.5115], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.4106
1 mode projection succeeded
New goal: tensor([ 0.0314,  0.5359,  0.5354,  0.6446, -0.0705,  0.4853,  0.8777,  0.8500,
         1.2860,  0.2782,  0.2021,  1.1899,  0.0056,  0.0172, -1.4407],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -113.85140991210938
Adjusted likelihood: -113.85140991210938
Likelihood residual: 0.0
Original likelihood: -90.1717300415039
Adjusted likelihood: -90.1717300415039
Likelihood residual: 0.0
{'index': 90.1717300415039, 'thumb_middle': 113.85140991210938}
Current yaw: tensor([ 0.0213,  0.0750, -0.3977], device='cuda:1')
5 index
tensor([ 0.0508,  0.5119,  0.5721,  0.6684, -0.1603,  0.4779,  0.7291,  1.0348,
         1.5000,  0.1611,  0.2181,  0.9150,  0.0213,  0.0750, -0.3977, -0.2721],
       device='cuda:1')
Solve time for step 1 11.724692423013039
Current ori: tensor([ 0.0213,  0.0750, -0.3977], device='cuda:1')
Middle force: tensor([0.6288, 0.5550, 0.5470, 0.5014], device='cuda:1')
Thumb force: tensor([0.7075, 0.5508, 0.5217, 0.6045], device='cuda:1')
tensor([ 0.0712,  0.4768,  0.4953,  0.6263, -0.0995,  0.4351,  0.8789,  0.9342,
         1.4046,  0.2862,  0.1879,  1.0108,  0.0276,  0.0358, -0.4006,  0.3400],
       device='cuda:1')
Solve time for step 2 4.806328425009269
Current ori: tensor([ 0.0276,  0.0358, -0.4006], device='cuda:1')
Middle force: tensor([0.5501, 0.5428, 0.5011], device='cuda:1')
Thumb force: tensor([0.5482, 0.5189, 0.5995], device='cuda:1')
tensor([ 0.0776,  0.4846,  0.4867,  0.6201, -0.0571,  0.4540,  0.9022,  0.9047,
         1.3813,  0.2991,  0.1435,  1.0617,  0.0252,  0.0085, -0.3941,  0.6357],
       device='cuda:1')
Solve time for step 3 4.283001477015205
Current ori: tensor([ 0.0252,  0.0085, -0.3941], device='cuda:1')
Middle force: tensor([0.5608, 0.5865], device='cuda:1')
Thumb force: tensor([0.5493, 0.5688], device='cuda:1')
tensor([ 8.0124e-02,  4.8515e-01,  4.8754e-01,  6.1888e-01, -4.5446e-02,
         4.5740e-01,  9.1591e-01,  9.0184e-01,  1.3744e+00,  3.0060e-01,
         1.2657e-01,  1.0863e+00,  2.7946e-02, -8.9172e-04, -3.9436e-01,
         6.8655e-01], device='cuda:1')
Solve time for step 4 4.582918594009243
Current ori: tensor([ 0.0279, -0.0009, -0.3944], device='cuda:1')
Middle force: tensor([0.5675], device='cuda:1')
Thumb force: tensor([0.5796], device='cuda:1')
Storing RECOVERY transition: reward=0.0037 (scaled=0.0018), steps=2
Reward stats updated: mean 0.0377 -> 0.0362, std: 0.0623
Collected 24 transitions for RL
Original likelihood: -99.9611587524414
Adjusted likelihood: -99.9611587524414
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0216, -0.0185, -0.3901], device='cuda:1')
6 turn
Sampling time 5.040778563998174
tensor([ 0.0427,  0.5464,  0.5282,  0.6393, -0.0196,  0.4883,  0.9091,  0.8795,
         1.3539,  0.3225,  0.1075,  1.0979,  0.0216, -0.0185, -0.3901,  0.7012],
       device='cuda:1')
Original likelihood: -97.76415252685547
Adjusted likelihood: -97.76415252685547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.897319259995129
Current ori: tensor([ 0.0216, -0.0185, -0.3901], device='cuda:1')
Middle force: tensor([0.8927, 0.5288, 0.9867, 0.5149, 1.0629, 0.5561, 1.0085, 1.1084, 0.5536,
        0.4826, 0.5153, 0.5518], device='cuda:1')
Thumb force: tensor([0.8331, 0.5892, 0.6474, 1.0233, 0.7449, 0.4862, 0.8843, 1.6279, 0.4855,
        0.6751, 0.5357, 0.5259], device='cuda:1')
Index force: tensor([1.0442, 0.5373, 0.7752, 0.6649, 0.7299, 0.5583, 0.5200, 0.7943, 0.5825,
        0.5066, 0.5348, 0.5648], device='cuda:1')
Storing NORMAL transition: reward=0.0381 (scaled=0.0381), steps=1
Reward stats updated: mean 0.0362 -> 0.0363, std: 0.0610
Collected 25 transitions for RL
tensor([ 0.0140,  0.5416,  0.5151,  0.6267, -0.0395,  0.4727,  0.8990,  0.9150,
         1.3975,  0.2982,  0.1193,  1.0401,  0.0225, -0.0054, -0.4280,  0.7408],
       device='cuda:1')
Original likelihood: -94.8416748046875
Adjusted likelihood: -94.8416748046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.106942160986364
Current ori: tensor([ 0.0225, -0.0054, -0.4280], device='cuda:1')
Middle force: tensor([0.5938, 0.5419, 1.1523, 0.8365, 0.8797, 0.8151, 0.5956, 0.5553, 0.6152,
        1.0012, 0.5889], device='cuda:1')
Thumb force: tensor([0.5624, 0.5437, 1.1323, 0.5118, 0.5029, 0.5735, 0.8015, 0.5598, 0.5972,
        0.5765, 0.5958], device='cuda:1')
Index force: tensor([0.6528, 0.7060, 1.1743, 0.7323, 0.9632, 0.8427, 0.5520, 0.6014, 0.6041,
        0.5379, 0.6222], device='cuda:1')
Storing NORMAL transition: reward=0.0304 (scaled=0.0304), steps=1
Reward stats updated: mean 0.0363 -> 0.0360, std: 0.0599
Collected 26 transitions for RL
tensor([ 4.1330e-02,  4.6176e-01,  5.6016e-01,  8.1011e-01,  5.0802e-04,
         4.2890e-01,  8.3348e-01,  1.0094e+00,  1.4752e+00,  9.6713e-02,
         1.9963e-01,  9.4303e-01,  6.9931e-02, -6.4276e-03, -4.6327e-01,
         8.8945e-01], device='cuda:1')
Original likelihood: -179.89358520507812
Adjusted likelihood: -179.89358520507812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -8.4907,  -8.8443,  -9.9376, -10.0328, -12.6051, -13.1799, -13.2487,
        -13.2586, -13.6712, -13.6893, -14.5867, -14.8157, -15.0800, -15.1707,
        -15.8076, -15.9212], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -8.4907,  -8.8443,  -9.9376, -10.0328, -12.6051, -13.1799, -13.2487,
        -13.2586, -13.6712, -13.6893, -14.5867, -14.8157, -15.0800, -15.1707,
        -15.8076, -15.9212], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -13.0213
1 mode projection succeeded
New goal: tensor([ 0.0237,  0.5454,  0.5287,  0.6166, -0.0411,  0.4627,  0.8374,  0.9548,
         1.2813,  0.3069,  0.2115,  1.1405,  0.0064,  0.0110,  0.2917],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0039]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -100.44792175292969
Adjusted likelihood: -100.44792175292969
Likelihood residual: 0.0
Original likelihood: -184.78565979003906
Adjusted likelihood: -184.78565979003906
Likelihood residual: 0.0
{'index': 184.78565979003906, 'thumb_middle': 100.44792175292969}
Current yaw: tensor([ 0.0699, -0.0064, -0.4633], device='cuda:1')
7 thumb_middle
tensor([ 4.1330e-02,  4.6176e-01,  5.6016e-01,  8.1011e-01,  5.0802e-04,
         4.2890e-01,  8.3348e-01,  1.0094e+00,  1.4752e+00,  9.6713e-02,
         1.9963e-01,  9.4303e-01,  6.9931e-02, -6.4276e-03, -4.6327e-01,
         8.8945e-01], device='cuda:1')
Solve time for step 1 9.839644958032295
Current ori: tensor([ 0.0699, -0.0064, -0.4633], device='cuda:1')
Index force: tensor([0.6154, 0.5865, 0.5717, 0.5602], device='cuda:1')
tensor([ 0.0238,  0.4883,  0.5642,  0.6955, -0.1286,  0.4536,  0.8067,  0.9377,
         1.2674,  0.2474,  0.1442,  1.0798,  0.0567,  0.0071, -0.4633,  0.9075],
       device='cuda:1')
Solve time for step 2 3.9731728190090507
Current ori: tensor([ 0.0567,  0.0071, -0.4633], device='cuda:1')
Index force: tensor([0.5754, 0.5631, 0.5534], device='cuda:1')
tensor([ 0.0188,  0.5356,  0.5228,  0.6381, -0.1476,  0.4549,  0.8065,  0.9464,
         1.2357,  0.2804,  0.1424,  1.1204,  0.0453,  0.0126, -0.4633,  0.9333],
       device='cuda:1')
Solve time for step 3 3.897235195967369
Current ori: tensor([ 0.0453,  0.0126, -0.4633], device='cuda:1')
Index force: tensor([0.5488, 0.5432], device='cuda:1')
tensor([ 0.0244,  0.5637,  0.5136,  0.5885, -0.1343,  0.4507,  0.8052,  0.9184,
         1.2343,  0.2971,  0.1397,  1.1089,  0.0343,  0.0085, -0.4633,  0.9194],
       device='cuda:1')
Solve time for step 4 3.751799572026357
Current ori: tensor([ 0.0343,  0.0085, -0.4633], device='cuda:1')
Index force: tensor([0.5320], device='cuda:1')
Storing RECOVERY transition: reward=0.0023 (scaled=0.0011), steps=2
Reward stats updated: mean 0.0360 -> 0.0347, std: 0.0591
Collected 27 transitions for RL
Original likelihood: -80.28669738769531
Adjusted likelihood: -80.28669738769531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0419,  0.0130, -0.4622], device='cuda:1')
8 turn
Sampling time 5.156007340992801
tensor([ 0.0151,  0.5457,  0.5133,  0.6223, -0.0783,  0.4992,  0.8402,  0.9551,
         1.3090,  0.3115,  0.1972,  1.1428,  0.0419,  0.0130, -0.4622,  0.9518],
       device='cuda:1')
Original likelihood: -76.17335510253906
Adjusted likelihood: -76.17335510253906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.304677879961673
Current ori: tensor([ 0.0419,  0.0130, -0.4622], device='cuda:1')
Middle force: tensor([1.2816, 0.5223, 1.1359, 0.8529, 0.5045, 1.0302, 0.7569, 0.5877, 0.5567,
        0.7935, 0.6507, 0.5550], device='cuda:1')
Thumb force: tensor([1.2947, 0.6964, 1.2098, 0.5039, 0.5591, 0.6088, 0.7216, 0.5653, 0.6866,
        0.5674, 0.5665, 0.5578], device='cuda:1')
Index force: tensor([0.6629, 0.7890, 1.2436, 1.0992, 1.0138, 0.5469, 0.5515, 0.6154, 0.5750,
        0.5275, 0.7407, 0.5815], device='cuda:1')
Storing NORMAL transition: reward=0.1874 (scaled=0.1874), steps=1
Reward stats updated: mean 0.0347 -> 0.0402, std: 0.0646
Collected 28 transitions for RL
tensor([ 0.0221,  0.5370,  0.5020,  0.6500, -0.0363,  0.4983,  0.8422,  1.0613,
         1.3051,  0.3528,  0.2449,  0.9548,  0.0379, -0.0181, -0.6504, -5.6363],
       device='cuda:1')
Original likelihood: -116.55328369140625
Adjusted likelihood: -116.55328369140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.189196071005426
Current ori: tensor([ 0.0379, -0.0181, -0.6504], device='cuda:1')
Middle force: tensor([0.5231, 1.1647, 0.8725, 0.5020, 1.0093, 0.7323, 0.6261, 0.6014, 0.7572,
        0.6236, 1.0705], device='cuda:1')
Thumb force: tensor([0.6662, 1.1451, 0.5037, 0.5504, 0.6031, 0.7147, 0.5794, 0.6102, 0.5622,
        0.5196, 0.5240], device='cuda:1')
Index force: tensor([0.7615, 1.1936, 1.0672, 1.0115, 0.5445, 0.5483, 0.6011, 0.6086, 0.5537,
        0.5568, 0.5515], device='cuda:1')
Storing NORMAL transition: reward=0.0270 (scaled=0.0270), steps=1
Reward stats updated: mean 0.0402 -> 0.0397, std: 0.0635
Collected 29 transitions for RL
tensor([-0.0411,  0.5688,  0.4591,  0.5568, -0.1649,  0.5760,  0.8871,  0.9714,
         1.4367,  0.1549,  0.2413,  0.8805,  0.0358,  0.0090, -0.6770, -5.6678],
       device='cuda:1')
Original likelihood: -173.74876403808594
Adjusted likelihood: -173.74876403808594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.9342, -3.1014, -3.2347, -3.4161, -3.7172, -4.0404, -4.1312, -4.2334,
        -4.2375, -4.2825, -4.3305, -4.3967, -5.2019, -5.7534, -7.0362, -7.3066],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9342, -3.1014, -3.2347, -3.4161, -3.7172, -4.0404, -4.1312, -4.2334,
        -4.2375, -4.2825, -4.3305, -4.3967, -5.2019, -5.7534, -7.0362, -7.3066],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.4596
1 mode projection succeeded
New goal: tensor([ 0.0218,  0.5353,  0.5560,  0.5871, -0.0729,  0.4911,  0.8493,  0.9310,
         1.2848,  0.3069,  0.1843,  1.2018,  0.0052,  0.0145, -0.1435],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -114.21916961669922
Adjusted likelihood: -114.21916961669922
Likelihood residual: 0.0
Original likelihood: -188.21878051757812
Adjusted likelihood: -188.21878051757812
Likelihood residual: 0.0
{'index': 188.21878051757812, 'thumb_middle': 114.21916961669922}
Current yaw: tensor([ 0.0358,  0.0090, -0.6770], device='cuda:1')
9 thumb_middle
tensor([-0.0411,  0.5688,  0.4591,  0.5568, -0.1649,  0.5760,  0.8871,  0.9714,
         1.4367,  0.1549,  0.2413,  0.8805,  0.0358,  0.0090, -0.6770, -5.6678],
       device='cuda:1')
Solve time for step 1 10.030136950023007
Current ori: tensor([ 0.0358,  0.0090, -0.6770], device='cuda:1')
Index force: tensor([0.5597, 0.5852, 0.5861, 0.5822], device='cuda:1')
tensor([-0.0437,  0.5501,  0.4989,  0.5253, -0.1779,  0.4874,  0.8144,  0.9177,
         1.2531,  0.2519,  0.1346,  1.1392,  0.0369,  0.0092, -0.6770, -5.6528],
       device='cuda:1')
Solve time for step 2 3.841665974992793
Current ori: tensor([ 0.0369,  0.0092, -0.6770], device='cuda:1')
Index force: tensor([0.5746, 0.5763, 0.5737], device='cuda:1')
tensor([-2.2890e-02,  5.2896e-01,  5.2998e-01,  5.5682e-01, -1.6219e-01,
         5.0958e-01,  8.1280e-01,  9.0572e-01,  1.2345e+00,  2.7752e-01,
         1.0904e-01,  1.1635e+00,  4.5222e-02, -2.6758e-04, -6.7696e-01,
        -5.6190e+00], device='cuda:1')
Solve time for step 3 3.7757604740327224
Current ori: tensor([ 4.5222e-02, -2.6758e-04, -6.7696e-01], device='cuda:1')
Index force: tensor([0.5669, 0.5658], device='cuda:1')
tensor([-4.5404e-03,  5.3149e-01,  5.2896e-01,  5.8200e-01, -1.3983e-01,
         4.8966e-01,  8.2446e-01,  9.2345e-01,  1.2153e+00,  2.6394e-01,
         1.0626e-01,  1.1925e+00,  4.8216e-02, -8.2868e-03, -6.7696e-01,
        -5.5882e+00], device='cuda:1')
Solve time for step 4 3.7756882089888677
Current ori: tensor([ 0.0482, -0.0083, -0.6770], device='cuda:1')
Index force: tensor([0.5600], device='cuda:1')
Storing RECOVERY transition: reward=-0.0119 (scaled=-0.0059), steps=2
Reward stats updated: mean 0.0397 -> 0.0382, std: 0.0630
Collected 30 transitions for RL
Original likelihood: -119.12638854980469
Adjusted likelihood: -119.12638854980469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0505, -0.0027, -0.6669], device='cuda:1')
10 turn
Sampling time 5.377551432000473
tensor([-1.8989e-02,  5.2297e-01,  5.3133e-01,  5.7590e-01, -8.4935e-02,
         5.4845e-01,  8.5714e-01,  9.3313e-01,  1.2817e+00,  3.0068e-01,
         1.7327e-01,  1.2255e+00,  5.0485e-02, -2.6789e-03, -6.6689e-01,
        -5.5771e+00], device='cuda:1')
Original likelihood: -113.67941284179688
Adjusted likelihood: -113.67941284179688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.252256205014419
Current ori: tensor([ 0.0505, -0.0027, -0.6669], device='cuda:1')
Middle force: tensor([0.5626, 0.5734, 1.2481, 0.6286, 2.0588, 0.6294, 1.0712, 1.0119, 0.5800,
        0.7265, 0.5742, 0.5075], device='cuda:1')
Thumb force: tensor([0.6231, 1.6449, 1.2618, 1.2138, 0.7549, 0.5592, 0.8319, 0.5047, 0.6904,
        0.5712, 0.5122, 0.5611], device='cuda:1')
Index force: tensor([0.7404, 0.5321, 1.1650, 0.6021, 0.7494, 0.6070, 0.5104, 0.5358, 0.5703,
        0.5747, 0.6142, 0.6484], device='cuda:1')
Storing NORMAL transition: reward=0.1066 (scaled=0.1066), steps=1
Reward stats updated: mean 0.0382 -> 0.0404, std: 0.0631
Collected 31 transitions for RL
tensor([-1.5037e-02,  4.8929e-01,  5.7039e-01,  6.0197e-01, -9.2191e-02,
         5.1866e-01,  8.8955e-01,  9.6615e-01,  1.3068e+00,  3.0036e-01,
         1.8848e-01,  1.1331e+00,  5.2716e-02, -1.8726e-03, -7.7436e-01,
        -5.5687e+00], device='cuda:1')
Original likelihood: -121.40557861328125
Adjusted likelihood: -121.40557861328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.674293471034616
Current ori: tensor([ 0.0527, -0.0019, -0.7744], device='cuda:1')
Middle force: tensor([0.5693, 1.2381, 0.6266, 2.0148, 0.6258, 1.0535, 1.0013, 0.5770, 0.7210,
        0.5669, 0.5068], device='cuda:1')
Thumb force: tensor([1.6102, 1.2377, 1.1932, 0.7562, 0.5572, 0.8256, 0.5045, 0.6856, 0.5678,
        0.5116, 0.5592], device='cuda:1')
Index force: tensor([0.5298, 1.1423, 0.5977, 0.7415, 0.6031, 0.5100, 0.5336, 0.5679, 0.5716,
        0.6157, 0.6465], device='cuda:1')
Storing NORMAL transition: reward=-0.0207 (scaled=-0.0207), steps=1
Reward stats updated: mean 0.0404 -> 0.0385, std: 0.0630
Collected 32 transitions for RL
tensor([-0.2046,  0.3723,  0.6098,  0.6412, -0.1267,  0.5763,  0.8060,  1.0023,
         1.2428,  0.3910,  0.2519,  1.1416,  0.0589,  0.0110, -0.7544,  5.4824],
       device='cuda:1')
Original likelihood: -183.974609375
Adjusted likelihood: -183.974609375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -7.0098,  -7.4151,  -7.6575,  -7.8371,  -7.8896,  -7.9181,  -8.2693,
         -8.6435,  -8.7293,  -8.9940, -10.3101, -10.7621, -10.9931, -11.3758,
        -13.3225, -13.3622], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -7.0098,  -7.4151,  -7.6575,  -7.8371,  -7.8896,  -7.9181,  -8.2693,
         -8.6435,  -8.7293,  -8.9940, -10.3101, -10.7621, -10.9931, -11.3758,
        -13.3225, -13.3622], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.4056
1 mode projection succeeded
New goal: tensor([-0.0344,  0.5195,  0.4936,  0.6482, -0.0128,  0.5440,  0.7071,  0.9010,
         1.2925,  0.3057,  0.2890,  0.9359,  0.0065,  0.0093,  3.0198],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -188.0875701904297
Adjusted likelihood: -188.0875701904297
Likelihood residual: 0.0
Original likelihood: -141.52894592285156
Adjusted likelihood: -141.52894592285156
Likelihood residual: 0.0
{'index': 141.52894592285156, 'thumb_middle': 188.0875701904297}
Current yaw: tensor([ 0.0589,  0.0110, -0.7544], device='cuda:1')
11 index
tensor([-0.2046,  0.3723,  0.6098,  0.6412, -0.1267,  0.5763,  0.8060,  1.0023,
         1.2428,  0.3910,  0.2519,  1.1416,  0.0589,  0.0110, -0.7544,  5.4824],
       device='cuda:1')
Solve time for step 1 11.342451050004456
Current ori: tensor([ 0.0589,  0.0110, -0.7544], device='cuda:1')
Middle force: tensor([0.5344, 0.5399, 0.5662, 0.5336], device='cuda:1')
Thumb force: tensor([0.5144, 0.6505, 0.6213, 0.5349], device='cuda:1')
tensor([-0.0200,  0.4412,  0.4642,  0.6192, -0.1305,  0.5941,  0.7889,  0.9637,
         1.2810,  0.3578,  0.2480,  1.0702,  0.0389,  0.0153, -0.7936,  5.4776],
       device='cuda:1')
Solve time for step 2 4.457560818991624
Current ori: tensor([ 0.0389,  0.0153, -0.7936], device='cuda:1')
Middle force: tensor([0.5357, 0.5621, 0.5301], device='cuda:1')
Thumb force: tensor([0.6440, 0.6175, 0.5323], device='cuda:1')
tensor([-2.0243e-03,  4.6087e-01,  4.4532e-01,  6.2060e-01, -1.2170e-01,
         6.3235e-01,  7.5266e-01,  9.1441e-01,  1.3043e+00,  3.3680e-01,
         2.3622e-01,  1.0150e+00,  1.4483e-02,  1.2519e-02, -8.0496e-01,
         5.5943e+00], device='cuda:1')
Solve time for step 3 4.402581295988057
Current ori: tensor([ 0.0145,  0.0125, -0.8050], device='cuda:1')
Middle force: tensor([0.5557, 0.5274], device='cuda:1')
Thumb force: tensor([0.6093, 0.5287], device='cuda:1')
tensor([ 3.6191e-03,  4.6657e-01,  4.4185e-01,  6.2075e-01, -1.3987e-01,
         6.3350e-01,  7.3917e-01,  9.0092e-01,  1.3179e+00,  3.2794e-01,
         2.5680e-01,  9.8668e-01,  1.1198e-02,  2.6632e-02, -7.8996e-01,
         5.7467e+00], device='cuda:1')
Solve time for step 4 4.393911934981588
Current ori: tensor([ 0.0112,  0.0266, -0.7900], device='cuda:1')
Middle force: tensor([0.5316], device='cuda:1')
Thumb force: tensor([0.5592], device='cuda:1')
Storing RECOVERY transition: reward=0.0404 (scaled=0.0202), steps=2
Reward stats updated: mean 0.0385 -> 0.0380, std: 0.0621
Collected 33 transitions for RL
Original likelihood: -136.39630126953125
Adjusted likelihood: -136.39630126953125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0097,  0.0277, -0.7917], device='cuda:1')
12 turn
Sampling time 5.0339033380150795
tensor([-0.0414,  0.5275,  0.4810,  0.6444, -0.1410,  0.6353,  0.7359,  0.8990,
         1.3193,  0.3278,  0.2591,  0.9801,  0.0097,  0.0277, -0.7917,  5.8007],
       device='cuda:1')
Original likelihood: -139.8234405517578
Adjusted likelihood: -139.8234405517578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.856453011976555
Current ori: tensor([ 0.0097,  0.0277, -0.7917], device='cuda:1')
Middle force: tensor([1.0471, 1.3032, 0.7495, 0.5692, 0.6532, 0.9739, 0.5159, 0.5370, 0.5399,
        0.5809, 0.5486, 0.6691], device='cuda:1')
Thumb force: tensor([0.5085, 0.5708, 0.4990, 1.1826, 1.5509, 0.5653, 0.8009, 0.6877, 0.6196,
        0.5478, 0.5855, 0.7362], device='cuda:1')
Index force: tensor([0.8734, 1.2547, 1.1040, 0.6893, 0.5224, 0.5110, 0.5674, 0.7722, 0.6897,
        0.6060, 0.5611, 0.5092], device='cuda:1')
Storing NORMAL transition: reward=-0.0164 (scaled=-0.0164), steps=1
Reward stats updated: mean 0.0380 -> 0.0364, std: 0.0619
Collected 34 transitions for RL
tensor([-3.3438e-02,  5.5652e-01,  4.0979e-01,  7.2497e-01, -1.6633e-01,
         6.4846e-01,  6.7594e-01,  8.2900e-01,  1.3706e+00,  2.8754e-01,
         3.0294e-01,  8.8863e-01, -3.1556e-03,  6.2596e-02, -7.7812e-01,
         5.2540e+00], device='cuda:1')
Original likelihood: -264.1385498046875
Adjusted likelihood: -264.1385498046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([  -5.8873,   -6.6628,   -6.8188,   -7.1189,   -8.8499,   -9.2612,
         -10.1428,  -10.5290,  -10.9615,  -13.0887,  -16.6366,  -18.9722,
         -28.8173,  -61.6396,  -63.8409, -108.1947], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([  -5.8873,   -6.6628,   -6.8188,   -7.1189,   -8.8499,   -9.2612,
         -10.1428,  -10.5290,  -10.9615,  -13.0887,  -16.6366,  -18.9722,
         -28.8173,  -61.6396,  -63.8409, -108.1947], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -24.2139
1 mode projection succeeded
New goal: tensor([ 0.0546,  0.5368,  0.5698,  0.6169, -0.0890,  0.5089,  0.8534,  0.9250,
         1.2668,  0.3282,  0.1855,  1.2248,  0.0059,  0.0152, -1.7306],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -118.63397979736328
Adjusted likelihood: -118.63397979736328
Likelihood residual: 0.0
Original likelihood: -122.66036987304688
Adjusted likelihood: -122.66036987304688
Likelihood residual: 0.0
{'index': 122.66036987304688, 'thumb_middle': 118.63397979736328}
Current yaw: tensor([-0.0032,  0.0626, -0.7781], device='cuda:1')
13 thumb_middle
tensor([-3.3438e-02,  5.5652e-01,  4.0979e-01,  7.2497e-01, -1.6633e-01,
         6.4846e-01,  6.7594e-01,  8.2900e-01,  1.3706e+00,  2.8754e-01,
         3.0294e-01,  8.8863e-01, -3.1556e-03,  6.2596e-02, -7.7812e-01,
         5.2540e+00], device='cuda:1')
Solve time for step 1 9.519231595040765
Current ori: tensor([-0.0032,  0.0626, -0.7781], device='cuda:1')
Index force: tensor([0.5281, 0.5016, 0.6184, 0.6113], device='cuda:1')
tensor([-4.2982e-02,  5.0997e-01,  5.1076e-01,  6.4134e-01, -2.2604e-01,
         5.2294e-01,  7.6489e-01,  8.6992e-01,  1.2531e+00,  3.0035e-01,
         1.8106e-01,  1.1669e+00, -2.9566e-04,  6.7057e-02, -7.7818e-01,
         5.2424e+00], device='cuda:1')
Solve time for step 2 3.8755464839632623
Current ori: tensor([-2.9566e-04,  6.7057e-02, -7.7818e-01], device='cuda:1')
Index force: tensor([0.5011, 0.6163, 0.6061], device='cuda:1')
tensor([-4.2585e-02,  5.0362e-01,  5.3157e-01,  6.1844e-01, -2.2987e-01,
         5.0799e-01,  7.8407e-01,  8.7880e-01,  1.2474e+00,  3.0536e-01,
         1.6350e-01,  1.2150e+00, -1.0110e-03,  6.6915e-02, -7.7818e-01,
         5.2387e+00], device='cuda:1')
Solve time for step 3 3.7173034559818916
Current ori: tensor([-0.0010,  0.0669, -0.7782], device='cuda:1')
Index force: tensor([0.6127, 0.5995], device='cuda:1')
tensor([-2.2356e-02,  5.0124e-01,  5.5110e-01,  6.1969e-01, -2.2403e-01,
         5.0612e-01,  7.9592e-01,  8.8317e-01,  1.2356e+00,  3.0101e-01,
         1.5357e-01,  1.2218e+00, -1.2175e-03,  5.5757e-02, -7.7818e-01,
         5.2663e+00], device='cuda:1')
Solve time for step 4 3.6117507660528645
Current ori: tensor([-0.0012,  0.0558, -0.7782], device='cuda:1')
Index force: tensor([0.5797], device='cuda:1')
Storing RECOVERY transition: reward=0.0231 (scaled=0.0231), steps=1
Reward stats updated: mean 0.0364 -> 0.0360, std: 0.0611
Collected 35 transitions for RL
Original likelihood: -140.39385986328125
Adjusted likelihood: -140.39385986328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0026,  0.0392, -0.7991], device='cuda:1')
14 turn
Sampling time 5.187829829985276
tensor([ 6.6064e-03,  5.0759e-01,  5.6273e-01,  6.2730e-01, -1.5311e-01,
         5.4117e-01,  8.3796e-01,  9.1061e-01,  1.2898e+00,  3.2260e-01,
         1.8900e-01,  1.2423e+00, -2.6312e-03,  3.9199e-02, -7.9906e-01,
         5.3310e+00], device='cuda:1')
Original likelihood: -145.525390625
Adjusted likelihood: -145.525390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9927)
Solve time for step 1 15.391433611046523
Current ori: tensor([-0.0026,  0.0392, -0.7991], device='cuda:1')
Middle force: tensor([1.2852, 0.5199, 0.5438, 0.5066, 0.5710, 1.0191, 1.6031, 0.5538, 0.5543,
        0.5093, 0.5500, 0.5115], device='cuda:1')
Thumb force: tensor([1.1421, 1.7299, 1.0308, 0.5285, 0.5685, 1.2437, 0.9832, 0.9610, 0.6240,
        0.5668, 1.1556, 0.5350], device='cuda:1')
Index force: tensor([0.9638, 0.6715, 0.5019, 0.7706, 0.5787, 1.2047, 0.7813, 0.5525, 0.6141,
        0.6662, 0.5521, 0.5845], device='cuda:1')
Storing NORMAL transition: reward=0.1532 (scaled=0.1532), steps=1
Reward stats updated: mean 0.0360 -> 0.0392, std: 0.0632
Collected 36 transitions for RL
tensor([ 0.0613,  0.4307,  0.6085,  0.4477, -0.1448,  0.4359,  1.0145,  0.9627,
         1.2945,  0.3289,  0.2088,  1.1206,  0.0078,  0.0192, -0.9514,  6.1731],
       device='cuda:1')
Original likelihood: -141.87606811523438
Adjusted likelihood: -141.87606811523438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.954557840013877
Current ori: tensor([ 0.0078,  0.0192, -0.9514], device='cuda:1')
Middle force: tensor([0.5223, 0.5428, 0.5060, 0.5659, 1.0169, 1.5408, 0.5512, 0.5738, 0.5122,
        0.5567, 0.5107], device='cuda:1')
Thumb force: tensor([1.6465, 0.9953, 0.5220, 0.5624, 1.1725, 0.9484, 0.9248, 0.5943, 0.5517,
        1.1072, 0.5301], device='cuda:1')
Index force: tensor([0.6416, 0.5015, 0.7613, 0.5719, 1.1513, 0.7622, 0.5473, 0.5936, 0.6403,
        0.5434, 0.5780], device='cuda:1')
Storing NORMAL transition: reward=0.0727 (scaled=0.0727), steps=1
Reward stats updated: mean 0.0392 -> 0.0401, std: 0.0626
Collected 37 transitions for RL
tensor([ 1.5972e-01,  5.3166e-01,  7.4161e-01,  4.9545e-01, -3.7318e-02,
         4.5934e-01,  9.3332e-01,  1.0601e+00,  1.3164e+00,  2.5870e-01,
         1.0417e-01,  1.1610e+00,  4.2331e-03, -3.1510e-02, -1.0252e+00,
        -6.1388e+00], device='cuda:1')
Original likelihood: -135.54249572753906
Adjusted likelihood: -135.54249572753906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.44120068103075
Current ori: tensor([ 0.0042, -0.0315, -1.0252], device='cuda:1')
Middle force: tensor([0.5747, 1.6586, 0.5695, 1.1867, 0.5168, 1.0177, 0.6067, 0.5279, 0.5628,
        0.5312], device='cuda:1')
Thumb force: tensor([0.5381, 1.3589, 0.5308, 0.7440, 0.5566, 1.2183, 1.7268, 0.6031, 0.5145,
        0.6097], device='cuda:1')
Index force: tensor([0.5231, 0.5273, 0.5568, 0.6042, 0.7579, 0.5914, 0.5570, 0.6739, 0.5657,
        0.6639], device='cuda:1')
Storing NORMAL transition: reward=0.0238 (scaled=0.0238), steps=1
Reward stats updated: mean 0.0401 -> 0.0397, std: 0.0618
Collected 38 transitions for RL
tensor([ 0.2068,  0.4986,  0.8097,  0.5386, -0.0322,  0.4469,  0.9401,  1.1010,
         1.3442,  0.2119,  0.0889,  1.1891,  0.0177, -0.0290, -1.0494,  6.1633],
       device='cuda:1')
Original likelihood: -211.07473754882812
Adjusted likelihood: -211.07473754882812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.7096, -2.8463, -3.1643, -3.2222, -3.5268, -3.5338, -4.3499, -4.4093,
        -4.5171, -4.7479, -4.8233, -4.8987, -5.2082, -5.2909, -5.2925, -5.5762],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.7096, -2.8463, -3.1643, -3.2222, -3.5268, -3.5338, -4.3499, -4.4093,
        -4.5171, -4.7479, -4.8233, -4.8987, -5.2082, -5.2909, -5.2925, -5.5762],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.2573
1 mode projection succeeded
New goal: tensor([ 0.0560,  0.5612,  0.6101,  0.4741, -0.0667,  0.4752,  0.8666,  0.9240,
         1.2600,  0.3170,  0.2472,  1.1168,  0.0033,  0.0139, -1.7661],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -79.89398193359375
Adjusted likelihood: -79.89398193359375
Likelihood residual: 0.0
Original likelihood: -120.68782806396484
Adjusted likelihood: -120.68782806396484
Likelihood residual: 0.0
{'index': 120.68782806396484, 'thumb_middle': 79.89398193359375}
Current yaw: tensor([ 0.0177, -0.0290, -1.0494], device='cuda:1')
15 thumb_middle
tensor([ 0.2068,  0.4986,  0.8097,  0.5386, -0.0322,  0.4469,  0.9401,  1.1010,
         1.3442,  0.2119,  0.0889,  1.1891,  0.0177, -0.0290, -1.0494,  6.1633],
       device='cuda:1')
Solve time for step 1 9.4601301579969
Current ori: tensor([ 0.0177, -0.0290, -1.0494], device='cuda:1')
Index force: tensor([0.6252, 0.5091, 0.6251, 0.5075], device='cuda:1')
tensor([ 1.4993e-01,  5.0073e-01,  7.4746e-01,  5.4155e-01, -1.5463e-01,
         4.7349e-01,  8.3721e-01,  9.1625e-01,  1.1994e+00,  2.7174e-01,
         1.6714e-01,  1.1245e+00,  1.4250e-02,  2.0692e-03, -1.0494e+00,
         6.0892e+00], device='cuda:1')
Solve time for step 2 3.8592058869544417
Current ori: tensor([ 0.0142,  0.0021, -1.0494], device='cuda:1')
Index force: tensor([0.5061, 0.6176, 0.5007], device='cuda:1')
tensor([ 0.1409,  0.5120,  0.7269,  0.5342, -0.1776,  0.4873,  0.8312,  0.9063,
         1.1974,  0.2792,  0.1857,  1.1019,  0.0108,  0.0066, -1.0494,  6.0708],
       device='cuda:1')
Solve time for step 3 3.761376618000213
Current ori: tensor([ 0.0108,  0.0066, -1.0494], device='cuda:1')
Index force: tensor([0.5971, 0.5000], device='cuda:1')
tensor([ 1.0523e-01,  5.4836e-01,  6.5633e-01,  5.0969e-01, -1.9218e-01,
         4.8347e-01,  8.2407e-01,  8.8259e-01,  1.2160e+00,  2.8015e-01,
         1.8251e-01,  1.1043e+00,  3.0087e-04,  2.4451e-02, -1.0494e+00,
         6.0077e+00], device='cuda:1')
Solve time for step 4 3.376514233998023
Current ori: tensor([ 3.0087e-04,  2.4451e-02, -1.0494e+00], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0098 (scaled=0.0033), steps=3
Reward stats updated: mean 0.0397 -> 0.0388, std: 0.0613
Collected 39 transitions for RL
Original likelihood: -109.82839965820312
Adjusted likelihood: -109.82839965820312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-7.5095e-04,  2.3354e-02, -1.0581e+00], device='cuda:1')
16 turn
Sampling time 5.201735838025343
tensor([ 1.0317e-01,  5.5869e-01,  6.4868e-01,  4.9268e-01, -1.2066e-01,
         5.2163e-01,  8.5885e-01,  9.2606e-01,  1.2622e+00,  3.1371e-01,
         2.4313e-01,  1.1553e+00, -7.5095e-04,  2.3354e-02, -1.0581e+00,
         6.0281e+00], device='cuda:1')
Original likelihood: -113.94215393066406
Adjusted likelihood: -113.94215393066406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.076397127995733
Current ori: tensor([-7.5095e-04,  2.3354e-02, -1.0581e+00], device='cuda:1')
Middle force: tensor([0.5206, 0.5764, 0.5845, 1.8396, 0.5716, 1.3128, 0.5076, 0.5531, 0.5110,
        0.5293, 0.5655, 0.5747], device='cuda:1')
Thumb force: tensor([0.6704, 0.8347, 0.5975, 1.5587, 0.5510, 0.8456, 0.6255, 0.5128, 0.5837,
        1.0678, 0.5779, 0.6523], device='cuda:1')
Index force: tensor([0.8005, 0.5012, 0.5085, 0.5481, 0.5827, 0.6332, 0.7673, 0.7337, 0.5455,
        0.5397, 0.5627, 0.5909], device='cuda:1')
Storing NORMAL transition: reward=-0.0029 (scaled=-0.0029), steps=1
Reward stats updated: mean 0.0388 -> 0.0377, std: 0.0609
Collected 40 transitions for RL
tensor([ 6.2820e-02,  5.2314e-01,  6.4665e-01,  5.1505e-01, -1.6709e-01,
         5.6846e-01,  9.0694e-01,  1.0302e+00,  1.2893e+00,  4.1063e-01,
         1.7850e-01,  9.8175e-01,  2.0967e-03,  3.7501e-05, -1.0547e+00,
        -5.7515e+00], device='cuda:1')
Original likelihood: -149.894287109375
Adjusted likelihood: -149.894287109375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5230)
Solve time for step 2 6.191515678016003
Current ori: tensor([ 2.0967e-03,  3.7501e-05, -1.0547e+00], device='cuda:1')
Middle force: tensor([1.1265, 0.5653, 0.5027, 1.0778, 0.8521, 0.5744, 0.5682, 0.5058, 0.6313,
        0.5472, 0.5266], device='cuda:1')
Thumb force: tensor([1.0768, 0.9708, 0.9203, 0.7214, 0.5318, 0.5001, 1.2145, 0.6332, 0.6098,
        0.6021, 0.5550], device='cuda:1')
Index force: tensor([1.4464, 0.5335, 0.5229, 0.5213, 0.5613, 0.5706, 0.6179, 0.6273, 0.5533,
        0.6429, 0.5047], device='cuda:1')
Storing NORMAL transition: reward=0.0597 (scaled=0.0597), steps=1
Reward stats updated: mean 0.0377 -> 0.0383, std: 0.0602
Collected 41 transitions for RL
tensor([ 6.7401e-02,  5.7700e-01,  5.8632e-01,  4.9938e-01, -1.6099e-01,
         5.7730e-01,  9.0010e-01,  1.0362e+00,  1.3610e+00,  3.5929e-01,
         1.9210e-01,  9.0609e-01, -1.1214e-02, -4.4157e-03, -1.1146e+00,
        -5.6924e+00], device='cuda:1')
Original likelihood: -143.09608459472656
Adjusted likelihood: -143.09608459472656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 3 5.855321353999898
Current ori: tensor([-0.0112, -0.0044, -1.1146], device='cuda:1')
Middle force: tensor([0.5587, 0.5022, 1.0696, 0.8392, 0.5724, 0.5643, 0.5082, 0.6302, 0.5477,
        0.5273], device='cuda:1')
Thumb force: tensor([0.9582, 0.9023, 0.7017, 0.5282, 0.5000, 1.1987, 0.6165, 0.6041, 0.5938,
        0.5498], device='cuda:1')
Index force: tensor([0.5300, 0.5196, 0.5192, 0.5570, 0.5667, 0.6098, 0.5966, 0.5475, 0.6336,
        0.5039], device='cuda:1')
Storing NORMAL transition: reward=0.1052 (scaled=0.1052), steps=1
Reward stats updated: mean 0.0383 -> 0.0399, std: 0.0604
Collected 42 transitions for RL
tensor([ 0.1009,  0.5986,  0.5885,  0.4931, -0.1209,  0.5844,  0.8911,  1.0576,
         1.4079,  0.3864,  0.1995,  0.7350, -0.0194, -0.0240, -1.2209, -5.5720],
       device='cuda:1')
Original likelihood: -156.0924530029297
Adjusted likelihood: -156.0924530029297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0004)
State is out of distribution
Final likelihood: tensor([-3.2069, -3.4680, -3.4806, -3.6843, -4.1108, -4.1398, -4.2737, -4.6473,
        -4.9924, -5.0987, -5.2328, -5.3675, -6.1534, -7.6060, -8.3304, -8.4455],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2069, -3.4680, -3.4806, -3.6843, -4.1108, -4.1398, -4.2737, -4.6473,
        -4.9924, -5.0987, -5.2328, -5.3675, -6.1534, -7.6060, -8.3304, -8.4455],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.1399
1 mode projection succeeded
New goal: tensor([ 0.0782,  0.5829,  0.5384,  0.5974, -0.0741,  0.5234,  0.8310,  0.9021,
         1.2604,  0.3509,  0.2238,  1.1298,  0.0036,  0.0111, -0.8889],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -78.15644836425781
Adjusted likelihood: -78.15644836425781
Likelihood residual: 0.0
Original likelihood: -175.43667602539062
Adjusted likelihood: -175.43667602539062
Likelihood residual: 0.0
{'index': 175.43667602539062, 'thumb_middle': 78.15644836425781}
Current yaw: tensor([-0.0194, -0.0240, -1.2209], device='cuda:1')
17 thumb_middle
tensor([ 0.1009,  0.5986,  0.5885,  0.4931, -0.1209,  0.5844,  0.8911,  1.0576,
         1.4079,  0.3864,  0.1995,  0.7350, -0.0194, -0.0240, -1.2209, -5.5720],
       device='cuda:1')
Solve time for step 1 9.449737688992172
Current ori: tensor([-0.0194, -0.0240, -1.2209], device='cuda:1')
Index force: tensor([0.5640, 0.6036, 0.5974, 0.5979], device='cuda:1')
tensor([ 6.8914e-02,  5.7822e-01,  5.5000e-01,  5.6959e-01, -1.6650e-01,
         5.4305e-01,  8.0363e-01,  8.9904e-01,  1.2175e+00,  3.2552e-01,
         1.5096e-01,  1.0371e+00, -9.0155e-03, -4.5263e-03, -1.2209e+00,
        -5.6024e+00], device='cuda:1')
Solve time for step 2 4.025789989973418
Current ori: tensor([-0.0090, -0.0045, -1.2209], device='cuda:1')
Index force: tensor([0.5958, 0.5922, 0.5933], device='cuda:1')
tensor([ 5.3283e-02,  5.6354e-01,  5.4921e-01,  5.8207e-01, -1.8390e-01,
         5.4627e-01,  7.9956e-01,  8.8440e-01,  1.1958e+00,  3.1837e-01,
         1.5924e-01,  1.1001e+00, -5.1753e-03,  4.7273e-03, -1.2209e+00,
        -5.6198e+00], device='cuda:1')
Solve time for step 3 3.8892759829759598
Current ori: tensor([-0.0052,  0.0047, -1.2209], device='cuda:1')
Index force: tensor([0.5833, 0.5856], device='cuda:1')
tensor([ 5.8495e-02,  5.6525e-01,  5.3342e-01,  6.1781e-01, -1.7798e-01,
         5.4753e-01,  7.9942e-01,  8.7430e-01,  1.2020e+00,  3.1005e-01,
         1.4717e-01,  1.1070e+00, -2.0015e-03,  2.0919e-03, -1.2209e+00,
        -5.6016e+00], device='cuda:1')
Solve time for step 4 3.772048638027627
Current ori: tensor([-0.0020,  0.0021, -1.2209], device='cuda:1')
Index force: tensor([0.5663], device='cuda:1')
Storing RECOVERY transition: reward=-0.0028 (scaled=-0.0009), steps=3
Reward stats updated: mean 0.0399 -> 0.0389, std: 0.0600
Collected 43 transitions for RL
Original likelihood: -67.05818939208984
Adjusted likelihood: -67.05818939208984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0033,  0.0124, -1.2171], device='cuda:1')
18 turn
Sampling time 5.056855596019886
tensor([ 3.9545e-02,  5.6352e-01,  5.3004e-01,  5.9476e-01, -1.2473e-01,
         5.9279e-01,  8.2748e-01,  8.8327e-01,  1.2575e+00,  3.3244e-01,
         2.2321e-01,  1.1475e+00, -3.2926e-03,  1.2445e-02, -1.2171e+00,
        -5.6210e+00], device='cuda:1')
Original likelihood: -61.450523376464844
Adjusted likelihood: -61.450523376464844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.17824972094968
Current ori: tensor([-0.0033,  0.0124, -1.2171], device='cuda:1')
Middle force: tensor([1.4304, 0.7549, 0.7841, 1.0435, 0.5882, 0.5116, 0.5375, 0.6866, 1.0606,
        0.5544, 0.5991, 0.5032], device='cuda:1')
Thumb force: tensor([0.5525, 2.0383, 0.5704, 0.6123, 0.5874, 2.4507, 0.5190, 0.5751, 1.2146,
        0.5371, 0.6670, 0.5633], device='cuda:1')
Index force: tensor([0.6069, 0.5912, 0.6513, 0.5205, 0.6063, 0.5492, 0.6054, 0.9799, 0.7663,
        0.6136, 0.6142, 0.5245], device='cuda:1')
Storing NORMAL transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean 0.0389 -> 0.0381, std: 0.0595
Collected 44 transitions for RL
tensor([ 5.7381e-02,  5.4168e-01,  5.3726e-01,  6.7333e-01, -1.1930e-01,
         6.7151e-01,  6.3014e-01,  1.1294e+00,  1.2942e+00,  3.0170e-01,
         2.3757e-01,  1.0035e+00,  9.0492e-03,  3.1511e-03, -1.2188e+00,
        -5.5645e+00], device='cuda:1')
Original likelihood: -136.8963165283203
Adjusted likelihood: -136.8963165283203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.018327152007259
Current ori: tensor([ 0.0090,  0.0032, -1.2188], device='cuda:1')
Middle force: tensor([1.5148, 0.5351, 1.0995, 0.5841, 0.8161, 0.5236, 0.6865, 0.5115, 0.5097,
        0.5747, 0.8322], device='cuda:1')
Thumb force: tensor([0.8471, 1.1902, 0.5209, 0.5281, 0.5874, 0.5120, 0.5692, 0.9259, 0.5182,
        0.5324, 0.5620], device='cuda:1')
Index force: tensor([1.1922, 0.5615, 0.5933, 0.6627, 0.6294, 0.6207, 0.6725, 0.5854, 0.5418,
        0.5760, 0.5604], device='cuda:1')
Storing NORMAL transition: reward=0.0800 (scaled=0.0800), steps=1
Reward stats updated: mean 0.0381 -> 0.0390, std: 0.0592
Collected 45 transitions for RL
tensor([ 0.0753,  0.6180,  0.4714,  0.6273, -0.0963,  0.6568,  0.7112,  1.0068,
         1.3564,  0.2290,  0.2140,  0.9204, -0.0153, -0.0093, -1.2991, -5.5337],
       device='cuda:1')
Original likelihood: -101.91773986816406
Adjusted likelihood: -101.91773986816406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.605706452974118
Current ori: tensor([-0.0153, -0.0093, -1.2991], device='cuda:1')
Middle force: tensor([0.5229, 0.9433, 0.5628, 0.7331, 0.5160, 0.6399, 0.5042, 0.5771, 0.5514,
        0.5348], device='cuda:1')
Thumb force: tensor([1.0504, 0.5070, 0.5185, 0.5714, 0.5087, 0.5485, 0.8281, 0.5643, 0.5226,
        0.5457], device='cuda:1')
Index force: tensor([0.5405, 0.5707, 0.6287, 0.5997, 0.5884, 0.6242, 0.5694, 0.6132, 0.5260,
        0.5792], device='cuda:1')
Storing NORMAL transition: reward=-0.0035 (scaled=-0.0035), steps=1
Reward stats updated: mean 0.0390 -> 0.0381, std: 0.0589
Collected 46 transitions for RL
tensor([ 1.0039e-01,  5.4608e-01,  6.0278e-01,  6.1346e-01, -1.2234e-01,
         6.8602e-01,  7.2207e-01,  1.0845e+00,  1.3371e+00,  1.5805e-01,
         3.6175e-01,  7.2177e-01,  3.4727e-03, -2.1595e-02, -1.2957e+00,
        -5.4449e+00], device='cuda:1')
Original likelihood: -136.52999877929688
Adjusted likelihood: -136.52999877929688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.517824908019975
Current ori: tensor([ 0.0035, -0.0216, -1.2957], device='cuda:1')
Middle force: tensor([0.8927, 0.5596, 0.7000, 0.5215, 0.6185, 0.5013, 0.5598, 0.5418, 0.5491],
       device='cuda:1')
Thumb force: tensor([0.5099, 0.5139, 0.5597, 0.5049, 0.5362, 0.7665, 0.5520, 0.5125, 0.5372],
       device='cuda:1')
Index force: tensor([0.5513, 0.6025, 0.5826, 0.5677, 0.6012, 0.5693, 0.5948, 0.5205, 0.5356],
       device='cuda:1')
Storing NORMAL transition: reward=0.1430 (scaled=0.1430), steps=1
Reward stats updated: mean 0.0381 -> 0.0403, std: 0.0602
Collected 47 transitions for RL
tensor([ 0.0158,  0.4960,  0.5765,  0.6208, -0.0984,  0.6214,  0.8391,  1.1666,
         1.3752,  0.0854,  0.3773,  0.6275,  0.0298, -0.0509, -1.4440, -5.3436],
       device='cuda:1')
Original likelihood: -173.14710998535156
Adjusted likelihood: -173.14710998535156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.8670,  -3.7990,  -3.8382,  -4.2412,  -4.7374,  -4.9557,  -5.1908,
         -5.3936,  -5.7330,  -5.8036,  -5.9050,  -6.3918,  -6.5741,  -7.2930,
         -7.9862, -10.0659], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.8670,  -3.7990,  -3.8382,  -4.2412,  -4.7374,  -4.9557,  -5.1908,
         -5.3936,  -5.7330,  -5.8036,  -5.9050,  -6.3918,  -6.5741,  -7.2930,
         -7.9862, -10.0659], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.6735
1 mode projection succeeded
New goal: tensor([ 0.0490,  0.5597,  0.5383,  0.6053, -0.1014,  0.5254,  0.8421,  0.9522,
         1.2802,  0.2566,  0.2435,  1.1324,  0.0051,  0.0143, -2.3107],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -142.0821990966797
Adjusted likelihood: -142.0821990966797
Likelihood residual: 0.0
Original likelihood: -237.87847900390625
Adjusted likelihood: -237.87847900390625
Likelihood residual: 0.0
{'index': 237.87847900390625, 'thumb_middle': 142.0821990966797}
Current yaw: tensor([ 0.0298, -0.0509, -1.4440], device='cuda:1')
19 thumb_middle
tensor([ 0.0158,  0.4960,  0.5765,  0.6208, -0.0984,  0.6214,  0.8391,  1.1666,
         1.3752,  0.0854,  0.3773,  0.6275,  0.0298, -0.0509, -1.4440, -5.3436],
       device='cuda:1')
Solve time for step 1 9.844305759994313
Current ori: tensor([ 0.0298, -0.0509, -1.4440], device='cuda:1')
Index force: tensor([0.5622, 0.6016, 0.5912, 0.5919], device='cuda:1')
tensor([-3.9589e-03,  5.3950e-01,  5.6922e-01,  6.2385e-01, -1.5433e-01,
         5.6857e-01,  8.3430e-01,  9.7721e-01,  1.2040e+00,  1.9672e-01,
         1.7715e-01,  9.3846e-01,  7.7061e-02, -1.3914e-01, -1.4439e+00,
        -4.1546e+00], device='cuda:1')
Solve time for step 2 3.823078024026472
Current ori: tensor([ 0.0771, -0.1391, -1.4439], device='cuda:1')
Index force: tensor([0.5916, 0.5866, 0.5872], device='cuda:1')
tensor([-0.0564,  0.6068,  0.6157,  0.6488, -0.0815,  0.6091,  0.8533,  0.9395,
         1.1761,  0.2114,  0.1053,  1.0443,  0.1943, -0.3332, -1.4513, -2.9951],
       device='cuda:1')
Solve time for step 3 3.649570525973104
Current ori: tensor([ 0.1943, -0.3332, -1.4513], device='cuda:1')
Index force: tensor([0.5014, 0.5745], device='cuda:1')
tensor([-0.0177,  0.8077,  0.8994,  0.7940,  0.0335,  0.7112,  0.9148,  0.9590,
         1.1684,  0.2369,  0.0222,  1.0215,  0.2411, -0.4210, -1.5015, -0.7148],
       device='cuda:1')
Solve time for step 4 3.766013259009924
Current ori: tensor([ 0.2411, -0.4210, -1.5015], device='cuda:1')
Index force: tensor([0.5557], device='cuda:1')
Storing RECOVERY transition: reward=-0.2100 (scaled=-0.0525), steps=4
Reward stats updated: mean 0.0403 -> 0.0384, std: 0.0610
Collected 48 transitions for RL
Original likelihood: -1269.124267578125
Adjusted likelihood: -1269.124267578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 3
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 5.083627335028723
tensor([ 1.3627e-01,  6.1540e-01,  5.7061e-01,  5.5968e-01, -9.0339e-02,
         4.9037e-01,  9.5328e-01,  8.3483e-01,  1.2332e+00,  2.7069e-01,
         2.4651e-01,  1.2007e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:1')
Original likelihood: -101.56613159179688
Adjusted likelihood: -101.56613159179688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.069110715994611
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([2.6620, 0.5013, 0.5363, 0.5050, 0.5075, 0.5903, 0.5024, 0.6663, 0.5637,
        0.4984, 0.5232, 0.5342], device='cuda:1')
Thumb force: tensor([2.5134, 0.6383, 0.6181, 0.8379, 0.5674, 0.9245, 0.8074, 0.9366, 0.5975,
        0.6193, 0.6789, 0.5303], device='cuda:1')
Index force: tensor([0.5402, 0.7653, 0.6286, 0.8564, 0.6189, 0.5758, 0.5129, 0.5072, 0.5687,
        0.7506, 0.8486, 0.5925], device='cuda:1')
Storing NORMAL transition: reward=0.0201 (scaled=0.0201), steps=1
Reward stats updated: mean 0.0384 -> 0.0380, std: 0.0604
Collected 49 transitions for RL
tensor([ 1.2924e-01,  6.4234e-01,  5.8512e-01,  4.3365e-01, -7.3900e-02,
         4.5567e-01,  9.4730e-01,  9.4304e-01,  1.2599e+00,  1.6896e-01,
         2.7424e-01,  1.1815e+00,  2.0401e-02, -1.0036e-03, -4.9188e-02,
        -3.5899e-01], device='cuda:1')
Original likelihood: -121.88255310058594
Adjusted likelihood: -121.88255310058594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.207683229004033
Current ori: tensor([ 0.0204, -0.0010, -0.0492], device='cuda:1')
Middle force: tensor([0.5010, 0.5361, 0.5062, 0.5061, 0.5836, 0.5019, 0.6631, 0.5587, 0.5018,
        0.5272, 0.5331], device='cuda:1')
Thumb force: tensor([0.6208, 0.5990, 0.7828, 0.5534, 0.9076, 0.7879, 0.9159, 0.5926, 0.5785,
        0.6393, 0.5276], device='cuda:1')
Index force: tensor([0.7481, 0.6242, 0.8386, 0.6167, 0.5717, 0.5124, 0.5059, 0.5652, 0.7563,
        0.8464, 0.5866], device='cuda:1')
Storing NORMAL transition: reward=-0.0309 (scaled=-0.0309), steps=1
Reward stats updated: mean 0.0380 -> 0.0366, std: 0.0606
Collected 50 transitions for RL
tensor([ 0.0532,  0.5832,  0.5974,  0.4164, -0.0517,  0.4631,  0.9550,  0.9375,
         1.2710,  0.1151,  0.3234,  1.0578,  0.0281, -0.0151, -0.0188, -1.0330],
       device='cuda:1')
Original likelihood: -132.14236450195312
Adjusted likelihood: -132.14236450195312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.523548919009045
Current ori: tensor([ 0.0281, -0.0151, -0.0188], device='cuda:1')
Middle force: tensor([0.7577, 0.5099, 0.5126, 0.7881, 1.0847, 0.5034, 0.5069, 0.5310, 0.5195,
        0.6306], device='cuda:1')
Thumb force: tensor([0.5057, 0.5248, 0.7100, 1.2355, 0.6043, 0.5032, 0.6269, 0.9122, 0.5874,
        0.6107], device='cuda:1')
Index force: tensor([0.5346, 0.6381, 0.9491, 0.5334, 0.5032, 0.5337, 0.6033, 0.6290, 0.5941,
        0.5716], device='cuda:1')
Storing NORMAL transition: reward=0.0450 (scaled=0.0450), steps=1
Reward stats updated: mean 0.0366 -> 0.0368, std: 0.0600
Collected 51 transitions for RL
tensor([ 0.0481,  0.5728,  0.5950,  0.4307, -0.0243,  0.4882,  0.9574,  0.9757,
         1.1861,  0.2374,  0.3830,  0.8702,  0.0243, -0.0411, -0.0653, -0.8824],
       device='cuda:1')
Original likelihood: -255.64163208007812
Adjusted likelihood: -255.64163208007812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.7861, -2.8525, -2.9082, -3.1647, -3.3658, -3.6020, -3.6112, -3.6276,
        -4.3001, -4.4600, -4.4657, -4.5991, -4.6713, -5.4114, -5.8447, -6.8072],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.7861, -2.8525, -2.9082, -3.1647, -3.3658, -3.6020, -3.6112, -3.6276,
        -4.3001, -4.4600, -4.4657, -4.5991, -4.6713, -5.4114, -5.8447, -6.8072],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.1548
1 mode projection succeeded
New goal: tensor([ 0.0581,  0.5429,  0.5950,  0.5572, -0.0773,  0.4393,  0.9344,  0.9238,
         1.2500,  0.3259,  0.2615,  1.1028,  0.0046,  0.0132,  0.1159],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -115.85125732421875
Adjusted likelihood: -115.85125732421875
Likelihood residual: 0.0
Original likelihood: -207.2174530029297
Adjusted likelihood: -207.2174530029297
Likelihood residual: 0.0
{'index': 207.2174530029297, 'thumb_middle': 115.85125732421875}
Current yaw: tensor([ 0.0243, -0.0411, -0.0653], device='cuda:1')
2 thumb_middle
tensor([ 0.0481,  0.5728,  0.5950,  0.4307, -0.0243,  0.4882,  0.9574,  0.9757,
         1.1861,  0.2374,  0.3830,  0.8702,  0.0243, -0.0411, -0.0653, -0.8824],
       device='cuda:1')
Solve time for step 1 9.255260508973151
Current ori: tensor([ 0.0243, -0.0411, -0.0653], device='cuda:1')
Index force: tensor([0.5822, 0.5741, 0.5864, 0.5954], device='cuda:1')
tensor([ 0.0078,  0.5249,  0.5740,  0.5297, -0.1313,  0.4301,  0.9170,  0.9176,
         1.1986,  0.2989,  0.1942,  1.0241,  0.0380, -0.0244, -0.0654, -1.0324],
       device='cuda:1')
Solve time for step 2 3.906186048989184
Current ori: tensor([ 0.0380, -0.0244, -0.0654], device='cuda:1')
Index force: tensor([0.5650, 0.5786, 0.5873], device='cuda:1')
tensor([-0.0038,  0.5359,  0.5528,  0.5223, -0.1384,  0.4383,  0.9164,  0.9123,
         1.2018,  0.3048,  0.1661,  1.0505,  0.0508, -0.0254, -0.0651, -0.9348],
       device='cuda:1')
Solve time for step 3 3.666618893039413
Current ori: tensor([ 0.0508, -0.0254, -0.0651], device='cuda:1')
Index force: tensor([0.5675, 0.5764], device='cuda:1')
tensor([-0.0096,  0.5588,  0.5545,  0.5147, -0.1305,  0.4405,  0.9242,  0.9117,
         1.2032,  0.3093,  0.1569,  1.0534,  0.1178, -0.0422, -0.0650, -0.1786],
       device='cuda:1')
Solve time for step 4 3.5356307930196635
Current ori: tensor([ 0.1178, -0.0422, -0.0650], device='cuda:1')
Index force: tensor([0.5685], device='cuda:1')
Storing RECOVERY transition: reward=-0.0758 (scaled=-0.0253), steps=3
Reward stats updated: mean 0.0368 -> 0.0356, std: 0.0601
Collected 52 transitions for RL
Original likelihood: -292.2345886230469
Adjusted likelihood: -292.2345886230469
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-127.1472, -134.5001, -134.6909, -135.7336, -143.5943, -147.5132,
        -148.6738, -149.4713, -149.4739, -150.7041, -155.6205, -165.1942,
        -172.2933, -172.3410, -181.7231, -225.7126], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([-127.1472, -134.5001, -134.6909, -135.7336, -143.5943, -147.5132,
        -148.6738, -149.4713, -149.4739, -150.7041, -155.6205, -165.1942,
        -172.2933, -172.3410, -181.7231, -225.7126], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -155.8992
1 mode projection failed, trying anyway
New goal: tensor([ 0.0842,  0.3302,  0.7591,  0.7960,  0.0240,  0.4985,  0.7626,  1.1604,
         1.3727,  0.2335,  0.2455,  1.1765,  0.1589, -0.0485,  0.7293],
       device='cuda:1')
tensor([[0.0062]], device='cuda:1') tensor([[0.0225]], device='cuda:1') tensor([[0.0018]], device='cuda:1')
Original likelihood: -459.816650390625
Adjusted likelihood: -459.816650390625
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 459.816650390625}
Current yaw: tensor([ 0.2468, -0.1316, -0.0611], device='cuda:1')
3 thumb_middle
tensor([-0.0548,  0.6094,  0.5781,  0.4936, -0.0303,  0.5285,  0.9885,  0.9587,
         1.2838,  0.3245,  0.2584,  1.1170,  0.2468, -0.1316, -0.0611,  0.7746],
       device='cuda:1')
Solve time for step 1 9.590578300994821
Current ori: tensor([ 0.2468, -0.1316, -0.0611], device='cuda:1')
Index force: tensor([0.5882, 0.5974, 0.5564, 0.5957], device='cuda:1')
tensor([-0.0648,  0.6594,  0.8031,  0.7232,  0.0594,  0.5629,  0.8259,  1.1143,
         1.3137,  0.2457,  0.1447,  1.1072,  0.2533, -0.1614,  0.0595,  0.9719],
       device='cuda:1')
Solve time for step 2 3.8190333070233464
Current ori: tensor([ 0.2533, -0.1614,  0.0595], device='cuda:1')
Index force: tensor([0.5881, 0.5499, 0.5864], device='cuda:1')
tensor([-0.0403,  0.6892,  0.7561,  0.7482,  0.0767,  0.5889,  0.7982,  1.1523,
         1.3203,  0.2208,  0.1175,  1.1121,  0.2650, -0.1841,  0.1862,  0.9585],
       device='cuda:1')
Solve time for step 3 3.84467013401445
Current ori: tensor([ 0.2650, -0.1841,  0.1862], device='cuda:1')
Index force: tensor([0.5431, 0.5750], device='cuda:1')
tensor([-0.0288,  0.7023,  0.7054,  0.7794,  0.1036,  0.6404,  0.7950,  1.1298,
         1.3230,  0.2178,  0.1106,  1.1063,  0.2800, -0.2027,  0.3096,  0.9235],
       device='cuda:1')
Solve time for step 4 3.65073020698037
Current ori: tensor([ 0.2800, -0.2027,  0.3096], device='cuda:1')
Index force: tensor([0.5723], device='cuda:1')
Storing RECOVERY transition: reward=-0.4852 (scaled=-0.1617), steps=3
Reward stats updated: mean 0.0356 -> 0.0319, std: 0.0653
Collected 53 transitions for RL
Original likelihood: -959.3519287109375
Adjusted likelihood: -959.3519287109375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 4
Loaded trajectory sampler
Current yaw: tensor([-0.0008,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0008,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 5.3290567740332335
tensor([ 1.2396e-01,  6.1740e-01,  5.4103e-01,  5.8811e-01, -1.1072e-01,
         5.1435e-01,  9.3527e-01,  8.6933e-01,  1.2549e+00,  2.6037e-01,
         2.0515e-01,  1.2488e+00, -7.8310e-04,  1.4796e-02, -2.8903e-02,
         2.4645e-01], device='cuda:1')
Original likelihood: -101.99038696289062
Adjusted likelihood: -101.99038696289062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.328676007979084
Current ori: tensor([-0.0008,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([0.5786, 0.5723, 1.1957, 0.5684, 1.1665, 0.6526, 0.5388, 0.5375, 0.5122,
        0.8692, 0.5316, 0.5558], device='cuda:1')
Thumb force: tensor([0.8977, 0.8569, 0.7604, 1.0465, 0.9672, 0.6649, 0.5245, 0.8790, 0.5417,
        0.5351, 0.7907, 0.6591], device='cuda:1')
Index force: tensor([0.5955, 0.6076, 0.5605, 0.5794, 0.8415, 0.5332, 1.0249, 0.9424, 0.5635,
        0.6109, 0.5976, 0.6344], device='cuda:1')
Storing NORMAL transition: reward=-0.0323 (scaled=-0.0323), steps=1
Reward stats updated: mean 0.0319 -> 0.0307, std: 0.0652
Collected 54 transitions for RL
tensor([ 1.7793e-01,  6.7006e-01,  5.4371e-01,  5.4361e-01, -1.1415e-01,
         4.6245e-01,  9.0335e-01,  1.0270e+00,  1.1745e+00,  3.6148e-01,
         2.5221e-01,  1.2691e+00, -7.3516e-04,  7.2280e-03,  3.5674e-03,
        -3.8128e-01], device='cuda:1')
Original likelihood: -135.90989685058594
Adjusted likelihood: -135.90989685058594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.2342421129578725
Current ori: tensor([-0.0007,  0.0072,  0.0036], device='cuda:1')
Middle force: tensor([0.5651, 1.1752, 0.5621, 1.1265, 0.6448, 0.5352, 0.5163, 0.5101, 0.8462,
        0.5269, 0.5484], device='cuda:1')
Thumb force: tensor([0.8372, 0.7483, 1.0327, 0.9693, 0.6630, 0.5218, 0.9362, 0.5430, 0.5344,
        0.7963, 0.6641], device='cuda:1')
Index force: tensor([0.5979, 0.5548, 0.5726, 0.8179, 0.5299, 1.0085, 0.9479, 0.5571, 0.6042,
        0.5906, 0.6263], device='cuda:1')
Storing NORMAL transition: reward=0.0287 (scaled=0.0287), steps=1
Reward stats updated: mean 0.0307 -> 0.0306, std: 0.0646
Collected 55 transitions for RL
tensor([ 0.1514,  0.6871,  0.5109,  0.5116, -0.0964,  0.4794,  0.8890,  1.0472,
         1.2049,  0.2869,  0.2760,  1.2005, -0.0056,  0.0070, -0.0252, -0.2964],
       device='cuda:1')
Original likelihood: -127.25367736816406
Adjusted likelihood: -127.25367736816406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.847613062011078
Current ori: tensor([-0.0056,  0.0070, -0.0252], device='cuda:1')
Middle force: tensor([1.1525, 0.5586, 1.1049, 0.6389, 0.5332, 0.5169, 0.5091, 0.8329, 0.5262,
        0.5467], device='cuda:1')
Thumb force: tensor([0.7281, 1.0102, 0.9381, 0.6516, 0.5196, 0.8942, 0.5376, 0.5322, 0.7795,
        0.6531], device='cuda:1')
Index force: tensor([0.5498, 0.5681, 0.8111, 0.5281, 0.9912, 0.9396, 0.5559, 0.5977, 0.5874,
        0.6228], device='cuda:1')
Storing NORMAL transition: reward=-0.0550 (scaled=-0.0550), steps=1
Reward stats updated: mean 0.0306 -> 0.0291, std: 0.0651
Collected 56 transitions for RL
tensor([ 0.0976,  0.6875,  0.4124,  0.5727, -0.1912,  0.4222,  0.9130,  1.0739,
         1.2568,  0.2587,  0.3386,  1.2407,  0.0207,  0.0582,  0.0266, -1.0143],
       device='cuda:1')
Original likelihood: -247.08892822265625
Adjusted likelihood: -247.08892822265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.6378, -4.0720, -4.1734, -4.1799, -4.3986, -4.5111, -4.7297, -5.1346,
        -5.7609, -5.7758, -6.1596, -6.1803, -7.5201, -7.5583, -8.5727, -8.6886],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.6378, -4.0720, -4.1734, -4.1799, -4.3986, -4.5111, -4.7297, -5.1346,
        -5.7609, -5.7758, -6.1596, -6.1803, -7.5201, -7.5583, -8.5727, -8.6886],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.6908
1 mode projection succeeded
New goal: tensor([ 0.0678,  0.5609,  0.5706,  0.5723, -0.0822,  0.5274,  0.8440,  0.8693,
         1.2489,  0.3591,  0.2069,  1.1931,  0.0045,  0.0139,  2.1205],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -144.70016479492188
Adjusted likelihood: -144.70016479492188
Likelihood residual: 0.0
Original likelihood: -116.65961456298828
Adjusted likelihood: -116.65961456298828
Likelihood residual: 0.0
{'index': 116.65961456298828, 'thumb_middle': 144.70016479492188}
Current yaw: tensor([0.0207, 0.0582, 0.0266], device='cuda:1')
2 index
tensor([ 0.0976,  0.6875,  0.4124,  0.5727, -0.1912,  0.4222,  0.9130,  1.0739,
         1.2568,  0.2587,  0.3386,  1.2407,  0.0207,  0.0582,  0.0266, -1.0143],
       device='cuda:1')
Solve time for step 1 11.063699630962219
Current ori: tensor([0.0207, 0.0582, 0.0266], device='cuda:1')
Middle force: tensor([0.6322, 0.6233, 0.5970, 0.6190], device='cuda:1')
Thumb force: tensor([0.6059, 0.5456, 0.5922, 0.5322], device='cuda:1')
tensor([ 0.1158,  0.5226,  0.4916,  0.5491, -0.1616,  0.4672,  0.9065,  0.9776,
         1.2335,  0.2906,  0.3328,  1.1894, -0.0089,  0.0454,  0.0154,  0.9272],
       device='cuda:1')
Solve time for step 2 4.7479093539877795
Current ori: tensor([-0.0089,  0.0454,  0.0154], device='cuda:1')
Middle force: tensor([0.5620, 0.5301, 0.5915], device='cuda:1')
Thumb force: tensor([0.5212, 0.5134, 0.6037], device='cuda:1')
tensor([ 0.1155,  0.5075,  0.5105,  0.5463, -0.1380,  0.5014,  0.8938,  0.9355,
         1.2420,  0.2771,  0.2967,  1.1867, -0.0255,  0.0317,  0.0073,  2.0384],
       device='cuda:1')
Solve time for step 3 4.28828615398379
Current ori: tensor([-0.0255,  0.0317,  0.0073], device='cuda:1')
Middle force: tensor([0.5889, 0.6125], device='cuda:1')
Thumb force: tensor([0.5861, 0.5279], device='cuda:1')
tensor([ 0.1188,  0.5051,  0.5171,  0.5466, -0.1140,  0.5344,  0.8784,  0.9079,
         1.2379,  0.2782,  0.2666,  1.1826, -0.0404,  0.0164, -0.0092,  2.5527],
       device='cuda:1')
Solve time for step 4 4.431842087011319
Current ori: tensor([-0.0404,  0.0164, -0.0092], device='cuda:1')
Middle force: tensor([0.5516], device='cuda:1')
Thumb force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0283 (scaled=0.0094), steps=3
Reward stats updated: mean 0.0291 -> 0.0288, std: 0.0645
Collected 57 transitions for RL
Original likelihood: -149.44773864746094
Adjusted likelihood: -149.44773864746094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6184)
State is out of distribution
Final likelihood: tensor([ -2.9767,  -3.5804,  -3.7597,  -4.0366,  -4.2251,  -4.5014,  -4.8721,
         -5.7470,  -5.8742,  -5.8974,  -5.9123,  -5.9998,  -6.6410,  -6.6992,
         -8.8745, -10.7571], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.9767,  -3.5804,  -3.7597,  -4.0366,  -4.2251,  -4.5014,  -4.8721,
         -5.7470,  -5.8742,  -5.8974,  -5.9123,  -5.9998,  -6.6410,  -6.6992,
         -8.8745, -10.7571], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.6471
1 mode projection succeeded
New goal: tensor([ 0.0597,  0.5169,  0.5793,  0.6565, -0.0304,  0.5429,  0.6927,  1.1316,
         1.3635,  0.1760,  0.1323,  1.1255, -0.0203, -0.0049, -1.2948],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -85.74744415283203
Adjusted likelihood: -85.74744415283203
Likelihood residual: 0.0
Original likelihood: -130.13833618164062
Adjusted likelihood: -130.13833618164062
Likelihood residual: 0.0
{'index': 130.13833618164062, 'thumb_middle': 85.74744415283203}
Current yaw: tensor([-0.0474,  0.0126, -0.0006], device='cuda:1')
3 thumb_middle
tensor([ 7.2232e-02,  5.7425e-01,  5.6123e-01,  5.6723e-01, -1.0769e-01,
         5.5227e-01,  8.6691e-01,  8.8787e-01,  1.2345e+00,  2.8298e-01,
         2.6252e-01,  1.1755e+00, -4.7356e-02,  1.2593e-02, -6.0172e-04,
         2.6134e+00], device='cuda:1')
Solve time for step 1 9.604326409986243
Current ori: tensor([-0.0474,  0.0126, -0.0006], device='cuda:1')
Index force: tensor([0.5745, 0.5912, 0.6001, 0.5827], device='cuda:1')
tensor([ 7.2571e-02,  5.4733e-01,  5.6804e-01,  6.2707e-01, -1.4265e-01,
         5.0371e-01,  6.8869e-01,  1.0695e+00,  1.3060e+00,  1.7639e-01,
         8.2991e-02,  1.1050e+00, -3.6035e-02,  1.3108e-02, -6.3389e-04,
         2.6396e+00], device='cuda:1')
Solve time for step 2 3.7911471290281042
Current ori: tensor([-0.0360,  0.0131, -0.0006], device='cuda:1')
Index force: tensor([0.5781, 0.5886, 0.5739], device='cuda:1')
tensor([ 7.8279e-02,  5.4451e-01,  5.7115e-01,  6.3650e-01, -1.3674e-01,
         5.0900e-01,  6.6478e-01,  1.1078e+00,  1.3282e+00,  1.5420e-01,
         5.6509e-02,  1.0919e+00, -3.4238e-02,  1.0642e-02, -6.3389e-04,
         2.6346e+00], device='cuda:1')
Solve time for step 3 3.637612564023584
Current ori: tensor([-0.0342,  0.0106, -0.0006], device='cuda:1')
Index force: tensor([0.5810, 0.5747], device='cuda:1')
tensor([ 9.4792e-02,  5.3442e-01,  5.8210e-01,  6.7365e-01, -1.3127e-01,
         5.1415e-01,  6.6955e-01,  1.1161e+00,  1.3273e+00,  1.5765e-01,
         4.5517e-02,  1.0876e+00, -2.7970e-02,  6.0986e-04, -6.3386e-04,
         2.6743e+00], device='cuda:1')
Solve time for step 4 3.7464879829785787
Current ori: tensor([-0.0280,  0.0006, -0.0006], device='cuda:1')
Index force: tensor([0.5579], device='cuda:1')
Storing RECOVERY transition: reward=0.0303 (scaled=0.0101), steps=3
Reward stats updated: mean 0.0288 -> 0.0285, std: 0.0640
Collected 58 transitions for RL
Original likelihood: -50.12887954711914
Adjusted likelihood: -50.12887954711914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0271,  0.0011, -0.0011], device='cuda:1')
4 turn
Sampling time 5.155636381008662
tensor([ 8.9623e-02,  5.2963e-01,  5.8692e-01,  6.6719e-01, -6.1376e-02,
         5.6350e-01,  7.0306e-01,  1.1226e+00,  1.3912e+00,  1.7928e-01,
         9.6534e-02,  1.1279e+00, -2.7059e-02,  1.1141e-03, -1.0595e-03,
         2.6729e+00], device='cuda:1')
Original likelihood: -49.92245101928711
Adjusted likelihood: -49.92245101928711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.259929126012139
Current ori: tensor([-0.0271,  0.0011, -0.0011], device='cuda:1')
Middle force: tensor([0.5459, 1.8117, 0.5144, 0.5982, 0.7466, 0.6266, 0.5125, 0.5076, 0.5714,
        1.0203, 0.5666, 0.5439], device='cuda:1')
Thumb force: tensor([0.5676, 2.1641, 0.7704, 1.3262, 0.5391, 0.5314, 0.5647, 0.8789, 0.6230,
        1.2152, 0.5537, 0.6001], device='cuda:1')
Index force: tensor([0.6462, 0.5627, 0.6150, 0.9990, 0.6174, 0.6071, 0.5337, 0.5155, 0.5959,
        0.6126, 0.6170, 0.5647], device='cuda:1')
Storing NORMAL transition: reward=-0.0014 (scaled=-0.0014), steps=1
Reward stats updated: mean 0.0285 -> 0.0279, std: 0.0636
Collected 59 transitions for RL
tensor([ 6.8283e-02,  6.1550e-01,  4.4088e-01,  6.7689e-01, -1.3887e-01,
         5.8050e-01,  6.1653e-01,  1.2349e+00,  1.3980e+00,  2.7354e-01,
         8.1955e-02,  9.8758e-01, -4.6310e-02,  1.4448e-02, -1.1654e-03,
         2.6371e+00], device='cuda:1')
Original likelihood: -127.50918579101562
Adjusted likelihood: -127.50918579101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.205955302051734
Current ori: tensor([-0.0463,  0.0144, -0.0012], device='cuda:1')
Middle force: tensor([1.6412, 0.5142, 0.5767, 0.7079, 0.6315, 0.5159, 0.5042, 0.5698, 0.5555,
        0.7886, 0.9936], device='cuda:1')
Thumb force: tensor([1.9852, 0.7291, 1.2410, 0.5430, 0.5229, 0.5432, 0.8262, 0.5578, 0.6178,
        0.5547, 0.6266], device='cuda:1')
Index force: tensor([0.5683, 0.5982, 0.9548, 0.6002, 0.5917, 0.5110, 0.5050, 0.5197, 0.6201,
        0.5888, 0.5385], device='cuda:1')
Storing NORMAL transition: reward=-0.0017 (scaled=-0.0017), steps=1
Reward stats updated: mean 0.0279 -> 0.0275, std: 0.0632
Collected 60 transitions for RL
tensor([ 5.2765e-02,  5.6377e-01,  5.1333e-01,  6.4977e-01, -8.4607e-02,
         5.1919e-01,  6.3367e-01,  1.4004e+00,  1.4300e+00,  2.6219e-01,
         1.1258e-01,  9.8967e-01, -3.7413e-02,  2.5692e-02,  7.8111e-04,
         2.6148e+00], device='cuda:1')
Original likelihood: -129.908935546875
Adjusted likelihood: -129.908935546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.465540359029546
Current ori: tensor([-0.0374,  0.0257,  0.0008], device='cuda:1')
Middle force: tensor([0.5164, 0.5876, 0.7144, 0.6491, 0.5188, 0.5007, 0.5148, 0.5222, 1.3131,
        0.5477], device='cuda:1')
Thumb force: tensor([0.7476, 1.3043, 0.5349, 0.5216, 0.5399, 0.5909, 0.6755, 0.5775, 0.5292,
        0.5887], device='cuda:1')
Index force: tensor([0.5990, 0.9806, 0.6267, 0.5988, 0.5265, 0.7808, 0.6389, 0.6703, 0.7226,
        0.5456], device='cuda:1')
Storing NORMAL transition: reward=0.1342 (scaled=0.1342), steps=1
Reward stats updated: mean 0.0275 -> 0.0292, std: 0.0641
Collected 61 transitions for RL
tensor([ 0.1156,  0.5636,  0.5731,  0.6536, -0.0499,  0.4597,  0.9171,  1.3980,
         1.4725,  0.1672,  0.0763,  0.9491, -0.0374, -0.0033, -0.1333,  2.7782],
       device='cuda:1')
Original likelihood: -115.07765197753906
Adjusted likelihood: -115.07765197753906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.2800860200077295
Current ori: tensor([-0.0374, -0.0033, -0.1333], device='cuda:1')
Middle force: tensor([0.5939, 0.7006, 0.6578, 0.5283, 0.5008, 0.5177, 0.5291, 1.2557, 0.5523],
       device='cuda:1')
Thumb force: tensor([1.2768, 0.5354, 0.5193, 0.5325, 0.5811, 0.6664, 0.5675, 0.5361, 0.5795],
       device='cuda:1')
Index force: tensor([0.9481, 0.6223, 0.5955, 0.5204, 0.7558, 0.6193, 0.6501, 0.7112, 0.5434],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0510 (scaled=-0.0510), steps=1
Reward stats updated: mean 0.0292 -> 0.0279, std: 0.0644
Collected 62 transitions for RL
tensor([-0.0410,  0.4119,  0.6364,  0.6531, -0.1367,  0.4114,  0.9148,  1.4257,
         1.5000,  0.1605, -0.0140,  0.8437, -0.0151,  0.0398, -0.0825,  2.8727],
       device='cuda:1')
Original likelihood: -158.80599975585938
Adjusted likelihood: -158.80599975585938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.0323,  -3.4033,  -3.7110,  -3.8246,  -4.1497,  -4.3767,  -4.5478,
         -4.9099,  -5.1426,  -5.4916,  -6.2490,  -6.9042,  -7.7162,  -7.8620,
        -10.6156, -11.4582], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.0323,  -3.4033,  -3.7110,  -3.8246,  -4.1497,  -4.3767,  -4.5478,
         -4.9099,  -5.1426,  -5.4916,  -6.2490,  -6.9042,  -7.7162,  -7.8620,
        -10.6156, -11.4582], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.8372
1 mode projection succeeded
New goal: tensor([ 3.3855e-02,  5.2491e-01,  5.7701e-01,  5.9762e-01, -6.6528e-02,
         4.6721e-01,  8.8064e-01,  9.1442e-01,  1.2758e+00,  3.6269e-01,
         2.1547e-01,  1.1025e+00, -6.1133e-04,  1.4335e-02,  1.0687e-01],
       device='cuda:1')
tensor([[0.0160]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0032]], device='cuda:1')
Original likelihood: -115.99121856689453
Adjusted likelihood: -115.99121856689453
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 115.99121856689453}
Current yaw: tensor([-0.0151,  0.0398, -0.0825], device='cuda:1')
5 thumb_middle
tensor([-0.0410,  0.4119,  0.6364,  0.6531, -0.1367,  0.4114,  0.9148,  1.4257,
         1.5000,  0.1605, -0.0140,  0.8437, -0.0151,  0.0398, -0.0825,  2.8727],
       device='cuda:1')
Solve time for step 1 9.335695444024168
Current ori: tensor([-0.0151,  0.0398, -0.0825], device='cuda:1')
Index force: tensor([0.5947, 0.6128, 0.6036, 0.5992], device='cuda:1')
tensor([-0.0296,  0.4371,  0.6096,  0.6560, -0.1906,  0.4228,  0.8428,  1.1147,
         1.2841,  0.3143,  0.1188,  1.0409, -0.0262,  0.0407, -0.0739,  2.8253],
       device='cuda:1')
Solve time for step 2 3.535987598996144
Current ori: tensor([-0.0262,  0.0407, -0.0739], device='cuda:1')
Index force: tensor([0.6048, 0.5974, 0.5923], device='cuda:1')
tensor([-0.0255,  0.4712,  0.5772,  0.6334, -0.1848,  0.4305,  0.8362,  0.9603,
         1.2577,  0.3347,  0.1395,  1.0608, -0.0370,  0.0394, -0.0739,  2.8170],
       device='cuda:1')
Solve time for step 3 3.6413006290094927
Current ori: tensor([-0.0370,  0.0394, -0.0739], device='cuda:1')
Index force: tensor([0.5881, 0.5834], device='cuda:1')
tensor([-0.0111,  0.4826,  0.5839,  0.6133, -0.1836,  0.4486,  0.8496,  0.9020,
         1.2602,  0.3378,  0.1212,  1.0685, -0.0505,  0.0670, -0.0739,  2.4993],
       device='cuda:1')
Solve time for step 4 3.5416219719918445
Current ori: tensor([-0.0505,  0.0670, -0.0739], device='cuda:1')
Index force: tensor([0.5706], device='cuda:1')
Storing RECOVERY transition: reward=-0.0050 (scaled=-0.0012), steps=4
Reward stats updated: mean 0.0279 -> 0.0274, std: 0.0640
Collected 63 transitions for RL
Original likelihood: -119.58935546875
Adjusted likelihood: -119.58935546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0503,  0.0423, -0.0804], device='cuda:1')
6 turn
Sampling time 5.076652607007418
tensor([ 0.0152,  0.4860,  0.5913,  0.6329, -0.1140,  0.4817,  0.8641,  0.9169,
         1.3248,  0.3863,  0.1793,  1.0840, -0.0503,  0.0423, -0.0804,  2.6449],
       device='cuda:1')
Original likelihood: -119.08175659179688
Adjusted likelihood: -119.08175659179688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.480368095973972
Current ori: tensor([-0.0503,  0.0423, -0.0804], device='cuda:1')
Middle force: tensor([0.9190, 1.5473, 0.6810, 0.4991, 0.5120, 0.5056, 0.5592, 0.5693, 0.7631,
        0.7371, 0.5018, 0.5758], device='cuda:1')
Thumb force: tensor([1.0634, 1.1611, 0.5454, 2.3886, 1.0816, 0.5509, 0.5362, 0.8517, 0.5019,
        0.9837, 0.5859, 0.5961], device='cuda:1')
Index force: tensor([0.8847, 0.8068, 0.8294, 0.7068, 0.8407, 0.6193, 0.5411, 0.5876, 0.8020,
        0.5242, 0.5662, 0.5864], device='cuda:1')
Storing NORMAL transition: reward=0.0154 (scaled=0.0154), steps=1
Reward stats updated: mean 0.0274 -> 0.0273, std: 0.0635
Collected 64 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.0866, Q2 Loss=1.0866, Entropy=0.0216, Time=0.12sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0780
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0778, Q2 Loss=1.0778, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0241
SAC Update 3/5: Actor Loss=-0.0066, Q1 Loss=1.0743, Q2 Loss=1.0743, Entropy=0.3462, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0568
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0688, Q2 Loss=1.0688, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0182
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0654, Q2 Loss=1.0654, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0504

------ SAC Update Summary (5 iterations) ------
Total time: 0.41s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.09s (22.2%)
Q1 update: 0.09s (21.3%)
Q2 update: 0.07s (18.2%)
Actor update: 0.14s (35.3%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001326
Q1 loss: 1.074578
Q2 loss: 1.074576
Current threshold: -149.9669
Global Scale Offset: 1.0374
Reward stats: mean=0.0273, std=0.0635, count=64
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.0746, Q2 Loss: 1.0746, Entropy: 0.0736, Mean TD Error: 0.0455, Threshold: -149.9669
tensor([ 0.0485,  0.4301,  0.6164,  0.7866,  0.0065,  0.4659,  0.8311,  1.0122,
         1.3232,  0.3491,  0.0668,  1.1973, -0.0224, -0.0119, -0.0922,  3.1933],
       device='cuda:1')
Original likelihood: -91.72532653808594
Adjusted likelihood: -91.72532653808594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.290640724007972
Current ori: tensor([-0.0224, -0.0119, -0.0922], device='cuda:1')
Middle force: tensor([1.5103, 0.7555, 0.5005, 0.5162, 0.5138, 0.5572, 0.5715, 0.7927, 0.7302,
        0.5022, 0.5733], device='cuda:1')
Thumb force: tensor([1.1331, 0.5244, 2.3192, 1.0328, 0.5335, 0.5338, 0.8348, 0.5016, 0.9688,
        0.5757, 0.5923], device='cuda:1')
Index force: tensor([0.7872, 0.8090, 0.7042, 0.8069, 0.5813, 0.5412, 0.5835, 0.7951, 0.5230,
        0.5599, 0.5833], device='cuda:1')
Storing NORMAL transition: reward=0.0357 (scaled=0.0357), steps=1
Reward stats updated: mean 0.0273 -> 0.0274, std: 0.0630
Collected 65 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0603, Q2 Loss=1.0603, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0353
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0561, Q2 Loss=1.0561, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0349
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0533, Q2 Loss=1.0533, Entropy=0.0007, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0722
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0465, Q2 Loss=1.0465, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0081
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0422, Q2 Loss=1.0422, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0180

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.8%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (18.2%)
Actor update: 0.13s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.051693
Q2 loss: 1.051693
Current threshold: -149.9516
Global Scale Offset: 1.0575
Reward stats: mean=0.0274, std=0.0630, count=65
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0517, Q2 Loss: 1.0517, Entropy: 0.0001, Mean TD Error: 0.0337, Threshold: -149.9516
tensor([ 0.0245,  0.3371,  0.6893,  0.8423, -0.0267,  0.4998,  0.7432,  1.0383,
         1.3950,  0.2521,  0.1084,  1.0469, -0.0412,  0.0118, -0.1293,  2.7386],
       device='cuda:1')
Original likelihood: -114.4156494140625
Adjusted likelihood: -114.4156494140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.488806053006556
Current ori: tensor([-0.0412,  0.0118, -0.1293], device='cuda:1')
Middle force: tensor([0.7436, 0.5003, 0.5129, 0.5155, 0.5561, 0.5685, 0.7924, 0.7236, 0.5020,
        0.5703], device='cuda:1')
Thumb force: tensor([0.5241, 2.2567, 1.0154, 0.5314, 0.5338, 0.8287, 0.5014, 0.9559, 0.5728,
        0.5892], device='cuda:1')
Index force: tensor([0.7999, 0.7200, 0.8150, 0.5731, 0.5384, 0.5807, 0.7855, 0.5220, 0.5585,
        0.5808], device='cuda:1')
Storing NORMAL transition: reward=-0.0985 (scaled=-0.0985), steps=1
Reward stats updated: mean 0.0274 -> 0.0255, std: 0.0644
Collected 66 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0396, Q2 Loss=1.0396, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0532
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0430, Q2 Loss=1.0430, Entropy=0.0001, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1418
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7784, Q2 Loss=0.7784, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0769
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0265, Q2 Loss=1.0265, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0539
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0205, Q2 Loss=1.0205, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0289

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.8%)
Q1 update: 0.08s (20.1%)
Q2 update: 0.08s (19.7%)
Actor update: 0.16s (39.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.981589
Q2 loss: 0.981589
Current threshold: -149.9428
Global Scale Offset: 1.0694
Reward stats: mean=0.0255, std=0.0644, count=66
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9816, Q2 Loss: 0.9816, Entropy: 0.0000, Mean TD Error: 0.0709, Threshold: -149.9428
tensor([ 0.0090,  0.3347,  0.6629,  0.8750, -0.1735,  0.4695,  0.7614,  0.9230,
         1.4787,  0.2031,  0.1600,  1.0437, -0.0353,  0.0987, -0.0384,  1.9402],
       device='cuda:1')
Original likelihood: -222.5069580078125
Adjusted likelihood: -222.5069580078125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([  -7.8257,   -9.1139,  -10.1481,  -10.5189,  -11.5098,  -12.5217,
         -14.3315,  -14.5978,  -14.7127,  -15.0286,  -18.5954,  -19.6867,
         -25.2989,  -31.6642,  -39.6504, -231.0441], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([  -7.8257,   -9.1139,  -10.1481,  -10.5189,  -11.5098,  -12.5217,
         -14.3315,  -14.5978,  -14.7127,  -15.0286,  -18.5954,  -19.6867,
         -25.2989,  -31.6642,  -39.6504, -231.0441], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -30.3905
1 mode projection succeeded
New goal: tensor([ 0.0372,  0.4930,  0.6285,  0.5888, -0.0289,  0.4705,  0.8140,  0.9177,
         1.2730,  0.3088,  0.2193,  1.1448, -0.0018,  0.0139, -0.0739],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -208.9515838623047
Adjusted likelihood: -208.9515838623047
Likelihood residual: 0.0
Original likelihood: -128.73155212402344
Adjusted likelihood: -128.73155212402344
Likelihood residual: 0.0
{'index': 128.73155212402344, 'thumb_middle': 208.9515838623047}
Current yaw: tensor([-0.0353,  0.0987, -0.0384], device='cuda:1')
7 index
tensor([ 0.0090,  0.3347,  0.6629,  0.8750, -0.1735,  0.4695,  0.7614,  0.9230,
         1.4787,  0.2031,  0.1600,  1.0437, -0.0353,  0.0987, -0.0384,  1.9402],
       device='cuda:1')
Solve time for step 1 11.834351247991435
Current ori: tensor([-0.0353,  0.0987, -0.0384], device='cuda:1')
Middle force: tensor([0.5525, 0.5703, 0.5772, 0.5544], device='cuda:1')
Thumb force: tensor([0.7179, 0.6230, 0.5073, 0.5003], device='cuda:1')
tensor([ 0.0693,  0.4056,  0.5803,  0.6135, -0.1246,  0.4695,  0.8003,  0.9175,
         1.3909,  0.3267,  0.1606,  1.0730, -0.0373,  0.0653, -0.0697, -0.7710],
       device='cuda:1')
Solve time for step 2 4.643373975995928
Current ori: tensor([-0.0373,  0.0653, -0.0697], device='cuda:1')
Middle force: tensor([0.5674, 0.5730, 0.5507], device='cuda:1')
Thumb force: tensor([0.6177, 0.5059, 0.5001], device='cuda:1')
tensor([ 0.0731,  0.4272,  0.5742,  0.5711, -0.0942,  0.4654,  0.8203,  0.9339,
         1.3595,  0.3567,  0.1331,  1.1328, -0.0311,  0.0442, -0.0750, -2.1904],
       device='cuda:1')
Solve time for step 3 4.331197060993873
Current ori: tensor([-0.0311,  0.0442, -0.0750], device='cuda:1')
Middle force: tensor([0.5756, 0.5468], device='cuda:1')
Thumb force: tensor([0.5573, 0.5839], device='cuda:1')
tensor([ 0.0758,  0.4312,  0.5737,  0.5630, -0.0839,  0.4673,  0.8266,  0.9360,
         1.3474,  0.3760,  0.1175,  1.1592, -0.0323,  0.0369, -0.0914, -3.0438],
       device='cuda:1')
Solve time for step 4 4.619373460009228
Current ori: tensor([-0.0323,  0.0369, -0.0914], device='cuda:1')
Middle force: tensor([0.5259], device='cuda:1')
Thumb force: tensor([0.5590], device='cuda:1')
Storing RECOVERY transition: reward=0.0582 (scaled=0.0194), steps=3
Reward stats updated: mean 0.0255 -> 0.0254, std: 0.0639
Collected 67 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0196, Q2 Loss=1.0196, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0873
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0112, Q2 Loss=1.0112, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0278
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0064, Q2 Loss=1.0064, Entropy=0.0029, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0005
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0057, Q2 Loss=1.0057, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0701
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0069, Q2 Loss=1.0069, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1430

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.6%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.8%)
Actor update: 0.16s (39.7%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000001
Q1 loss: 1.009963
Q2 loss: 1.009963
Current threshold: -149.9375
Global Scale Offset: 1.0786
Reward stats: mean=0.0254, std=0.0639, count=67
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0100, Q2 Loss: 1.0100, Entropy: 0.0006, Mean TD Error: 0.0657, Threshold: -149.9375
Original likelihood: -119.13227844238281
Adjusted likelihood: -119.13227844238281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0350,  0.0414, -0.0899], device='cuda:1')
8 turn
Sampling time 5.187302408972755
tensor([ 0.0277,  0.4955,  0.6171,  0.5846, -0.0900,  0.4708,  0.8196,  0.9296,
         1.3466,  0.3867,  0.1156,  1.1692, -0.0350,  0.0414, -0.0899, -3.2855],
       device='cuda:1')
Original likelihood: -113.24114990234375
Adjusted likelihood: -113.24114990234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.720288536977023
Current ori: tensor([-0.0350,  0.0414, -0.0899], device='cuda:1')
Middle force: tensor([0.5637, 0.6048, 0.5790, 1.7786, 0.5751, 1.1948, 0.5166, 0.6031, 0.7679,
        0.5741, 0.5028, 0.5936], device='cuda:1')
Thumb force: tensor([0.5313, 0.7400, 0.5130, 1.5149, 0.5545, 0.7918, 0.5035, 0.5884, 0.6385,
        1.2547, 0.5595, 0.6168], device='cuda:1')
Index force: tensor([0.7023, 0.5161, 0.5622, 0.5350, 0.5651, 0.6337, 0.7330, 0.6340, 0.5426,
        0.5776, 0.5460, 0.6274], device='cuda:1')
Storing NORMAL transition: reward=0.0111 (scaled=0.0111), steps=1
Reward stats updated: mean 0.0254 -> 0.0252, std: 0.0635
Collected 68 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7447, Q2 Loss=0.7447, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0500
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9889, Q2 Loss=0.9889, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0270
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6103, Q2 Loss=0.6103, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0088
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6766, Q2 Loss=0.6766, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0310
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9757, Q2 Loss=0.9757, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0231

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (20.4%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.799242
Q2 loss: 0.799242
Current threshold: -149.9343
Global Scale Offset: 1.0854
Reward stats: mean=0.0252, std=0.0635, count=68
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7992, Q2 Loss: 0.7992, Entropy: 0.0000, Mean TD Error: 0.0280, Threshold: -149.9343
tensor([ 0.0413,  0.4308,  0.4672,  0.6644, -0.0758,  0.3651,  0.9169,  0.7923,
         1.3348,  0.3556,  0.0964,  1.1006, -0.0636,  0.0733, -0.1074, -3.4406],
       device='cuda:1')
Original likelihood: -208.73800659179688
Adjusted likelihood: -208.73800659179688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.7837,  -5.5912,  -7.0934,  -7.2650,  -7.7574,  -7.9563,  -8.3988,
         -8.4676,  -9.1942,  -9.2748, -10.6313, -10.7359, -11.0270, -13.1634,
        -17.9151, -23.6506], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.7837,  -5.5912,  -7.0934,  -7.2650,  -7.7574,  -7.9563,  -8.3988,
         -8.4676,  -9.1942,  -9.2748, -10.6313, -10.7359, -11.0270, -13.1634,
        -17.9151, -23.6506], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.1816
1 mode projection succeeded
New goal: tensor([ 0.0490,  0.5818,  0.5003,  0.6181, -0.0325,  0.4824,  0.8915,  0.8271,
         1.3292,  0.2972,  0.1565,  1.0751, -0.0285,  0.0027, -0.0776],
       device='cuda:1')
tensor([[0.0110]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0137]], device='cuda:1')
Original likelihood: -131.03042602539062
Adjusted likelihood: -131.03042602539062
Likelihood residual: 0.0
Original likelihood: -99.90734100341797
Adjusted likelihood: -99.90734100341797
Likelihood residual: 0.0
{'index': 99.90734100341797, 'thumb_middle': 131.03042602539062}
Current yaw: tensor([-0.0636,  0.0733, -0.1074], device='cuda:1')
9 index
tensor([ 0.0413,  0.4308,  0.4672,  0.6644, -0.0758,  0.3651,  0.9169,  0.7923,
         1.3348,  0.3556,  0.0964,  1.1006, -0.0636,  0.0733, -0.1074, -3.4406],
       device='cuda:1')
Solve time for step 1 11.384221258980688
Current ori: tensor([-0.0636,  0.0733, -0.1074], device='cuda:1')
Middle force: tensor([0.5004, 0.5094, 0.5355, 0.5093], device='cuda:1')
Thumb force: tensor([0.5776, 0.5600, 0.5983, 0.5233], device='cuda:1')
tensor([ 0.0779,  0.5055,  0.4491,  0.6048, -0.0313,  0.4292,  0.8790,  0.8199,
         1.3925,  0.3473,  0.0944,  1.0815, -0.0944,  0.0480, -0.1193, -4.0011],
       device='cuda:1')
Solve time for step 2 4.886629475047812
Current ori: tensor([-0.0944,  0.0480, -0.1193], device='cuda:1')
Middle force: tensor([0.5081, 0.5309, 0.5070], device='cuda:1')
Thumb force: tensor([0.5528, 0.5908, 0.5206], device='cuda:1')
tensor([ 0.0834,  0.5228,  0.4471,  0.5922, -0.0305,  0.4388,  0.8882,  0.8366,
         1.4043,  0.3423,  0.0669,  1.1068, -0.1120,  0.0512, -0.1274, -4.6822],
       device='cuda:1')
Solve time for step 3 4.6994493129896
Current ori: tensor([-0.1120,  0.0512, -0.1274], device='cuda:1')
Middle force: tensor([0.5448, 0.5061], device='cuda:1')
Thumb force: tensor([0.6274, 0.6229], device='cuda:1')
tensor([ 0.0791,  0.5312,  0.4518,  0.5911, -0.0202,  0.4512,  0.8813,  0.8289,
         1.4015,  0.3562,  0.0544,  1.1175, -0.1238,  0.0502, -0.1591, -5.0630],
       device='cuda:1')
Solve time for step 4 4.306517524004448
Current ori: tensor([-0.1238,  0.0502, -0.1591], device='cuda:1')
Middle force: tensor([0.5069], device='cuda:1')
Thumb force: tensor([0.5793], device='cuda:1')
Storing RECOVERY transition: reward=0.0344 (scaled=0.0344), steps=1
Reward stats updated: mean 0.0252 -> 0.0253, std: 0.0630
Collected 69 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9713, Q2 Loss=0.9713, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0289
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9711, Q2 Loss=0.9711, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0715
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6829, Q2 Loss=0.6829, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0830
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6548, Q2 Loss=0.6548, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0343
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9536, Q2 Loss=0.9536, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0256

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.3%)
Q1 update: 0.07s (19.5%)
Q2 update: 0.07s (18.8%)
Actor update: 0.14s (38.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.846726
Q2 loss: 0.846726
Current threshold: -149.9322
Global Scale Offset: 1.0897
Reward stats: mean=0.0253, std=0.0630, count=69
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.8467, Q2 Loss: 0.8467, Entropy: 0.0000, Mean TD Error: 0.0487, Threshold: -149.9322
Original likelihood: -191.88832092285156
Adjusted likelihood: -191.88832092285156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-43.5054, -43.8151, -43.9387, -43.9464, -44.3104, -45.3793, -45.8836,
        -46.0605, -46.6302, -47.8627, -48.5434, -48.5654, -50.4791, -53.1655,
        -57.2324, -63.3519], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-43.5054, -43.8151, -43.9387, -43.9464, -44.3104, -45.3793, -45.8836,
        -46.0605, -46.6302, -47.8627, -48.5434, -48.5654, -50.4791, -53.1655,
        -57.2324, -63.3519], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -48.2919
1 mode projection succeeded
New goal: tensor([ 0.0531,  0.5855,  0.4915,  0.6362, -0.0286,  0.4850,  0.8736,  0.8144,
         1.3387,  0.2914,  0.1530,  1.0772, -0.0550,  0.0087, -0.5774],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -235.81724548339844
Adjusted likelihood: -235.81724548339844
Likelihood residual: 0.0
Original likelihood: -187.3747100830078
Adjusted likelihood: -187.3747100830078
Likelihood residual: 0.0
{'index': 187.3747100830078, 'thumb_middle': 235.81724548339844}
Current yaw: tensor([-0.1412,  0.0535, -0.1568], device='cuda:1')
10 index
tensor([ 0.0331,  0.5894,  0.4860,  0.6098, -0.0273,  0.4713,  0.8900,  0.8326,
         1.4009,  0.3770,  0.0360,  1.1397, -0.1412,  0.0535, -0.1568, -4.9654],
       device='cuda:1')
Solve time for step 1 11.880957944027614
Current ori: tensor([-0.1412,  0.0535, -0.1568], device='cuda:1')
Middle force: tensor([0.5676, 0.5100, 0.5401, 0.5042], device='cuda:1')
Thumb force: tensor([0.5504, 0.5130, 0.6582, 0.5604], device='cuda:1')
tensor([ 0.0736,  0.5441,  0.4490,  0.6072, -0.0411,  0.5079,  0.8929,  0.8288,
         1.4117,  0.3686,  0.0424,  1.1116, -0.1727,  0.0612, -0.1371, -4.9733],
       device='cuda:1')
Solve time for step 2 4.885724932944868
Current ori: tensor([-0.1727,  0.0612, -0.1371], device='cuda:1')
Middle force: tensor([0.5074, 0.5332, 0.5032], device='cuda:1')
Thumb force: tensor([0.5130, 0.6656, 0.5573], device='cuda:1')
tensor([ 0.0701,  0.5569,  0.4553,  0.6112, -0.0352,  0.5639,  0.9208,  0.8377,
         1.4447,  0.3687,  0.0531,  1.1081, -0.3837,  0.1335, -0.1354, -4.6148],
       device='cuda:1')
Solve time for step 3 4.233604851993732
Current ori: tensor([-0.3837,  0.1335, -0.1354], device='cuda:1')
Middle force: tensor([0.5276, 0.5008], device='cuda:1')
Thumb force: tensor([0.5913, 0.5691], device='cuda:1')
tensor([-0.0287,  0.6600,  0.4881,  0.6160, -0.0386,  0.7096,  0.9226,  0.7979,
         1.5000,  0.3727,  0.0974,  1.1046, -0.9047,  0.2846, -0.1354, -4.3324],
       device='cuda:1')
Solve time for step 4 4.247393425030168
Current ori: tensor([-0.9047,  0.2846, -0.1354], device='cuda:1')
Middle force: tensor([0.5020], device='cuda:1')
Thumb force: tensor([0.5434], device='cuda:1')
Storing RECOVERY transition: reward=-1.2936 (scaled=-1.2936), steps=1
Reward stats updated: mean 0.0253 -> 0.0065, std: 0.1686
Collected 70 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9578, Q2 Loss=0.9578, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1352
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6572, Q2 Loss=0.6572, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0234
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9416, Q2 Loss=0.9416, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0420
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7522, Q2 Loss=0.7522, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1081
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7007, Q2 Loss=0.7007, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0591

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.3%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (36.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.801907
Q2 loss: 0.801907
Current threshold: -149.9309
Global Scale Offset: 1.0924
Reward stats: mean=0.0065, std=0.1686, count=70
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8019, Q2 Loss: 0.8019, Entropy: 0.0000, Mean TD Error: 0.0736, Threshold: -149.9309
Original likelihood: -2558.060791015625
Adjusted likelihood: -2558.060791015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 5
Loaded trajectory sampler
Current yaw: tensor([-0.0007,  0.0139, -0.0336], device='cuda:1')
Current yaw: tensor([-0.0007,  0.0139, -0.0336], device='cuda:1')
1 turn
Sampling time 5.304054401989561
tensor([ 1.5301e-01,  5.8409e-01,  6.5786e-01,  5.0526e-01, -1.1233e-01,
         5.2159e-01,  9.3161e-01,  8.8353e-01,  1.2385e+00,  2.9936e-01,
         2.2439e-01,  1.1975e+00, -6.8447e-04,  1.3870e-02, -3.3592e-02,
         4.4109e-01], device='cuda:1')
Original likelihood: -118.531982421875
Adjusted likelihood: -118.531982421875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.791353077976964
Current ori: tensor([-0.0007,  0.0139, -0.0336], device='cuda:1')
Middle force: tensor([0.6578, 0.7204, 0.5322, 0.5190, 0.6185, 0.9616, 1.0120, 0.5751, 0.5474,
        0.5181, 0.5198, 0.5971], device='cuda:1')
Thumb force: tensor([0.5457, 2.3626, 0.6334, 1.5400, 1.0491, 0.8677, 1.9477, 0.6133, 0.5857,
        0.6098, 0.6091, 0.5946], device='cuda:1')
Index force: tensor([0.5794, 0.5016, 0.5947, 0.5585, 0.5707, 0.5079, 0.5923, 0.6064, 0.5035,
        0.5671, 0.6100, 0.6287], device='cuda:1')
Storing NORMAL transition: reward=0.0050 (scaled=0.0050), steps=1
Reward stats updated: mean 0.0065 -> 0.0064, std: 0.1674
Collected 71 transitions for RL
SAC Update 1/5: Actor Loss=-0.0044, Q1 Loss=0.6698, Q2 Loss=0.6698, Entropy=0.3296, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0423
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6864, Q2 Loss=0.6864, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0608
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.9183, Q2 Loss=0.9183, Entropy=0.0232, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0177
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8768, Q2 Loss=0.8768, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1769
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5978, Q2 Loss=0.5978, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0117

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (20.7%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (19.1%)
Actor update: 0.13s (38.2%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000896
Q1 loss: 0.749802
Q2 loss: 0.749802
Current threshold: -149.9424
Global Scale Offset: 1.0739
Reward stats: mean=0.0064, std=0.1674, count=71
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 0.7498, Q2 Loss: 0.7498, Entropy: 0.0706, Mean TD Error: 0.0619, Threshold: -149.9424
tensor([ 0.1185,  0.5370,  0.6628,  0.5546, -0.1345,  0.5147,  0.8337,  1.0308,
         1.2871,  0.2483,  0.2311,  1.2045,  0.0124,  0.0256, -0.0392,  0.6246],
       device='cuda:1')
Original likelihood: -138.19244384765625
Adjusted likelihood: -138.19244384765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.897224810963962
Current ori: tensor([ 0.0124,  0.0256, -0.0392], device='cuda:1')
Middle force: tensor([0.7119, 0.5325, 0.5180, 0.6157, 0.9510, 0.9958, 0.5765, 0.5465, 0.5180,
        0.5198, 0.5980], device='cuda:1')
Thumb force: tensor([2.3081, 0.6248, 1.5043, 1.0257, 0.8539, 1.9064, 0.6012, 0.5734, 0.5977,
        0.5933, 0.5792], device='cuda:1')
Index force: tensor([0.5012, 0.5859, 0.5575, 0.5694, 0.5070, 0.5884, 0.6023, 0.5033, 0.5650,
        0.6120, 0.6332], device='cuda:1')
Storing NORMAL transition: reward=0.0875 (scaled=0.0875), steps=1
Reward stats updated: mean 0.0064 -> 0.0076, std: 0.1665
Collected 72 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8313, Q2 Loss=0.8313, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6802
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9040, Q2 Loss=0.9040, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0797
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6213, Q2 Loss=0.6213, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1062
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6537, Q2 Loss=0.6537, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0538
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8837, Q2 Loss=0.8837, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0849

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.07s (22.0%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.05s (17.4%)
Actor update: 0.12s (38.3%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.778812
Q2 loss: 0.778812
Current threshold: -149.9493
Global Scale Offset: 1.0658
Reward stats: mean=0.0076, std=0.1665, count=72
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7788, Q2 Loss: 0.7788, Entropy: 0.0000, Mean TD Error: 0.2010, Threshold: -149.9493
tensor([ 0.0960,  0.6011,  0.5522,  0.5444, -0.2149,  0.5196,  0.8130,  1.0766,
         1.3789,  0.2919,  0.1807,  1.1311, -0.0139,  0.0653, -0.1311,  0.5214],
       device='cuda:1')
Original likelihood: -211.5393524169922
Adjusted likelihood: -211.5393524169922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.9725, -3.0931, -3.7619, -3.8523, -4.2746, -4.5837, -4.6826, -5.0614,
        -5.0893, -5.4374, -5.5011, -5.5818, -5.7699, -5.8329, -6.0119, -6.1845],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9725, -3.0931, -3.7619, -3.8523, -4.2746, -4.5837, -4.6826, -5.0614,
        -5.0893, -5.4374, -5.5011, -5.5818, -5.7699, -5.8329, -6.0119, -6.1845],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.8557
1 mode projection succeeded
New goal: tensor([ 0.0575,  0.5760,  0.5373,  0.5807, -0.0739,  0.4991,  0.8824,  0.8501,
         1.2997,  0.2499,  0.1996,  1.1680,  0.0030,  0.0124, -1.1834],
       device='cuda:1')
tensor([[0.0019]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -129.4448699951172
Adjusted likelihood: -129.4448699951172
Likelihood residual: 0.0
Original likelihood: -109.71437072753906
Adjusted likelihood: -109.71437072753906
Likelihood residual: 0.0
{'index': 109.71437072753906, 'thumb_middle': 129.4448699951172}
Current yaw: tensor([-0.0139,  0.0653, -0.1311], device='cuda:1')
2 index
tensor([ 0.0960,  0.6011,  0.5522,  0.5444, -0.2149,  0.5196,  0.8130,  1.0766,
         1.3789,  0.2919,  0.1807,  1.1311, -0.0139,  0.0653, -0.1311,  0.5214],
       device='cuda:1')
Solve time for step 1 11.12907908600755
Current ori: tensor([-0.0139,  0.0653, -0.1311], device='cuda:1')
Middle force: tensor([0.6019, 0.5338, 0.5287, 0.5818], device='cuda:1')
Thumb force: tensor([0.5081, 0.5471, 0.5897, 0.5421], device='cuda:1')
tensor([ 0.1049,  0.5164,  0.4869,  0.5506, -0.1830,  0.5101,  0.9052,  0.9274,
         1.3750,  0.2899,  0.1543,  1.1191, -0.0326,  0.0486, -0.1339,  0.5584],
       device='cuda:1')
Solve time for step 2 4.417004680028185
Current ori: tensor([-0.0326,  0.0486, -0.1339], device='cuda:1')
Middle force: tensor([0.5318, 0.5264, 0.5775], device='cuda:1')
Thumb force: tensor([0.5418, 0.5858, 0.5394], device='cuda:1')
tensor([ 0.1049,  0.5175,  0.4836,  0.5537, -0.1522,  0.5319,  0.9145,  0.8839,
         1.3713,  0.2845,  0.1214,  1.1198, -0.0466,  0.0292, -0.1460,  0.7445],
       device='cuda:1')
Solve time for step 3 4.343761690019164
Current ori: tensor([-0.0466,  0.0292, -0.1460], device='cuda:1')
Middle force: tensor([0.5244, 0.5730], device='cuda:1')
Thumb force: tensor([0.5756, 0.5362], device='cuda:1')
tensor([ 0.1047,  0.5169,  0.4837,  0.5532, -0.1428,  0.5200,  0.9335,  0.8997,
         1.3607,  0.2921,  0.1019,  1.1634, -0.0387,  0.0209, -0.1495,  1.0305],
       device='cuda:1')
Solve time for step 4 4.161758319998626
Current ori: tensor([-0.0387,  0.0209, -0.1495], device='cuda:1')
Middle force: tensor([0.5431], device='cuda:1')
Thumb force: tensor([0.5848], device='cuda:1')
Storing RECOVERY transition: reward=0.0188 (scaled=0.0094), steps=2
Reward stats updated: mean 0.0076 -> 0.0076, std: 0.1653
Collected 73 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7083, Q2 Loss=0.7083, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6595
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8569, Q2 Loss=0.8569, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1204
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6509, Q2 Loss=0.6509, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0570
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8386, Q2 Loss=0.8386, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7012
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7207, Q2 Loss=0.7207, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0329

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.1%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.06s (18.2%)
Actor update: 0.13s (37.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 0.755085
Q2 loss: 0.755085
Current threshold: -149.9536
Global Scale Offset: 1.0609
Reward stats: mean=0.0076, std=0.1653, count=73
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.7551, Q2 Loss: 0.7551, Entropy: 0.0000, Mean TD Error: 0.3142, Threshold: -149.9536
Original likelihood: -109.17774963378906
Adjusted likelihood: -109.17774963378906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0406,  0.0212, -0.1473], device='cuda:1')
3 turn
Sampling time 5.164162186032627
tensor([ 0.0533,  0.5819,  0.5275,  0.5749, -0.1432,  0.5236,  0.9315,  0.8945,
         1.3571,  0.2988,  0.1064,  1.1568, -0.0406,  0.0212, -0.1473,  1.1151],
       device='cuda:1')
Original likelihood: -99.98785400390625
Adjusted likelihood: -99.98785400390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.673528631043155
Current ori: tensor([-0.0406,  0.0212, -0.1473], device='cuda:1')
Middle force: tensor([0.8556, 1.2005, 0.9153, 0.5124, 0.8222, 0.5765, 0.8201, 0.5214, 0.5092,
        0.5995, 0.7195, 0.6035], device='cuda:1')
Thumb force: tensor([3.1256, 1.1842, 0.6322, 0.5648, 0.9517, 0.5701, 0.5415, 0.5539, 0.5586,
        0.5845, 0.6569, 0.6181], device='cuda:1')
Index force: tensor([1.0435, 0.7827, 0.6814, 0.5472, 0.5889, 0.5490, 0.5209, 0.5982, 0.5554,
        0.6112, 0.5558, 0.6090], device='cuda:1')
Storing NORMAL transition: reward=0.1187 (scaled=0.1187), steps=1
Reward stats updated: mean 0.0076 -> 0.0091, std: 0.1647
Collected 74 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8593, Q2 Loss=0.8593, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0013
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6528, Q2 Loss=0.6528, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0856
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6195, Q2 Loss=0.6195, Entropy=0.0008, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1120
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8434, Q2 Loss=0.8434, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0544
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6049, Q2 Loss=0.6049, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6477

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (24.3%)
Q1 update: 0.05s (17.5%)
Q2 update: 0.05s (16.7%)
Actor update: 0.11s (35.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.715987
Q2 loss: 0.715987
Current threshold: -149.9563
Global Scale Offset: 1.0581
Reward stats: mean=0.0091, std=0.1647, count=74
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7160, Q2 Loss: 0.7160, Entropy: 0.0002, Mean TD Error: 0.1802, Threshold: -149.9563
tensor([ 0.0190,  0.5652,  0.5313,  0.5441, -0.1402,  0.4877,  0.9628,  0.9439,
         1.2968,  0.4052,  0.1873,  1.0634, -0.0380,  0.0217, -0.2664,  1.2400],
       device='cuda:1')
Original likelihood: -134.62155151367188
Adjusted likelihood: -134.62155151367188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.810808625014033
Current ori: tensor([-0.0380,  0.0217, -0.2664], device='cuda:1')
Middle force: tensor([1.1335, 0.9150, 0.5130, 0.8291, 0.5670, 0.8221, 0.5477, 0.8475, 0.5580,
        0.5098, 0.5192], device='cuda:1')
Thumb force: tensor([1.0674, 0.5984, 0.5596, 0.9237, 0.5571, 0.5455, 0.5966, 0.5155, 0.9330,
        1.2179, 0.5862], device='cuda:1')
Index force: tensor([0.7564, 0.6778, 0.5425, 0.5742, 0.5454, 0.5200, 0.6320, 0.5757, 0.5806,
        0.5529, 0.6628], device='cuda:1')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean 0.0091 -> 0.0092, std: 0.1636
Collected 75 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5454, Q2 Loss=0.5454, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0201
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8575, Q2 Loss=0.8575, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7163
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8400, Q2 Loss=0.8400, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1366
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6539, Q2 Loss=0.6539, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6550
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5404, Q2 Loss=0.5404, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0212

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.5%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (39.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.687440
Q2 loss: 0.687440
Current threshold: -149.9579
Global Scale Offset: 1.0565
Reward stats: mean=0.0092, std=0.1636, count=75
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6874, Q2 Loss: 0.6874, Entropy: 0.0000, Mean TD Error: 0.3098, Threshold: -149.9579
tensor([ 0.1491,  0.5369,  0.5885,  0.7498, -0.0703,  0.4335,  0.9627,  0.9181,
         1.3552,  0.3153,  0.1017,  1.1324, -0.0420,  0.0154, -0.2798,  0.4457],
       device='cuda:1')
Original likelihood: -117.28704833984375
Adjusted likelihood: -117.28704833984375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.518085244984832
Current ori: tensor([-0.0420,  0.0154, -0.2798], device='cuda:1')
Middle force: tensor([1.4751, 0.5194, 0.5394, 0.7780, 0.5248, 0.5488, 0.8799, 0.5292, 0.6272,
        0.5672], device='cuda:1')
Thumb force: tensor([0.5897, 0.5877, 0.6588, 1.3266, 0.5119, 0.5690, 0.8522, 1.0894, 0.6028,
        1.9522], device='cuda:1')
Index force: tensor([0.5708, 0.6612, 0.5956, 0.8292, 0.6695, 0.6614, 0.7283, 0.5751, 0.5652,
        0.5229], device='cuda:1')
Storing NORMAL transition: reward=-0.0711 (scaled=-0.0711), steps=1
Reward stats updated: mean 0.0092 -> 0.0081, std: 0.1628
Collected 76 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5671, Q2 Loss=0.5671, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0690
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6639, Q2 Loss=0.6639, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0655
SAC Update 3/5: Actor Loss=-0.0037, Q1 Loss=0.6322, Q2 Loss=0.6322, Entropy=0.3464, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0392
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6745, Q2 Loss=0.6745, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1010
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7422, Q2 Loss=0.7422, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0287

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.3%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.9%)
Actor update: 0.13s (38.6%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000736
Q1 loss: 0.655986
Q2 loss: 0.655986
Current threshold: -149.9495
Global Scale Offset: 1.0575
Reward stats: mean=0.0081, std=0.1628, count=76
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 0.6560, Q2 Loss: 0.6560, Entropy: 0.0693, Mean TD Error: 0.0607, Threshold: -149.9495
tensor([ 0.2530,  0.5696,  0.6674,  0.7324, -0.0856,  0.4515,  0.8841,  0.9977,
         1.4106,  0.2067,  0.0552,  1.2115, -0.0247,  0.0214, -0.2073, -0.8384],
       device='cuda:1')
Original likelihood: -168.73333740234375
Adjusted likelihood: -168.73333740234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.6394, -3.6632, -3.7220, -3.7494, -3.7598, -4.5568, -4.8691, -5.1342,
        -5.1481, -5.3318, -5.5205, -5.7705, -6.1838, -6.3489, -7.3791, -9.3069],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.6394, -3.6632, -3.7220, -3.7494, -3.7598, -4.5568, -4.8691, -5.1342,
        -5.1481, -5.3318, -5.5205, -5.7705, -6.1838, -6.3489, -7.3791, -9.3069],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2552
1 mode projection succeeded
New goal: tensor([ 0.0647,  0.5533,  0.5508,  0.6287, -0.0500,  0.5011,  0.7945,  0.9356,
         1.2345,  0.3608,  0.2422,  1.1562,  0.0044,  0.0143, -0.3141],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -181.35621643066406
Adjusted likelihood: -181.35621643066406
Likelihood residual: 0.0
Original likelihood: -97.97740936279297
Adjusted likelihood: -97.97740936279297
Likelihood residual: 0.0
{'index': 97.97740936279297, 'thumb_middle': 181.35621643066406}
Current yaw: tensor([-0.0247,  0.0214, -0.2073], device='cuda:1')
4 index
tensor([ 0.2530,  0.5696,  0.6674,  0.7324, -0.0856,  0.4515,  0.8841,  0.9977,
         1.4106,  0.2067,  0.0552,  1.2115, -0.0247,  0.0214, -0.2073, -0.8384],
       device='cuda:1')
Solve time for step 1 11.2756009940058
Current ori: tensor([-0.0247,  0.0214, -0.2073], device='cuda:1')
Middle force: tensor([0.5673, 0.5261, 0.5208, 0.5504], device='cuda:1')
Thumb force: tensor([0.5370, 0.6206, 0.5917, 0.6110], device='cuda:1')
tensor([ 0.1424,  0.4976,  0.5185,  0.6217, -0.0765,  0.4815,  0.8520,  0.9931,
         1.3203,  0.3609,  0.1240,  1.1540, -0.0366,  0.0166, -0.2175,  1.1609],
       device='cuda:1')
Solve time for step 2 4.509233318967745
Current ori: tensor([-0.0366,  0.0166, -0.2175], device='cuda:1')
Middle force: tensor([0.5358, 0.5147, 0.5006], device='cuda:1')
Thumb force: tensor([0.5357, 0.5048, 0.5381], device='cuda:1')
tensor([ 0.1234,  0.4978,  0.5057,  0.6075, -0.0862,  0.4944,  0.8504,  0.9934,
         1.2856,  0.4202,  0.1600,  1.1288, -0.0436,  0.0186, -0.2197,  2.4874],
       device='cuda:1')
Solve time for step 3 4.410930333950091
Current ori: tensor([-0.0436,  0.0186, -0.2197], device='cuda:1')
Middle force: tensor([0.5184, 0.5458], device='cuda:1')
Thumb force: tensor([0.5806, 0.6030], device='cuda:1')
tensor([ 0.1146,  0.4977,  0.4995,  0.6029, -0.0910,  0.5020,  0.8560,  1.0000,
         1.2902,  0.4138,  0.1504,  1.1337, -0.0460,  0.0169, -0.2202,  3.1284],
       device='cuda:1')
Solve time for step 4 4.563399312959518
Current ori: tensor([-0.0460,  0.0169, -0.2202], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5273], device='cuda:1')
Storing RECOVERY transition: reward=0.0082 (scaled=0.0027), steps=3
Reward stats updated: mean 0.0081 -> 0.0080, std: 0.1617
Collected 77 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8423, Q2 Loss=0.8423, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7163
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5057, Q2 Loss=0.5057, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0117
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9119, Q2 Loss=0.9119, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7522
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6580, Q2 Loss=0.6580, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0192
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7670, Q2 Loss=0.7670, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0801

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.0%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (17.4%)
Actor update: 0.13s (37.5%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.736972
Q2 loss: 0.736972
Current threshold: -149.9394
Global Scale Offset: 1.0591
Reward stats: mean=0.0080, std=0.1617, count=77
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7370, Q2 Loss: 0.7370, Entropy: 0.0000, Mean TD Error: 0.3159, Threshold: -149.9394
Original likelihood: -90.46211242675781
Adjusted likelihood: -90.46211242675781
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0449,  0.0158, -0.2169], device='cuda:1')
5 turn
Sampling time 5.069529766973574
tensor([ 0.0670,  0.5592,  0.5451,  0.6252, -0.0896,  0.5012,  0.8580,  1.0004,
         1.2889,  0.4140,  0.1479,  1.1399, -0.0449,  0.0158, -0.2169,  3.2126],
       device='cuda:1')
Original likelihood: -84.32571411132812
Adjusted likelihood: -84.32571411132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.87250701704761
Current ori: tensor([-0.0449,  0.0158, -0.2169], device='cuda:1')
Middle force: tensor([0.9075, 1.5645, 0.6669, 0.5011, 0.5126, 0.5023, 0.6108, 0.6965, 0.6844,
        0.5236, 0.5955, 0.5769], device='cuda:1')
Thumb force: tensor([1.0917, 1.1551, 0.5544, 2.3985, 1.0855, 0.5346, 0.5544, 0.5147, 0.5171,
        0.8649, 1.5385, 0.6172], device='cuda:1')
Index force: tensor([0.8789, 0.8023, 0.7892, 0.7097, 0.8330, 0.6128, 0.5419, 0.6346, 0.7688,
        0.5861, 0.5336, 0.6080], device='cuda:1')
Storing NORMAL transition: reward=0.0714 (scaled=0.0714), steps=1
Reward stats updated: mean 0.0080 -> 0.0088, std: 0.1608
Collected 78 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6583, Q2 Loss=0.6583, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6603
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7388, Q2 Loss=0.7388, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0870
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6055, Q2 Loss=0.6055, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0812
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7564, Q2 Loss=0.7564, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0324
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=0.5878, Q2 Loss=0.5878, Entropy=0.3286, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0653

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.0%)
Q1 update: 0.07s (19.3%)
Q2 update: 0.07s (19.1%)
Actor update: 0.14s (38.5%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002006
Q1 loss: 0.669362
Q2 loss: 0.669362
Current threshold: -149.9397
Global Scale Offset: 1.0519
Reward stats: mean=0.0088, std=0.1608, count=78
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 0.6694, Q2 Loss: 0.6694, Entropy: 0.0657, Mean TD Error: 0.1852, Threshold: -149.9397
tensor([ 0.0593,  0.5341,  0.5655,  0.6392, -0.0876,  0.4719,  0.8875,  1.0305,
         1.3255,  0.3852,  0.1399,  1.0787, -0.0378,  0.0164, -0.2879,  3.2909],
       device='cuda:1')
Original likelihood: -82.02490234375
Adjusted likelihood: -82.02490234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.182811804988887
Current ori: tensor([-0.0378,  0.0164, -0.2879], device='cuda:1')
Middle force: tensor([1.5481, 0.6950, 0.5110, 0.5136, 1.0917, 0.5738, 1.0003, 0.7589, 0.5107,
        0.5489, 0.5501], device='cuda:1')
Thumb force: tensor([1.1321, 0.5265, 2.4065, 1.0091, 0.8448, 0.6034, 0.7965, 0.5251, 0.5079,
        0.7932, 0.5809], device='cuda:1')
Index force: tensor([0.7890, 0.8300, 0.6549, 0.7941, 0.5517, 0.5785, 0.5192, 0.5384, 0.7421,
        0.6013, 0.5493], device='cuda:1')
Storing NORMAL transition: reward=0.1215 (scaled=0.1215), steps=1
Reward stats updated: mean 0.0088 -> 0.0103, std: 0.1603
Collected 79 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5364, Q2 Loss=0.5364, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0826
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6878, Q2 Loss=0.6878, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0261
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=0.4620, Q2 Loss=0.4620, Entropy=0.3273, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0416
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6038, Q2 Loss=0.6038, Entropy=0.0022, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0159
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7364, Q2 Loss=0.7364, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1126

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (19.3%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (19.2%)
Actor update: 0.15s (39.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002034
Q1 loss: 0.605287
Q2 loss: 0.605287
Current threshold: -149.9722
Global Scale Offset: 1.0103
Reward stats: mean=0.0103, std=0.1603, count=79
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 0.6053, Q2 Loss: 0.6053, Entropy: 0.0659, Mean TD Error: 0.0558, Threshold: -149.9722
tensor([ 0.0745,  0.4934,  0.6082,  0.6919, -0.0671,  0.4458,  0.9088,  1.1193,
         1.3631,  0.3215,  0.1128,  1.0570, -0.0242,  0.0043, -0.4084,  3.4939],
       device='cuda:1')
Original likelihood: -77.44111633300781
Adjusted likelihood: -77.44111633300781
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.544791135005653
Current ori: tensor([-0.0242,  0.0043, -0.4084], device='cuda:1')
Middle force: tensor([0.6803, 0.5003, 0.5142, 0.5030, 0.6056, 0.6915, 0.6994, 0.5295, 0.5978,
        0.5689], device='cuda:1')
Thumb force: tensor([0.5375, 2.2703, 1.0239, 0.5292, 0.5503, 0.5130, 0.5119, 0.8269, 1.4767,
        0.6100], device='cuda:1')
Index force: tensor([0.7767, 0.7514, 0.7999, 0.5918, 0.5392, 0.6248, 0.7580, 0.5714, 0.5302,
        0.6036], device='cuda:1')
Storing NORMAL transition: reward=-0.0065 (scaled=-0.0065), steps=1
Reward stats updated: mean 0.0103 -> 0.0101, std: 0.1593
Collected 80 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5071, Q2 Loss=0.5071, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0966
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7044, Q2 Loss=0.7044, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0634
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4513, Q2 Loss=0.4513, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0115
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5307, Q2 Loss=0.5307, Entropy=0.0211, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0817
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5809, Q2 Loss=0.5809, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0169

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (18.7%)
Q1 update: 0.07s (19.3%)
Q2 update: 0.07s (18.8%)
Actor update: 0.14s (40.0%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000007
Q1 loss: 0.554868
Q2 loss: 0.554868
Current threshold: -149.9982
Global Scale Offset: 0.9806
Reward stats: mean=0.0101, std=0.1593, count=80
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.5549, Q2 Loss: 0.5549, Entropy: 0.0042, Mean TD Error: 0.0540, Threshold: -149.9982
tensor([ 0.0808,  0.4151,  0.6435,  0.8451, -0.1206,  0.4191,  0.9999,  1.1140,
         1.4277,  0.3444,  0.0431,  1.0889, -0.0051,  0.0118, -0.4012,  3.0350],
       device='cuda:1')
Original likelihood: -136.47714233398438
Adjusted likelihood: -136.47714233398438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.2149494549958035
Current ori: tensor([-0.0051,  0.0118, -0.4012], device='cuda:1')
Middle force: tensor([0.5006, 0.5109, 0.5073, 0.5843, 0.6873, 0.6592, 0.5656, 0.5834, 0.8393],
       device='cuda:1')
Thumb force: tensor([1.9913, 0.9721, 0.5324, 0.5400, 0.5122, 0.5345, 0.5412, 0.5806, 0.5137],
       device='cuda:1')
Index force: tensor([0.6912, 0.7723, 0.5771, 0.5267, 0.5931, 0.5003, 0.5641, 0.5905, 0.6817],
       device='cuda:1')
Storing NORMAL transition: reward=0.0117 (scaled=0.0117), steps=1
Reward stats updated: mean 0.0101 -> 0.0101, std: 0.1583
Collected 81 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6556, Q2 Loss=0.6556, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6664
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.6686, Q2 Loss=0.6686, Entropy=0.0196, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1263
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5027, Q2 Loss=0.5027, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0613
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6924, Q2 Loss=0.6924, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1863
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5541, Q2 Loss=0.5541, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0697

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (18.9%)
Q1 update: 0.08s (19.4%)
Q2 update: 0.08s (18.8%)
Actor update: 0.16s (39.9%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000011
Q1 loss: 0.614695
Q2 loss: 0.614695
Current threshold: -150.0135
Global Scale Offset: 0.9659
Reward stats: mean=0.0101, std=0.1583, count=81
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6147, Q2 Loss: 0.6147, Entropy: 0.0039, Mean TD Error: 0.2220, Threshold: -150.0135
tensor([ 0.0922,  0.4073,  0.6734,  0.8255, -0.1138,  0.4280,  0.9970,  1.1371,
         1.4003,  0.4720,  0.0727,  1.0354, -0.0047,  0.0054, -0.4127,  3.0697],
       device='cuda:1')
Original likelihood: -142.35794067382812
Adjusted likelihood: -142.35794067382812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 5.382658273971174
Current ori: tensor([-0.0047,  0.0054, -0.4127], device='cuda:1')
Middle force: tensor([0.5126, 1.0650, 0.5708, 0.9721, 0.7413, 0.5083, 0.5458, 0.5474],
       device='cuda:1')
Thumb force: tensor([0.9727, 0.8085, 0.5930, 0.7691, 0.5222, 0.5075, 0.7675, 0.5742],
       device='cuda:1')
Index force: tensor([0.7546, 0.5465, 0.5704, 0.5162, 0.5348, 0.7199, 0.5918, 0.5429],
       device='cuda:1')
Storing NORMAL transition: reward=0.0001 (scaled=0.0001), steps=1
Reward stats updated: mean 0.0101 -> 0.0100, std: 0.1574
Collected 82 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8100, Q2 Loss=0.8100, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7183
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8220, Q2 Loss=0.8220, Entropy=0.0182, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7238
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4191, Q2 Loss=0.4191, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0078
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6418, Q2 Loss=0.6418, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1018
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6023, Q2 Loss=0.6023, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0210

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.8%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.06s (18.5%)
Actor update: 0.13s (37.2%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000012
Q1 loss: 0.659020
Q2 loss: 0.659020
Current threshold: -150.0225
Global Scale Offset: 0.9600
Reward stats: mean=0.0100, std=0.1574, count=82
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6590, Q2 Loss: 0.6590, Entropy: 0.0037, Mean TD Error: 0.3146, Threshold: -150.0225
tensor([ 1.0153e-01,  4.0764e-01,  6.6889e-01,  8.5312e-01, -2.1443e-01,
         4.1877e-01,  9.9657e-01,  1.0902e+00,  1.3289e+00,  5.8545e-01,
         1.0341e-01,  1.0440e+00, -7.2319e-04, -3.5200e-04, -4.1275e-01,
         3.1166e+00], device='cuda:1')
Original likelihood: -214.33102416992188
Adjusted likelihood: -214.33102416992188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.4728,  -2.7194,  -3.1732,  -3.3452,  -3.3543,  -3.4760,  -3.7123,
         -3.9748,  -4.1410,  -4.3495,  -4.6016,  -4.8822,  -5.0058,  -7.5946,
         -9.6533, -10.1871], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.4728,  -2.7194,  -3.1732,  -3.3452,  -3.3543,  -3.4760,  -3.7123,
         -3.9748,  -4.1410,  -4.3495,  -4.6016,  -4.8822,  -5.0058,  -7.5946,
         -9.6533, -10.1871], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.7902
1 mode projection succeeded
New goal: tensor([ 3.4331e-02,  5.2567e-01,  5.7668e-01,  5.9788e-01, -6.6729e-02,
         4.6678e-01,  8.8225e-01,  9.1292e-01,  1.2754e+00,  3.6390e-01,
         2.1661e-01,  1.1007e+00, -4.0359e-04,  1.4199e-02, -1.0915e-01],
       device='cuda:1')
tensor([[0.0044]], device='cuda:1') tensor([[0.0104]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -85.45745849609375
Adjusted likelihood: -85.45745849609375
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 85.45745849609375}
Current yaw: tensor([-7.2319e-04, -3.5200e-04, -4.1275e-01], device='cuda:1')
6 thumb_middle
tensor([ 1.0153e-01,  4.0764e-01,  6.6889e-01,  8.5312e-01, -2.1443e-01,
         4.1877e-01,  9.9657e-01,  1.0902e+00,  1.3289e+00,  5.8545e-01,
         1.0341e-01,  1.0440e+00, -7.2319e-04, -3.5200e-04, -4.1275e-01,
         3.1166e+00], device='cuda:1')
Solve time for step 1 9.944436674006283
Current ori: tensor([-7.2319e-04, -3.5200e-04, -4.1275e-01], device='cuda:1')
Index force: tensor([0.5987, 0.6411, 0.6353, 0.6044], device='cuda:1')
tensor([ 0.0750,  0.4270,  0.6660,  0.7537, -0.1755,  0.4463,  0.8737,  0.9250,
         1.2335,  0.3883,  0.1273,  1.0608, -0.0172,  0.0155, -0.4127,  3.0472],
       device='cuda:1')
Solve time for step 2 3.802585540979635
Current ori: tensor([-0.0172,  0.0155, -0.4127], device='cuda:1')
Index force: tensor([0.6339, 0.6231, 0.5942], device='cuda:1')
tensor([ 0.0549,  0.4628,  0.6327,  0.6863, -0.1829,  0.4569,  0.8532,  0.9005,
         1.2331,  0.3533,  0.1408,  1.0728, -0.0329,  0.0330, -0.4127,  2.9306],
       device='cuda:1')
Solve time for step 3 3.855682188004721
Current ori: tensor([-0.0329,  0.0330, -0.4127], device='cuda:1')
Index force: tensor([0.6074, 0.5844], device='cuda:1')
tensor([ 0.0488,  0.5000,  0.6027,  0.6342, -0.1954,  0.4566,  0.8576,  0.9005,
         1.2346,  0.3481,  0.1464,  1.0777, -0.0460,  0.0425, -0.4127,  2.8497],
       device='cuda:1')
Solve time for step 4 3.5584620489971712
Current ori: tensor([-0.0460,  0.0425, -0.4127], device='cuda:1')
Index force: tensor([0.5660], device='cuda:1')
Storing RECOVERY transition: reward=-0.0040 (scaled=-0.0008), steps=5
Reward stats updated: mean 0.0100 -> 0.0098, std: 0.1564
Collected 83 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5299, Q2 Loss=0.5299, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0406
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6444, Q2 Loss=0.6444, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1185
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4828, Q2 Loss=0.4828, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0698
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6111, Q2 Loss=0.6111, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0276
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5918, Q2 Loss=0.5918, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0789

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.2%)
Q1 update: 0.08s (19.9%)
Q2 update: 0.07s (19.4%)
Actor update: 0.15s (40.4%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.572023
Q2 loss: 0.572023
Current threshold: -150.0278
Global Scale Offset: 0.9569
Reward stats: mean=0.0098, std=0.1564, count=83
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.5720, Q2 Loss: 0.5720, Entropy: 0.0000, Mean TD Error: 0.0671, Threshold: -150.0278
Original likelihood: -134.77694702148438
Adjusted likelihood: -134.77694702148438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0422,  0.0401, -0.4139], device='cuda:1')
7 turn
Sampling time 5.020655594998971
tensor([ 0.0342,  0.4875,  0.6017,  0.6446, -0.1408,  0.4982,  0.8908,  0.9141,
         1.3031,  0.3693,  0.2036,  1.1060, -0.0422,  0.0401, -0.4139,  2.9603],
       device='cuda:1')
Original likelihood: -128.50340270996094
Adjusted likelihood: -128.50340270996094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.179711322998628
Current ori: tensor([-0.0422,  0.0401, -0.4139], device='cuda:1')
Middle force: tensor([0.5524, 0.5360, 0.5839, 1.6577, 0.5730, 1.1356, 0.5048, 1.0828, 0.6694,
        0.5587, 0.5571, 0.6177], device='cuda:1')
Thumb force: tensor([0.5600, 0.7150, 0.5113, 1.4115, 0.5436, 0.7179, 0.5062, 1.2605, 1.7494,
        0.5982, 0.5781, 0.6959], device='cuda:1')
Index force: tensor([0.7201, 0.5115, 0.5546, 0.5168, 0.5513, 0.6207, 0.7032, 0.5890, 0.5662,
        0.5902, 0.5531, 0.5665], device='cuda:1')
Storing NORMAL transition: reward=0.1445 (scaled=0.1445), steps=1
Reward stats updated: mean 0.0098 -> 0.0114, std: 0.1562
Collected 84 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5993, Q2 Loss=0.5993, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1071
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4577, Q2 Loss=0.4577, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1278
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5750, Q2 Loss=0.5750, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1086
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4538, Q2 Loss=0.4538, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0415
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.8090, Q2 Loss=0.8090, Entropy=0.0172, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7238

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.2%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.07s (18.0%)
Actor update: 0.15s (38.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000011
Q1 loss: 0.578952
Q2 loss: 0.578952
Current threshold: -150.0310
Global Scale Offset: 0.9558
Reward stats: mean=0.0114, std=0.1562, count=84
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.5790, Q2 Loss: 0.5790, Entropy: 0.0034, Mean TD Error: 0.2218, Threshold: -150.0310
tensor([-3.1407e-03,  3.5302e-01,  6.8814e-01,  6.6634e-01, -5.4010e-03,
         4.9038e-01,  9.8805e-01,  9.0596e-01,  1.2925e+00,  3.4520e-01,
         9.9174e-02,  1.0904e+00, -6.0933e-02, -3.5485e-02, -5.6175e-01,
         4.4642e+00], device='cuda:1')
Original likelihood: -138.51980590820312
Adjusted likelihood: -138.51980590820312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.347439470991958
Current ori: tensor([-0.0609, -0.0355, -0.5617], device='cuda:1')
Middle force: tensor([0.5080, 0.6504, 0.5453, 0.5801, 0.5297, 0.5996, 0.5374, 0.8994, 0.5445,
        0.5235, 0.5963], device='cuda:1')
Thumb force: tensor([0.7895, 0.5841, 0.6661, 0.6705, 0.5573, 0.5936, 0.5434, 0.5142, 1.2632,
        0.5557, 0.7847], device='cuda:1')
Index force: tensor([0.5254, 0.5663, 0.5505, 0.5861, 0.6447, 0.5891, 0.5747, 0.5900, 0.5441,
        0.5414, 0.5907], device='cuda:1')
Storing NORMAL transition: reward=-0.0432 (scaled=-0.0432), steps=1
Reward stats updated: mean 0.0114 -> 0.0108, std: 0.1554
Collected 85 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5070, Q2 Loss=0.5070, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0310
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4715, Q2 Loss=0.4715, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0912
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.8066, Q2 Loss=0.8066, Entropy=0.0173, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7238
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.8058, Q2 Loss=0.8058, Entropy=0.0174, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7238
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4971, Q2 Loss=0.4971, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0873

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.06s (17.3%)
Q1 update: 0.07s (19.8%)
Q2 update: 0.07s (19.5%)
Actor update: 0.15s (40.4%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000022
Q1 loss: 0.617597
Q2 loss: 0.617597
Current threshold: -150.0321
Global Scale Offset: 0.9607
Reward stats: mean=0.0108, std=0.1554, count=85
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6176, Q2 Loss: 0.6176, Entropy: 0.0069, Mean TD Error: 0.3314, Threshold: -150.0321
tensor([ 1.4796e-03,  3.4956e-01,  6.3298e-01,  6.8513e-01, -1.0077e-01,
         5.9521e-01,  9.6542e-01,  1.0057e+00,  1.3029e+00,  3.6310e-01,
         4.6637e-02,  1.1756e+00, -9.6851e-02, -2.5165e-02, -5.2396e-01,
         4.8737e+00], device='cuda:1')
Original likelihood: -192.80191040039062
Adjusted likelihood: -192.80191040039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -9.2470,  -9.7610, -11.2207, -11.4543, -11.5602, -11.7104, -12.1717,
        -12.2977, -12.4368, -12.6546, -13.2375, -13.8379, -14.1126, -15.7391,
        -22.6919, -25.9769], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -9.2470,  -9.7610, -11.2207, -11.4543, -11.5602, -11.7104, -12.1717,
        -12.2977, -12.4368, -12.6546, -13.2375, -13.8379, -14.1126, -15.7391,
        -22.6919, -25.9769], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -13.7569
1 mode projection succeeded
New goal: tensor([ 0.0312,  0.4868,  0.6026,  0.6340, -0.0221,  0.5458,  0.7371,  1.0160,
         1.2853,  0.4089,  0.1692,  1.0394, -0.0302, -0.0071, -0.7539],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0123]], device='cuda:1')
Original likelihood: -162.1471710205078
Adjusted likelihood: -162.1471710205078
Likelihood residual: 0.0
{'index': 162.1471710205078, 'thumb_middle': inf}
Current yaw: tensor([-0.0969, -0.0252, -0.5240], device='cuda:1')
8 index
tensor([ 1.4796e-03,  3.4956e-01,  6.3298e-01,  6.8513e-01, -1.0077e-01,
         5.9521e-01,  9.6542e-01,  1.0057e+00,  1.3029e+00,  3.6310e-01,
         4.6637e-02,  1.1756e+00, -9.6851e-02, -2.5165e-02, -5.2396e-01,
         4.8737e+00], device='cuda:1')
Solve time for step 1 11.18142059497768
Current ori: tensor([-0.0969, -0.0252, -0.5240], device='cuda:1')
Middle force: tensor([0.5057, 0.5237, 0.5011, 0.5166], device='cuda:1')
Thumb force: tensor([0.5648, 0.5538, 0.5260, 0.6033], device='cuda:1')
tensor([ 0.0411,  0.4357,  0.5603,  0.6145, -0.1050,  0.6430,  0.8593,  1.0774,
         1.2796,  0.4208,  0.1028,  1.0968, -0.1120, -0.0187, -0.5501,  4.7382],
       device='cuda:1')
Solve time for step 2 4.796375403006095
Current ori: tensor([-0.1120, -0.0187, -0.5501], device='cuda:1')
Middle force: tensor([0.5734, 0.5429, 0.5619], device='cuda:1')
Thumb force: tensor([0.5552, 0.5832, 0.6046], device='cuda:1')
tensor([ 0.0487,  0.4518,  0.5535,  0.6053, -0.1193,  0.6564,  0.8490,  1.0665,
         1.2907,  0.4177,  0.1218,  1.0609, -0.1343, -0.0053, -0.5449,  4.1136],
       device='cuda:1')
Solve time for step 3 4.525843668030575
Current ori: tensor([-0.1343, -0.0053, -0.5449], device='cuda:1')
Middle force: tensor([0.5403, 0.5570], device='cuda:1')
Thumb force: tensor([0.5760, 0.5984], device='cuda:1')
tensor([ 0.0408,  0.4507,  0.5554,  0.6106, -0.1261,  0.6636,  0.8286,  1.0746,
         1.2982,  0.4149,  0.1275,  1.0616, -0.1475,  0.0054, -0.5704,  3.0960],
       device='cuda:1')
Solve time for step 4 4.562064872996416
Current ori: tensor([-0.1475,  0.0054, -0.5704], device='cuda:1')
Middle force: tensor([0.5507], device='cuda:1')
Thumb force: tensor([0.5897], device='cuda:1')
Storing RECOVERY transition: reward=0.0372 (scaled=0.0186), steps=2
Reward stats updated: mean 0.0108 -> 0.0109, std: 0.1545
Collected 86 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4217, Q2 Loss=0.4217, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0749
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5015, Q2 Loss=0.5015, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1212
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4638, Q2 Loss=0.4638, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1147
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5384, Q2 Loss=0.5384, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0928
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8732, Q2 Loss=0.8732, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7522

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.7%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.5%)
Actor update: 0.13s (37.6%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.559719
Q2 loss: 0.559719
Current threshold: -150.0324
Global Scale Offset: 0.9663
Reward stats: mean=0.0109, std=0.1545, count=86
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.5597, Q2 Loss: 0.5597, Entropy: 0.0000, Mean TD Error: 0.2312, Threshold: -150.0324
Original likelihood: -173.6112060546875
Adjusted likelihood: -173.6112060546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-57.9388, -58.2908, -64.7314, -64.9434, -67.9837, -72.3547, -78.4541,
        -79.5359, -79.5525, -79.6149, -81.7883, -87.1854, -88.9417, -89.6452,
        -89.6780, -93.0941], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-57.9388, -58.2908, -64.7314, -64.9434, -67.9837, -72.3547, -78.4541,
        -79.5359, -79.5525, -79.6149, -81.7883, -87.1854, -88.9417, -89.6452,
        -89.6780, -93.0941], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -77.1083
1 mode projection succeeded
New goal: tensor([ 0.0537,  0.5237,  0.5620,  0.6521, -0.0383,  0.5283,  0.7661,  0.9937,
         1.3278,  0.2949,  0.1729,  1.0314, -0.0806,  0.0090, -2.4076],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -168.556640625
Adjusted likelihood: -168.556640625
Likelihood residual: 0.0
Original likelihood: -175.5435028076172
Adjusted likelihood: -175.5435028076172
Likelihood residual: 0.0
{'index': 175.5435028076172, 'thumb_middle': 168.556640625}
Current yaw: tensor([-0.1635,  0.0076, -0.5854], device='cuda:1')
9 thumb_middle
tensor([ 0.0066,  0.5241,  0.6033,  0.6255, -0.1208,  0.6731,  0.8356,  1.0711,
         1.2911,  0.4314,  0.1148,  1.0999, -0.1635,  0.0076, -0.5854,  2.5800],
       device='cuda:1')
Solve time for step 1 10.01606700901175
Current ori: tensor([-0.1635,  0.0076, -0.5854], device='cuda:1')
Index force: tensor([0.5843, 0.5855, 0.5863, 0.5653], device='cuda:1')
tensor([-0.0249,  0.5758,  0.6256,  0.6525, -0.1236,  0.5553,  0.7634,  1.0006,
         1.2695,  0.2912,  0.1077,  1.0311, -0.3956,  0.0142, -0.5854,  1.7309],
       device='cuda:1')
Solve time for step 2 3.9792726039886475
Current ori: tensor([-0.3956,  0.0142, -0.5854], device='cuda:1')
Index force: tensor([0.5605, 0.5659, 0.5503], device='cuda:1')
tensor([-0.1011,  0.6984,  0.6325,  0.6575, -0.1029,  0.5897,  0.7654,  0.9872,
         1.3047,  0.2809,  0.1458,  1.0330, -0.9446,  0.0300, -0.5854,  2.3674],
       device='cuda:1')
Solve time for step 3 3.722084643028211
Current ori: tensor([-0.9446,  0.0300, -0.5854], device='cuda:1')
Index force: tensor([0.5015, 0.5199], device='cuda:1')
tensor([-0.3571,  0.9843,  0.8580,  0.8893, -0.1626,  0.6448,  0.7966,  0.9688,
         1.2720,  0.2543,  0.1161,  1.0358, -1.7626,  0.0365, -0.5854,  2.5989],
       device='cuda:1')
Solve time for step 4 3.7931403929833323
Current ori: tensor([-1.7626,  0.0365, -0.5854], device='cuda:1')
Index force: tensor([0.5337], device='cuda:1')
Storing RECOVERY transition: reward=-1.6788 (scaled=-0.8394), steps=2
Reward stats updated: mean 0.0109 -> 0.0011, std: 0.1783
Collected 87 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4361, Q2 Loss=0.4361, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4298
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4805, Q2 Loss=0.4805, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0177
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4501, Q2 Loss=0.4501, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0575
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4410, Q2 Loss=0.4410, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0210
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5323, Q2 Loss=0.5323, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0345

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.4%)
Q1 update: 0.08s (20.0%)
Q2 update: 0.07s (18.5%)
Actor update: 0.14s (38.1%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.467991
Q2 loss: 0.467991
Current threshold: -150.0326
Global Scale Offset: 0.9697
Reward stats: mean=0.0011, std=0.1783, count=87
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4680, Q2 Loss: 0.4680, Entropy: 0.0000, Mean TD Error: 0.1121, Threshold: -150.0326
Original likelihood: -2596.296142578125
Adjusted likelihood: -2596.296142578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 6
Loaded trajectory sampler
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
1 turn
Sampling time 5.052159769984428
tensor([ 1.5245e-01,  5.9836e-01,  5.7452e-01,  6.3051e-01, -8.8809e-02,
         5.3144e-01,  8.5012e-01,  9.3939e-01,  1.2482e+00,  3.0086e-01,
         2.3729e-01,  1.1482e+00,  5.5207e-05,  1.3631e-02, -4.8130e-02,
         4.4650e-01], device='cuda:1')
Original likelihood: -113.56716918945312
Adjusted likelihood: -113.56716918945312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.980864497018047
Current ori: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Middle force: tensor([0.5851, 0.5720, 1.1685, 0.5660, 1.1154, 0.6374, 0.5376, 0.5293, 0.5139,
        0.8312, 0.5607, 0.4944], device='cuda:1')
Thumb force: tensor([0.9019, 0.8748, 0.7794, 1.0494, 1.0432, 0.6631, 0.5323, 0.9244, 0.5400,
        0.5483, 0.5351, 0.5465], device='cuda:1')
Index force: tensor([0.6045, 0.6089, 0.5646, 0.5760, 0.8223, 0.5277, 1.0148, 0.9436, 0.5767,
        0.5876, 0.5952, 0.7388], device='cuda:1')
Storing NORMAL transition: reward=-0.0496 (scaled=-0.0496), steps=1
Reward stats updated: mean 0.0011 -> 0.0005, std: 0.1774
Collected 88 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4718, Q2 Loss=0.4718, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6488
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5451, Q2 Loss=0.5451, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4597
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5430, Q2 Loss=0.5430, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4597
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.3834, Q2 Loss=0.3834, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0740
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5106, Q2 Loss=0.5106, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0167

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (19.7%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.490763
Q2 loss: 0.490763
Current threshold: -150.0327
Global Scale Offset: 0.9718
Reward stats: mean=0.0005, std=0.1774, count=88
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.4908, Q2 Loss: 0.4908, Entropy: 0.0000, Mean TD Error: 0.3318, Threshold: -150.0327
tensor([ 1.2547e-01,  5.7165e-01,  5.4525e-01,  7.0528e-01, -1.1907e-01,
         6.6109e-01,  6.7899e-01,  9.1861e-01,  1.3076e+00,  2.3466e-01,
         1.9389e-01,  1.1871e+00, -1.7886e-02,  1.9169e-02,  1.0471e-03,
         1.4421e+00], device='cuda:1')
Original likelihood: -160.85911560058594
Adjusted likelihood: -160.85911560058594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.6589, -3.1656, -3.6943, -4.4576, -4.5969, -4.7310, -5.0340, -5.2778,
        -5.4645, -5.6011, -5.8532, -5.8986, -6.2614, -6.6437, -7.0423, -8.0722],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.6589, -3.1656, -3.6943, -4.4576, -4.5969, -4.7310, -5.0340, -5.2778,
        -5.4645, -5.6011, -5.8532, -5.8986, -6.2614, -6.6437, -7.0423, -8.0722],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2783
1 mode projection succeeded
New goal: tensor([ 4.0749e-02,  5.4899e-01,  5.4146e-01,  6.1421e-01, -4.2717e-02,
         5.1164e-01,  8.1619e-01,  8.3793e-01,  1.2962e+00,  2.8304e-01,
         1.8119e-01,  1.1824e+00, -1.1951e-03,  1.2707e-02,  1.9553e+00],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -113.9830322265625
Adjusted likelihood: -113.9830322265625
Likelihood residual: 0.0
Original likelihood: -81.04508972167969
Adjusted likelihood: -81.04508972167969
Likelihood residual: 0.0
{'index': 81.04508972167969, 'thumb_middle': 113.9830322265625}
Current yaw: tensor([-0.0179,  0.0192,  0.0010], device='cuda:1')
2 index
tensor([ 1.2547e-01,  5.7165e-01,  5.4525e-01,  7.0528e-01, -1.1907e-01,
         6.6109e-01,  6.7899e-01,  9.1861e-01,  1.3076e+00,  2.3466e-01,
         1.9389e-01,  1.1871e+00, -1.7886e-02,  1.9169e-02,  1.0471e-03,
         1.4421e+00], device='cuda:1')
Solve time for step 1 11.78387120203115
Current ori: tensor([-0.0179,  0.0192,  0.0010], device='cuda:1')
Middle force: tensor([0.6247, 0.5580, 0.5459, 0.5349], device='cuda:1')
Thumb force: tensor([0.5429, 0.5657, 0.5665, 0.5420], device='cuda:1')
tensor([ 0.1000,  0.4963,  0.4935,  0.6062, -0.1174,  0.5850,  0.8185,  0.8644,
         1.2937,  0.2504,  0.1967,  1.2006, -0.0048,  0.0157, -0.0488,  1.7321],
       device='cuda:1')
Solve time for step 2 4.771840161993168
Current ori: tensor([-0.0048,  0.0157, -0.0488], device='cuda:1')
Middle force: tensor([0.5547, 0.5430, 0.5319], device='cuda:1')
Thumb force: tensor([0.5589, 0.5621, 0.5391], device='cuda:1')
tensor([ 0.0929,  0.4951,  0.4903,  0.5925, -0.1086,  0.5884,  0.8318,  0.8371,
         1.2888,  0.2538,  0.1877,  1.2031, -0.0087,  0.0100, -0.0481,  1.8151],
       device='cuda:1')
Solve time for step 3 4.622442361025605
Current ori: tensor([-0.0087,  0.0100, -0.0481], device='cuda:1')
Middle force: tensor([0.5293, 0.5002], device='cuda:1')
Thumb force: tensor([0.5432, 0.5655], device='cuda:1')
tensor([ 0.0904,  0.4924,  0.4914,  0.5883, -0.1100,  0.5925,  0.8290,  0.8266,
         1.3292,  0.1976,  0.1669,  1.2007, -0.0126,  0.0113, -0.0522,  1.8202],
       device='cuda:1')
Solve time for step 4 4.563157613039948
Current ori: tensor([-0.0126,  0.0113, -0.0522], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5572], device='cuda:1')
Storing RECOVERY transition: reward=0.0664 (scaled=0.0664), steps=1
Reward stats updated: mean 0.0005 -> 0.0013, std: 0.1765
Collected 89 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4240, Q2 Loss=0.4240, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0466
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.3933, Q2 Loss=0.3933, Entropy=0.0185, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1018
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3875, Q2 Loss=0.3875, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4215
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4721, Q2 Loss=0.4721, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1082
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7220, Q2 Loss=0.7220, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7001

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.1%)
Q1 update: 0.08s (19.4%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000012
Q1 loss: 0.479789
Q2 loss: 0.479789
Current threshold: -150.0324
Global Scale Offset: 0.9760
Reward stats: mean=0.0013, std=0.1765, count=89
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4798, Q2 Loss: 0.4798, Entropy: 0.0037, Mean TD Error: 0.2756, Threshold: -150.0324
Original likelihood: -74.73019409179688
Adjusted likelihood: -74.73019409179688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0081,  0.0126, -0.0650], device='cuda:1')
3 turn
Sampling time 5.053963238024153
tensor([ 0.0383,  0.5529,  0.5350,  0.6116, -0.1127,  0.5802,  0.8393,  0.8407,
         1.2776,  0.2780,  0.1927,  1.2088, -0.0081,  0.0126, -0.0650,  1.8240],
       device='cuda:1')
Original likelihood: -75.80339050292969
Adjusted likelihood: -75.80339050292969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.906374515965581
Current ori: tensor([-0.0081,  0.0126, -0.0650], device='cuda:1')
Middle force: tensor([0.8866, 2.2567, 0.5694, 1.4022, 0.6807, 0.9632, 0.5605, 0.8339, 0.5116,
        0.6426, 0.5637, 0.7637], device='cuda:1')
Thumb force: tensor([0.6634, 1.1143, 1.6164, 0.5412, 0.5453, 0.6799, 0.5158, 0.6236, 1.2326,
        0.6629, 0.6453, 0.5586], device='cuda:1')
Index force: tensor([0.6253, 1.7208, 0.6438, 0.7136, 0.7530, 0.7438, 0.6565, 0.7871, 0.5993,
        0.7490, 0.6099, 0.5496], device='cuda:1')
Storing NORMAL transition: reward=-0.0232 (scaled=-0.0232), steps=1
Reward stats updated: mean 0.0013 -> 0.0010, std: 0.1756
Collected 90 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3765, Q2 Loss=0.3765, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0750
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4190, Q2 Loss=0.4190, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0769
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4150, Q2 Loss=0.4150, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1302
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.2855, Q2 Loss=0.2855, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0339
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7126, Q2 Loss=0.7126, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6982

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.9%)
Q1 update: 0.08s (19.1%)
Q2 update: 0.07s (18.6%)
Actor update: 0.16s (39.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.441714
Q2 loss: 0.441714
Current threshold: -150.0321
Global Scale Offset: 0.9791
Reward stats: mean=0.0010, std=0.1756, count=90
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.4417, Q2 Loss: 0.4417, Entropy: 0.0000, Mean TD Error: 0.2029, Threshold: -150.0321
tensor([ 0.0233,  0.4842,  0.5816,  0.6816, -0.1507,  0.5876,  0.8238,  0.8276,
         1.3364,  0.1872,  0.2491,  1.1183, -0.0050,  0.0340, -0.0427,  1.5852],
       device='cuda:1')
Original likelihood: -127.59051513671875
Adjusted likelihood: -127.59051513671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.26232965500094
Current ori: tensor([-0.0050,  0.0340, -0.0427], device='cuda:1')
Middle force: tensor([1.6228, 2.0989, 0.5554, 0.7685, 0.6087, 0.5258, 0.7418, 0.6029, 0.5657,
        0.5261, 0.5888], device='cuda:1')
Thumb force: tensor([1.4382, 0.7281, 0.5929, 0.5175, 1.1372, 1.2825, 1.5595, 0.5052, 0.5232,
        0.6195, 0.5973], device='cuda:1')
Index force: tensor([0.7837, 0.5824, 0.6265, 0.5324, 0.9202, 0.5223, 0.5586, 0.6040, 0.5889,
        0.6257, 0.5903], device='cuda:1')
Storing NORMAL transition: reward=0.2172 (scaled=0.2172), steps=1
Reward stats updated: mean 0.0010 -> 0.0034, std: 0.1760
Collected 91 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4030, Q2 Loss=0.4030, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2140
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3572, Q2 Loss=0.3572, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0773
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4714, Q2 Loss=0.4714, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6519
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8435, Q2 Loss=0.8435, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7405
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5567, Q2 Loss=0.5567, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6640

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (20.0%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.0%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.526356
Q2 loss: 0.526356
Current threshold: -150.0320
Global Scale Offset: 0.9809
Reward stats: mean=0.0034, std=0.1760, count=91
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.5264, Q2 Loss: 0.5264, Entropy: 0.0000, Mean TD Error: 0.4695, Threshold: -150.0320
tensor([ 0.0457,  0.4723,  0.5985,  0.7197, -0.1360,  0.5289,  0.8765,  0.9361,
         1.3575,  0.1672,  0.2470,  1.0287, -0.0039,  0.0231, -0.2596,  1.7662],
       device='cuda:1')
Original likelihood: -105.93875122070312
Adjusted likelihood: -105.93875122070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.9504199479706585
Current ori: tensor([-0.0039,  0.0231, -0.2596], device='cuda:1')
Middle force: tensor([1.9155, 0.5472, 0.7546, 0.5916, 0.5220, 0.7070, 0.5189, 0.5688, 0.5834,
        0.5154], device='cuda:1')
Thumb force: tensor([0.6772, 0.5799, 0.5099, 1.0475, 1.2015, 1.4223, 0.5594, 0.5950, 0.5933,
        0.5648], device='cuda:1')
Index force: tensor([0.5596, 0.6148, 0.5308, 0.8803, 0.5152, 0.5507, 0.5473, 0.6173, 0.5895,
        0.6275], device='cuda:1')
Storing NORMAL transition: reward=0.0589 (scaled=0.0589), steps=1
Reward stats updated: mean 0.0034 -> 0.0040, std: 0.1752
Collected 92 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4696, Q2 Loss=0.4696, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0691
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2939, Q2 Loss=0.2939, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0473
SAC Update 3/5: Actor Loss=-0.0032, Q1 Loss=0.3478, Q2 Loss=0.3478, Entropy=0.3457, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0392
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4167, Q2 Loss=0.4167, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0627
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3036, Q2 Loss=0.3036, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0475

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.6%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.5%)
Actor update: 0.15s (38.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000632
Q1 loss: 0.366337
Q2 loss: 0.366337
Current threshold: -150.0248
Global Scale Offset: 0.9837
Reward stats: mean=0.0040, std=0.1752, count=92
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 0.3663, Q2 Loss: 0.3663, Entropy: 0.0691, Mean TD Error: 0.0532, Threshold: -150.0248
tensor([ 0.0706,  0.4215,  0.6518,  0.7923, -0.2556,  0.5546,  0.9947,  0.8321,
         1.3605,  0.2432,  0.2856,  0.9687,  0.0065,  0.0518, -0.3227,  1.4441],
       device='cuda:1')
Original likelihood: -259.89715576171875
Adjusted likelihood: -259.89715576171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.0480, -3.6745, -3.9041, -4.0843, -4.2475, -4.2737, -4.3887, -4.9685,
        -5.2639, -5.4117, -5.5414, -5.5441, -5.5747, -6.1823, -7.1217, -8.4747],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.0480, -3.6745, -3.9041, -4.0843, -4.2475, -4.2737, -4.3887, -4.9685,
        -5.2639, -5.4117, -5.5414, -5.5441, -5.5747, -6.1823, -7.1217, -8.4747],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.1065
1 mode projection succeeded
New goal: tensor([ 0.0763,  0.5115,  0.5961,  0.6756, -0.0658,  0.4561,  0.9281,  0.8355,
         1.2642,  0.3281,  0.2223,  1.1541,  0.0039,  0.0139,  2.1473],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -111.08543395996094
Adjusted likelihood: -111.08543395996094
Likelihood residual: 0.0
Original likelihood: -146.4117431640625
Adjusted likelihood: -146.4117431640625
Likelihood residual: 0.0
{'index': 146.4117431640625, 'thumb_middle': 111.08543395996094}
Current yaw: tensor([ 0.0065,  0.0518, -0.3227], device='cuda:1')
4 thumb_middle
tensor([ 0.0706,  0.4215,  0.6518,  0.7923, -0.2556,  0.5546,  0.9947,  0.8321,
         1.3605,  0.2432,  0.2856,  0.9687,  0.0065,  0.0518, -0.3227,  1.4441],
       device='cuda:1')
Solve time for step 1 9.67027625296032
Current ori: tensor([ 0.0065,  0.0518, -0.3227], device='cuda:1')
Index force: tensor([0.6038, 0.5079, 0.6269, 0.6034], device='cuda:1')
tensor([ 0.0754,  0.4506,  0.6236,  0.7800, -0.2262,  0.4613,  0.9105,  0.8093,
         1.2484,  0.2967,  0.1855,  1.0974, -0.0018,  0.0488, -0.3227,  1.4429],
       device='cuda:1')
Solve time for step 2 3.8346477809827775
Current ori: tensor([-0.0018,  0.0488, -0.3227], device='cuda:1')
Index force: tensor([0.5046, 0.6165, 0.5911], device='cuda:1')
tensor([ 0.0741,  0.4490,  0.6325,  0.7624, -0.2176,  0.4474,  0.8915,  0.8064,
         1.2519,  0.3112,  0.1664,  1.1186, -0.0030,  0.0497, -0.3227,  1.4376],
       device='cuda:1')
Solve time for step 3 3.699507113022264
Current ori: tensor([-0.0030,  0.0497, -0.3227], device='cuda:1')
Index force: tensor([0.6054, 0.5812], device='cuda:1')
tensor([ 0.0784,  0.4779,  0.6161,  0.7251, -0.2019,  0.4354,  0.8801,  0.7973,
         1.2449,  0.3103,  0.1539,  1.1340, -0.0134,  0.0469, -0.3227,  1.4316],
       device='cuda:1')
Solve time for step 4 3.5589616610086523
Current ori: tensor([-0.0134,  0.0469, -0.3227], device='cuda:1')
Index force: tensor([0.5721], device='cuda:1')
Storing RECOVERY transition: reward=0.0161 (scaled=0.0054), steps=3
Reward stats updated: mean 0.0040 -> 0.0040, std: 0.1742
Collected 93 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4428, Q2 Loss=0.4428, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0893
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5361, Q2 Loss=0.5361, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6620
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6321, Q2 Loss=0.6321, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6802
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5315, Q2 Loss=0.5315, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4752
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7098, Q2 Loss=0.7098, Entropy=0.0004, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6994

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.09s (22.0%)
Q1 update: 0.07s (18.3%)
Q2 update: 0.07s (17.8%)
Actor update: 0.15s (38.4%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.570463
Q2 loss: 0.570463
Current threshold: -150.0168
Global Scale Offset: 0.9862
Reward stats: mean=0.0040, std=0.1742, count=93
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.5705, Q2 Loss: 0.5705, Entropy: 0.0001, Mean TD Error: 0.5212, Threshold: -150.0168
Original likelihood: -115.41929626464844
Adjusted likelihood: -115.41929626464844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0206,  0.0344, -0.3369], device='cuda:1')
5 turn
Sampling time 5.0393382260226645
tensor([ 0.0982,  0.4959,  0.6294,  0.6870, -0.1227,  0.4802,  0.9317,  0.8275,
         1.2793,  0.3561,  0.2072,  1.1656, -0.0206,  0.0344, -0.3369,  1.4393],
       device='cuda:1')
Original likelihood: -122.36273193359375
Adjusted likelihood: -122.36273193359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.329780198051594
Current ori: tensor([-0.0206,  0.0344, -0.3369], device='cuda:1')
Middle force: tensor([0.5407, 0.6417, 0.5098, 2.2544, 1.2019, 0.5068, 0.6491, 0.5697, 0.5235,
        0.5124, 0.5591, 0.7724], device='cuda:1')
Thumb force: tensor([0.5830, 0.7639, 1.3747, 1.7347, 1.2236, 0.5850, 0.9405, 0.6148, 0.6055,
        0.5410, 0.5664, 0.5561], device='cuda:1')
Index force: tensor([0.5997, 0.5347, 0.5780, 1.1847, 0.5220, 0.5506, 0.9594, 0.5837, 0.5376,
        0.5695, 0.6138, 0.5506], device='cuda:1')
Storing NORMAL transition: reward=0.0722 (scaled=0.0722), steps=1
Reward stats updated: mean 0.0040 -> 0.0047, std: 0.1734
Collected 94 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5556, Q2 Loss=0.5556, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4868
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4061, Q2 Loss=0.4061, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0912
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3776, Q2 Loss=0.3776, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0379
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.3982, Q2 Loss=0.3982, Entropy=0.0203, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1207
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3630, Q2 Loss=0.3630, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0985

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.3%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (19.5%)
Actor update: 0.13s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000011
Q1 loss: 0.420108
Q2 loss: 0.420108
Current threshold: -150.0118
Global Scale Offset: 0.9894
Reward stats: mean=0.0047, std=0.1734, count=94
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4201, Q2 Loss: 0.4201, Entropy: 0.0041, Mean TD Error: 0.1670, Threshold: -150.0118
tensor([ 0.1056,  0.5021,  0.6499,  0.6434, -0.1218,  0.4891,  0.9007,  0.8921,
         1.3234,  0.3184,  0.1905,  1.1051, -0.0255,  0.0308, -0.4094,  1.5124],
       device='cuda:1')
Original likelihood: -115.81832885742188
Adjusted likelihood: -115.81832885742188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.791297363000922
Current ori: tensor([-0.0255,  0.0308, -0.4094], device='cuda:1')
Middle force: tensor([0.6392, 0.5093, 2.2167, 1.1919, 0.5061, 0.6520, 0.5690, 0.5225, 0.5122,
        0.5569, 0.7651], device='cuda:1')
Thumb force: tensor([0.7502, 1.3566, 1.6888, 1.2032, 0.5816, 0.9201, 0.6078, 0.5989, 0.5391,
        0.5628, 0.5547], device='cuda:1')
Index force: tensor([0.5327, 0.5745, 1.1750, 0.5220, 0.5504, 0.9483, 0.5815, 0.5372, 0.5674,
        0.6120, 0.5485], device='cuda:1')
Storing NORMAL transition: reward=0.1159 (scaled=0.1159), steps=1
Reward stats updated: mean 0.0047 -> 0.0059, std: 0.1729
Collected 95 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2665, Q2 Loss=0.2665, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0616
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6558, Q2 Loss=0.6558, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6868
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3026, Q2 Loss=0.3026, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1294
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5496, Q2 Loss=0.5496, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4891
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6019, Q2 Loss=0.6019, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5134

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.2%)
Q1 update: 0.07s (18.3%)
Q2 update: 0.07s (19.0%)
Actor update: 0.14s (37.3%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.475259
Q2 loss: 0.475259
Current threshold: -150.0086
Global Scale Offset: 0.9932
Reward stats: mean=0.0059, std=0.1729, count=95
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.4753, Q2 Loss: 0.4753, Entropy: 0.0000, Mean TD Error: 0.3761, Threshold: -150.0086
tensor([ 0.0978,  0.4967,  0.6575,  0.6267, -0.1249,  0.4750,  0.8989,  0.9353,
         1.3389,  0.3119,  0.2096,  1.0239, -0.0288,  0.0338, -0.5264,  1.7166],
       device='cuda:1')
Original likelihood: -114.40137481689453
Adjusted likelihood: -114.40137481689453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.595223067968618
Current ori: tensor([-0.0288,  0.0338, -0.5264], device='cuda:1')
Middle force: tensor([0.5084, 2.1784, 1.1772, 0.5056, 0.6520, 0.5688, 0.5217, 0.5121, 0.5554,
        0.7587], device='cuda:1')
Thumb force: tensor([1.3367, 1.6441, 1.1831, 0.5756, 0.9042, 0.5988, 0.5912, 0.5350, 0.5586,
        0.5523], device='cuda:1')
Index force: tensor([0.5699, 1.1612, 0.5213, 0.5495, 0.9361, 0.5797, 0.5367, 0.5672, 0.6102,
        0.5472], device='cuda:1')
Storing NORMAL transition: reward=-0.0020 (scaled=-0.0020), steps=1
Reward stats updated: mean 0.0059 -> 0.0058, std: 0.1720
Collected 96 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3104, Q2 Loss=0.3104, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0964
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3821, Q2 Loss=0.3821, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0743
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3956, Q2 Loss=0.3956, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6484
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.2203, Q2 Loss=0.2203, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0040
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3145, Q2 Loss=0.3145, Entropy=0.0151, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0180

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (18.1%)
Actor update: 0.13s (37.6%)
Target update: 0.01s (1.9%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000006
Q1 loss: 0.324593
Q2 loss: 0.324593
Current threshold: -150.0066
Global Scale Offset: 0.9961
Reward stats: mean=0.0058, std=0.1720, count=96
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.3246, Q2 Loss: 0.3246, Entropy: 0.0030, Mean TD Error: 0.1682, Threshold: -150.0066
tensor([ 0.0657,  0.4907,  0.5970,  0.7072, -0.1567,  0.4339,  0.9274,  0.8486,
         1.3261,  0.2457,  0.2536,  1.0178, -0.0185,  0.0545, -0.5264,  1.6555],
       device='cuda:1')
Original likelihood: -172.90359497070312
Adjusted likelihood: -172.90359497070312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.8568, -3.0429, -3.2033, -3.7843, -4.1235, -4.1865, -4.1880, -4.2150,
        -4.2233, -4.3197, -4.3212, -4.6305, -5.0402, -7.1017, -7.1411, -7.3226],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8568, -3.0429, -3.2033, -3.7843, -4.1235, -4.1865, -4.1880, -4.2150,
        -4.2233, -4.3197, -4.3212, -4.6305, -5.0402, -7.1017, -7.1411, -7.3226],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.6063
1 mode projection succeeded
New goal: tensor([ 0.0538,  0.6054,  0.5084,  0.5522, -0.0706,  0.5099,  0.8377,  0.9067,
         1.2506,  0.2753,  0.2384,  1.1954, -0.0013,  0.0132,  0.1904],
       device='cuda:1')
tensor([[0.0058]], device='cuda:1') tensor([[0.0042]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -134.7877960205078
Adjusted likelihood: -134.7877960205078
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 134.7877960205078}
Current yaw: tensor([-0.0185,  0.0545, -0.5264], device='cuda:1')
6 thumb_middle
tensor([ 0.0657,  0.4907,  0.5970,  0.7072, -0.1567,  0.4339,  0.9274,  0.8486,
         1.3261,  0.2457,  0.2536,  1.0178, -0.0185,  0.0545, -0.5264,  1.6555],
       device='cuda:1')
Solve time for step 1 9.953771828033496
Current ori: tensor([-0.0185,  0.0545, -0.5264], device='cuda:1')
Index force: tensor([0.6352, 0.6254, 0.6029, 0.5915], device='cuda:1')
tensor([ 0.0693,  0.5245,  0.5739,  0.6649, -0.2107,  0.4751,  0.8108,  0.8652,
         1.2333,  0.2524,  0.1994,  1.1638, -0.0303,  0.0528, -0.5264,  1.6307],
       device='cuda:1')
Solve time for step 2 3.8536752419895492
Current ori: tensor([-0.0303,  0.0528, -0.5264], device='cuda:1')
Index force: tensor([0.6166, 0.5925, 0.5798], device='cuda:1')
tensor([ 0.0654,  0.5605,  0.5514,  0.6044, -0.2077,  0.4725,  0.8087,  0.8739,
         1.2194,  0.2494,  0.2133,  1.1949, -0.0425,  0.0560, -0.5264,  1.5918],
       device='cuda:1')
Solve time for step 3 3.8355801180005074
Current ori: tensor([-0.0425,  0.0560, -0.5264], device='cuda:1')
Index force: tensor([0.5777, 0.5543], device='cuda:1')
tensor([ 0.0720,  0.5843,  0.5376,  0.5793, -0.2067,  0.4821,  0.8012,  0.8699,
         1.2184,  0.2540,  0.2052,  1.2007, -0.0501,  0.0513, -0.5264,  1.5948],
       device='cuda:1')
Solve time for step 4 3.6643564559635706
Current ori: tensor([-0.0501,  0.0513, -0.5264], device='cuda:1')
Index force: tensor([0.5403], device='cuda:1')
Storing RECOVERY transition: reward=0.0047 (scaled=0.0016), steps=3
Reward stats updated: mean 0.0058 -> 0.0058, std: 0.1711
Collected 97 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3786, Q2 Loss=0.3786, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6475
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.2792, Q2 Loss=0.2792, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0805
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.2683, Q2 Loss=0.2683, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0750
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4029, Q2 Loss=0.4029, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6498
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.2491, Q2 Loss=0.2491, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0522

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.8%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (18.5%)
Actor update: 0.12s (38.7%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.315632
Q2 loss: 0.315632
Current threshold: -150.0051
Global Scale Offset: 0.9995
Reward stats: mean=0.0058, std=0.1711, count=97
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.3156, Q2 Loss: 0.3156, Entropy: 0.0000, Mean TD Error: 0.3010, Threshold: -150.0051
Original likelihood: -142.354736328125
Adjusted likelihood: -142.354736328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0482,  0.0388, -0.5319], device='cuda:1')
7 turn
Sampling time 5.246048400003929
tensor([ 0.0908,  0.5788,  0.5517,  0.6025, -0.1353,  0.5358,  0.8405,  0.8986,
         1.2759,  0.2668,  0.2616,  1.2289, -0.0482,  0.0388, -0.5319,  1.6448],
       device='cuda:1')
Original likelihood: -160.58338928222656
Adjusted likelihood: -160.58338928222656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.2673, -3.5105, -3.9618, -3.9944, -4.3293, -5.3444, -5.5508, -5.8772,
        -6.1810, -6.1833, -6.2089, -6.4474, -6.5181, -8.2898, -9.0021, -9.3296],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2673, -3.5105, -3.9618, -3.9944, -4.3293, -5.3444, -5.5508, -5.8772,
        -6.1810, -6.1833, -6.2089, -6.4474, -6.5181, -8.2898, -9.0021, -9.3296],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.8747
1 mode projection succeeded
New goal: tensor([ 0.0489,  0.5832,  0.4977,  0.6192, -0.0320,  0.4817,  0.8937,  0.8282,
         1.3272,  0.3006,  0.1573,  1.0738, -0.0267,  0.0018,  0.1810],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -89.12227630615234
Adjusted likelihood: -89.12227630615234
Likelihood residual: 0.0
Original likelihood: -126.22299194335938
Adjusted likelihood: -126.22299194335938
Likelihood residual: 0.0
{'index': 126.22299194335938, 'thumb_middle': 89.12227630615234}
Current yaw: tensor([-0.0482,  0.0388, -0.5319], device='cuda:1')
8 thumb_middle
tensor([ 0.0908,  0.5788,  0.5517,  0.6025, -0.1353,  0.5358,  0.8405,  0.8986,
         1.2759,  0.2668,  0.2616,  1.2289, -0.0482,  0.0388, -0.5319,  1.6448],
       device='cuda:1')
Solve time for step 1 8.975193816993851
Current ori: tensor([-0.0482,  0.0388, -0.5319], device='cuda:1')
Index force: tensor([0.5702, 0.5987, 0.6036, 0.5865], device='cuda:1')
tensor([ 0.1021,  0.6000,  0.5217,  0.6258, -0.1679,  0.4658,  0.8430,  0.8176,
         1.2750,  0.2739,  0.1212,  1.0852, -0.0511,  0.0315, -0.5320,  1.6571],
       device='cuda:1')
Solve time for step 2 3.753467358998023
Current ori: tensor([-0.0511,  0.0315, -0.5320], device='cuda:1')
Index force: tensor([0.5921, 0.5978, 0.5818], device='cuda:1')
tensor([ 0.1031,  0.6043,  0.5143,  0.6304, -0.1650,  0.4638,  0.8489,  0.8053,
         1.2892,  0.2801,  0.1024,  1.0617, -0.0517,  0.0307, -0.5320,  1.6607],
       device='cuda:1')
Solve time for step 3 3.583337499992922
Current ori: tensor([-0.0517,  0.0307, -0.5320], device='cuda:1')
Index force: tensor([0.5336, 0.5432], device='cuda:1')
tensor([ 0.1166,  0.6176,  0.5075,  0.6348, -0.1572,  0.4584,  0.8746,  0.8031,
         1.2732,  0.2826,  0.0990,  1.0788, -0.0545,  0.0215, -0.5320,  1.6806],
       device='cuda:1')
Solve time for step 4 3.5440681220497936
Current ori: tensor([-0.0545,  0.0215, -0.5320], device='cuda:1')
Index force: tensor([0.5324], device='cuda:1')
Storing RECOVERY transition: reward=0.0084 (scaled=0.0084), steps=0
Reward stats updated: mean 0.0058 -> 0.0058, std: 0.1702
Collected 98 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3668, Q2 Loss=0.3668, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1288
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5160, Q2 Loss=0.5160, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6630
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5897, Q2 Loss=0.5897, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6750
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6173, Q2 Loss=0.6173, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6802
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5241, Q2 Loss=0.5241, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4868

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.0%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (18.1%)
Actor update: 0.13s (38.1%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.522768
Q2 loss: 0.522768
Current threshold: -150.0043
Global Scale Offset: 1.0016
Reward stats: mean=0.0058, std=0.1702, count=98
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.5228, Q2 Loss: 0.5228, Entropy: 0.0000, Mean TD Error: 0.5268, Threshold: -150.0043
Original likelihood: -92.44448852539062
Adjusted likelihood: -92.44448852539062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0516,  0.0223, -0.5397], device='cuda:1')
9 turn
Sampling time 5.334199044969864
tensor([ 0.1085,  0.6011,  0.5208,  0.6378, -0.0887,  0.5148,  0.8824,  0.8248,
         1.3536,  0.2880,  0.1491,  1.0749, -0.0516,  0.0223, -0.5397,  1.7529],
       device='cuda:1')
Original likelihood: -85.37350463867188
Adjusted likelihood: -85.37350463867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.016457284975331
Current ori: tensor([-0.0516,  0.0223, -0.5397], device='cuda:1')
Middle force: tensor([0.9256, 0.7478, 0.5206, 0.5885, 0.5948, 0.6554, 0.5781, 0.8386, 0.5434,
        0.5371, 0.8612, 0.5415], device='cuda:1')
Thumb force: tensor([0.5624, 0.8259, 0.7394, 0.5688, 0.5897, 1.2310, 0.5884, 1.0566, 0.5119,
        0.5613, 1.2646, 0.5923], device='cuda:1')
Index force: tensor([0.5935, 0.7710, 0.5884, 0.6083, 0.6006, 0.5128, 0.5836, 0.5404, 0.5742,
        0.6005, 0.9515, 0.5704], device='cuda:1')
Storing NORMAL transition: reward=0.1830 (scaled=0.1830), steps=1
Reward stats updated: mean 0.0058 -> 0.0076, std: 0.1703
Collected 99 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.2552, Q2 Loss=0.2552, Entropy=0.0217, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0812
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.2727, Q2 Loss=0.2727, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1282
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3271, Q2 Loss=0.3271, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0557
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4032, Q2 Loss=0.4032, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4460
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.2343, Q2 Loss=0.2343, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1429

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (22.2%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.6%)
Actor update: 0.13s (38.4%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000015
Q1 loss: 0.298509
Q2 loss: 0.298509
Current threshold: -150.0031
Global Scale Offset: 1.0078
Reward stats: mean=0.0076, std=0.1703, count=99
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.2985, Q2 Loss: 0.2985, Entropy: 0.0043, Mean TD Error: 0.1708, Threshold: -150.0031
tensor([ 0.0535,  0.5764,  0.5030,  0.6352, -0.1223,  0.4574,  0.8635,  0.9782,
         1.4277,  0.4190,  0.1057,  0.9704, -0.0459,  0.0491, -0.7263,  1.9403],
       device='cuda:1')
Original likelihood: -141.48573303222656
Adjusted likelihood: -141.48573303222656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.81487191299675
Current ori: tensor([-0.0459,  0.0491, -0.7263], device='cuda:1')
Middle force: tensor([0.7329, 0.5205, 0.5855, 0.5939, 0.6428, 0.5791, 0.8271, 0.5450, 0.5366,
        0.8599, 0.5418], device='cuda:1')
Thumb force: tensor([0.8208, 0.7290, 0.5656, 0.5846, 1.2375, 0.5820, 1.0443, 0.5106, 0.5587,
        1.2316, 0.5877], device='cuda:1')
Index force: tensor([0.7593, 0.5868, 0.6079, 0.5984, 0.5112, 0.5817, 0.5389, 0.5727, 0.5978,
        0.9426, 0.5687], device='cuda:1')
Storing NORMAL transition: reward=0.1367 (scaled=0.1367), steps=1
Reward stats updated: mean 0.0076 -> 0.0089, std: 0.1699
Collected 100 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=12.5550, Q2 Loss=12.5550, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9388
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8057, Q2 Loss=0.8057, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5474
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=7.1287, Q2 Loss=7.1287, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0417
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4055, Q2 Loss=0.4055, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2705
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4990, Q2 Loss=0.4990, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3967

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (18.9%)
Q1 update: 0.07s (20.1%)
Q2 update: 0.07s (19.0%)
Actor update: 0.14s (38.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 4.278773
Q2 loss: 4.278773
Current threshold: -150.0024
Global Scale Offset: 1.0115
Reward stats: mean=0.0089, std=0.1699, count=100
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 4.2788, Q2 Loss: 4.2788, Entropy: 0.0000, Mean TD Error: 1.8390, Threshold: -150.0024
tensor([ 1.2816e-01,  6.3767e-01,  4.7929e-01,  6.6162e-01, -5.1476e-02,
         5.5112e-01,  7.6452e-01,  1.0668e+00,  1.4680e+00,  3.3560e-01,
         5.7579e-02,  8.8429e-01, -5.8852e-02,  6.2476e-04, -8.6493e-01,
         2.1928e+00], device='cuda:1')
Original likelihood: -116.61201477050781
Adjusted likelihood: -116.61201477050781
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.800294182961807
Current ori: tensor([-5.8852e-02,  6.2476e-04, -8.6493e-01], device='cuda:1')
Middle force: tensor([0.5998, 0.5632, 0.8082, 0.5577, 0.9369, 0.5427, 0.5332, 0.5694, 0.6714,
        0.6751], device='cuda:1')
Thumb force: tensor([0.6019, 1.1619, 0.5647, 0.7280, 0.5647, 0.5116, 0.8435, 0.5966, 0.5649,
        0.6923], device='cuda:1')
Index force: tensor([0.8497, 0.7742, 0.6564, 0.6006, 0.5032, 0.5906, 0.5408, 0.5863, 0.5927,
        0.5379], device='cuda:1')
Storing NORMAL transition: reward=-0.0124 (scaled=-0.0124), steps=1
Reward stats updated: mean 0.0089 -> 0.0087, std: 0.1691
Collected 101 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=36.9701, Q2 Loss=36.9701, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.3581
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3286, Q2 Loss=0.3286, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2388
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.1584, Q2 Loss=2.1584, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5416
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=54.2511, Q2 Loss=54.2511, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.3581
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6640, Q2 Loss=0.6640, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4246

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.1%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (17.3%)
Actor update: 0.14s (38.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 18.874445
Q2 loss: 18.874445
Current threshold: -150.0020
Global Scale Offset: 1.0138
Reward stats: mean=0.0087, std=0.1691, count=101
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 18.8744, Q2 Loss: 18.8744, Entropy: 0.0000, Mean TD Error: 3.1842, Threshold: -150.0020
tensor([ 0.1323,  0.5654,  0.5614,  0.7034, -0.0534,  0.5159,  0.8323,  1.0225,
         1.4627,  0.3355,  0.0284,  0.9652, -0.0393, -0.0043, -0.8476,  2.2709],
       device='cuda:1')
Original likelihood: -111.62928009033203
Adjusted likelihood: -111.62928009033203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.265327107044868
Current ori: tensor([-0.0393, -0.0043, -0.8476], device='cuda:1')
Middle force: tensor([0.5618, 0.7927, 0.5546, 0.9191, 0.5369, 0.5306, 0.5666, 0.6644, 0.6688],
       device='cuda:1')
Thumb force: tensor([1.1124, 0.5592, 0.7144, 0.5603, 0.5095, 0.8236, 0.5898, 0.5586, 0.6815],
       device='cuda:1')
Index force: tensor([0.7518, 0.6491, 0.5953, 0.5027, 0.5844, 0.5375, 0.5807, 0.5880, 0.5345],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0419 (scaled=-0.0419), steps=1
Reward stats updated: mean 0.0087 -> 0.0082, std: 0.1683
Collected 102 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6589, Q2 Loss=0.6589, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5409
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4075, Q2 Loss=0.4075, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3622
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.8528, Q2 Loss=1.8528, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5387
SAC Update 4/5: Actor Loss=-0.0062, Q1 Loss=0.5681, Q2 Loss=0.5681, Entropy=0.3460, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3329
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3070, Q2 Loss=0.3070, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3146

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.5%)
Q1 update: 0.06s (17.7%)
Q2 update: 0.06s (17.3%)
Actor update: 0.14s (39.0%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001246
Q1 loss: 0.758837
Q2 loss: 0.758837
Current threshold: -149.9915
Global Scale Offset: 1.0172
Reward stats: mean=0.0082, std=0.1683, count=102
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 0.7588, Q2 Loss: 0.7588, Entropy: 0.0692, Mean TD Error: 0.8179, Threshold: -149.9915
tensor([ 0.0719,  0.4909,  0.5762,  0.7576, -0.1355,  0.5202,  0.9746,  1.0077,
         1.4199,  0.4571, -0.0738,  0.9891, -0.0146, -0.0077, -0.8025,  2.5883],
       device='cuda:1')
Original likelihood: -170.47512817382812
Adjusted likelihood: -170.47512817382812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.5785, -2.7408, -2.9220, -3.8075, -4.0554, -4.0709, -4.4037, -4.9521,
        -5.2683, -5.6877, -5.9281, -5.9577, -6.2029, -6.9832, -7.5608, -7.5857],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.5785, -2.7408, -2.9220, -3.8075, -4.0554, -4.0709, -4.4037, -4.9521,
        -5.2683, -5.6877, -5.9281, -5.9577, -6.2029, -6.9832, -7.5608, -7.5857],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.0441
1 mode projection succeeded
New goal: tensor([ 3.4502e-02,  5.2509e-01,  5.7684e-01,  5.9942e-01, -6.6357e-02,
         4.6763e-01,  8.8042e-01,  9.1364e-01,  1.2760e+00,  3.6234e-01,
         2.1501e-01,  1.1029e+00, -4.7268e-04,  1.4151e-02, -3.0333e+00],
       device='cuda:1')
tensor([[0.0133]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -94.77278137207031
Adjusted likelihood: -94.77278137207031
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 94.77278137207031}
Current yaw: tensor([-0.0146, -0.0077, -0.8025], device='cuda:1')
10 thumb_middle
tensor([ 0.0719,  0.4909,  0.5762,  0.7576, -0.1355,  0.5202,  0.9746,  1.0077,
         1.4199,  0.4571, -0.0738,  0.9891, -0.0146, -0.0077, -0.8025,  2.5883],
       device='cuda:1')
Solve time for step 1 9.613301669014618
Current ori: tensor([-0.0146, -0.0077, -0.8025], device='cuda:1')
Index force: tensor([0.5799, 0.5951, 0.5960, 0.5921], device='cuda:1')
tensor([ 0.0471,  0.5121,  0.5838,  0.6385, -0.1721,  0.4816,  0.8736,  0.9088,
         1.2451,  0.3539,  0.0938,  1.0686, -0.0336,  0.0123, -0.8016,  2.4962],
       device='cuda:1')
Solve time for step 2 4.024665697012097
Current ori: tensor([-0.0336,  0.0123, -0.8016], device='cuda:1')
Index force: tensor([0.5838, 0.5869, 0.5833], device='cuda:1')
tensor([ 0.0323,  0.5026,  0.5829,  0.6401, -0.1722,  0.4678,  0.8409,  0.8986,
         1.2234,  0.3416,  0.1404,  1.0831, -0.0316,  0.0217, -0.8016,  2.4750],
       device='cuda:1')
Solve time for step 3 3.797788457944989
Current ori: tensor([-0.0316,  0.0217, -0.8016], device='cuda:1')
Index force: tensor([0.5735, 0.5697], device='cuda:1')
tensor([ 0.0416,  0.5020,  0.5943,  0.6354, -0.1738,  0.4668,  0.8522,  0.9047,
         1.2087,  0.3354,  0.1518,  1.0908, -0.0318,  0.0161, -0.8016,  2.4872],
       device='cuda:1')
Solve time for step 4 3.3383774050162174
Current ori: tensor([-0.0318,  0.0161, -0.8016], device='cuda:1')
Index force: tensor([0.6304], device='cuda:1')
Storing RECOVERY transition: reward=-0.0020 (scaled=-0.0005), steps=4
Reward stats updated: mean 0.0082 -> 0.0081, std: 0.1675
Collected 103 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8734, Q2 Loss=0.8734, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7866
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6517, Q2 Loss=0.6517, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5373
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.3155, Q2 Loss=0.3155, Entropy=0.0001, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4265
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2258, Q2 Loss=1.2258, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7866
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5289, Q2 Loss=0.5289, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3259

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.6%)
Q1 update: 0.08s (19.6%)
Q2 update: 0.07s (18.9%)
Actor update: 0.15s (38.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.719066
Q2 loss: 0.719066
Current threshold: -149.9734
Global Scale Offset: 1.0218
Reward stats: mean=0.0081, std=0.1675, count=103
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7191, Q2 Loss: 0.7191, Entropy: 0.0000, Mean TD Error: 0.5726, Threshold: -149.9734
Original likelihood: -112.94844818115234
Adjusted likelihood: -112.94844818115234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0345,  0.0143, -0.8027], device='cuda:1')
11 turn
Sampling time 5.172248438990209
tensor([ 0.0364,  0.5137,  0.5855,  0.6118, -0.1066,  0.5207,  0.8847,  0.9136,
         1.2740,  0.3516,  0.2015,  1.1149, -0.0345,  0.0143, -0.8027,  2.5021],
       device='cuda:1')
Original likelihood: -109.67408752441406
Adjusted likelihood: -109.67408752441406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.466867038980126
Current ori: tensor([-0.0345,  0.0143, -0.8027], device='cuda:1')
Middle force: tensor([0.5389, 0.5396, 1.1795, 0.5648, 0.6292, 0.7377, 0.5225, 0.5747, 0.9284,
        0.5706, 0.5196, 0.5774], device='cuda:1')
Thumb force: tensor([0.5792, 1.0354, 0.9529, 1.0277, 0.5398, 0.5643, 0.5794, 0.6067, 0.5921,
        0.5834, 0.5237, 0.5304], device='cuda:1')
Index force: tensor([0.6478, 0.5084, 1.2668, 0.5650, 0.6023, 0.6160, 0.5863, 0.6176, 0.5304,
        0.5873, 0.5295, 0.5849], device='cuda:1')
Storing NORMAL transition: reward=0.0677 (scaled=0.0677), steps=1
Reward stats updated: mean 0.0081 -> 0.0087, std: 0.1668
Collected 104 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2962, Q2 Loss=0.2962, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2999
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3631, Q2 Loss=0.3631, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2748
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.0792, Q2 Loss=2.0792, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1607
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7009, Q2 Loss=0.7009, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5437
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5940, Q2 Loss=0.5940, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4527

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.8%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.06s (16.8%)
Actor update: 0.13s (37.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.806698
Q2 loss: 0.806698
Current threshold: -149.9625
Global Scale Offset: 1.0245
Reward stats: mean=0.0087, std=0.1668, count=104
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8067, Q2 Loss: 0.8067, Entropy: 0.0000, Mean TD Error: 0.5464, Threshold: -149.9625
tensor([ 0.0498,  0.4841,  0.6164,  0.6542, -0.1014,  0.5192,  0.8450,  1.0219,
         1.3188,  0.2838,  0.1741,  1.1024, -0.0264,  0.0101, -0.8699,  2.5676],
       device='cuda:1')
Original likelihood: -111.37468719482422
Adjusted likelihood: -111.37468719482422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.846164187998511
Current ori: tensor([-0.0264,  0.0101, -0.8699], device='cuda:1')
Middle force: tensor([0.5363, 1.1298, 0.5530, 0.6316, 0.7182, 0.6203, 0.6669, 0.5882, 0.5970,
        0.5708, 0.7039], device='cuda:1')
Thumb force: tensor([0.9966, 0.9231, 1.0153, 0.5272, 0.5604, 0.5615, 0.5366, 0.7954, 0.5721,
        0.5832, 0.5324], device='cuda:1')
Index force: tensor([0.5078, 1.2216, 0.5578, 0.5935, 0.6135, 0.5750, 0.5022, 0.5762, 0.5747,
        0.5855, 0.6228], device='cuda:1')
Storing NORMAL transition: reward=0.0803 (scaled=0.0803), steps=1
Reward stats updated: mean 0.0087 -> 0.0093, std: 0.1662
Collected 105 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=38.6429, Q2 Loss=38.6429, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1340
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=5.2013, Q2 Loss=5.2013, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7354
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5022, Q2 Loss=0.5022, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5228
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=5.2218, Q2 Loss=5.2218, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1399
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6126, Q2 Loss=0.6126, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7248

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.4%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.6%)
Actor update: 0.16s (39.7%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 10.036167
Q2 loss: 10.036167
Current threshold: -149.9560
Global Scale Offset: 1.0261
Reward stats: mean=0.0093, std=0.1662, count=105
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 10.0362, Q2 Loss: 10.0362, Entropy: 0.0000, Mean TD Error: 2.4513, Threshold: -149.9560
tensor([ 0.0543,  0.4614,  0.6340,  0.6883, -0.1101,  0.5042,  0.8352,  1.0765,
         1.3531,  0.2472,  0.1827,  1.0534, -0.0238,  0.0174, -0.9505,  2.5672],
       device='cuda:1')
Original likelihood: -112.52629089355469
Adjusted likelihood: -112.52629089355469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.972533026011661
Current ori: tensor([-0.0238,  0.0174, -0.9505], device='cuda:1')
Middle force: tensor([1.0782, 0.5580, 0.5577, 0.5444, 0.5985, 0.5398, 1.0296, 0.5506, 0.5368,
        0.5386], device='cuda:1')
Thumb force: tensor([0.9304, 0.9952, 0.5035, 0.5839, 0.5697, 0.6454, 0.8448, 0.5601, 0.7776,
        0.5999], device='cuda:1')
Index force: tensor([1.1807, 0.6051, 0.5866, 0.5621, 0.5614, 0.5752, 0.5280, 0.5897, 0.5432,
        0.5697], device='cuda:1')
Storing NORMAL transition: reward=-0.0792 (scaled=-0.0792), steps=1
Reward stats updated: mean 0.0093 -> 0.0085, std: 0.1656
Collected 106 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2882, Q2 Loss=0.2882, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2854
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.0237, Q2 Loss=2.0237, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1701
SAC Update 3/5: Actor Loss=-0.0067, Q1 Loss=0.7117, Q2 Loss=0.7117, Entropy=0.3464, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5486
SAC Update 4/5: Actor Loss=-0.0035, Q1 Loss=0.4957, Q2 Loss=0.4957, Entropy=0.3464, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3513
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.6223, Q2 Loss=2.6223, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7538

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (24.0%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.3%)
Actor update: 0.12s (37.2%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002037
Q1 loss: 1.228317
Q2 loss: 1.228317
Current threshold: -149.9323
Global Scale Offset: 1.0296
Reward stats: mean=0.0085, std=0.1656, count=106
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 1.2283, Q2 Loss: 1.2283, Entropy: 0.1386, Mean TD Error: 1.0218, Threshold: -149.9323
tensor([ 4.9541e-02,  4.0786e-01,  6.6180e-01,  7.7114e-01, -7.3733e-02,
         4.7176e-01,  8.6463e-01,  1.0466e+00,  1.3173e+00,  1.3334e-01,
         2.4577e-01,  1.1279e+00,  4.3379e-04,  4.8723e-03, -8.7018e-01,
         2.5797e+00], device='cuda:1')
Original likelihood: -67.44064331054688
Adjusted likelihood: -67.44063568115234
Likelihood residual: 7.62939453125e-06
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.292407348984852
Current ori: tensor([ 4.3379e-04,  4.8723e-03, -8.7018e-01], device='cuda:1')
Middle force: tensor([0.6051, 0.8672, 0.5614, 0.9933, 0.5508, 0.8418, 0.5659, 0.5571, 0.6264],
       device='cuda:1')
Thumb force: tensor([1.0105, 0.5433, 0.7407, 0.5818, 0.5907, 0.5438, 0.5940, 0.5633, 0.5006],
       device='cuda:1')
Index force: tensor([0.7483, 0.6549, 0.5920, 0.5062, 0.5883, 0.5076, 0.5825, 0.5638, 0.7128],
       device='cuda:1')
Storing NORMAL transition: reward=0.0246 (scaled=0.0246), steps=1
Reward stats updated: mean 0.0085 -> 0.0086, std: 0.1648
Collected 107 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4030, Q2 Loss=0.4030, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1520
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3243, Q2 Loss=1.3243, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1494
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0261, Q2 Loss=1.0261, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5905
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=7.5892, Q2 Loss=7.5892, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0744
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8009, Q2 Loss=0.8009, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7429

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (18.9%)
Q1 update: 0.08s (19.6%)
Q2 update: 0.07s (19.1%)
Actor update: 0.15s (39.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.228677
Q2 loss: 2.228677
Current threshold: -149.9046
Global Scale Offset: 1.0334
Reward stats: mean=0.0086, std=0.1648, count=107
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.2287, Q2 Loss: 2.2287, Entropy: 0.0000, Mean TD Error: 1.3418, Threshold: -149.9046
tensor([-0.0102,  0.4414,  0.6124,  0.6766, -0.1221,  0.4392,  0.8786,  1.0518,
         1.2870,  0.1133,  0.3122,  1.0788, -0.0148,  0.0360, -0.8965,  2.5752],
       device='cuda:1')
Original likelihood: -119.98725128173828
Adjusted likelihood: -119.98725128173828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 5.484582120960113
Current ori: tensor([-0.0148,  0.0360, -0.8965], device='cuda:1')
Middle force: tensor([0.8501, 0.5626, 0.8321, 0.5705, 0.5424, 0.5703, 0.5018, 0.5795],
       device='cuda:1')
Thumb force: tensor([0.5393, 0.7101, 0.5500, 0.5312, 0.5770, 0.7853, 0.9097, 0.5719],
       device='cuda:1')
Index force: tensor([0.6635, 0.5856, 0.5471, 0.5846, 0.5644, 0.5336, 0.5272, 0.5729],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0021 (scaled=-0.0021), steps=1
Reward stats updated: mean 0.0086 -> 0.0085, std: 0.1641
Collected 108 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=35.8897, Q2 Loss=35.8897, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0008
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=8.2533, Q2 Loss=8.2533, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1289
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=3.4795, Q2 Loss=3.4795, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0582
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=68.8254, Q2 Loss=68.8254, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.9364
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.6236, Q2 Loss=3.6236, Entropy=0.0002, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9940

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (18.1%)
Q1 update: 0.07s (19.6%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (40.1%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 24.014304
Q2 loss: 24.014304
Current threshold: -149.8881
Global Scale Offset: 1.0357
Reward stats: mean=0.0085, std=0.1641, count=108
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 24.0143, Q2 Loss: 24.0143, Entropy: 0.0000, Mean TD Error: 4.6237, Threshold: -149.8881
tensor([ 0.0259,  0.4147,  0.6661,  0.6983, -0.1369,  0.4763,  0.8825,  0.9690,
         1.4011,  0.0113,  0.3857,  0.9001, -0.0229,  0.0394, -0.8950,  2.3183],
       device='cuda:1')
Original likelihood: -138.5367889404297
Adjusted likelihood: -138.5367889404297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 5.332662653003354
Current ori: tensor([-0.0229,  0.0394, -0.8950], device='cuda:1')
Middle force: tensor([0.5365, 0.5896, 0.5271, 1.0104, 0.5461, 0.5274, 0.5331],
       device='cuda:1')
Thumb force: tensor([0.5715, 0.5524, 0.6327, 0.7863, 0.5457, 0.7561, 0.5831],
       device='cuda:1')
Index force: tensor([0.5502, 0.5624, 0.5757, 0.5221, 0.5741, 0.5369, 0.5554],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0192 (scaled=-0.0192), steps=1
Reward stats updated: mean 0.0085 -> 0.0083, std: 0.1633
Collected 109 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.4318, Q2 Loss=0.4318, Entropy=0.0209, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2745
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1475, Q2 Loss=1.1475, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6471
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2335, Q2 Loss=1.2335, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8946
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=32.4179, Q2 Loss=32.4179, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0695
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1685, Q2 Loss=1.1685, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8617

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.2%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.07s (18.1%)
Actor update: 0.14s (38.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000014
Q1 loss: 7.279837
Q2 loss: 7.279837
Current threshold: -149.8776
Global Scale Offset: 1.0428
Reward stats: mean=0.0083, std=0.1633, count=109
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 7.2798, Q2 Loss: 7.2798, Entropy: 0.0042, Mean TD Error: 1.3495, Threshold: -149.8776
tensor([ 0.0966,  0.4815,  0.6154,  0.7462, -0.1301,  0.5089,  0.9251,  0.9277,
         1.3420,  0.0405,  0.4072,  0.8830, -0.0354,  0.0179, -0.8751,  2.2203],
       device='cuda:1')
Original likelihood: -149.4731903076172
Adjusted likelihood: -149.4731903076172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5847)
State is out of distribution
Final likelihood: tensor([ -2.5970,  -3.3284,  -4.3995,  -4.6194,  -4.7880,  -4.9953,  -5.1830,
         -5.2615,  -5.8256,  -6.3088,  -7.1274,  -7.5029,  -8.7076,  -9.1948,
         -9.2848, -10.4302], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.5970,  -3.3284,  -4.3995,  -4.6194,  -4.7880,  -4.9953,  -5.1830,
         -5.2615,  -5.8256,  -6.3088,  -7.1274,  -7.5029,  -8.7076,  -9.1948,
         -9.2848, -10.4302], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.2221
1 mode projection succeeded
New goal: tensor([ 0.0837,  0.5044,  0.5432,  0.8078, -0.0060,  0.5447,  0.8339,  0.7484,
         1.3260,  0.2418,  0.2693,  0.8663, -0.0184, -0.0089, -1.8539],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -84.818115234375
Adjusted likelihood: -84.818115234375
Likelihood residual: 0.0
Original likelihood: -167.28128051757812
Adjusted likelihood: -167.28128051757812
Likelihood residual: 0.0
{'index': 167.28128051757812, 'thumb_middle': 84.818115234375}
Current yaw: tensor([-0.0354,  0.0179, -0.8751], device='cuda:1')
12 thumb_middle
tensor([ 0.0966,  0.4815,  0.6154,  0.7462, -0.1301,  0.5089,  0.9251,  0.9277,
         1.3420,  0.0405,  0.4072,  0.8830, -0.0354,  0.0179, -0.8751,  2.2203],
       device='cuda:1')
Solve time for step 1 10.000849168980494
Current ori: tensor([-0.0354,  0.0179, -0.8751], device='cuda:1')
Index force: tensor([0.5666, 0.5882, 0.5777, 0.5708], device='cuda:1')
tensor([ 0.0959,  0.4972,  0.5686,  0.7956, -0.1534,  0.5272,  0.7893,  0.7523,
         1.2894,  0.1694,  0.2459,  0.8611, -0.0344,  0.0190, -0.8751,  2.2189],
       device='cuda:1')
Solve time for step 2 3.7833098209812306
Current ori: tensor([-0.0344,  0.0190, -0.8751], device='cuda:1')
Index force: tensor([0.5811, 0.5730, 0.5661], device='cuda:1')
tensor([ 0.1159,  0.5108,  0.5632,  0.8092, -0.1385,  0.5423,  0.8035,  0.7227,
         1.2891,  0.2150,  0.2064,  0.8429, -0.0359,  0.0051, -0.8751,  2.2605],
       device='cuda:1')
Solve time for step 3 3.911388121021446
Current ori: tensor([-0.0359,  0.0051, -0.8751], device='cuda:1')
Index force: tensor([0.5653, 0.5603], device='cuda:1')
tensor([ 1.2555e-01,  5.0981e-01,  5.6394e-01,  8.3027e-01, -1.4062e-01,
         5.6078e-01,  7.9902e-01,  7.3629e-01,  1.2769e+00,  2.1396e-01,
         2.0528e-01,  8.5170e-01, -3.3128e-02, -1.9194e-03, -8.7512e-01,
         2.2885e+00], device='cuda:1')
Solve time for step 4 3.5726339039974846
Current ori: tensor([-0.0331, -0.0019, -0.8751], device='cuda:1')
Index force: tensor([0.5457], device='cuda:1')
Storing RECOVERY transition: reward=-0.0008 (scaled=-0.0001), steps=6
Reward stats updated: mean 0.0083 -> 0.0082, std: 0.1626
Collected 110 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=31.8129, Q2 Loss=31.8129, Entropy=0.3394, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0222
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.5705, Q2 Loss=4.5705, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2942
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=6.9467, Q2 Loss=6.9467, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1574
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1802, Q2 Loss=1.1802, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8820
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6268, Q2 Loss=0.6268, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4512

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.2%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.4%)
Actor update: 0.13s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001758
Q1 loss: 9.027433
Q2 loss: 9.027433
Current threshold: -149.8968
Global Scale Offset: 1.0244
Reward stats: mean=0.0082, std=0.1626, count=110
----------------------------------------------
SAC Update - Actor Loss: -0.0018, Q1 Loss: 9.0274, Q2 Loss: 9.0274, Entropy: 0.0679, Mean TD Error: 2.7614, Threshold: -149.8968
Original likelihood: -93.4041748046875
Adjusted likelihood: -93.4041748046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0269,  0.0126, -0.8735], device='cuda:1')
13 turn
Sampling time 5.315869087993633
tensor([ 0.0885,  0.4830,  0.5629,  0.8340, -0.0917,  0.5876,  0.8399,  0.7503,
         1.3397,  0.2368,  0.2763,  0.8789, -0.0269,  0.0126, -0.8735,  2.2934],
       device='cuda:1')
Original likelihood: -104.5936050415039
Adjusted likelihood: -104.5936050415039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.870112619013526
Current ori: tensor([-0.0269,  0.0126, -0.8735], device='cuda:1')
Middle force: tensor([0.7642, 0.5730, 0.6430, 0.6497, 0.6896, 0.8824, 1.3214, 0.5552, 0.5941,
        0.5533, 0.5339, 0.5679], device='cuda:1')
Thumb force: tensor([0.5992, 0.8116, 0.5238, 0.5826, 0.5616, 0.8973, 1.3906, 0.7299, 0.5877,
        0.9574, 1.3910, 0.8334], device='cuda:1')
Index force: tensor([0.5637, 0.6022, 0.5635, 0.5183, 0.5664, 0.5796, 0.5915, 0.5914, 0.5957,
        0.5844, 0.5722, 0.5605], device='cuda:1')
Storing NORMAL transition: reward=0.0284 (scaled=0.0284), steps=1
Reward stats updated: mean 0.0082 -> 0.0084, std: 0.1619
Collected 111 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3776, Q2 Loss=0.3776, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1536
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7010, Q2 Loss=0.7010, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4473
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.1180, Q2 Loss=2.1180, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8146
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=4.2193, Q2 Loss=4.2193, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8397
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8728, Q2 Loss=0.8728, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6165

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.3%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (17.9%)
Actor update: 0.15s (38.5%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 1.657725
Q2 loss: 1.657725
Current threshold: -149.9084
Global Scale Offset: 1.0136
Reward stats: mean=0.0084, std=0.1619, count=111
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.6577, Q2 Loss: 1.6577, Entropy: 0.0000, Mean TD Error: 1.3743, Threshold: -149.9084
tensor([ 0.0871,  0.4449,  0.6475,  0.7646, -0.0988,  0.5777,  0.8347,  0.7848,
         1.3085,  0.2908,  0.3220,  0.8330, -0.0247,  0.0171, -0.9020,  2.2945],
       device='cuda:1')
Original likelihood: -109.38665771484375
Adjusted likelihood: -109.38665771484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.268254867987707
Current ori: tensor([-0.0247,  0.0171, -0.9020], device='cuda:1')
Middle force: tensor([0.5703, 0.6398, 0.6468, 0.6848, 0.8727, 1.3017, 0.5534, 0.5915, 0.5513,
        0.5327, 0.5658], device='cuda:1')
Thumb force: tensor([0.7997, 0.5229, 0.5798, 0.5595, 0.8864, 1.3675, 0.7247, 0.5854, 0.9489,
        1.3691, 0.8256], device='cuda:1')
Index force: tensor([0.5975, 0.5625, 0.5176, 0.5645, 0.5774, 0.5889, 0.5890, 0.5931, 0.5813,
        0.5702, 0.5588], device='cuda:1')
Storing NORMAL transition: reward=0.0653 (scaled=0.0653), steps=1
Reward stats updated: mean 0.0084 -> 0.0089, std: 0.1612
Collected 112 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=29.4800, Q2 Loss=29.4800, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2138
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=57.6669, Q2 Loss=57.6669, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=8.0781
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.6167, Q2 Loss=1.6167, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0689
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=34.7338, Q2 Loss=34.7338, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.6696
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.4114, Q2 Loss=0.4114, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4291

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (18.8%)
Q1 update: 0.08s (19.5%)
Q2 update: 0.07s (18.8%)
Actor update: 0.15s (39.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 24.781747
Q2 loss: 24.781747
Current threshold: -149.9153
Global Scale Offset: 1.0072
Reward stats: mean=0.0089, std=0.1612, count=112
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 24.7817, Q2 Loss: 24.7817, Entropy: 0.0000, Mean TD Error: 4.0919, Threshold: -149.9153
tensor([ 0.0564,  0.4188,  0.5654,  0.9403, -0.0555,  0.5600,  0.8515,  0.8803,
         1.3240,  0.2221,  0.3291,  0.7735, -0.0075, -0.0138, -0.9667,  2.6399],
       device='cuda:1')
Original likelihood: -86.50140380859375
Adjusted likelihood: -86.50140380859375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.569650235003792
Current ori: tensor([-0.0075, -0.0138, -0.9667], device='cuda:1')
Middle force: tensor([0.6580, 0.9008, 1.0508, 0.8408, 0.6646, 0.5372, 0.5627, 0.5883, 0.5701,
        0.5699], device='cuda:1')
Thumb force: tensor([0.8393, 0.7737, 1.6950, 0.7962, 0.5147, 0.5069, 0.5553, 0.5610, 0.5247,
        0.5839], device='cuda:1')
Index force: tensor([0.5221, 0.7869, 0.5197, 0.5514, 0.5189, 0.5613, 0.5683, 0.5870, 0.5447,
        0.5645], device='cuda:1')
Storing NORMAL transition: reward=0.0009 (scaled=0.0009), steps=1
Reward stats updated: mean 0.0089 -> 0.0088, std: 0.1605
Collected 113 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9025, Q2 Loss=0.9025, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7412
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=8.5826, Q2 Loss=8.5826, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3990
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=9.5474, Q2 Loss=9.5474, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4795
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0451, Q2 Loss=1.0451, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6852
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=4.3766, Q2 Loss=4.3766, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9348

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.4%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (18.2%)
Actor update: 0.13s (36.6%)
Target update: 0.01s (1.7%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 4.890812
Q2 loss: 4.890812
Current threshold: -149.9194
Global Scale Offset: 1.0034
Reward stats: mean=0.0088, std=0.1605, count=113
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 4.8908, Q2 Loss: 4.8908, Entropy: 0.0000, Mean TD Error: 2.6480, Threshold: -149.9194
tensor([ 0.0504,  0.3215,  0.7095,  0.8910, -0.0432,  0.4708,  0.9705,  1.0001,
         1.2519,  0.1193,  0.3836,  0.7654,  0.0422, -0.0335, -0.9707,  3.0717],
       device='cuda:1')
Original likelihood: -179.33642578125
Adjusted likelihood: -179.33642578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.7791,  -4.1082,  -4.3799,  -5.0272,  -5.0614,  -5.2967,  -5.3044,
         -5.5144,  -6.2432,  -6.6998,  -7.0102,  -7.1050,  -7.4463,  -8.2076,
         -9.1033, -10.9462], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.7791,  -4.1082,  -4.3799,  -5.0272,  -5.0614,  -5.2967,  -5.3044,
         -5.5144,  -6.2432,  -6.6998,  -7.0102,  -7.1050,  -7.4463,  -8.2076,
         -9.1033, -10.9462], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.3271
1 mode projection succeeded
New goal: tensor([ 0.0372,  0.4878,  0.4898,  0.8758, -0.0352,  0.4754,  0.8304,  0.9144,
         1.2883,  0.3212,  0.2897,  0.9353,  0.0030,  0.0109, -1.5148],
       device='cuda:1')
tensor([[0.0081]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -103.50819396972656
Adjusted likelihood: -103.50819396972656
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 103.50819396972656}
Current yaw: tensor([ 0.0422, -0.0335, -0.9707], device='cuda:1')
14 thumb_middle
tensor([ 0.0504,  0.3215,  0.7095,  0.8910, -0.0432,  0.4708,  0.9705,  1.0001,
         1.2519,  0.1193,  0.3836,  0.7654,  0.0422, -0.0335, -0.9707,  3.0717],
       device='cuda:1')
Solve time for step 1 9.553443315962795
Current ori: tensor([ 0.0422, -0.0335, -0.9707], device='cuda:1')
Index force: tensor([0.6226, 0.6194, 0.5936, 0.5881], device='cuda:1')
tensor([ 0.0242,  0.4048,  0.5602,  0.9296, -0.1142,  0.4916,  0.8291,  0.9186,
         1.2274,  0.2779,  0.2311,  0.8744,  0.0371, -0.0258, -0.9707,  3.1340],
       device='cuda:1')
Solve time for step 2 3.795720790978521
Current ori: tensor([ 0.0371, -0.0258, -0.9707], device='cuda:1')
Index force: tensor([0.6051, 0.5824, 0.5793], device='cuda:1')
tensor([-0.0088,  0.4481,  0.4957,  0.8840, -0.1206,  0.4933,  0.7997,  0.8888,
         1.2271,  0.3053,  0.2190,  0.9118,  0.0362, -0.0100, -0.9707,  3.2402],
       device='cuda:1')
Solve time for step 3 3.654467582993675
Current ori: tensor([ 0.0362, -0.0100, -0.9707], device='cuda:1')
Index force: tensor([0.5712, 0.5701], device='cuda:1')
tensor([-0.0083,  0.4726,  0.4740,  0.8591, -0.1237,  0.4900,  0.8114,  0.8970,
         1.2275,  0.3015,  0.2247,  0.9007,  0.0308, -0.0086, -0.9707,  3.2494],
       device='cuda:1')
Solve time for step 4 3.7818789259763435
Current ori: tensor([ 0.0308, -0.0086, -0.9707], device='cuda:1')
Index force: tensor([0.5566], device='cuda:1')
Storing RECOVERY transition: reward=-0.0030 (scaled=-0.0010), steps=3
Reward stats updated: mean 0.0088 -> 0.0088, std: 0.1598
Collected 114 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=26.4542, Q2 Loss=26.4542, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0989
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.3247, Q2 Loss=4.3247, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9477
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=4.2844, Q2 Loss=4.2844, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9477
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=3.5299, Q2 Loss=3.5299, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8528
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6155, Q2 Loss=0.6155, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5829

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.0%)
Q1 update: 0.07s (18.6%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (38.3%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 7.841728
Q2 loss: 7.841728
Current threshold: -149.9218
Global Scale Offset: 1.0012
Reward stats: mean=0.0088, std=0.1598, count=114
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 7.8417, Q2 Loss: 7.8417, Entropy: 0.0000, Mean TD Error: 2.6860, Threshold: -149.9218
Original likelihood: -118.22166442871094
Adjusted likelihood: -118.22166442871094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0360, -0.0032, -0.9658], device='cuda:1')
15 turn
Sampling time 5.0758326220093295
tensor([-0.0238,  0.4616,  0.4615,  0.8896, -0.0574,  0.5361,  0.8354,  0.9128,
         1.3031,  0.3118,  0.2759,  0.9464,  0.0360, -0.0032, -0.9658,  3.2370],
       device='cuda:1')
Original likelihood: -97.16569519042969
Adjusted likelihood: -97.16569519042969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.784495925996453
Current ori: tensor([ 0.0360, -0.0032, -0.9658], device='cuda:1')
Middle force: tensor([0.5325, 0.5351, 0.5785, 0.9277, 0.6067, 0.5237, 0.6061, 1.0175, 0.5765,
        0.6152, 0.5865, 0.6218], device='cuda:1')
Thumb force: tensor([0.5728, 0.5584, 0.7994, 0.5937, 0.5309, 0.5826, 0.9782, 0.5784, 1.0882,
        0.5329, 0.6087, 0.6009], device='cuda:1')
Index force: tensor([0.8375, 0.5215, 0.6047, 0.5524, 0.5748, 0.6665, 0.5898, 0.5014, 0.6164,
        0.6015, 0.6167, 0.6143], device='cuda:1')
Storing NORMAL transition: reward=0.0755 (scaled=0.0755), steps=1
Reward stats updated: mean 0.0088 -> 0.0093, std: 0.1592
Collected 115 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4570, Q2 Loss=0.4570, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4226
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4996, Q2 Loss=0.4996, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2272
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4804, Q2 Loss=1.4804, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8204
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=25.2568, Q2 Loss=25.2568, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2987
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7238, Q2 Loss=0.7238, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6398

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.9%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (18.1%)
Actor update: 0.12s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 5.683534
Q2 loss: 5.683534
Current threshold: -149.9233
Global Scale Offset: 0.9998
Reward stats: mean=0.0093, std=0.1592, count=115
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.6835, Q2 Loss: 5.6835, Entropy: 0.0000, Mean TD Error: 1.6817, Threshold: -149.9233
tensor([-3.3902e-02,  4.4161e-01,  5.0488e-01,  8.4255e-01, -6.7770e-02,
         5.2660e-01,  8.2787e-01,  9.5111e-01,  1.3592e+00,  2.7153e-01,
         2.8778e-01,  8.5940e-01,  3.3702e-02,  2.1243e-03, -1.0414e+00,
         3.2879e+00], device='cuda:1')
Original likelihood: -110.23762512207031
Adjusted likelihood: -110.23762512207031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.857851210981607
Current ori: tensor([ 0.0337,  0.0021, -1.0414], device='cuda:1')
Middle force: tensor([0.5419, 0.5620, 0.9161, 0.5650, 0.5224, 0.6093, 0.5902, 0.5783, 0.6086,
        0.5727, 0.6419], device='cuda:1')
Thumb force: tensor([0.5531, 0.8047, 0.5993, 0.5717, 0.5844, 0.5887, 0.5703, 0.5668, 0.7283,
        0.5660, 0.6017], device='cuda:1')
Index force: tensor([0.5057, 0.6081, 0.5447, 0.5752, 0.6731, 0.6303, 0.5532, 0.5920, 0.6102,
        0.5630, 0.5803], device='cuda:1')
Storing NORMAL transition: reward=0.1276 (scaled=0.1276), steps=1
Reward stats updated: mean 0.0093 -> 0.0104, std: 0.1589
Collected 116 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=6.1946, Q2 Loss=6.1946, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3220
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5193, Q2 Loss=0.5193, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4729
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5778, Q2 Loss=0.5778, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4796
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6737, Q2 Loss=0.6737, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3966
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=5.6853, Q2 Loss=5.6853, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2907

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.8%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.4%)
Actor update: 0.13s (37.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.730130
Q2 loss: 2.730130
Current threshold: -149.9241
Global Scale Offset: 0.9990
Reward stats: mean=0.0104, std=0.1589, count=116
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.7301, Q2 Loss: 2.7301, Entropy: 0.0000, Mean TD Error: 1.9924, Threshold: -149.9241
tensor([-0.0112,  0.3863,  0.6145,  0.8208, -0.1668,  0.5407,  0.9294,  1.0135,
         1.3959,  0.3051,  0.2809,  0.8331,  0.0591,  0.0059, -1.1732,  3.5812],
       device='cuda:1')
Original likelihood: -218.4269561767578
Adjusted likelihood: -218.4269561767578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.3993,  -4.1945,  -4.9119,  -5.2490,  -5.5080,  -5.5629,  -5.9800,
         -5.9823,  -6.0152,  -6.4607,  -6.5032,  -6.5224,  -6.5710,  -6.5925,
         -8.0212, -10.3698], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.3993,  -4.1945,  -4.9119,  -5.2490,  -5.5080,  -5.5629,  -5.9800,
         -5.9823,  -6.0152,  -6.4607,  -6.5032,  -6.5224,  -6.5710,  -6.5925,
         -8.0212, -10.3698], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.1152
1 mode projection succeeded
New goal: tensor([ 0.0385,  0.5345,  0.5431,  0.6478, -0.0564,  0.5202,  0.8131,  0.8572,
         1.2751,  0.3041,  0.2115,  1.1707,  0.0050,  0.0149, -1.4926],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -115.99711608886719
Adjusted likelihood: -115.99711608886719
Likelihood residual: 0.0
Original likelihood: -177.99502563476562
Adjusted likelihood: -177.99502563476562
Likelihood residual: 0.0
{'index': 177.99502563476562, 'thumb_middle': 115.99711608886719}
Current yaw: tensor([ 0.0591,  0.0059, -1.1732], device='cuda:1')
16 thumb_middle
tensor([-0.0112,  0.3863,  0.6145,  0.8208, -0.1668,  0.5407,  0.9294,  1.0135,
         1.3959,  0.3051,  0.2809,  0.8331,  0.0591,  0.0059, -1.1732,  3.5812],
       device='cuda:1')
Solve time for step 1 9.494577791017946
Current ori: tensor([ 0.0591,  0.0059, -1.1732], device='cuda:1')
Index force: tensor([0.7047, 0.6568, 0.6059, 0.5059], device='cuda:1')
tensor([-1.6385e-04,  4.2260e-01,  6.0603e-01,  7.5349e-01, -1.5651e-01,
         5.4224e-01,  7.8619e-01,  8.6293e-01,  1.2412e+00,  2.9263e-01,
         1.4735e-01,  1.0827e+00,  4.7427e-02,  3.0875e-03, -1.1732e+00,
         3.6179e+00], device='cuda:1')
Solve time for step 2 3.7840188129921444
Current ori: tensor([ 0.0474,  0.0031, -1.1732], device='cuda:1')
Index force: tensor([0.5229, 0.6919, 0.6116], device='cuda:1')
tensor([ 5.3136e-04,  4.3340e-01,  5.9557e-01,  7.4440e-01, -1.5582e-01,
         5.4620e-01,  7.7532e-01,  8.3676e-01,  1.2298e+00,  2.6968e-01,
         1.4162e-01,  1.1386e+00,  4.3215e-02,  2.7903e-03, -1.1732e+00,
         3.6116e+00], device='cuda:1')
Solve time for step 3 3.7112338559818454
Current ori: tensor([ 0.0432,  0.0028, -1.1732], device='cuda:1')
Index force: tensor([0.6765, 0.6016], device='cuda:1')
tensor([-2.9956e-03,  4.8442e-01,  5.4801e-01,  6.9298e-01, -1.5797e-01,
         5.4940e-01,  7.7894e-01,  8.2389e-01,  1.2046e+00,  2.6582e-01,
         1.5079e-01,  1.1579e+00,  2.9745e-02,  5.1680e-03, -1.1732e+00,
         3.6018e+00], device='cuda:1')
Solve time for step 4 3.557066254026722
Current ori: tensor([ 0.0297,  0.0052, -1.1732], device='cuda:1')
Index force: tensor([0.5827], device='cuda:1')
Storing RECOVERY transition: reward=0.0078 (scaled=0.0039), steps=2
Reward stats updated: mean 0.0104 -> 0.0103, std: 0.1583
Collected 117 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5319, Q2 Loss=0.5319, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2540
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5635, Q2 Loss=0.5635, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5891
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5960, Q2 Loss=0.5960, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3126
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.1290, Q2 Loss=3.1290, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1647
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=7.3697, Q2 Loss=7.3697, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4531

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.9%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (37.8%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.438033
Q2 loss: 2.438033
Current threshold: -149.9247
Global Scale Offset: 0.9985
Reward stats: mean=0.0103, std=0.1583, count=117
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.4380, Q2 Loss: 2.4380, Entropy: 0.0000, Mean TD Error: 1.9547, Threshold: -149.9247
Original likelihood: -80.04368591308594
Adjusted likelihood: -80.04368591308594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0272,  0.0045, -1.1767], device='cuda:1')
17 turn
Sampling time 5.037751936004497
tensor([-0.0086,  0.5138,  0.5259,  0.6438, -0.0866,  0.5814,  0.8238,  0.8520,
         1.2843,  0.2863,  0.1942,  1.1845,  0.0272,  0.0045, -1.1767,  3.7227],
       device='cuda:1')
Original likelihood: -77.93994140625
Adjusted likelihood: -77.93994140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.492933997011278
Current ori: tensor([ 0.0272,  0.0045, -1.1767], device='cuda:1')
Middle force: tensor([0.5840, 1.9570, 1.0019, 1.0498, 0.7374, 0.5886, 0.5631, 0.5428, 0.5993,
        0.5875, 0.5237, 0.5288], device='cuda:1')
Thumb force: tensor([0.5218, 1.1970, 0.5765, 1.3766, 0.8617, 0.8446, 0.5245, 0.5846, 0.5794,
        0.8309, 0.5145, 0.5599], device='cuda:1')
Index force: tensor([0.6014, 0.5301, 0.5384, 0.5237, 0.5359, 0.5823, 0.6061, 0.5824, 0.5828,
        0.6223, 0.6517, 0.5258], device='cuda:1')
Storing NORMAL transition: reward=0.1164 (scaled=0.1164), steps=1
Reward stats updated: mean 0.0103 -> 0.0112, std: 0.1579
Collected 118 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7965, Q2 Loss=0.7965, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5853
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5710, Q2 Loss=0.5710, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5580
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9734, Q2 Loss=0.9734, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6021
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8469, Q2 Loss=0.8469, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4322
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8734, Q2 Loss=0.8734, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7189

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.7%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (17.9%)
Actor update: 0.13s (38.2%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.812266
Q2 loss: 0.812266
Current threshold: -149.9250
Global Scale Offset: 0.9983
Reward stats: mean=0.0112, std=0.1579, count=118
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8123, Q2 Loss: 0.8123, Entropy: 0.0000, Mean TD Error: 0.5793, Threshold: -149.9250
tensor([ 0.0190,  0.5796,  0.4355,  0.6767, -0.0394,  0.5565,  0.8089,  0.9700,
         1.3311,  0.2047,  0.1532,  1.1431,  0.0324, -0.0189, -1.2941,  4.1041],
       device='cuda:1')
Original likelihood: -119.33601379394531
Adjusted likelihood: -119.33601379394531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.977735363005195
Current ori: tensor([ 0.0324, -0.0189, -1.2941], device='cuda:1')
Middle force: tensor([1.9166, 0.9816, 1.0135, 0.7176, 0.5818, 1.0622, 0.5424, 0.5817, 0.5512,
        0.6021, 0.5758], device='cuda:1')
Thumb force: tensor([1.1395, 0.5674, 1.3490, 0.8451, 0.8792, 1.0018, 0.5652, 0.6043, 0.5699,
        0.6019, 1.3820], device='cuda:1')
Index force: tensor([0.5241, 0.5391, 0.5249, 0.5262, 0.5766, 0.8033, 0.5002, 0.6001, 0.5709,
        0.6079, 0.5816], device='cuda:1')
Storing NORMAL transition: reward=0.1677 (scaled=0.1677), steps=1
Reward stats updated: mean 0.0112 -> 0.0125, std: 0.1579
Collected 119 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6570, Q2 Loss=0.6570, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5937
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=29.4805, Q2 Loss=29.4805, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.8348
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0006, Q2 Loss=1.0006, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9163
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4394, Q2 Loss=0.4394, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5969
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7534, Q2 Loss=0.7534, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6428

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (19.0%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.5%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 6.466165
Q2 loss: 6.466165
Current threshold: -149.9252
Global Scale Offset: 0.9981
Reward stats: mean=0.0125, std=0.1579, count=119
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 6.4662, Q2 Loss: 6.4662, Entropy: 0.0000, Mean TD Error: 1.9169, Threshold: -149.9252
tensor([-0.0157,  0.5860,  0.4364,  0.6236, -0.0107,  0.4662,  0.9799,  0.9824,
         1.3017,  0.2660,  0.1524,  1.1187,  0.0523, -0.0457, -1.4704,  4.4578],
       device='cuda:1')
Original likelihood: -206.43118286132812
Adjusted likelihood: -206.43118286132812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.4128,  -5.6743,  -5.7996,  -5.8539,  -6.1641,  -6.3552,  -8.7016,
        -10.5689, -11.8507, -11.9550, -11.9666, -12.9638, -13.5556, -13.7844,
        -15.2417, -18.0756], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.4128,  -5.6743,  -5.7996,  -5.8539,  -6.1641,  -6.3552,  -8.7016,
        -10.5689, -11.8507, -11.9550, -11.9666, -12.9638, -13.5556, -13.7844,
        -15.2417, -18.0756], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.1828
1 mode projection succeeded
New goal: tensor([ 0.0545,  0.5610,  0.5935,  0.5025, -0.0853,  0.5131,  0.8691,  0.8717,
         1.2622,  0.3207,  0.2387,  1.1281,  0.0052,  0.0137, -1.6302],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -174.85440063476562
Adjusted likelihood: -174.85440063476562
Likelihood residual: 0.0
Original likelihood: -170.14486694335938
Adjusted likelihood: -170.14486694335938
Likelihood residual: 0.0
{'index': 170.14486694335938, 'thumb_middle': 174.85440063476562}
Current yaw: tensor([ 0.0523, -0.0457, -1.4704], device='cuda:1')
18 index
tensor([-0.0157,  0.5860,  0.4364,  0.6236, -0.0107,  0.4662,  0.9799,  0.9824,
         1.3017,  0.2660,  0.1524,  1.1187,  0.0523, -0.0457, -1.4704,  4.4578],
       device='cuda:1')
Solve time for step 1 10.999147869006265
Current ori: tensor([ 0.0523, -0.0457, -1.4704], device='cuda:1')
Middle force: tensor([0.5176, 0.5565, 0.5135, 0.5632], device='cuda:1')
Thumb force: tensor([0.5100, 0.5584, 0.5092, 0.5338], device='cuda:1')
tensor([ 0.1015,  0.5102,  0.5148,  0.5062, -0.0159,  0.4707,  0.9719,  0.9794,
         1.2721,  0.3168,  0.1901,  1.0878,  0.0532, -0.0424, -1.4950,  4.7821],
       device='cuda:1')
Solve time for step 2 4.304459356004372
Current ori: tensor([ 0.0532, -0.0424, -1.4950], device='cuda:1')
Middle force: tensor([0.5485, 0.5116, 0.5581], device='cuda:1')
Thumb force: tensor([0.5602, 0.5088, 0.5319], device='cuda:1')
tensor([ 0.1264,  0.5159,  0.5353,  0.4860, -0.0171,  0.4859,  0.9540,  0.9685,
         1.2550,  0.3479,  0.2159,  1.0551,  0.0491, -0.0412, -1.5131,  5.2819],
       device='cuda:1')
Solve time for step 3 3.9775933279888704
Current ori: tensor([ 0.0491, -0.0412, -1.5131], device='cuda:1')
Middle force: tensor([0.5096, 0.5521], device='cuda:1')
Thumb force: tensor([0.5081, 0.5293], device='cuda:1')
tensor([ 0.1184,  0.5096,  0.5411,  0.4776, -0.0212,  0.5067,  0.9456,  0.9404,
         1.2872,  0.2992,  0.1900,  1.0627,  0.0471, -0.0416, -1.5151,  5.7449],
       device='cuda:1')
Solve time for step 4 4.246224593021907
Current ori: tensor([ 0.0471, -0.0416, -1.5151], device='cuda:1')
Middle force: tensor([0.5268], device='cuda:1')
Thumb force: tensor([0.5499], device='cuda:1')
Storing RECOVERY transition: reward=0.0364 (scaled=0.0182), steps=2
Reward stats updated: mean 0.0125 -> 0.0126, std: 0.1572
Collected 120 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4638, Q2 Loss=0.4638, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1989
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9932, Q2 Loss=0.9932, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6158
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6108, Q2 Loss=0.6108, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4046
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1358, Q2 Loss=1.1358, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7431
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=4.0835, Q2 Loss=4.0835, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0472

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.9%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.7%)
Actor update: 0.14s (38.9%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.457404
Q2 loss: 1.457404
Current threshold: -149.9253
Global Scale Offset: 0.9980
Reward stats: mean=0.0126, std=0.1572, count=120
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.4574, Q2 Loss: 1.4574, Entropy: 0.0000, Mean TD Error: 1.4019, Threshold: -149.9253
Original likelihood: -150.6793975830078
Adjusted likelihood: -150.6793975830078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3403)
Current yaw: tensor([ 0.0427, -0.0392, -1.5049], device='cuda:1')
19 turn
Sampling time 5.274056383990683
tensor([ 0.0692,  0.5712,  0.5837,  0.4974, -0.0284,  0.5243,  0.9293,  0.9223,
         1.2837,  0.3076,  0.1981,  1.0495,  0.0427, -0.0392, -1.5049,  5.8092],
       device='cuda:1')
Original likelihood: -146.8277587890625
Adjusted likelihood: -146.8277587890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9546)
Solve time for step 1 14.43586286000209
Current ori: tensor([ 0.0427, -0.0392, -1.5049], device='cuda:1')
Middle force: tensor([0.9877, 0.8886, 0.5705, 0.5509, 0.8437, 0.9049, 0.5721, 0.7451, 0.6413,
        0.7222, 0.8441, 0.6675], device='cuda:1')
Thumb force: tensor([0.8443, 0.5319, 0.9540, 1.0164, 0.5548, 0.5789, 0.5950, 0.7053, 0.5429,
        0.5276, 0.5719, 0.5662], device='cuda:1')
Index force: tensor([0.5347, 0.9129, 0.5494, 0.5003, 0.5571, 0.5411, 0.6335, 0.5393, 0.5479,
        0.5706, 0.5339, 0.5757], device='cuda:1')
Storing NORMAL transition: reward=0.0425 (scaled=0.0425), steps=1
Reward stats updated: mean 0.0126 -> 0.0128, std: 0.1566
Collected 121 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8323, Q2 Loss=0.8323, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5310
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6549, Q2 Loss=0.6549, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4696
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1449, Q2 Loss=1.1449, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8881
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=23.8908, Q2 Loss=23.8908, Entropy=0.0924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2684
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=28.8830, Q2 Loss=28.8830, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.8928

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (25.2%)
Q1 update: 0.05s (17.2%)
Q2 update: 0.05s (17.3%)
Actor update: 0.11s (36.4%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000093
Q1 loss: 11.081188
Q2 loss: 11.081188
Current threshold: -149.9239
Global Scale Offset: 1.0069
Reward stats: mean=0.0128, std=0.1566, count=121
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 11.0812, Q2 Loss: 11.0812, Entropy: 0.0185, Mean TD Error: 2.6100, Threshold: -149.9239
tensor([ 0.0310,  0.5922,  0.5349,  0.4664, -0.0464,  0.5199,  0.9228,  0.9003,
         1.3568,  0.2155,  0.2068,  0.9667,  0.0304, -0.0258, -1.5459,  5.7140],
       device='cuda:1')
Original likelihood: -120.46204376220703
Adjusted likelihood: -120.46204376220703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.444628715980798
Current ori: tensor([ 0.0304, -0.0258, -1.5459], device='cuda:1')
Middle force: tensor([1.0826, 0.7789, 1.5393, 0.5135, 0.5028, 0.6032, 0.5565, 0.5469, 0.5064,
        0.8007, 0.6327], device='cuda:1')
Thumb force: tensor([0.5361, 0.5243, 0.5122, 0.5595, 0.5282, 0.5404, 0.5583, 0.8010, 0.5155,
        0.5764, 0.5691], device='cuda:1')
Index force: tensor([0.6486, 0.5225, 0.9667, 0.5325, 0.5751, 0.5905, 0.5344, 0.5441, 0.5734,
        0.5396, 0.5815], device='cuda:1')
Storing NORMAL transition: reward=-0.0107 (scaled=-0.0107), steps=1
Reward stats updated: mean 0.0128 -> 0.0126, std: 0.1560
Collected 122 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=3.2801, Q2 Loss=3.2801, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9547
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=23.6076, Q2 Loss=23.6076, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2626
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7906, Q2 Loss=0.7906, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3165
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8390, Q2 Loss=0.8390, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4168
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=6.6187, Q2 Loss=6.6187, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5205

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (25.0%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.05s (16.7%)
Actor update: 0.12s (36.6%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 7.027214
Q2 loss: 7.027214
Current threshold: -149.9214
Global Scale Offset: 1.0229
Reward stats: mean=0.0126, std=0.1560, count=122
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 7.0272, Q2 Loss: 7.0272, Entropy: 0.0000, Mean TD Error: 2.4942, Threshold: -149.9214
tensor([-0.0392,  0.5325,  0.5750,  0.4486, -0.0355,  0.5307,  0.8951,  0.9756,
         1.3761,  0.2552,  0.1759,  0.9327,  0.0585, -0.0378, -1.5385,  5.7028],
       device='cuda:1')
Original likelihood: -182.33792114257812
Adjusted likelihood: -182.33792114257812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -7.0971,  -7.4334,  -8.5990,  -9.3462,  -9.4917,  -9.6820, -10.7814,
        -10.9266, -12.0334, -13.2286, -13.6590, -13.8175, -15.1063, -16.0244,
        -16.0787, -22.9484], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -7.0971,  -7.4334,  -8.5990,  -9.3462,  -9.4917,  -9.6820, -10.7814,
        -10.9266, -12.0334, -13.2286, -13.6590, -13.8175, -15.1063, -16.0244,
        -16.0787, -22.9484], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -12.2659
1 mode projection succeeded
New goal: tensor([ 0.0393,  0.5424,  0.5420,  0.6269, -0.0729,  0.4883,  0.8543,  0.9165,
         1.2881,  0.2903,  0.2406,  1.0925,  0.0086,  0.0155, -1.0286],
       device='cuda:1')
tensor([[0.0050]], device='cuda:1') tensor([[0.0032]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -190.0465850830078
Adjusted likelihood: -190.0465850830078
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 190.0465850830078}
Current yaw: tensor([ 0.0585, -0.0378, -1.5385], device='cuda:1')
20 thumb_middle
tensor([-0.0392,  0.5325,  0.5750,  0.4486, -0.0355,  0.5307,  0.8951,  0.9756,
         1.3761,  0.2552,  0.1759,  0.9327,  0.0585, -0.0378, -1.5385,  5.7028],
       device='cuda:1')
Solve time for step 1 9.262938144966029
Current ori: tensor([ 0.0585, -0.0378, -1.5385], device='cuda:1')
Index force: tensor([0.5542, 0.5859, 0.5724, 0.5644], device='cuda:1')
tensor([-0.0920,  0.5745,  0.5439,  0.5984, -0.1311,  0.5182,  0.8308,  0.8962,
         1.2515,  0.2606,  0.1656,  1.0357,  0.1515, -0.1060, -1.5385,  5.6625],
       device='cuda:1')
Solve time for step 2 3.7817677360144444
Current ori: tensor([ 0.1515, -0.1060, -1.5385], device='cuda:1')
Index force: tensor([0.5641, 0.5677, 0.5627], device='cuda:1')
tensor([-0.1307,  0.7000,  0.5795,  0.6514, -0.0551,  0.5729,  0.8740,  0.8985,
         1.2263,  0.2709,  0.1571,  1.0463,  0.3546, -0.2624, -1.5286,  5.9245],
       device='cuda:1')
Solve time for step 3 3.805996370036155
Current ori: tensor([ 0.3546, -0.2624, -1.5286], device='cuda:1')
Index force: tensor([0.5728, 0.5547], device='cuda:1')
tensor([ 0.0350,  0.8345,  0.9025,  0.7690,  0.0874,  0.6784,  0.9130,  0.9072,
         1.2159,  0.2970,  0.1060,  1.0096,  0.3846, -0.3603, -1.3829,  5.9663],
       device='cuda:1')
Solve time for step 4 3.5552139740320854
Current ori: tensor([ 0.3846, -0.3603, -1.3829], device='cuda:1')
Index force: tensor([0.5471], device='cuda:1')
Storing RECOVERY transition: reward=-0.3264 (scaled=-0.1632), steps=2
Reward stats updated: mean 0.0126 -> 0.0112, std: 0.1561
Collected 123 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6407, Q2 Loss=0.6407, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7861
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.4908, Q2 Loss=0.4908, Entropy=0.0192, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1581
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5883, Q2 Loss=0.5883, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0938
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8686, Q2 Loss=0.8686, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6018
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9142, Q2 Loss=0.9142, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4839

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (20.0%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (18.0%)
Actor update: 0.13s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000013
Q1 loss: 0.700507
Q2 loss: 0.700507
Current threshold: -149.9195
Global Scale Offset: 1.0371
Reward stats: mean=0.0112, std=0.1561, count=123
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7005, Q2 Loss: 0.7005, Entropy: 0.0039, Mean TD Error: 0.4247, Threshold: -149.9195
Original likelihood: -1217.8587646484375
Adjusted likelihood: -1217.8587646484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 7
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
1 turn
Sampling time 5.111768089001998
tensor([ 1.3876e-01,  6.0474e-01,  5.4566e-01,  6.4287e-01, -1.3715e-01,
         5.5133e-01,  9.2983e-01,  8.6323e-01,  1.2156e+00,  2.9816e-01,
         2.4837e-01,  1.2230e+00, -8.6170e-04,  1.4795e-02, -2.9074e-02,
         2.5272e-01], device='cuda:1')
Original likelihood: -113.89268493652344
Adjusted likelihood: -113.89268493652344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.677128689014353
Current ori: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Middle force: tensor([1.7585, 0.6041, 0.5202, 1.1158, 0.5384, 0.5502, 0.5596, 0.5453, 0.5262,
        0.4956, 0.8288, 0.5643], device='cuda:1')
Thumb force: tensor([1.0524, 0.6168, 1.4799, 1.0665, 0.6707, 1.0229, 0.5846, 0.5879, 1.6237,
        0.5666, 0.7131, 0.5727], device='cuda:1')
Index force: tensor([0.6403, 0.5190, 0.5528, 0.5042, 0.5362, 0.5332, 0.5944, 0.6559, 0.8355,
        0.7242, 0.5902, 0.5548], device='cuda:1')
Storing NORMAL transition: reward=0.1900 (scaled=0.1900), steps=1
Reward stats updated: mean 0.0112 -> 0.0126, std: 0.1563
Collected 124 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1011, Q2 Loss=1.1011, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8698
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=22.7518, Q2 Loss=22.7518, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7459
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9002, Q2 Loss=0.9002, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5309
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9121, Q2 Loss=0.9121, Entropy=0.0001, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7547
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7556, Q2 Loss=0.7556, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6712

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.8%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.07s (18.6%)
Actor update: 0.15s (38.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 5.284126
Q2 loss: 5.284126
Current threshold: -149.9182
Global Scale Offset: 1.0465
Reward stats: mean=0.0126, std=0.1563, count=124
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.2841, Q2 Loss: 5.2841, Entropy: 0.0000, Mean TD Error: 1.5145, Threshold: -149.9182
tensor([ 0.0368,  0.5067,  0.6083,  0.5916, -0.2326,  0.4108,  1.0397,  1.0500,
         1.3976,  0.1316,  0.2351,  1.1397,  0.0183,  0.0535, -0.2237,  0.7267],
       device='cuda:1')
Original likelihood: -261.650634765625
Adjusted likelihood: -261.650634765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.2052, -3.6837, -3.7445, -3.8881, -4.0539, -4.4886, -4.6112, -4.6227,
        -5.0875, -5.6474, -5.9210, -6.2839, -6.4635, -6.8754, -7.2534, -7.5400],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2052, -3.6837, -3.7445, -3.8881, -4.0539, -4.4886, -4.6112, -4.6227,
        -5.0875, -5.6474, -5.9210, -6.2839, -6.4635, -6.8754, -7.2534, -7.5400],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2106
1 mode projection succeeded
New goal: tensor([ 0.0646,  0.5769,  0.5299,  0.6070, -0.0941,  0.4886,  0.8897,  0.9336,
         1.2734,  0.3381,  0.2061,  1.1538,  0.0055,  0.0139, -0.3932],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -65.34101104736328
Adjusted likelihood: -65.34101104736328
Likelihood residual: 0.0
Original likelihood: -111.47421264648438
Adjusted likelihood: -111.47421264648438
Likelihood residual: 0.0
{'index': 111.47421264648438, 'thumb_middle': 65.34101104736328}
Current yaw: tensor([ 0.0183,  0.0535, -0.2237], device='cuda:1')
2 thumb_middle
tensor([ 0.0368,  0.5067,  0.6083,  0.5916, -0.2326,  0.4108,  1.0397,  1.0500,
         1.3976,  0.1316,  0.2351,  1.1397,  0.0183,  0.0535, -0.2237,  0.7267],
       device='cuda:1')
Solve time for step 1 9.803313153039198
Current ori: tensor([ 0.0183,  0.0535, -0.2237], device='cuda:1')
Index force: tensor([0.5987, 0.5077, 0.5853, 0.5018], device='cuda:1')
tensor([ 0.0615,  0.5310,  0.5747,  0.6359, -0.2334,  0.4472,  0.8849,  0.9255,
         1.2654,  0.2827,  0.1472,  1.1354,  0.0151,  0.0423, -0.2210,  0.7180],
       device='cuda:1')
Solve time for step 2 3.887831623025704
Current ori: tensor([ 0.0151,  0.0423, -0.2210], device='cuda:1')
Index force: tensor([0.5056, 0.5761, 0.4999], device='cuda:1')
tensor([ 0.0601,  0.5397,  0.5662,  0.6257, -0.2385,  0.4640,  0.8680,  0.9082,
         1.2469,  0.3226,  0.1624,  1.1220,  0.0122,  0.0429, -0.2210,  0.7125],
       device='cuda:1')
Solve time for step 3 3.8643940970068797
Current ori: tensor([ 0.0122,  0.0429, -0.2210], device='cuda:1')
Index force: tensor([0.6199, 0.5951], device='cuda:1')
tensor([ 0.0685,  0.5726,  0.5393,  0.6058, -0.2243,  0.4710,  0.8588,  0.9074,
         1.2438,  0.3226,  0.1455,  1.1248,  0.0029,  0.0372, -0.2210,  0.7157],
       device='cuda:1')
Solve time for step 4 3.6990569799672812
Current ori: tensor([ 0.0029,  0.0372, -0.2210], device='cuda:1')
Index force: tensor([0.5812], device='cuda:1')
Storing RECOVERY transition: reward=0.0125 (scaled=0.0125), steps=1
Reward stats updated: mean 0.0126 -> 0.0126, std: 0.1557
Collected 125 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=26.8818, Q2 Loss=26.8818, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.9315
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4604, Q2 Loss=0.4604, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0601
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.7253, Q2 Loss=0.7253, Entropy=0.1019, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3532
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5527, Q2 Loss=1.5527, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1070
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8656, Q2 Loss=0.8656, Entropy=0.0001, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3682

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.0%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.07s (18.3%)
Actor update: 0.15s (38.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000106
Q1 loss: 6.097148
Q2 loss: 6.097148
Current threshold: -149.9152
Global Scale Offset: 1.0666
Reward stats: mean=0.0126, std=0.1557, count=125
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 6.0971, Q2 Loss: 6.0971, Entropy: 0.0204, Mean TD Error: 1.7640, Threshold: -149.9152
Original likelihood: -100.52342224121094
Adjusted likelihood: -100.52342224121094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0018,  0.0271, -0.2325], device='cuda:1')
3 turn
Sampling time 5.122824145015329
tensor([ 0.0854,  0.5807,  0.5396,  0.6155, -0.1432,  0.5190,  0.8913,  0.9285,
         1.3026,  0.3424,  0.1882,  1.1542,  0.0018,  0.0271, -0.2325,  0.7653],
       device='cuda:1')
Original likelihood: -104.91128540039062
Adjusted likelihood: -104.91128540039062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.379336415033322
Current ori: tensor([ 0.0018,  0.0271, -0.2325], device='cuda:1')
Middle force: tensor([0.5668, 0.4862, 1.2597, 0.7968, 0.5121, 1.4407, 0.5013, 0.7703, 0.5696,
        0.4859, 0.8989, 0.5551], device='cuda:1')
Thumb force: tensor([0.5984, 1.5285, 0.8769, 1.3274, 0.7958, 0.5209, 0.5118, 1.5314, 0.5614,
        0.5046, 0.5500, 0.5849], device='cuda:1')
Index force: tensor([0.5041, 0.6620, 0.6817, 0.5298, 0.6473, 0.7681, 0.5493, 0.5586, 0.7342,
        0.7880, 0.6553, 0.6426], device='cuda:1')
Storing NORMAL transition: reward=0.0994 (scaled=0.0994), steps=1
Reward stats updated: mean 0.0126 -> 0.0133, std: 0.1553
Collected 126 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8345, Q2 Loss=0.8345, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5952
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8726, Q2 Loss=0.8726, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5844
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8849, Q2 Loss=0.8849, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7385
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1982, Q2 Loss=1.1982, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9287
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9622, Q2 Loss=0.9622, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8378

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.09s (22.2%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.07s (17.5%)
Actor update: 0.15s (38.0%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.950493
Q2 loss: 0.950493
Current threshold: -149.9122
Global Scale Offset: 1.0864
Reward stats: mean=0.0133, std=0.1553, count=126
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9505, Q2 Loss: 0.9505, Entropy: 0.0000, Mean TD Error: 0.7369, Threshold: -149.9122
tensor([ 0.1023,  0.5722,  0.5598,  0.6314, -0.1398,  0.4937,  0.9132,  0.9920,
         1.3368,  0.2931,  0.1692,  1.1180,  0.0045,  0.0188, -0.3316,  0.8901],
       device='cuda:1')
Original likelihood: -85.07603454589844
Adjusted likelihood: -85.07603454589844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.038804798037745
Current ori: tensor([ 0.0045,  0.0188, -0.3316], device='cuda:1')
Middle force: tensor([0.5085, 1.2323, 0.7845, 0.5112, 1.3945, 0.5009, 0.7586, 0.5603, 0.5023,
        0.8845, 0.5471], device='cuda:1')
Thumb force: tensor([1.4730, 0.8645, 1.2947, 0.7857, 0.5200, 0.5126, 1.4929, 0.5617, 0.5060,
        0.5478, 0.5827], device='cuda:1')
Index force: tensor([0.6531, 0.6712, 0.5282, 0.6424, 0.7626, 0.5533, 0.5553, 0.7281, 0.8044,
        0.6508, 0.6468], device='cuda:1')
Storing NORMAL transition: reward=0.0034 (scaled=0.0034), steps=1
Reward stats updated: mean 0.0133 -> 0.0132, std: 0.1546
Collected 127 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9056, Q2 Loss=0.9056, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4091
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.1254, Q2 Loss=3.1254, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0155
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5936, Q2 Loss=0.5936, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2905
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9289, Q2 Loss=0.9289, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5565
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0274, Q2 Loss=1.0274, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6232

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.0%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (18.4%)
Actor update: 0.13s (37.8%)
Target update: 0.01s (2.1%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.316176
Q2 loss: 1.316176
Current threshold: -149.9104
Global Scale Offset: 1.0983
Reward stats: mean=0.0132, std=0.1546, count=127
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3162, Q2 Loss: 1.3162, Entropy: 0.0000, Mean TD Error: 0.9790, Threshold: -149.9104
tensor([ 0.1701,  0.5955,  0.5076,  0.4739, -0.0741,  0.5325,  0.9141,  0.9975,
         1.2904,  0.2650,  0.1762,  1.0740,  0.0029, -0.0282, -0.3356, -0.3919],
       device='cuda:1')
Original likelihood: -149.76010131835938
Adjusted likelihood: -149.76010131835938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5305)
Solve time for step 3 5.840013123990502
Current ori: tensor([ 0.0029, -0.0282, -0.3356], device='cuda:1')
Middle force: tensor([0.5074, 0.9543, 0.5129, 0.5066, 0.5547, 0.5425, 0.7676, 0.5852, 0.5025,
        0.5009], device='cuda:1')
Thumb force: tensor([0.5127, 1.1559, 0.8528, 0.5062, 0.5260, 0.5217, 0.6284, 0.5123, 0.5022,
        0.5096], device='cuda:1')
Index force: tensor([0.5132, 0.5091, 0.5172, 0.5950, 0.5008, 0.6284, 0.7720, 0.5170, 0.6043,
        0.6116], device='cuda:1')
Storing NORMAL transition: reward=0.0463 (scaled=0.0463), steps=1
Reward stats updated: mean 0.0132 -> 0.0135, std: 0.1541
Collected 128 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7500, Q2 Loss=0.7500, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3797
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9606, Q2 Loss=0.9606, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7887
SAC Update 3/5: Actor Loss=-0.0011, Q1 Loss=0.4923, Q2 Loss=0.4923, Entropy=0.3466, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1602
SAC Update 4/5: Actor Loss=-0.0017, Q1 Loss=0.6785, Q2 Loss=0.6785, Entropy=0.3457, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4636
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=26.3529, Q2 Loss=26.3529, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.0099

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.2%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (17.9%)
Actor update: 0.12s (37.1%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000549
Q1 loss: 5.846878
Q2 loss: 5.846878
Current threshold: -149.9040
Global Scale Offset: 1.1065
Reward stats: mean=0.0135, std=0.1541, count=128
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 5.8469, Q2 Loss: 5.8469, Entropy: 0.1384, Mean TD Error: 1.7604, Threshold: -149.9040
tensor([ 0.1165,  0.7073,  0.4271,  0.5415, -0.0507,  0.5028,  0.9411,  1.0327,
         1.2181,  0.2249,  0.1922,  0.9716,  0.0039, -0.0366, -0.3827, -0.4860],
       device='cuda:1')
Original likelihood: -193.92144775390625
Adjusted likelihood: -193.92144775390625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.9490, -3.1815, -3.5527, -3.8075, -3.8415, -4.6154, -4.8531, -5.2756,
        -5.4512, -5.4616, -5.6221, -6.1780, -6.3721, -6.8998, -7.4983, -8.8917],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9490, -3.1815, -3.5527, -3.8075, -3.8415, -4.6154, -4.8531, -5.2756,
        -5.4512, -5.4616, -5.6221, -6.1780, -6.3721, -6.8998, -7.4983, -8.8917],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2782
1 mode projection succeeded
New goal: tensor([ 3.4700e-02,  5.2640e-01,  5.7483e-01,  6.0026e-01, -6.6339e-02,
         4.6658e-01,  8.8234e-01,  9.1316e-01,  1.2752e+00,  3.6324e-01,
         2.1553e-01,  1.1025e+00, -3.8151e-04,  1.4029e-02, -3.2476e-01],
       device='cuda:1')
tensor([[0.0122]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -109.04476165771484
Adjusted likelihood: -109.04476165771484
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 109.04476165771484}
Current yaw: tensor([ 0.0039, -0.0366, -0.3827], device='cuda:1')
4 thumb_middle
tensor([ 0.1165,  0.7073,  0.4271,  0.5415, -0.0507,  0.5028,  0.9411,  1.0327,
         1.2181,  0.2249,  0.1922,  0.9716,  0.0039, -0.0366, -0.3827, -0.4860],
       device='cuda:1')
Solve time for step 1 9.857881707022898
Current ori: tensor([ 0.0039, -0.0366, -0.3827], device='cuda:1')
Index force: tensor([0.6191, 0.6088, 0.5799, 0.5003], device='cuda:1')
tensor([ 0.0886,  0.5999,  0.5411,  0.5573, -0.1322,  0.4705,  0.8603,  0.9256,
         1.2245,  0.3248,  0.1340,  1.0502,  0.0270, -0.0161, -0.3828, -0.4917],
       device='cuda:1')
Solve time for step 2 3.9885830390267074
Current ori: tensor([ 0.0270, -0.0161, -0.3828], device='cuda:1')
Index force: tensor([0.5904, 0.5727, 0.5000], device='cuda:1')
tensor([ 0.0514,  0.5299,  0.5741,  0.6119, -0.1590,  0.4528,  0.8543,  0.8949,
         1.2480,  0.3332,  0.1451,  1.0674,  0.0470,  0.0063, -0.3828, -0.5083],
       device='cuda:1')
Solve time for step 3 3.767494924017228
Current ori: tensor([ 0.0470,  0.0063, -0.3828], device='cuda:1')
Index force: tensor([0.5780, 0.5865], device='cuda:1')
tensor([ 0.0523,  0.5455,  0.5652,  0.5887, -0.1590,  0.4623,  0.8530,  0.8913,
         1.2438,  0.3438,  0.1386,  1.0701,  0.0411,  0.0050, -0.3828, -0.5207],
       device='cuda:1')
Solve time for step 4 3.565252017986495
Current ori: tensor([ 0.0411,  0.0050, -0.3828], device='cuda:1')
Index force: tensor([0.5663], device='cuda:1')
Storing RECOVERY transition: reward=0.0092 (scaled=0.0031), steps=3
Reward stats updated: mean 0.0135 -> 0.0134, std: 0.1535
Collected 129 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9121, Q2 Loss=0.9121, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7620
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=6.5218, Q2 Loss=6.5218, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6599
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9204, Q2 Loss=0.9204, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7658
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6112, Q2 Loss=0.6112, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3574
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9989, Q2 Loss=0.9989, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6770

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.8%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (18.3%)
Actor update: 0.13s (37.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.992890
Q2 loss: 1.992890
Current threshold: -149.8956
Global Scale Offset: 1.1126
Reward stats: mean=0.0134, std=0.1535, count=129
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.9929, Q2 Loss: 1.9929, Entropy: 0.0000, Mean TD Error: 1.4444, Threshold: -149.8956
Original likelihood: -91.12095642089844
Adjusted likelihood: -91.12095642089844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0373,  0.0070, -0.3921], device='cuda:1')
5 turn
Sampling time 5.2179649350000545
tensor([ 0.0437,  0.5609,  0.5490,  0.5626, -0.0914,  0.5058,  0.8914,  0.9131,
         1.3066,  0.3758,  0.1882,  1.0994,  0.0373,  0.0070, -0.3921, -0.4637],
       device='cuda:1')
Original likelihood: -87.67253875732422
Adjusted likelihood: -87.67253875732422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.275841074006166
Current ori: tensor([ 0.0373,  0.0070, -0.3921], device='cuda:1')
Middle force: tensor([0.5729, 1.6758, 0.5301, 0.5392, 0.6685, 0.6501, 0.7463, 0.5675, 0.5698,
        0.5032, 0.5388, 0.5443], device='cuda:1')
Thumb force: tensor([0.7852, 1.0047, 0.4984, 0.9248, 0.8383, 0.5915, 0.9795, 0.5569, 1.0505,
        0.5517, 0.6028, 0.5426], device='cuda:1')
Index force: tensor([0.5020, 0.7131, 0.7903, 0.5836, 0.5090, 0.5677, 0.6095, 0.5024, 0.5795,
        0.5727, 0.6442, 0.5441], device='cuda:1')
Storing NORMAL transition: reward=0.0158 (scaled=0.0158), steps=1
Reward stats updated: mean 0.0134 -> 0.0134, std: 0.1529
Collected 130 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=7.9221, Q2 Loss=7.9221, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8523
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4963, Q2 Loss=0.4963, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1110
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=3.2247, Q2 Loss=3.2247, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0816
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5986, Q2 Loss=0.5986, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3844
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0770, Q2 Loss=1.0770, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7404

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.2%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.5%)
Actor update: 0.12s (37.2%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 2.663760
Q2 loss: 2.663760
Current threshold: -149.8907
Global Scale Offset: 1.1162
Reward stats: mean=0.0134, std=0.1529, count=130
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 2.6638, Q2 Loss: 2.6638, Entropy: 0.0000, Mean TD Error: 1.8339, Threshold: -149.8907
tensor([-0.0105,  0.5190,  0.5242,  0.6231,  0.0313,  0.3869,  0.8907,  0.9738,
         1.3385,  0.2951,  0.1554,  1.1443,  0.0991, -0.0076, -0.4163, -0.3972],
       device='cuda:1')
Original likelihood: -222.9900665283203
Adjusted likelihood: -222.9900665283203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -25.5539,  -26.0571,  -27.0107,  -28.8085,  -28.9357,  -32.3350,
         -36.1342,  -49.3071,  -51.5449,  -67.4751,  -94.2862,  -94.9273,
        -106.3963, -132.3013, -179.1980, -237.1772], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -25.5539,  -26.0571,  -27.0107,  -28.8085,  -28.9357,  -32.3350,
         -36.1342,  -49.3071,  -51.5449,  -67.4751,  -94.2862,  -94.9273,
        -106.3963, -132.3013, -179.1980, -237.1772], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -76.0905
1 mode projection succeeded
New goal: tensor([ 0.0316,  0.5229,  0.5562,  0.6460, -0.0664,  0.4921,  0.8645,  0.8535,
         1.2994,  0.2844,  0.1939,  1.1856,  0.0235,  0.0138, -1.4320],
       device='cuda:1')
tensor([[0.0054]], device='cuda:1') tensor([[0.0032]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -207.73995971679688
Adjusted likelihood: -207.73995971679688
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 207.73995971679688}
Current yaw: tensor([ 0.0991, -0.0076, -0.4163], device='cuda:1')
6 thumb_middle
tensor([-0.0105,  0.5190,  0.5242,  0.6231,  0.0313,  0.3869,  0.8907,  0.9738,
         1.3385,  0.2951,  0.1554,  1.1443,  0.0991, -0.0076, -0.4163, -0.3972],
       device='cuda:1')
Solve time for step 1 9.60459268197883
Current ori: tensor([ 0.0991, -0.0076, -0.4163], device='cuda:1')
Index force: tensor([0.5898, 0.5988, 0.6059, 0.5749], device='cuda:1')
tensor([-0.0215,  0.5430,  0.5390,  0.6118, -0.1151,  0.4705,  0.8434,  0.8572,
         1.2672,  0.2689,  0.1228,  1.1531,  0.2184, -0.0339, -0.4163,  0.9168],
       device='cuda:1')
Solve time for step 2 3.8754698680131696
Current ori: tensor([ 0.2184, -0.0339, -0.4163], device='cuda:1')
Index force: tensor([0.5950, 0.6013, 0.5722], device='cuda:1')
tensor([-0.0210,  0.5763,  0.6443,  0.7338, -0.0760,  0.5282,  0.8866,  0.8629,
         1.2959,  0.2771,  0.1550,  1.1793,  0.2337, -0.0750, -0.3907,  1.6958],
       device='cuda:1')
Solve time for step 3 3.70940267998958
Current ori: tensor([ 0.2337, -0.0750, -0.3907], device='cuda:1')
Index force: tensor([0.5887, 0.5632], device='cuda:1')
tensor([-9.6710e-04,  6.6554e-01,  5.9228e-01,  6.7235e-01,  9.5199e-03,
         5.9015e-01,  8.9919e-01,  8.5231e-01,  1.2880e+00,  2.7779e-01,
         1.4246e-01,  1.1746e+00,  2.5621e-01, -1.6879e-01, -3.6292e-01,
         2.5720e+00], device='cuda:1')
Solve time for step 4 3.50323147198651
Current ori: tensor([ 0.2562, -0.1688, -0.3629], device='cuda:1')
Index force: tensor([0.5506], device='cuda:1')
Storing RECOVERY transition: reward=-0.3004 (scaled=-0.3004), steps=1
Reward stats updated: mean 0.0134 -> 0.0110, std: 0.1547
Collected 131 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2494, Q2 Loss=1.2494, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8168
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.8299, Q2 Loss=0.8299, Entropy=0.3466, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5703
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=0.9129, Q2 Loss=0.9129, Entropy=0.3466, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3353
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8921, Q2 Loss=0.8921, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5205
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9030, Q2 Loss=0.9030, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3152

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.0%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (18.2%)
Actor update: 0.13s (39.0%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002785
Q1 loss: 0.957475
Q2 loss: 0.957475
Current threshold: -149.8543
Global Scale Offset: 1.1178
Reward stats: mean=0.0110, std=0.1547, count=131
----------------------------------------------
SAC Update - Actor Loss: -0.0028, Q1 Loss: 0.9575, Q2 Loss: 0.9575, Entropy: 0.1386, Mean TD Error: 0.7116, Threshold: -149.8543
Original likelihood: -1075.8389892578125
Adjusted likelihood: -1075.8389892578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 8
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
1 turn
Sampling time 5.094448775984347
tensor([ 1.5283e-01,  6.0120e-01,  5.9625e-01,  5.8028e-01, -1.3878e-01,
         5.6232e-01,  9.0018e-01,  9.0714e-01,  1.2496e+00,  3.2832e-01,
         1.9714e-01,  1.2105e+00, -1.3005e-04,  1.3937e-02, -3.9258e-02,
         4.4622e-01], device='cuda:1')
Original likelihood: -127.58174896240234
Adjusted likelihood: -127.58174896240234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.534522873000242
Current ori: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Middle force: tensor([0.5010, 0.6444, 0.5451, 0.5044, 0.7739, 1.1271, 0.5842, 0.5658, 0.5155,
        0.5112, 0.6100, 0.6248], device='cuda:1')
Thumb force: tensor([0.9116, 0.7445, 1.6581, 2.5901, 0.9185, 1.7966, 0.6026, 0.6887, 0.6056,
        1.7437, 0.5865, 0.6100], device='cuda:1')
Index force: tensor([0.5707, 0.8964, 0.5994, 0.6062, 0.5905, 0.5908, 0.5927, 0.5191, 0.4890,
        0.9207, 0.5499, 0.5811], device='cuda:1')
Storing NORMAL transition: reward=-0.0103 (scaled=-0.0103), steps=1
Reward stats updated: mean 0.0110 -> 0.0109, std: 0.1541
Collected 132 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=3.0309, Q2 Loss=3.0309, Entropy=0.1186, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3363
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=17.9176, Q2 Loss=17.9176, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5157
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7575, Q2 Loss=0.7575, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4972
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9382, Q2 Loss=0.9382, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5978
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1917, Q2 Loss=1.1917, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9130

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.2%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (18.3%)
Actor update: 0.13s (37.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000132
Q1 loss: 4.767184
Q2 loss: 4.767184
Current threshold: -149.8180
Global Scale Offset: 1.1452
Reward stats: mean=0.0109, std=0.1541, count=132
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 4.7672, Q2 Loss: 4.7672, Entropy: 0.0237, Mean TD Error: 2.3720, Threshold: -149.8180
tensor([ 1.9353e-01,  6.0323e-01,  6.7069e-01,  5.1525e-01, -7.7203e-02,
         5.6754e-01,  8.2867e-01,  9.8422e-01,  1.2297e+00,  2.9089e-01,
         1.8310e-01,  1.2504e+00, -1.0802e-03, -1.3332e-02, -2.8949e-02,
         4.1731e-01], device='cuda:1')
Original likelihood: -145.340576171875
Adjusted likelihood: -145.340576171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9866)
Solve time for step 2 6.114845809002873
Current ori: tensor([-0.0011, -0.0133, -0.0289], device='cuda:1')
Middle force: tensor([1.6995, 0.8209, 0.5183, 0.5765, 0.8721, 1.1335, 0.5077, 0.7873, 0.5339,
        0.5441, 0.5670], device='cuda:1')
Thumb force: tensor([1.3653, 0.5703, 0.5511, 0.5334, 1.2874, 0.6582, 0.5584, 0.6660, 0.6506,
        0.7830, 0.6672], device='cuda:1')
Index force: tensor([1.7774, 0.5630, 0.5976, 0.5993, 0.8274, 0.5434, 0.5892, 0.5266, 0.6605,
        0.6219, 0.5942], device='cuda:1')
Storing NORMAL transition: reward=0.4314 (scaled=0.4314), steps=1
Reward stats updated: mean 0.0109 -> 0.0140, std: 0.1578
Collected 133 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5004, Q2 Loss=0.5004, Entropy=0.0354, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3548
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.3167, Q2 Loss=4.3167, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2532
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=3.7377, Q2 Loss=3.7377, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3091
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.4652, Q2 Loss=1.4652, Entropy=0.0371, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5794
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7568, Q2 Loss=0.7568, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4199

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.6%)
Q1 update: 0.06s (17.1%)
Q2 update: 0.06s (18.0%)
Actor update: 0.14s (39.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000012
Q1 loss: 2.155379
Q2 loss: 2.155379
Current threshold: -149.7962
Global Scale Offset: 1.1642
Reward stats: mean=0.0140, std=0.1578, count=133
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.1554, Q2 Loss: 2.1554, Entropy: 0.0145, Mean TD Error: 2.1833, Threshold: -149.7962
tensor([ 0.2550,  0.6459,  0.6433,  0.6030,  0.0373,  0.4614,  1.0031,  1.1779,
         1.3108,  0.1717,  0.1054,  1.0831,  0.0035, -0.0772, -0.4954,  1.5536],
       device='cuda:1')
Original likelihood: -229.4656219482422
Adjusted likelihood: -229.4656219482422
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.3606,  -4.8250,  -4.9408,  -5.0494,  -6.2918,  -8.4714,  -8.6770,
         -9.0941,  -9.7251,  -9.8563, -10.3137, -10.6885, -12.0372, -12.5014,
        -19.0066, -32.5604], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.3606,  -4.8250,  -4.9408,  -5.0494,  -6.2918,  -8.4714,  -8.6770,
         -9.0941,  -9.7251,  -9.8563, -10.3137, -10.6885, -12.0372, -12.5014,
        -19.0066, -32.5604], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.5250
1 mode projection succeeded
New goal: tensor([ 4.1662e-02,  5.7728e-01,  4.7642e-01,  6.6451e-01, -4.0854e-02,
         5.3431e-01,  7.5940e-01,  1.0057e+00,  1.2846e+00,  3.3913e-01,
         1.7569e-01,  1.1221e+00, -1.4587e-02,  4.0927e-04, -5.6722e-01],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -175.65704345703125
Adjusted likelihood: -175.65704345703125
Likelihood residual: 0.0
Original likelihood: -209.699951171875
Adjusted likelihood: -209.699951171875
Likelihood residual: 0.0
{'index': 209.699951171875, 'thumb_middle': 175.65704345703125}
Current yaw: tensor([ 0.0035, -0.0772, -0.4954], device='cuda:1')
2 thumb_middle
tensor([ 0.2550,  0.6459,  0.6433,  0.6030,  0.0373,  0.4614,  1.0031,  1.1779,
         1.3108,  0.1717,  0.1054,  1.0831,  0.0035, -0.0772, -0.4954,  1.5536],
       device='cuda:1')
Solve time for step 1 9.569387322000694
Current ori: tensor([ 0.0035, -0.0772, -0.4954], device='cuda:1')
Index force: tensor([0.5002, 0.5014, 0.7002, 0.5029], device='cuda:1')
tensor([ 0.2578,  0.6707,  0.5748,  0.6753, -0.0609,  0.5545,  0.7883,  1.0275,
         1.2048,  0.2906,  0.0605,  1.0655,  0.0030, -0.0773, -0.4916,  1.5265],
       device='cuda:1')
Solve time for step 2 4.037205164029729
Current ori: tensor([ 0.0030, -0.0773, -0.4916], device='cuda:1')
Index force: tensor([0.6852, 0.6520, 0.6037], device='cuda:1')
tensor([ 0.2047,  0.6630,  0.5275,  0.6664, -0.0954,  0.5542,  0.7533,  1.0006,
         1.2190,  0.3138,  0.0693,  1.0767, -0.0018, -0.0462, -0.4916,  1.4420],
       device='cuda:1')
Solve time for step 3 3.935081497998908
Current ori: tensor([-0.0018, -0.0462, -0.4916], device='cuda:1')
Index force: tensor([0.6521, 0.6008], device='cuda:1')
tensor([ 0.1513,  0.6434,  0.4990,  0.6573, -0.1296,  0.5361,  0.7331,  0.9853,
         1.2343,  0.3194,  0.0903,  1.0909, -0.0016, -0.0147, -0.4916,  1.3607],
       device='cuda:1')
Solve time for step 4 3.6481164040160365
Current ori: tensor([-0.0016, -0.0147, -0.4916], device='cuda:1')
Index force: tensor([0.5848], device='cuda:1')
Storing RECOVERY transition: reward=0.0255 (scaled=0.0127), steps=2
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.1572
Collected 134 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8899, Q2 Loss=0.8899, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7421
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0438, Q2 Loss=1.0438, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1727
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8571, Q2 Loss=0.8571, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0176
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1143, Q2 Loss=1.1143, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8680
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=5.2388, Q2 Loss=5.2388, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4842

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (22.2%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.828776
Q2 loss: 1.828776
Current threshold: -149.7830
Global Scale Offset: 1.1781
Reward stats: mean=0.0140, std=0.1572, count=134
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.8288, Q2 Loss: 1.8288, Entropy: 0.0000, Mean TD Error: 1.4569, Threshold: -149.7830
Original likelihood: -70.37019348144531
Adjusted likelihood: -70.37019348144531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0035,  0.0064, -0.4860], device='cuda:1')
3 turn
Sampling time 5.065757710020989
tensor([ 0.1149,  0.6200,  0.4896,  0.6639, -0.0847,  0.5717,  0.7603,  1.0005,
         1.3054,  0.3360,  0.1657,  1.1296,  0.0035,  0.0064, -0.4860,  1.2867],
       device='cuda:1')
Original likelihood: -72.0130844116211
Adjusted likelihood: -72.0130844116211
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.858263836009428
Current ori: tensor([ 0.0035,  0.0064, -0.4860], device='cuda:1')
Middle force: tensor([1.3050, 0.5428, 1.4163, 0.5114, 0.5218, 0.6318, 0.5472, 0.4959, 0.5321,
        0.5159, 0.8695, 0.5614], device='cuda:1')
Thumb force: tensor([0.7680, 0.5766, 1.5641, 0.5155, 1.8394, 0.9098, 0.5229, 0.6251, 1.2154,
        0.7260, 0.7189, 0.7031], device='cuda:1')
Index force: tensor([0.5567, 0.6445, 0.5172, 0.6595, 0.7823, 0.5409, 0.5675, 0.7038, 0.5421,
        0.5777, 0.5519, 0.5658], device='cuda:1')
Storing NORMAL transition: reward=0.0329 (scaled=0.0329), steps=1
Reward stats updated: mean 0.0140 -> 0.0142, std: 0.1566
Collected 135 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7278, Q2 Loss=0.7278, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4578
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5999, Q2 Loss=0.5999, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2631
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.7095, Q2 Loss=1.7095, Entropy=0.0407, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6924
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=6.4916, Q2 Loss=6.4916, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6645
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9173, Q2 Loss=0.9173, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3935

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (19.1%)
Q1 update: 0.07s (19.7%)
Q2 update: 0.07s (18.9%)
Actor update: 0.15s (39.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000015
Q1 loss: 2.089219
Q2 loss: 2.089219
Current threshold: -149.7748
Global Scale Offset: 1.1903
Reward stats: mean=0.0142, std=0.1566, count=135
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.0892, Q2 Loss: 2.0892, Entropy: 0.0081, Mean TD Error: 1.4943, Threshold: -149.7748
tensor([ 0.1865,  0.5652,  0.6735,  0.5941,  0.0254,  0.6282,  0.7760,  1.0426,
         1.3058,  0.1894,  0.1411,  1.0283,  0.0119, -0.0765, -0.5250,  1.3189],
       device='cuda:1')
Original likelihood: -138.7252960205078
Adjusted likelihood: -138.7252960205078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.189273452968337
Current ori: tensor([ 0.0119, -0.0765, -0.5250], device='cuda:1')
Middle force: tensor([0.5370, 1.3763, 0.5099, 0.5274, 0.6443, 0.5479, 0.5106, 0.5330, 0.5205,
        0.8538, 0.5614], device='cuda:1')
Thumb force: tensor([0.5737, 1.5108, 0.5142, 1.7285, 0.8677, 0.5192, 0.5725, 1.1601, 0.6943,
        0.7058, 0.6861], device='cuda:1')
Index force: tensor([0.6314, 0.5164, 0.6521, 0.7808, 0.5365, 0.5666, 0.6495, 0.5417, 0.5656,
        0.5482, 0.5620], device='cuda:1')
Storing NORMAL transition: reward=0.0836 (scaled=0.0836), steps=1
Reward stats updated: mean 0.0142 -> 0.0147, std: 0.1562
Collected 136 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.8352, Q2 Loss=0.8352, Entropy=0.3460, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5125
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.5578, Q2 Loss=1.5578, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1262
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=6.4423, Q2 Loss=6.4423, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6784
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8213, Q2 Loss=0.8213, Entropy=0.0002, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7735
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.5096, Q2 Loss=2.5096, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9433

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.3%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.06s (16.8%)
Actor update: 0.13s (36.7%)
Target update: 0.01s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001480
Q1 loss: 2.433238
Q2 loss: 2.433238
Current threshold: -149.7481
Global Scale Offset: 1.1927
Reward stats: mean=0.0147, std=0.1562, count=136
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 2.4332, Q2 Loss: 2.4332, Entropy: 0.0692, Mean TD Error: 2.0068, Threshold: -149.7481
tensor([ 0.1674,  0.6150,  0.6120,  0.5453, -0.1351,  0.7387,  0.7806,  1.1002,
         1.3265,  0.2154,  0.2086,  0.8524, -0.0067, -0.0696, -0.6085,  1.3492],
       device='cuda:1')
Original likelihood: -205.29193115234375
Adjusted likelihood: -205.29193115234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.8998,  -3.4476,  -3.9416,  -4.8458,  -5.3000,  -6.1064,  -6.4073,
         -6.9694,  -7.0614,  -7.2188,  -8.0145,  -8.0248,  -8.4164,  -8.8152,
        -31.6571, -45.9852], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.8998,  -3.4476,  -3.9416,  -4.8458,  -5.3000,  -6.1064,  -6.4073,
         -6.9694,  -7.0614,  -7.2188,  -8.0145,  -8.0248,  -8.4164,  -8.8152,
        -31.6571, -45.9852], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.3195
1 mode projection succeeded
New goal: tensor([ 0.0713,  0.4534,  0.6519,  0.7006, -0.0742,  0.5783,  0.9031,  0.7639,
         1.2411,  0.5610,  0.3071,  0.8311, -0.0192, -0.0127, -1.2867],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0038]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -203.7983856201172
Adjusted likelihood: -203.7983856201172
Likelihood residual: 0.0
Original likelihood: -170.58428955078125
Adjusted likelihood: -170.58428955078125
Likelihood residual: 0.0
{'index': 170.58428955078125, 'thumb_middle': 203.7983856201172}
Current yaw: tensor([-0.0067, -0.0696, -0.6085], device='cuda:1')
4 index
tensor([ 0.1674,  0.6150,  0.6120,  0.5453, -0.1351,  0.7387,  0.7806,  1.1002,
         1.3265,  0.2154,  0.2086,  0.8524, -0.0067, -0.0696, -0.6085,  1.3492],
       device='cuda:1')
Solve time for step 1 11.115910961991176
Current ori: tensor([-0.0067, -0.0696, -0.6085], device='cuda:1')
Middle force: tensor([0.5020, 0.5739, 0.5865, 0.5815], device='cuda:1')
Thumb force: tensor([0.5326, 0.5746, 0.5332, 0.5265], device='cuda:1')
tensor([ 0.1302,  0.4285,  0.5923,  0.6445, -0.1234,  0.6850,  0.9740,  0.8973,
         1.1654,  0.4934,  0.3307,  0.7927, -0.0088, -0.0773, -0.6280,  0.6053],
       device='cuda:1')
Solve time for step 2 4.478871300991159
Current ori: tensor([-0.0088, -0.0773, -0.6280], device='cuda:1')
Middle force: tensor([0.5517, 0.5304, 0.5711], device='cuda:1')
Thumb force: tensor([0.5889, 0.5243, 0.5645], device='cuda:1')
tensor([ 0.1108,  0.4095,  0.5992,  0.6627, -0.1313,  0.6944,  1.0099,  0.8467,
         1.1859,  0.4682,  0.3055,  0.7950, -0.0119, -0.0827, -0.6524,  0.0765],
       device='cuda:1')
Solve time for step 3 4.43423856399022
Current ori: tensor([-0.0119, -0.0827, -0.6524], device='cuda:1')
Middle force: tensor([0.5265, 0.5662], device='cuda:1')
Thumb force: tensor([0.5222, 0.5612], device='cuda:1')
tensor([ 0.1068,  0.4055,  0.5975,  0.6674, -0.1440,  0.7104,  1.0141,  0.8265,
         1.1795,  0.4767,  0.3174,  0.7876, -0.0086, -0.0824, -0.6664, -0.5438],
       device='cuda:1')
Solve time for step 4 4.252796231012326
Current ori: tensor([-0.0086, -0.0824, -0.6664], device='cuda:1')
Middle force: tensor([0.5774], device='cuda:1')
Thumb force: tensor([0.5512], device='cuda:1')
Storing RECOVERY transition: reward=0.0813 (scaled=0.0407), steps=2
Reward stats updated: mean 0.0147 -> 0.0149, std: 0.1556
Collected 137 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1096, Q2 Loss=1.1096, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7080
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.5376, Q2 Loss=1.5376, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1074
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9735, Q2 Loss=0.9735, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8916
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.8199, Q2 Loss=0.8199, Entropy=0.3459, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5424
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8870, Q2 Loss=0.8870, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6742

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.3%)
Q1 update: 0.06s (17.7%)
Q2 update: 0.07s (18.0%)
Actor update: 0.14s (38.5%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001510
Q1 loss: 1.065525
Q2 loss: 1.065525
Current threshold: -149.7224
Global Scale Offset: 1.1899
Reward stats: mean=0.0149, std=0.1556, count=137
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 1.0655, Q2 Loss: 1.0655, Entropy: 0.0692, Mean TD Error: 1.1847, Threshold: -149.7224
Original likelihood: -197.6686553955078
Adjusted likelihood: -197.6686553955078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.2136,  -4.4280,  -4.8063,  -5.0418,  -5.9213,  -6.2631,  -6.5814,
         -6.7293,  -6.9620,  -7.0236,  -7.1480,  -7.6129,  -7.8552,  -8.8679,
        -10.0284, -12.3885], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.2136,  -4.4280,  -4.8063,  -5.0418,  -5.9213,  -6.2631,  -6.5814,
         -6.7293,  -6.9620,  -7.0236,  -7.1480,  -7.6129,  -7.8552,  -8.8679,
        -10.0284, -12.3885], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.9919
1 mode projection succeeded
New goal: tensor([ 0.0706,  0.4539,  0.6506,  0.7021, -0.0737,  0.5773,  0.9050,  0.7636,
         1.2383,  0.5657,  0.3089,  0.8316, -0.0189, -0.0131, -0.3583],
       device='cuda:1')
tensor([[0.0018]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -169.93572998046875
Adjusted likelihood: -169.93572998046875
Likelihood residual: 0.0
Original likelihood: -209.41592407226562
Adjusted likelihood: -209.41592407226562
Likelihood residual: 0.0
{'index': 209.41592407226562, 'thumb_middle': 169.93572998046875}
Current yaw: tensor([-3.2719e-04, -8.6057e-02, -6.9532e-01], device='cuda:1')
5 thumb_middle
tensor([ 6.6279e-02,  4.5783e-01,  6.4274e-01,  6.9421e-01, -1.5957e-01,
         7.3269e-01,  1.0204e+00,  8.1965e-01,  1.1771e+00,  4.7578e-01,
         3.1730e-01,  7.9628e-01, -3.2719e-04, -8.6057e-02, -6.9532e-01,
        -5.3592e-01], device='cuda:1')
Solve time for step 1 9.874552841996774
Current ori: tensor([-3.2719e-04, -8.6057e-02, -6.9532e-01], device='cuda:1')
Index force: tensor([0.5711, 0.6117, 0.6094, 0.6121], device='cuda:1')
tensor([ 0.0458,  0.4825,  0.6570,  0.6959, -0.1200,  0.6265,  0.9132,  0.7638,
         1.1606,  0.5487,  0.2044,  0.7792, -0.0056, -0.1838, -0.7125,  2.9949],
       device='cuda:1')
Solve time for step 2 3.8928444290068
Current ori: tensor([-0.0056, -0.1838, -0.7125], device='cuda:1')
Index force: tensor([0.6021, 0.6049, 0.6065], device='cuda:1')
tensor([-0.0067,  0.5473,  0.7009,  0.7107, -0.0705,  0.6593,  0.9287,  0.7668,
         1.1382,  0.5666,  0.1437,  0.7562, -0.0121, -0.2495, -0.7819,  5.9828],
       device='cuda:1')
Solve time for step 3 3.8772946289973333
Current ori: tensor([-0.0121, -0.2495, -0.7819], device='cuda:1')
Index force: tensor([0.5001, 0.5781], device='cuda:1')
tensor([-0.0212,  0.5817,  0.7197,  0.7278, -0.0410,  0.6873,  0.9323,  0.7588,
         1.1236,  0.5769,  0.1181,  0.7278, -0.0071, -0.2872, -0.8578, -5.7537],
       device='cuda:1')
Solve time for step 4 3.8136107359896414
Current ori: tensor([-0.0071, -0.2872, -0.8578], device='cuda:1')
Index force: tensor([0.5569], device='cuda:1')
Storing RECOVERY transition: reward=0.1433 (scaled=0.0717), steps=2
Reward stats updated: mean 0.0149 -> 0.0153, std: 0.1551
Collected 138 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0608, Q2 Loss=1.0608, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6378
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=20.0278, Q2 Loss=20.0278, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4003
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6741, Q2 Loss=0.6741, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4240
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8901, Q2 Loss=0.8901, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6075
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6794, Q2 Loss=0.6794, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4658

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.9%)
Q1 update: 0.07s (18.3%)
Q2 update: 0.07s (18.3%)
Actor update: 0.14s (38.3%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 4.666415
Q2 loss: 4.666415
Current threshold: -149.6959
Global Scale Offset: 1.1832
Reward stats: mean=0.0153, std=0.1551, count=138
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 4.6664, Q2 Loss: 4.6664, Entropy: 0.0000, Mean TD Error: 1.3071, Threshold: -149.6959
Original likelihood: -507.3472900390625
Adjusted likelihood: -507.3472900390625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 9
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
1 turn
Sampling time 5.258703731000423
tensor([ 1.3969e-01,  6.2847e-01,  5.2785e-01,  6.1418e-01, -1.7712e-01,
         5.6624e-01,  9.4041e-01,  9.3824e-01,  1.2329e+00,  2.7382e-01,
         2.6411e-01,  1.1681e+00, -1.3005e-04,  1.3937e-02, -3.9258e-02,
         4.4622e-01], device='cuda:1')
Original likelihood: -149.95468139648438
Adjusted likelihood: -149.95468139648438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4502)
State is out of distribution
Final likelihood: tensor([-2.2801, -3.6947, -3.7374, -3.8928, -3.9569, -4.2954, -4.3024, -4.4366,
        -4.4368, -4.4674, -4.6063, -4.7075, -4.7543, -4.8291, -5.1487, -5.2992],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.2801, -3.6947, -3.7374, -3.8928, -3.9569, -4.2954, -4.3024, -4.4366,
        -4.4368, -4.4674, -4.6063, -4.7075, -4.7543, -4.8291, -5.1487, -5.2992],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3028
1 mode projection succeeded
New goal: tensor([ 0.0448,  0.5203,  0.5762,  0.6315, -0.0666,  0.4932,  0.8217,  0.9711,
         1.2719,  0.3300,  0.2298,  1.1104,  0.0057,  0.0132, -1.2572],
       device='cuda:1')
tensor([[0.0034]], device='cuda:1') tensor([[0.0018]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -138.45846557617188
Adjusted likelihood: -138.45846557617188
Likelihood residual: 0.0
Original likelihood: -154.4725341796875
Adjusted likelihood: -154.4725341796875
Likelihood residual: 0.0
{'index': 154.4725341796875, 'thumb_middle': 138.45846557617188}
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
2 thumb_middle
tensor([ 1.3969e-01,  6.2847e-01,  5.2785e-01,  6.1418e-01, -1.7712e-01,
         5.6624e-01,  9.4041e-01,  9.3824e-01,  1.2329e+00,  2.7382e-01,
         2.6411e-01,  1.1681e+00, -1.3005e-04,  1.3937e-02, -3.9258e-02,
         4.4622e-01], device='cuda:1')
Solve time for step 1 9.539298417046666
Current ori: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Index force: tensor([0.5611, 0.5929, 0.5822, 0.6048], device='cuda:1')
tensor([ 0.1038,  0.5807,  0.5588,  0.6090, -0.2008,  0.4636,  0.7953,  0.9370,
         1.2419,  0.3058,  0.1750,  1.0968,  0.0103,  0.0360, -0.0392,  0.4005],
       device='cuda:1')
Solve time for step 2 3.8373462090385146
Current ori: tensor([ 0.0103,  0.0360, -0.0392], device='cuda:1')
Index force: tensor([0.5815, 0.5731, 0.5952], device='cuda:1')
tensor([ 0.1013,  0.5656,  0.5745,  0.6135, -0.1966,  0.4594,  0.7806,  0.9404,
         1.2514,  0.3156,  0.1656,  1.0854,  0.0141,  0.0381, -0.0392,  0.3986],
       device='cuda:1')
Solve time for step 3 3.97297753096791
Current ori: tensor([ 0.0141,  0.0381, -0.0392], device='cuda:1')
Index force: tensor([0.5930, 0.5872], device='cuda:1')
tensor([ 0.1075,  0.5409,  0.6005,  0.6406, -0.1950,  0.4605,  0.7792,  0.9447,
         1.2518,  0.3214,  0.1645,  1.0818,  0.0217,  0.0362, -0.0392,  0.4141],
       device='cuda:1')
Solve time for step 4 3.6188898389809765
Current ori: tensor([ 0.0217,  0.0362, -0.0392], device='cuda:1')
Index force: tensor([0.5672], device='cuda:1')
Storing RECOVERY transition: reward=0.0056 (scaled=0.0056), steps=0
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.1546
Collected 139 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8512, Q2 Loss=0.8512, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5982
SAC Update 2/5: Actor Loss=-0.0018, Q1 Loss=0.9301, Q2 Loss=0.9301, Entropy=0.3440, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5967
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1001, Q2 Loss=1.1001, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8679
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2173, Q2 Loss=1.2173, Entropy=0.0002, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7931
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5602, Q2 Loss=0.5602, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4029

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.0%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.08s (18.9%)
Actor update: 0.15s (38.8%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000370
Q1 loss: 0.931801
Q2 loss: 0.931801
Current threshold: -149.6850
Global Scale Offset: 1.1828
Reward stats: mean=0.0152, std=0.1546, count=139
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.9318, Q2 Loss: 0.9318, Entropy: 0.0688, Mean TD Error: 0.6518, Threshold: -149.6850
Original likelihood: -136.82138061523438
Adjusted likelihood: -136.82138061523438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0225,  0.0369, -0.0465], device='cuda:1')
3 turn
Sampling time 5.263723723997828
tensor([ 0.1039,  0.5423,  0.5910,  0.6490, -0.1263,  0.5047,  0.8163,  0.9631,
         1.3150,  0.3375,  0.2199,  1.1138,  0.0225,  0.0369, -0.0465,  0.4495],
       device='cuda:1')
Original likelihood: -137.1339111328125
Adjusted likelihood: -137.1339111328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 16.302952401980292
Current ori: tensor([ 0.0225,  0.0369, -0.0465], device='cuda:1')
Middle force: tensor([1.1688, 1.6840, 0.8327, 0.5096, 0.5998, 0.9470, 1.1556, 0.5119, 0.7008,
        0.9546, 0.5295, 0.5683], device='cuda:1')
Thumb force: tensor([0.9454, 1.5293, 0.5780, 0.5327, 0.5127, 1.1979, 0.6964, 0.5619, 0.5922,
        1.1813, 0.6206, 0.6025], device='cuda:1')
Index force: tensor([0.9163, 1.8258, 0.5603, 0.5851, 0.6062, 0.7883, 0.5477, 0.5909, 0.5837,
        0.5428, 0.6151, 0.5802], device='cuda:1')
Storing NORMAL transition: reward=0.1775 (scaled=0.1775), steps=1
Reward stats updated: mean 0.0152 -> 0.0164, std: 0.1546
Collected 140 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=3.5209, Q2 Loss=3.5209, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1816
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=2.7362, Q2 Loss=2.7362, Entropy=0.1438, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3234
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8996, Q2 Loss=0.8996, Entropy=0.0004, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7438
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.0642, Q2 Loss=2.0642, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6531
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0860, Q2 Loss=1.0860, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8532

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (18.1%)
Q1 update: 0.08s (19.7%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (39.8%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000175
Q1 loss: 2.061388
Q2 loss: 2.061388
Current threshold: -149.6758
Global Scale Offset: 1.2103
Reward stats: mean=0.0164, std=0.1546, count=140
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 2.0614, Q2 Loss: 2.0614, Entropy: 0.0288, Mean TD Error: 2.1510, Threshold: -149.6758
tensor([ 0.0868,  0.5939,  0.5281,  0.6002, -0.1374,  0.4655,  0.8513,  1.0113,
         1.3283,  0.3498,  0.2773,  0.9540,  0.0081,  0.0438, -0.2250,  0.5887],
       device='cuda:1')
Original likelihood: -184.71640014648438
Adjusted likelihood: -184.71640014648438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.9009, -3.5073, -3.7641, -3.7874, -4.0424, -4.0728, -4.1294, -4.1392,
        -4.1920, -4.4024, -4.4599, -4.9441, -5.3647, -5.7118, -5.7467, -5.9894],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9009, -3.5073, -3.7641, -3.7874, -4.0424, -4.0728, -4.1294, -4.1392,
        -4.1920, -4.4024, -4.4599, -4.9441, -5.3647, -5.7118, -5.7467, -5.9894],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.4471
1 mode projection succeeded
New goal: tensor([ 0.0443,  0.5193,  0.5774,  0.6303, -0.0666,  0.4928,  0.8211,  0.9742,
         1.2725,  0.3293,  0.2298,  1.1089,  0.0060,  0.0132,  0.9348],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -126.69513702392578
Adjusted likelihood: -126.69513702392578
Likelihood residual: 0.0
Original likelihood: -78.83834838867188
Adjusted likelihood: -78.83834838867188
Likelihood residual: 0.0
{'index': 78.83834838867188, 'thumb_middle': 126.69513702392578}
Current yaw: tensor([ 0.0081,  0.0438, -0.2250], device='cuda:1')
4 index
tensor([ 0.0868,  0.5939,  0.5281,  0.6002, -0.1374,  0.4655,  0.8513,  1.0113,
         1.3283,  0.3498,  0.2773,  0.9540,  0.0081,  0.0438, -0.2250,  0.5887],
       device='cuda:1')
Solve time for step 1 12.0278293939773
Current ori: tensor([ 0.0081,  0.0438, -0.2250], device='cuda:1')
Middle force: tensor([0.5127, 0.5632, 0.5366, 0.5468], device='cuda:1')
Thumb force: tensor([0.5003, 0.6190, 0.5128, 0.6042], device='cuda:1')
tensor([ 9.0126e-02,  4.7534e-01,  5.1861e-01,  6.0120e-01, -1.4288e-01,
         4.7852e-01,  8.4862e-01,  1.0071e+00,  1.3912e+00,  2.6770e-01,
         2.1796e-01,  9.7485e-01, -1.5191e-03,  4.3633e-02, -2.4204e-01,
         2.3968e+00], device='cuda:1')
Solve time for step 2 4.635242204996757
Current ori: tensor([-0.0015,  0.0436, -0.2420], device='cuda:1')
Middle force: tensor([0.5604, 0.5340, 0.5438], device='cuda:1')
Thumb force: tensor([0.6118, 0.5114, 0.6003], device='cuda:1')
tensor([ 8.9832e-02,  4.6780e-01,  5.2494e-01,  6.0362e-01, -1.0885e-01,
         4.8410e-01,  8.6279e-01,  1.0196e+00,  1.3395e+00,  3.2903e-01,
         1.9137e-01,  1.0372e+00,  1.8864e-03,  1.9770e-02, -2.4594e-01,
         3.3534e+00], device='cuda:1')
Solve time for step 3 4.7800856760004535
Current ori: tensor([ 0.0019,  0.0198, -0.2459], device='cuda:1')
Middle force: tensor([0.5835, 0.5720], device='cuda:1')
Thumb force: tensor([0.5703, 0.5332], device='cuda:1')
tensor([ 0.0924,  0.4661,  0.5255,  0.6042, -0.0853,  0.5070,  0.8560,  1.0039,
         1.3294,  0.3347,  0.1653,  1.0567, -0.0039,  0.0044, -0.2418,  3.8882],
       device='cuda:1')
Solve time for step 4 4.564369961968623
Current ori: tensor([-0.0039,  0.0044, -0.2418], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5026], device='cuda:1')
Storing RECOVERY transition: reward=0.0122 (scaled=0.0122), steps=1
Reward stats updated: mean 0.0164 -> 0.0163, std: 0.1541
Collected 141 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8692, Q2 Loss=0.8692, Entropy=0.0003, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5692
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=20.1567, Q2 Loss=20.1567, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7737
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6978, Q2 Loss=0.6978, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4605
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.0285, Q2 Loss=2.0285, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6590
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=2.1787, Q2 Loss=2.1787, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9554

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.4%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.06s (18.1%)
Actor update: 0.14s (38.5%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 5.186208
Q2 loss: 5.186208
Current threshold: -149.6696
Global Scale Offset: 1.2324
Reward stats: mean=0.0163, std=0.1541, count=141
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.1862, Q2 Loss: 5.1862, Entropy: 0.0001, Mean TD Error: 2.0836, Threshold: -149.6696
Original likelihood: -55.1799430847168
Adjusted likelihood: -55.1799430847168
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0004,  0.0043, -0.2343], device='cuda:1')
5 turn
Sampling time 5.2224506250349805
tensor([ 4.4620e-02,  5.2419e-01,  5.7224e-01,  6.2663e-01, -8.5448e-02,
         5.0222e-01,  8.6017e-01,  1.0100e+00,  1.3152e+00,  3.5496e-01,
         1.6864e-01,  1.0736e+00, -3.5405e-04,  4.2659e-03, -2.3431e-01,
         3.9971e+00], device='cuda:1')
Original likelihood: -55.75379943847656
Adjusted likelihood: -55.75379943847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.837479579029605
Current ori: tensor([-0.0004,  0.0043, -0.2343], device='cuda:1')
Middle force: tensor([0.5711, 0.5811, 0.8581, 0.5441, 0.5026, 0.5462, 0.5885, 0.5791, 0.5169,
        0.5517, 0.6957, 0.5990], device='cuda:1')
Thumb force: tensor([0.5516, 0.5311, 0.5479, 0.7865, 0.5309, 1.0454, 0.5859, 0.5869, 0.5633,
        1.3552, 0.6074, 0.5823], device='cuda:1')
Index force: tensor([0.5042, 0.5885, 0.8745, 0.5487, 0.7384, 0.6387, 0.5864, 0.5761, 0.6272,
        0.5903, 0.5593, 0.5655], device='cuda:1')
Storing NORMAL transition: reward=-0.0002 (scaled=-0.0002), steps=1
Reward stats updated: mean 0.0163 -> 0.0162, std: 0.1535
Collected 142 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6059, Q2 Loss=0.6059, Entropy=0.0004, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2343
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7912, Q2 Loss=0.7912, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4613
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=9.8484, Q2 Loss=9.8484, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2965
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6468, Q2 Loss=0.6468, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6012
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=8.7887, Q2 Loss=8.7887, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8398

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.3%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.8%)
Actor update: 0.14s (38.5%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 4.136205
Q2 loss: 4.136205
Current threshold: -149.6659
Global Scale Offset: 1.2460
Reward stats: mean=0.0162, std=0.1535, count=142
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.1362, Q2 Loss: 4.1362, Entropy: 0.0001, Mean TD Error: 1.8866, Threshold: -149.6659
tensor([ 5.7509e-02,  4.3759e-01,  6.6069e-01,  7.0715e-01, -1.0015e-01,
         4.4748e-01,  9.3093e-01,  1.0398e+00,  1.2718e+00,  3.5442e-01,
         8.5475e-02,  1.1110e+00,  1.6190e-02, -1.2945e-04, -2.3431e-01,
         3.8850e+00], device='cuda:1')
Original likelihood: -125.93397521972656
Adjusted likelihood: -125.93397521972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.958966630976647
Current ori: tensor([ 1.6190e-02, -1.2945e-04, -2.3431e-01], device='cuda:1')
Middle force: tensor([0.5784, 0.8542, 0.5416, 0.5020, 0.5453, 0.5846, 0.5763, 0.5157, 0.5491,
        0.6932, 0.5959], device='cuda:1')
Thumb force: tensor([0.5286, 0.5452, 0.7743, 0.5294, 1.0237, 0.5818, 0.5832, 0.5542, 1.3324,
        0.6020, 0.5783], device='cuda:1')
Index force: tensor([0.5822, 0.8509, 0.5468, 0.7432, 0.6331, 0.5821, 0.5719, 0.6214, 0.5865,
        0.5557, 0.5622], device='cuda:1')
Storing NORMAL transition: reward=0.0100 (scaled=0.0100), steps=1
Reward stats updated: mean 0.0162 -> 0.0162, std: 0.1530
Collected 143 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6744, Q2 Loss=0.6744, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3498
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.3887, Q2 Loss=4.3887, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4527
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7297, Q2 Loss=0.7297, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6971
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5758, Q2 Loss=0.5758, Entropy=0.0044, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3112
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2831, Q2 Loss=1.2831, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9825

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (38.1%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 1.530344
Q2 loss: 1.530344
Current threshold: -149.6637
Global Scale Offset: 1.2549
Reward stats: mean=0.0162, std=0.1530, count=143
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.5303, Q2 Loss: 1.5303, Entropy: 0.0009, Mean TD Error: 1.1587, Threshold: -149.6637
tensor([ 0.0941,  0.4908,  0.6149,  0.7305, -0.0455,  0.4772,  0.9150,  1.0453,
         1.3978,  0.1347,  0.2249,  0.8759,  0.0097, -0.0232, -0.2447,  3.9588],
       device='cuda:1')
Original likelihood: -102.33936309814453
Adjusted likelihood: -102.33936309814453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.415562527021393
Current ori: tensor([ 0.0097, -0.0232, -0.2447], device='cuda:1')
Middle force: tensor([0.5289, 1.0151, 1.5159, 0.9464, 0.5534, 0.5010, 0.6625, 0.5704, 0.5414,
        0.5467], device='cuda:1')
Thumb force: tensor([0.5467, 1.2413, 1.4577, 0.8588, 0.5054, 0.5264, 0.5475, 0.5646, 0.5116,
        0.5784], device='cuda:1')
Index force: tensor([0.5264, 0.5797, 0.5189, 0.5307, 0.5530, 0.7423, 0.5212, 0.6053, 0.6053,
        0.6247], device='cuda:1')
Storing NORMAL transition: reward=0.0937 (scaled=0.0937), steps=1
Reward stats updated: mean 0.0162 -> 0.0167, std: 0.1526
Collected 144 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7143, Q2 Loss=0.7143, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4000
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.5437, Q2 Loss=3.5437, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4747
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7497, Q2 Loss=0.7497, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6194
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4763, Q2 Loss=0.4763, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2757
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8714, Q2 Loss=0.8714, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6814

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.1%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.6%)
Actor update: 0.15s (38.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.271102
Q2 loss: 1.271102
Current threshold: -149.6623
Global Scale Offset: 1.2612
Reward stats: mean=0.0167, std=0.1526, count=144
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2711, Q2 Loss: 1.2711, Entropy: 0.0000, Mean TD Error: 1.2902, Threshold: -149.6623
tensor([ 0.0767,  0.4454,  0.6545,  0.7373, -0.1790,  0.5002,  0.9756,  1.0053,
         1.4654,  0.4572,  0.1939,  0.6960,  0.0191, -0.0107, -0.3384,  4.0327],
       device='cuda:1')
Original likelihood: -167.8931884765625
Adjusted likelihood: -167.8931884765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.4759, -2.7237, -2.7609, -2.9539, -3.2342, -3.5023, -3.8103, -4.1230,
        -4.1800, -4.2283, -4.8385, -5.1380, -5.1611, -5.9668, -6.2788, -6.5010],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.4759, -2.7237, -2.7609, -2.9539, -3.2342, -3.5023, -3.8103, -4.1230,
        -4.1800, -4.2283, -4.8385, -5.1380, -5.1611, -5.9668, -6.2788, -6.5010],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.2423
1 mode projection succeeded
New goal: tensor([ 0.0385,  0.5439,  0.5389,  0.6280, -0.0737,  0.4901,  0.8532,  0.9148,
         1.2890,  0.2910,  0.2403,  1.0882,  0.0051,  0.0162,  0.8000],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0064]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -90.52251434326172
Adjusted likelihood: -90.52251434326172
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 90.52251434326172}
Current yaw: tensor([ 0.0191, -0.0107, -0.3384], device='cuda:1')
6 thumb_middle
tensor([ 0.0767,  0.4454,  0.6545,  0.7373, -0.1790,  0.5002,  0.9756,  1.0053,
         1.4654,  0.4572,  0.1939,  0.6960,  0.0191, -0.0107, -0.3384,  4.0327],
       device='cuda:1')
Solve time for step 1 9.9797011440387
Current ori: tensor([ 0.0191, -0.0107, -0.3384], device='cuda:1')
Index force: tensor([0.5875, 0.6178, 0.5934, 0.5892], device='cuda:1')
tensor([ 3.6851e-02,  4.9263e-01,  5.8179e-01,  6.8050e-01, -1.7462e-01,
         4.7763e-01,  8.4327e-01,  9.0936e-01,  1.2676e+00,  2.9971e-01,
         1.5722e-01,  9.8622e-01, -1.3732e-05,  1.0689e-02, -3.3836e-01,
         3.9454e+00], device='cuda:1')
Solve time for step 2 4.08575958898291
Current ori: tensor([-1.3732e-05,  1.0689e-02, -3.3836e-01], device='cuda:1')
Index force: tensor([0.6054, 0.5830, 0.5813], device='cuda:1')
tensor([ 0.0108,  0.5369,  0.5282,  0.6197, -0.1836,  0.4788,  0.8226,  0.8934,
         1.2508,  0.2764,  0.1624,  1.0459, -0.0167,  0.0254, -0.3384,  3.8781],
       device='cuda:1')
Solve time for step 3 3.7564711900195107
Current ori: tensor([-0.0167,  0.0254, -0.3384], device='cuda:1')
Index force: tensor([0.5675, 0.5693], device='cuda:1')
tensor([ 0.0164,  0.5377,  0.5311,  0.6214, -0.1804,  0.4796,  0.8194,  0.8955,
         1.2447,  0.2691,  0.1621,  1.0578, -0.0168,  0.0222, -0.3384,  3.8858],
       device='cuda:1')
Solve time for step 4 3.7751292909961194
Current ori: tensor([-0.0168,  0.0222, -0.3384], device='cuda:1')
Index force: tensor([0.5522], device='cuda:1')
Storing RECOVERY transition: reward=-0.0029 (scaled=-0.0010), steps=3
Reward stats updated: mean 0.0167 -> 0.0166, std: 0.1521
Collected 145 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9352, Q2 Loss=0.9352, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8322
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=0.5907, Q2 Loss=0.5907, Entropy=0.3462, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1137
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=3.2976, Q2 Loss=3.2976, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4755
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8817, Q2 Loss=0.8817, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7270
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0348, Q2 Loss=1.0348, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8653

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (18.9%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.06s (18.4%)
Actor update: 0.14s (40.3%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000413
Q1 loss: 1.348010
Q2 loss: 1.348010
Current threshold: -149.6564
Global Scale Offset: 1.2636
Reward stats: mean=0.0166, std=0.1521, count=145
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.3480, Q2 Loss: 1.3480, Entropy: 0.0692, Mean TD Error: 1.4028, Threshold: -149.6564
Original likelihood: -62.572479248046875
Adjusted likelihood: -62.572479248046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0103,  0.0192, -0.3355], device='cuda:1')
7 turn
Sampling time 5.207752211019397
tensor([ 0.0209,  0.5191,  0.5485,  0.6460, -0.1116,  0.5300,  0.8569,  0.9096,
         1.3084,  0.2923,  0.2152,  1.0864, -0.0103,  0.0192, -0.3355,  3.8902],
       device='cuda:1')
Original likelihood: -59.209835052490234
Adjusted likelihood: -59.209835052490234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.976395887031686
Current ori: tensor([-0.0103,  0.0192, -0.3355], device='cuda:1')
Middle force: tensor([1.0758, 1.0583, 0.5344, 1.1273, 1.7092, 1.0049, 0.5757, 0.7346, 0.5921,
        0.5604, 0.5435, 0.5531], device='cuda:1')
Thumb force: tensor([1.0011, 0.5948, 0.5698, 1.4317, 1.6934, 0.9458, 0.5084, 0.5715, 0.5883,
        0.5731, 1.1154, 0.5368], device='cuda:1')
Index force: tensor([0.5399, 0.6532, 0.5377, 0.6067, 0.5300, 0.5422, 0.5701, 0.5175, 0.5811,
        0.6226, 0.6378, 0.6884], device='cuda:1')
Storing NORMAL transition: reward=0.0141 (scaled=0.0141), steps=1
Reward stats updated: mean 0.0166 -> 0.0166, std: 0.1516
Collected 146 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9846, Q2 Loss=0.9846, Entropy=0.0008, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3686
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9099, Q2 Loss=0.9099, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6213
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8930, Q2 Loss=0.8930, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7699
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3579, Q2 Loss=1.3579, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3827
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6855, Q2 Loss=0.6855, Entropy=0.0008, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2431

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.7%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.07s (18.7%)
Actor update: 0.14s (37.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.966180
Q2 loss: 0.966180
Current threshold: -149.6520
Global Scale Offset: 1.2651
Reward stats: mean=0.0166, std=0.1516, count=146
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9662, Q2 Loss: 0.9662, Entropy: 0.0003, Mean TD Error: 0.6771, Threshold: -149.6520
tensor([-2.1655e-03,  4.4505e-01,  6.2240e-01,  6.5465e-01, -9.8714e-02,
         4.6937e-01,  8.6896e-01,  1.0751e+00,  1.4372e+00,  2.0502e-01,
         1.0249e-01,  8.4167e-01,  2.8179e-02,  9.5881e-03, -3.4993e-01,
         4.1412e+00], device='cuda:1')
Original likelihood: -159.23577880859375
Adjusted likelihood: -159.23577880859375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.6820, -3.1070, -3.2734, -3.4120, -3.4672, -3.4697, -3.6430, -3.7238,
        -3.9091, -4.0941, -4.1693, -4.3188, -4.8154, -5.4079, -5.9789, -9.1707],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.6820, -3.1070, -3.2734, -3.4120, -3.4672, -3.4697, -3.6430, -3.7238,
        -3.9091, -4.0941, -4.1693, -4.3188, -4.8154, -5.4079, -5.9789, -9.1707],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.2902
1 mode projection succeeded
New goal: tensor([ 0.0389,  0.5438,  0.5390,  0.6279, -0.0733,  0.4893,  0.8531,  0.9156,
         1.2890,  0.2900,  0.2405,  1.0900,  0.0052,  0.0162,  1.6557],
       device='cuda:1')
tensor([[0.0127]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -61.22174072265625
Adjusted likelihood: -61.22174072265625
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 61.22174072265625}
Current yaw: tensor([ 0.0282,  0.0096, -0.3499], device='cuda:1')
8 thumb_middle
tensor([-2.1655e-03,  4.4505e-01,  6.2240e-01,  6.5465e-01, -9.8714e-02,
         4.6937e-01,  8.6896e-01,  1.0751e+00,  1.4372e+00,  2.0502e-01,
         1.0249e-01,  8.4167e-01,  2.8179e-02,  9.5881e-03, -3.4993e-01,
         4.1412e+00], device='cuda:1')
Solve time for step 1 9.936017311993055
Current ori: tensor([ 0.0282,  0.0096, -0.3499], device='cuda:1')
Index force: tensor([0.5741, 0.5182, 0.5671, 0.5607], device='cuda:1')
tensor([ 1.6244e-02,  4.7242e-01,  5.8850e-01,  6.8008e-01, -1.4917e-01,
         4.7345e-01,  8.3274e-01,  9.1633e-01,  1.2653e+00,  2.6407e-01,
         1.4738e-01,  1.0143e+00,  2.5509e-02,  1.3506e-04, -3.4992e-01,
         4.1682e+00], device='cuda:1')
Solve time for step 2 4.102380628988612
Current ori: tensor([ 2.5509e-02,  1.3506e-04, -3.4992e-01], device='cuda:1')
Index force: tensor([0.5140, 0.5545, 0.5512], device='cuda:1')
tensor([ 1.3784e-02,  4.8444e-01,  5.7294e-01,  6.7294e-01, -1.5739e-01,
         4.9351e-01,  8.2195e-01,  8.8372e-01,  1.2381e+00,  2.4897e-01,
         1.6789e-01,  1.0519e+00,  2.1642e-02,  1.4191e-03, -3.4992e-01,
         4.1602e+00], device='cuda:1')
Solve time for step 3 3.7277003310155123
Current ori: tensor([ 0.0216,  0.0014, -0.3499], device='cuda:1')
Index force: tensor([0.5411, 0.5401], device='cuda:1')
tensor([ 0.0063,  0.5236,  0.5288,  0.6408, -0.1552,  0.4691,  0.8280,  0.9220,
         1.2349,  0.2705,  0.1621,  1.0471,  0.0086,  0.0052, -0.3499,  4.1293],
       device='cuda:1')
Solve time for step 4 3.5379800479859114
Current ori: tensor([ 0.0086,  0.0052, -0.3499], device='cuda:1')
Index force: tensor([0.5430], device='cuda:1')
Storing RECOVERY transition: reward=-0.0042 (scaled=-0.0042), steps=1
Reward stats updated: mean 0.0166 -> 0.0164, std: 0.1511
Collected 147 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.5317, Q2 Loss=0.5317, Entropy=0.3420, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6259
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.7164, Q2 Loss=1.7164, Entropy=0.0547, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7646
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5191, Q2 Loss=0.5191, Entropy=0.0046, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3205
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7809, Q2 Loss=0.7809, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2293
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7261, Q2 Loss=0.7261, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0869

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (19.5%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.07s (19.0%)
Actor update: 0.14s (39.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001697
Q1 loss: 0.854824
Q2 loss: 0.854824
Current threshold: -149.6714
Global Scale Offset: 1.2496
Reward stats: mean=0.0164, std=0.1511, count=147
----------------------------------------------
SAC Update - Actor Loss: -0.0017, Q1 Loss: 0.8548, Q2 Loss: 0.8548, Entropy: 0.0803, Mean TD Error: 0.6054, Threshold: -149.6714
Original likelihood: -51.27381896972656
Adjusted likelihood: -51.27381896972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0108,  0.0200, -0.3453], device='cuda:1')
9 turn
Sampling time 5.063284903997555
tensor([-0.0217,  0.5148,  0.5177,  0.6404, -0.0963,  0.4977,  0.8587,  0.9263,
         1.2971,  0.2985,  0.2390,  1.0833,  0.0108,  0.0200, -0.3453,  4.0954],
       device='cuda:1')
Original likelihood: -48.728450775146484
Adjusted likelihood: -48.728450775146484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.449974057963118
Current ori: tensor([ 0.0108,  0.0200, -0.3453], device='cuda:1')
Middle force: tensor([0.7902, 1.5644, 0.5017, 1.1238, 0.5361, 0.9293, 1.0358, 1.0849, 0.5796,
        0.5082, 0.5594, 0.6422], device='cuda:1')
Thumb force: tensor([0.9063, 0.7947, 0.5645, 1.3822, 1.0387, 0.9315, 1.2039, 0.7631, 0.6960,
        0.9385, 0.5238, 0.5228], device='cuda:1')
Index force: tensor([0.8491, 0.8745, 0.7107, 0.5710, 0.5352, 0.5285, 0.5199, 0.5382, 0.6059,
        0.6174, 0.5767, 0.5387], device='cuda:1')
Storing NORMAL transition: reward=0.1730 (scaled=0.1730), steps=1
Reward stats updated: mean 0.0164 -> 0.0175, std: 0.1511
Collected 148 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2484, Q2 Loss=1.2484, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9493
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5389, Q2 Loss=0.5389, Entropy=0.0525, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4262
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6237, Q2 Loss=0.6237, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7414
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=19.7610, Q2 Loss=19.7610, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3500
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9540, Q2 Loss=0.9540, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3861

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.7%)
Q1 update: 0.08s (19.1%)
Q2 update: 0.08s (19.4%)
Actor update: 0.15s (38.7%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000001
Q1 loss: 4.625209
Q2 loss: 4.625209
Current threshold: -149.6828
Global Scale Offset: 1.2422
Reward stats: mean=0.0175, std=0.1511, count=148
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.6252, Q2 Loss: 4.6252, Entropy: 0.0105, Mean TD Error: 1.5706, Threshold: -149.6828
tensor([-5.6426e-02,  4.3823e-01,  5.4828e-01,  7.2044e-01, -7.4604e-02,
         4.3523e-01,  9.4262e-01,  9.8765e-01,  1.2806e+00,  3.2964e-01,
         2.7500e-01,  9.6999e-01,  1.4161e-02,  3.7395e-03, -5.1817e-01,
         3.9231e+00], device='cuda:1')
Original likelihood: -75.27887725830078
Adjusted likelihood: -75.27887725830078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.05390532099409
Current ori: tensor([ 0.0142,  0.0037, -0.5182], device='cuda:1')
Middle force: tensor([1.5110, 0.5011, 1.1043, 0.5310, 0.9180, 1.0092, 1.0638, 0.5760, 0.5072,
        0.5623, 0.6344], device='cuda:1')
Thumb force: tensor([0.7564, 0.5521, 1.3390, 1.0146, 0.9007, 1.1735, 0.7441, 0.6804, 0.9106,
        0.5200, 0.5194], device='cuda:1')
Index force: tensor([0.8349, 0.6867, 0.5639, 0.5311, 0.5246, 0.5177, 0.5340, 0.5990, 0.6091,
        0.5658, 0.5351], device='cuda:1')
Storing NORMAL transition: reward=-0.0579 (scaled=-0.0579), steps=1
Reward stats updated: mean 0.0175 -> 0.0170, std: 0.1507
Collected 149 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.8295, Q2 Loss=0.8295, Entropy=0.3454, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5458
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6353, Q2 Loss=0.6353, Entropy=0.0041, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3632
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0642, Q2 Loss=1.0642, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9422
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.7556, Q2 Loss=1.7556, Entropy=0.0508, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7991
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6928, Q2 Loss=1.6928, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9743

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.9%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (17.5%)
Actor update: 0.14s (38.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001573
Q1 loss: 1.195482
Q2 loss: 1.195482
Current threshold: -149.6679
Global Scale Offset: 1.2302
Reward stats: mean=0.0170, std=0.1507, count=149
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 1.1955, Q2 Loss: 1.1955, Entropy: 0.0800, Mean TD Error: 1.3249, Threshold: -149.6679
tensor([ 0.0276,  0.5215,  0.5444,  0.6460, -0.0137,  0.5054,  0.8175,  1.0197,
         1.3273,  0.1624,  0.2915,  0.8913,  0.0145, -0.0182, -0.4606,  3.9950],
       device='cuda:1')
Original likelihood: -76.64128112792969
Adjusted likelihood: -76.64128112792969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.440332917030901
Current ori: tensor([ 0.0145, -0.0182, -0.4606], device='cuda:1')
Middle force: tensor([0.5004, 1.0894, 0.5278, 0.8971, 0.9836, 1.0379, 0.5696, 0.5062, 0.5543,
        0.6269], device='cuda:1')
Thumb force: tensor([0.5458, 1.3060, 0.9916, 0.8807, 1.1475, 0.7307, 0.6709, 0.8901, 0.5181,
        0.5170], device='cuda:1')
Index force: tensor([0.6866, 0.5588, 0.5281, 0.5228, 0.5160, 0.5317, 0.5945, 0.6042, 0.5656,
        0.5325], device='cuda:1')
Storing NORMAL transition: reward=0.1170 (scaled=0.1170), steps=1
Reward stats updated: mean 0.0170 -> 0.0177, std: 0.1504
Collected 150 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.6596, Q2 Loss=1.6596, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9711
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6776, Q2 Loss=0.6776, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3359
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=11.7034, Q2 Loss=11.7034, Entropy=0.0509, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7347
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.4190, Q2 Loss=1.4190, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9251
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0890, Q2 Loss=1.0890, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8266

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000042
Q1 loss: 3.309706
Q2 loss: 3.309706
Current threshold: -149.6578
Global Scale Offset: 1.2375
Reward stats: mean=0.0177, std=0.1504, count=150
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.3097, Q2 Loss: 3.3097, Entropy: 0.0102, Mean TD Error: 2.5587, Threshold: -149.6578
tensor([ 3.3648e-03,  4.4939e-01,  6.0993e-01,  6.8490e-01,  4.2455e-02,
         4.1593e-01,  1.0093e+00,  9.7251e-01,  1.3390e+00,  2.3596e-01,
         2.4598e-01,  8.4199e-01,  3.0548e-02, -5.5425e-02, -5.8388e-01,
         3.8011e+00], device='cuda:1')
Original likelihood: -166.38482666015625
Adjusted likelihood: -166.38482666015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.8665,  -3.9994,  -4.2818,  -4.3523,  -4.7167,  -4.9142,  -4.9629,
         -5.0739,  -5.2253,  -5.3613,  -5.3996,  -5.4704,  -6.2191,  -7.1984,
         -7.9837, -15.8685], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.8665,  -3.9994,  -4.2818,  -4.3523,  -4.7167,  -4.9142,  -4.9629,
         -5.0739,  -5.2253,  -5.3613,  -5.3996,  -5.4704,  -6.2191,  -7.1984,
         -7.9837, -15.8685], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.9309
1 mode projection succeeded
New goal: tensor([ 0.0530,  0.4618,  0.6475,  0.6598, -0.0208,  0.4863,  0.8311,  0.8982,
         1.3814,  0.0812,  0.3350,  0.8058,  0.0017,  0.0020, -0.6311],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -155.3306884765625
Adjusted likelihood: -155.3306884765625
Likelihood residual: 0.0
Original likelihood: -156.230224609375
Adjusted likelihood: -156.230224609375
Likelihood residual: 0.0
{'index': 156.230224609375, 'thumb_middle': 155.3306884765625}
Current yaw: tensor([ 0.0305, -0.0554, -0.5839], device='cuda:1')
10 thumb_middle
tensor([ 3.3648e-03,  4.4939e-01,  6.0993e-01,  6.8490e-01,  4.2455e-02,
         4.1593e-01,  1.0093e+00,  9.7251e-01,  1.3390e+00,  2.3596e-01,
         2.4598e-01,  8.4199e-01,  3.0548e-02, -5.5425e-02, -5.8388e-01,
         3.8011e+00], device='cuda:1')
Solve time for step 1 9.920797327999026
Current ori: tensor([ 0.0305, -0.0554, -0.5839], device='cuda:1')
Index force: tensor([0.6022, 0.6000, 0.6044, 0.5984], device='cuda:1')
tensor([-0.0713,  0.4817,  0.6456,  0.6621, -0.0826,  0.4721,  0.8353,  0.8903,
         1.3204,  0.0838,  0.2472,  0.7834,  0.0688, -0.1237, -0.5842,  4.1893],
       device='cuda:1')
Solve time for step 2 3.9684283519745804
Current ori: tensor([ 0.0688, -0.1237, -0.5842], device='cuda:1')
Index force: tensor([0.5863, 0.5953, 0.5882], device='cuda:1')
tensor([-0.0961,  0.5458,  0.6913,  0.6659, -0.0242,  0.5377,  0.8530,  0.9025,
         1.3019,  0.0483,  0.2096,  0.7544,  0.1714, -0.3112, -0.5842,  4.7765],
       device='cuda:1')
Solve time for step 3 3.9412731979973614
Current ori: tensor([ 0.1714, -0.3112, -0.5842], device='cuda:1')
Index force: tensor([0.5510, 0.5647], device='cuda:1')
tensor([-0.0157,  0.7267,  0.9254,  0.7779,  0.0901,  0.6236,  0.8894,  0.9118,
         1.2632,  0.0500,  0.1128,  0.7226,  0.1972, -0.3562, -0.6868,  4.8719],
       device='cuda:1')
Solve time for step 4 3.815546168014407
Current ori: tensor([ 0.1972, -0.3562, -0.6868], device='cuda:1')
Index force: tensor([0.5436], device='cuda:1')
Storing RECOVERY transition: reward=-0.1091 (scaled=-0.0364), steps=3
Reward stats updated: mean 0.0177 -> 0.0173, std: 0.1500
Collected 151 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6557, Q2 Loss=0.6557, Entropy=0.0042, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6255
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1435, Q2 Loss=1.1435, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9737
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5053, Q2 Loss=0.5053, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3090
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7235, Q2 Loss=0.7235, Entropy=0.0004, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4674
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5873, Q2 Loss=0.5873, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4597

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.1%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.06s (17.3%)
Actor update: 0.14s (38.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 0.723081
Q2 loss: 0.723081
Current threshold: -149.6513
Global Scale Offset: 1.2488
Reward stats: mean=0.0173, std=0.1500, count=151
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7231, Q2 Loss: 0.7231, Entropy: 0.0009, Mean TD Error: 0.5671, Threshold: -149.6513
Original likelihood: -1187.9088134765625
Adjusted likelihood: -1187.9088134765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 10
Loaded trajectory sampler
Current yaw: tensor([-0.0022,  0.0148, -0.0223], device='cuda:1')
Current yaw: tensor([-0.0022,  0.0148, -0.0223], device='cuda:1')
1 turn
Sampling time 5.4496633050148375
tensor([ 0.1325,  0.5956,  0.5705,  0.6070, -0.1060,  0.5115,  0.9452,  0.8556,
         1.2681,  0.2756,  0.2271,  1.1384, -0.0022,  0.0148, -0.0223,  0.1757],
       device='cuda:1')
Original likelihood: -107.90909576416016
Adjusted likelihood: -107.90909576416016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.149199139967095
Current ori: tensor([-0.0022,  0.0148, -0.0223], device='cuda:1')
Middle force: tensor([1.1849, 1.7736, 0.8323, 0.5297, 0.5681, 0.8984, 1.1491, 0.5121, 0.6985,
        0.8845, 0.8522, 0.4933], device='cuda:1')
Thumb force: tensor([0.8768, 1.3496, 0.5745, 0.5536, 0.5404, 1.2599, 0.6572, 0.5564, 0.6028,
        1.2155, 1.5914, 0.5547], device='cuda:1')
Index force: tensor([0.9312, 1.8290, 0.5664, 0.6012, 0.5915, 0.8133, 0.5438, 0.5912, 0.5971,
        0.5484, 0.6109, 0.7547], device='cuda:1')
Storing NORMAL transition: reward=0.0072 (scaled=0.0072), steps=1
Reward stats updated: mean 0.0173 -> 0.0172, std: 0.1495
Collected 152 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9652, Q2 Loss=0.9652, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5223
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6303, Q2 Loss=0.6303, Entropy=0.0540, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4303
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=1.8189, Q2 Loss=1.8189, Entropy=0.3445, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0137
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9639, Q2 Loss=0.9639, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5721
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.4430, Q2 Loss=1.4430, Entropy=0.0543, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6851

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.3%)
Q1 update: 0.06s (19.0%)
Q2 update: 0.06s (18.1%)
Actor update: 0.13s (37.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001597
Q1 loss: 1.164257
Q2 loss: 1.164257
Current threshold: -149.6335
Global Scale Offset: 1.2483
Reward stats: mean=0.0172, std=0.1495, count=152
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 1.1643, Q2 Loss: 1.1643, Entropy: 0.0906, Mean TD Error: 1.4447, Threshold: -149.6335
tensor([ 0.1116,  0.6330,  0.5158,  0.5714, -0.1212,  0.5428,  0.8746,  0.8874,
         1.2611,  0.3035,  0.2747,  1.0629, -0.0134,  0.0169, -0.0297,  0.2784],
       device='cuda:1')
Original likelihood: -88.87004852294922
Adjusted likelihood: -88.87004852294922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.7391093539772555
Current ori: tensor([-0.0134,  0.0169, -0.0297], device='cuda:1')
Middle force: tensor([1.5999, 0.7217, 0.5284, 0.6467, 0.5107, 0.9799, 0.5407, 0.5348, 0.6812,
        0.5179, 0.5016], device='cuda:1')
Thumb force: tensor([1.0901, 0.6997, 0.9768, 1.0656, 0.5724, 1.6868, 0.6849, 0.9251, 0.9476,
        0.5504, 0.5330], device='cuda:1')
Index force: tensor([0.5420, 0.5139, 0.5227, 0.6234, 0.6087, 0.8910, 0.6942, 0.5441, 0.5808,
        0.5695, 0.8501], device='cuda:1')
Storing NORMAL transition: reward=0.3471 (scaled=0.3471), steps=1
Reward stats updated: mean 0.0172 -> 0.0194, std: 0.1514
Collected 153 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7684, Q2 Loss=0.7684, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3272
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6506, Q2 Loss=0.6506, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1849
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6794, Q2 Loss=0.6794, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6419
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9351, Q2 Loss=0.9351, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5206
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6822, Q2 Loss=0.6822, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4915

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.5%)
Q1 update: 0.06s (17.5%)
Q2 update: 0.06s (17.8%)
Actor update: 0.12s (37.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.743138
Q2 loss: 0.743138
Current threshold: -149.6154
Global Scale Offset: 1.2478
Reward stats: mean=0.0194, std=0.1514, count=153
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7431, Q2 Loss: 0.7431, Entropy: 0.0000, Mean TD Error: 0.4332, Threshold: -149.6154
tensor([ 0.1936,  0.7409,  0.4452,  0.5924, -0.0232,  0.4942,  0.9617,  1.0399,
         1.2723,  0.4060,  0.2492,  0.8376, -0.0327, -0.0402, -0.3844,  0.7847],
       device='cuda:1')
Original likelihood: -184.80081176757812
Adjusted likelihood: -184.80081176757812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.8650,  -3.3260,  -3.4723,  -3.5534,  -3.6417,  -3.7689,  -4.0881,
         -4.3008,  -4.8731,  -5.0039,  -5.9513,  -7.2970,  -7.3274,  -7.7241,
         -8.8389, -10.3131], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.8650,  -3.3260,  -3.4723,  -3.5534,  -3.6417,  -3.7689,  -4.0881,
         -4.3008,  -4.8731,  -5.0039,  -5.9513,  -7.2970,  -7.3274,  -7.7241,
         -8.8389, -10.3131], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.3966
1 mode projection succeeded
New goal: tensor([ 0.0278,  0.5787,  0.4794,  0.6290, -0.0368,  0.4976,  0.8431,  0.8495,
         1.2506,  0.4934,  0.2344,  1.0208, -0.0136,  0.0091, -0.8269],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -190.05914306640625
Adjusted likelihood: -190.05914306640625
Likelihood residual: 0.0
Original likelihood: -153.059814453125
Adjusted likelihood: -153.059814453125
Likelihood residual: 0.0
{'index': 153.059814453125, 'thumb_middle': 190.05914306640625}
Current yaw: tensor([-0.0327, -0.0402, -0.3844], device='cuda:1')
2 index
tensor([ 0.1936,  0.7409,  0.4452,  0.5924, -0.0232,  0.4942,  0.9617,  1.0399,
         1.2723,  0.4060,  0.2492,  0.8376, -0.0327, -0.0402, -0.3844,  0.7847],
       device='cuda:1')
Solve time for step 1 11.077421675028745
Current ori: tensor([-0.0327, -0.0402, -0.3844], device='cuda:1')
Middle force: tensor([0.5201, 0.6126, 0.5870, 0.5477], device='cuda:1')
Thumb force: tensor([0.5341, 0.5407, 0.5835, 0.5500], device='cuda:1')
tensor([ 0.1047,  0.5488,  0.4231,  0.5971, -0.0137,  0.4856,  0.9935,  1.0151,
         1.2313,  0.4514,  0.2430,  0.8939, -0.0243, -0.0499, -0.3419,  3.4840],
       device='cuda:1')
Solve time for step 2 4.7331127600045875
Current ori: tensor([-0.0243, -0.0499, -0.3419], device='cuda:1')
Middle force: tensor([0.6082, 0.5812, 0.5427], device='cuda:1')
Thumb force: tensor([0.5339, 0.5780, 0.5458], device='cuda:1')
tensor([ 7.1503e-02,  5.3071e-01,  4.3011e-01,  5.9778e-01,  4.7717e-03,
         5.1001e-01,  9.8944e-01,  9.8912e-01,  1.2440e+00,  4.3713e-01,
         2.1625e-01,  8.8197e-01, -3.5799e-02, -6.3005e-02, -3.6550e-01,
         5.1170e+00], device='cuda:1')
Solve time for step 3 4.617496663995553
Current ori: tensor([-0.0358, -0.0630, -0.3655], device='cuda:1')
Middle force: tensor([0.5746, 0.5381], device='cuda:1')
Thumb force: tensor([0.5693, 0.5416], device='cuda:1')
tensor([ 6.1385e-02,  5.2871e-01,  4.2935e-01,  6.0094e-01, -4.1372e-03,
         5.3226e-01,  9.9496e-01,  9.8567e-01,  1.2526e+00,  4.2579e-01,
         2.0179e-01,  8.7720e-01, -4.2062e-02, -6.8165e-02, -3.7040e-01,
         5.7527e+00], device='cuda:1')
Solve time for step 4 4.454586367995944
Current ori: tensor([-0.0421, -0.0682, -0.3704], device='cuda:1')
Middle force: tensor([0.5389], device='cuda:1')
Thumb force: tensor([0.5618], device='cuda:1')
Storing RECOVERY transition: reward=-0.0150 (scaled=-0.0075), steps=2
Reward stats updated: mean 0.0194 -> 0.0192, std: 0.1509
Collected 154 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8335, Q2 Loss=0.8335, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3856
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8906, Q2 Loss=0.8906, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3788
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=2.2593, Q2 Loss=2.2593, Entropy=0.0556, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0020
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4949, Q2 Loss=0.4949, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0769
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8506, Q2 Loss=0.8506, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5574

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.1%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (18.5%)
Actor update: 0.13s (38.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000029
Q1 loss: 1.065777
Q2 loss: 1.065777
Current threshold: -149.6041
Global Scale Offset: 1.2545
Reward stats: mean=0.0192, std=0.1509, count=154
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0658, Q2 Loss: 1.0658, Entropy: 0.0111, Mean TD Error: 0.8801, Threshold: -149.6041
Original likelihood: -193.30172729492188
Adjusted likelihood: -193.30172729492188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.0352, -3.1862, -3.7179, -4.2105, -4.3036, -4.6095, -4.8798, -5.0699,
        -5.1565, -5.2005, -5.4930, -6.1161, -6.5507, -7.1324, -7.1696, -8.7113],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.0352, -3.1862, -3.7179, -4.2105, -4.3036, -4.6095, -4.8798, -5.0699,
        -5.1565, -5.2005, -5.4930, -6.1161, -6.5507, -7.1324, -7.1696, -8.7113],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2839
1 mode projection succeeded
New goal: tensor([ 0.0301,  0.4883,  0.5983,  0.6372, -0.0216,  0.5451,  0.7389,  1.0164,
         1.2851,  0.4063,  0.1701,  1.0387, -0.0264, -0.0082, -0.3149],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -121.51463317871094
Adjusted likelihood: -121.51463317871094
Likelihood residual: 0.0
Original likelihood: -167.9326171875
Adjusted likelihood: -167.9326171875
Likelihood residual: 0.0
{'index': 167.9326171875, 'thumb_middle': 121.51463317871094}
Current yaw: tensor([-0.0458, -0.0773, -0.3847], device='cuda:1')
3 thumb_middle
tensor([ 0.0391,  0.5908,  0.4762,  0.6249, -0.0140,  0.5599,  1.0048,  0.9870,
         1.2472,  0.4362,  0.1927,  0.8768, -0.0458, -0.0773, -0.3847,  5.8841],
       device='cuda:1')
Solve time for step 1 9.852203697024379
Current ori: tensor([-0.0458, -0.0773, -0.3847], device='cuda:1')
Index force: tensor([0.6091, 0.5986, 0.5573, 0.6044], device='cuda:1')
tensor([-0.0243,  0.5959,  0.5776,  0.6128, -0.0744,  0.5483,  0.7704,  1.0000,
         1.2237,  0.4049,  0.0706,  0.9677, -0.0865, -0.1286, -0.3768,  5.8361],
       device='cuda:1')
Solve time for step 2 3.819727119989693
Current ori: tensor([-0.0865, -0.1286, -0.3768], device='cuda:1')
Index force: tensor([0.5914, 0.5537, 0.5982], device='cuda:1')
tensor([-5.1809e-02,  6.2738e-01,  6.3087e-01,  6.2994e-01, -2.4675e-02,
         6.1146e-01,  7.6676e-01,  1.0142e+00,  1.2100e+00,  4.0681e-01,
        -2.8183e-03,  9.5701e-01, -1.2237e-01, -1.8052e-01, -3.5664e-01,
         5.8740e+00], device='cuda:1')
Solve time for step 3 3.7883752299821936
Current ori: tensor([-0.1224, -0.1805, -0.3566], device='cuda:1')
Index force: tensor([0.5793, 0.5821], device='cuda:1')
tensor([-7.1096e-02,  6.7342e-01,  6.7333e-01,  6.5872e-01, -5.0317e-03,
         6.9038e-01,  7.4691e-01,  9.7879e-01,  1.1934e+00,  4.1133e-01,
        -5.4956e-02,  9.3560e-01, -1.5316e-01, -2.2424e-01, -3.1950e-01,
         5.2509e+00], device='cuda:1')
Solve time for step 4 3.5928643860388547
Current ori: tensor([-0.1532, -0.2242, -0.3195], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-0.2317 (scaled=-0.1159), steps=2
Reward stats updated: mean 0.0192 -> 0.0183, std: 0.1508
Collected 155 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=8.8144, Q2 Loss=8.8144, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2891
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0017, Q2 Loss=1.0017, Entropy=0.0003, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4171
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8853, Q2 Loss=0.8853, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5142
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.8836, Q2 Loss=0.8836, Entropy=0.0670, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9944
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1262, Q2 Loss=1.1262, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7456

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (17.6%)
Actor update: 0.13s (38.4%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000061
Q1 loss: 2.542229
Q2 loss: 2.542229
Current threshold: -149.5963
Global Scale Offset: 1.2713
Reward stats: mean=0.0183, std=0.1508, count=155
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.5422, Q2 Loss: 2.5422, Entropy: 0.0135, Mean TD Error: 1.1921, Threshold: -149.5963
Original likelihood: -662.5423583984375
Adjusted likelihood: -662.5423583984375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 11
Loaded trajectory sampler
Current yaw: tensor([-0.0006,  0.0140, -0.0340], device='cuda:1')
Current yaw: tensor([-0.0006,  0.0140, -0.0340], device='cuda:1')
1 turn
Sampling time 5.170188745018095
tensor([ 1.5093e-01,  6.1654e-01,  5.4672e-01,  6.3208e-01, -1.2376e-01,
         5.0509e-01,  9.4592e-01,  9.1568e-01,  1.1885e+00,  2.6416e-01,
         3.2457e-01,  1.2011e+00, -5.9850e-04,  1.3961e-02, -3.3954e-02,
         3.5835e-01], device='cuda:1')
Original likelihood: -143.21026611328125
Adjusted likelihood: -143.21026611328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9983)
Solve time for step 1 14.201728642976377
Current ori: tensor([-0.0006,  0.0140, -0.0340], device='cuda:1')
Middle force: tensor([1.3727, 0.5132, 0.4981, 0.5219, 0.6244, 0.5940, 1.0974, 0.8123, 0.8276,
        0.6085, 0.5021, 0.5748], device='cuda:1')
Thumb force: tensor([1.8374, 2.0269, 1.4675, 0.5832, 1.1725, 0.7790, 1.4377, 0.5776, 0.7350,
        0.6867, 0.6639, 0.5655], device='cuda:1')
Index force: tensor([0.5648, 0.8833, 0.8972, 0.6421, 0.5746, 0.5538, 0.5925, 0.5290, 0.5820,
        0.5755, 0.5301, 0.6493], device='cuda:1')
Storing NORMAL transition: reward=0.1183 (scaled=0.1183), steps=1
Reward stats updated: mean 0.0183 -> 0.0190, std: 0.1505
Collected 156 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9332, Q2 Loss=0.9332, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8510
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.8903, Q2 Loss=1.8903, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6613
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=19.2772, Q2 Loss=19.2772, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4482
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7450, Q2 Loss=0.7450, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3430
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5746, Q2 Loss=0.5746, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4671

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (23.1%)
Q1 update: 0.06s (17.7%)
Q2 update: 0.06s (19.3%)
Actor update: 0.12s (36.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 4.684071
Q2 loss: 4.684071
Current threshold: -149.5908
Global Scale Offset: 1.2921
Reward stats: mean=0.0190, std=0.1505, count=156
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 4.6841, Q2 Loss: 4.6841, Entropy: 0.0000, Mean TD Error: 1.5541, Threshold: -149.5908
tensor([ 0.0799,  0.5984,  0.5336,  0.5410, -0.0259,  0.5095,  0.9097,  1.0036,
         1.2277,  0.3692,  0.2168,  1.0442, -0.0705, -0.0187, -0.1587,  1.3165],
       device='cuda:1')
Original likelihood: -127.77864074707031
Adjusted likelihood: -127.77864074707031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.630438407999463
Current ori: tensor([-0.0705, -0.0187, -0.1587], device='cuda:1')
Middle force: tensor([0.5143, 0.5048, 0.5215, 0.6486, 0.6205, 1.0732, 0.8239, 0.8497, 0.6184,
        0.5041, 0.6158], device='cuda:1')
Thumb force: tensor([1.9791, 1.3721, 0.5717, 1.1206, 0.7291, 1.4189, 0.5610, 0.7019, 0.6684,
        0.6405, 0.5333], device='cuda:1')
Index force: tensor([0.8435, 0.8274, 0.6422, 0.5721, 0.5496, 0.5890, 0.5284, 0.5769, 0.5704,
        0.5199, 0.6491], device='cuda:1')
Storing NORMAL transition: reward=0.0118 (scaled=0.0118), steps=1
Reward stats updated: mean 0.0190 -> 0.0189, std: 0.1500
Collected 157 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.9765, Q2 Loss=1.9765, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7037
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.4934, Q2 Loss=0.4934, Entropy=0.0069, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3476
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=5.4074, Q2 Loss=5.4074, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8876
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1411, Q2 Loss=1.1411, Entropy=0.0071, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6729
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7375, Q2 Loss=0.7375, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4370

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.6%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (37.9%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000004
Q1 loss: 1.951181
Q2 loss: 1.951181
Current threshold: -149.5874
Global Scale Offset: 1.3061
Reward stats: mean=0.0189, std=0.1500, count=157
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.9512, Q2 Loss: 1.9512, Entropy: 0.0028, Mean TD Error: 1.6098, Threshold: -149.5874
tensor([ 0.2542,  0.6948,  0.5218,  0.6906,  0.0428,  0.6147,  0.8238,  0.9990,
         1.3201,  0.3083,  0.0405,  1.0230, -0.0898, -0.0716, -0.1810,  0.6723],
       device='cuda:1')
Original likelihood: -229.92108154296875
Adjusted likelihood: -229.92108154296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -8.2022, -10.1114, -13.3021, -15.4489, -16.8584, -22.6815, -33.1653,
        -38.2662, -40.0720, -40.5409, -41.4494, -43.5452, -43.9328, -46.2461,
        -48.0965, -48.7324], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -8.2022, -10.1114, -13.3021, -15.4489, -16.8584, -22.6815, -33.1653,
        -38.2662, -40.0720, -40.5409, -41.4494, -43.5452, -43.9328, -46.2461,
        -48.0965, -48.7324], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -31.9157
1 mode projection succeeded
New goal: tensor([ 0.0325,  0.4907,  0.5972,  0.6355, -0.0204,  0.5476,  0.7372,  1.0143,
         1.2859,  0.4049,  0.1699,  1.0343, -0.0290, -0.0088, -1.1085],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -208.26727294921875
Adjusted likelihood: -208.26727294921875
Likelihood residual: 0.0
Original likelihood: -232.048583984375
Adjusted likelihood: -232.048583984375
Likelihood residual: 0.0
{'index': 232.048583984375, 'thumb_middle': 208.26727294921875}
Current yaw: tensor([-0.0898, -0.0716, -0.1810], device='cuda:1')
2 thumb_middle
tensor([ 0.2542,  0.6948,  0.5218,  0.6906,  0.0428,  0.6147,  0.8238,  0.9990,
         1.3201,  0.3083,  0.0405,  1.0230, -0.0898, -0.0716, -0.1810,  0.6723],
       device='cuda:1')
Solve time for step 1 9.300454929994885
Current ori: tensor([-0.0898, -0.0716, -0.1810], device='cuda:1')
Index force: tensor([0.7079, 0.6605, 0.6004, 0.5002], device='cuda:1')
tensor([ 0.2120,  0.6011,  0.6127,  0.6650, -0.0702,  0.5521,  0.7393,  1.0000,
         1.2406,  0.3703,  0.0616,  0.9855, -0.0769, -0.0608, -0.1810,  0.8457],
       device='cuda:1')
Solve time for step 2 3.790754346002359
Current ori: tensor([-0.0769, -0.0608, -0.1810], device='cuda:1')
Index force: tensor([0.6726, 0.6051, 0.5001], device='cuda:1')
tensor([ 0.1655,  0.5331,  0.6559,  0.6582, -0.0913,  0.5487,  0.7225,  0.9991,
         1.2464,  0.3890,  0.0712,  0.9862, -0.0653, -0.0384, -0.1810,  0.8661],
       device='cuda:1')
Solve time for step 3 3.6040547430166043
Current ori: tensor([-0.0653, -0.0384, -0.1810], device='cuda:1')
Index force: tensor([0.5984, 0.5000], device='cuda:1')
tensor([ 0.1265,  0.4724,  0.6753,  0.7019, -0.1168,  0.5319,  0.7237,  1.0115,
         1.2602,  0.3928,  0.0731,  1.0033, -0.0468, -0.0199, -0.1810,  0.9823],
       device='cuda:1')
Solve time for step 4 3.5091741870273836
Current ori: tensor([-0.0468, -0.0199, -0.1810], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0194 (scaled=0.0097), steps=2
Reward stats updated: mean 0.0189 -> 0.0189, std: 0.1496
Collected 158 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5301, Q2 Loss=0.5301, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3949
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.8892, Q2 Loss=0.8892, Entropy=0.0739, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6538
SAC Update 3/5: Actor Loss=-0.0011, Q1 Loss=1.3543, Q2 Loss=1.3543, Entropy=0.1711, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9517
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9374, Q2 Loss=0.9374, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4669
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2552, Q2 Loss=1.2552, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3979

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.3%)
Q1 update: 0.07s (19.3%)
Q2 update: 0.06s (18.4%)
Actor update: 0.13s (36.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000267
Q1 loss: 0.993232
Q2 loss: 0.993232
Current threshold: -149.5811
Global Scale Offset: 1.3518
Reward stats: mean=0.0189, std=0.1496, count=158
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.9932, Q2 Loss: 0.9932, Entropy: 0.0490, Mean TD Error: 1.1730, Threshold: -149.5811
Original likelihood: -88.67650604248047
Adjusted likelihood: -88.67650604248047
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0486, -0.0196, -0.1869], device='cuda:1')
3 turn
Sampling time 5.1557485579978675
tensor([ 0.1163,  0.4793,  0.6581,  0.6972, -0.0414,  0.5883,  0.7580,  1.0112,
         1.2950,  0.4129,  0.1377,  1.0278, -0.0486, -0.0196, -0.1869,  1.0128],
       device='cuda:1')
Original likelihood: -89.15510559082031
Adjusted likelihood: -89.15510559082031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.42188368999632
Current ori: tensor([-0.0486, -0.0196, -0.1869], device='cuda:1')
Middle force: tensor([0.5705, 0.5562, 1.3149, 0.5927, 0.6435, 0.5109, 1.5121, 0.5691, 0.9555,
        0.5348, 0.5555, 0.6808], device='cuda:1')
Thumb force: tensor([0.6162, 1.1222, 1.0358, 1.1428, 0.5498, 0.6608, 0.5686, 0.5916, 0.5108,
        0.6411, 0.5555, 1.0180], device='cuda:1')
Index force: tensor([0.6574, 0.5224, 1.4552, 0.5921, 0.6301, 0.6006, 0.6056, 0.5994, 0.5136,
        0.6798, 0.5756, 0.6221], device='cuda:1')
Storing NORMAL transition: reward=0.1114 (scaled=0.1114), steps=1
Reward stats updated: mean 0.0189 -> 0.0195, std: 0.1493
Collected 159 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2078, Q2 Loss=1.2078, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4352
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.9881, Q2 Loss=3.9881, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7249
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9383, Q2 Loss=0.9383, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4253
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=8.8872, Q2 Loss=8.8872, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4697
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=8.5926, Q2 Loss=8.5926, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9095

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (22.1%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.3%)
Actor update: 0.13s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 4.722804
Q2 loss: 4.722804
Current threshold: -149.5755
Global Scale Offset: 1.3952
Reward stats: mean=0.0195, std=0.1493, count=159
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.7228, Q2 Loss: 4.7228, Entropy: 0.0000, Mean TD Error: 3.5929, Threshold: -149.5755
tensor([ 0.1641,  0.3865,  0.7376,  0.8593,  0.0390,  0.5801,  0.7972,  1.0833,
         1.3812,  0.2230, -0.0144,  1.1116, -0.0366, -0.0686, -0.3031,  0.8343],
       device='cuda:1')
Original likelihood: -150.5447998046875
Adjusted likelihood: -150.5447998046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3385)
State is out of distribution
Final likelihood: tensor([ -3.4554,  -3.6660,  -3.9999,  -4.9468,  -4.9984,  -5.3360,  -6.1992,
         -6.2597,  -6.7121,  -8.6353, -10.0449, -11.4484, -11.8742, -12.1013,
        -14.3789, -15.8338], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.4554,  -3.6660,  -3.9999,  -4.9468,  -4.9984,  -5.3360,  -6.1992,
         -6.2597,  -6.7121,  -8.6353, -10.0449, -11.4484, -11.8742, -12.1013,
        -14.3789, -15.8338], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -8.1181
1 mode projection succeeded
New goal: tensor([ 0.0878,  0.4358,  0.7557,  0.5703, -0.0142,  0.5480,  0.7151,  1.0612,
         1.3043,  0.2706,  0.2161,  0.9827, -0.0222, -0.0108, -1.2115],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -216.80441284179688
Adjusted likelihood: -216.80441284179688
Likelihood residual: 0.0
Original likelihood: -164.11715698242188
Adjusted likelihood: -164.11715698242188
Likelihood residual: 0.0
{'index': 164.11715698242188, 'thumb_middle': 216.80441284179688}
Current yaw: tensor([-0.0366, -0.0686, -0.3031], device='cuda:1')
4 index
tensor([ 0.1641,  0.3865,  0.7376,  0.8593,  0.0390,  0.5801,  0.7972,  1.0833,
         1.3812,  0.2230, -0.0144,  1.1116, -0.0366, -0.0686, -0.3031,  0.8343],
       device='cuda:1')
Solve time for step 1 11.035255134047475
Current ori: tensor([-0.0366, -0.0686, -0.3031], device='cuda:1')
Middle force: tensor([0.5006, 0.5020, 0.5006, 0.5104], device='cuda:1')
Thumb force: tensor([0.6009, 0.6287, 0.6848, 0.5271], device='cuda:1')
tensor([ 0.1417,  0.3764,  0.7010,  0.6001,  0.0345,  0.5946,  0.7723,  1.0838,
         1.3731,  0.2569,  0.0208,  1.0426, -0.0486, -0.0648, -0.3432,  2.6466],
       device='cuda:1')
Solve time for step 2 4.467233998002484
Current ori: tensor([-0.0486, -0.0648, -0.3432], device='cuda:1')
Middle force: tensor([0.5019, 0.5003, 0.5073], device='cuda:1')
Thumb force: tensor([0.6210, 0.6897, 0.5258], device='cuda:1')
tensor([ 0.1279,  0.3843,  0.6998,  0.5498,  0.0182,  0.5906,  0.7619,  1.0855,
         1.3642,  0.2878,  0.0538,  1.0143, -0.0505, -0.0524, -0.3411,  3.8810],
       device='cuda:1')
Solve time for step 3 4.364959106023889
Current ori: tensor([-0.0505, -0.0524, -0.3411], device='cuda:1')
Middle force: tensor([0.5002, 0.5050], device='cuda:1')
Thumb force: tensor([0.6824, 0.5240], device='cuda:1')
tensor([ 1.2440e-01,  3.7921e-01,  7.0360e-01,  5.4098e-01,  1.6950e-03,
         5.8655e-01,  7.4989e-01,  1.0895e+00,  1.3501e+00,  3.2397e-01,
         9.0083e-02,  9.8759e-01, -5.1304e-02, -4.0544e-02, -3.3270e-01,
         4.3630e+00], device='cuda:1')
Solve time for step 4 4.1926349609857425
Current ori: tensor([-0.0513, -0.0405, -0.3327], device='cuda:1')
Middle force: tensor([0.5060], device='cuda:1')
Thumb force: tensor([0.5603], device='cuda:1')
Storing RECOVERY transition: reward=0.0241 (scaled=0.0241), steps=1
Reward stats updated: mean 0.0195 -> 0.0195, std: 0.1488
Collected 160 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6584, Q2 Loss=0.6584, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2527
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.5112, Q2 Loss=3.5112, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6806
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=4.7614, Q2 Loss=4.7614, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8669
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8008, Q2 Loss=0.8008, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6927
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5207, Q2 Loss=0.5207, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3714

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.0%)
Q1 update: 0.07s (18.2%)
Q2 update: 0.06s (17.6%)
Actor update: 0.14s (38.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 2.050504
Q2 loss: 2.050504
Current threshold: -149.5722
Global Scale Offset: 1.4216
Reward stats: mean=0.0195, std=0.1488, count=160
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 2.0505, Q2 Loss: 2.0505, Entropy: 0.0000, Mean TD Error: 2.1729, Threshold: -149.5722
Original likelihood: -115.66952514648438
Adjusted likelihood: -115.66952514648438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0507, -0.0377, -0.3250], device='cuda:1')
5 turn
Sampling time 5.247777829004917
tensor([ 0.0835,  0.4371,  0.7443,  0.5639, -0.0098,  0.5889,  0.7538,  1.0868,
         1.3521,  0.3209,  0.0923,  0.9881, -0.0507, -0.0377, -0.3250,  4.3859],
       device='cuda:1')
Original likelihood: -116.66239166259766
Adjusted likelihood: -116.66239166259766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.845721528981812
Current ori: tensor([-0.0507, -0.0377, -0.3250], device='cuda:1')
Middle force: tensor([0.6034, 0.5628, 1.4272, 0.6475, 0.6782, 0.7874, 0.6490, 0.6487, 0.8896,
        0.5731, 0.6312, 0.5442], device='cuda:1')
Thumb force: tensor([0.6108, 1.1398, 0.9683, 1.1169, 0.5451, 0.5739, 0.5810, 0.5700, 0.9199,
        0.7727, 0.6633, 0.7070], device='cuda:1')
Index force: tensor([0.6288, 0.5217, 1.4226, 0.6129, 0.6028, 0.6374, 0.5955, 0.5980, 0.5499,
        0.5766, 0.5895, 0.5705], device='cuda:1')
Storing NORMAL transition: reward=-0.0186 (scaled=-0.0186), steps=1
Reward stats updated: mean 0.0195 -> 0.0192, std: 0.1484
Collected 161 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.7202, Q2 Loss=0.7202, Entropy=0.3442, Time=0.11sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2385
SAC Update 2/5: Actor Loss=-0.0042, Q1 Loss=18.9477, Q2 Loss=18.9477, Entropy=0.3207, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.4469
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5517, Q2 Loss=0.5517, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2705
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8684, Q2 Loss=0.8684, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4595
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5377, Q2 Loss=0.5377, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6030

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.6%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (37.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002424
Q1 loss: 4.325145
Q2 loss: 4.325145
Current threshold: -149.6002
Global Scale Offset: 1.4501
Reward stats: mean=0.0192, std=0.1484, count=161
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 4.3251, Q2 Loss: 4.3251, Entropy: 0.1330, Mean TD Error: 1.2037, Threshold: -149.6002
tensor([ 0.0505,  0.4433,  0.6777,  0.6207, -0.0273,  0.5833,  0.7424,  1.0943,
         1.3787,  0.2739,  0.0911,  0.9916, -0.0452, -0.0273, -0.3052,  4.4888],
       device='cuda:1')
Original likelihood: -94.91217803955078
Adjusted likelihood: -94.91217803955078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.104579295031726
Current ori: tensor([-0.0452, -0.0273, -0.3052], device='cuda:1')
Middle force: tensor([0.5601, 1.4078, 0.6402, 0.6820, 0.7810, 0.6473, 0.6484, 0.8865, 0.5724,
        0.6338, 0.5436], device='cuda:1')
Thumb force: tensor([1.1200, 0.9530, 1.0989, 0.5421, 0.5718, 0.5781, 0.5667, 0.9078, 0.7647,
        0.6572, 0.7003], device='cuda:1')
Index force: tensor([0.5207, 1.3940, 0.6117, 0.5985, 0.6330, 0.5920, 0.5949, 0.5471, 0.5734,
        0.5833, 0.5679], device='cuda:1')
Storing NORMAL transition: reward=-0.0443 (scaled=-0.0443), steps=1
Reward stats updated: mean 0.0192 -> 0.0189, std: 0.1480
Collected 162 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=3.4606, Q2 Loss=3.4606, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4539
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.9837, Q2 Loss=1.9837, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5339
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8408, Q2 Loss=0.8408, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2228
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2792, Q2 Loss=1.2792, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9790
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=1.1282, Q2 Loss=1.1282, Entropy=0.0920, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7834

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.5%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (36.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000075
Q1 loss: 1.738500
Q2 loss: 1.738500
Current threshold: -149.6183
Global Scale Offset: 1.4787
Reward stats: mean=0.0189, std=0.1480, count=162
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.7385, Q2 Loss: 1.7385, Entropy: 0.0184, Mean TD Error: 1.9946, Threshold: -149.6183
tensor([ 3.1162e-03,  3.7886e-01,  7.1061e-01,  6.5950e-01, -2.0539e-01,
         6.1402e-01,  5.9995e-01,  1.1482e+00,  1.4415e+00,  2.8994e-01,
         1.6492e-01,  9.8071e-01, -3.4978e-02,  7.6864e-02, -2.6442e-01,
         3.5491e+00], device='cuda:1')
Original likelihood: -209.8201904296875
Adjusted likelihood: -209.8201904296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.8996,  -4.3003,  -4.7902,  -4.8556,  -5.7320,  -6.2909,  -6.5286,
         -6.5682,  -7.5470,  -7.6500,  -8.5507,  -8.7117,  -9.0933, -10.7942,
        -12.4079, -15.6377], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.8996,  -4.3003,  -4.7902,  -4.8556,  -5.7320,  -6.2909,  -6.5286,
         -6.5682,  -7.5470,  -7.6500,  -8.5507,  -8.7117,  -9.0933, -10.7942,
        -12.4079, -15.6377], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.7099
1 mode projection succeeded
New goal: tensor([ 3.7025e-02,  4.9245e-01,  6.3113e-01,  5.8496e-01, -2.8503e-02,
         4.7052e-01,  8.1497e-01,  9.1680e-01,  1.2732e+00,  3.0740e-01,
         2.1882e-01,  1.1458e+00, -9.9960e-04,  1.3326e-02,  1.2718e+00],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -157.46542358398438
Adjusted likelihood: -157.46542358398438
Likelihood residual: 0.0
Original likelihood: -108.13385009765625
Adjusted likelihood: -108.13385009765625
Likelihood residual: 0.0
{'index': 108.13385009765625, 'thumb_middle': 157.46542358398438}
Current yaw: tensor([-0.0350,  0.0769, -0.2644], device='cuda:1')
6 index
tensor([ 3.1162e-03,  3.7886e-01,  7.1061e-01,  6.5950e-01, -2.0539e-01,
         6.1402e-01,  5.9995e-01,  1.1482e+00,  1.4415e+00,  2.8994e-01,
         1.6492e-01,  9.8071e-01, -3.4978e-02,  7.6864e-02, -2.6442e-01,
         3.5491e+00], device='cuda:1')
Solve time for step 1 11.051707122998778
Current ori: tensor([-0.0350,  0.0769, -0.2644], device='cuda:1')
Middle force: tensor([0.6232, 0.5828, 0.5753, 0.5301], device='cuda:1')
Thumb force: tensor([0.5400, 0.6550, 0.5799, 0.5356], device='cuda:1')
tensor([ 0.0654,  0.4120,  0.5892,  0.5696, -0.1755,  0.5352,  0.8091,  0.9894,
         1.4063,  0.3309,  0.1496,  1.0161, -0.0310,  0.0549, -0.2816,  5.0024],
       device='cuda:1')
Solve time for step 2 4.469811758026481
Current ori: tensor([-0.0310,  0.0549, -0.2816], device='cuda:1')
Middle force: tensor([0.5801, 0.5730, 0.5279], device='cuda:1')
Thumb force: tensor([0.6478, 0.5757, 0.5325], device='cuda:1')
tensor([ 0.0749,  0.4295,  0.5782,  0.5592, -0.1440,  0.5189,  0.8656,  0.9728,
         1.3773,  0.3561,  0.1106,  1.0890, -0.0233,  0.0309, -0.2788,  6.0442],
       device='cuda:1')
Solve time for step 3 4.708405932004098
Current ori: tensor([-0.0233,  0.0309, -0.2788], device='cuda:1')
Middle force: tensor([0.5077, 0.5181], device='cuda:1')
Thumb force: tensor([0.5744, 0.5869], device='cuda:1')
tensor([ 0.0765,  0.4320,  0.5762,  0.5578, -0.1401,  0.5161,  0.8775,  0.9722,
         1.3619,  0.3832,  0.1024,  1.1142, -0.0226,  0.0267, -0.2861, -5.6925],
       device='cuda:1')
Solve time for step 4 4.232585935969837
Current ori: tensor([-0.0226,  0.0267, -0.2861], device='cuda:1')
Middle force: tensor([0.5546], device='cuda:1')
Thumb force: tensor([0.5155], device='cuda:1')
Storing RECOVERY transition: reward=0.0104 (scaled=0.0052), steps=2
Reward stats updated: mean 0.0189 -> 0.0188, std: 0.1475
Collected 163 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9254, Q2 Loss=0.9254, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6345
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=1.1011, Q2 Loss=1.1011, Entropy=0.0937, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7893
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0987, Q2 Loss=1.0987, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8501
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9066, Q2 Loss=0.9066, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7378
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0957, Q2 Loss=1.0957, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8688

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.9%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (39.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000073
Q1 loss: 1.025487
Q2 loss: 1.025487
Current threshold: -149.6264
Global Scale Offset: 1.5311
Reward stats: mean=0.0188, std=0.1475, count=163
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0255, Q2 Loss: 1.0255, Entropy: 0.0187, Mean TD Error: 0.7761, Threshold: -149.6264
Original likelihood: -124.19685363769531
Adjusted likelihood: -124.19685363769531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0231,  0.0259, -0.2698], device='cuda:1')
7 turn
Sampling time 5.073650923965033
tensor([ 0.0285,  0.4956,  0.6207,  0.5799, -0.1391,  0.5212,  0.8756,  0.9632,
         1.3573,  0.3882,  0.1023,  1.1201, -0.0231,  0.0259, -0.2698, -5.4942],
       device='cuda:1')
Original likelihood: -117.49583435058594
Adjusted likelihood: -117.49583435058594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.742407702025957
Current ori: tensor([-0.0231,  0.0259, -0.2698], device='cuda:1')
Middle force: tensor([1.0167, 1.1351, 0.9314, 0.9718, 0.5120, 0.5095, 0.6159, 0.5137, 0.5932,
        0.5392, 0.5003, 0.5742], device='cuda:1')
Thumb force: tensor([0.6494, 0.7332, 1.0416, 0.5529, 0.8219, 1.7856, 0.5477, 0.5797, 0.6074,
        0.5875, 0.5718, 0.6082], device='cuda:1')
Index force: tensor([0.9477, 0.7883, 0.5587, 0.7573, 0.6484, 0.8943, 0.7269, 0.7340, 0.6296,
        0.5777, 0.5544, 0.6710], device='cuda:1')
Storing NORMAL transition: reward=0.0710 (scaled=0.0710), steps=1
Reward stats updated: mean 0.0188 -> 0.0191, std: 0.1472
Collected 164 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8975, Q2 Loss=0.8975, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5463
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6059, Q2 Loss=0.6059, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4098
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5191, Q2 Loss=0.5191, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1037
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6629, Q2 Loss=0.6629, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5275
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=5.2593, Q2 Loss=5.2593, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0171

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.1%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.588962
Q2 loss: 1.588962
Current threshold: -149.6309
Global Scale Offset: 1.5666
Reward stats: mean=0.0191, std=0.1472, count=164
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.5890, Q2 Loss: 1.5890, Entropy: 0.0000, Mean TD Error: 1.3209, Threshold: -149.6309
tensor([ 0.0464,  0.4701,  0.6443,  0.6329, -0.1221,  0.4949,  0.9024,  1.0261,
         1.3579,  0.3942,  0.1135,  1.0722, -0.0123,  0.0123, -0.3400, -5.3885],
       device='cuda:1')
Original likelihood: -103.47747802734375
Adjusted likelihood: -103.47747802734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.851338606036734
Current ori: tensor([-0.0123,  0.0123, -0.3400], device='cuda:1')
Middle force: tensor([1.1254, 0.9336, 0.9668, 0.5122, 0.5078, 0.6262, 0.5138, 0.5936, 0.5403,
        0.5003, 0.5820], device='cuda:1')
Thumb force: tensor([0.7160, 1.0194, 0.5501, 0.8098, 1.7510, 0.5397, 0.5724, 0.6029, 0.5826,
        0.5690, 0.5957], device='cuda:1')
Index force: tensor([0.7777, 0.5560, 0.7492, 0.6421, 0.9042, 0.7212, 0.7314, 0.6244, 0.5741,
        0.5527, 0.6621], device='cuda:1')
Storing NORMAL transition: reward=-0.0392 (scaled=-0.0392), steps=1
Reward stats updated: mean 0.0191 -> 0.0187, std: 0.1468
Collected 165 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.8066, Q2 Loss=1.8066, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6929
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.8687, Q2 Loss=1.8687, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7020
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9233, Q2 Loss=0.9233, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7840
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8805, Q2 Loss=0.8805, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7621
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0518, Q2 Loss=1.0518, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4988

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.2%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (17.3%)
Actor update: 0.13s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.306181
Q2 loss: 1.306181
Current threshold: -149.6335
Global Scale Offset: 1.5881
Reward stats: mean=0.0187, std=0.1468, count=165
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.3062, Q2 Loss: 1.3062, Entropy: 0.0000, Mean TD Error: 1.0880, Threshold: -149.6335
tensor([-0.0706,  0.3167,  0.7505,  0.6433, -0.1560,  0.4519,  0.8546,  0.9322,
         1.3671,  0.2866,  0.2242,  0.9719,  0.0205,  0.0633, -0.3050, -5.5548],
       device='cuda:1')
Original likelihood: -212.05471801757812
Adjusted likelihood: -212.05471801757812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -2.8652,  -3.0371,  -5.0702,  -5.2946,  -5.3741,  -5.5139,  -5.6643,
         -6.2154,  -6.3258,  -6.9053,  -7.2303,  -8.0890,  -8.7634,  -9.3835,
        -16.2346, -21.9744], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.8652,  -3.0371,  -5.0702,  -5.2946,  -5.3741,  -5.5139,  -5.6643,
         -6.2154,  -6.3258,  -6.9053,  -7.2303,  -8.0890,  -8.7634,  -9.3835,
        -16.2346, -21.9744], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.7463
1 mode projection succeeded
New goal: tensor([ 0.0257,  0.5189,  0.5668,  0.6182, -0.0564,  0.4756,  0.8303,  0.9544,
         1.2796,  0.2565,  0.2103,  1.2032,  0.0050,  0.0150, -1.8106],
       device='cuda:1')
tensor([[0.0077]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -117.57807922363281
Adjusted likelihood: -117.57807922363281
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 117.57807922363281}
Current yaw: tensor([ 0.0205,  0.0633, -0.3050], device='cuda:1')
8 thumb_middle
tensor([-0.0706,  0.3167,  0.7505,  0.6433, -0.1560,  0.4519,  0.8546,  0.9322,
         1.3671,  0.2866,  0.2242,  0.9719,  0.0205,  0.0633, -0.3050, -5.5548],
       device='cuda:1')
Solve time for step 1 9.563689805974718
Current ori: tensor([ 0.0205,  0.0633, -0.3050], device='cuda:1')
Index force: tensor([0.5001, 0.5477, 0.7017, 0.6212], device='cuda:1')
tensor([-0.0553,  0.3599,  0.6557,  0.7437, -0.2061,  0.4302,  0.7899,  0.9010,
         1.2759,  0.2442,  0.1698,  1.1482,  0.0188,  0.0556, -0.3049, -5.5292],
       device='cuda:1')
Solve time for step 2 3.690198649012018
Current ori: tensor([ 0.0188,  0.0556, -0.3049], device='cuda:1')
Index force: tensor([0.5321, 0.6976, 0.6129], device='cuda:1')
tensor([-0.0528,  0.3792,  0.6252,  0.7562, -0.2075,  0.4382,  0.7764,  0.9193,
         1.2696,  0.2467,  0.1579,  1.1800,  0.0152,  0.0547, -0.3049, -5.5241],
       device='cuda:1')
Solve time for step 3 3.890625761996489
Current ori: tensor([ 0.0152,  0.0547, -0.3049], device='cuda:1')
Index force: tensor([0.6913, 0.6010], device='cuda:1')
tensor([-5.5939e-02,  4.2008e-01,  5.9407e-01,  7.0056e-01, -2.0409e-01,
         4.3366e-01,  7.7576e-01,  9.2905e-01,  1.2662e+00,  2.2972e-01,
         1.6356e-01,  1.1926e+00, -1.2209e-03,  5.8852e-02, -3.0492e-01,
        -5.5705e+00], device='cuda:1')
Solve time for step 4 3.586687965958845
Current ori: tensor([-0.0012,  0.0589, -0.3049], device='cuda:1')
Index force: tensor([0.5925], device='cuda:1')
Storing RECOVERY transition: reward=0.0047 (scaled=0.0024), steps=2
Reward stats updated: mean 0.0187 -> 0.0186, std: 0.1463
Collected 166 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=18.8910, Q2 Loss=18.8910, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5392
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7308, Q2 Loss=0.7308, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3414
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3669, Q2 Loss=1.3669, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0378
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2389, Q2 Loss=1.2389, Entropy=0.0030, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8039
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0012, Q2 Loss=1.0012, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4578

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.8%)
Q1 update: 0.08s (19.2%)
Q2 update: 0.07s (18.3%)
Actor update: 0.15s (38.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000001
Q1 loss: 4.645735
Q2 loss: 4.645735
Current threshold: -149.6351
Global Scale Offset: 1.6017
Reward stats: mean=0.0186, std=0.1463, count=166
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.6457, Q2 Loss: 4.6457, Entropy: 0.0006, Mean TD Error: 1.8360, Threshold: -149.6351
Original likelihood: -144.12542724609375
Adjusted likelihood: -144.12542724609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9840)
Current yaw: tensor([-0.0089,  0.0505, -0.3079], device='cuda:1')
9 turn
Sampling time 5.224127469002269
tensor([-0.0495,  0.4422,  0.5954,  0.6448, -0.1241,  0.4779,  0.8184,  0.9467,
         1.3128,  0.2688,  0.2173,  1.2210, -0.0089,  0.0505, -0.3079, -5.4800],
       device='cuda:1')
Original likelihood: -141.13308715820312
Adjusted likelihood: -141.13308715820312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 1 15.51150848902762
Current ori: tensor([-0.0089,  0.0505, -0.3079], device='cuda:1')
Middle force: tensor([0.9716, 1.4204, 0.5236, 1.0620, 0.8061, 0.5221, 0.6025, 0.5099, 0.6043,
        0.5981, 0.5542, 0.5097], device='cuda:1')
Thumb force: tensor([1.0908, 0.5670, 0.5726, 0.5253, 0.8370, 0.5281, 0.5651, 0.5160, 0.5767,
        0.5874, 1.2707, 0.9173], device='cuda:1')
Index force: tensor([0.8489, 0.8615, 0.6440, 0.7032, 0.5881, 0.7866, 0.5621, 0.5275, 0.5524,
        0.5747, 0.6323, 0.6798], device='cuda:1')
Storing NORMAL transition: reward=0.1648 (scaled=0.1648), steps=1
Reward stats updated: mean 0.0186 -> 0.0195, std: 0.1463
Collected 167 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6888, Q2 Loss=0.6888, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3674
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8336, Q2 Loss=0.8336, Entropy=0.3450, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7685
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=4.8420, Q2 Loss=4.8420, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0112
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6649, Q2 Loss=0.6649, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4595
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=3.4660, Q2 Loss=3.4660, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8007

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.4%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (19.0%)
Actor update: 0.13s (39.9%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001554
Q1 loss: 2.099046
Q2 loss: 2.099046
Current threshold: -149.6210
Global Scale Offset: 1.5971
Reward stats: mean=0.0195, std=0.1463, count=167
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 2.0990, Q2 Loss: 2.0990, Entropy: 0.0690, Mean TD Error: 2.2815, Threshold: -149.6210
tensor([-0.0158,  0.4288,  0.6076,  0.7122, -0.1181,  0.4380,  0.8516,  1.0193,
         1.3610,  0.2078,  0.2010,  1.1546, -0.0076,  0.0435, -0.4730, -5.3375],
       device='cuda:1')
Original likelihood: -135.72451782226562
Adjusted likelihood: -135.72451782226562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.945439841016196
Current ori: tensor([-0.0076,  0.0435, -0.4730], device='cuda:1')
Middle force: tensor([0.9025, 0.7192, 1.3515, 0.6497, 0.5725, 0.5066, 0.8135, 0.5521, 0.5395,
        0.5239, 0.6378], device='cuda:1')
Thumb force: tensor([1.3524, 0.5472, 1.0320, 0.5016, 0.7123, 0.5156, 1.0964, 0.5535, 0.8849,
        0.5621, 0.5509], device='cuda:1')
Index force: tensor([0.8711, 0.5232, 0.6705, 0.7749, 0.5770, 0.5888, 0.7527, 0.5961, 0.5714,
        0.7223, 0.5284], device='cuda:1')
Storing NORMAL transition: reward=0.0914 (scaled=0.0914), steps=1
Reward stats updated: mean 0.0195 -> 0.0199, std: 0.1460
Collected 168 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=5.5109, Q2 Loss=5.5109, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1256
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9972, Q2 Loss=0.9972, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4589
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5814, Q2 Loss=0.5814, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4236
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8778, Q2 Loss=0.8778, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8061
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=6.9458, Q2 Loss=6.9458, Entropy=0.0956, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3538

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.06s (17.7%)
Q1 update: 0.07s (19.4%)
Q2 update: 0.07s (19.4%)
Actor update: 0.14s (40.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000097
Q1 loss: 2.982623
Q2 loss: 2.982623
Current threshold: -149.6093
Global Scale Offset: 1.5994
Reward stats: mean=0.0199, std=0.1460, count=168
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.9826, Q2 Loss: 2.9826, Entropy: 0.0191, Mean TD Error: 2.2336, Threshold: -149.6093
tensor([ 1.2178e-02,  3.9109e-01,  6.8104e-01,  7.1267e-01, -1.0479e-01,
         4.2116e-01,  8.5778e-01,  1.0861e+00,  1.3516e+00,  2.2035e-01,
         2.0353e-01,  1.1298e+00, -2.4523e-03,  3.4504e-02, -5.6388e-01,
        -5.2452e+00], device='cuda:1')
Original likelihood: -127.1318359375
Adjusted likelihood: -127.1318359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.478256563015748
Current ori: tensor([-0.0025,  0.0345, -0.5639], device='cuda:1')
Middle force: tensor([0.7053, 1.3066, 0.6321, 0.5672, 0.5053, 0.8080, 0.5458, 0.5221, 0.5514,
        0.5483], device='cuda:1')
Thumb force: tensor([0.5377, 0.9883, 0.5006, 0.7067, 0.5157, 1.0638, 0.5506, 0.5199, 0.7512,
        0.6389], device='cuda:1')
Index force: tensor([0.5242, 0.6604, 0.7622, 0.5718, 0.5739, 0.7237, 0.5892, 0.6735, 0.5971,
        0.5353], device='cuda:1')
Storing NORMAL transition: reward=-0.0236 (scaled=-0.0236), steps=1
Reward stats updated: mean 0.0199 -> 0.0197, std: 0.1456
Collected 169 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6122, Q2 Loss=0.6122, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4349
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1223, Q2 Loss=1.1223, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9550
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8992, Q2 Loss=0.8992, Entropy=0.3446, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2434
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5756, Q2 Loss=0.5756, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1805
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5340, Q2 Loss=0.5340, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6590

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.4%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.06s (17.5%)
Actor update: 0.14s (39.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001573
Q1 loss: 0.748638
Q2 loss: 0.748638
Current threshold: -149.5890
Global Scale Offset: 1.6129
Reward stats: mean=0.0197, std=0.1456, count=169
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 0.7486, Q2 Loss: 0.7486, Entropy: 0.0689, Mean TD Error: 0.6946, Threshold: -149.5890
tensor([-0.1447,  0.3828,  0.6507,  0.5559, -0.1720,  0.3780,  0.9132,  1.1288,
         1.3257,  0.3858,  0.2561,  1.0352,  0.0239,  0.0565, -0.5446, -4.9842],
       device='cuda:1')
Original likelihood: -247.80044555664062
Adjusted likelihood: -247.80044555664062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -6.2100,  -6.2474,  -6.3913,  -6.7539,  -6.7897,  -6.8991,  -7.0694,
         -7.1150,  -7.1337,  -7.3489,  -7.8547,  -7.9781,  -8.3126,  -8.4882,
         -9.0109, -10.1792], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -6.2100,  -6.2474,  -6.3913,  -6.7539,  -6.7897,  -6.8991,  -7.0694,
         -7.1150,  -7.1337,  -7.3489,  -7.8547,  -7.9781,  -8.3126,  -8.4882,
         -9.0109, -10.1792], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.4864
1 mode projection succeeded
New goal: tensor([-0.0220,  0.5020,  0.5622,  0.5854, -0.0458,  0.4327,  0.8872,  0.9318,
         1.2665,  0.3167,  0.2134,  1.1710,  0.0050,  0.0134, -0.1973],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -102.33233642578125
Adjusted likelihood: -102.33233642578125
Likelihood residual: 0.0
Original likelihood: -104.84053802490234
Adjusted likelihood: -104.84053802490234
Likelihood residual: 0.0
{'index': 104.84053802490234, 'thumb_middle': 102.33233642578125}
Current yaw: tensor([ 0.0239,  0.0565, -0.5446], device='cuda:1')
10 thumb_middle
tensor([-0.1447,  0.3828,  0.6507,  0.5559, -0.1720,  0.3780,  0.9132,  1.1288,
         1.3257,  0.3858,  0.2561,  1.0352,  0.0239,  0.0565, -0.5446, -4.9842],
       device='cuda:1')
Solve time for step 1 9.624984397960361
Current ori: tensor([ 0.0239,  0.0565, -0.5446], device='cuda:1')
Index force: tensor([0.6642, 0.5145, 0.6489, 0.5069], device='cuda:1')
tensor([-0.0969,  0.4039,  0.6202,  0.6227, -0.1880,  0.3981,  0.8497,  0.9477,
         1.2449,  0.3094,  0.1523,  1.1321,  0.0076,  0.0452, -0.5421, -5.0220],
       device='cuda:1')
Solve time for step 2 3.826559276029002
Current ori: tensor([ 0.0076,  0.0452, -0.5421], device='cuda:1')
Index force: tensor([0.7035, 0.6269, 0.5985], device='cuda:1')
tensor([-8.5603e-02,  4.3544e-01,  5.8647e-01,  6.2038e-01, -1.8573e-01,
         4.1243e-01,  8.4175e-01,  9.1307e-01,  1.2360e+00,  2.9775e-01,
         1.5313e-01,  1.1522e+00, -3.7486e-03,  4.5247e-02, -5.4209e-01,
        -5.0919e+00], device='cuda:1')
Solve time for step 3 3.7247099920059554
Current ori: tensor([-0.0037,  0.0452, -0.5421], device='cuda:1')
Index force: tensor([0.6208, 0.5955], device='cuda:1')
tensor([-0.0801,  0.4652,  0.5615,  0.5946, -0.1871,  0.4150,  0.8398,  0.9041,
         1.2342,  0.2962,  0.1558,  1.1569, -0.0158,  0.0430, -0.5421, -5.0908],
       device='cuda:1')
Solve time for step 4 3.7608900319901295
Current ori: tensor([-0.0158,  0.0430, -0.5421], device='cuda:1')
Index force: tensor([0.5862], device='cuda:1')
Storing RECOVERY transition: reward=0.0153 (scaled=0.0051), steps=3
Reward stats updated: mean 0.0197 -> 0.0196, std: 0.1452
Collected 170 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1412, Q2 Loss=1.1412, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9940
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8269, Q2 Loss=0.8269, Entropy=0.3443, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6115
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8343, Q2 Loss=0.8343, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6647
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5805, Q2 Loss=0.5805, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3297
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=18.5670, Q2 Loss=18.5670, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5725

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.3%)
Q1 update: 0.07s (18.4%)
Q2 update: 0.07s (18.3%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001587
Q1 loss: 4.389972
Q2 loss: 4.389972
Current threshold: -149.5566
Global Scale Offset: 1.5990
Reward stats: mean=0.0196, std=0.1452, count=170
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 4.3900, Q2 Loss: 4.3900, Entropy: 0.0689, Mean TD Error: 1.4345, Threshold: -149.5566
Original likelihood: -123.68205261230469
Adjusted likelihood: -123.68205261230469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0175,  0.0280, -0.5553], device='cuda:1')
11 turn
Sampling time 5.279581220005639
tensor([-0.0558,  0.4756,  0.5623,  0.5998, -0.1008,  0.4717,  0.8846,  0.9289,
         1.2877,  0.3138,  0.1987,  1.1784, -0.0175,  0.0280, -0.5553, -5.0534],
       device='cuda:1')
Original likelihood: -121.40957641601562
Adjusted likelihood: -121.40957641601562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.363827487046365
Current ori: tensor([-0.0175,  0.0280, -0.5553], device='cuda:1')
Middle force: tensor([0.6078, 1.6781, 0.8034, 0.5417, 0.5357, 0.5463, 0.5773, 0.5389, 0.6354,
        0.5393, 0.5925, 0.5922], device='cuda:1')
Thumb force: tensor([0.5704, 2.0725, 0.5106, 0.7183, 0.5432, 0.5613, 0.5971, 0.5469, 0.5566,
        0.8427, 0.5597, 0.5962], device='cuda:1')
Index force: tensor([0.5893, 1.0213, 0.8909, 0.5828, 0.5007, 0.5348, 0.5464, 0.5339, 0.5910,
        0.5200, 0.6112, 0.6001], device='cuda:1')
Storing NORMAL transition: reward=0.0374 (scaled=0.0374), steps=1
Reward stats updated: mean 0.0196 -> 0.0197, std: 0.1448
Collected 171 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5833, Q2 Loss=0.5833, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2143
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9215, Q2 Loss=0.9215, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7184
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8084, Q2 Loss=0.8084, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4098
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.9456, Q2 Loss=2.9456, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7916
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9536, Q2 Loss=0.9536, Entropy=0.0022, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0804

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (18.0%)
Q1 update: 0.07s (19.4%)
Q2 update: 0.07s (20.2%)
Actor update: 0.14s (39.2%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.242495
Q2 loss: 1.242495
Current threshold: -149.5346
Global Scale Offset: 1.5880
Reward stats: mean=0.0197, std=0.1448, count=171
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2425, Q2 Loss: 1.2425, Entropy: 0.0004, Mean TD Error: 1.4429, Threshold: -149.5346
tensor([-0.0404,  0.4332,  0.6022,  0.6602, -0.0920,  0.4461,  0.9176,  0.9530,
         1.3063,  0.2920,  0.1746,  1.1811, -0.0102,  0.0205, -0.5922, -5.1163],
       device='cuda:1')
Original likelihood: -107.949951171875
Adjusted likelihood: -107.949951171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.073911329964176
Current ori: tensor([-0.0102,  0.0205, -0.5922], device='cuda:1')
Middle force: tensor([1.5788, 0.7681, 0.5377, 0.5330, 0.5430, 0.5710, 0.5345, 0.6289, 0.5360,
        0.5887, 0.5810], device='cuda:1')
Thumb force: tensor([1.9268, 0.5091, 0.7005, 0.5386, 0.5551, 0.5879, 0.5419, 0.5496, 0.8263,
        0.5548, 0.5877], device='cuda:1')
Index force: tensor([0.9704, 0.8670, 0.5749, 0.5004, 0.5305, 0.5404, 0.5313, 0.5819, 0.5160,
        0.6022, 0.5918], device='cuda:1')
Storing NORMAL transition: reward=0.1208 (scaled=0.1208), steps=1
Reward stats updated: mean 0.0197 -> 0.0203, std: 0.1445
Collected 172 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.7960, Q2 Loss=0.7960, Entropy=0.0996, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4726
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2523, Q2 Loss=1.2523, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9210
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4608, Q2 Loss=1.4608, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5601
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.0149, Q2 Loss=2.0149, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2442
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=4.7265, Q2 Loss=4.7265, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0884

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (18.1%)
Q1 update: 0.07s (19.5%)
Q2 update: 0.07s (19.8%)
Actor update: 0.14s (39.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000014
Q1 loss: 2.050096
Q2 loss: 2.050096
Current threshold: -149.5213
Global Scale Offset: 1.5858
Reward stats: mean=0.0203, std=0.1445, count=172
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.0501, Q2 Loss: 2.0501, Entropy: 0.0199, Mean TD Error: 2.4573, Threshold: -149.5213
tensor([-0.0260,  0.3914,  0.6405,  0.7180, -0.0847,  0.4173,  0.9480,  0.9831,
         1.3409,  0.2544,  0.1933,  1.0790, -0.0132,  0.0181, -0.7132, -5.3634],
       device='cuda:1')
Original likelihood: -113.03116607666016
Adjusted likelihood: -113.03116607666016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.667666112014558
Current ori: tensor([-0.0132,  0.0181, -0.7132], device='cuda:1')
Middle force: tensor([0.7522, 0.5340, 0.5305, 0.5406, 0.5648, 0.5308, 0.6218, 0.5334, 0.5828,
        0.5726], device='cuda:1')
Thumb force: tensor([0.5075, 0.6857, 0.5354, 0.5506, 0.5811, 0.5382, 0.5448, 0.8125, 0.5512,
        0.5813], device='cuda:1')
Index force: tensor([0.8362, 0.5688, 0.5002, 0.5269, 0.5372, 0.5291, 0.5757, 0.5132, 0.5973,
        0.5857], device='cuda:1')
Storing NORMAL transition: reward=0.0518 (scaled=0.0518), steps=1
Reward stats updated: mean 0.0203 -> 0.0205, std: 0.1442
Collected 173 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8652, Q2 Loss=0.8652, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2572
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6685, Q2 Loss=0.6685, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2354
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.8870, Q2 Loss=0.8870, Entropy=0.0960, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3104
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7389, Q2 Loss=0.7389, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4716
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6495, Q2 Loss=0.6495, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6416

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (24.2%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (36.4%)
Target update: 0.01s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000098
Q1 loss: 0.761830
Q2 loss: 0.761830
Current threshold: -149.5119
Global Scale Offset: 1.6047
Reward stats: mean=0.0205, std=0.1442, count=173
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7618, Q2 Loss: 0.7618, Entropy: 0.0192, Mean TD Error: 0.7832, Threshold: -149.5119
tensor([-0.0066,  0.3725,  0.6641,  0.7530, -0.0748,  0.4014,  0.9697,  1.0055,
         1.3435,  0.2501,  0.1836,  1.0743, -0.0110,  0.0128, -0.7648, -5.3799],
       device='cuda:1')
Original likelihood: -100.16646575927734
Adjusted likelihood: -100.16646575927734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.14009061397519
Current ori: tensor([-0.0110,  0.0128, -0.7648], device='cuda:1')
Middle force: tensor([0.5304, 0.5270, 0.5367, 0.5589, 0.5270, 0.6147, 0.5301, 0.5782, 0.5651],
       device='cuda:1')
Thumb force: tensor([0.6691, 0.5329, 0.5469, 0.5753, 0.5354, 0.5409, 0.8010, 0.5480, 0.5755],
       device='cuda:1')
Index force: tensor([0.5611, 0.5001, 0.5248, 0.5344, 0.5274, 0.5702, 0.5111, 0.5918, 0.5806],
       device='cuda:1')
Storing NORMAL transition: reward=0.1412 (scaled=0.1412), steps=1
Reward stats updated: mean 0.0205 -> 0.0212, std: 0.1440
Collected 174 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6194, Q2 Loss=0.6194, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3831
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5740, Q2 Loss=0.5740, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2682
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5395, Q2 Loss=0.5395, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4252
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1061, Q2 Loss=1.1061, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8629
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=8.4512, Q2 Loss=8.4512, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4042

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.5%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (18.5%)
Actor update: 0.15s (38.8%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.258050
Q2 loss: 2.258050
Current threshold: -149.5056
Global Scale Offset: 1.6266
Reward stats: mean=0.0212, std=0.1440, count=174
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.2580, Q2 Loss: 2.2580, Entropy: 0.0000, Mean TD Error: 1.0687, Threshold: -149.5056
tensor([ 0.0831,  0.3564,  0.7019,  0.8670, -0.0340,  0.4077,  0.9761,  1.0520,
         1.3214,  0.3372,  0.1502,  1.0483, -0.0227, -0.0063, -0.9072, -5.7595],
       device='cuda:1')
Original likelihood: -113.98387145996094
Adjusted likelihood: -113.98387145996094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 5.376109428005293
Current ori: tensor([-0.0227, -0.0063, -0.9072], device='cuda:1')
Middle force: tensor([0.5237, 0.5309, 0.5533, 0.5226, 0.6007, 0.5261, 0.5660, 0.5576],
       device='cuda:1')
Thumb force: tensor([0.5307, 0.5458, 0.5709, 0.5343, 0.5404, 0.7962, 0.5484, 0.5727],
       device='cuda:1')
Index force: tensor([0.5001, 0.5242, 0.5332, 0.5266, 0.5686, 0.5099, 0.5927, 0.5770],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0137 (scaled=-0.0137), steps=1
Reward stats updated: mean 0.0212 -> 0.0210, std: 0.1436
Collected 175 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0253, Q2 Loss=1.0253, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8539
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.7162, Q2 Loss=1.7162, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2042
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=0.7834, Q2 Loss=0.7834, Entropy=0.1180, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5834
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.7873, Q2 Loss=1.7873, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2129
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=2.1400, Q2 Loss=2.1400, Entropy=0.1090, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0918

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.4%)
Q1 update: 0.06s (18.9%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (37.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000198
Q1 loss: 1.490440
Q2 loss: 1.490440
Current threshold: -149.4997
Global Scale Offset: 1.6683
Reward stats: mean=0.0210, std=0.1436, count=175
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.4904, Q2 Loss: 1.4904, Entropy: 0.0454, Mean TD Error: 1.9892, Threshold: -149.4997
tensor([ 0.0407,  0.3856,  0.6802,  0.7488,  0.0035,  0.4170,  1.1107,  1.0980,
         1.2919,  0.2791,  0.1376,  0.8812, -0.0536, -0.0645, -0.9117,  1.0654],
       device='cuda:1')
Original likelihood: -183.0861053466797
Adjusted likelihood: -183.0861053466797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.6684,  -5.0533,  -5.2364,  -7.0060,  -7.5799,  -7.6442,  -7.9336,
         -8.1705,  -8.6342,  -8.9642,  -9.4625,  -9.6444, -13.5662, -14.4273,
        -15.6519, -18.0392], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.6684,  -5.0533,  -5.2364,  -7.0060,  -7.5799,  -7.6442,  -7.9336,
         -8.1705,  -8.6342,  -8.9642,  -9.4625,  -9.6444, -13.5662, -14.4273,
        -15.6519, -18.0392], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.4176
1 mode projection succeeded
New goal: tensor([ 0.0404,  0.4919,  0.6609,  0.5235, -0.0131,  0.4798,  0.9680,  0.6616,
         1.2541,  0.4367,  0.1683,  1.1148, -0.0228, -0.0067, -1.0789],
       device='cuda:1')
tensor([[0.0066]], device='cuda:1') tensor([[0.0057]], device='cuda:1') tensor([[0.0040]], device='cuda:1')
Original likelihood: -171.72781372070312
Adjusted likelihood: -171.72781372070312
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 171.72781372070312}
Current yaw: tensor([-0.0536, -0.0645, -0.9117], device='cuda:1')
12 thumb_middle
tensor([ 0.0407,  0.3856,  0.6802,  0.7488,  0.0035,  0.4170,  1.1107,  1.0980,
         1.2919,  0.2791,  0.1376,  0.8812, -0.0536, -0.0645, -0.9117,  1.0654],
       device='cuda:1')
Solve time for step 1 9.464089038025122
Current ori: tensor([-0.0536, -0.0645, -0.9117], device='cuda:1')
Index force: tensor([0.5406, 0.5200, 0.6553, 0.6119], device='cuda:1')
tensor([ 0.0388,  0.4071,  0.7842,  0.6437, -0.0498,  0.5007,  0.9845,  0.7871,
         1.1762,  0.3899,  0.0524,  1.0349, -0.1192, -0.1450, -0.8989, -5.5890],
       device='cuda:1')
Solve time for step 2 4.02077892201487
Current ori: tensor([-0.1192, -0.1450, -0.8989], device='cuda:1')
Index force: tensor([0.5173, 0.6478, 0.6030], device='cuda:1')
tensor([ 0.0124,  0.4633,  0.7943,  0.6252, -0.0200,  0.5654,  0.9916,  0.6899,
         1.1605,  0.4242, -0.0115,  1.0375, -0.1586, -0.1876, -0.8210, -1.8698],
       device='cuda:1')
Solve time for step 3 3.7356968150124885
Current ori: tensor([-0.1586, -0.1876, -0.8210], device='cuda:1')
Index force: tensor([0.6255, 0.5924], device='cuda:1')
tensor([-0.0300,  0.5851,  0.7854,  0.6058, -0.0216,  0.6294,  0.9614,  0.6315,
         1.1280,  0.4224, -0.0248,  1.0380, -0.2083, -0.2194, -0.7141, -0.2817],
       device='cuda:1')
Solve time for step 4 3.6570264629554003
Current ori: tensor([-0.2083, -0.2194, -0.7141], device='cuda:1')
Index force: tensor([0.5579], device='cuda:1')
Storing RECOVERY transition: reward=-0.4133 (scaled=-0.0827), steps=5
Reward stats updated: mean 0.0210 -> 0.0204, std: 0.1434
Collected 176 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7350, Q2 Loss=0.7350, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5609
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6356, Q2 Loss=0.6356, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6427
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7195, Q2 Loss=0.7195, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5995
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0823, Q2 Loss=1.0823, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5596
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=2.2697, Q2 Loss=2.2697, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7567

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.3%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.06s (17.6%)
Actor update: 0.13s (37.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.088428
Q2 loss: 1.088428
Current threshold: -149.4942
Global Scale Offset: 1.7212
Reward stats: mean=0.0204, std=0.1434, count=176
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0884, Q2 Loss: 1.0884, Entropy: 0.0000, Mean TD Error: 1.4239, Threshold: -149.4942
Original likelihood: -933.637451171875
Adjusted likelihood: -933.637451171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 12
Loaded trajectory sampler
Current yaw: tensor([-0.0012,  0.0145, -0.0305], device='cuda:1')
Current yaw: tensor([-0.0012,  0.0145, -0.0305], device='cuda:1')
1 turn
Sampling time 5.171128140005749
tensor([ 1.3523e-01,  5.6154e-01,  6.0244e-01,  6.4100e-01, -9.8461e-02,
         5.0412e-01,  9.0268e-01,  9.1869e-01,  1.2490e+00,  3.0553e-01,
         2.3143e-01,  1.1626e+00, -1.1755e-03,  1.4471e-02, -3.0544e-02,
         5.0366e-02], device='cuda:1')
Original likelihood: -84.65676879882812
Adjusted likelihood: -84.65676879882812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.540783573000226
Current ori: tensor([-0.0012,  0.0145, -0.0305], device='cuda:1')
Middle force: tensor([0.7221, 0.7165, 0.5403, 0.8601, 0.5321, 0.5939, 0.5183, 0.5134, 0.4876,
        0.5209, 0.8953, 0.5458], device='cuda:1')
Thumb force: tensor([0.6457, 0.6796, 0.7117, 1.3018, 1.1905, 1.4264, 1.2412, 0.5121, 0.5483,
        0.5661, 1.0757, 0.5232], device='cuda:1')
Index force: tensor([0.6520, 0.6406, 0.5431, 0.5818, 1.0623, 0.7440, 0.7836, 0.7756, 0.7280,
        0.5700, 0.7315, 0.5726], device='cuda:1')
Storing NORMAL transition: reward=0.1386 (scaled=0.1386), steps=1
Reward stats updated: mean 0.0204 -> 0.0210, std: 0.1433
Collected 177 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.1174, Q2 Loss=1.1174, Entropy=0.0258, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6422
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3112, Q2 Loss=1.3112, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6637
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8696, Q2 Loss=0.8696, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5138
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.1405, Q2 Loss=1.1405, Entropy=0.0275, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6095
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6892, Q2 Loss=0.6892, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6926

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (22.0%)
Q1 update: 0.05s (18.0%)
Q2 update: 0.05s (18.4%)
Actor update: 0.11s (37.9%)
Target update: 0.01s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000038
Q1 loss: 1.025571
Q2 loss: 1.025571
Current threshold: -149.4902
Global Scale Offset: 1.7701
Reward stats: mean=0.0210, std=0.1433, count=177
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0256, Q2 Loss: 1.0256, Entropy: 0.0106, Mean TD Error: 1.4243, Threshold: -149.4902
tensor([ 0.1624,  0.7139,  0.4925,  0.4666, -0.1525,  0.4164,  0.9735,  0.9458,
         1.3555,  0.1899,  0.2971,  0.9872,  0.0027,  0.0426, -0.1714, -0.6910],
       device='cuda:1')
Original likelihood: -208.3907928466797
Adjusted likelihood: -208.3907928466797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.2031, -3.3231, -3.4191, -3.6808, -3.8305, -3.9519, -4.0321, -4.1754,
        -4.2141, -4.4398, -4.6133, -4.6612, -4.8161, -5.4524, -5.4788, -8.9410],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2031, -3.3231, -3.4191, -3.6808, -3.8305, -3.9519, -4.0321, -4.1754,
        -4.2141, -4.4398, -4.6133, -4.6612, -4.8161, -5.4524, -5.4788, -8.9410],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.5145
1 mode projection succeeded
New goal: tensor([ 0.1100,  0.5408,  0.6191,  0.6150, -0.0685,  0.4819,  0.8494,  0.9502,
         1.2490,  0.3078,  0.2432,  1.1575,  0.0044,  0.0129, -0.3564],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -134.963134765625
Adjusted likelihood: -134.963134765625
Likelihood residual: 0.0
Original likelihood: -91.06261444091797
Adjusted likelihood: -91.06261444091797
Likelihood residual: 0.0
{'index': 91.06261444091797, 'thumb_middle': 134.963134765625}
Current yaw: tensor([ 0.0027,  0.0426, -0.1714], device='cuda:1')
2 index
tensor([ 0.1624,  0.7139,  0.4925,  0.4666, -0.1525,  0.4164,  0.9735,  0.9458,
         1.3555,  0.1899,  0.2971,  0.9872,  0.0027,  0.0426, -0.1714, -0.6910],
       device='cuda:1')
Solve time for step 1 11.093468456005212
Current ori: tensor([ 0.0027,  0.0426, -0.1714], device='cuda:1')
Middle force: tensor([0.6221, 0.5836, 0.5533, 0.5622], device='cuda:1')
Thumb force: tensor([0.5403, 0.5870, 0.5772, 0.5832], device='cuda:1')
tensor([ 0.1652,  0.5174,  0.5482,  0.5658, -0.1135,  0.4668,  0.9152,  0.9888,
         1.2851,  0.2760,  0.2884,  1.0033, -0.0063,  0.0179, -0.1808,  2.8635],
       device='cuda:1')
Solve time for step 2 4.620235487003811
Current ori: tensor([-0.0063,  0.0179, -0.1808], device='cuda:1')
Middle force: tensor([0.5793, 0.5507, 0.5594], device='cuda:1')
Thumb force: tensor([0.5840, 0.5736, 0.5783], device='cuda:1')
tensor([ 1.6572e-01,  4.9677e-01,  5.6398e-01,  5.8560e-01, -8.2901e-02,
         4.8915e-01,  9.0666e-01,  9.9829e-01,  1.2838e+00,  2.5967e-01,
         2.3674e-01,  1.0526e+00, -7.9153e-03, -3.2360e-03, -1.8333e-01,
         4.9883e+00], device='cuda:1')
Solve time for step 3 4.339479247981217
Current ori: tensor([-0.0079, -0.0032, -0.1833], device='cuda:1')
Middle force: tensor([0.5481, 0.5557], device='cuda:1')
Thumb force: tensor([0.5674, 0.5741], device='cuda:1')
tensor([ 1.6694e-01,  4.9360e-01,  5.6904e-01,  5.8807e-01, -8.0007e-02,
         4.8925e-01,  9.1357e-01,  1.0114e+00,  1.2706e+00,  2.7164e-01,
         2.2684e-01,  1.0834e+00, -2.3846e-03, -8.4410e-03, -1.8064e-01,
         6.2381e+00], device='cuda:1')
Solve time for step 4 4.56867844494991
Current ori: tensor([-0.0024, -0.0084, -0.1806], device='cuda:1')
Middle force: tensor([0.5318], device='cuda:1')
Thumb force: tensor([0.5697], device='cuda:1')
Storing RECOVERY transition: reward=0.0080 (scaled=0.0080), steps=1
Reward stats updated: mean 0.0210 -> 0.0210, std: 0.1429
Collected 178 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=8.3748, Q2 Loss=8.3748, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0557
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.2378, Q2 Loss=2.2378, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7744
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5277, Q2 Loss=0.5277, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4145
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0561, Q2 Loss=1.0561, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3168
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9220, Q2 Loss=0.9220, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7896

------ SAC Update Summary (5 iterations) ------
Total time: 0.41s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.5%)
Q1 update: 0.08s (19.4%)
Q2 update: 0.08s (18.8%)
Actor update: 0.16s (39.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 2.623681
Q2 loss: 2.623681
Current threshold: -149.4876
Global Scale Offset: 1.8063
Reward stats: mean=0.0210, std=0.1429, count=178
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 2.6237, Q2 Loss: 2.6237, Entropy: 0.0000, Mean TD Error: 1.8702, Threshold: -149.4876
Original likelihood: -71.08192443847656
Adjusted likelihood: -71.08192443847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0055, -0.0102, -0.1771], device='cuda:1')
3 turn
Sampling time 5.118121880979743
tensor([ 1.1447e-01,  5.5133e-01,  6.1262e-01,  6.0872e-01, -7.6603e-02,
         4.9694e-01,  9.0810e-01,  1.0034e+00,  1.2616e+00,  2.8462e-01,
         2.3032e-01,  1.0772e+00, -5.4658e-03, -1.0219e-02, -1.7711e-01,
        -6.0622e+00], device='cuda:1')
Original likelihood: -74.64717102050781
Adjusted likelihood: -74.64717102050781
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.342770769959316
Current ori: tensor([-0.0055, -0.0102, -0.1771], device='cuda:1')
Middle force: tensor([1.4009, 0.5009, 0.5312, 0.5809, 0.5344, 0.5045, 0.5761, 0.4989, 0.4945,
        0.5951, 0.9626, 0.5816], device='cuda:1')
Thumb force: tensor([0.8925, 0.5363, 0.9832, 1.2386, 0.5449, 0.5311, 1.9974, 0.5566, 0.5434,
        0.5932, 0.8212, 0.6087], device='cuda:1')
Index force: tensor([0.8071, 0.9852, 0.5287, 0.5594, 0.5987, 0.7036, 0.5797, 0.7880, 0.8263,
        0.5934, 0.5109, 0.6411], device='cuda:1')
Storing NORMAL transition: reward=0.0458 (scaled=0.0458), steps=1
Reward stats updated: mean 0.0210 -> 0.0211, std: 0.1425
Collected 179 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5766, Q2 Loss=0.5766, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3448
SAC Update 2/5: Actor Loss=-0.0057, Q1 Loss=0.6282, Q2 Loss=0.6282, Entropy=0.3422, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3148
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.1462, Q2 Loss=1.1462, Entropy=0.0347, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0295
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0751, Q2 Loss=1.0751, Entropy=0.0004, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4346
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9776, Q2 Loss=0.9776, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5651

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (22.1%)
Q1 update: 0.05s (17.0%)
Q2 update: 0.05s (17.9%)
Actor update: 0.12s (39.1%)
Target update: 0.01s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001164
Q1 loss: 0.880750
Q2 loss: 0.880750
Current threshold: -149.4967
Global Scale Offset: 1.8580
Reward stats: mean=0.0211, std=0.1425, count=179
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 0.8807, Q2 Loss: 0.8807, Entropy: 0.0755, Mean TD Error: 0.5378, Threshold: -149.4967
tensor([ 0.0894,  0.4803,  0.6646,  0.6216, -0.0295,  0.5013,  1.0308,  1.0187,
         1.2117,  0.3975,  0.2969,  0.8469,  0.0091, -0.0674, -0.2276, -5.7008],
       device='cuda:1')
Original likelihood: -158.59616088867188
Adjusted likelihood: -158.59616088867188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0007)
State is out of distribution
Final likelihood: tensor([ -4.8493,  -6.3045,  -6.6359,  -6.7883,  -7.0537,  -7.2419,  -7.3403,
         -7.6518,  -7.8269,  -7.8540,  -7.9739,  -8.4915,  -8.9811,  -9.1295,
         -9.7966, -14.5604], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.8493,  -6.3045,  -6.6359,  -6.7883,  -7.0537,  -7.2419,  -7.3403,
         -7.6518,  -7.8269,  -7.8540,  -7.9739,  -8.4915,  -8.9811,  -9.1295,
         -9.7966, -14.5604], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -8.0300
1 mode projection succeeded
New goal: tensor([ 0.0477,  0.4658,  0.7223,  0.4851, -0.0679,  0.6135,  0.7739,  0.9261,
         1.2534,  0.4048,  0.3824,  0.7061, -0.0145, -0.0128,  0.0632],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -137.84803771972656
Adjusted likelihood: -137.84803771972656
Likelihood residual: 0.0
Original likelihood: -161.9191436767578
Adjusted likelihood: -161.9191436767578
Likelihood residual: 0.0
{'index': 161.9191436767578, 'thumb_middle': 137.84803771972656}
Current yaw: tensor([ 0.0091, -0.0674, -0.2276], device='cuda:1')
4 thumb_middle
tensor([ 0.0894,  0.4803,  0.6646,  0.6216, -0.0295,  0.5013,  1.0308,  1.0187,
         1.2117,  0.3975,  0.2969,  0.8469,  0.0091, -0.0674, -0.2276, -5.7008],
       device='cuda:1')
Solve time for step 1 9.889890266989823
Current ori: tensor([ 0.0091, -0.0674, -0.2276], device='cuda:1')
Index force: tensor([0.5883, 0.6018, 0.5847, 0.6045], device='cuda:1')
tensor([ 3.6427e-02,  4.6485e-01,  7.0314e-01,  4.9404e-01, -1.2950e-01,
         5.7845e-01,  7.9500e-01,  9.2749e-01,  1.2071e+00,  3.9981e-01,
         2.8432e-01,  6.9488e-01, -3.8680e-03, -3.5821e-02, -2.2243e-01,
        -5.7687e+00], device='cuda:1')
Solve time for step 2 3.9785877440008335
Current ori: tensor([-0.0039, -0.0358, -0.2224], device='cuda:1')
Index force: tensor([0.5886, 0.5762, 0.5953], device='cuda:1')
tensor([-0.0089,  0.4534,  0.6932,  0.4691, -0.1672,  0.5948,  0.7506,  0.9042,
         1.2272,  0.4015,  0.3048,  0.6767, -0.0072, -0.0104, -0.2224, -5.8365],
       device='cuda:1')
Solve time for step 3 3.7476283659925684
Current ori: tensor([-0.0072, -0.0104, -0.2224], device='cuda:1')
Index force: tensor([0.5638, 0.5834], device='cuda:1')
tensor([ 1.7656e-02,  4.5028e-01,  7.0859e-01,  4.9003e-01, -1.5330e-01,
         6.1260e-01,  7.4496e-01,  9.0196e-01,  1.2194e+00,  3.9586e-01,
         2.9684e-01,  6.7066e-01, -2.7485e-03, -2.5187e-02, -2.2243e-01,
        -5.7949e+00], device='cuda:1')
Solve time for step 4 3.8121196199790575
Current ori: tensor([-0.0027, -0.0252, -0.2224], device='cuda:1')
Index force: tensor([0.5638], device='cuda:1')
Storing RECOVERY transition: reward=-0.0117 (scaled=-0.0117), steps=1
Reward stats updated: mean 0.0211 -> 0.0209, std: 0.1421
Collected 180 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6534, Q2 Loss=0.6534, Entropy=0.0030, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4161
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.1034, Q2 Loss=3.1034, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5960
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=8.0280, Q2 Loss=8.0280, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7711
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7011, Q2 Loss=0.7011, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3470
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0282, Q2 Loss=1.0282, Entropy=0.0004, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3726

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.1%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.6%)
Actor update: 0.13s (38.4%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.702808
Q2 loss: 2.702808
Current threshold: -149.5041
Global Scale Offset: 1.8989
Reward stats: mean=0.0209, std=0.1421, count=180
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.7028, Q2 Loss: 2.7028, Entropy: 0.0007, Mean TD Error: 2.3006, Threshold: -149.5041
Original likelihood: -101.95397186279297
Adjusted likelihood: -101.95397186279297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 1.7403e-05, -1.7858e-02, -2.1136e-01], device='cuda:1')
5 turn
Sampling time 5.160636310989503
tensor([ 6.4122e-04,  4.4452e-01,  7.0585e-01,  4.8202e-01, -9.4080e-02,
         6.6056e-01,  7.7369e-01,  9.1420e-01,  1.2714e+00,  4.0640e-01,
         3.6403e-01,  7.1681e-01,  1.7403e-05, -1.7858e-02, -2.1136e-01,
        -5.8032e+00], device='cuda:1')
Original likelihood: -117.47268676757812
Adjusted likelihood: -117.47268676757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.108997536997776
Current ori: tensor([ 1.7403e-05, -1.7858e-02, -2.1136e-01], device='cuda:1')
Middle force: tensor([1.0696, 0.9422, 1.7786, 1.8269, 0.5778, 1.3230, 0.5897, 0.5254, 0.6344,
        0.6177, 0.5914, 1.7758], device='cuda:1')
Thumb force: tensor([0.7024, 0.6506, 0.5948, 0.8153, 0.9580, 0.6261, 0.5309, 0.6269, 0.5473,
        0.7407, 0.7239, 1.2601], device='cuda:1')
Index force: tensor([0.9842, 0.6344, 0.9598, 1.2455, 0.6562, 0.9122, 0.6048, 0.5335, 0.6118,
        0.5595, 0.5772, 0.6555], device='cuda:1')
Storing NORMAL transition: reward=0.0442 (scaled=0.0442), steps=1
Reward stats updated: mean 0.0209 -> 0.0211, std: 0.1418
Collected 181 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8778, Q2 Loss=0.8778, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5292
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6538, Q2 Loss=0.6538, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2873
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5760, Q2 Loss=0.5760, Entropy=0.0003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2414
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1036, Q2 Loss=1.1036, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3933
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.8603, Q2 Loss=1.8603, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2911

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.9%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (18.2%)
Actor update: 0.14s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.014295
Q2 loss: 1.014295
Current threshold: -149.5085
Global Scale Offset: 1.9240
Reward stats: mean=0.0211, std=0.1418, count=181
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0143, Q2 Loss: 1.0143, Entropy: 0.0001, Mean TD Error: 1.1485, Threshold: -149.5085
tensor([ 5.9493e-03,  3.9717e-01,  7.4223e-01,  5.4503e-01, -9.9811e-02,
         6.6196e-01,  7.3132e-01,  1.0128e+00,  1.4053e+00,  2.4462e-01,
         2.7779e-01,  7.0362e-01,  4.4566e-03, -1.6321e-02, -2.5552e-01,
        -5.8252e+00], device='cuda:1')
Original likelihood: -150.73223876953125
Adjusted likelihood: -150.73223876953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3384)
State is out of distribution
Final likelihood: tensor([-2.5950, -2.8375, -3.0494, -3.1382, -3.2254, -3.8955, -4.0867, -4.3870,
        -4.6530, -5.0789, -5.2494, -5.7540, -5.7986, -6.1277, -7.4671, -7.8612],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.5950, -2.8375, -3.0494, -3.1382, -3.2254, -3.8955, -4.0867, -4.3870,
        -4.6530, -5.0789, -5.2494, -5.7540, -5.7986, -6.1277, -7.4671, -7.8612],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.7003
1 mode projection succeeded
New goal: tensor([ 0.0389,  0.5431,  0.5396,  0.6281, -0.0730,  0.4906,  0.8518,  0.9150,
         1.2886,  0.2912,  0.2407,  1.0874,  0.0050,  0.0159, -1.6155],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -118.60987091064453
Adjusted likelihood: -118.60987091064453
Likelihood residual: 0.0
Original likelihood: -178.4483642578125
Adjusted likelihood: -178.4483642578125
Likelihood residual: 0.0
{'index': 178.4483642578125, 'thumb_middle': 118.60987091064453}
Current yaw: tensor([ 0.0045, -0.0163, -0.2555], device='cuda:1')
6 thumb_middle
tensor([ 5.9493e-03,  3.9717e-01,  7.4223e-01,  5.4503e-01, -9.9811e-02,
         6.6196e-01,  7.3132e-01,  1.0128e+00,  1.4053e+00,  2.4462e-01,
         2.7779e-01,  7.0362e-01,  4.4566e-03, -1.6321e-02, -2.5552e-01,
        -5.8252e+00], device='cuda:1')
Solve time for step 1 9.873518646985758
Current ori: tensor([ 0.0045, -0.0163, -0.2555], device='cuda:1')
Index force: tensor([0.5980, 0.6095, 0.5921, 0.6006], device='cuda:1')
tensor([-1.4292e-02,  4.8829e-01,  5.7027e-01,  6.1077e-01, -1.4922e-01,
         5.1494e-01,  8.0555e-01,  9.1740e-01,  1.2513e+00,  2.6051e-01,
         1.5909e-01,  9.7970e-01, -1.0081e-02, -5.4475e-03, -2.5548e-01,
        -5.8389e+00], device='cuda:1')
Solve time for step 2 3.8453300510300323
Current ori: tensor([-0.0101, -0.0054, -0.2555], device='cuda:1')
Index force: tensor([0.6028, 0.5883, 0.5972], device='cuda:1')
tensor([-2.4230e-02,  5.1123e-01,  5.2771e-01,  6.1555e-01, -1.5484e-01,
         4.9761e-01,  8.2455e-01,  9.0267e-01,  1.2403e+00,  2.6489e-01,
         1.4710e-01,  1.0317e+00, -1.7852e-02,  8.9014e-04, -2.5548e-01,
        -5.8700e+00], device='cuda:1')
Solve time for step 3 3.724561701004859
Current ori: tensor([-0.0179,  0.0009, -0.2555], device='cuda:1')
Index force: tensor([0.5756, 0.5879], device='cuda:1')
tensor([-2.8094e-02,  5.0658e-01,  5.2482e-01,  6.2783e-01, -1.5729e-01,
         4.9384e-01,  8.2666e-01,  8.9752e-01,  1.2375e+00,  2.6720e-01,
         1.4536e-01,  1.0469e+00, -1.5992e-02,  3.0775e-03, -2.5548e-01,
        -5.8737e+00], device='cuda:1')
Solve time for step 4 3.8658026010380127
Current ori: tensor([-0.0160,  0.0031, -0.2555], device='cuda:1')
Index force: tensor([0.6393], device='cuda:1')
Storing RECOVERY transition: reward=-0.0104 (scaled=-0.0104), steps=1
Reward stats updated: mean 0.0211 -> 0.0209, std: 0.1414
Collected 182 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.5279, Q2 Loss=1.5279, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2217
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9555, Q2 Loss=0.9555, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6445
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1019, Q2 Loss=1.1019, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6135
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0677, Q2 Loss=1.0677, Entropy=0.0005, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4841
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0620, Q2 Loss=1.0620, Entropy=0.0001, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8436

------ SAC Update Summary (5 iterations) ------
Total time: 0.41s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.9%)
Q1 update: 0.08s (18.8%)
Q2 update: 0.08s (18.6%)
Actor update: 0.16s (39.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.143007
Q2 loss: 1.143007
Current threshold: -149.5111
Global Scale Offset: 1.9392
Reward stats: mean=0.0209, std=0.1414, count=182
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.1430, Q2 Loss: 1.1430, Entropy: 0.0001, Mean TD Error: 1.1615, Threshold: -149.5111
Original likelihood: -77.18898010253906
Adjusted likelihood: -77.18898010253906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0127,  0.0049, -0.2451], device='cuda:1')
7 turn
Sampling time 5.099349031981546
tensor([-3.4173e-02,  5.0758e-01,  5.2028e-01,  6.2425e-01, -9.3478e-02,
         5.3870e-01,  8.6509e-01,  9.1731e-01,  1.2963e+00,  2.8506e-01,
         2.0722e-01,  1.0838e+00, -1.2732e-02,  4.9028e-03, -2.4505e-01,
        -5.8763e+00], device='cuda:1')
Original likelihood: -78.91912841796875
Adjusted likelihood: -78.91912841796875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.627972515998408
Current ori: tensor([-0.0127,  0.0049, -0.2451], device='cuda:1')
Middle force: tensor([0.8910, 1.5395, 1.1127, 0.5063, 0.5605, 0.5345, 0.5416, 0.6020, 0.6646,
        0.5435, 0.5790, 0.6985], device='cuda:1')
Thumb force: tensor([0.9366, 0.7778, 0.9656, 0.5467, 0.7939, 0.8369, 0.8924, 0.6308, 0.5435,
        0.5388, 0.5124, 0.5645], device='cuda:1')
Index force: tensor([0.8670, 0.8262, 0.5581, 0.8031, 0.5711, 0.5322, 0.5329, 0.5597, 0.6388,
        0.7694, 0.5677, 0.6023], device='cuda:1')
Storing NORMAL transition: reward=0.0751 (scaled=0.0751), steps=1
Reward stats updated: mean 0.0209 -> 0.0212, std: 0.1411
Collected 183 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7520, Q2 Loss=0.7520, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5374
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8924, Q2 Loss=0.8924, Entropy=0.0005, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3610
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8840, Q2 Loss=0.8840, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8332
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.7362, Q2 Loss=0.7362, Entropy=0.3206, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5227
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=3.3766, Q2 Loss=3.3766, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0375

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.8%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (18.5%)
Actor update: 0.13s (40.5%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000133
Q1 loss: 1.328241
Q2 loss: 1.328241
Current threshold: -149.5134
Global Scale Offset: 1.9526
Reward stats: mean=0.0212, std=0.1411, count=183
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.3282, Q2 Loss: 1.3282, Entropy: 0.0642, Mean TD Error: 1.4583, Threshold: -149.5134
tensor([-0.0531,  0.4734,  0.5426,  0.6443, -0.1144,  0.5261,  0.8512,  0.9498,
         1.3411,  0.2645,  0.2248,  0.9876, -0.0186,  0.0191, -0.3208, -5.9206],
       device='cuda:1')
Original likelihood: -93.35406494140625
Adjusted likelihood: -93.35406494140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.111740580992773
Current ori: tensor([-0.0186,  0.0191, -0.3208], device='cuda:1')
Middle force: tensor([1.4822, 1.0819, 0.5048, 0.5502, 0.5299, 0.5378, 0.5923, 0.6561, 0.5364,
        0.5716, 0.6864], device='cuda:1')
Thumb force: tensor([0.7517, 0.9403, 0.5412, 0.7730, 0.8183, 0.8772, 0.6254, 0.5390, 0.5345,
        0.5103, 0.5601], device='cuda:1')
Index force: tensor([0.8027, 0.5525, 0.8026, 0.5644, 0.5288, 0.5302, 0.5558, 0.6317, 0.7690,
        0.5635, 0.5960], device='cuda:1')
Storing NORMAL transition: reward=-0.0219 (scaled=-0.0219), steps=1
Reward stats updated: mean 0.0212 -> 0.0209, std: 0.1407
Collected 184 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5372, Q2 Loss=0.5372, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2534
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9462, Q2 Loss=0.9462, Entropy=0.0007, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8718
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6987, Q2 Loss=0.6987, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0882
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=3.4174, Q2 Loss=3.4174, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0499
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6479, Q2 Loss=0.6479, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3963

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (21.8%)
Q1 update: 0.06s (18.9%)
Q2 update: 0.06s (18.4%)
Actor update: 0.12s (37.5%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.249480
Q2 loss: 1.249480
Current threshold: -149.5157
Global Scale Offset: 1.9655
Reward stats: mean=0.0209, std=0.1407, count=184
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2495, Q2 Loss: 1.2495, Entropy: 0.0001, Mean TD Error: 1.9319, Threshold: -149.5157
tensor([-0.1480,  0.3033,  0.5445,  0.5925, -0.0267,  0.5432,  0.8234,  0.9339,
         1.3199,  0.2638,  0.1498,  1.0639, -0.0249, -0.0186, -0.2991, -3.1144],
       device='cuda:1')
Original likelihood: -200.04066467285156
Adjusted likelihood: -200.04066467285156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.2310, -3.4187, -3.5524, -4.2545, -4.5659, -4.5757, -4.7807, -4.8468,
        -4.9894, -5.3546, -5.7391, -5.8196, -6.0935, -6.7410, -8.9521, -9.7679],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2310, -3.4187, -3.5524, -4.2545, -4.5659, -4.5757, -4.7807, -4.8468,
        -4.9894, -5.3546, -5.7391, -5.8196, -6.0935, -6.7410, -8.9521, -9.7679],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.4177
1 mode projection succeeded
New goal: tensor([ 8.7553e-04,  4.8995e-01,  6.1319e-01,  5.4891e-01, -1.1219e-02,
         6.0202e-01,  6.3035e-01,  1.0124e+00,  1.3837e+00,  9.6487e-02,
         1.3596e-01,  1.1441e+00, -2.1815e-02, -5.7233e-03, -1.6398e-01],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0206]], device='cuda:1')
Original likelihood: -104.18841552734375
Adjusted likelihood: -104.18841552734375
Likelihood residual: 0.0
{'index': 104.18841552734375, 'thumb_middle': inf}
Current yaw: tensor([-0.0249, -0.0186, -0.2991], device='cuda:1')
8 index
tensor([-0.1480,  0.3033,  0.5445,  0.5925, -0.0267,  0.5432,  0.8234,  0.9339,
         1.3199,  0.2638,  0.1498,  1.0639, -0.0249, -0.0186, -0.2991, -3.1144],
       device='cuda:1')
Solve time for step 1 11.087604566011578
Current ori: tensor([-0.0249, -0.0186, -0.2991], device='cuda:1')
Middle force: tensor([0.5099, 0.5428, 0.5724, 0.5348], device='cuda:1')
Thumb force: tensor([0.5747, 0.6351, 0.6143, 0.5000], device='cuda:1')
tensor([-0.0097,  0.4138,  0.5595,  0.5327, -0.0167,  0.5972,  0.7073,  1.0410,
         1.3943,  0.1370,  0.0732,  1.0963, -0.0318, -0.0260, -0.3362, -1.3181],
       device='cuda:1')
Solve time for step 2 4.48588898498565
Current ori: tensor([-0.0318, -0.0260, -0.3362], device='cuda:1')
Middle force: tensor([0.5251, 0.5213, 0.5517], device='cuda:1')
Thumb force: tensor([0.6604, 0.5645, 0.5245], device='cuda:1')
tensor([ 0.0154,  0.4301,  0.5586,  0.5216, -0.0253,  0.6101,  0.6768,  1.0496,
         1.4123,  0.1065,  0.0722,  1.0980, -0.0331, -0.0198, -0.3117, -0.4379],
       device='cuda:1')
Solve time for step 3 4.744605341984425
Current ori: tensor([-0.0331, -0.0198, -0.3117], device='cuda:1')
Middle force: tensor([0.5620, 0.5255], device='cuda:1')
Thumb force: tensor([0.5535, 0.6391], device='cuda:1')
tensor([ 0.0212,  0.4325,  0.5597,  0.5196, -0.0273,  0.6143,  0.6740,  1.0550,
         1.4098,  0.1081,  0.0687,  1.1107, -0.0309, -0.0206, -0.3006,  0.0842],
       device='cuda:1')
Solve time for step 4 4.2366275590029545
Current ori: tensor([-0.0309, -0.0206, -0.3006], device='cuda:1')
Middle force: tensor([0.5172], device='cuda:1')
Thumb force: tensor([0.5298], device='cuda:1')
Storing RECOVERY transition: reward=0.0110 (scaled=0.0055), steps=2
Reward stats updated: mean 0.0209 -> 0.0209, std: 0.1403
Collected 185 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8115, Q2 Loss=0.8115, Entropy=0.0006, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7203
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.5778, Q2 Loss=1.5778, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1802
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.5682, Q2 Loss=0.5682, Entropy=0.3440, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1999
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9483, Q2 Loss=0.9483, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5525
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2091, Q2 Loss=1.2091, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7380

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.5%)
Q1 update: 0.07s (19.9%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (40.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001599
Q1 loss: 1.022997
Q2 loss: 1.022997
Current threshold: -149.5063
Global Scale Offset: 1.9569
Reward stats: mean=0.0209, std=0.1403, count=185
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 1.0230, Q2 Loss: 1.0230, Entropy: 0.0689, Mean TD Error: 1.4782, Threshold: -149.5063
Original likelihood: -125.43838500976562
Adjusted likelihood: -125.43838500976562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0391, -0.0194, -0.3111], device='cuda:1')
9 turn
Sampling time 5.34226663998561
tensor([-0.0045,  0.4925,  0.6019,  0.5420, -0.0311,  0.6244,  0.6670,  1.0463,
         1.4169,  0.1040,  0.0658,  1.0956, -0.0391, -0.0194, -0.3111,  0.3934],
       device='cuda:1')
Original likelihood: -123.70072174072266
Adjusted likelihood: -123.70072174072266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.604241075983737
Current ori: tensor([-0.0391, -0.0194, -0.3111], device='cuda:1')
Middle force: tensor([0.9255, 0.6173, 0.6249, 0.8206, 1.0975, 0.5141, 0.5531, 0.5918, 0.5060,
        0.5086, 0.5617, 0.8227], device='cuda:1')
Thumb force: tensor([0.9605, 0.5704, 0.6114, 0.6384, 1.1179, 0.5922, 0.6832, 0.5993, 1.9534,
        0.5536, 0.5571, 0.5500], device='cuda:1')
Index force: tensor([1.1908, 0.5919, 0.5147, 0.5038, 0.5531, 0.7106, 0.6387, 0.5935, 0.5141,
        0.8116, 0.6959, 0.5613], device='cuda:1')
Storing NORMAL transition: reward=0.0302 (scaled=0.0302), steps=1
Reward stats updated: mean 0.0209 -> 0.0209, std: 0.1400
Collected 186 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6743, Q2 Loss=0.6743, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4843
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=9.8193, Q2 Loss=9.8193, Entropy=0.1399, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.1653
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7337, Q2 Loss=0.7337, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3207
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.4455, Q2 Loss=1.4455, Entropy=0.0089, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2154
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.0331, Q2 Loss=3.0331, Entropy=0.0001, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6325

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.6%)
Q1 update: 0.07s (19.4%)
Q2 update: 0.07s (19.2%)
Actor update: 0.15s (40.8%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000173
Q1 loss: 3.141198
Q2 loss: 3.141198
Current threshold: -149.4927
Global Scale Offset: 1.9876
Reward stats: mean=0.0209, std=0.1400, count=186
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 3.1412, Q2 Loss: 3.1412, Entropy: 0.0298, Mean TD Error: 2.3636, Threshold: -149.4927
tensor([-0.0197,  0.4671,  0.6425,  0.5086, -0.0505,  0.6140,  0.6462,  1.0865,
         1.4154,  0.1281,  0.1032,  1.0534, -0.0369, -0.0054, -0.3410,  0.3576],
       device='cuda:1')
Original likelihood: -106.2576675415039
Adjusted likelihood: -106.2576675415039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.27220722194761
Current ori: tensor([-0.0369, -0.0054, -0.3410], device='cuda:1')
Middle force: tensor([0.6109, 0.6108, 0.8101, 1.0862, 0.5127, 0.5509, 0.5896, 0.5056, 0.5076,
        0.5578, 0.8154], device='cuda:1')
Thumb force: tensor([0.5686, 0.6095, 0.6349, 1.1015, 0.5899, 0.6793, 0.5956, 1.9186, 0.5518,
        0.5557, 0.5486], device='cuda:1')
Index force: tensor([0.5884, 0.5161, 0.5039, 0.5521, 0.7115, 0.6358, 0.5913, 0.5136, 0.8144,
        0.6948, 0.5594], device='cuda:1')
Storing NORMAL transition: reward=-0.0308 (scaled=-0.0308), steps=1
Reward stats updated: mean 0.0209 -> 0.0206, std: 0.1396
Collected 187 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7919, Q2 Loss=0.7919, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7375
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5820, Q2 Loss=0.5820, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5572
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6512, Q2 Loss=0.6512, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4469
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.4493, Q2 Loss=1.4493, Entropy=0.0099, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0977
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=3.0359, Q2 Loss=3.0359, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0310

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.3%)
Q1 update: 0.08s (19.2%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000006
Q1 loss: 1.302059
Q2 loss: 1.302059
Current threshold: -149.4840
Global Scale Offset: 2.0196
Reward stats: mean=0.0206, std=0.1396, count=187
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3021, Q2 Loss: 1.3021, Entropy: 0.0020, Mean TD Error: 1.5740, Threshold: -149.4840
tensor([-0.0845,  0.3791,  0.6916,  0.5535, -0.1646,  0.6267,  0.5958,  1.1274,
         1.4343,  0.1702,  0.1721,  1.0394, -0.0385,  0.0549, -0.3130, -0.0863],
       device='cuda:1')
Original likelihood: -256.68743896484375
Adjusted likelihood: -256.68743896484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.5733, -3.7117, -3.7266, -3.8994, -3.9242, -4.0412, -4.1774, -4.5291,
        -4.5425, -5.1691, -6.1368, -6.5777, -6.7633, -7.4232, -7.5087, -7.9527],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.5733, -3.7117, -3.7266, -3.8994, -3.9242, -4.0412, -4.1774, -4.5291,
        -4.5425, -5.1691, -6.1368, -6.5777, -6.7633, -7.4232, -7.5087, -7.9527],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2286
1 mode projection succeeded
New goal: tensor([ 8.9888e-04,  4.9061e-01,  6.1329e-01,  5.4706e-01, -1.2281e-02,
         6.0310e-01,  6.2767e-01,  1.0133e+00,  1.3846e+00,  9.4145e-02,
         1.3688e-01,  1.1430e+00, -2.2046e-02, -5.2664e-03, -2.0500e-01],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0033]], device='cuda:1')
Original likelihood: -118.3673324584961
Adjusted likelihood: -118.3673324584961
Likelihood residual: 0.0
Original likelihood: -141.88430786132812
Adjusted likelihood: -141.88430786132812
Likelihood residual: 0.0
{'index': 141.88430786132812, 'thumb_middle': 118.3673324584961}
Current yaw: tensor([-0.0385,  0.0549, -0.3130], device='cuda:1')
10 thumb_middle
tensor([-0.0845,  0.3791,  0.6916,  0.5535, -0.1646,  0.6267,  0.5958,  1.1274,
         1.4343,  0.1702,  0.1721,  1.0394, -0.0385,  0.0549, -0.3130, -0.0863],
       device='cuda:1')
Solve time for step 1 9.185760184016544
Current ori: tensor([-0.0385,  0.0549, -0.3130], device='cuda:1')
Index force: tensor([0.6204, 0.6131, 0.5905, 0.6026], device='cuda:1')
tensor([-0.0620,  0.4279,  0.6370,  0.5668, -0.1732,  0.5631,  0.5778,  1.0064,
         1.3663,  0.0842,  0.1001,  1.1121, -0.0581,  0.1039, -0.3130, -0.5377],
       device='cuda:1')
Solve time for step 2 3.983384167018812
Current ori: tensor([-0.0581,  0.1039, -0.3130], device='cuda:1')
Index force: tensor([0.6156, 0.5897, 0.5963], device='cuda:1')
tensor([-0.0347,  0.4430,  0.6304,  0.5804, -0.2018,  0.5476,  0.5660,  0.9828,
         1.3946,  0.0869,  0.1095,  1.1388, -0.0482,  0.1267, -0.3090, -0.9012],
       device='cuda:1')
Solve time for step 3 3.868594808038324
Current ori: tensor([-0.0482,  0.1267, -0.3090], device='cuda:1')
Index force: tensor([0.6260, 0.5929], device='cuda:1')
tensor([-0.0159,  0.4571,  0.6260,  0.5782, -0.2174,  0.5454,  0.5500,  0.9722,
         1.4262,  0.0867,  0.1130,  1.1479, -0.0391,  0.1372, -0.2916, -1.1566],
       device='cuda:1')
Solve time for step 4 3.5235498710535467
Current ori: tensor([-0.0391,  0.1372, -0.2916], device='cuda:1')
Index force: tensor([0.5884], device='cuda:1')
Storing RECOVERY transition: reward=-0.0055 (scaled=-0.0028), steps=2
Reward stats updated: mean 0.0206 -> 0.0205, std: 0.1393
Collected 188 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=8.5253, Q2 Loss=8.5253, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1706
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6718, Q2 Loss=0.6718, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3638
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=1.2939, Q2 Loss=1.2939, Entropy=0.1483, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7916
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0765, Q2 Loss=1.0765, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1719
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0743, Q2 Loss=1.0743, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6009

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.0%)
Q1 update: 0.06s (17.7%)
Q2 update: 0.06s (17.9%)
Actor update: 0.14s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000057
Q1 loss: 2.528350
Q2 loss: 2.528350
Current threshold: -149.4781
Global Scale Offset: 2.0530
Reward stats: mean=0.0205, std=0.1393, count=188
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.5284, Q2 Loss: 2.5284, Entropy: 0.0297, Mean TD Error: 1.8197, Threshold: -149.4781
Original likelihood: -226.48593139648438
Adjusted likelihood: -226.48593139648438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -19.8531,  -21.0336,  -23.0998,  -27.9757,  -28.8952,  -28.9985,
         -30.7034,  -31.5492,  -31.9289,  -33.1065,  -35.4568,  -39.9115,
         -39.9577,  -45.9315,  -73.4726, -102.4742], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -19.8531,  -21.0336,  -23.0998,  -27.9757,  -28.8952,  -28.9985,
         -30.7034,  -31.5492,  -31.9289,  -33.1065,  -35.4568,  -39.9115,
         -39.9577,  -45.9315,  -73.4726, -102.4742], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -38.3968
1 mode projection succeeded
New goal: tensor([ 0.0237,  0.5394,  0.5630,  0.5691, -0.0716,  0.4858,  0.8753,  0.8734,
         1.2860,  0.2778,  0.1755,  1.2432, -0.0064,  0.0171, -2.9988],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -202.3096923828125
Adjusted likelihood: -202.3096923828125
Likelihood residual: 0.0
Original likelihood: -168.317138671875
Adjusted likelihood: -168.317138671875
Likelihood residual: 0.0
{'index': 168.317138671875, 'thumb_middle': 202.3096923828125}
Current yaw: tensor([-0.0480,  0.1199, -0.3191], device='cuda:1')
11 index
tensor([ 0.0046,  0.4690,  0.6313,  0.5701, -0.1876,  0.5451,  0.5704,  0.9820,
         1.4929,  0.1296,  0.1744,  1.1626, -0.0480,  0.1199, -0.3191, -1.0561],
       device='cuda:1')
Solve time for step 1 11.912848447973374
Current ori: tensor([-0.0480,  0.1199, -0.3191], device='cuda:1')
Middle force: tensor([0.5474, 0.5153, 0.5724, 0.5584], device='cuda:1')
Thumb force: tensor([0.6648, 0.5899, 0.5142, 0.5864], device='cuda:1')
tensor([ 0.0494,  0.4627,  0.5191,  0.5413, -0.1353,  0.4730,  0.7755,  0.8458,
         1.3760,  0.2859,  0.1905,  1.1648, -0.0505,  0.0864, -0.3871, -1.4183],
       device='cuda:1')
Solve time for step 2 4.455339160980657
Current ori: tensor([-0.0505,  0.0864, -0.3871], device='cuda:1')
Middle force: tensor([0.5158, 0.5706, 0.5557], device='cuda:1')
Thumb force: tensor([0.5910, 0.5134, 0.5809], device='cuda:1')
tensor([ 0.0560,  0.4736,  0.5069,  0.5425, -0.1271,  0.4464,  0.8157,  0.8490,
         1.3647,  0.2897,  0.1717,  1.2200, -0.0400,  0.0794, -0.3851, -1.4123],
       device='cuda:1')
Solve time for step 3 4.448131799988914
Current ori: tensor([-0.0400,  0.0794, -0.3851], device='cuda:1')
Middle force: tensor([0.5667, 0.5524], device='cuda:1')
Thumb force: tensor([0.5115, 0.5741], device='cuda:1')
tensor([ 0.0528,  0.4749,  0.5050,  0.5391, -0.1178,  0.4523,  0.8192,  0.8398,
         1.3610,  0.2891,  0.1605,  1.2321, -0.0417,  0.0734, -0.3783, -1.1622],
       device='cuda:1')
Solve time for step 4 4.445175395987462
Current ori: tensor([-0.0417,  0.0734, -0.3783], device='cuda:1')
Middle force: tensor([0.5474], device='cuda:1')
Thumb force: tensor([0.5622], device='cuda:1')
Storing RECOVERY transition: reward=0.0514 (scaled=0.0257), steps=2
Reward stats updated: mean 0.0205 -> 0.0205, std: 0.1389
Collected 189 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8126, Q2 Loss=0.8126, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8486
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.6569, Q2 Loss=0.6569, Entropy=0.0477, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3242
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8012, Q2 Loss=0.8012, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3028
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0151, Q2 Loss=1.0151, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8698
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9713, Q2 Loss=0.9713, Entropy=0.0009, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0890

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (25.1%)
Q1 update: 0.05s (17.5%)
Q2 update: 0.05s (17.1%)
Actor update: 0.11s (36.3%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000039
Q1 loss: 0.851419
Q2 loss: 0.851419
Current threshold: -149.4735
Global Scale Offset: 2.0984
Reward stats: mean=0.0205, std=0.1389, count=189
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8514, Q2 Loss: 0.8514, Entropy: 0.0097, Mean TD Error: 0.4869, Threshold: -149.4735
Original likelihood: -150.39614868164062
Adjusted likelihood: -150.39614868164062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3840)
Current yaw: tensor([-0.0437,  0.0682, -0.3671], device='cuda:1')
12 turn
Sampling time 5.138933257025201
tensor([ 0.0086,  0.5395,  0.5505,  0.5638, -0.1093,  0.4612,  0.8169,  0.8308,
         1.3519,  0.2969,  0.1553,  1.2423, -0.0437,  0.0682, -0.3671, -1.0496],
       device='cuda:1')
Original likelihood: -148.1086883544922
Adjusted likelihood: -148.1086883544922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6687)
State is out of distribution
Final likelihood: tensor([ -2.9854,  -4.1112,  -4.1584,  -4.3524,  -4.4428,  -4.5577,  -4.6915,
         -5.2966,  -5.3912,  -6.1672,  -7.0753,  -7.1103,  -7.3597,  -8.0242,
         -8.2185, -12.4238], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.9854,  -4.1112,  -4.1584,  -4.3524,  -4.4428,  -4.5577,  -4.6915,
         -5.2966,  -5.3912,  -6.1672,  -7.0753,  -7.1103,  -7.3597,  -8.0242,
         -8.2185, -12.4238], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.0229
1 mode projection succeeded
New goal: tensor([ 0.0475,  0.5155,  0.6233,  0.5569, -0.0561,  0.5002,  0.8244,  0.8963,
         1.2917,  0.2843,  0.1936,  1.1760, -0.0025,  0.0145, -0.9923],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -121.83927154541016
Adjusted likelihood: -121.83927154541016
Likelihood residual: 0.0
Original likelihood: -116.08523559570312
Adjusted likelihood: -116.08523559570312
Likelihood residual: 0.0
{'index': 116.08523559570312, 'thumb_middle': 121.83927154541016}
Current yaw: tensor([-0.0437,  0.0682, -0.3671], device='cuda:1')
13 index
tensor([ 0.0086,  0.5395,  0.5505,  0.5638, -0.1093,  0.4612,  0.8169,  0.8308,
         1.3519,  0.2969,  0.1553,  1.2423, -0.0437,  0.0682, -0.3671, -1.0496],
       device='cuda:1')
Solve time for step 1 11.934090403956361
Current ori: tensor([-0.0437,  0.0682, -0.3671], device='cuda:1')
Middle force: tensor([0.5793, 0.5241, 0.5261, 0.5052], device='cuda:1')
Thumb force: tensor([0.5579, 0.5957, 0.6859, 0.5744], device='cuda:1')
tensor([ 0.0781,  0.4590,  0.5556,  0.5306, -0.0855,  0.4698,  0.8009,  0.8703,
         1.3306,  0.3217,  0.1426,  1.2430, -0.0469,  0.0533, -0.4125, -1.0906],
       device='cuda:1')
Solve time for step 2 4.8592907229904085
Current ori: tensor([-0.0469,  0.0533, -0.4125], device='cuda:1')
Middle force: tensor([0.5197, 0.5441, 0.5583], device='cuda:1')
Thumb force: tensor([0.5971, 0.6019, 0.6207], device='cuda:1')
tensor([ 0.0825,  0.4552,  0.5645,  0.5251, -0.0875,  0.4593,  0.8052,  0.8904,
         1.3405,  0.3071,  0.1334,  1.2555, -0.0431,  0.0541, -0.4226, -0.9166],
       device='cuda:1')
Solve time for step 3 4.589741236995906
Current ori: tensor([-0.0431,  0.0541, -0.4226], device='cuda:1')
Middle force: tensor([0.5406, 0.5542], device='cuda:1')
Thumb force: tensor([0.5926, 0.6142], device='cuda:1')
tensor([ 0.0810,  0.4558,  0.5614,  0.5290, -0.0830,  0.4674,  0.7987,  0.8875,
         1.3304,  0.3199,  0.1359,  1.2552, -0.0449,  0.0513, -0.4180, -0.5556],
       device='cuda:1')
Solve time for step 4 4.54500794201158
Current ori: tensor([-0.0449,  0.0513, -0.4180], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5528], device='cuda:1')
Storing RECOVERY transition: reward=0.0511 (scaled=0.0511), steps=0
Reward stats updated: mean 0.0205 -> 0.0207, std: 0.1386
Collected 190 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0745, Q2 Loss=1.0745, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6063
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.7589, Q2 Loss=4.7589, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3538
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=4.3968, Q2 Loss=4.3968, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2925
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=1.6528, Q2 Loss=1.6528, Entropy=0.3251, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9667
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1970, Q2 Loss=1.1970, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4952

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.7%)
Q1 update: 0.06s (19.1%)
Q2 update: 0.06s (18.0%)
Actor update: 0.13s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000306
Q1 loss: 2.616007
Q2 loss: 2.616007
Current threshold: -149.4684
Global Scale Offset: 2.1661
Reward stats: mean=0.0207, std=0.1386, count=190
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 2.6160, Q2 Loss: 2.6160, Entropy: 0.0650, Mean TD Error: 2.9429, Threshold: -149.4684
Original likelihood: -129.32980346679688
Adjusted likelihood: -129.32980346679688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0489,  0.0475, -0.4169], device='cuda:1')
14 turn
Sampling time 5.30307287798496
tensor([ 0.0339,  0.5200,  0.6062,  0.5491, -0.0768,  0.4785,  0.7940,  0.8754,
         1.3209,  0.3326,  0.1367,  1.2505, -0.0489,  0.0475, -0.4169, -0.3814],
       device='cuda:1')
Original likelihood: -133.25950622558594
Adjusted likelihood: -133.25950622558594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.851895471976604
Current ori: tensor([-0.0489,  0.0475, -0.4169], device='cuda:1')
Middle force: tensor([0.5205, 0.5041, 0.5408, 1.5513, 0.5777, 0.9340, 0.6202, 0.5822, 0.5881,
        0.5796, 0.5942, 0.5746], device='cuda:1')
Thumb force: tensor([0.5436, 0.6778, 0.5923, 1.4048, 0.5567, 0.6101, 0.5355, 0.5008, 0.5822,
        0.6173, 0.5971, 1.0048], device='cuda:1')
Index force: tensor([0.7390, 0.5415, 0.6138, 0.5077, 0.5798, 0.5711, 0.5829, 0.5472, 0.5943,
        0.6102, 0.5878, 0.6138], device='cuda:1')
Storing NORMAL transition: reward=0.0038 (scaled=0.0038), steps=1
Reward stats updated: mean 0.0207 -> 0.0206, std: 0.1382
Collected 191 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=1.0874, Q2 Loss=1.0874, Entropy=0.1568, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3693
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=1.1536, Q2 Loss=1.1536, Entropy=0.0615, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0143
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9332, Q2 Loss=0.9332, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3265
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7197, Q2 Loss=0.7197, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4684
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=1.5559, Q2 Loss=1.5559, Entropy=0.1725, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9208

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.8%)
Q1 update: 0.07s (19.2%)
Q2 update: 0.07s (18.6%)
Actor update: 0.15s (38.1%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000344
Q1 loss: 1.089972
Q2 loss: 1.089972
Current threshold: -149.4581
Global Scale Offset: 2.3318
Reward stats: mean=0.0206, std=0.1382, count=191
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.0900, Q2 Loss: 1.0900, Entropy: 0.0782, Mean TD Error: 0.8199, Threshold: -149.4581
tensor([ 0.0453,  0.5598,  0.5441,  0.5837, -0.0574,  0.4085,  0.9062,  0.8123,
         1.3167,  0.3496,  0.0679,  1.4483, -0.0551,  0.0464, -0.4212, -0.4452],
       device='cuda:1')
Original likelihood: -131.42822265625
Adjusted likelihood: -131.42822265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.18718110001646
Current ori: tensor([-0.0551,  0.0464, -0.4212], device='cuda:1')
Middle force: tensor([0.5037, 0.5324, 1.4879, 0.5724, 0.9086, 0.6139, 0.5755, 0.5802, 0.5705,
        0.5834, 0.5671], device='cuda:1')
Thumb force: tensor([0.6652, 0.5999, 1.3601, 0.5549, 0.6048, 0.5316, 0.5002, 0.5798, 0.6137,
        0.5939, 0.9816], device='cuda:1')
Index force: tensor([0.5391, 0.6059, 0.5073, 0.5733, 0.5646, 0.5783, 0.5434, 0.5900, 0.6028,
        0.5833, 0.6082], device='cuda:1')
Storing NORMAL transition: reward=0.1325 (scaled=0.1325), steps=1
Reward stats updated: mean 0.0206 -> 0.0212, std: 0.1381
Collected 192 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6409, Q2 Loss=0.6409, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3390
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2898, Q2 Loss=1.2898, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8346
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=3.6872, Q2 Loss=3.6872, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1864
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1644, Q2 Loss=1.1644, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7011
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6297, Q2 Loss=1.6297, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2738

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.6%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.5%)
Actor update: 0.14s (37.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.682409
Q2 loss: 1.682409
Current threshold: -149.4508
Global Scale Offset: 2.4591
Reward stats: mean=0.0212, std=0.1381, count=192
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.6824, Q2 Loss: 1.6824, Entropy: 0.0000, Mean TD Error: 1.6670, Threshold: -149.4508
tensor([-0.0114,  0.4725,  0.5986,  0.6137,  0.0115,  0.3536,  0.7955,  0.8862,
         1.3275,  0.4955,  0.0924,  1.2334, -0.0408,  0.0552, -0.5548,  0.0263],
       device='cuda:1')
Original likelihood: -178.80975341796875
Adjusted likelihood: -178.80975341796875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.1780,  -3.4383,  -4.1695,  -4.4063,  -4.5414,  -5.0100,  -5.0586,
         -5.0630,  -5.2650,  -5.6612,  -5.8648,  -6.2213,  -6.9201,  -7.4061,
         -8.0711, -12.4819], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.1780,  -3.4383,  -4.1695,  -4.4063,  -4.5414,  -5.0100,  -5.0586,
         -5.0630,  -5.2650,  -5.6612,  -5.8648,  -6.2213,  -6.9201,  -7.4061,
         -8.0711, -12.4819], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.7973
1 mode projection succeeded
New goal: tensor([ 0.0493,  0.5389,  0.5198,  0.6995, -0.0743,  0.4946,  0.8853,  0.8506,
         1.2711,  0.3137,  0.2216,  1.1419,  0.0013,  0.0130, -0.8453],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -115.65220642089844
Adjusted likelihood: -115.65220642089844
Likelihood residual: 0.0
Original likelihood: -167.8284149169922
Adjusted likelihood: -167.8284149169922
Likelihood residual: 0.0
{'index': 167.8284149169922, 'thumb_middle': 115.65220642089844}
Current yaw: tensor([-0.0408,  0.0552, -0.5548], device='cuda:1')
15 thumb_middle
tensor([-0.0114,  0.4725,  0.5986,  0.6137,  0.0115,  0.3536,  0.7955,  0.8862,
         1.3275,  0.4955,  0.0924,  1.2334, -0.0408,  0.0552, -0.5548,  0.0263],
       device='cuda:1')
Solve time for step 1 9.136189081997145
Current ori: tensor([-0.0408,  0.0552, -0.5548], device='cuda:1')
Index force: tensor([0.5761, 0.6041, 0.5991, 0.5955], device='cuda:1')
tensor([ 0.0093,  0.5014,  0.5370,  0.6915, -0.1777,  0.4502,  0.8298,  0.8332,
         1.2351,  0.3225,  0.1502,  1.1456, -0.0416,  0.0650, -0.5546, -0.1511],
       device='cuda:1')
Solve time for step 2 3.7814030000008643
Current ori: tensor([-0.0416,  0.0650, -0.5546], device='cuda:1')
Index force: tensor([0.5992, 0.5942, 0.5888], device='cuda:1')
tensor([ 0.0289,  0.5133,  0.5264,  0.7136, -0.2052,  0.4681,  0.8340,  0.8247,
         1.2395,  0.2976,  0.1681,  1.1352, -0.0396,  0.0643, -0.5546, -0.1292],
       device='cuda:1')
Solve time for step 3 3.6028381289797835
Current ori: tensor([-0.0396,  0.0643, -0.5546], device='cuda:1')
Index force: tensor([0.5997, 0.5741], device='cuda:1')
tensor([ 0.0486,  0.5227,  0.5256,  0.7248, -0.2068,  0.4699,  0.8343,  0.8225,
         1.2393,  0.2934,  0.1712,  1.1334, -0.0385,  0.0597, -0.5546, -0.1636],
       device='cuda:1')
Solve time for step 4 3.7296695870463736
Current ori: tensor([-0.0385,  0.0597, -0.5546], device='cuda:1')
Index force: tensor([0.5363], device='cuda:1')
Storing RECOVERY transition: reward=0.0050 (scaled=0.0025), steps=2
Reward stats updated: mean 0.0212 -> 0.0211, std: 0.1377
Collected 193 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0700, Q2 Loss=1.0700, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6181
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=1.2864, Q2 Loss=1.2864, Entropy=0.1865, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8036
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6694, Q2 Loss=0.6694, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3855
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2924, Q2 Loss=1.2924, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9080
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9473, Q2 Loss=0.9473, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8422

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.2%)
Q1 update: 0.07s (18.4%)
Q2 update: 0.07s (18.3%)
Actor update: 0.14s (37.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000080
Q1 loss: 1.053103
Q2 loss: 1.053103
Current threshold: -149.4454
Global Scale Offset: 2.5557
Reward stats: mean=0.0211, std=0.1377, count=193
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0531, Q2 Loss: 1.0531, Entropy: 0.0373, Mean TD Error: 0.9115, Threshold: -149.4454
Original likelihood: -156.37548828125
Adjusted likelihood: -156.37548828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0281)
State is out of distribution
Final likelihood: tensor([-4.9918, -5.4907, -5.8808, -5.9926, -6.0588, -6.8258, -6.8430, -7.0449,
        -7.3633, -7.3868, -7.4281, -7.6988, -7.7216, -8.0301, -8.0575, -8.9559],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-4.9918, -5.4907, -5.8808, -5.9926, -6.0588, -6.8258, -6.8430, -7.0449,
        -7.3633, -7.3868, -7.4281, -7.6988, -7.7216, -8.0301, -8.0575, -8.9559],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.9857
1 mode projection succeeded
New goal: tensor([ 4.9419e-02,  5.3850e-01,  5.1838e-01,  7.0394e-01, -7.4186e-02,
         4.9596e-01,  8.8356e-01,  8.5120e-01,  1.2700e+00,  3.1355e-01,
         2.2245e-01,  1.1429e+00,  1.1341e-03,  1.2879e-02, -1.4490e+00],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -119.10118865966797
Adjusted likelihood: -119.10118865966797
Likelihood residual: 0.0
Original likelihood: -111.27535247802734
Adjusted likelihood: -111.27535247802734
Likelihood residual: 0.0
{'index': 111.27535247802734, 'thumb_middle': 119.10118865966797}
Current yaw: tensor([-0.0409,  0.0439, -0.5584], device='cuda:1')
16 index
tensor([ 0.0694,  0.5232,  0.5408,  0.7312, -0.1475,  0.5408,  0.8700,  0.8190,
         1.3004,  0.3122,  0.2191,  1.1438, -0.0409,  0.0439, -0.5584, -0.0803],
       device='cuda:1')
Solve time for step 1 10.973878090037033
Current ori: tensor([-0.0409,  0.0439, -0.5584], device='cuda:1')
Middle force: tensor([0.5734, 0.5663, 0.5425, 0.5187], device='cuda:1')
Thumb force: tensor([0.5281, 0.5074, 0.5642, 0.5529], device='cuda:1')
tensor([ 0.0928,  0.4780,  0.4704,  0.6802, -0.1525,  0.5295,  0.8823,  0.8370,
         1.3051,  0.3110,  0.2287,  1.1167, -0.0435,  0.0462, -0.5923,  0.0464],
       device='cuda:1')
Solve time for step 2 4.358829187985975
Current ori: tensor([-0.0435,  0.0462, -0.5923], device='cuda:1')
Middle force: tensor([0.5648, 0.5402, 0.5171], device='cuda:1')
Thumb force: tensor([0.5062, 0.5594, 0.5493], device='cuda:1')
tensor([ 0.0886,  0.4839,  0.4632,  0.6741, -0.1499,  0.5086,  0.9006,  0.8701,
         1.3017,  0.3060,  0.2131,  1.1610, -0.0314,  0.0422, -0.5904,  0.4148],
       device='cuda:1')
Solve time for step 3 4.201559292036109
Current ori: tensor([-0.0314,  0.0422, -0.5904], device='cuda:1')
Middle force: tensor([0.5046, 0.5635], device='cuda:1')
Thumb force: tensor([0.5781, 0.5744], device='cuda:1')
tensor([ 0.0874,  0.4843,  0.4620,  0.6723, -0.1361,  0.5114,  0.9060,  0.8733,
         1.2857,  0.3209,  0.1999,  1.1816, -0.0310,  0.0320, -0.5952,  0.8855],
       device='cuda:1')
Solve time for step 4 4.334809165971819
Current ori: tensor([-0.0310,  0.0320, -0.5952], device='cuda:1')
Middle force: tensor([0.5249], device='cuda:1')
Thumb force: tensor([0.6412], device='cuda:1')
Storing RECOVERY transition: reward=0.0365 (scaled=0.0183), steps=2
Reward stats updated: mean 0.0211 -> 0.0211, std: 0.1374
Collected 194 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.8001, Q2 Loss=2.8001, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0703
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7693, Q2 Loss=0.7693, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7209
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6483, Q2 Loss=0.6483, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7384
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.5871, Q2 Loss=0.5871, Entropy=0.3262, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2845
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3659, Q2 Loss=1.3659, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2763

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.1%)
Q1 update: 0.07s (18.1%)
Q2 update: 0.07s (18.5%)
Actor update: 0.15s (39.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000169
Q1 loss: 1.234125
Q2 loss: 1.234125
Current threshold: -149.4427
Global Scale Offset: 2.6144
Reward stats: mean=0.0211, std=0.1374, count=194
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.2341, Q2 Loss: 1.2341, Entropy: 0.0652, Mean TD Error: 2.0181, Threshold: -149.4427
Original likelihood: -110.15803527832031
Adjusted likelihood: -110.15803527832031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0316,  0.0293, -0.5879], device='cuda:1')
17 turn
Sampling time 5.052573022025172
tensor([ 0.0411,  0.5446,  0.5052,  0.6964, -0.1322,  0.5162,  0.9047,  0.8686,
         1.2839,  0.3206,  0.1947,  1.1877, -0.0316,  0.0293, -0.5879,  1.0207],
       device='cuda:1')
Original likelihood: -95.31477355957031
Adjusted likelihood: -95.31477355957031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.565723409992643
Current ori: tensor([-0.0316,  0.0293, -0.5879], device='cuda:1')
Middle force: tensor([0.7212, 0.6156, 1.0027, 0.5141, 0.6108, 0.5175, 0.5095, 1.2273, 0.5426,
        0.5250, 0.6444, 0.5516], device='cuda:1')
Thumb force: tensor([2.5191, 1.6316, 0.5877, 0.5751, 0.5176, 0.5450, 0.5413, 0.5008, 0.8140,
        0.6233, 0.5590, 0.5079], device='cuda:1')
Index force: tensor([0.6284, 0.5701, 0.5034, 0.5457, 0.5184, 0.6818, 0.6522, 0.5505, 0.6009,
        0.5867, 0.5420, 0.6446], device='cuda:1')
Storing NORMAL transition: reward=-0.0037 (scaled=-0.0037), steps=1
Reward stats updated: mean 0.0211 -> 0.0210, std: 0.1370
Collected 195 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0541, Q2 Loss=1.0541, Entropy=0.0045, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4405
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5968, Q2 Loss=0.5968, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5778
SAC Update 3/5: Actor Loss=-0.0028, Q1 Loss=0.8532, Q2 Loss=0.8532, Entropy=0.3278, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1658
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2925, Q2 Loss=1.2925, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8431
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7407, Q2 Loss=0.7407, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1716

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (24.8%)
Q1 update: 0.06s (17.8%)
Q2 update: 0.05s (17.3%)
Actor update: 0.11s (36.3%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000564
Q1 loss: 0.907461
Q2 loss: 0.907461
Current threshold: -149.4455
Global Scale Offset: 2.6713
Reward stats: mean=0.0210, std=0.1370, count=195
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 0.9075, Q2 Loss: 0.9075, Entropy: 0.0665, Mean TD Error: 0.4398, Threshold: -149.4455
tensor([ 0.0527,  0.6156,  0.4595,  0.6062, -0.1263,  0.5900,  0.8021,  0.8684,
         1.3158,  0.3796,  0.1181,  1.1885, -0.0573,  0.0289, -0.5864,  0.9372],
       device='cuda:1')
Original likelihood: -132.89710998535156
Adjusted likelihood: -132.89710998535156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.817240662989207
Current ori: tensor([-0.0573,  0.0289, -0.5864], device='cuda:1')
Middle force: tensor([0.6159, 0.9704, 0.5132, 0.5999, 0.5121, 0.5065, 1.1922, 0.5384, 0.5214,
        0.6318, 0.5462], device='cuda:1')
Thumb force: tensor([1.6001, 0.5883, 0.5753, 0.5164, 0.5449, 0.5468, 0.5005, 0.8062, 0.6314,
        0.5602, 0.5075], device='cuda:1')
Index force: tensor([0.5634, 0.5040, 0.5428, 0.5186, 0.6810, 0.6461, 0.5496, 0.5965, 0.5820,
        0.5397, 0.6402], device='cuda:1')
Storing NORMAL transition: reward=-0.0503 (scaled=-0.0503), steps=1
Reward stats updated: mean 0.0210 -> 0.0206, std: 0.1368
Collected 196 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5702, Q2 Loss=0.5702, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2399
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5765, Q2 Loss=0.5765, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1920
SAC Update 3/5: Actor Loss=-0.0015, Q1 Loss=10.0550, Q2 Loss=10.0550, Entropy=0.2010, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.3101
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6128, Q2 Loss=0.6128, Entropy=0.0021, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2259
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7067, Q2 Loss=0.7067, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6886

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.3%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (38.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000298
Q1 loss: 2.504231
Q2 loss: 2.504231
Current threshold: -149.4465
Global Scale Offset: 2.7675
Reward stats: mean=0.0206, std=0.1368, count=196
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 2.5042, Q2 Loss: 2.5042, Entropy: 0.0406, Mean TD Error: 1.7313, Threshold: -149.4465
tensor([ 0.0906,  0.5556,  0.5715,  0.6234, -0.1773,  0.4791,  0.8553,  1.0227,
         1.3070,  0.3628,  0.1459,  1.3166,  0.0051,  0.0555, -0.5349,  0.2234],
       device='cuda:1')
Original likelihood: -226.95262145996094
Adjusted likelihood: -226.95262145996094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.0812, -3.2539, -3.5753, -3.7754, -4.0214, -4.2915, -4.3913, -4.5718,
        -4.9549, -5.1264, -5.7498, -5.8790, -6.0194, -6.1907, -6.7891, -6.7960],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.0812, -3.2539, -3.5753, -3.7754, -4.0214, -4.2915, -4.3913, -4.5718,
        -4.9549, -5.1264, -5.7498, -5.8790, -6.0194, -6.1907, -6.7891, -6.7960],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.9042
1 mode projection succeeded
New goal: tensor([ 0.0679,  0.5610,  0.5720,  0.5696, -0.0823,  0.5279,  0.8429,  0.8706,
         1.2505,  0.3590,  0.2053,  1.1943,  0.0042,  0.0138, -0.9731],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -147.20223999023438
Adjusted likelihood: -147.20223999023438
Likelihood residual: 0.0
Original likelihood: -124.30914306640625
Adjusted likelihood: -124.30914306640625
Likelihood residual: 0.0
{'index': 124.30914306640625, 'thumb_middle': 147.20223999023438}
Current yaw: tensor([ 0.0051,  0.0555, -0.5349], device='cuda:1')
18 index
tensor([ 0.0906,  0.5556,  0.5715,  0.6234, -0.1773,  0.4791,  0.8553,  1.0227,
         1.3070,  0.3628,  0.1459,  1.3166,  0.0051,  0.0555, -0.5349,  0.2234],
       device='cuda:1')
Solve time for step 1 11.062443001021165
Current ori: tensor([ 0.0051,  0.0555, -0.5349], device='cuda:1')
Middle force: tensor([0.5194, 0.5834, 0.5552, 0.5373], device='cuda:1')
Thumb force: tensor([0.5010, 0.6048, 0.5736, 0.5203], device='cuda:1')
tensor([ 0.1092,  0.5015,  0.5157,  0.5561, -0.1711,  0.4763,  0.8879,  0.9613,
         1.2848,  0.4020,  0.1622,  1.2881, -0.0064,  0.0536, -0.5623,  0.8189],
       device='cuda:1')
Solve time for step 2 4.561930674011819
Current ori: tensor([-0.0064,  0.0536, -0.5623], device='cuda:1')
Middle force: tensor([0.5800, 0.5518, 0.5345], device='cuda:1')
Thumb force: tensor([0.5929, 0.5700, 0.5189], device='cuda:1')
tensor([ 0.1115,  0.5011,  0.5170,  0.5442, -0.1474,  0.5268,  0.8594,  0.8975,
         1.2898,  0.4034,  0.1458,  1.2457, -0.0329,  0.0422, -0.5785,  1.2719],
       device='cuda:1')
Solve time for step 3 4.327607519982848
Current ori: tensor([-0.0329,  0.0422, -0.5785], device='cuda:1')
Middle force: tensor([0.5483, 0.5318], device='cuda:1')
Thumb force: tensor([0.5651, 0.5175], device='cuda:1')
tensor([ 0.1112,  0.5020,  0.5152,  0.5435, -0.1359,  0.5449,  0.8511,  0.8769,
         1.2838,  0.4106,  0.1387,  1.2418, -0.0402,  0.0351, -0.5765,  1.6176],
       device='cuda:1')
Solve time for step 4 4.631486495025456
Current ori: tensor([-0.0402,  0.0351, -0.5765], device='cuda:1')
Middle force: tensor([0.5413], device='cuda:1')
Thumb force: tensor([0.5455], device='cuda:1')
Storing RECOVERY transition: reward=0.0389 (scaled=0.0195), steps=2
Reward stats updated: mean 0.0206 -> 0.0206, std: 0.1364
Collected 197 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5766, Q2 Loss=0.5766, Entropy=0.0989, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3297
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6381, Q2 Loss=0.6381, Entropy=0.0096, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6137
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9720, Q2 Loss=0.9720, Entropy=0.0068, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0878
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.0862, Q2 Loss=1.0862, Entropy=0.2093, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7285
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9879, Q2 Loss=0.9879, Entropy=0.0012, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4324

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.2%)
Q1 update: 0.07s (19.6%)
Q2 update: 0.07s (19.0%)
Actor update: 0.13s (37.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000091
Q1 loss: 0.852170
Q2 loss: 0.852170
Current threshold: -149.4451
Global Scale Offset: 2.8739
Reward stats: mean=0.0206, std=0.1364, count=197
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.8522, Q2 Loss: 0.8522, Entropy: 0.0652, Mean TD Error: 0.6384, Threshold: -149.4451
Original likelihood: -130.012451171875
Adjusted likelihood: -130.012451171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0390,  0.0377, -0.5738], device='cuda:1')
19 turn
Sampling time 5.397760801017284
tensor([ 0.0572,  0.5651,  0.5596,  0.5651, -0.1396,  0.5416,  0.8522,  0.8782,
         1.2872,  0.4067,  0.1400,  1.2426, -0.0390,  0.0377, -0.5738,  1.7174],
       device='cuda:1')
Original likelihood: -124.86204528808594
Adjusted likelihood: -124.86204528808594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.684233770007268
Current ori: tensor([-0.0390,  0.0377, -0.5738], device='cuda:1')
Middle force: tensor([0.5583, 0.5228, 1.4963, 0.5107, 0.5181, 0.8254, 0.5899, 0.5010, 0.5613,
        0.5454, 0.5466, 0.5556], device='cuda:1')
Thumb force: tensor([1.1584, 1.2579, 0.5763, 0.5765, 0.6444, 1.3864, 0.6142, 0.5436, 0.7311,
        0.5692, 0.5755, 0.6013], device='cuda:1')
Index force: tensor([0.5519, 0.7173, 0.6024, 0.6569, 0.6192, 0.8549, 0.6160, 0.5706, 0.5623,
        0.7692, 0.5586, 0.5726], device='cuda:1')
Storing NORMAL transition: reward=0.1198 (scaled=0.1198), steps=1
Reward stats updated: mean 0.0206 -> 0.0211, std: 0.1363
Collected 198 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.9552, Q2 Loss=0.9552, Entropy=0.2118, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7058
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9910, Q2 Loss=0.9910, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6768
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1646, Q2 Loss=1.1646, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0368
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2217, Q2 Loss=1.2217, Entropy=0.0044, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9646
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.7609, Q2 Loss=1.7609, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7901

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.7%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (17.8%)
Actor update: 0.14s (39.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000059
Q1 loss: 1.218684
Q2 loss: 1.218684
Current threshold: -149.4430
Global Scale Offset: 2.9688
Reward stats: mean=0.0211, std=0.1363, count=198
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2187, Q2 Loss: 1.2187, Entropy: 0.0432, Mean TD Error: 1.2348, Threshold: -149.4430
tensor([ 0.0758,  0.5568,  0.5846,  0.5724, -0.1345,  0.5086,  0.8814,  0.9259,
         1.3540,  0.3267,  0.1084,  1.1820, -0.0381,  0.0333, -0.6940,  1.8115],
       device='cuda:1')
Original likelihood: -111.76701354980469
Adjusted likelihood: -111.76701354980469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.8089883829816245
Current ori: tensor([-0.0381,  0.0333, -0.6940], device='cuda:1')
Middle force: tensor([0.5202, 1.4376, 0.5101, 0.5157, 0.7974, 0.5868, 0.5005, 0.5567, 0.5450,
        0.5435, 0.5497], device='cuda:1')
Thumb force: tensor([1.2119, 0.5667, 0.5645, 0.6329, 1.3354, 0.6056, 0.5388, 0.7201, 0.5580,
        0.5697, 0.5920], device='cuda:1')
Index force: tensor([0.7050, 0.6077, 0.6448, 0.6090, 0.8417, 0.6087, 0.5645, 0.5560, 0.7605,
        0.5547, 0.5683], device='cuda:1')
Storing NORMAL transition: reward=0.0560 (scaled=0.0560), steps=1
Reward stats updated: mean 0.0211 -> 0.0213, std: 0.1359
Collected 199 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3055, Q2 Loss=1.3055, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8247
SAC Update 2/5: Actor Loss=-0.0017, Q1 Loss=7.0995, Q2 Loss=7.0995, Entropy=0.2179, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6784
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6515, Q2 Loss=0.6515, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6339
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1682, Q2 Loss=1.1682, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4833
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5835, Q2 Loss=0.5835, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2823

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (19.4%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000343
Q1 loss: 2.161644
Q2 loss: 2.161644
Current threshold: -149.4383
Global Scale Offset: 3.0987
Reward stats: mean=0.0213, std=0.1359, count=199
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 2.1616, Q2 Loss: 2.1616, Entropy: 0.0436, Mean TD Error: 1.5805, Threshold: -149.4383
tensor([ 0.0956,  0.5280,  0.6203,  0.6166, -0.1220,  0.4803,  0.9144,  0.9648,
         1.3825,  0.2744,  0.0824,  1.1817, -0.0289,  0.0241, -0.7489,  1.8950],
       device='cuda:1')
Original likelihood: -139.4254150390625
Adjusted likelihood: -139.4254150390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9913)
Solve time for step 3 5.833709056023508
Current ori: tensor([-0.0289,  0.0241, -0.7489], device='cuda:1')
Middle force: tensor([1.3878, 0.5091, 0.5123, 0.7722, 0.5846, 0.5002, 0.5527, 0.5415, 0.5415,
        0.5436], device='cuda:1')
Thumb force: tensor([0.5543, 0.5563, 0.6240, 1.2902, 0.5943, 0.5331, 0.7094, 0.5520, 0.5621,
        0.5839], device='cuda:1')
Index force: tensor([0.6038, 0.6333, 0.5995, 0.8245, 0.6024, 0.5589, 0.5495, 0.7507, 0.5508,
        0.5639], device='cuda:1')
Storing NORMAL transition: reward=0.1002 (scaled=0.1002), steps=1
Reward stats updated: mean 0.0213 -> 0.0217, std: 0.1357
Collected 200 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=1.0622, Q2 Loss=1.0622, Entropy=0.0777, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4326
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0653, Q2 Loss=1.0653, Entropy=0.0260, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0101
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6224, Q2 Loss=0.6224, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4038
SAC Update 4/5: Actor Loss=-0.0048, Q1 Loss=1.6502, Q2 Loss=1.6502, Entropy=0.3324, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9570
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2982, Q2 Loss=1.2982, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8611

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.2%)
Q1 update: 0.06s (17.6%)
Q2 update: 0.06s (17.6%)
Actor update: 0.13s (38.1%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001039
Q1 loss: 1.139647
Q2 loss: 1.139647
Current threshold: -149.4375
Global Scale Offset: 3.2683
Reward stats: mean=0.0217, std=0.1357, count=200
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 1.1396, Q2 Loss: 1.1396, Entropy: 0.0873, Mean TD Error: 1.5329, Threshold: -149.4375
tensor([ 0.1165,  0.5045,  0.6518,  0.6568, -0.0993,  0.4537,  0.9527,  1.0161,
         1.3766,  0.2762,  0.0683,  1.1744, -0.0212,  0.0096, -0.8481,  2.0864],
       device='cuda:1')
Original likelihood: -110.98060607910156
Adjusted likelihood: -110.98060607910156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.224740126985125
Current ori: tensor([-0.0212,  0.0096, -0.8481], device='cuda:1')
Middle force: tensor([0.5084, 0.5116, 0.7566, 0.5848, 0.5000, 0.5493, 0.5417, 0.5408, 0.5392],
       device='cuda:1')
Thumb force: tensor([0.5421, 0.6032, 1.2423, 0.5808, 0.5273, 0.6981, 0.5425, 0.5537, 0.5747],
       device='cuda:1')
Index force: tensor([0.6273, 0.5878, 0.8072, 0.5964, 0.5536, 0.5436, 0.7411, 0.5469, 0.5594],
       device='cuda:1')
Storing NORMAL transition: reward=0.0720 (scaled=0.0720), steps=1
Reward stats updated: mean 0.0217 -> 0.0219, std: 0.1354
Collected 201 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0222, Q2 Loss=1.0222, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4055
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.4691, Q2 Loss=1.4691, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6428
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=19.2348, Q2 Loss=19.2348, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0420
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0167, Q2 Loss=1.0167, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8598
SAC Update 5/5: Actor Loss=-0.0061, Q1 Loss=0.8969, Q2 Loss=0.8969, Entropy=0.3445, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1414

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.7%)
Q1 update: 0.08s (19.9%)
Q2 update: 0.08s (19.7%)
Actor update: 0.14s (36.7%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001213
Q1 loss: 4.727930
Q2 loss: 4.727930
Current threshold: -149.4438
Global Scale Offset: 3.4127
Reward stats: mean=0.0219, std=0.1354, count=201
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 4.7279, Q2 Loss: 4.7279, Entropy: 0.0689, Mean TD Error: 1.8183, Threshold: -149.4438
tensor([ 2.6038e-01,  4.8946e-01,  7.9948e-01,  6.9914e-01, -1.3864e-01,
         4.0820e-01,  8.5282e-01,  1.0977e+00,  1.3550e+00,  2.7585e-01,
        -1.2583e-02,  1.2148e+00, -8.1215e-04, -5.3989e-02, -9.2740e-01,
         2.2419e+00], device='cuda:1')
Original likelihood: -239.8336639404297
Adjusted likelihood: -239.8336639404297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.4918,  -3.6670,  -3.8606,  -3.9887,  -4.1593,  -4.1699,  -4.7123,
         -4.8146,  -5.1501,  -6.5717,  -6.8732,  -6.9003,  -7.2420, -15.5269,
        -17.3043, -17.9335], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.4918,  -3.6670,  -3.8606,  -3.9887,  -4.1593,  -4.1699,  -4.7123,
         -4.8146,  -5.1501,  -6.5717,  -6.8732,  -6.9003,  -7.2420, -15.5269,
        -17.3043, -17.9335], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.2729
1 mode projection succeeded
New goal: tensor([ 4.6296e-02,  5.3607e-01,  5.8564e-01,  5.7296e-01, -7.7149e-02,
         4.9333e-01,  8.6704e-01,  9.1583e-01,  1.2892e+00,  3.2230e-01,
         1.6327e-01,  1.2049e+00,  5.7554e-04,  1.2774e-02, -6.6347e-01],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0197]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -158.60951232910156
Adjusted likelihood: -158.60951232910156
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 158.60951232910156}
Current yaw: tensor([-8.1215e-04, -5.3989e-02, -9.2740e-01], device='cuda:1')
20 thumb_middle
tensor([ 2.6038e-01,  4.8946e-01,  7.9948e-01,  6.9914e-01, -1.3864e-01,
         4.0820e-01,  8.5282e-01,  1.0977e+00,  1.3550e+00,  2.7585e-01,
        -1.2583e-02,  1.2148e+00, -8.1215e-04, -5.3989e-02, -9.2740e-01,
         2.2419e+00], device='cuda:1')
Solve time for step 1 10.044001129979733
Current ori: tensor([-8.1215e-04, -5.3989e-02, -9.2740e-01], device='cuda:1')
Index force: tensor([0.7401, 0.7432, 0.6761, 0.6111], device='cuda:1')
tensor([ 0.2047,  0.4976,  0.7323,  0.6928, -0.1421,  0.5042,  0.8474,  0.9341,
         1.2217,  0.2827,  0.0541,  1.1805, -0.0100, -0.0244, -0.9274,  2.1777],
       device='cuda:1')
Solve time for step 2 4.015386945975479
Current ori: tensor([-0.0100, -0.0244, -0.9274], device='cuda:1')
Index force: tensor([0.7300, 0.6702, 0.6073], device='cuda:1')
tensor([ 1.6169e-01,  5.3445e-01,  6.6469e-01,  6.4079e-01, -1.6548e-01,
         5.1041e-01,  8.4101e-01,  9.0213e-01,  1.2204e+00,  2.8575e-01,
         7.6753e-02,  1.1859e+00, -2.4883e-02, -7.8289e-04, -9.2740e-01,
         2.0947e+00], device='cuda:1')
Solve time for step 3 3.9499333369894885
Current ori: tensor([-2.4883e-02, -7.8289e-04, -9.2740e-01], device='cuda:1')
Index force: tensor([0.6579, 0.6015], device='cuda:1')
tensor([ 0.1136,  0.5536,  0.6136,  0.5940, -0.1968,  0.4985,  0.8281,  0.8908,
         1.2328,  0.2911,  0.1029,  1.1948, -0.0335,  0.0275, -0.9274,  2.0173],
       device='cuda:1')
Solve time for step 4 3.8340938719920814
Current ori: tensor([-0.0335,  0.0275, -0.9274], device='cuda:1')
Index force: tensor([0.5808], device='cuda:1')
Storing RECOVERY transition: reward=0.0056 (scaled=0.0014), steps=4
Reward stats updated: mean 0.0219 -> 0.0218, std: 0.1351
Collected 202 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.1869, Q2 Loss=2.1869, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0542
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.7711, Q2 Loss=0.7711, Entropy=0.0763, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2944
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6637, Q2 Loss=0.6637, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3755
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6686, Q2 Loss=0.6686, Entropy=0.0006, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2398
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0426, Q2 Loss=1.0426, Entropy=0.0059, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7031

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.0%)
Q1 update: 0.06s (17.8%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000034
Q1 loss: 1.066588
Q2 loss: 1.066588
Current threshold: -149.4543
Global Scale Offset: 3.5422
Reward stats: mean=0.0218, std=0.1351, count=202
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0666, Q2 Loss: 1.0666, Entropy: 0.0166, Mean TD Error: 1.3334, Threshold: -149.4543
Original likelihood: -130.22735595703125
Adjusted likelihood: -130.22735595703125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Marked last transition as done (final step)
{}

Trial 13
Loaded trajectory sampler
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
1 turn
Sampling time 5.161167019046843
tensor([ 1.1680e-01,  6.2619e-01,  5.5873e-01,  5.1534e-01, -1.0696e-01,
         5.1773e-01,  9.0413e-01,  9.2253e-01,  1.2022e+00,  3.2502e-01,
         2.4856e-01,  1.2241e+00, -1.1403e-03,  1.4469e-02, -3.0450e-02,
         5.5898e-02], device='cuda:1')
Original likelihood: -83.46725463867188
Adjusted likelihood: -83.46725463867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.870060465007555
Current ori: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
Middle force: tensor([2.6917, 0.5004, 0.5544, 0.5333, 0.5185, 0.6170, 0.5061, 0.6832, 0.5523,
        0.7392, 0.5748, 0.5004], device='cuda:1')
Thumb force: tensor([2.6063, 0.6273, 0.5987, 0.7310, 0.5489, 0.9126, 0.7426, 0.9147, 0.5917,
        0.5621, 0.6004, 0.5779], device='cuda:1')
Index force: tensor([0.6200, 0.7901, 0.6154, 0.7846, 0.5895, 0.5870, 0.5019, 0.5024, 0.5679,
        0.7460, 0.5830, 0.5497], device='cuda:1')
Storing NORMAL transition: reward=0.2097 (scaled=0.2097), steps=1
Reward stats updated: mean 0.0218 -> 0.0227, std: 0.1354
Collected 203 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1006, Q2 Loss=1.1006, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3850
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5637, Q2 Loss=0.5637, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1074
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=1.0569, Q2 Loss=1.0569, Entropy=0.0820, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8134
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.4807, Q2 Loss=1.4807, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9724
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7399, Q2 Loss=0.7399, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5349

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.8%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (18.1%)
Actor update: 0.13s (37.1%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000050
Q1 loss: 0.988349
Q2 loss: 0.988349
Current threshold: -149.4599
Global Scale Offset: 3.6522
Reward stats: mean=0.0227, std=0.1354, count=203
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9883, Q2 Loss: 0.9883, Entropy: 0.0164, Mean TD Error: 1.5626, Threshold: -149.4599
tensor([ 0.0951,  0.5730,  0.5941,  0.5476, -0.0292,  0.4243,  0.9548,  1.0413,
         1.2764,  0.2502,  0.2200,  1.0863, -0.0257, -0.0077, -0.2411,  0.1860],
       device='cuda:1')
Original likelihood: -99.52083587646484
Adjusted likelihood: -99.52083587646484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.19753533200128
Current ori: tensor([-0.0257, -0.0077, -0.2411], device='cuda:1')
Middle force: tensor([1.6124, 0.5291, 0.5125, 0.6253, 1.5590, 0.5722, 0.5572, 0.5555, 0.5350,
        0.5374, 0.5508], device='cuda:1')
Thumb force: tensor([0.8891, 0.5016, 0.9165, 0.8703, 1.0158, 0.6789, 0.6915, 0.6340, 0.7295,
        0.6951, 0.9533], device='cuda:1')
Index force: tensor([0.6990, 0.9220, 0.6168, 0.5061, 0.5106, 0.5000, 0.5519, 0.5671, 0.5391,
        0.5639, 0.5546], device='cuda:1')
Storing NORMAL transition: reward=-0.0051 (scaled=-0.0051), steps=1
Reward stats updated: mean 0.0227 -> 0.0226, std: 0.1351
Collected 204 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0507, Q2 Loss=1.0507, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2931
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=3.2783, Q2 Loss=3.2783, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2316
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0369, Q2 Loss=1.0369, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8096
SAC Update 4/5: Actor Loss=-0.0021, Q1 Loss=1.1147, Q2 Loss=1.1147, Entropy=0.2455, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3761
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8490, Q2 Loss=0.8490, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6951

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.6%)
Q1 update: 0.06s (17.8%)
Q2 update: 0.06s (17.8%)
Actor update: 0.12s (37.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000429
Q1 loss: 1.465910
Q2 loss: 1.465910
Current threshold: -149.4612
Global Scale Offset: 3.7794
Reward stats: mean=0.0226, std=0.1351, count=204
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.4659, Q2 Loss: 1.4659, Entropy: 0.0491, Mean TD Error: 1.4811, Threshold: -149.4612
tensor([ 0.0506,  0.5308,  0.5297,  0.5369, -0.0468,  0.4338,  0.9039,  1.0992,
         1.3830,  0.0838,  0.1823,  1.0989, -0.0217,  0.0028, -0.2357,  1.1473],
       device='cuda:1')
Original likelihood: -117.80370330810547
Adjusted likelihood: -117.80370330810547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.394979269010946
Current ori: tensor([-0.0217,  0.0028, -0.2357], device='cuda:1')
Middle force: tensor([0.5323, 0.5144, 0.6275, 1.5395, 0.5751, 0.5543, 0.5597, 0.5406, 0.5367,
        0.5548], device='cuda:1')
Thumb force: tensor([0.5012, 0.8809, 0.8506, 0.9842, 0.6624, 0.6812, 0.6178, 0.7083, 0.6821,
        0.9301], device='cuda:1')
Index force: tensor([0.8818, 0.6030, 0.5050, 0.5090, 0.5001, 0.5495, 0.5614, 0.5310, 0.5616,
        0.5481], device='cuda:1')
Storing NORMAL transition: reward=-0.0086 (scaled=-0.0086), steps=1
Reward stats updated: mean 0.0226 -> 0.0224, std: 0.1348
Collected 205 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6653, Q2 Loss=0.6653, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4004
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9171, Q2 Loss=0.9171, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4630
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4560, Q2 Loss=1.4560, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6467
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3499, Q2 Loss=1.3499, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5944
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0549, Q2 Loss=1.0549, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7912

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.0%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.088641
Q2 loss: 1.088641
Current threshold: -149.4596
Global Scale Offset: 3.9147
Reward stats: mean=0.0224, std=0.1348, count=205
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0886, Q2 Loss: 1.0886, Entropy: 0.0000, Mean TD Error: 0.9791, Threshold: -149.4596
tensor([ 0.0149,  0.4564,  0.6140,  0.6634, -0.0248,  0.4007,  0.9798,  1.0719,
         1.3646,  0.0878,  0.1486,  1.1706, -0.0069, -0.0130, -0.2267,  1.0700],
       device='cuda:1')
Original likelihood: -116.35720825195312
Adjusted likelihood: -116.35720825195312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.47836011799518
Current ori: tensor([-0.0069, -0.0130, -0.2267], device='cuda:1')
Middle force: tensor([0.5142, 0.6231, 1.5132, 0.5754, 0.5504, 0.5615, 0.5444, 0.5354, 0.5588],
       device='cuda:1')
Thumb force: tensor([0.8599, 0.8354, 0.9597, 0.6532, 0.6739, 0.6076, 0.6966, 0.6742, 0.9130],
       device='cuda:1')
Index force: tensor([0.5902, 0.5044, 0.5077, 0.5000, 0.5463, 0.5560, 0.5244, 0.5580, 0.5407],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0021 (scaled=-0.0021), steps=1
Reward stats updated: mean 0.0224 -> 0.0223, std: 0.1345
Collected 206 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.6970, Q2 Loss=2.6970, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1590
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8455, Q2 Loss=0.8455, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2471
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6448, Q2 Loss=0.6448, Entropy=0.0229, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6252
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=8.0983, Q2 Loss=8.0983, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.1011
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5956, Q2 Loss=0.5956, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4499

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.8%)
Q1 update: 0.06s (18.8%)
Q2 update: 0.05s (17.6%)
Actor update: 0.13s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 2.576238
Q2 loss: 2.576238
Current threshold: -149.4587
Global Scale Offset: 3.9992
Reward stats: mean=0.0223, std=0.1345, count=206
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.5762, Q2 Loss: 2.5762, Entropy: 0.0046, Mean TD Error: 2.5165, Threshold: -149.4587
tensor([-0.0063,  0.4484,  0.5907,  0.6953, -0.0475,  0.4172,  0.9213,  1.1086,
         1.3620,  0.1172,  0.1709,  1.1522, -0.0120,  0.0021, -0.2245,  0.9934],
       device='cuda:1')
Original likelihood: -86.92155456542969
Adjusted likelihood: -86.92155456542969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 4.945348329027183
Current ori: tensor([-0.0120,  0.0021, -0.2245], device='cuda:1')
Middle force: tensor([0.6180, 1.4826, 0.5717, 0.5475, 0.5575, 0.5412, 0.5335, 0.5553],
       device='cuda:1')
Thumb force: tensor([0.8185, 0.9408, 0.6469, 0.6661, 0.6016, 0.6894, 0.6683, 0.9027],
       device='cuda:1')
Index force: tensor([0.5038, 0.5069, 0.5000, 0.5438, 0.5531, 0.5223, 0.5551, 0.5383],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0029 (scaled=-0.0029), steps=1
Reward stats updated: mean 0.0223 -> 0.0222, std: 0.1341
Collected 207 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2989, Q2 Loss=1.2989, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0592
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7213, Q2 Loss=0.7213, Entropy=0.0245, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6656
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9021, Q2 Loss=0.9021, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7280
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6267, Q2 Loss=0.6267, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3263
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2684, Q2 Loss=1.2684, Entropy=0.0012, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9536

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.2%)
Q1 update: 0.07s (19.5%)
Q2 update: 0.07s (18.2%)
Actor update: 0.14s (37.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000005
Q1 loss: 0.963497
Q2 loss: 0.963497
Current threshold: -149.4581
Global Scale Offset: 4.0559
Reward stats: mean=0.0222, std=0.1341, count=207
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9635, Q2 Loss: 0.9635, Entropy: 0.0051, Mean TD Error: 0.7465, Threshold: -149.4581
tensor([-0.0247,  0.3708,  0.6285,  0.6681, -0.0638,  0.4712,  0.8548,  1.0591,
         1.3359,  0.1254,  0.1107,  1.1514, -0.0346,  0.0038, -0.2232,  2.4337],
       device='cuda:1')
Original likelihood: -152.4976806640625
Adjusted likelihood: -152.4976806640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2798)
Solve time for step 6 4.857960682013072
Current ori: tensor([-0.0346,  0.0038, -0.2232], device='cuda:1')
Middle force: tensor([1.4437, 0.5698, 0.5444, 0.5555, 0.5400, 0.5320, 0.5535],
       device='cuda:1')
Thumb force: tensor([0.9220, 0.6403, 0.6583, 0.5945, 0.6803, 0.6629, 0.8900],
       device='cuda:1')
Index force: tensor([0.5064, 0.5000, 0.5410, 0.5496, 0.5196, 0.5507, 0.5356],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0084 (scaled=-0.0084), steps=1
Reward stats updated: mean 0.0222 -> 0.0221, std: 0.1338
Collected 208 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0854, Q2 Loss=1.0854, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3544
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9418, Q2 Loss=0.9418, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7419
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5738, Q2 Loss=0.5738, Entropy=0.2605, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6223
SAC Update 4/5: Actor Loss=-0.0011, Q1 Loss=0.5901, Q2 Loss=0.5901, Entropy=0.3428, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2612
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0083, Q2 Loss=1.0083, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9848

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (20.2%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (19.4%)
Actor update: 0.15s (38.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000229
Q1 loss: 0.839878
Q2 loss: 0.839878
Current threshold: -149.4570
Global Scale Offset: 4.1018
Reward stats: mean=0.0221, std=0.1338, count=208
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.8399, Q2 Loss: 0.8399, Entropy: 0.1207, Mean TD Error: 1.5929, Threshold: -149.4570
tensor([-0.0811,  0.4106,  0.6168,  0.7287, -0.0087,  0.5403,  0.8817,  1.0192,
         1.3265,  0.0698,  0.1588,  1.0169, -0.0913, -0.0381, -0.2276,  3.3361],
       device='cuda:1')
Original likelihood: -169.81878662109375
Adjusted likelihood: -169.81878662109375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0001)
State is out of distribution
Final likelihood: tensor([ -6.3364,  -6.5245,  -6.6226,  -7.5781,  -7.6100,  -7.7641,  -7.8208,
         -8.3661,  -8.4994,  -9.5685,  -9.8053, -10.5152, -11.5238, -13.4692,
        -13.7643, -15.0297], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -6.3364,  -6.5245,  -6.6226,  -7.5781,  -7.6100,  -7.7641,  -7.8208,
         -8.3661,  -8.4994,  -9.5685,  -9.8053, -10.5152, -11.5238, -13.4692,
        -13.7643, -15.0297], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.4249
1 mode projection succeeded
New goal: tensor([ 0.0306,  0.4879,  0.6009,  0.6338, -0.0215,  0.5459,  0.7378,  1.0147,
         1.2855,  0.4071,  0.1695,  1.0383, -0.0293, -0.0076, -0.6358],
       device='cuda:1')
tensor([[0.0052]], device='cuda:1') tensor([[0.0039]], device='cuda:1') tensor([[0.0053]], device='cuda:1')
Original likelihood: -170.57681274414062
Adjusted likelihood: -170.57681274414062
Likelihood residual: 0.0
Original likelihood: -190.65274047851562
Adjusted likelihood: -190.65274047851562
Likelihood residual: 0.0
{'index': 190.65274047851562, 'thumb_middle': 170.57681274414062}
Current yaw: tensor([-0.0913, -0.0381, -0.2276], device='cuda:1')
2 thumb_middle
tensor([-0.0811,  0.4106,  0.6168,  0.7287, -0.0087,  0.5403,  0.8817,  1.0192,
         1.3265,  0.0698,  0.1588,  1.0169, -0.0913, -0.0381, -0.2276,  3.3361],
       device='cuda:1')
Solve time for step 1 9.457644967013039
Current ori: tensor([-0.0913, -0.0381, -0.2276], device='cuda:1')
Index force: tensor([0.6043, 0.5983, 0.5864, 0.5950], device='cuda:1')
tensor([-0.0881,  0.4494,  0.6436,  0.6994, -0.0821,  0.5373,  0.7458,  1.0064,
         1.2412,  0.3288,  0.0794,  0.9967, -0.2307, -0.0959, -0.2276,  3.4472],
       device='cuda:1')
Solve time for step 2 4.000370604044292
Current ori: tensor([-0.2307, -0.0959, -0.2276], device='cuda:1')
Index force: tensor([0.5856, 0.5728, 0.5891], device='cuda:1')
tensor([-0.1234,  0.5449,  0.6844,  0.7095, -0.0693,  0.5785,  0.7447,  1.0099,
         1.2323,  0.3757,  0.0655,  0.9951, -0.5677, -0.2276, -0.2276,  2.5061],
       device='cuda:1')
Solve time for step 3 3.9215105709736235
Current ori: tensor([-0.5677, -0.2276, -0.2276], device='cuda:1')
Index force: tensor([0.5477, 0.5051], device='cuda:1')
tensor([-0.2390,  0.7127,  0.8073,  0.8002, -0.1009,  0.6788,  0.7851,  1.0016,
         1.2333,  0.3857,  0.0710,  0.9997, -1.2365, -0.4101, -0.2277,  1.9150],
       device='cuda:1')
Solve time for step 4 3.822892703989055
Current ori: tensor([-1.2365, -0.4101, -0.2277], device='cuda:1')
Index force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=-1.6358 (scaled=-0.2726), steps=6
Reward stats updated: mean 0.0221 -> 0.0206, std: 0.1351
Collected 209 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7808, Q2 Loss=0.7808, Entropy=0.0002, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5430
SAC Update 2/5: Actor Loss=-0.0024, Q1 Loss=6.9628, Q2 Loss=6.9628, Entropy=0.2617, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7099
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8816, Q2 Loss=0.8816, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1993
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7774, Q2 Loss=0.7774, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8082
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6638, Q2 Loss=0.6638, Entropy=0.0004, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2509

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.5%)
Q1 update: 0.08s (19.2%)
Q2 update: 0.08s (18.7%)
Actor update: 0.16s (39.3%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000490
Q1 loss: 2.013290
Q2 loss: 2.013290
Current threshold: -149.4518
Global Scale Offset: 4.2379
Reward stats: mean=0.0206, std=0.1351, count=209
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 2.0133, Q2 Loss: 2.0133, Entropy: 0.0525, Mean TD Error: 1.5023, Threshold: -149.4518
Original likelihood: -2525.048828125
Adjusted likelihood: -2525.048828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 14
Loaded trajectory sampler
Current yaw: tensor([ 0.0004,  0.0141, -0.0491], device='cuda:1')
Current yaw: tensor([ 0.0004,  0.0141, -0.0491], device='cuda:1')
1 turn
Sampling time 5.346639216993935
tensor([ 1.3012e-01,  6.1607e-01,  5.4170e-01,  6.0244e-01, -8.4474e-02,
         5.0191e-01,  9.1226e-01,  8.6906e-01,  1.2590e+00,  2.8240e-01,
         2.2487e-01,  1.1673e+00,  3.6090e-04,  1.4063e-02, -4.9093e-02,
         4.8253e-01], device='cuda:1')
Original likelihood: -87.60818481445312
Adjusted likelihood: -87.60818481445312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.889450825052336
Current ori: tensor([ 0.0004,  0.0141, -0.0491], device='cuda:1')
Middle force: tensor([0.5557, 0.5587, 0.7119, 0.5293, 0.4915, 0.5517, 0.5292, 0.5119, 0.6206,
        0.5122, 0.5397, 0.5216], device='cuda:1')
Thumb force: tensor([0.5626, 0.5397, 0.6186, 0.7758, 0.5105, 0.5560, 0.6991, 0.5602, 1.7830,
        0.6351, 0.5983, 0.6863], device='cuda:1')
Index force: tensor([0.5199, 0.6256, 0.8296, 0.5428, 0.7427, 0.5510, 0.7576, 0.6052, 0.6175,
        0.6981, 0.5767, 0.6594], device='cuda:1')
Storing NORMAL transition: reward=0.1113 (scaled=0.1113), steps=1
Reward stats updated: mean 0.0206 -> 0.0211, std: 0.1349
Collected 210 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6139, Q2 Loss=0.6139, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5237
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7234, Q2 Loss=0.7234, Entropy=0.0044, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6366
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7129, Q2 Loss=0.7129, Entropy=0.0003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5231
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1920, Q2 Loss=1.1920, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8074
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.4404, Q2 Loss=1.4404, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9592

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (21.5%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (17.3%)
Actor update: 0.14s (39.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.936517
Q2 loss: 0.936517
Current threshold: -149.4480
Global Scale Offset: 4.3408
Reward stats: mean=0.0211, std=0.1349, count=210
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9365, Q2 Loss: 0.9365, Entropy: 0.0009, Mean TD Error: 1.4900, Threshold: -149.4480
tensor([ 0.1171,  0.4991,  0.6405,  0.6982, -0.0731,  0.4652,  0.8771,  0.9374,
         1.3145,  0.2413,  0.2338,  1.0991,  0.0161,  0.0159, -0.1608,  0.8901],
       device='cuda:1')
Original likelihood: -76.62103271484375
Adjusted likelihood: -76.62103271484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.834011137951165
Current ori: tensor([ 0.0161,  0.0159, -0.1608], device='cuda:1')
Middle force: tensor([0.5873, 0.5095, 0.5233, 0.5463, 0.5315, 0.5042, 0.5655, 0.5221, 1.0858,
        1.0107, 0.5472], device='cuda:1')
Thumb force: tensor([0.5627, 0.5638, 0.7062, 0.6302, 0.6042, 0.8910, 0.5273, 0.5309, 0.6797,
        0.5225, 0.5486], device='cuda:1')
Index force: tensor([0.5864, 0.6607, 0.5210, 0.5599, 0.6004, 0.5496, 0.5816, 0.5778, 0.5597,
        0.5581, 0.5616], device='cuda:1')
Storing NORMAL transition: reward=0.1212 (scaled=0.1212), steps=1
Reward stats updated: mean 0.0211 -> 0.0216, std: 0.1347
Collected 211 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=0.6891, Q2 Loss=0.6891, Entropy=0.1876, Time=0.11sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6839
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1412, Q2 Loss=1.1412, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9412
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.9978, Q2 Loss=0.9978, Entropy=0.0528, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7557
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1944, Q2 Loss=1.1944, Entropy=0.0003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0943
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.6580, Q2 Loss=0.6580, Entropy=0.1988, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5015

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (21.2%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.06s (17.6%)
Actor update: 0.15s (39.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000360
Q1 loss: 0.936087
Q2 loss: 0.936087
Current threshold: -149.4427
Global Scale Offset: 4.5490
Reward stats: mean=0.0216, std=0.1347, count=211
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.9361, Q2 Loss: 0.9361, Entropy: 0.0879, Mean TD Error: 1.5953, Threshold: -149.4427
tensor([ 1.2754e-01,  5.1362e-01,  5.8297e-01,  6.7475e-01, -3.8808e-02,
         3.6326e-01,  9.1098e-01,  1.1494e+00,  1.2926e+00,  2.3094e-01,
         2.7315e-01,  1.0649e+00,  5.0753e-02,  1.8682e-03, -2.8584e-01,
        -3.5978e+00], device='cuda:1')
Original likelihood: -140.19354248046875
Adjusted likelihood: -140.19354248046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9471)
Solve time for step 3 5.779421970015392
Current ori: tensor([ 0.0508,  0.0019, -0.2858], device='cuda:1')
Middle force: tensor([0.5093, 0.5204, 0.5433, 0.5306, 0.5036, 0.5636, 0.5204, 1.0727, 0.9961,
        0.5506], device='cuda:1')
Thumb force: tensor([0.5480, 0.6917, 0.6153, 0.5938, 0.8720, 0.5239, 0.5276, 0.6689, 0.5203,
        0.5385], device='cuda:1')
Index force: tensor([0.6652, 0.5207, 0.5591, 0.5955, 0.5465, 0.5776, 0.5736, 0.5561, 0.5547,
        0.5599], device='cuda:1')
Storing NORMAL transition: reward=0.0020 (scaled=0.0020), steps=1
Reward stats updated: mean 0.0216 -> 0.0215, std: 0.1344
Collected 212 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.9153, Q2 Loss=0.9153, Entropy=0.0546, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5023
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8863, Q2 Loss=0.8863, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3412
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9994, Q2 Loss=0.9994, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4107
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=1.0906, Q2 Loss=1.0906, Entropy=0.1607, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3780
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7648, Q2 Loss=0.7648, Entropy=0.0024, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1813

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (17.7%)
Actor update: 0.14s (38.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000243
Q1 loss: 0.931294
Q2 loss: 0.931294
Current threshold: -149.4387
Global Scale Offset: 4.8042
Reward stats: mean=0.0215, std=0.1344, count=212
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.9313, Q2 Loss: 0.9313, Entropy: 0.0435, Mean TD Error: 0.3627, Threshold: -149.4387
tensor([ 9.9410e-02,  5.7202e-01,  5.8678e-01,  5.6642e-01,  1.1302e-01,
         2.2602e-01,  9.2165e-01,  1.0405e+00,  1.1453e+00,  3.4343e-01,
         2.7997e-01,  1.0317e+00,  3.6780e-02, -1.2561e-04, -2.8571e-01,
        -3.8961e+00], device='cuda:1')
Original likelihood: -242.51490783691406
Adjusted likelihood: -242.51490783691406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-3.2466, -3.3536, -3.5122, -3.5440, -4.0843, -4.2675, -4.2989, -4.8985,
        -5.2369, -5.6948, -5.9159, -6.1516, -6.1529, -6.1656, -7.0440, -7.6704],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2466, -3.3536, -3.5122, -3.5440, -4.0843, -4.2675, -4.2989, -4.8985,
        -5.2369, -5.6948, -5.9159, -6.1516, -6.1529, -6.1656, -7.0440, -7.6704],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.0774
1 mode projection succeeded
New goal: tensor([ 0.0643,  0.5532,  0.5500,  0.6305, -0.0490,  0.4992,  0.7967,  0.9353,
         1.2329,  0.3629,  0.2445,  1.1544,  0.0047,  0.0142,  0.3655],
       device='cuda:1')
tensor([[0.0119]], device='cuda:1') tensor([[0.0031]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -101.39488220214844
Adjusted likelihood: -101.39488220214844
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 101.39488220214844}
Current yaw: tensor([ 3.6780e-02, -1.2561e-04, -2.8571e-01], device='cuda:1')
2 thumb_middle
tensor([ 9.9410e-02,  5.7202e-01,  5.8678e-01,  5.6642e-01,  1.1302e-01,
         2.2602e-01,  9.2165e-01,  1.0405e+00,  1.1453e+00,  3.4343e-01,
         2.7997e-01,  1.0317e+00,  3.6780e-02, -1.2561e-04, -2.8571e-01,
        -3.8961e+00], device='cuda:1')
Solve time for step 1 9.99000138998963
Current ori: tensor([ 3.6780e-02, -1.2561e-04, -2.8571e-01], device='cuda:1')
Index force: tensor([0.6039, 0.5040, 0.6191, 0.6092], device='cuda:1')
tensor([ 0.0909,  0.5103,  0.5910,  0.7065, -0.1071,  0.4323,  0.7854,  0.9301,
         1.1876,  0.3491,  0.1921,  1.1113,  0.0635,  0.0104, -0.2857, -3.8300],
       device='cuda:1')
Solve time for step 2 3.8667565470095724
Current ori: tensor([ 0.0635,  0.0104, -0.2857], device='cuda:1')
Index force: tensor([0.5039, 0.6154, 0.6060], device='cuda:1')
tensor([ 0.0862,  0.5189,  0.5822,  0.6903, -0.1430,  0.4749,  0.7671,  0.9153,
         1.2012,  0.3500,  0.1798,  1.1259,  0.0599,  0.0120, -0.2857, -3.8462],
       device='cuda:1')
Solve time for step 3 3.860775150009431
Current ori: tensor([ 0.0599,  0.0120, -0.2857], device='cuda:1')
Index force: tensor([0.6081, 0.6028], device='cuda:1')
tensor([ 0.0702,  0.5630,  0.5429,  0.6191, -0.1562,  0.4841,  0.7623,  0.9102,
         1.2016,  0.3488,  0.1746,  1.1286,  0.0431,  0.0164, -0.2857, -3.9131],
       device='cuda:1')
Solve time for step 4 3.561625683971215
Current ori: tensor([ 0.0431,  0.0164, -0.2857], device='cuda:1')
Index force: tensor([0.5911], device='cuda:1')
Storing RECOVERY transition: reward=0.0001 (scaled=0.0000), steps=3
Reward stats updated: mean 0.0215 -> 0.0214, std: 0.1341
Collected 213 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0582, Q2 Loss=1.0582, Entropy=0.0006, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8095
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.6106, Q2 Loss=0.6106, Entropy=0.3466, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7756
SAC Update 3/5: Actor Loss=-0.0069, Q1 Loss=0.7747, Q2 Loss=0.7747, Entropy=0.3792, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3351
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.7528, Q2 Loss=1.7528, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8021
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.3628, Q2 Loss=2.3628, Entropy=0.0103, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1174

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.6%)
Q1 update: 0.08s (19.4%)
Q2 update: 0.07s (18.7%)
Actor update: 0.16s (39.4%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002771
Q1 loss: 1.311835
Q2 loss: 1.311835
Current threshold: -149.4474
Global Scale Offset: 5.0361
Reward stats: mean=0.0214, std=0.1341, count=213
----------------------------------------------
SAC Update - Actor Loss: -0.0028, Q1 Loss: 1.3118, Q2 Loss: 1.3118, Entropy: 0.1474, Mean TD Error: 1.7679, Threshold: -149.4474
Original likelihood: -86.01094818115234
Adjusted likelihood: -86.01094818115234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0433,  0.0175, -0.2873], device='cuda:1')
3 turn
Sampling time 5.114386881003156
tensor([ 0.0657,  0.5643,  0.5372,  0.6184, -0.0857,  0.5340,  0.8019,  0.9332,
         1.2604,  0.3667,  0.2325,  1.1603,  0.0433,  0.0175, -0.2873, -3.8733],
       device='cuda:1')
Original likelihood: -89.63041687011719
Adjusted likelihood: -89.63041687011719
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 16.051743972988334
Current ori: tensor([ 0.0433,  0.0175, -0.2873], device='cuda:1')
Middle force: tensor([1.5869, 0.5286, 0.5216, 0.5369, 0.6000, 0.6394, 1.0827, 0.8151, 0.8882,
        0.5586, 0.6125, 0.5706], device='cuda:1')
Thumb force: tensor([2.3340, 1.9136, 1.3494, 0.5140, 1.1086, 0.7478, 1.5217, 0.5777, 0.7324,
        0.5084, 0.5524, 0.5625], device='cuda:1')
Index force: tensor([0.5556, 0.8336, 0.6654, 0.6376, 0.5650, 0.5532, 0.5907, 0.5309, 0.5697,
        0.6656, 0.6359, 0.5878], device='cuda:1')
Storing NORMAL transition: reward=0.3428 (scaled=0.3428), steps=1
Reward stats updated: mean 0.0214 -> 0.0229, std: 0.1356
Collected 214 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8333, Q2 Loss=0.8333, Entropy=0.0202, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3001
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.9163, Q2 Loss=0.9163, Entropy=0.1537, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7207
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.9993, Q2 Loss=0.9993, Entropy=0.1285, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7552
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1873, Q2 Loss=1.1873, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6875
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1521, Q2 Loss=1.1521, Entropy=0.0087, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7352

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.3%)
Q1 update: 0.07s (19.4%)
Q2 update: 0.07s (19.5%)
Actor update: 0.14s (37.8%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000139
Q1 loss: 1.017660
Q2 loss: 1.017660
Current threshold: -149.4556
Global Scale Offset: 5.2765
Reward stats: mean=0.0229, std=0.1356, count=214
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0177, Q2 Loss: 1.0177, Entropy: 0.0622, Mean TD Error: 0.6398, Threshold: -149.4556
tensor([ 0.1735,  0.6129,  0.5045,  0.5834, -0.0393,  0.4072,  0.9822,  1.2954,
         1.1896,  0.6174,  0.4542,  0.8086,  0.1251, -0.0456, -0.6855, -1.8884],
       device='cuda:1')
Original likelihood: -221.7130126953125
Adjusted likelihood: -221.7130126953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-39.9212, -42.4143, -52.0241, -54.7786, -54.9199, -56.7449, -57.6786,
        -57.7816, -58.5677, -59.3601, -61.7504, -62.9828, -63.8856, -65.9253,
        -66.9264, -70.0777], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-39.9212, -42.4143, -52.0241, -54.7786, -54.9199, -56.7449, -57.6786,
        -57.7816, -58.5677, -59.3601, -61.7504, -62.9828, -63.8856, -65.9253,
        -66.9264, -70.0777], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -57.8587
1 mode projection succeeded
New goal: tensor([ 0.0643,  0.5312,  0.6164,  0.5722, -0.0754,  0.4355,  0.9453,  0.9443,
         1.2510,  0.3331,  0.2647,  1.1081,  0.0324,  0.0065, -0.7072],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0043]], device='cuda:1')
Original likelihood: -204.71762084960938
Adjusted likelihood: -204.71762084960938
Likelihood residual: 0.0
Original likelihood: -254.22161865234375
Adjusted likelihood: -254.22161865234375
Likelihood residual: 0.0
{'index': 254.22161865234375, 'thumb_middle': 204.71762084960938}
Current yaw: tensor([ 0.1251, -0.0456, -0.6855], device='cuda:1')
4 thumb_middle
tensor([ 0.1735,  0.6129,  0.5045,  0.5834, -0.0393,  0.4072,  0.9822,  1.2954,
         1.1896,  0.6174,  0.4542,  0.8086,  0.1251, -0.0456, -0.6855, -1.8884],
       device='cuda:1')
Solve time for step 1 10.334568505990319
Current ori: tensor([ 0.1251, -0.0456, -0.6855], device='cuda:1')
Index force: tensor([0.5864, 0.6062, 0.5858, 0.5958], device='cuda:1')
tensor([ 0.1131,  0.6275,  0.5808,  0.6004, -0.1106,  0.4300,  0.9219,  0.9847,
         1.1985,  0.3633,  0.2369,  1.0396,  0.2393, -0.1149, -0.6837, -0.5648],
       device='cuda:1')
Solve time for step 2 4.068539664032869
Current ori: tensor([ 0.2393, -0.1149, -0.6837], device='cuda:1')
Index force: tensor([0.6035, 0.5758, 0.5897], device='cuda:1')
tensor([ 0.0966,  0.6507,  0.8110,  0.8150, -0.0373,  0.5053,  1.0123,  0.9685,
         1.2174,  0.3197,  0.2129,  1.0888,  0.3679, -0.3179, -0.5538,  1.5991],
       device='cuda:1')
Solve time for step 3 3.9614102469640784
Current ori: tensor([ 0.3679, -0.3179, -0.5538], device='cuda:1')
Index force: tensor([0.5082, 0.5953], device='cuda:1')
tensor([ 0.0736,  0.8523,  0.7447,  0.6657,  0.0809,  0.6020,  1.0688,  0.9803,
         1.1891,  0.3009,  0.2269,  1.1220,  0.3829, -0.3557, -0.4606,  2.8870],
       device='cuda:1')
Solve time for step 4 3.824977008975111
Current ori: tensor([ 0.3829, -0.3557, -0.4606], device='cuda:1')
Index force: tensor([0.5821], device='cuda:1')
Storing RECOVERY transition: reward=-0.4942 (scaled=-0.4942), steps=1
Reward stats updated: mean 0.0229 -> 0.0205, std: 0.1398
Collected 215 transitions for RL
SAC Update 1/5: Actor Loss=-0.0114, Q1 Loss=0.7778, Q2 Loss=0.7778, Entropy=0.3156, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5409
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2515, Q2 Loss=1.2515, Entropy=0.0047, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0137
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=6.8197, Q2 Loss=6.8197, Entropy=0.0031, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7492
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2737, Q2 Loss=1.2737, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7651
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9359, Q2 Loss=0.9359, Entropy=0.0133, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7843

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.4%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.06s (17.9%)
Actor update: 0.14s (38.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002298
Q1 loss: 2.211709
Q2 loss: 2.211709
Current threshold: -149.4494
Global Scale Offset: 5.2062
Reward stats: mean=0.0205, std=0.1398, count=215
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 2.2117, Q2 Loss: 2.2117, Entropy: 0.0673, Mean TD Error: 2.5706, Threshold: -149.4494
Original likelihood: -1176.4388427734375
Adjusted likelihood: -1176.4388427734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 15
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
1 turn
Sampling time 5.313213378016371
tensor([ 1.1374e-01,  6.4746e-01,  5.1076e-01,  5.4455e-01, -1.0766e-01,
         5.2551e-01,  9.1529e-01,  8.6953e-01,  1.2572e+00,  2.4097e-01,
         2.3264e-01,  1.2006e+00, -1.3005e-04,  1.3937e-02, -3.9258e-02,
         4.4622e-01], device='cuda:1')
Original likelihood: -78.08509826660156
Adjusted likelihood: -78.08509826660156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.89433707203716
Current ori: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Middle force: tensor([0.5276, 0.5449, 1.3111, 1.6710, 0.5567, 0.4916, 0.5542, 0.7227, 0.5088,
        0.7758, 0.5151, 0.4957], device='cuda:1')
Thumb force: tensor([0.5393, 0.9608, 1.0714, 1.1085, 0.6063, 1.0381, 1.0892, 0.6867, 0.6342,
        0.5573, 0.8290, 0.5439], device='cuda:1')
Index force: tensor([0.6329, 0.5038, 0.6322, 0.7944, 0.5033, 0.7149, 0.5088, 0.6192, 0.7009,
        0.5162, 0.5719, 0.8360], device='cuda:1')
Storing NORMAL transition: reward=-0.0478 (scaled=-0.0478), steps=1
Reward stats updated: mean 0.0205 -> 0.0201, std: 0.1395
Collected 216 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.7363, Q2 Loss=0.7363, Entropy=0.1589, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5974
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7124, Q2 Loss=0.7124, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3811
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7156, Q2 Loss=0.7156, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7620
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2919, Q2 Loss=1.2919, Entropy=0.0044, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8428
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.4712, Q2 Loss=1.4712, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2661

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (20.5%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (38.5%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000057
Q1 loss: 0.985484
Q2 loss: 0.985484
Current threshold: -149.4454
Global Scale Offset: 5.2086
Reward stats: mean=0.0201, std=0.1395, count=216
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.9855, Q2 Loss: 0.9855, Entropy: 0.0326, Mean TD Error: 1.1699, Threshold: -149.4454
tensor([ 0.0593,  0.6562,  0.4915,  0.4183, -0.1634,  0.5366,  0.9316,  0.8012,
         1.3235,  0.2975,  0.1762,  0.9553, -0.0088,  0.0351,  0.0076,  0.4877],
       device='cuda:1')
Original likelihood: -169.4965057373047
Adjusted likelihood: -169.4965057373047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0009)
State is out of distribution
Final likelihood: tensor([-2.6052, -3.2996, -3.4295, -3.6128, -3.6928, -4.0785, -4.0892, -4.2247,
        -4.2646, -4.5087, -4.7499, -4.9415, -5.0462, -5.2323, -5.6333, -6.7891],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.6052, -3.2996, -3.4295, -3.6128, -3.6928, -4.0785, -4.0892, -4.2247,
        -4.2646, -4.5087, -4.7499, -4.9415, -5.0462, -5.2323, -5.6333, -6.7891],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3874
1 mode projection succeeded
New goal: tensor([ 0.0543,  0.5619,  0.5926,  0.5017, -0.0861,  0.5141,  0.8680,  0.8699,
         1.2632,  0.3195,  0.2399,  1.1220,  0.0037,  0.0142, -1.2910],
       device='cuda:1')
tensor([[0.0111]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -84.85661315917969
Adjusted likelihood: -84.85661315917969
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 84.85661315917969}
Current yaw: tensor([-0.0088,  0.0351,  0.0076], device='cuda:1')
2 thumb_middle
tensor([ 0.0593,  0.6562,  0.4915,  0.4183, -0.1634,  0.5366,  0.9316,  0.8012,
         1.3235,  0.2975,  0.1762,  0.9553, -0.0088,  0.0351,  0.0076,  0.4877],
       device='cuda:1')
Solve time for step 1 9.47526196599938
Current ori: tensor([-0.0088,  0.0351,  0.0076], device='cuda:1')
Index force: tensor([0.6176, 0.4999, 0.5856, 0.6017], device='cuda:1')
tensor([ 0.0611,  0.5713,  0.5761,  0.5204, -0.2090,  0.4830,  0.8370,  0.8300,
         1.2555,  0.3034,  0.1737,  1.0693,  0.0163,  0.0363,  0.0076,  0.5116],
       device='cuda:1')
Solve time for step 2 4.039492753974628
Current ori: tensor([0.0163, 0.0363, 0.0076], device='cuda:1')
Index force: tensor([0.5000, 0.5809, 0.5950], device='cuda:1')
tensor([ 0.0600,  0.5645,  0.5857,  0.5172, -0.2102,  0.4843,  0.8285,  0.8392,
         1.2504,  0.3109,  0.1724,  1.0887,  0.0176,  0.0371,  0.0076,  0.5106],
       device='cuda:1')
Solve time for step 3 3.445598168997094
Current ori: tensor([0.0176, 0.0371, 0.0076], device='cuda:1')
Index force: tensor([0.5706, 0.5685], device='cuda:1')
tensor([ 0.0794,  0.5741,  0.5953,  0.5096, -0.1998,  0.4860,  0.8356,  0.8588,
         1.2298,  0.3131,  0.1699,  1.0917,  0.0146,  0.0262,  0.0076,  0.5342],
       device='cuda:1')
Solve time for step 4 3.297769646975212
Current ori: tensor([0.0146, 0.0262, 0.0076], device='cuda:1')
Index force: tensor([0.5496], device='cuda:1')
Storing RECOVERY transition: reward=-0.0135 (scaled=-0.0135), steps=1
Reward stats updated: mean 0.0201 -> 0.0200, std: 0.1392
Collected 217 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=19.8809, Q2 Loss=19.8809, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.5644
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5647, Q2 Loss=0.5647, Entropy=0.0623, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6322
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6630, Q2 Loss=0.6630, Entropy=0.0035, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4055
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6627, Q2 Loss=0.6627, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0885
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.9766, Q2 Loss=0.9766, Entropy=0.0589, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6407

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.6%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.07s (19.2%)
Actor update: 0.14s (37.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000033
Q1 loss: 4.549568
Q2 loss: 4.549568
Current threshold: -149.4429
Global Scale Offset: 5.2220
Reward stats: mean=0.0200, std=0.1392, count=217
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.5496, Q2 Loss: 4.5496, Entropy: 0.0249, Mean TD Error: 1.6663, Threshold: -149.4429
Original likelihood: -143.39340209960938
Adjusted likelihood: -143.39340209960938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8274)
Current yaw: tensor([0.0196, 0.0418, 0.0204], device='cuda:1')
3 turn
Sampling time 5.1451627659844235
tensor([ 0.0486,  0.5593,  0.5839,  0.5148, -0.1618,  0.5342,  0.8669,  0.8641,
         1.3095,  0.3272,  0.2302,  1.1298,  0.0196,  0.0418,  0.0204,  0.5070],
       device='cuda:1')
Original likelihood: -145.8016815185547
Adjusted likelihood: -145.8016815185547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7150)
State is out of distribution
Final likelihood: tensor([-3.3673, -3.5670, -3.6380, -3.6494, -3.7907, -4.0302, -4.2607, -4.5552,
        -5.0161, -5.3653, -5.3708, -5.7616, -5.8733, -6.2332, -6.5275, -9.9756],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.3673, -3.5670, -3.6380, -3.6494, -3.7907, -4.0302, -4.2607, -4.5552,
        -5.0161, -5.3653, -5.3708, -5.7616, -5.8733, -6.2332, -6.5275, -9.9756],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.0614
1 mode projection succeeded
New goal: tensor([ 0.0669,  0.5600,  0.5720,  0.5698, -0.0819,  0.5287,  0.8423,  0.8699,
         1.2501,  0.3592,  0.2042,  1.1925,  0.0042,  0.0139,  1.3224],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -87.17706298828125
Adjusted likelihood: -87.17706298828125
Likelihood residual: 0.0
Original likelihood: -91.34394836425781
Adjusted likelihood: -91.34394836425781
Likelihood residual: 0.0
{'index': 91.34394836425781, 'thumb_middle': 87.17706298828125}
Current yaw: tensor([0.0196, 0.0418, 0.0204], device='cuda:1')
4 thumb_middle
tensor([ 0.0486,  0.5593,  0.5839,  0.5148, -0.1618,  0.5342,  0.8669,  0.8641,
         1.3095,  0.3272,  0.2302,  1.1298,  0.0196,  0.0418,  0.0204,  0.5070],
       device='cuda:1')
Solve time for step 1 9.685653656022623
Current ori: tensor([0.0196, 0.0418, 0.0204], device='cuda:1')
Index force: tensor([0.5293, 0.5934, 0.5894, 0.5906], device='cuda:1')
tensor([ 0.0449,  0.5631,  0.5599,  0.5439, -0.2120,  0.4892,  0.8052,  0.8489,
         1.2388,  0.3450,  0.1570,  1.1591,  0.0205,  0.0456,  0.0205,  0.4840],
       device='cuda:1')
Solve time for step 2 3.845903417968657
Current ori: tensor([0.0205, 0.0456, 0.0205], device='cuda:1')
Index force: tensor([0.5544, 0.5796, 0.5785], device='cuda:1')
tensor([ 0.0636,  0.5751,  0.5573,  0.5512, -0.1987,  0.4953,  0.8012,  0.8393,
         1.2332,  0.3567,  0.1371,  1.1548,  0.0178,  0.0354,  0.0205,  0.5081],
       device='cuda:1')
Solve time for step 3 3.7451589520205744
Current ori: tensor([0.0178, 0.0354, 0.0205], device='cuda:1')
Index force: tensor([0.5702, 0.5704], device='cuda:1')
tensor([ 0.0837,  0.5829,  0.5603,  0.5624, -0.1923,  0.5067,  0.8039,  0.8589,
         1.2281,  0.3344,  0.1272,  1.1610,  0.0168,  0.0245,  0.0205,  0.5378],
       device='cuda:1')
Solve time for step 4 3.638908759050537
Current ori: tensor([0.0168, 0.0245, 0.0205], device='cuda:1')
Index force: tensor([0.5547], device='cuda:1')
Storing RECOVERY transition: reward=-0.0150 (scaled=-0.0150), steps=0
Reward stats updated: mean 0.0200 -> 0.0198, std: 0.1389
Collected 218 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=1.1602, Q2 Loss=1.1602, Entropy=0.1597, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8707
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2474, Q2 Loss=1.2474, Entropy=0.0004, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5126
SAC Update 3/5: Actor Loss=-0.0011, Q1 Loss=1.1021, Q2 Loss=1.1021, Entropy=0.1635, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4938
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.0166, Q2 Loss=1.0166, Entropy=0.0989, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2586
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9219, Q2 Loss=0.9219, Entropy=0.0157, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8893

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.9%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (18.3%)
Actor update: 0.13s (40.0%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000454
Q1 loss: 1.089647
Q2 loss: 1.089647
Current threshold: -149.4382
Global Scale Offset: 5.4390
Reward stats: mean=0.0198, std=0.1389, count=218
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.0896, Q2 Loss: 1.0896, Entropy: 0.0876, Mean TD Error: 0.8050, Threshold: -149.4382
Original likelihood: -118.58482360839844
Adjusted likelihood: -118.58482360839844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([0.0242, 0.0389, 0.0355], device='cuda:1')
5 turn
Sampling time 5.074618828017265
tensor([ 0.0555,  0.5533,  0.5765,  0.5577, -0.1428,  0.5402,  0.8348,  0.8666,
         1.2889,  0.3701,  0.2057,  1.1956,  0.0242,  0.0389,  0.0355,  0.5131],
       device='cuda:1')
Original likelihood: -113.23902893066406
Adjusted likelihood: -113.23902893066406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.368956481048372
Current ori: tensor([0.0242, 0.0389, 0.0355], device='cuda:1')
Middle force: tensor([1.3079, 0.5040, 0.5014, 0.5328, 0.5900, 0.5964, 1.0557, 0.8122, 0.5651,
        0.5115, 0.6125, 1.0145], device='cuda:1')
Thumb force: tensor([1.9311, 1.8669, 1.3993, 0.5811, 1.0922, 0.7919, 1.4230, 0.5765, 0.6140,
        0.5763, 0.6157, 0.5735], device='cuda:1')
Index force: tensor([0.5699, 0.8425, 0.8218, 0.6381, 0.5675, 0.5590, 0.5823, 0.5267, 0.6330,
        0.6742, 0.6120, 0.5488], device='cuda:1')
Storing NORMAL transition: reward=0.1996 (scaled=0.1996), steps=1
Reward stats updated: mean 0.0198 -> 0.0206, std: 0.1391
Collected 219 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.7041, Q2 Loss=0.7041, Entropy=0.0685, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2462
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.7037, Q2 Loss=0.7037, Entropy=0.0687, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4866
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0554, Q2 Loss=1.0554, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3872
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8970, Q2 Loss=0.8970, Entropy=0.0074, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5661
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.5515, Q2 Loss=0.5515, Entropy=0.3046, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1448

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (18.8%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (19.0%)
Actor update: 0.16s (40.1%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000079
Q1 loss: 0.782331
Q2 loss: 0.782331
Current threshold: -149.4342
Global Scale Offset: 5.6950
Reward stats: mean=0.0206, std=0.1391, count=219
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7823, Q2 Loss: 0.7823, Entropy: 0.0898, Mean TD Error: 0.7662, Threshold: -149.4342
tensor([ 0.0718,  0.5959,  0.5252,  0.5676, -0.0538,  0.5077,  0.9487,  0.8862,
         1.3659,  0.2763,  0.0774,  1.1320,  0.0141, -0.0212, -0.1631,  0.7782],
       device='cuda:1')
Original likelihood: -104.64588165283203
Adjusted likelihood: -104.64588165283203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 6.237370967981406
Current ori: tensor([ 0.0141, -0.0212, -0.1631], device='cuda:1')
Middle force: tensor([0.5049, 0.5039, 0.5345, 0.5996, 0.6185, 1.0333, 0.8217, 0.5713, 0.5308,
        0.6331, 1.0136], device='cuda:1')
Thumb force: tensor([1.8008, 1.3212, 0.5688, 1.0484, 0.7515, 1.3858, 0.5642, 0.5941, 0.5397,
        0.5930, 0.5657], device='cuda:1')
Index force: tensor([0.7996, 0.7353, 0.6333, 0.5625, 0.5519, 0.5788, 0.5248, 0.6288, 0.6345,
        0.6032, 0.5456], device='cuda:1')
Storing NORMAL transition: reward=-0.0079 (scaled=-0.0079), steps=1
Reward stats updated: mean 0.0206 -> 0.0205, std: 0.1388
Collected 220 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=17.2110, Q2 Loss=17.2110, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8353
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1397, Q2 Loss=1.1397, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9886
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0864, Q2 Loss=1.0864, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3392
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=2.1528, Q2 Loss=2.1528, Entropy=0.0227, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9373
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6748, Q2 Loss=1.6748, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7611

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.2%)
Q1 update: 0.07s (18.4%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000016
Q1 loss: 4.652947
Q2 loss: 4.652947
Current threshold: -149.4320
Global Scale Offset: 5.8674
Reward stats: mean=0.0205, std=0.1388, count=220
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.6529, Q2 Loss: 4.6529, Entropy: 0.0045, Mean TD Error: 2.5723, Threshold: -149.4320
tensor([ 0.0921,  0.6084,  0.5351,  0.5498, -0.0565,  0.4790,  0.8275,  0.8459,
         1.3997,  0.2507,  0.1015,  1.1603,  0.0397,  0.0129, -0.1568,  1.3994],
       device='cuda:1')
Original likelihood: -112.61911010742188
Adjusted likelihood: -112.61911010742188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.801765125012025
Current ori: tensor([ 0.0397,  0.0129, -0.1568], device='cuda:1')
Middle force: tensor([0.5040, 0.5053, 0.5775, 0.5951, 0.9844, 0.7633, 0.7722, 0.5944, 0.5445,
        0.5911], device='cuda:1')
Thumb force: tensor([1.2908, 0.5450, 1.0469, 0.7342, 1.3619, 0.5664, 0.6971, 0.6369, 0.5590,
        0.5612], device='cuda:1')
Index force: tensor([0.6761, 0.6702, 0.5581, 0.5444, 0.5695, 0.5218, 0.5562, 0.5581, 0.5066,
        0.5625], device='cuda:1')
Storing NORMAL transition: reward=0.1925 (scaled=0.1925), steps=1
Reward stats updated: mean 0.0205 -> 0.0213, std: 0.1390
Collected 221 transitions for RL
SAC Update 1/5: Actor Loss=-0.0064, Q1 Loss=0.7041, Q2 Loss=0.7041, Entropy=0.3457, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4100
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2500, Q2 Loss=1.2500, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7046
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5930, Q2 Loss=0.5930, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6993
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5755, Q2 Loss=0.5755, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3218
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1488, Q2 Loss=1.1488, Entropy=0.0021, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5897

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.2%)
Q1 update: 0.07s (18.4%)
Q2 update: 0.06s (17.6%)
Actor update: 0.14s (38.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001273
Q1 loss: 0.854288
Q2 loss: 0.854288
Current threshold: -149.4375
Global Scale Offset: 6.0141
Reward stats: mean=0.0213, std=0.1390, count=221
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 0.8543, Q2 Loss: 0.8543, Entropy: 0.0696, Mean TD Error: 0.5451, Threshold: -149.4375
tensor([ 0.1194,  0.5795,  0.6007,  0.5500,  0.0348,  0.4725,  0.8806,  0.9937,
         1.4280,  0.4558,  0.1302,  0.8965,  0.0495, -0.0393, -0.3616,  1.3829],
       device='cuda:1')
Original likelihood: -198.95574951171875
Adjusted likelihood: -198.95574951171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.1181,  -4.9559,  -7.1988,  -8.3152,  -8.4301,  -8.5027, -10.3500,
        -10.3967, -10.8633, -11.3187, -11.9698, -12.9887, -13.1906, -13.4775,
        -18.3181, -19.1427], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.1181,  -4.9559,  -7.1988,  -8.3152,  -8.4301,  -8.5027, -10.3500,
        -10.3967, -10.8633, -11.3187, -11.9698, -12.9887, -13.1906, -13.4775,
        -18.3181, -19.1427], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.8461
1 mode projection succeeded
New goal: tensor([ 0.0395,  0.5369,  0.5415,  0.6471, -0.0560,  0.5205,  0.8130,  0.8572,
         1.2740,  0.3060,  0.2110,  1.1720,  0.0049,  0.0145, -0.3389],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -127.8189926147461
Adjusted likelihood: -127.8189926147461
Likelihood residual: 0.0
Original likelihood: -211.90789794921875
Adjusted likelihood: -211.90789794921875
Likelihood residual: 0.0
{'index': 211.90789794921875, 'thumb_middle': 127.8189926147461}
Current yaw: tensor([ 0.0495, -0.0393, -0.3616], device='cuda:1')
6 thumb_middle
tensor([ 0.1194,  0.5795,  0.6007,  0.5500,  0.0348,  0.4725,  0.8806,  0.9937,
         1.4280,  0.4558,  0.1302,  0.8965,  0.0495, -0.0393, -0.3616,  1.3829],
       device='cuda:1')
Solve time for step 1 9.099835064960644
Current ori: tensor([ 0.0495, -0.0393, -0.3616], device='cuda:1')
Index force: tensor([0.5431, 0.6182, 0.5834, 0.5988], device='cuda:1')
tensor([ 0.1166,  0.5950,  0.5505,  0.5973, -0.0804,  0.5226,  0.8131,  0.8711,
         1.2349,  0.3134,  0.1054,  1.0832,  0.0489, -0.0357, -0.3622,  1.2558],
       device='cuda:1')
Solve time for step 2 3.7205695530283265
Current ori: tensor([ 0.0489, -0.0357, -0.3622], device='cuda:1')
Index force: tensor([0.6055, 0.5762, 0.5927], device='cuda:1')
tensor([ 0.0730,  0.5675,  0.5356,  0.6169, -0.1208,  0.5248,  0.7979,  0.8453,
         1.2339,  0.2892,  0.1205,  1.1286,  0.0548, -0.0126, -0.3622,  1.2083],
       device='cuda:1')
Solve time for step 3 3.8397293660091236
Current ori: tensor([ 0.0548, -0.0126, -0.3622], device='cuda:1')
Index force: tensor([0.5634, 0.5823], device='cuda:1')
tensor([ 0.0241,  0.5482,  0.5178,  0.6155, -0.1521,  0.5139,  0.7770,  0.8310,
         1.2396,  0.2907,  0.1434,  1.1474,  0.0584,  0.0112, -0.3622,  1.1542],
       device='cuda:1')
Solve time for step 4 3.54881311400095
Current ori: tensor([ 0.0584,  0.0112, -0.3622], device='cuda:1')
Index force: tensor([0.5698], device='cuda:1')
Storing RECOVERY transition: reward=-0.0030 (scaled=-0.0010), steps=3
Reward stats updated: mean 0.0213 -> 0.0212, std: 0.1387
Collected 222 transitions for RL
SAC Update 1/5: Actor Loss=-0.0064, Q1 Loss=0.6956, Q2 Loss=0.6956, Entropy=0.3458, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4330
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.7800, Q2 Loss=1.7800, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3640
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.7319, Q2 Loss=1.7319, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7682
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9575, Q2 Loss=0.9575, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2262
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.6080, Q2 Loss=1.6080, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2771

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (22.3%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (17.3%)
Actor update: 0.13s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001275
Q1 loss: 1.354598
Q2 loss: 1.354598
Current threshold: -149.4473
Global Scale Offset: 6.1326
Reward stats: mean=0.0212, std=0.1387, count=222
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.3546, Q2 Loss: 1.3546, Entropy: 0.0692, Mean TD Error: 1.6137, Threshold: -149.4473
Original likelihood: -147.52984619140625
Adjusted likelihood: -147.52984619140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6030)
Current yaw: tensor([ 0.0576,  0.0118, -0.3562], device='cuda:1')
7 turn
Sampling time 5.296750281006098
tensor([ 0.0211,  0.5535,  0.5135,  0.6037, -0.0674,  0.5733,  0.8056,  0.8447,
         1.3060,  0.3134,  0.1901,  1.1749,  0.0576,  0.0118, -0.3562,  1.1808],
       device='cuda:1')
Original likelihood: -135.1837158203125
Adjusted likelihood: -135.1837158203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9740)
Solve time for step 1 14.89783296501264
Current ori: tensor([ 0.0576,  0.0118, -0.3562], device='cuda:1')
Middle force: tensor([1.5087, 0.9772, 0.9753, 1.5747, 1.4394, 0.7452, 0.6213, 0.7775, 0.5071,
        0.5600, 0.5660, 0.5312], device='cuda:1')
Thumb force: tensor([0.6394, 0.5084, 0.5856, 0.7487, 0.9404, 1.0779, 0.8665, 0.5822, 0.5462,
        0.7045, 0.5507, 1.0323], device='cuda:1')
Index force: tensor([0.7909, 0.8458, 0.6923, 0.5245, 0.9430, 0.7904, 0.5451, 0.5184, 0.5081,
        0.5659, 0.5633, 0.8576], device='cuda:1')
Storing NORMAL transition: reward=0.0806 (scaled=0.0806), steps=1
Reward stats updated: mean 0.0212 -> 0.0215, std: 0.1384
Collected 223 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7243, Q2 Loss=0.7243, Entropy=0.0603, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5783
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6915, Q2 Loss=0.6915, Entropy=0.0079, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5039
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1784, Q2 Loss=1.1784, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4700
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=4.5359, Q2 Loss=4.5359, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3930
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6888, Q2 Loss=0.6888, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1719

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.4%)
Q1 update: 0.07s (18.7%)
Q2 update: 0.07s (18.3%)
Actor update: 0.14s (37.0%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000009
Q1 loss: 1.563783
Q2 loss: 1.563783
Current threshold: -149.4530
Global Scale Offset: 6.2149
Reward stats: mean=0.0215, std=0.1384, count=223
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.5638, Q2 Loss: 1.5638, Entropy: 0.0136, Mean TD Error: 1.8234, Threshold: -149.4530
tensor([ 0.0134,  0.4709,  0.5463,  0.6796, -0.0975,  0.5523,  0.8770,  0.9610,
         1.2629,  0.3665,  0.2282,  1.1197,  0.0664, -0.0072, -0.4385,  3.0777],
       device='cuda:1')
Original likelihood: -154.8970184326172
Adjusted likelihood: -154.8970184326172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2317)
State is out of distribution
Final likelihood: tensor([ -8.1264,  -9.0674,  -9.1285,  -9.1381,  -9.3147,  -9.5192,  -9.9481,
        -10.0891, -10.1338, -10.3525, -10.7328, -10.9146, -10.9844, -11.5108,
        -11.6171, -13.3997], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -8.1264,  -9.0674,  -9.1285,  -9.1381,  -9.3147,  -9.5192,  -9.9481,
        -10.0891, -10.1338, -10.3525, -10.7328, -10.9146, -10.9844, -11.5108,
        -11.6171, -13.3997], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -10.2486
1 mode projection succeeded
New goal: tensor([ 0.0190,  0.5712,  0.5000,  0.5949, -0.0831,  0.4753,  0.9087,  0.8818,
         1.2563,  0.3453,  0.2362,  1.1334,  0.0079,  0.0145, -0.9741],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0050]], device='cuda:1')
Original likelihood: -136.01873779296875
Adjusted likelihood: -136.01873779296875
Likelihood residual: 0.0
Original likelihood: -143.91473388671875
Adjusted likelihood: -143.91473388671875
Likelihood residual: 0.0
{'index': 143.91473388671875, 'thumb_middle': 136.01873779296875}
Current yaw: tensor([ 0.0664, -0.0072, -0.4385], device='cuda:1')
8 thumb_middle
tensor([ 0.0134,  0.4709,  0.5463,  0.6796, -0.0975,  0.5523,  0.8770,  0.9610,
         1.2629,  0.3665,  0.2282,  1.1197,  0.0664, -0.0072, -0.4385,  3.0777],
       device='cuda:1')
Solve time for step 1 8.921917986008339
Current ori: tensor([ 0.0664, -0.0072, -0.4385], device='cuda:1')
Index force: tensor([0.5705, 0.5798, 0.5955, 0.5077], device='cuda:1')
tensor([-0.0289,  0.5457,  0.4906,  0.5911, -0.1733,  0.4721,  0.8647,  0.8721,
         1.2111,  0.3332,  0.1665,  1.1079,  0.1207,  0.0209, -0.4386,  3.8282],
       device='cuda:1')
Solve time for step 2 3.7395192850381136
Current ori: tensor([ 0.1207,  0.0209, -0.4386], device='cuda:1')
Index force: tensor([0.5727, 0.5875, 0.5002], device='cuda:1')
tensor([-0.0217,  0.5598,  0.4880,  0.5714, -0.1786,  0.4678,  0.8705,  0.8585,
         1.2357,  0.3344,  0.1849,  1.1161,  0.1399,  0.0349, -0.4386,  4.1447],
       device='cuda:1')
Solve time for step 3 3.6679606389952824
Current ori: tensor([ 0.1399,  0.0349, -0.4386], device='cuda:1')
Index force: tensor([0.5001, 0.5753], device='cuda:1')
tensor([-0.0229,  0.5591,  0.4973,  0.5487, -0.1982,  0.4650,  0.8508,  0.8452,
         1.2424,  0.3378,  0.2158,  1.1417,  0.1385,  0.0364, -0.4386,  4.1798],
       device='cuda:1')
Solve time for step 4 3.615335001028143
Current ori: tensor([ 0.1385,  0.0364, -0.4386], device='cuda:1')
Index force: tensor([0.5703], device='cuda:1')
Storing RECOVERY transition: reward=0.0082 (scaled=0.0082), steps=1
Reward stats updated: mean 0.0215 -> 0.0214, std: 0.1381
Collected 224 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0566, Q2 Loss=1.0566, Entropy=0.0000, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8719
SAC Update 2/5: Actor Loss=-0.0010, Q1 Loss=0.7334, Q2 Loss=0.7334, Entropy=0.1561, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7527
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.7235, Q2 Loss=1.7235, Entropy=0.0089, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3124
SAC Update 4/5: Actor Loss=-0.0013, Q1 Loss=1.0432, Q2 Loss=1.0432, Entropy=0.2554, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3932
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9727, Q2 Loss=0.9727, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1330

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.9%)
Q1 update: 0.07s (18.3%)
Q2 update: 0.07s (18.2%)
Actor update: 0.15s (39.1%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000467
Q1 loss: 1.105877
Q2 loss: 1.105877
Current threshold: -149.4577
Global Scale Offset: 6.4659
Reward stats: mean=0.0214, std=0.1381, count=224
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.1059, Q2 Loss: 1.1059, Entropy: 0.0841, Mean TD Error: 0.8926, Threshold: -149.4577
Original likelihood: -231.04586791992188
Adjusted likelihood: -231.04586791992188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -52.7221,  -53.3889,  -59.5687,  -60.5181,  -67.8066,  -67.9847,
         -80.7518,  -90.0040,  -98.1341, -100.6270, -105.5515, -119.4169,
        -120.3567, -120.9444, -133.2691, -214.0490], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -52.7221,  -53.3889,  -59.5687,  -60.5181,  -67.8066,  -67.9847,
         -80.7518,  -90.0040,  -98.1341, -100.6270, -105.5515, -119.4169,
        -120.3567, -120.9444, -133.2691, -214.0490], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -96.5683
1 mode projection succeeded
New goal: tensor([ 0.0383,  0.5173,  0.5887,  0.6074, -0.0686,  0.5079,  0.8005,  0.9459,
         1.2561,  0.3131,  0.2660,  1.1395,  0.0291,  0.0181, -0.0761],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0018]], device='cuda:1')
Original likelihood: -248.98025512695312
Adjusted likelihood: -248.98025512695312
Likelihood residual: 0.0
Original likelihood: -228.59576416015625
Adjusted likelihood: -228.59576416015625
Likelihood residual: 0.0
{'index': 228.59576416015625, 'thumb_middle': 248.98025512695312}
Current yaw: tensor([ 0.1265,  0.0239, -0.4610], device='cuda:1')
9 index
tensor([-0.0152,  0.5917,  0.4517,  0.5529, -0.1091,  0.5162,  0.9293,  0.8952,
         1.3100,  0.3488,  0.2588,  1.1592,  0.1265,  0.0239, -0.4610,  4.1116],
       device='cuda:1')
Solve time for step 1 12.064469467964955
Current ori: tensor([ 0.1265,  0.0239, -0.4610], device='cuda:1')
Middle force: tensor([0.5706, 0.5568, 0.5949, 0.5255], device='cuda:1')
Thumb force: tensor([0.5264, 0.6149, 0.5777, 0.6389], device='cuda:1')
tensor([ 0.0577,  0.4403,  0.5205,  0.5823, -0.0926,  0.5614,  0.8578,  0.9485,
         1.3115,  0.3480,  0.2424,  1.1452,  0.1171,  0.0125, -0.4866,  6.1505],
       device='cuda:1')
Solve time for step 2 4.436233594024088
Current ori: tensor([ 0.1171,  0.0125, -0.4866], device='cuda:1')
Middle force: tensor([0.5508, 0.5867, 0.5229], device='cuda:1')
Thumb force: tensor([0.6125, 0.5777, 0.6356], device='cuda:1')
tensor([ 0.0726,  0.4433,  0.5366,  0.5875, -0.0948,  0.5826,  0.8360,  0.9397,
         1.3212,  0.3391,  0.2387,  1.1252,  0.1090,  0.0122, -0.4961, -5.4091],
       device='cuda:1')
Solve time for step 3 4.710417631955352
Current ori: tensor([ 0.1090,  0.0122, -0.4961], device='cuda:1')
Middle force: tensor([0.5590, 0.5236], device='cuda:1')
Thumb force: tensor([0.5458, 0.5057], device='cuda:1')
tensor([ 0.0770,  0.4553,  0.5404,  0.5860, -0.1006,  0.6096,  0.8225,  0.9236,
         1.3267,  0.3351,  0.2329,  1.1063,  0.0997,  0.0093, -0.5066, -5.3454],
       device='cuda:1')
Solve time for step 4 4.569889325997792
Current ori: tensor([ 0.0997,  0.0093, -0.5066], device='cuda:1')
Middle force: tensor([0.5202], device='cuda:1')
Thumb force: tensor([0.5037], device='cuda:1')
Storing RECOVERY transition: reward=0.0407 (scaled=0.0407), steps=1
Reward stats updated: mean 0.0214 -> 0.0215, std: 0.1378
Collected 225 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.1202, Q2 Loss=2.1202, Entropy=0.0028, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4798
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6209, Q2 Loss=0.6209, Entropy=0.0009, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2716
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0404, Q2 Loss=1.0404, Entropy=0.0077, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3592
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=7.2503, Q2 Loss=7.2503, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9365
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7031, Q2 Loss=0.7031, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6448

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.5%)
Q1 update: 0.06s (18.1%)
Q2 update: 0.06s (18.0%)
Actor update: 0.13s (36.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000006
Q1 loss: 2.346993
Q2 loss: 2.346993
Current threshold: -149.4607
Global Scale Offset: 6.7623
Reward stats: mean=0.0215, std=0.1378, count=225
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.3470, Q2 Loss: 2.3470, Entropy: 0.0023, Mean TD Error: 2.1384, Threshold: -149.4607
Original likelihood: -295.3992919921875
Adjusted likelihood: -295.3992919921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-36.7160, -38.5815, -39.9439, -40.6027, -40.6303, -41.3335, -43.2768,
        -43.4055, -43.6460, -43.7325, -45.1198, -50.7578, -53.1184, -61.2099,
        -88.0815, -94.6372], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-36.7160, -38.5815, -39.9439, -40.6027, -40.6303, -41.3335, -43.2768,
        -43.4055, -43.6460, -43.7325, -45.1198, -50.7578, -53.1184, -61.2099,
        -88.0815, -94.6372], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -50.2996
1 mode projection succeeded
New goal: tensor([ 0.0712,  0.5431,  0.5629,  0.6503, -0.0811,  0.5044,  0.8646,  0.9034,
         1.2938,  0.3120,  0.1677,  1.2180,  0.0254,  0.0129, -0.2807],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -231.45059204101562
Adjusted likelihood: -231.45059204101562
Likelihood residual: 0.0
Original likelihood: -220.01004028320312
Adjusted likelihood: -220.01004028320312
Likelihood residual: 0.0
{'index': 220.01004028320312, 'thumb_middle': 231.45059204101562}
Current yaw: tensor([ 0.1236,  0.0090, -0.4936], device='cuda:1')
10 index
tensor([ 0.0284,  0.5097,  0.5831,  0.6057, -0.1034,  0.6490,  0.8236,  0.9112,
         1.3384,  0.3424,  0.2439,  1.1067,  0.1236,  0.0090, -0.4936, -5.2336],
       device='cuda:1')
Solve time for step 1 11.575464735971764
Current ori: tensor([ 0.1236,  0.0090, -0.4936], device='cuda:1')
Middle force: tensor([0.5973, 0.5995, 0.5089, 0.5146], device='cuda:1')
Thumb force: tensor([0.5673, 0.5904, 0.5209, 0.5438], device='cuda:1')
tensor([ 0.1033,  0.4509,  0.5233,  0.6245, -0.0640,  0.6842,  0.8785,  0.8573,
         1.4021,  0.3190,  0.2155,  1.1307,  0.2216, -0.0081, -0.4806, -5.9670],
       device='cuda:1')
Solve time for step 2 4.838197365985252
Current ori: tensor([ 0.2216, -0.0081, -0.4806], device='cuda:1')
Middle force: tensor([0.5379, 0.5885, 0.5899], device='cuda:1')
Thumb force: tensor([0.5807, 0.6084, 0.5854], device='cuda:1')
tensor([ 0.0658,  0.3536,  0.5329,  0.6522, -0.0417,  0.7716,  0.8956,  0.8480,
         1.4844,  0.3160,  0.2208,  1.1100,  0.2620, -0.0097, -0.4670, -6.0826],
       device='cuda:1')
Solve time for step 3 4.349988530040719
Current ori: tensor([ 0.2620, -0.0097, -0.4670], device='cuda:1')
Middle force: tensor([0.5819, 0.5836], device='cuda:1')
Thumb force: tensor([0.6067, 0.5846], device='cuda:1')
tensor([ 0.0726,  0.2681,  0.5594,  0.6492,  0.0074,  0.7990,  0.8906,  0.9556,
         1.4750,  0.3549,  0.2149,  1.1200,  0.2824, -0.0219, -0.4403, -5.8178],
       device='cuda:1')
Solve time for step 4 4.262020899972413
Current ori: tensor([ 0.2824, -0.0219, -0.4403], device='cuda:1')
Middle force: tensor([0.5108], device='cuda:1')
Thumb force: tensor([0.5298], device='cuda:1')
Storing RECOVERY transition: reward=-0.0887 (scaled=-0.0887), steps=1
Reward stats updated: mean 0.0215 -> 0.0210, std: 0.1377
Collected 226 transitions for RL
SAC Update 1/5: Actor Loss=-0.0016, Q1 Loss=1.0177, Q2 Loss=1.0177, Entropy=0.2282, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2922
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.7358, Q2 Loss=0.7358, Entropy=0.2813, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4280
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3511, Q2 Loss=1.3511, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8490
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.6261, Q2 Loss=0.6261, Entropy=0.2835, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2706
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=4.3812, Q2 Loss=4.3812, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3956

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.8%)
Q1 update: 0.06s (18.8%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (39.1%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000468
Q1 loss: 1.622401
Q2 loss: 1.622401
Current threshold: -149.4609
Global Scale Offset: 7.1318
Reward stats: mean=0.0210, std=0.1377, count=226
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.6224, Q2 Loss: 1.6224, Entropy: 0.1586, Mean TD Error: 2.4471, Threshold: -149.4609
Original likelihood: -351.9759521484375
Adjusted likelihood: -351.9759521484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -77.3217,  -87.1049, -103.8575, -108.6166, -111.9662, -114.3835,
        -121.7914, -128.4712, -128.7692, -131.2365, -140.4746, -141.9290,
        -142.8809, -186.9535, -202.7578, -233.0724], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -77.3217,  -87.1049, -103.8575, -108.6166, -111.9662, -114.3835,
        -121.7914, -128.4712, -128.7692, -131.2365, -140.4746, -141.9290,
        -142.8809, -186.9535, -202.7578, -233.0724], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -135.0992
1 mode projection succeeded
New goal: tensor([ 0.0882,  0.3695,  0.6967,  0.7945,  0.0032,  0.5581,  0.7310,  1.0854,
         1.3763,  0.2491,  0.2793,  1.0967,  0.1695, -0.0052,  0.9221],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0042]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -331.9961242675781
Adjusted likelihood: -331.9961242675781
Likelihood residual: 0.0
Original likelihood: -381.3702087402344
Adjusted likelihood: -381.3702087402344
Likelihood residual: 0.0
{'index': 381.3702087402344, 'thumb_middle': 331.9961242675781}
Current yaw: tensor([ 0.2680, -0.0340, -0.4181], device='cuda:1')
11 thumb_middle
tensor([ 6.0007e-02,  3.5889e-01,  5.6503e-01,  6.5162e-01, -6.8826e-04,
         7.5851e-01,  9.4917e-01,  9.7300e-01,  1.4829e+00,  3.6325e-01,
         2.0837e-01,  1.1656e+00,  2.6803e-01, -3.4019e-02, -4.1810e-01,
        -5.8289e+00], device='cuda:1')
Solve time for step 1 9.915797511988785
Current ori: tensor([ 0.2680, -0.0340, -0.4181], device='cuda:1')
Index force: tensor([0.5709, 0.5974, 0.5883, 0.5861], device='cuda:1')
tensor([ 0.2796,  0.5132,  0.7087,  0.7643,  0.0463,  0.6389,  0.7949,  1.0756,
         1.3563,  0.2569,  0.2038,  1.0801,  0.2527, -0.0976, -0.3599, -5.2073],
       device='cuda:1')
Solve time for step 2 3.705752781010233
Current ori: tensor([ 0.2527, -0.0976, -0.3599], device='cuda:1')
Index force: tensor([0.5911, 0.5827, 0.5803], device='cuda:1')
tensor([ 0.2485,  0.5473,  0.7174,  0.7577,  0.0540,  0.6610,  0.7784,  1.0889,
         1.3472,  0.2406,  0.1954,  1.0746,  0.2622, -0.1209, -0.2466, -4.9710],
       device='cuda:1')
Solve time for step 3 3.8973260860075243
Current ori: tensor([ 0.2622, -0.1209, -0.2466], device='cuda:1')
Index force: tensor([0.5762, 0.5740], device='cuda:1')
tensor([ 0.2270,  0.5858,  0.7223,  0.8029,  0.0849,  0.6727,  0.7832,  1.0905,
         1.3399,  0.2427,  0.1962,  1.0588,  0.3615, -0.2967, -0.0474, -3.3195],
       device='cuda:1')
Solve time for step 4 3.745951884018723
Current ori: tensor([ 0.3615, -0.2967, -0.0474], device='cuda:1')
Index force: tensor([0.5346], device='cuda:1')
Storing RECOVERY transition: reward=-0.4879 (scaled=-0.4879), steps=1
Reward stats updated: mean 0.0210 -> 0.0188, std: 0.1415
Collected 227 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.6291, Q2 Loss=0.6291, Entropy=0.2874, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5494
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.9881, Q2 Loss=0.9881, Entropy=0.2865, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1025
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6579, Q2 Loss=0.6579, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3743
SAC Update 4/5: Actor Loss=-0.0018, Q1 Loss=1.0642, Q2 Loss=1.0642, Entropy=0.2251, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5557
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7480, Q2 Loss=0.7480, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4242

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.4%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (17.3%)
Actor update: 0.13s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000498
Q1 loss: 0.817454
Q2 loss: 0.817454
Current threshold: -149.4608
Global Scale Offset: 7.4833
Reward stats: mean=0.0188, std=0.1415, count=227
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.8175, Q2 Loss: 0.8175, Entropy: 0.1598, Mean TD Error: 0.8012, Threshold: -149.4608
Original likelihood: -1120.107177734375
Adjusted likelihood: -1120.107177734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 16
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
1 turn
Sampling time 5.042914893012494
tensor([ 1.4163e-01,  6.2800e-01,  5.1079e-01,  6.5357e-01, -9.7885e-02,
         5.2371e-01,  8.9398e-01,  8.8673e-01,  1.2207e+00,  2.4420e-01,
         2.8613e-01,  1.1987e+00, -1.3005e-04,  1.3937e-02, -3.9258e-02,
         4.4622e-01], device='cuda:1')
Original likelihood: -124.0627670288086
Adjusted likelihood: -124.0627670288086
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9982)
Solve time for step 1 15.509458296990488
Current ori: tensor([-0.0001,  0.0139, -0.0393], device='cuda:1')
Middle force: tensor([0.4822, 0.5474, 1.1830, 0.5385, 1.0991, 0.6028, 0.5217, 0.5581, 0.4842,
        0.5241, 0.4413, 0.4296], device='cuda:1')
Thumb force: tensor([0.9195, 0.9182, 0.8298, 1.0780, 1.1236, 0.6619, 0.5326, 0.8338, 0.5156,
        0.5812, 0.5545, 0.6270], device='cuda:1')
Index force: tensor([0.5709, 0.5806, 0.5262, 0.5529, 0.8193, 0.4591, 1.0112, 0.9175, 0.5937,
        0.5697, 0.7751, 0.7574], device='cuda:1')
Storing NORMAL transition: reward=-0.1509 (scaled=-0.1509), steps=1
Reward stats updated: mean 0.0188 -> 0.0180, std: 0.1416
Collected 228 transitions for RL
SAC Update 1/5: Actor Loss=-0.0009, Q1 Loss=1.5135, Q2 Loss=1.5135, Entropy=0.1562, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2692
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=1.3459, Q2 Loss=1.3459, Entropy=0.1287, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8787
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.9252, Q2 Loss=0.9252, Entropy=0.6607, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6198
SAC Update 4/5: Actor Loss=-0.0028, Q1 Loss=2.8934, Q2 Loss=2.8934, Entropy=0.2788, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9904
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.9807, Q2 Loss=1.9807, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8202

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.7%)
Q1 update: 0.07s (19.5%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (38.2%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002488
Q1 loss: 1.731743
Q2 loss: 1.731743
Current threshold: -149.4517
Global Scale Offset: 8.1206
Reward stats: mean=0.0180, std=0.1416, count=228
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 1.7317, Q2 Loss: 1.7317, Entropy: 0.2449, Mean TD Error: 2.7157, Threshold: -149.4517
tensor([ 0.1526,  0.6232,  0.4888,  0.7340, -0.0707,  0.6230,  0.7042,  0.9254,
         1.2093,  0.2421,  0.2539,  1.3967,  0.0057,  0.0033,  0.1118,  0.5081],
       device='cuda:1')
Original likelihood: -150.85537719726562
Adjusted likelihood: -150.85537719726562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4404)
State is out of distribution
Final likelihood: tensor([-3.2131, -3.4596, -3.4685, -3.4985, -3.8223, -3.9161, -4.1233, -4.3201,
        -4.6220, -4.7080, -4.8323, -4.9446, -4.9784, -5.7146, -6.1040, -7.3533],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.2131, -3.4596, -3.4685, -3.4985, -3.8223, -3.9161, -4.1233, -4.3201,
        -4.6220, -4.7080, -4.8323, -4.9446, -4.9784, -5.7146, -6.1040, -7.3533],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.5674
1 mode projection succeeded
New goal: tensor([ 0.0394,  0.5371,  0.5408,  0.6478, -0.0564,  0.5219,  0.8112,  0.8570,
         1.2738,  0.3045,  0.2128,  1.1698,  0.0041,  0.0146, -0.7618],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -109.23877716064453
Adjusted likelihood: -109.23877716064453
Likelihood residual: 0.0
Original likelihood: -110.7791748046875
Adjusted likelihood: -110.7791748046875
Likelihood residual: 0.0
{'index': 110.7791748046875, 'thumb_middle': 109.23877716064453}
Current yaw: tensor([0.0057, 0.0033, 0.1118], device='cuda:1')
2 thumb_middle
tensor([ 0.1526,  0.6232,  0.4888,  0.7340, -0.0707,  0.6230,  0.7042,  0.9254,
         1.2093,  0.2421,  0.2539,  1.3967,  0.0057,  0.0033,  0.1118,  0.5081],
       device='cuda:1')
Solve time for step 1 9.73056686198106
Current ori: tensor([0.0057, 0.0033, 0.1118], device='cuda:1')
Index force: tensor([0.5563, 0.5980, 0.5795, 0.5867], device='cuda:1')
tensor([ 0.1426,  0.5983,  0.5447,  0.6684, -0.1426,  0.5121,  0.7675,  0.8480,
         1.2183,  0.2727,  0.1389,  1.1715,  0.0056,  0.0097,  0.1118,  0.4666],
       device='cuda:1')
Solve time for step 2 3.6132617730181664
Current ori: tensor([0.0056, 0.0097, 0.1118], device='cuda:1')
Index force: tensor([0.5876, 0.5731, 0.5807], device='cuda:1')
tensor([ 0.1041,  0.5874,  0.5362,  0.6374, -0.1683,  0.4889,  0.7726,  0.8313,
         1.2483,  0.2858,  0.1389,  1.1389,  0.0057,  0.0311,  0.1118,  0.4044],
       device='cuda:1')
Solve time for step 3 3.9699564640177414
Current ori: tensor([0.0057, 0.0311, 0.1118], device='cuda:1')
Index force: tensor([0.5650, 0.5705], device='cuda:1')
tensor([ 0.0912,  0.5638,  0.5427,  0.6631, -0.1786,  0.4864,  0.7662,  0.8211,
         1.2550,  0.2850,  0.1463,  1.1393,  0.0134,  0.0395,  0.1118,  0.3930],
       device='cuda:1')
Solve time for step 4 3.8051755969645455
Current ori: tensor([0.0134, 0.0395, 0.1118], device='cuda:1')
Index force: tensor([0.5549], device='cuda:1')
Storing RECOVERY transition: reward=0.0144 (scaled=0.0144), steps=1
Reward stats updated: mean 0.0180 -> 0.0180, std: 0.1413
Collected 229 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0328, Q2 Loss=1.0328, Entropy=0.0005, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2259
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.9753, Q2 Loss=0.9753, Entropy=0.3305, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1384
SAC Update 3/5: Actor Loss=-0.0041, Q1 Loss=7.3066, Q2 Loss=7.3066, Entropy=0.3432, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0395
SAC Update 4/5: Actor Loss=-0.0026, Q1 Loss=0.6501, Q2 Loss=0.6501, Entropy=0.2704, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2073
SAC Update 5/5: Actor Loss=-0.0013, Q1 Loss=0.9355, Q2 Loss=0.9355, Entropy=0.1844, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5401

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.3%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.08s (19.0%)
Actor update: 0.16s (39.5%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003103
Q1 loss: 2.180071
Q2 loss: 2.180071
Current threshold: -149.4392
Global Scale Offset: 8.6487
Reward stats: mean=0.0180, std=0.1413, count=229
----------------------------------------------
SAC Update - Actor Loss: -0.0031, Q1 Loss: 2.1801, Q2 Loss: 2.1801, Entropy: 0.2258, Mean TD Error: 1.0302, Threshold: -149.4392
Original likelihood: -119.25909423828125
Adjusted likelihood: -119.25909423828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9989)
Current yaw: tensor([0.0107, 0.0297, 0.0966], device='cuda:1')
3 turn
Sampling time 5.0591691200388595
tensor([ 0.1064,  0.5720,  0.5557,  0.6455, -0.0960,  0.5293,  0.8144,  0.8476,
         1.3153,  0.3088,  0.1877,  1.1713,  0.0107,  0.0297,  0.0966,  0.4409],
       device='cuda:1')
Original likelihood: -116.12039184570312
Adjusted likelihood: -116.12039184570312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Solve time for step 1 15.777738078031689
Current ori: tensor([0.0107, 0.0297, 0.0966], device='cuda:1')
Middle force: tensor([0.6415, 0.9938, 0.5554, 0.5037, 0.5255, 0.7425, 0.5152, 0.6144, 0.5496,
        0.6998, 0.7371, 0.5530], device='cuda:1')
Thumb force: tensor([1.4846, 1.6587, 0.6626, 0.6894, 0.8406, 1.9313, 0.7203, 0.5563, 0.5262,
        1.0844, 1.1614, 0.6114], device='cuda:1')
Index force: tensor([1.0807, 1.4577, 0.9713, 0.7232, 1.2903, 0.7287, 0.5480, 0.5316, 0.5842,
        0.5744, 0.5457, 0.5841], device='cuda:1')
Storing NORMAL transition: reward=0.0320 (scaled=0.0320), steps=1
Reward stats updated: mean 0.0180 -> 0.0181, std: 0.1410
Collected 230 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.6655, Q2 Loss=0.6655, Entropy=0.0353, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3081
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6921, Q2 Loss=0.6921, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4581
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6843, Q2 Loss=0.6843, Entropy=0.0022, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6500
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=1.0660, Q2 Loss=1.0660, Entropy=0.3167, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9616
SAC Update 5/5: Actor Loss=-0.0016, Q1 Loss=0.9759, Q2 Loss=0.9759, Entropy=0.2092, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9446

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.5%)
Q1 update: 0.07s (18.6%)
Q2 update: 0.06s (17.8%)
Actor update: 0.14s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000479
Q1 loss: 0.816731
Q2 loss: 0.816731
Current threshold: -149.4315
Global Scale Offset: 9.3020
Reward stats: mean=0.0181, std=0.1410, count=230
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.8167, Q2 Loss: 0.8167, Entropy: 0.1127, Mean TD Error: 1.0645, Threshold: -149.4315
tensor([ 0.3277,  0.6307,  0.6582,  0.6358, -0.1771,  0.4769,  0.8945,  0.8952,
         1.5000,  0.2275,  0.0518,  1.0862,  0.0064,  0.0602,  0.0618, -0.6906],
       device='cuda:1')
Original likelihood: -315.87335205078125
Adjusted likelihood: -315.87335205078125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([-2.9873, -3.4213, -3.4520, -3.7301, -4.0893, -4.1043, -4.1459, -4.1805,
        -4.3019, -4.3355, -4.4292, -4.6443, -4.7283, -5.7249, -5.9144, -6.7798],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9873, -3.4213, -3.4520, -3.7301, -4.0893, -4.1043, -4.1459, -4.1805,
        -4.3019, -4.3355, -4.4292, -4.6443, -4.7283, -5.7249, -5.9144, -6.7798],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.4356
1 mode projection succeeded
New goal: tensor([ 0.1113,  0.5388,  0.6227,  0.6163, -0.0681,  0.4824,  0.8491,  0.9503,
         1.2507,  0.3052,  0.2411,  1.1591,  0.0044,  0.0130,  2.0373],
       device='cuda:1')
tensor([[0.0033]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0093]], device='cuda:1')
Original likelihood: -97.55677032470703
Adjusted likelihood: -97.55677032470703
Likelihood residual: 0.0
{'index': 97.55677032470703, 'thumb_middle': inf}
Current yaw: tensor([0.0064, 0.0602, 0.0618], device='cuda:1')
4 index
tensor([ 0.3277,  0.6307,  0.6582,  0.6358, -0.1771,  0.4769,  0.8945,  0.8952,
         1.5000,  0.2275,  0.0518,  1.0862,  0.0064,  0.0602,  0.0618, -0.6906],
       device='cuda:1')
Solve time for step 1 11.197861065040343
Current ori: tensor([0.0064, 0.0602, 0.0618], device='cuda:1')
Middle force: tensor([0.5785, 0.5480, 0.5111, 0.5157], device='cuda:1')
Thumb force: tensor([0.5993, 0.5826, 0.5807, 0.5383], device='cuda:1')
tensor([ 0.1894,  0.4991,  0.5797,  0.5965, -0.1479,  0.4974,  0.8690,  0.9432,
         1.4286,  0.3481,  0.0767,  1.1027,  0.0085,  0.0408,  0.0631, -1.1897],
       device='cuda:1')
Solve time for step 2 4.57445698097581
Current ori: tensor([0.0085, 0.0408, 0.0631], device='cuda:1')
Middle force: tensor([0.5462, 0.5101, 0.5135], device='cuda:1')
Thumb force: tensor([0.5740, 0.5782, 0.5363], device='cuda:1')
tensor([ 0.1614,  0.4871,  0.5745,  0.5917, -0.1427,  0.4949,  0.8689,  0.9626,
         1.3970,  0.4001,  0.0942,  1.1073,  0.0123,  0.0365,  0.0625, -1.2869],
       device='cuda:1')
Solve time for step 3 4.390635287039913
Current ori: tensor([0.0123, 0.0365, 0.0625], device='cuda:1')
Middle force: tensor([0.5578, 0.5001], device='cuda:1')
Thumb force: tensor([0.5942, 0.5007], device='cuda:1')
tensor([ 0.1559,  0.4851,  0.5727,  0.5920, -0.1350,  0.5034,  0.8640,  0.9594,
         1.3774,  0.4269,  0.1037,  1.1079,  0.0117,  0.0317,  0.0753, -1.1760],
       device='cuda:1')
Solve time for step 4 4.6391765649896115
Current ori: tensor([0.0117, 0.0317, 0.0753], device='cuda:1')
Middle force: tensor([0.5450], device='cuda:1')
Thumb force: tensor([0.5772], device='cuda:1')
Storing RECOVERY transition: reward=-0.0156 (scaled=-0.0156), steps=1
Reward stats updated: mean 0.0181 -> 0.0179, std: 0.1407
Collected 231 transitions for RL
SAC Update 1/5: Actor Loss=-0.0022, Q1 Loss=1.1760, Q2 Loss=1.1760, Entropy=0.3307, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4499
SAC Update 2/5: Actor Loss=-0.0017, Q1 Loss=1.0243, Q2 Loss=1.0243, Entropy=0.2161, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3823
SAC Update 3/5: Actor Loss=-0.0047, Q1 Loss=1.2732, Q2 Loss=1.2732, Entropy=0.6229, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7918
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7501, Q2 Loss=0.7501, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1946
SAC Update 5/5: Actor Loss=-0.0017, Q1 Loss=1.9875, Q2 Loss=1.9875, Entropy=0.3123, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3776

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.1%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.9%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002048
Q1 loss: 1.242233
Q2 loss: 1.242233
Current threshold: -149.4197
Global Scale Offset: 10.4714
Reward stats: mean=0.0179, std=0.1407, count=231
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 1.2422, Q2 Loss: 1.2422, Entropy: 0.2964, Mean TD Error: 1.4392, Threshold: -149.4197
Original likelihood: -119.02139282226562
Adjusted likelihood: -119.02139282226562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9952)
Current yaw: tensor([0.0127, 0.0221, 0.0805], device='cuda:1')
5 turn
Sampling time 5.099475139984861
tensor([ 0.1106,  0.5416,  0.6178,  0.6138, -0.1213,  0.5084,  0.8675,  0.9612,
         1.3683,  0.4337,  0.0929,  1.1240,  0.0127,  0.0221,  0.0805, -1.1051],
       device='cuda:1')
Original likelihood: -103.56289672851562
Adjusted likelihood: -103.56289672851562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.019334562006406
Current ori: tensor([0.0127, 0.0221, 0.0805], device='cuda:1')
Middle force: tensor([0.9296, 0.9991, 0.6057, 1.1813, 0.5670, 0.4988, 0.6258, 1.0680, 0.5744,
        0.5386, 0.5296, 0.5259], device='cuda:1')
Thumb force: tensor([1.4970, 0.5261, 0.6277, 0.7009, 0.9240, 0.5475, 0.7087, 0.6106, 0.6309,
        0.6459, 0.6409, 0.5385], device='cuda:1')
Index force: tensor([1.0857, 0.5151, 0.5394, 0.7573, 0.5317, 0.6093, 0.8476, 0.5060, 0.6058,
        0.6615, 0.6495, 0.5646], device='cuda:1')
Storing NORMAL transition: reward=0.0302 (scaled=0.0302), steps=1
Reward stats updated: mean 0.0179 -> 0.0180, std: 0.1404
Collected 232 transitions for RL
SAC Update 1/5: Actor Loss=-0.0028, Q1 Loss=0.6729, Q2 Loss=0.6729, Entropy=0.3163, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8347
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7647, Q2 Loss=0.7647, Entropy=0.0069, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4583
SAC Update 3/5: Actor Loss=-0.0047, Q1 Loss=1.4768, Q2 Loss=1.4768, Entropy=0.3309, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6218
SAC Update 4/5: Actor Loss=-0.0039, Q1 Loss=1.2120, Q2 Loss=1.2120, Entropy=0.3665, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6806
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=0.9279, Q2 Loss=0.9279, Entropy=0.1172, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3232

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.4%)
Q1 update: 0.07s (18.0%)
Q2 update: 0.07s (18.4%)
Actor update: 0.14s (39.1%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002403
Q1 loss: 1.010831
Q2 loss: 1.010831
Current threshold: -149.4064
Global Scale Offset: 11.8309
Reward stats: mean=0.0180, std=0.1404, count=232
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 1.0108, Q2 Loss: 1.0108, Entropy: 0.2276, Mean TD Error: 0.7837, Threshold: -149.4064
tensor([ 0.1352,  0.5393,  0.6278,  0.6483, -0.0811,  0.4854,  0.8461,  1.0132,
         1.3567,  0.4746,  0.1481,  1.0251,  0.0152,  0.0108,  0.0505, -1.0146],
       device='cuda:1')
Original likelihood: -91.41331481933594
Adjusted likelihood: -91.41331481933594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.953152525995392
Current ori: tensor([0.0152, 0.0108, 0.0505], device='cuda:1')
Middle force: tensor([1.0768, 0.9355, 0.9439, 0.5002, 0.5051, 0.5318, 0.5002, 0.5332, 0.5927,
        0.8362, 0.5021], device='cuda:1')
Thumb force: tensor([0.7900, 1.0698, 0.5555, 0.8072, 1.6897, 0.5564, 0.6383, 0.6135, 0.6659,
        0.5962, 0.6496], device='cuda:1')
Index force: tensor([0.6847, 0.5629, 0.7451, 0.6764, 0.8613, 0.6110, 0.6993, 0.6686, 0.5491,
        0.6015, 0.7315], device='cuda:1')
Storing NORMAL transition: reward=-0.0079 (scaled=-0.0079), steps=1
Reward stats updated: mean 0.0180 -> 0.0179, std: 0.1401
Collected 233 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.8000, Q2 Loss=0.8000, Entropy=0.0975, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7020
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0798, Q2 Loss=1.0798, Entropy=0.0003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4400
SAC Update 3/5: Actor Loss=-0.0032, Q1 Loss=1.4750, Q2 Loss=1.4750, Entropy=0.2931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1351
SAC Update 4/5: Actor Loss=-0.0040, Q1 Loss=2.0657, Q2 Loss=2.0657, Entropy=0.3207, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4234
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7977, Q2 Loss=0.7977, Entropy=0.0159, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2073

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.1%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.06s (18.9%)
Actor update: 0.12s (36.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001486
Q1 loss: 1.243637
Q2 loss: 1.243637
Current threshold: -149.3934
Global Scale Offset: 13.3324
Reward stats: mean=0.0179, std=0.1401, count=233
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 1.2436, Q2 Loss: 1.2436, Entropy: 0.1455, Mean TD Error: 1.1816, Threshold: -149.3934
tensor([ 0.2040,  0.6884,  0.5105,  0.5724, -0.0069,  0.5586,  0.7751,  1.0999,
         1.4207,  0.2098, -0.0141,  0.8036,  0.0254, -0.0477,  0.0559, -2.9330],
       device='cuda:1')
Original likelihood: -228.56436157226562
Adjusted likelihood: -228.56436157226562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -3.7147,  -3.7328,  -3.8664,  -4.0953,  -4.1575,  -4.1880,  -4.2299,
         -4.4245,  -4.6686,  -5.0142,  -5.0518,  -5.6195,  -6.0587,  -7.2204,
        -11.8906, -12.0367], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.7147,  -3.7328,  -3.8664,  -4.0953,  -4.1575,  -4.1880,  -4.2299,
         -4.4245,  -4.6686,  -5.0142,  -5.0518,  -5.6195,  -6.0587,  -7.2204,
        -11.8906, -12.0367], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.6231
1 mode projection succeeded
New goal: tensor([ 0.0398,  0.5439,  0.5391,  0.6301, -0.0725,  0.4904,  0.8532,  0.9138,
         1.2890,  0.2895,  0.2386,  1.0904,  0.0050,  0.0155,  0.5861],
       device='cuda:1')
tensor([[0.0183]], device='cuda:1') tensor([[0.0038]], device='cuda:1') tensor([[0.0040]], device='cuda:1')
Original likelihood: -117.3056869506836
Adjusted likelihood: -117.3056869506836
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 117.3056869506836}
Current yaw: tensor([ 0.0254, -0.0477,  0.0559], device='cuda:1')
6 thumb_middle
tensor([ 0.2040,  0.6884,  0.5105,  0.5724, -0.0069,  0.5586,  0.7751,  1.0999,
         1.4207,  0.2098, -0.0141,  0.8036,  0.0254, -0.0477,  0.0559, -2.9330],
       device='cuda:1')
Solve time for step 1 9.537308272963855
Current ori: tensor([ 0.0254, -0.0477,  0.0559], device='cuda:1')
Index force: tensor([0.7924, 0.5001, 0.5001, 0.6047], device='cuda:1')
tensor([ 0.1550,  0.5999,  0.5564,  0.6588, -0.1202,  0.4895,  0.8251,  0.9091,
         1.2823,  0.2700,  0.1238,  1.0049,  0.0478, -0.0227,  0.0559, -3.0155],
       device='cuda:1')
Solve time for step 2 3.9661253060330637
Current ori: tensor([ 0.0478, -0.0227,  0.0559], device='cuda:1')
Index force: tensor([0.5030, 0.6127, 0.5850], device='cuda:1')
tensor([ 0.1468,  0.5968,  0.5649,  0.6321, -0.1309,  0.4869,  0.8339,  0.9147,
         1.2676,  0.2853,  0.1287,  1.0258,  0.0458, -0.0192,  0.0559, -3.0367],
       device='cuda:1')
Solve time for step 3 3.7822112099966034
Current ori: tensor([ 0.0458, -0.0192,  0.0559], device='cuda:1')
Index force: tensor([0.5982, 0.5763], device='cuda:1')
tensor([ 0.0877,  0.5838,  0.5447,  0.5899, -0.1770,  0.4758,  0.8278,  0.8886,
         1.2630,  0.2845,  0.1585,  1.0564,  0.0434,  0.0097,  0.0559, -3.1359],
       device='cuda:1')
Solve time for step 4 3.6076095390017144
Current ori: tensor([0.0434, 0.0097, 0.0559], device='cuda:1')
Index force: tensor([0.5557], device='cuda:1')
Storing RECOVERY transition: reward=-0.0145 (scaled=-0.0072), steps=2
Reward stats updated: mean 0.0179 -> 0.0178, std: 0.1398
Collected 234 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6973, Q2 Loss=0.6973, Entropy=0.0013, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6345
SAC Update 2/5: Actor Loss=-0.0022, Q1 Loss=0.7872, Q2 Loss=0.7872, Entropy=0.2464, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5444
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8462, Q2 Loss=0.8462, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2560
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0418, Q2 Loss=1.0418, Entropy=0.0091, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1384
SAC Update 5/5: Actor Loss=-0.0021, Q1 Loss=1.5195, Q2 Loss=1.5195, Entropy=0.3399, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9273

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.5%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000844
Q1 loss: 0.978397
Q2 loss: 0.978397
Current threshold: -149.3820
Global Scale Offset: 14.7272
Reward stats: mean=0.0178, std=0.1398, count=234
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.9784, Q2 Loss: 0.9784, Entropy: 0.1193, Mean TD Error: 1.3001, Threshold: -149.3820
Original likelihood: -134.0462188720703
Adjusted likelihood: -134.0462188720703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8306)
Current yaw: tensor([0.0509, 0.0303, 0.0699], device='cuda:1')
7 turn
Sampling time 5.125467002973892
tensor([ 0.0473,  0.5619,  0.5222,  0.6178, -0.1256,  0.5197,  0.8474,  0.9152,
         1.3322,  0.2946,  0.2351,  1.0909,  0.0509,  0.0303,  0.0699, -3.1649],
       device='cuda:1')
Original likelihood: -135.40011596679688
Adjusted likelihood: -135.40011596679688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8084)
Solve time for step 1 14.97739845799515
Current ori: tensor([0.0509, 0.0303, 0.0699], device='cuda:1')
Middle force: tensor([0.7012, 0.6427, 0.5650, 0.6052, 1.4664, 0.5079, 0.4925, 0.5074, 0.5328,
        0.6086, 0.5976, 0.6719], device='cuda:1')
Thumb force: tensor([1.5573, 0.5376, 1.3169, 2.9863, 1.1961, 0.5081, 0.7117, 0.5323, 0.5789,
        0.6158, 0.6005, 1.1253], device='cuda:1')
Index force: tensor([0.5093, 0.5286, 0.7408, 0.7282, 0.6066, 0.7081, 0.7368, 0.6063, 0.6535,
        0.6116, 0.6041, 0.7201], device='cuda:1')
Storing NORMAL transition: reward=-0.0010 (scaled=-0.0010), steps=1
Reward stats updated: mean 0.0178 -> 0.0177, std: 0.1395
Collected 235 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.6045, Q2 Loss=0.6045, Entropy=0.1752, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0405
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=1.0379, Q2 Loss=1.0379, Entropy=0.1517, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8071
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0117, Q2 Loss=1.0117, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8113
SAC Update 4/5: Actor Loss=-0.0042, Q1 Loss=0.7033, Q2 Loss=0.7033, Entropy=0.3604, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7092
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9852, Q2 Loss=0.9852, Entropy=0.0005, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7643

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.1%)
Q1 update: 0.07s (19.2%)
Q2 update: 0.07s (18.7%)
Actor update: 0.14s (38.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001036
Q1 loss: 0.868524
Q2 loss: 0.868524
Current threshold: -149.3726
Global Scale Offset: 16.0355
Reward stats: mean=0.0177, std=0.1395, count=235
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 0.8685, Q2 Loss: 0.8685, Entropy: 0.1375, Mean TD Error: 0.8265, Threshold: -149.3726
tensor([-3.2562e-03,  4.6078e-01,  6.4987e-01,  6.3807e-01, -8.2447e-02,
         6.5575e-01,  8.9636e-01,  1.0203e+00,  1.4947e+00,  1.9381e-01,
         6.0499e-03,  9.9638e-01,  7.9178e-02, -6.7337e-02,  6.3875e-02,
        -4.1204e+00], device='cuda:1')
Original likelihood: -258.26116943359375
Adjusted likelihood: -258.26116943359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -25.8294,  -25.9284,  -26.3679,  -26.4293,  -26.8998,  -29.4309,
         -30.2890,  -30.3338,  -30.4040,  -34.8499,  -39.5524,  -83.1325,
         -99.5452, -102.4460, -117.3858, -198.5343], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -25.8294,  -25.9284,  -26.3679,  -26.4293,  -26.8998,  -29.4309,
         -30.2890,  -30.3338,  -30.4040,  -34.8499,  -39.5524,  -83.1325,
         -99.5452, -102.4460, -117.3858, -198.5343], device='cuda:1',
       grad_fn=<IndexBackward0>)
Final projection likelihood: -57.9599
1 mode projection succeeded
New goal: tensor([ 0.0237,  0.4923,  0.5898,  0.6466, -0.0858,  0.4884,  0.8757,  0.9630,
         1.2548,  0.3501,  0.2307,  1.1326,  0.0158,  0.0079,  0.6729],
       device='cuda:1')
tensor([[0.0053]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -207.29190063476562
Adjusted likelihood: -207.29190063476562
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 207.29190063476562}
Current yaw: tensor([ 0.0792, -0.0673,  0.0639], device='cuda:1')
8 thumb_middle
tensor([-3.2562e-03,  4.6078e-01,  6.4987e-01,  6.3807e-01, -8.2447e-02,
         6.5575e-01,  8.9636e-01,  1.0203e+00,  1.4947e+00,  1.9381e-01,
         6.0499e-03,  9.9638e-01,  7.9178e-02, -6.7337e-02,  6.3875e-02,
        -4.1204e+00], device='cuda:1')
Solve time for step 1 10.06040205201134
Current ori: tensor([ 0.0792, -0.0673,  0.0639], device='cuda:1')
Index force: tensor([0.5900, 0.5741, 0.6242, 0.6033], device='cuda:1')
tensor([-0.0439,  0.5158,  0.6453,  0.6837, -0.1096,  0.5196,  0.8761,  0.9690,
         1.2568,  0.3146,  0.0957,  1.0595,  0.2032, -0.1768,  0.0639, -2.8819],
       device='cuda:1')
Solve time for step 2 3.8490239349775948
Current ori: tensor([ 0.2032, -0.1768,  0.0639], device='cuda:1')
Index force: tensor([0.5719, 0.6059, 0.5942], device='cuda:1')
tensor([-0.0205,  0.5729,  0.7792,  0.7877, -0.0696,  0.5317,  0.9164,  0.9796,
         1.2263,  0.3397,  0.1081,  1.0736,  0.3846, -0.3613,  0.1449, -1.5121],
       device='cuda:1')
Solve time for step 3 3.773129246023018
Current ori: tensor([ 0.3846, -0.3613,  0.1449], device='cuda:1')
Index force: tensor([0.5003, 0.5006], device='cuda:1')
tensor([-2.6493e-02,  8.7267e-01,  1.0854e+00,  1.0400e+00, -1.4439e-03,
         6.0197e-01,  9.8061e-01,  9.9454e-01,  1.2122e+00,  3.4876e-01,
         1.2262e-01,  1.0998e+00,  3.8598e-01, -3.6506e-01,  1.5257e-01,
        -1.8217e+00], device='cuda:1')
Solve time for step 4 3.7446380910114385
Current ori: tensor([ 0.3860, -0.3651,  0.1526], device='cuda:1')
Index force: tensor([0.5004], device='cuda:1')
Storing RECOVERY transition: reward=-0.3398 (scaled=-0.3398), steps=1
Reward stats updated: mean 0.0177 -> 0.0162, std: 0.1412
Collected 236 transitions for RL
SAC Update 1/5: Actor Loss=-0.0023, Q1 Loss=0.9798, Q2 Loss=0.9798, Entropy=0.2549, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8397
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7748, Q2 Loss=0.7748, Entropy=0.0010, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3952
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=1.6089, Q2 Loss=1.6089, Entropy=0.0471, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7810
SAC Update 4/5: Actor Loss=-0.0026, Q1 Loss=1.7521, Q2 Loss=1.7521, Entropy=0.3389, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0332
SAC Update 5/5: Actor Loss=-0.0035, Q1 Loss=0.8953, Q2 Loss=0.8953, Entropy=0.4360, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7724

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (22.3%)
Q1 update: 0.06s (19.2%)
Q2 update: 0.06s (18.0%)
Actor update: 0.12s (37.2%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001704
Q1 loss: 1.202183
Q2 loss: 1.202183
Current threshold: -149.3640
Global Scale Offset: 17.4903
Reward stats: mean=0.0162, std=0.1412, count=236
----------------------------------------------
SAC Update - Actor Loss: -0.0017, Q1 Loss: 1.2022, Q2 Loss: 1.2022, Entropy: 0.2156, Mean TD Error: 1.7643, Threshold: -149.3640
Original likelihood: -1214.653076171875
Adjusted likelihood: -1214.653076171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 17
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 5.244118750968482
tensor([ 6.5686e-02,  5.5047e-01,  5.8206e-01,  5.7742e-01, -1.4111e-01,
         5.7078e-01,  8.9392e-01,  8.6086e-01,  1.2448e+00,  2.6782e-01,
         2.5778e-01,  1.1740e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:1')
Original likelihood: -93.03269958496094
Adjusted likelihood: -93.03269958496094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9986)
Solve time for step 1 15.766137397964485
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([0.6786, 0.9878, 0.5320, 0.5649, 0.5129, 0.5430, 1.0448, 0.7684, 0.7919,
        0.5533, 0.5450, 0.7466], device='cuda:1')
Thumb force: tensor([0.8508, 1.1633, 0.5402, 0.9236, 1.0861, 0.5905, 0.5792, 1.4569, 0.7727,
        0.5336, 0.6041, 0.5528], device='cuda:1')
Index force: tensor([0.8465, 0.8927, 0.6780, 0.6398, 0.5703, 0.6605, 0.5647, 0.6030, 0.5533,
        0.5632, 0.6563, 0.5202], device='cuda:1')
Storing NORMAL transition: reward=0.0441 (scaled=0.0441), steps=1
Reward stats updated: mean 0.0162 -> 0.0163, std: 0.1409
Collected 237 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7030, Q2 Loss=0.7030, Entropy=0.0000, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4111
SAC Update 2/5: Actor Loss=-0.0050, Q1 Loss=7.3345, Q2 Loss=7.3345, Entropy=0.3649, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8190
SAC Update 3/5: Actor Loss=-0.0013, Q1 Loss=1.0316, Q2 Loss=1.0316, Entropy=0.2404, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8675
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1808, Q2 Loss=1.1808, Entropy=0.0006, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0042
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.1355, Q2 Loss=1.1355, Entropy=0.0836, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7954

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.0%)
Q1 update: 0.06s (18.8%)
Q2 update: 0.06s (17.1%)
Actor update: 0.13s (37.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001316
Q1 loss: 2.277050
Q2 loss: 2.277050
Current threshold: -149.3617
Global Scale Offset: 19.2140
Reward stats: mean=0.0163, std=0.1409, count=237
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 2.2771, Q2 Loss: 2.2771, Entropy: 0.1379, Mean TD Error: 1.7794, Threshold: -149.3617
tensor([ 0.0555,  0.5694,  0.5933,  0.4868, -0.1133,  0.4242,  0.8818,  0.8858,
         1.3424,  0.2549,  0.1534,  1.1613, -0.0130,  0.0195, -0.0734,  0.2507],
       device='cuda:1')
Original likelihood: -109.37648010253906
Adjusted likelihood: -109.37648010253906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.9742)
State is out of distribution
Final likelihood: tensor([-2.8257, -2.8356, -2.9446, -3.1157, -3.4943, -3.7234, -3.8584, -4.0006,
        -4.2575, -5.1193, -5.1553, -5.2765, -5.3428, -6.5250, -6.5686, -7.5448],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8257, -2.8356, -2.9446, -3.1157, -3.4943, -3.7234, -3.8584, -4.0006,
        -4.2575, -5.1193, -5.1553, -5.2765, -5.3428, -6.5250, -6.5686, -7.5448],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.5368
1 mode projection succeeded
New goal: tensor([ 0.0240,  0.5073,  0.5885,  0.6046, -0.0598,  0.4574,  0.9023,  0.8533,
         1.2523,  0.2914,  0.2462,  1.1665,  0.0041,  0.0161, -0.7511],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0082]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -85.17852783203125
Adjusted likelihood: -85.17852783203125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 85.17852783203125}
Current yaw: tensor([-0.0130,  0.0195, -0.0734], device='cuda:1')
2 thumb_middle
tensor([ 0.0555,  0.5694,  0.5933,  0.4868, -0.1133,  0.4242,  0.8818,  0.8858,
         1.3424,  0.2549,  0.1534,  1.1613, -0.0130,  0.0195, -0.0734,  0.2507],
       device='cuda:1')
Solve time for step 1 10.000137144990731
Current ori: tensor([-0.0130,  0.0195, -0.0734], device='cuda:1')
Index force: tensor([0.5875, 0.5901, 0.5856, 0.5932], device='cuda:1')
tensor([ 0.0511,  0.5340,  0.5860,  0.5879, -0.1614,  0.4143,  0.8808,  0.8411,
         1.2413,  0.2583,  0.1562,  1.1245,  0.0035,  0.0235, -0.0734,  0.2821],
       device='cuda:1')
Solve time for step 2 3.911314480996225
Current ori: tensor([ 0.0035,  0.0235, -0.0734], device='cuda:1')
Index force: tensor([0.5743, 0.5730, 0.5810], device='cuda:1')
tensor([ 0.0376,  0.5269,  0.5831,  0.5886, -0.1754,  0.4387,  0.8550,  0.8260,
         1.2186,  0.2731,  0.1761,  1.1469,  0.0053,  0.0310, -0.0734,  0.2659],
       device='cuda:1')
Solve time for step 3 3.6751147800241597
Current ori: tensor([ 0.0053,  0.0310, -0.0734], device='cuda:1')
Index force: tensor([0.5606, 0.5698], device='cuda:1')
tensor([ 0.0410,  0.5340,  0.5781,  0.5853, -0.1666,  0.4216,  0.8688,  0.8344,
         1.2220,  0.2726,  0.1666,  1.1468,  0.0034,  0.0290, -0.0734,  0.2683],
       device='cuda:1')
Solve time for step 4 3.715586373989936
Current ori: tensor([ 0.0034,  0.0290, -0.0734], device='cuda:1')
Index force: tensor([0.5549], device='cuda:1')
Storing RECOVERY transition: reward=0.0001 (scaled=0.0001), steps=1
Reward stats updated: mean 0.0163 -> 0.0162, std: 0.1406
Collected 238 transitions for RL
SAC Update 1/5: Actor Loss=-0.0026, Q1 Loss=1.3770, Q2 Loss=1.3770, Entropy=0.4351, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4836
SAC Update 2/5: Actor Loss=-0.0037, Q1 Loss=0.8694, Q2 Loss=0.8694, Entropy=0.3635, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4931
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.6937, Q2 Loss=1.6937, Entropy=0.0146, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7549
SAC Update 4/5: Actor Loss=-0.0034, Q1 Loss=1.6471, Q2 Loss=1.6471, Entropy=0.3110, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7412
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.6054, Q2 Loss=1.6054, Entropy=0.2919, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1815

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.7%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (17.4%)
Actor update: 0.13s (37.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002164
Q1 loss: 1.438504
Q2 loss: 1.438504
Current threshold: -149.3583
Global Scale Offset: 21.4972
Reward stats: mean=0.0162, std=0.1406, count=238
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 1.4385, Q2 Loss: 1.4385, Entropy: 0.2832, Mean TD Error: 1.3308, Threshold: -149.3583
Original likelihood: -98.7613525390625
Adjusted likelihood: -98.7613525390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9867)
Current yaw: tensor([ 0.0108,  0.0322, -0.0741], device='cuda:1')
3 turn
Sampling time 5.027070849959273
tensor([ 0.0357,  0.5151,  0.5820,  0.6194, -0.1118,  0.4690,  0.9104,  0.8511,
         1.2931,  0.3012,  0.2235,  1.1697,  0.0108,  0.0322, -0.0741,  0.2712],
       device='cuda:1')
Original likelihood: -100.0089111328125
Adjusted likelihood: -100.0089111328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9847)
Solve time for step 1 15.116892427031416
Current ori: tensor([ 0.0108,  0.0322, -0.0741], device='cuda:1')
Middle force: tensor([0.7325, 0.7248, 0.5459, 0.5900, 0.7025, 0.5602, 0.5304, 0.6095, 0.5317,
        0.5726, 0.5771, 0.5266], device='cuda:1')
Thumb force: tensor([0.5980, 0.6774, 0.7942, 0.5184, 0.6062, 0.5584, 0.5204, 0.6200, 0.5798,
        0.6234, 1.3630, 0.5966], device='cuda:1')
Index force: tensor([0.6459, 0.6069, 0.5347, 0.5716, 0.6016, 0.6015, 0.8212, 0.6110, 0.5704,
        0.5542, 0.5573, 0.5185], device='cuda:1')
Storing NORMAL transition: reward=-0.0087 (scaled=-0.0087), steps=1
Reward stats updated: mean 0.0162 -> 0.0161, std: 0.1403
Collected 239 transitions for RL
SAC Update 1/5: Actor Loss=-0.0057, Q1 Loss=0.7559, Q2 Loss=0.7559, Entropy=0.2014, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4616
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9617, Q2 Loss=0.9617, Entropy=0.0177, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6340
SAC Update 3/5: Actor Loss=-0.0064, Q1 Loss=0.6030, Q2 Loss=0.6030, Entropy=0.3504, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3583
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.7776, Q2 Loss=0.7776, Entropy=0.3602, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8599
SAC Update 5/5: Actor Loss=-0.0020, Q1 Loss=1.1672, Q2 Loss=1.1672, Entropy=0.2789, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5180

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (24.7%)
Q1 update: 0.05s (17.8%)
Q2 update: 0.05s (17.4%)
Actor update: 0.11s (36.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002938
Q1 loss: 0.853075
Q2 loss: 0.853075
Current threshold: -149.3571
Global Scale Offset: 23.0152
Reward stats: mean=0.0161, std=0.1403, count=239
----------------------------------------------
SAC Update - Actor Loss: -0.0029, Q1 Loss: 0.8531, Q2 Loss: 0.8531, Entropy: 0.2417, Mean TD Error: 0.7664, Threshold: -149.3571
tensor([ 0.1150,  0.5486,  0.6043,  0.5943, -0.1482,  0.3664,  0.9242,  0.8965,
         1.2835,  0.2498,  0.3321,  1.1714,  0.0286,  0.0724, -0.0700, -0.0489],
       device='cuda:1')
Original likelihood: -248.3182373046875
Adjusted likelihood: -248.3182373046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Final likelihood: tensor([ -4.1787,  -5.5243,  -5.5395,  -5.6710,  -5.7330,  -6.0004,  -6.1686,
         -6.5058,  -6.7574,  -7.6011,  -8.1828,  -8.2579,  -8.4414,  -8.4692,
        -10.1203, -14.7860], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.1787,  -5.5243,  -5.5395,  -5.6710,  -5.7330,  -6.0004,  -6.1686,
         -6.5058,  -6.7574,  -7.6011,  -8.1828,  -8.2579,  -8.4414,  -8.4692,
        -10.1203, -14.7860], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.3711
1 mode projection succeeded
New goal: tensor([ 0.0700,  0.5312,  0.5550,  0.6917, -0.0703,  0.4980,  0.8362,  0.9231,
         1.2545,  0.3457,  0.2299,  1.1465,  0.0063,  0.0150, -0.2704],
       device='cuda:1')
tensor([[0.0039]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0034]], device='cuda:1')
Original likelihood: -135.6965789794922
Adjusted likelihood: -135.6965789794922
Likelihood residual: 0.0
Original likelihood: -199.49465942382812
Adjusted likelihood: -199.49465942382812
Likelihood residual: 0.0
{'index': 199.49465942382812, 'thumb_middle': 135.6965789794922}
Current yaw: tensor([ 0.0286,  0.0724, -0.0700], device='cuda:1')
4 thumb_middle
tensor([ 0.1150,  0.5486,  0.6043,  0.5943, -0.1482,  0.3664,  0.9242,  0.8965,
         1.2835,  0.2498,  0.3321,  1.1714,  0.0286,  0.0724, -0.0700, -0.0489],
       device='cuda:1')
Solve time for step 1 9.80222941498505
Current ori: tensor([ 0.0286,  0.0724, -0.0700], device='cuda:1')
Index force: tensor([0.6092, 0.5018, 0.5553, 0.5894], device='cuda:1')
tensor([ 0.1360,  0.5242,  0.5936,  0.7354, -0.2192,  0.4241,  0.8038,  0.8880,
         1.2484,  0.3182,  0.2068,  1.1352,  0.0414,  0.0690, -0.0699,  0.0142],
       device='cuda:1')
Solve time for step 2 3.848752935009543
Current ori: tensor([ 0.0414,  0.0690, -0.0699], device='cuda:1')
Index force: tensor([0.5014, 0.5525, 0.5861], device='cuda:1')
tensor([ 0.1352,  0.5333,  0.5809,  0.7334, -0.2282,  0.4361,  0.7881,  0.8886,
         1.2581,  0.3365,  0.1938,  1.1332,  0.0412,  0.0681, -0.0699, -0.0209],
       device='cuda:1')
Solve time for step 3 3.8368006980163045
Current ori: tensor([ 0.0412,  0.0681, -0.0699], device='cuda:1')
Index force: tensor([0.5506, 0.5831], device='cuda:1')
tensor([ 0.1446,  0.5611,  0.5726,  0.6960, -0.2183,  0.4430,  0.7864,  0.8909,
         1.2515,  0.3373,  0.1811,  1.1298,  0.0340,  0.0588, -0.0699, -0.0496],
       device='cuda:1')
Solve time for step 4 3.705226735037286
Current ori: tensor([ 0.0340,  0.0588, -0.0699], device='cuda:1')
Index force: tensor([0.5706], device='cuda:1')
Storing RECOVERY transition: reward=-0.0002 (scaled=-0.0002), steps=1
Reward stats updated: mean 0.0161 -> 0.0160, std: 0.1400
Collected 240 transitions for RL
SAC Update 1/5: Actor Loss=-0.0031, Q1 Loss=0.7312, Q2 Loss=0.7312, Entropy=0.5569, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4413
SAC Update 2/5: Actor Loss=-0.0012, Q1 Loss=0.9133, Q2 Loss=0.9133, Entropy=0.3574, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2036
SAC Update 3/5: Actor Loss=-0.0025, Q1 Loss=1.2526, Q2 Loss=1.2526, Entropy=0.3530, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8401
SAC Update 4/5: Actor Loss=-0.0018, Q1 Loss=0.7887, Q2 Loss=0.7887, Entropy=0.3379, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4343
SAC Update 5/5: Actor Loss=-0.0019, Q1 Loss=1.6724, Q2 Loss=1.6724, Entropy=0.2352, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7214

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (23.7%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (17.9%)
Actor update: 0.12s (36.2%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002090
Q1 loss: 1.071655
Q2 loss: 1.071655
Current threshold: -149.3578
Global Scale Offset: 25.4979
Reward stats: mean=0.0160, std=0.1400, count=240
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 1.0717, Q2 Loss: 1.0717, Entropy: 0.3681, Mean TD Error: 0.9281, Threshold: -149.3578
Original likelihood: -183.82504272460938
Adjusted likelihood: -183.82504272460938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0996)
State is out of distribution
Final likelihood: tensor([ -3.2866,  -4.1826,  -4.3155,  -4.8238,  -5.1293,  -5.1978,  -5.6420,
         -5.7712,  -5.9243,  -5.9494,  -6.2743,  -6.5313,  -6.5522,  -6.6601,
         -7.5167, -11.4120], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.2866,  -4.1826,  -4.3155,  -4.8238,  -5.1293,  -5.1978,  -5.6420,
         -5.7712,  -5.9243,  -5.9494,  -6.2743,  -6.5313,  -6.5522,  -6.6601,
         -7.5167, -11.4120], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.9481
1 mode projection succeeded
New goal: tensor([ 0.0904,  0.5437,  0.6043,  0.5988, -0.0739,  0.5123,  0.8125,  0.9466,
         1.2755,  0.2936,  0.2048,  1.1898,  0.0061,  0.0145, -1.7726],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -128.294677734375
Adjusted likelihood: -128.294677734375
Likelihood residual: 0.0
Original likelihood: -93.01466369628906
Adjusted likelihood: -93.01466369628906
Likelihood residual: 0.0
{'index': 93.01466369628906, 'thumb_middle': 128.294677734375}
Current yaw: tensor([ 0.0360,  0.0518, -0.0678], device='cuda:1')
5 index
tensor([ 0.1448,  0.5699,  0.5635,  0.6932, -0.1417,  0.4919,  0.8259,  0.9153,
         1.3070,  0.3585,  0.2328,  1.1581,  0.0360,  0.0518, -0.0678, -0.0907],
       device='cuda:1')
Solve time for step 1 11.432551242003683
Current ori: tensor([ 0.0360,  0.0518, -0.0678], device='cuda:1')
Middle force: tensor([0.5979, 0.5313, 0.5730, 0.5418], device='cuda:1')
Thumb force: tensor([0.5578, 0.5809, 0.5542, 0.5905], device='cuda:1')
tensor([ 0.1380,  0.4919,  0.5508,  0.5945, -0.1280,  0.5130,  0.8093,  0.9306,
         1.3420,  0.3146,  0.1802,  1.1698,  0.0282,  0.0409, -0.0985,  2.3401],
       device='cuda:1')
Solve time for step 2 4.813246637000702
Current ori: tensor([ 0.0282,  0.0409, -0.0985], device='cuda:1')
Middle force: tensor([0.5301, 0.5690, 0.5387], device='cuda:1')
Thumb force: tensor([0.5733, 0.5506, 0.5855], device='cuda:1')
tensor([ 0.1316,  0.4881,  0.5545,  0.5794, -0.1075,  0.5232,  0.8088,  0.9376,
         1.3275,  0.3271,  0.1631,  1.1865,  0.0267,  0.0274, -0.1088,  3.7395],
       device='cuda:1')
Solve time for step 3 4.6326347499853
Current ori: tensor([ 0.0267,  0.0274, -0.1088], device='cuda:1')
Middle force: tensor([0.5918, 0.5763], device='cuda:1')
Thumb force: tensor([0.5537, 0.5617], device='cuda:1')
tensor([ 0.1314,  0.4884,  0.5545,  0.5766, -0.1005,  0.5322,  0.8037,  0.9340,
         1.3247,  0.3286,  0.1560,  1.1897,  0.0243,  0.0230, -0.1083,  4.7206],
       device='cuda:1')
Solve time for step 4 4.27648278902052
Current ori: tensor([ 0.0243,  0.0230, -0.1083], device='cuda:1')
Middle force: tensor([0.5297], device='cuda:1')
Thumb force: tensor([0.5689], device='cuda:1')
Storing RECOVERY transition: reward=0.0454 (scaled=0.0454), steps=1
Reward stats updated: mean 0.0160 -> 0.0162, std: 0.1397
Collected 241 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=1.1103, Q2 Loss=1.1103, Entropy=0.0580, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0255
SAC Update 2/5: Actor Loss=-0.0050, Q1 Loss=1.2864, Q2 Loss=1.2864, Entropy=0.4962, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9457
SAC Update 3/5: Actor Loss=-0.0022, Q1 Loss=0.7077, Q2 Loss=0.7077, Entropy=0.2901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2321
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=1.1578, Q2 Loss=1.1578, Entropy=0.2022, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7658
SAC Update 5/5: Actor Loss=-0.0012, Q1 Loss=0.8372, Q2 Loss=0.8372, Entropy=0.1961, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2358

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.09s (22.2%)
Q1 update: 0.07s (19.3%)
Q2 update: 0.07s (17.6%)
Actor update: 0.14s (37.1%)
Target update: 0.01s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001981
Q1 loss: 1.019861
Q2 loss: 1.019861
Current threshold: -149.3557
Global Scale Offset: 28.7437
Reward stats: mean=0.0162, std=0.1397, count=241
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 1.0199, Q2 Loss: 1.0199, Entropy: 0.2485, Mean TD Error: 1.2410, Threshold: -149.3557
Original likelihood: -88.06288146972656
Adjusted likelihood: -88.06288146972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9791)
Current yaw: tensor([ 0.0176,  0.0204, -0.1104], device='cuda:1')
6 turn
Sampling time 5.278297585027758
tensor([ 0.0856,  0.5466,  0.5960,  0.5958, -0.1009,  0.5565,  0.7932,  0.9119,
         1.3325,  0.3210,  0.1460,  1.1796,  0.0176,  0.0204, -0.1104,  4.9724],
       device='cuda:1')
Original likelihood: -82.80438995361328
Adjusted likelihood: -82.80438995361328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9865)
Solve time for step 1 15.397055100009311
Current ori: tensor([ 0.0176,  0.0204, -0.1104], device='cuda:1')
Middle force: tensor([0.5121, 0.6956, 0.5420, 0.5046, 0.7857, 1.0929, 0.5887, 0.5725, 0.5292,
        0.5719, 0.8529, 0.5536], device='cuda:1')
Thumb force: tensor([0.8551, 0.6493, 1.5446, 2.4084, 0.8782, 1.7113, 0.5912, 0.6797, 0.5437,
        1.5876, 0.5466, 0.8795], device='cuda:1')
Index force: tensor([0.5024, 0.8875, 0.5942, 0.5953, 0.5819, 0.5841, 0.5918, 0.5369, 0.4911,
        0.8098, 0.5488, 0.6262], device='cuda:1')
Storing NORMAL transition: reward=-0.0334 (scaled=-0.0334), steps=1
Reward stats updated: mean 0.0162 -> 0.0160, std: 0.1395
Collected 242 transitions for RL
SAC Update 1/5: Actor Loss=-0.0063, Q1 Loss=1.0235, Q2 Loss=1.0235, Entropy=0.6318, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6996
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=0.9574, Q2 Loss=0.9574, Entropy=0.2078, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6959
SAC Update 3/5: Actor Loss=-0.0023, Q1 Loss=0.9972, Q2 Loss=0.9972, Entropy=0.3516, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6242
SAC Update 4/5: Actor Loss=-0.0061, Q1 Loss=2.3152, Q2 Loss=2.3152, Entropy=0.3942, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6719
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.8416, Q2 Loss=0.8416, Entropy=0.6293, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1904

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.5%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (17.2%)
Actor update: 0.13s (38.3%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004930
Q1 loss: 1.226988
Q2 loss: 1.226988
Current threshold: -149.3514
Global Scale Offset: 32.8545
Reward stats: mean=0.0160, std=0.1395, count=242
----------------------------------------------
SAC Update - Actor Loss: -0.0049, Q1 Loss: 1.2270, Q2 Loss: 1.2270, Entropy: 0.4430, Mean TD Error: 0.7764, Threshold: -149.3514
tensor([ 0.1386,  0.5681,  0.6299,  0.5785, -0.0750,  0.6491,  0.7594,  0.8548,
         1.2605,  0.4264,  0.1435,  1.1896,  0.0121, -0.0095, -0.0766,  4.9839],
       device='cuda:1')
Original likelihood: -130.15538024902344
Adjusted likelihood: -130.15538024902344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7126)
State is out of distribution
Final likelihood: tensor([-3.1128, -3.1301, -3.3820, -3.3857, -3.5464, -3.6104, -3.7305, -3.9882,
        -4.2475, -4.2751, -4.4298, -4.6277, -4.6713, -5.2495, -5.5220, -5.7072],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.1128, -3.1301, -3.3820, -3.3857, -3.5464, -3.6104, -3.7305, -3.9882,
        -4.2475, -4.2751, -4.4298, -4.6277, -4.6713, -5.2495, -5.5220, -5.7072],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.1635
1 mode projection succeeded
New goal: tensor([ 0.0674,  0.5616,  0.5713,  0.5687, -0.0819,  0.5288,  0.8429,  0.8683,
         1.2489,  0.3602,  0.2041,  1.1970,  0.0043,  0.0135, -0.6701],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -75.10063934326172
Adjusted likelihood: -75.10063934326172
Likelihood residual: 0.0
Original likelihood: -119.78350830078125
Adjusted likelihood: -119.78350830078125
Likelihood residual: 0.0
{'index': 119.78350830078125, 'thumb_middle': 75.10063934326172}
Current yaw: tensor([ 0.0121, -0.0095, -0.0766], device='cuda:1')
7 thumb_middle
tensor([ 0.1386,  0.5681,  0.6299,  0.5785, -0.0750,  0.6491,  0.7594,  0.8548,
         1.2605,  0.4264,  0.1435,  1.1896,  0.0121, -0.0095, -0.0766,  4.9839],
       device='cuda:1')
Solve time for step 1 9.50044870498823
Current ori: tensor([ 0.0121, -0.0095, -0.0766], device='cuda:1')
Index force: tensor([0.5519, 0.5713, 0.5863, 0.5836], device='cuda:1')
tensor([ 0.0807,  0.5769,  0.5692,  0.5579, -0.1786,  0.5166,  0.7903,  0.8363,
         1.2148,  0.3420,  0.1322,  1.1729,  0.0075,  0.0220, -0.0765,  4.9146],
       device='cuda:1')
Solve time for step 2 3.8279202369740233
Current ori: tensor([ 0.0075,  0.0220, -0.0765], device='cuda:1')
Index force: tensor([0.5602, 0.5735, 0.5717], device='cuda:1')
tensor([ 0.0852,  0.5732,  0.5716,  0.5715, -0.1935,  0.5201,  0.8122,  0.8427,
         1.2195,  0.3393,  0.1213,  1.1698,  0.0094,  0.0199, -0.0765,  4.9239],
       device='cuda:1')
Solve time for step 3 3.429074998944998
Current ori: tensor([ 0.0094,  0.0199, -0.0765], device='cuda:1')
Index force: tensor([0.5587, 0.5583], device='cuda:1')
tensor([ 0.0909,  0.5720,  0.5739,  0.5813, -0.1849,  0.5121,  0.8178,  0.8430,
         1.2059,  0.3455,  0.1359,  1.1587,  0.0105,  0.0169, -0.0765,  4.9336],
       device='cuda:1')
Solve time for step 4 3.7284854050376453
Current ori: tensor([ 0.0105,  0.0169, -0.0765], device='cuda:1')
Index force: tensor([0.5889], device='cuda:1')
Storing RECOVERY transition: reward=0.0152 (scaled=0.0152), steps=1
Reward stats updated: mean 0.0160 -> 0.0159, std: 0.1392
Collected 243 transitions for RL
SAC Update 1/5: Actor Loss=-0.0034, Q1 Loss=1.2222, Q2 Loss=1.2222, Entropy=0.3694, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9656
SAC Update 2/5: Actor Loss=-0.0014, Q1 Loss=1.2339, Q2 Loss=1.2339, Entropy=0.2635, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0086
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.7102, Q2 Loss=0.7102, Entropy=0.1466, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4500
SAC Update 4/5: Actor Loss=-0.0036, Q1 Loss=0.7382, Q2 Loss=0.7382, Entropy=0.5943, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5973
SAC Update 5/5: Actor Loss=-0.0016, Q1 Loss=3.0496, Q2 Loss=3.0496, Entropy=0.3102, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0824

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.6%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.4%)
Actor update: 0.15s (37.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002149
Q1 loss: 1.390815
Q2 loss: 1.390815
Current threshold: -149.3477
Global Scale Offset: 37.4165
Reward stats: mean=0.0159, std=0.1392, count=243
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 1.3908, Q2 Loss: 1.3908, Entropy: 0.3368, Mean TD Error: 1.6208, Threshold: -149.3477
Original likelihood: -70.46180725097656
Adjusted likelihood: -70.46180725097656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9790)
Current yaw: tensor([ 0.0039,  0.0247, -0.0921], device='cuda:1')
8 turn
Sampling time 5.224102003034204
tensor([ 6.8841e-02,  5.9081e-01,  5.4896e-01,  5.3781e-01, -1.2679e-01,
         5.5125e-01,  8.4560e-01,  8.6414e-01,  1.2795e+00,  3.6404e-01,
         1.8907e-01,  1.1921e+00,  3.8537e-03,  2.4740e-02, -9.2141e-02,
         4.9330e+00], device='cuda:1')
Original likelihood: -68.68150329589844
Adjusted likelihood: -68.68150329589844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9812)
Solve time for step 1 15.695686666993424
Current ori: tensor([ 0.0039,  0.0247, -0.0921], device='cuda:1')
Middle force: tensor([1.2853, 0.5074, 0.4992, 0.5255, 0.5930, 0.6079, 1.0678, 0.8031, 0.5031,
        0.5753, 0.5088, 0.8317], device='cuda:1')
Thumb force: tensor([1.9098, 1.9335, 1.4187, 0.5800, 1.0977, 0.7747, 1.4503, 0.5825, 0.5472,
        0.5727, 0.5591, 0.9159], device='cuda:1')
Index force: tensor([0.5712, 0.8525, 0.8573, 0.6512, 0.5757, 0.5613, 0.5904, 0.5251, 0.5228,
        0.5819, 0.6074, 0.5676], device='cuda:1')
Storing NORMAL transition: reward=0.1646 (scaled=0.1646), steps=1
Reward stats updated: mean 0.0159 -> 0.0166, std: 0.1392
Collected 244 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=0.9755, Q2 Loss=0.9755, Entropy=0.2275, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2159
SAC Update 2/5: Actor Loss=-0.0034, Q1 Loss=2.0855, Q2 Loss=2.0855, Entropy=0.4917, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4464
SAC Update 3/5: Actor Loss=-0.0019, Q1 Loss=16.1515, Q2 Loss=16.1515, Entropy=0.3087, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7896
SAC Update 4/5: Actor Loss=-0.0065, Q1 Loss=1.4886, Q2 Loss=1.4886, Entropy=0.6641, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9194
SAC Update 5/5: Actor Loss=-0.0028, Q1 Loss=1.3511, Q2 Loss=1.3511, Entropy=0.5268, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1184

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (21.5%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.06s (17.8%)
Actor update: 0.14s (39.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003198
Q1 loss: 4.410430
Q2 loss: 4.410430
Current threshold: -149.3439
Global Scale Offset: 43.2242
Reward stats: mean=0.0166, std=0.1392, count=244
----------------------------------------------
SAC Update - Actor Loss: -0.0032, Q1 Loss: 4.4104, Q2 Loss: 4.4104, Entropy: 0.4438, Mean TD Error: 2.4979, Threshold: -149.3439
tensor([ 0.0872,  0.5574,  0.5263,  0.7067, -0.1438,  0.4136,  1.0068,  1.0150,
         1.3611,  0.2541,  0.1869,  1.0872,  0.0251,  0.0208, -0.2577,  5.1613],
       device='cuda:1')
Original likelihood: -123.20315551757812
Adjusted likelihood: -123.20315551757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7211)
Solve time for step 2 6.043282625032589
Current ori: tensor([ 0.0251,  0.0208, -0.2577], device='cuda:1')
Middle force: tensor([0.5070, 0.5007, 0.5219, 0.5923, 0.6092, 1.0420, 0.7893, 0.5029, 0.5719,
        0.5081, 0.8307], device='cuda:1')
Thumb force: tensor([1.8769, 1.3789, 0.5798, 1.0699, 0.7592, 1.4178, 0.5825, 0.5412, 0.5695,
        0.5547, 0.8956], device='cuda:1')
Index force: tensor([0.8355, 0.8332, 0.6526, 0.5731, 0.5571, 0.5862, 0.5234, 0.5211, 0.5787,
        0.6081, 0.5644], device='cuda:1')
Storing NORMAL transition: reward=0.0350 (scaled=0.0350), steps=1
Reward stats updated: mean 0.0166 -> 0.0166, std: 0.1390
Collected 245 transitions for RL
SAC Update 1/5: Actor Loss=-0.0047, Q1 Loss=0.9459, Q2 Loss=0.9459, Entropy=0.4582, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7854
SAC Update 2/5: Actor Loss=-0.0065, Q1 Loss=0.8265, Q2 Loss=0.8265, Entropy=0.5186, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6006
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.7380, Q2 Loss=0.7380, Entropy=0.2467, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4030
SAC Update 4/5: Actor Loss=-0.0048, Q1 Loss=0.8045, Q2 Loss=0.8045, Entropy=0.6196, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5159
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=1.4046, Q2 Loss=1.4046, Entropy=0.6103, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9327

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (20.6%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.07s (18.8%)
Actor update: 0.15s (38.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004861
Q1 loss: 0.943891
Q2 loss: 0.943891
Current threshold: -149.3406
Global Scale Offset: 49.6804
Reward stats: mean=0.0166, std=0.1390, count=245
----------------------------------------------
SAC Update - Actor Loss: -0.0049, Q1 Loss: 0.9439, Q2 Loss: 0.9439, Entropy: 0.4907, Mean TD Error: 0.6475, Threshold: -149.3406
tensor([ 0.1076,  0.5779,  0.5294,  0.6851, -0.1247,  0.4470,  0.9539,  1.0698,
         1.3517,  0.2967,  0.1671,  1.0708,  0.0187,  0.0090, -0.2918,  5.2073],
       device='cuda:1')
Original likelihood: -102.79340362548828
Adjusted likelihood: -102.79340362548828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8190)
Solve time for step 3 5.709106669004541
Current ori: tensor([ 0.0187,  0.0090, -0.2918], device='cuda:1')
Middle force: tensor([0.5009, 0.5152, 0.5859, 0.6021, 0.9903, 0.7647, 0.5414, 0.5163, 0.5943,
        0.5849], device='cuda:1')
Thumb force: tensor([1.3301, 0.5722, 1.0324, 0.7407, 1.3366, 0.5762, 0.5397, 0.5654, 0.6177,
        0.5250], device='cuda:1')
Index force: tensor([0.7828, 0.6390, 0.5604, 0.5473, 0.5760, 0.5233, 0.5605, 0.5303, 0.5757,
        0.5755], device='cuda:1')
Storing NORMAL transition: reward=-0.0316 (scaled=-0.0316), steps=1
Reward stats updated: mean 0.0166 -> 0.0164, std: 0.1387
Collected 246 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=0.8846, Q2 Loss=0.8846, Entropy=0.3646, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6386
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.7108, Q2 Loss=0.7108, Entropy=0.1193, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6808
SAC Update 3/5: Actor Loss=-0.0137, Q1 Loss=1.1124, Q2 Loss=1.1124, Entropy=0.6923, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1836
SAC Update 4/5: Actor Loss=-0.0064, Q1 Loss=0.9413, Q2 Loss=0.9413, Entropy=0.5228, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9100
SAC Update 5/5: Actor Loss=-0.0049, Q1 Loss=0.9211, Q2 Loss=0.9211, Entropy=0.6368, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2000

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.8%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.4%)
Actor update: 0.13s (37.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005270
Q1 loss: 0.914047
Q2 loss: 0.914047
Current threshold: -149.3358
Global Scale Offset: 56.2066
Reward stats: mean=0.0164, std=0.1387, count=246
----------------------------------------------
SAC Update - Actor Loss: -0.0053, Q1 Loss: 0.9140, Q2 Loss: 0.9140, Entropy: 0.4671, Mean TD Error: 0.7226, Threshold: -149.3358
tensor([ 0.1108,  0.5469,  0.6133,  0.6104, -0.0847,  0.5387,  0.8304,  1.1750,
         1.3056,  0.5168,  0.2523,  0.7925,  0.0163, -0.0212, -0.2606,  5.6950],
       device='cuda:1')
Original likelihood: -149.73997497558594
Adjusted likelihood: -149.73997497558594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4972)
Solve time for step 4 5.417106690001674
Current ori: tensor([ 0.0163, -0.0212, -0.2606], device='cuda:1')
Middle force: tensor([0.5080, 0.5637, 0.5897, 0.8358, 0.7062, 0.7220, 0.5765, 0.5194, 0.5633],
       device='cuda:1')
Thumb force: tensor([0.5485, 0.8986, 0.6649, 1.1529, 0.5561, 0.6278, 0.6172, 0.5762, 0.5512],
       device='cuda:1')
Index force: tensor([0.6252, 0.5464, 0.5316, 0.5542, 0.5119, 0.5457, 0.5463, 0.5062, 0.5724],
       device='cuda:1')
Storing NORMAL transition: reward=0.0199 (scaled=0.0199), steps=1
Reward stats updated: mean 0.0164 -> 0.0165, std: 0.1384
Collected 247 transitions for RL
SAC Update 1/5: Actor Loss=-0.0049, Q1 Loss=0.9585, Q2 Loss=0.9585, Entropy=0.6446, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6623
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=0.8282, Q2 Loss=0.8282, Entropy=0.6738, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6012
SAC Update 3/5: Actor Loss=-0.0048, Q1 Loss=0.8281, Q2 Loss=0.8281, Entropy=0.6666, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8895
SAC Update 4/5: Actor Loss=-0.0017, Q1 Loss=0.5901, Q2 Loss=0.5901, Entropy=0.5297, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4380
SAC Update 5/5: Actor Loss=-0.0055, Q1 Loss=2.2723, Q2 Loss=2.2723, Entropy=0.5686, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9658

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.8%)
Q1 update: 0.06s (18.5%)
Q2 update: 0.06s (18.1%)
Actor update: 0.13s (38.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005121
Q1 loss: 1.095461
Q2 loss: 1.095461
Current threshold: -149.3327
Global Scale Offset: 62.8942
Reward stats: mean=0.0165, std=0.1384, count=247
----------------------------------------------
SAC Update - Actor Loss: -0.0051, Q1 Loss: 1.0955, Q2 Loss: 1.0955, Entropy: 0.6166, Mean TD Error: 1.7114, Threshold: -149.3327
tensor([ 1.4523e-01,  5.8594e-01,  6.2524e-01,  5.3036e-01, -1.2345e-01,
         4.5384e-01,  8.9220e-01,  1.2407e+00,  1.3881e+00,  4.0686e-01,
         2.3705e-01,  8.6994e-01,  5.4063e-02,  1.1669e-03, -2.8388e-01,
        -5.9500e+00], device='cuda:1')
Original likelihood: -157.20445251464844
Adjusted likelihood: -157.20445251464844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4513)
State is out of distribution
Final likelihood: tensor([ -4.4061,  -4.7663,  -5.6577,  -5.7262,  -6.0073,  -6.1554,  -6.4839,
         -6.6887,  -6.7328,  -6.7565,  -6.9460,  -7.4131,  -8.4996,  -8.8002,
        -10.1793, -10.2791], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.4061,  -4.7663,  -5.6577,  -5.7262,  -6.0073,  -6.1554,  -6.4839,
         -6.6887,  -6.7328,  -6.7565,  -6.9460,  -7.4131,  -8.4996,  -8.8002,
        -10.1793, -10.2791], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.9686
1 mode projection succeeded
New goal: tensor([ 0.0709,  0.5818,  0.5515,  0.5596, -0.0666,  0.4682,  0.8957,  0.8741,
         1.2559,  0.3109,  0.2590,  1.1106,  0.0042,  0.0141,  0.1851],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -122.27238464355469
Adjusted likelihood: -122.27238464355469
Likelihood residual: 0.0
Original likelihood: -165.25234985351562
Adjusted likelihood: -165.25234985351562
Likelihood residual: 0.0
{'index': 165.25234985351562, 'thumb_middle': 122.27238464355469}
Current yaw: tensor([ 0.0541,  0.0012, -0.2839], device='cuda:1')
9 thumb_middle
tensor([ 1.4523e-01,  5.8594e-01,  6.2524e-01,  5.3036e-01, -1.2345e-01,
         4.5384e-01,  8.9220e-01,  1.2407e+00,  1.3881e+00,  4.0686e-01,
         2.3705e-01,  8.6994e-01,  5.4063e-02,  1.1669e-03, -2.8388e-01,
        -5.9500e+00], device='cuda:1')
Solve time for step 1 9.999740724975709
Current ori: tensor([ 0.0541,  0.0012, -0.2839], device='cuda:1')
Index force: tensor([0.5827, 0.5990, 0.5002, 0.5818], device='cuda:1')
tensor([ 1.4591e-01,  6.4335e-01,  5.5015e-01,  5.2801e-01, -1.4869e-01,
         4.5345e-01,  8.6631e-01,  9.2974e-01,  1.2271e+00,  3.1010e-01,
         1.7753e-01,  1.0378e+00,  4.1515e-02, -2.8307e-03, -2.8386e-01,
        -5.9608e+00], device='cuda:1')
Solve time for step 2 3.7709859589813277
Current ori: tensor([ 0.0415, -0.0028, -0.2839], device='cuda:1')
Index force: tensor([0.5906, 0.5001, 0.5782], device='cuda:1')
tensor([ 1.3529e-01,  6.2228e-01,  5.4419e-01,  5.7320e-01, -1.5995e-01,
         4.5657e-01,  8.6323e-01,  8.6897e-01,  1.2233e+00,  2.9884e-01,
         1.8340e-01,  1.0704e+00,  4.9082e-02,  5.3961e-03, -2.8386e-01,
        -5.9557e+00], device='cuda:1')
Solve time for step 3 3.926198059984017
Current ori: tensor([ 0.0491,  0.0054, -0.2839], device='cuda:1')
Index force: tensor([0.5836, 0.5930], device='cuda:1')
tensor([ 0.1047,  0.6044,  0.5464,  0.5557, -0.1780,  0.4493,  0.8534,  0.8512,
         1.2290,  0.2966,  0.1938,  1.0846,  0.0516,  0.0208, -0.2839, -6.0030],
       device='cuda:1')
Solve time for step 4 3.826770937012043
Current ori: tensor([ 0.0516,  0.0208, -0.2839], device='cuda:1')
Index force: tensor([0.5825], device='cuda:1')
Storing RECOVERY transition: reward=0.0050 (scaled=0.0012), steps=4
Reward stats updated: mean 0.0165 -> 0.0164, std: 0.1381
Collected 248 transitions for RL
SAC Update 1/5: Actor Loss=-0.0027, Q1 Loss=0.7028, Q2 Loss=0.7028, Entropy=0.5316, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4862
SAC Update 2/5: Actor Loss=-0.0047, Q1 Loss=0.9519, Q2 Loss=0.9519, Entropy=0.5681, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7447
SAC Update 3/5: Actor Loss=-0.0013, Q1 Loss=0.9727, Q2 Loss=0.9727, Entropy=0.2485, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3158
SAC Update 4/5: Actor Loss=-0.0020, Q1 Loss=1.6823, Q2 Loss=1.6823, Entropy=0.3888, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6828
SAC Update 5/5: Actor Loss=-0.0041, Q1 Loss=0.9028, Q2 Loss=0.9028, Entropy=0.5317, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8962

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.4%)
Q1 update: 0.07s (18.4%)
Q2 update: 0.06s (18.0%)
Actor update: 0.13s (38.0%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002961
Q1 loss: 1.042514
Q2 loss: 1.042514
Current threshold: -149.3305
Global Scale Offset: 70.9119
Reward stats: mean=0.0164, std=0.1381, count=248
----------------------------------------------
SAC Update - Actor Loss: -0.0030, Q1 Loss: 1.0425, Q2 Loss: 1.0425, Entropy: 0.4537, Mean TD Error: 0.8251, Threshold: -149.3305
Original likelihood: -130.9493408203125
Adjusted likelihood: -130.9493408203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6003)
Current yaw: tensor([ 0.0487,  0.0233, -0.2889], device='cuda:1')
10 turn
Sampling time 5.264793128008023
tensor([ 0.0970,  0.6160,  0.5283,  0.5448, -0.1074,  0.4931,  0.8970,  0.8702,
         1.2889,  0.3184,  0.2493,  1.1166,  0.0487,  0.0233, -0.2889, -6.0313],
       device='cuda:1')
Original likelihood: -113.84393310546875
Adjusted likelihood: -113.84393310546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6882)
Solve time for step 1 15.004258339991793
Current ori: tensor([ 0.0487,  0.0233, -0.2889], device='cuda:1')
Middle force: tensor([0.7304, 0.9643, 0.5370, 0.5185, 0.9580, 0.8534, 0.5657, 0.5834, 0.5373,
        0.6380, 0.5132, 0.5193], device='cuda:1')
Thumb force: tensor([0.9113, 1.2031, 1.0734, 0.9105, 0.6790, 0.5250, 0.6079, 1.2264, 0.5947,
        1.1024, 0.5662, 0.5185], device='cuda:1')
Index force: tensor([1.2523, 1.4794, 0.5306, 0.5412, 0.5448, 0.5687, 0.5602, 0.6039, 0.6900,
        0.5960, 0.6395, 0.5523], device='cuda:1')
Storing NORMAL transition: reward=-0.0550 (scaled=-0.0550), steps=1
Reward stats updated: mean 0.0164 -> 0.0161, std: 0.1379
Collected 249 transitions for RL
SAC Update 1/5: Actor Loss=-0.0048, Q1 Loss=0.7929, Q2 Loss=0.7929, Entropy=0.6245, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5285
SAC Update 2/5: Actor Loss=-0.0065, Q1 Loss=0.7454, Q2 Loss=0.7454, Entropy=0.5459, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6327
SAC Update 3/5: Actor Loss=-0.0035, Q1 Loss=0.7408, Q2 Loss=0.7408, Entropy=0.5989, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6291
SAC Update 4/5: Actor Loss=-0.0054, Q1 Loss=0.9600, Q2 Loss=0.9600, Entropy=0.6640, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6906
SAC Update 5/5: Actor Loss=-0.0052, Q1 Loss=0.6668, Q2 Loss=0.6668, Entropy=0.6508, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7014

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (19.5%)
Q1 update: 0.06s (18.2%)
Q2 update: 0.06s (19.5%)
Actor update: 0.13s (39.5%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005098
Q1 loss: 0.781169
Q2 loss: 0.781169
Current threshold: -149.3272
Global Scale Offset: 80.2198
Reward stats: mean=0.0161, std=0.1379, count=249
----------------------------------------------
SAC Update - Actor Loss: -0.0051, Q1 Loss: 0.7812, Q2 Loss: 0.7812, Entropy: 0.6168, Mean TD Error: 0.6365, Threshold: -149.3272
tensor([ 0.1105,  0.7120,  0.4625,  0.4204, -0.0786,  0.5341,  0.9305,  0.6921,
         1.2293,  0.3504,  0.2940,  1.0647,  0.0201,  0.0092, -0.2316, -6.1228],
       device='cuda:1')
Original likelihood: -113.89754486083984
Adjusted likelihood: -113.89754486083984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6679)
Solve time for step 2 5.773913097043987
Current ori: tensor([ 0.0201,  0.0092, -0.2316], device='cuda:1')
Middle force: tensor([0.5265, 0.5516, 0.5019, 0.5310, 0.8448, 1.4234, 0.6162, 0.5458, 0.5000,
        0.6228, 0.5177], device='cuda:1')
Thumb force: tensor([1.6839, 0.9955, 0.5632, 0.5746, 1.2202, 0.9679, 0.5974, 0.6138, 0.6526,
        0.5564, 1.1646], device='cuda:1')
Index force: tensor([0.6556, 0.5835, 0.8183, 0.5881, 1.1617, 0.7523, 0.5977, 0.6158, 1.0980,
        0.5737, 0.5239], device='cuda:1')
Storing NORMAL transition: reward=0.0854 (scaled=0.0854), steps=1
Reward stats updated: mean 0.0161 -> 0.0164, std: 0.1377
Collected 250 transitions for RL
SAC Update 1/5: Actor Loss=-0.0045, Q1 Loss=0.6310, Q2 Loss=0.6310, Entropy=0.6484, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1860
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=1.1496, Q2 Loss=1.1496, Entropy=0.6912, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0351
SAC Update 3/5: Actor Loss=-0.0045, Q1 Loss=0.7932, Q2 Loss=0.7932, Entropy=0.5987, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2801
SAC Update 4/5: Actor Loss=-0.0056, Q1 Loss=0.7249, Q2 Loss=0.7249, Entropy=0.6572, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5998
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.8639, Q2 Loss=0.8639, Entropy=0.6478, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3063

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.0%)
Q1 update: 0.08s (20.0%)
Q2 update: 0.07s (17.9%)
Actor update: 0.15s (38.9%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005893
Q1 loss: 0.832529
Q2 loss: 0.832529
Current threshold: -149.3243
Global Scale Offset: 89.9221
Reward stats: mean=0.0164, std=0.1377, count=250
----------------------------------------------
SAC Update - Actor Loss: -0.0059, Q1 Loss: 0.8325, Q2 Loss: 0.8325, Entropy: 0.6486, Mean TD Error: 0.6815, Threshold: -149.3243
tensor([ 1.3267e-01,  7.3505e-01,  4.3444e-01,  4.6445e-01, -4.1090e-02,
         5.1071e-01,  8.8131e-01,  8.0732e-01,  1.3361e+00,  2.7810e-01,
         2.3733e-01,  9.5077e-01,  1.7645e-02, -2.5044e-03, -3.1689e-01,
        -5.9111e+00], device='cuda:1')
Original likelihood: -153.8839111328125
Adjusted likelihood: -153.8839111328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4801)
Solve time for step 3 5.949383567029145
Current ori: tensor([ 0.0176, -0.0025, -0.3169], device='cuda:1')
Middle force: tensor([0.5506, 0.5005, 0.5285, 0.8027, 1.3847, 0.6074, 0.5457, 0.5003, 0.6167,
        0.5171], device='cuda:1')
Thumb force: tensor([0.9741, 0.5782, 0.5703, 1.2304, 0.9648, 0.5969, 0.6041, 0.6474, 0.5539,
        1.1479], device='cuda:1')
Index force: tensor([0.5754, 0.8487, 0.5843, 1.1487, 0.7430, 0.5939, 0.6122, 1.0948, 0.5726,
        0.5225], device='cuda:1')
Storing NORMAL transition: reward=0.1188 (scaled=0.1188), steps=1
Reward stats updated: mean 0.0164 -> 0.0168, std: 0.1376
Collected 251 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=1.5078, Q2 Loss=1.5078, Entropy=0.5536, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2538
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.3474, Q2 Loss=1.3474, Entropy=0.6449, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8915
SAC Update 3/5: Actor Loss=-0.0031, Q1 Loss=0.7142, Q2 Loss=0.7142, Entropy=0.5456, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4131
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.8041, Q2 Loss=0.8041, Entropy=0.6790, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4689
SAC Update 5/5: Actor Loss=-0.0030, Q1 Loss=0.7419, Q2 Loss=0.7419, Entropy=0.5682, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6986

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (19.5%)
Q1 update: 0.08s (20.4%)
Q2 update: 0.07s (19.5%)
Actor update: 0.14s (37.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005922
Q1 loss: 1.023062
Q2 loss: 1.023062
Current threshold: -149.3202
Global Scale Offset: 101.4256
Reward stats: mean=0.0168, std=0.1376, count=251
----------------------------------------------
SAC Update - Actor Loss: -0.0059, Q1 Loss: 1.0231, Q2 Loss: 1.0231, Entropy: 0.5983, Mean TD Error: 0.7452, Threshold: -149.3202
tensor([ 0.1466,  0.6693,  0.4553,  0.5129,  0.0185,  0.5292,  0.8760,  0.8698,
         1.3674,  0.3672,  0.1575,  0.9079,  0.0082, -0.0397, -0.4376,  6.1117],
       device='cuda:1')
Original likelihood: -182.33834838867188
Adjusted likelihood: -182.33834838867188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3741)
State is out of distribution
Final likelihood: tensor([ -2.7767,  -2.8702,  -3.2471,  -3.3416,  -3.5606,  -4.7468,  -4.7622,
         -4.9344,  -4.9735,  -5.4739,  -6.0306,  -6.0476,  -6.1432,  -6.6335,
         -8.1846, -10.4556], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.7767,  -2.8702,  -3.2471,  -3.3416,  -3.5606,  -4.7468,  -4.7622,
         -4.9344,  -4.9735,  -5.4739,  -6.0306,  -6.0476,  -6.1432,  -6.6335,
         -8.1846, -10.4556], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2614
1 mode projection succeeded
New goal: tensor([ 0.0546,  0.5619,  0.5920,  0.5036, -0.0852,  0.5142,  0.8674,  0.8711,
         1.2634,  0.3205,  0.2391,  1.1212,  0.0036,  0.0138, -0.1549],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0062]], device='cuda:1')
Original likelihood: -172.005126953125
Adjusted likelihood: -172.005126953125
Likelihood residual: 0.0
{'index': 172.005126953125, 'thumb_middle': inf}
Current yaw: tensor([ 0.0082, -0.0397, -0.4376], device='cuda:1')
11 index
tensor([ 0.1466,  0.6693,  0.4553,  0.5129,  0.0185,  0.5292,  0.8760,  0.8698,
         1.3674,  0.3672,  0.1575,  0.9079,  0.0082, -0.0397, -0.4376,  6.1117],
       device='cuda:1')
Solve time for step 1 11.728346595948096
Current ori: tensor([ 0.0082, -0.0397, -0.4376], device='cuda:1')
Middle force: tensor([0.5029, 0.5757, 0.5158, 0.5616], device='cuda:1')
Thumb force: tensor([0.5192, 0.5766, 0.6479, 0.5909], device='cuda:1')
tensor([ 0.1296,  0.5259,  0.5193,  0.4820,  0.0288,  0.5331,  0.8839,  0.8816,
         1.3656,  0.3567,  0.1296,  0.9617,  0.0183, -0.0487, -0.4299,  5.4898],
       device='cuda:1')
Solve time for step 2 4.552406516973861
Current ori: tensor([ 0.0183, -0.0487, -0.4299], device='cuda:1')
Middle force: tensor([0.5682, 0.5138, 0.5574], device='cuda:1')
Thumb force: tensor([0.5760, 0.6464, 0.5885], device='cuda:1')
tensor([ 0.1224,  0.5120,  0.5356,  0.4790,  0.0314,  0.5273,  0.8928,  0.8876,
         1.3638,  0.3569,  0.1242,  0.9771,  0.0222, -0.0505, -0.4295,  4.8696],
       device='cuda:1')
Solve time for step 3 4.393351933045778
Current ori: tensor([ 0.0222, -0.0505, -0.4295], device='cuda:1')
Middle force: tensor([0.5000, 0.5772], device='cuda:1')
Thumb force: tensor([0.5135, 0.5666], device='cuda:1')
tensor([ 0.1202,  0.5076,  0.5401,  0.4784,  0.0374,  0.5299,  0.9008,  0.8980,
         1.3605,  0.3585,  0.1130,  0.9987,  0.0276, -0.0567, -0.4412,  4.3572],
       device='cuda:1')
Solve time for step 4 4.311303663009312
Current ori: tensor([ 0.0276, -0.0567, -0.4412], device='cuda:1')
Middle force: tensor([0.5557], device='cuda:1')
Thumb force: tensor([0.5633], device='cuda:1')
Storing RECOVERY transition: reward=-0.0041 (scaled=-0.0014), steps=3
Reward stats updated: mean 0.0168 -> 0.0167, std: 0.1373
Collected 252 transitions for RL
SAC Update 1/5: Actor Loss=-0.0051, Q1 Loss=2.2795, Q2 Loss=2.2795, Entropy=0.5782, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5415
SAC Update 2/5: Actor Loss=-0.0058, Q1 Loss=0.7867, Q2 Loss=0.7867, Entropy=0.6604, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7527
SAC Update 3/5: Actor Loss=-0.0051, Q1 Loss=1.0708, Q2 Loss=1.0708, Entropy=0.6364, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8092
SAC Update 4/5: Actor Loss=-0.0065, Q1 Loss=0.6179, Q2 Loss=0.6179, Entropy=0.6618, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5732
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.9179, Q2 Loss=0.9179, Entropy=0.6760, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8487

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.4%)
Q1 update: 0.07s (18.9%)
Q2 update: 0.07s (18.8%)
Actor update: 0.13s (37.5%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.005936
Q1 loss: 1.134538
Q2 loss: 1.134538
Current threshold: -149.3172
Global Scale Offset: 113.7681
Reward stats: mean=0.0167, std=0.1373, count=252
----------------------------------------------
SAC Update - Actor Loss: -0.0059, Q1 Loss: 1.1345, Q2 Loss: 1.1345, Entropy: 0.6426, Mean TD Error: 1.9051, Threshold: -149.3172
Original likelihood: -168.9019012451172
Adjusted likelihood: -168.9019012451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4325)
Current yaw: tensor([ 0.0303, -0.0555, -0.4365], device='cuda:1')
12 turn
Sampling time 5.250144458026625
tensor([ 0.0676,  0.5666,  0.5859,  0.4994,  0.0254,  0.5345,  0.9054,  0.9016,
         1.3556,  0.3656,  0.1175,  1.0033,  0.0303, -0.0555, -0.4365,  4.2355],
       device='cuda:1')
Original likelihood: -173.42662048339844
Adjusted likelihood: -173.42662048339844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4171)
Solve time for step 1 15.002623622014653
Current ori: tensor([ 0.0303, -0.0555, -0.4365], device='cuda:1')
Middle force: tensor([0.8266, 2.2605, 0.5516, 1.2945, 0.6590, 1.0381, 0.5337, 0.8841, 0.5354,
        0.7539, 0.7849, 0.6200], device='cuda:1')
Thumb force: tensor([0.7421, 0.9941, 1.5533, 0.5218, 0.5442, 0.6518, 0.5144, 0.6014, 1.1555,
        0.5589, 0.5524, 0.5719], device='cuda:1')
Index force: tensor([0.5739, 1.6983, 0.6462, 0.7056, 0.6505, 0.7001, 0.5920, 0.7621, 0.5282,
        0.7476, 0.5229, 0.5932], device='cuda:1')
Storing NORMAL transition: reward=0.0464 (scaled=0.0464), steps=1
Reward stats updated: mean 0.0167 -> 0.0168, std: 0.1371
Collected 253 transitions for RL
SAC Update 1/5: Actor Loss=-0.0037, Q1 Loss=0.5845, Q2 Loss=0.5845, Entropy=0.6390, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1728
SAC Update 2/5: Actor Loss=-0.0033, Q1 Loss=7.5237, Q2 Loss=7.5237, Entropy=0.5416, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0694
SAC Update 3/5: Actor Loss=-0.0054, Q1 Loss=1.2286, Q2 Loss=1.2286, Entropy=0.5675, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5945
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=1.2627, Q2 Loss=1.2627, Entropy=0.6287, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7002
SAC Update 5/5: Actor Loss=-0.0061, Q1 Loss=0.6612, Q2 Loss=0.6612, Entropy=0.6767, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3059

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.4%)
Target Q: 0.08s (20.1%)
Q1 update: 0.07s (18.5%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (39.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005225
Q1 loss: 2.252160
Q2 loss: 2.252160
Current threshold: -149.3152
Global Scale Offset: 127.2077
Reward stats: mean=0.0168, std=0.1371, count=253
----------------------------------------------
SAC Update - Actor Loss: -0.0052, Q1 Loss: 2.2522, Q2 Loss: 2.2522, Entropy: 0.6107, Mean TD Error: 1.7686, Threshold: -149.3152
tensor([-4.5963e-02,  6.0592e-01,  5.9170e-01,  4.6308e-01,  1.6522e-01,
         4.2139e-01,  9.1216e-01,  9.4475e-01,  1.3507e+00,  4.7247e-01,
        -3.4567e-03,  1.1566e+00,  6.4041e-02, -1.0601e-01, -4.9527e-01,
         5.4367e+00], device='cuda:1')
Original likelihood: -290.11419677734375
Adjusted likelihood: -290.11419677734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1368)
State is out of distribution
Final likelihood: tensor([-31.3785, -34.9996, -36.7709, -37.6600, -39.0329, -39.5795, -42.0378,
        -42.0903, -45.9508, -46.6383, -47.6409, -48.1244, -52.4022, -58.3020,
        -85.1348, -87.1009], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-31.3785, -34.9996, -36.7709, -37.6600, -39.0329, -39.5795, -42.0378,
        -42.0903, -45.9508, -46.6383, -47.6409, -48.1244, -52.4022, -58.3020,
        -85.1348, -87.1009], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -48.4277
1 mode projection succeeded
New goal: tensor([ 0.0260,  0.5135,  0.5283,  0.7159, -0.0074,  0.5463,  0.6661,  1.0339,
         1.2360,  0.4225,  0.3349,  0.8861,  0.0176, -0.0035, -0.2495],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0079]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -280.40655517578125
Adjusted likelihood: -280.40655517578125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 280.40655517578125}
Current yaw: tensor([ 0.0640, -0.1060, -0.4953], device='cuda:1')
13 thumb_middle
tensor([-4.5963e-02,  6.0592e-01,  5.9170e-01,  4.6308e-01,  1.6522e-01,
         4.2139e-01,  9.1216e-01,  9.4475e-01,  1.3507e+00,  4.7247e-01,
        -3.4567e-03,  1.1566e+00,  6.4041e-02, -1.0601e-01, -4.9527e-01,
         5.4367e+00], device='cuda:1')
Solve time for step 1 9.682734005036764
Current ori: tensor([ 0.0640, -0.1060, -0.4953], device='cuda:1')
Index force: tensor([0.5013, 0.5965, 0.5770, 0.5995], device='cuda:1')
tensor([-0.0378,  0.6643,  0.5306,  0.5809,  0.0374,  0.6090,  0.7090,  0.9894,
         1.1919,  0.4258,  0.1655,  0.8776,  0.1596, -0.2650, -0.4953,  5.3212],
       device='cuda:1')
Solve time for step 2 3.883167162013706
Current ori: tensor([ 0.1596, -0.2650, -0.4953], device='cuda:1')
Index force: tensor([0.6517, 0.6427, 0.5047], device='cuda:1')
tensor([-0.0904,  0.8070,  0.6750,  0.8171,  0.0553,  0.6581,  0.7022,  1.0148,
         1.1804,  0.4295,  0.2038,  0.8449,  0.2539, -0.3895, -0.5721,  4.3925],
       device='cuda:1')
Solve time for step 3 3.751777491008397
Current ori: tensor([ 0.2539, -0.3895, -0.5721], device='cuda:1')
Index force: tensor([0.5709, 0.5818], device='cuda:1')
tensor([-0.0757,  1.0266,  0.7765,  0.7403,  0.0826,  0.7099,  0.7632,  1.0728,
         1.1375,  0.3894,  0.2246,  0.8524,  0.3005, -0.3935, -0.7174,  4.3743],
       device='cuda:1')
Solve time for step 4 3.497708972019609
Current ori: tensor([ 0.3005, -0.3935, -0.7174], device='cuda:1')
Index force: tensor([0.5836], device='cuda:1')
Storing RECOVERY transition: reward=-0.1182 (scaled=-0.1182), steps=1
Reward stats updated: mean 0.0168 -> 0.0163, std: 0.1371
Collected 254 transitions for RL
SAC Update 1/5: Actor Loss=-0.0069, Q1 Loss=0.8053, Q2 Loss=0.8053, Entropy=0.6772, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5774
SAC Update 2/5: Actor Loss=-0.0057, Q1 Loss=0.9675, Q2 Loss=0.9675, Entropy=0.5118, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2797
SAC Update 3/5: Actor Loss=-0.0060, Q1 Loss=0.8726, Q2 Loss=0.8726, Entropy=0.6816, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6573
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=1.0097, Q2 Loss=1.0097, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1524
SAC Update 5/5: Actor Loss=-0.0057, Q1 Loss=0.9104, Q2 Loss=0.9104, Entropy=0.5569, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0454

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (20.4%)
Q1 update: 0.06s (18.4%)
Q2 update: 0.06s (18.4%)
Actor update: 0.12s (39.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007262
Q1 loss: 0.913102
Q2 loss: 0.913102
Current threshold: -149.3137
Global Scale Offset: 141.2449
Reward stats: mean=0.0163, std=0.1371, count=254
----------------------------------------------
SAC Update - Actor Loss: -0.0073, Q1 Loss: 0.9131, Q2 Loss: 0.9131, Entropy: 0.6241, Mean TD Error: 0.7424, Threshold: -149.3137
Original likelihood: -1245.3779296875
Adjusted likelihood: -1245.3779296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 18
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 5.323294772009831
tensor([ 1.0822e-01,  5.8954e-01,  5.5602e-01,  6.0394e-01, -1.2662e-01,
         5.2754e-01,  9.3417e-01,  8.7718e-01,  1.1978e+00,  3.5146e-01,
         2.4887e-01,  1.2247e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:1')
Original likelihood: -104.17555236816406
Adjusted likelihood: -104.17555236816406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6242)
Solve time for step 1 15.02721399901202
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([0.6991, 0.7110, 0.5350, 0.5234, 0.6485, 1.0080, 1.0028, 0.5889, 0.5018,
        0.5056, 0.5970, 0.6211], device='cuda:1')
Thumb force: tensor([0.5538, 2.3747, 0.6371, 1.5578, 1.0618, 0.9065, 1.9701, 0.5943, 0.7108,
        0.6029, 0.5850, 0.6091], device='cuda:1')
Index force: tensor([0.5897, 0.5011, 0.6131, 0.5631, 0.5779, 0.5244, 0.5823, 0.6240, 0.7098,
        0.7605, 0.6091, 0.6184], device='cuda:1')
Storing NORMAL transition: reward=0.0248 (scaled=0.0248), steps=1
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.1368
Collected 255 transitions for RL
SAC Update 1/5: Actor Loss=-0.0060, Q1 Loss=0.6414, Q2 Loss=0.6414, Entropy=0.6719, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2482
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=1.1853, Q2 Loss=1.1853, Entropy=0.6411, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8201
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=1.3190, Q2 Loss=1.3190, Entropy=0.6397, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7701
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=1.2712, Q2 Loss=1.2712, Entropy=0.6925, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8263
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.9780, Q2 Loss=0.9780, Entropy=0.6509, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3810

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.4%)
Q1 update: 0.06s (18.9%)
Q2 update: 0.06s (18.6%)
Actor update: 0.13s (38.7%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008375
Q1 loss: 1.078978
Q2 loss: 1.078978
Current threshold: -149.3118
Global Scale Offset: 156.1028
Reward stats: mean=0.0163, std=0.1368, count=255
----------------------------------------------
SAC Update - Actor Loss: -0.0084, Q1 Loss: 1.0790, Q2 Loss: 1.0790, Entropy: 0.6592, Mean TD Error: 0.6091, Threshold: -149.3118
tensor([ 3.1887e-02,  5.7219e-01,  5.0841e-01,  6.0274e-01, -1.6239e-01,
         5.0323e-01,  8.7076e-01,  8.5937e-01,  1.3907e+00,  2.4448e-01,
         2.4745e-01,  9.5896e-01,  3.1781e-05,  5.4399e-02, -5.6417e-02,
         2.4413e-01], device='cuda:1')
Original likelihood: -181.94065856933594
Adjusted likelihood: -181.94065856933594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4179)
State is out of distribution
Final likelihood: tensor([-2.8344, -3.0855, -3.0870, -3.2453, -4.0279, -4.0790, -4.5150, -4.5290,
        -4.8908, -4.9196, -5.3258, -5.6080, -5.7370, -5.7465, -6.0182, -6.2910],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8344, -3.0855, -3.0870, -3.2453, -4.0279, -4.0790, -4.5150, -4.5290,
        -4.8908, -4.9196, -5.3258, -5.6080, -5.7370, -5.7465, -6.0182, -6.2910],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.6212
1 mode projection succeeded
New goal: tensor([ 0.0389,  0.5450,  0.5381,  0.6262, -0.0738,  0.4897,  0.8537,  0.9135,
         1.2891,  0.2903,  0.2387,  1.0920,  0.0050,  0.0162,  0.3980],
       device='cuda:1')
tensor([[0.0031]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -120.25453186035156
Adjusted likelihood: -120.25453186035156
Likelihood residual: 0.0
Original likelihood: -72.74918365478516
Adjusted likelihood: -72.74918365478516
Likelihood residual: 0.0
{'index': 72.74918365478516, 'thumb_middle': 120.25453186035156}
Current yaw: tensor([ 3.1781e-05,  5.4399e-02, -5.6417e-02], device='cuda:1')
2 index
tensor([ 3.1887e-02,  5.7219e-01,  5.0841e-01,  6.0274e-01, -1.6239e-01,
         5.0323e-01,  8.7076e-01,  8.5937e-01,  1.3907e+00,  2.4448e-01,
         2.4745e-01,  9.5896e-01,  3.1781e-05,  5.4399e-02, -5.6417e-02,
         2.4413e-01], device='cuda:1')
Solve time for step 1 11.553546704992186
Current ori: tensor([ 3.1781e-05,  5.4399e-02, -5.6417e-02], device='cuda:1')
Middle force: tensor([0.5534, 0.5773, 0.5917, 0.5010], device='cuda:1')
Thumb force: tensor([0.6070, 0.5428, 0.6074, 0.5016], device='cuda:1')
tensor([ 0.0754,  0.4931,  0.4854,  0.5997, -0.1542,  0.4984,  0.8802,  0.9303,
         1.3534,  0.2907,  0.2356,  1.0119,  0.0109,  0.0403, -0.0751,  0.5638],
       device='cuda:1')
Solve time for step 2 4.493737103010062
Current ori: tensor([ 0.0109,  0.0403, -0.0751], device='cuda:1')
Middle force: tensor([0.5727, 0.5891, 0.5008], device='cuda:1')
Thumb force: tensor([0.5395, 0.6013, 0.5015], device='cuda:1')
tensor([ 0.0824,  0.4905,  0.4877,  0.6003, -0.1268,  0.5181,  0.8767,  0.9251,
         1.3424,  0.2928,  0.2053,  1.0382,  0.0066,  0.0222, -0.0750,  0.6626],
       device='cuda:1')
Solve time for step 3 4.30103086901363
Current ori: tensor([ 0.0066,  0.0222, -0.0750], device='cuda:1')
Middle force: tensor([0.5841, 0.5005], device='cuda:1')
Thumb force: tensor([0.5933, 0.5011], device='cuda:1')
tensor([ 0.0884,  0.4911,  0.4881,  0.6007, -0.1049,  0.5437,  0.8636,  0.9049,
         1.3531,  0.2682,  0.1716,  1.0435, -0.0033,  0.0088, -0.0806,  0.6800],
       device='cuda:1')
Solve time for step 4 4.1959766750223935
Current ori: tensor([-0.0033,  0.0088, -0.0806], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5003], device='cuda:1')
Storing RECOVERY transition: reward=0.0304 (scaled=0.0304), steps=1
Reward stats updated: mean 0.0163 -> 0.0164, std: 0.1365
Collected 256 transitions for RL
SAC Update 1/5: Actor Loss=-0.0116, Q1 Loss=1.2456, Q2 Loss=1.2456, Entropy=0.6902, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8538
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=16.3496, Q2 Loss=16.3496, Entropy=0.6655, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8486
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=0.9051, Q2 Loss=0.9051, Entropy=0.6871, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4476
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=1.4055, Q2 Loss=1.4055, Entropy=0.6567, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1100
SAC Update 5/5: Actor Loss=-0.0053, Q1 Loss=0.7587, Q2 Loss=0.7587, Entropy=0.6690, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7730

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (20.0%)
Q1 update: 0.06s (18.0%)
Q2 update: 0.06s (18.0%)
Actor update: 0.13s (40.6%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009030
Q1 loss: 4.132904
Q2 loss: 4.132904
Current threshold: -149.3108
Global Scale Offset: 171.9847
Reward stats: mean=0.0164, std=0.1365, count=256
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 4.1329, Q2 Loss: 4.1329, Entropy: 0.6737, Mean TD Error: 1.6066, Threshold: -149.3108
Original likelihood: -46.6265869140625
Adjusted likelihood: -46.6265869140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7231)
Current yaw: tensor([ 0.0044,  0.0077, -0.0840], device='cuda:1')
3 turn
Sampling time 5.272666419041343
tensor([ 0.0373,  0.5485,  0.5330,  0.6239, -0.1049,  0.5297,  0.8769,  0.9255,
         1.3146,  0.3286,  0.1838,  1.0753,  0.0044,  0.0077, -0.0840,  0.6974],
       device='cuda:1')
Original likelihood: -46.4107551574707
Adjusted likelihood: -46.4107551574707
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7236)
State is out of distribution
Final likelihood: tensor([-2.5903, -2.7210, -3.1469, -3.2947, -3.3339, -3.5712, -3.5812, -3.7103,
        -4.2221, -4.4167, -4.6368, -4.6626, -4.7090, -4.7158, -4.7862, -7.4208],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.5903, -2.7210, -3.1469, -3.2947, -3.3339, -3.5712, -3.5812, -3.7103,
        -4.2221, -4.4167, -4.6368, -4.6626, -4.7090, -4.7158, -4.7862, -7.4208],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.0950
1 mode projection succeeded
New goal: tensor([ 0.0386,  0.5446,  0.5380,  0.6276, -0.0732,  0.4891,  0.8544,  0.9138,
         1.2890,  0.2908,  0.2408,  1.0885,  0.0050,  0.0160, -0.0396],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -47.26106262207031
Adjusted likelihood: -47.26106262207031
Likelihood residual: 0.0
Original likelihood: -92.2796630859375
Adjusted likelihood: -92.2796630859375
Likelihood residual: 0.0
{'index': 92.2796630859375, 'thumb_middle': 47.26106262207031}
Current yaw: tensor([ 0.0044,  0.0077, -0.0840], device='cuda:1')
4 thumb_middle
tensor([ 0.0373,  0.5485,  0.5330,  0.6239, -0.1049,  0.5297,  0.8769,  0.9255,
         1.3146,  0.3286,  0.1838,  1.0753,  0.0044,  0.0077, -0.0840,  0.6974],
       device='cuda:1')
Solve time for step 1 9.235758810013067
Current ori: tensor([ 0.0044,  0.0077, -0.0840], device='cuda:1')
Index force: tensor([0.5666, 0.5762, 0.5001, 0.5729], device='cuda:1')
tensor([ 0.0396,  0.5670,  0.5315,  0.5811, -0.1496,  0.4689,  0.8372,  0.8999,
         1.2494,  0.2781,  0.1415,  1.0490, -0.0046,  0.0060, -0.0839,  0.6720],
       device='cuda:1')
Solve time for step 2 3.9695446839905344
Current ori: tensor([-0.0046,  0.0060, -0.0839], device='cuda:1')
Index force: tensor([0.5850, 0.6039, 0.5978], device='cuda:1')
tensor([ 0.0206,  0.5608,  0.5180,  0.5907, -0.1686,  0.4711,  0.8272,  0.8932,
         1.2545,  0.2740,  0.1497,  1.0517, -0.0023,  0.0167, -0.0839,  0.6523],
       device='cuda:1')
Solve time for step 3 3.7619429109618068
Current ori: tensor([-0.0023,  0.0167, -0.0839], device='cuda:1')
Index force: tensor([0.5989, 0.5943], device='cuda:1')
tensor([ 0.0209,  0.5508,  0.5234,  0.6078, -0.1722,  0.4749,  0.8255,  0.8936,
         1.2549,  0.2723,  0.1502,  1.0528,  0.0017,  0.0167, -0.0839,  0.6613],
       device='cuda:1')
Solve time for step 4 3.7663419850287028
Current ori: tensor([ 0.0017,  0.0167, -0.0839], device='cuda:1')
Index force: tensor([0.5387], device='cuda:1')
Storing RECOVERY transition: reward=0.0008 (scaled=0.0008), steps=0
Reward stats updated: mean 0.0164 -> 0.0163, std: 0.1363
Collected 257 transitions for RL
SAC Update 1/5: Actor Loss=-0.0142, Q1 Loss=7.4065, Q2 Loss=7.4065, Entropy=0.6315, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1837
SAC Update 2/5: Actor Loss=-0.0061, Q1 Loss=0.6928, Q2 Loss=0.6928, Entropy=0.6781, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4409
SAC Update 3/5: Actor Loss=-0.0064, Q1 Loss=10.4189, Q2 Loss=10.4189, Entropy=0.6507, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.6660
SAC Update 4/5: Actor Loss=-0.0058, Q1 Loss=0.7687, Q2 Loss=0.7687, Entropy=0.6550, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3165
SAC Update 5/5: Actor Loss=-0.0123, Q1 Loss=1.2242, Q2 Loss=1.2242, Entropy=0.6900, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5372

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.5%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.06s (18.3%)
Actor update: 0.14s (38.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008964
Q1 loss: 4.102238
Q2 loss: 4.102238
Current threshold: -149.3108
Global Scale Offset: 185.6879
Reward stats: mean=0.0163, std=0.1363, count=257
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 4.1022, Q2 Loss: 4.1022, Entropy: 0.6611, Mean TD Error: 2.2289, Threshold: -149.3108
Original likelihood: -58.08826446533203
Adjusted likelihood: -58.08826446533203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6871)
Current yaw: tensor([ 0.0122,  0.0259, -0.0855], device='cuda:1')
5 turn
Sampling time 5.377673607959878
tensor([ 0.0037,  0.5167,  0.5365,  0.6463, -0.1109,  0.5049,  0.8533,  0.9204,
         1.3192,  0.3025,  0.2173,  1.0918,  0.0122,  0.0259, -0.0855,  0.6402],
       device='cuda:1')
Original likelihood: -55.150596618652344
Adjusted likelihood: -55.150596618652344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6926)
Solve time for step 1 15.660313981992658
Current ori: tensor([ 0.0122,  0.0259, -0.0855], device='cuda:1')
Middle force: tensor([1.0867, 0.9956, 1.3732, 0.5032, 1.0117, 0.5812, 0.5479, 0.7337, 0.5759,
        0.5890, 0.5789, 0.5822], device='cuda:1')
Thumb force: tensor([0.8481, 0.7539, 0.7045, 0.5261, 0.5839, 0.5064, 0.9052, 0.7942, 0.5705,
        0.6296, 0.5971, 0.6288], device='cuda:1')
Index force: tensor([0.5761, 1.1686, 0.9471, 0.7465, 0.5607, 0.6910, 0.6206, 0.5515, 0.5669,
        0.6373, 0.5972, 0.6468], device='cuda:1')
Storing NORMAL transition: reward=0.0629 (scaled=0.0629), steps=1
Reward stats updated: mean 0.0163 -> 0.0165, std: 0.1361
Collected 258 transitions for RL
SAC Update 1/5: Actor Loss=-0.0130, Q1 Loss=1.2867, Q2 Loss=1.2867, Entropy=0.6928, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8314
SAC Update 2/5: Actor Loss=-0.0044, Q1 Loss=0.6729, Q2 Loss=0.6729, Entropy=0.6428, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4848
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=1.2835, Q2 Loss=1.2835, Entropy=0.6707, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7697
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=10.2453, Q2 Loss=10.2453, Entropy=0.6786, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.6552
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=0.9682, Q2 Loss=0.9682, Entropy=0.6913, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6234

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (20.7%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.06s (18.2%)
Actor update: 0.13s (38.8%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009200
Q1 loss: 2.891330
Q2 loss: 2.891330
Current threshold: -149.3099
Global Scale Offset: 200.2059
Reward stats: mean=0.0165, std=0.1361, count=258
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 2.8913, Q2 Loss: 2.8913, Entropy: 0.6753, Mean TD Error: 1.8729, Threshold: -149.3099
tensor([-0.0940,  0.4446,  0.5736,  0.6733, -0.0161,  0.4825,  0.9017,  1.0533,
         1.3467,  0.1260,  0.2025,  1.0488,  0.0468, -0.0361, -0.1515,  0.7505],
       device='cuda:1')
Original likelihood: -180.09017944335938
Adjusted likelihood: -180.09017944335938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4393)
State is out of distribution
Final likelihood: tensor([ -4.1285,  -4.1401,  -5.5187,  -6.1127,  -6.1259,  -6.6552,  -6.8026,
         -7.1698,  -7.3445,  -7.5629,  -7.6170,  -7.8507,  -8.3170,  -8.3800,
         -8.7925, -11.2200], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -4.1285,  -4.1401,  -5.5187,  -6.1127,  -6.1259,  -6.6552,  -6.8026,
         -7.1698,  -7.3445,  -7.5629,  -7.6170,  -7.8507,  -8.3170,  -8.3800,
         -8.7925, -11.2200], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -7.1086
1 mode projection succeeded
New goal: tensor([ 0.0389,  0.5437,  0.5383,  0.6287, -0.0724,  0.4894,  0.8535,  0.9157,
         1.2886,  0.2895,  0.2411,  1.0888,  0.0059,  0.0156, -0.8072],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -165.79959106445312
Adjusted likelihood: -165.79959106445312
Likelihood residual: 0.0
Original likelihood: -154.45132446289062
Adjusted likelihood: -154.45132446289062
Likelihood residual: 0.0
{'index': 154.45132446289062, 'thumb_middle': 165.79959106445312}
Current yaw: tensor([ 0.0468, -0.0361, -0.1515], device='cuda:1')
6 index
tensor([-0.0940,  0.4446,  0.5736,  0.6733, -0.0161,  0.4825,  0.9017,  1.0533,
         1.3467,  0.1260,  0.2025,  1.0488,  0.0468, -0.0361, -0.1515,  0.7505],
       device='cuda:1')
Solve time for step 1 11.515291327959858
Current ori: tensor([ 0.0468, -0.0361, -0.1515], device='cuda:1')
Middle force: tensor([0.5842, 0.5758, 0.5521, 0.5662], device='cuda:1')
Thumb force: tensor([0.5103, 0.5523, 0.6085, 0.5685], device='cuda:1')
tensor([ 0.0690,  0.4691,  0.4989,  0.6117, -0.0197,  0.4802,  0.9212,  1.0013,
         1.2725,  0.2471,  0.2549,  1.0054,  0.0407, -0.0327, -0.1403, -0.8003],
       device='cuda:1')
Solve time for step 2 5.063602843962144
Current ori: tensor([ 0.0407, -0.0327, -0.1403], device='cuda:1')
Middle force: tensor([0.5701, 0.5496, 0.5622], device='cuda:1')
Thumb force: tensor([0.5483, 0.6039, 0.5645], device='cuda:1')
tensor([ 0.0912,  0.4875,  0.4921,  0.6055, -0.0238,  0.5049,  0.9034,  0.9630,
         1.2945,  0.2251,  0.2560,  0.9602,  0.0255, -0.0306, -0.1456, -1.9270],
       device='cuda:1')
Solve time for step 3 4.74812975601526
Current ori: tensor([ 0.0255, -0.0306, -0.1456], device='cuda:1')
Middle force: tensor([0.5534, 0.5362], device='cuda:1')
Thumb force: tensor([0.5048, 0.5456], device='cuda:1')
tensor([ 0.0947,  0.4904,  0.4916,  0.6044, -0.0239,  0.5050,  0.9084,  0.9666,
         1.2841,  0.2377,  0.2568,  0.9676,  0.0275, -0.0325, -0.1447, -2.6202],
       device='cuda:1')
Solve time for step 4 4.6635037069791
Current ori: tensor([ 0.0275, -0.0325, -0.1447], device='cuda:1')
Middle force: tensor([0.5539], device='cuda:1')
Thumb force: tensor([0.5688], device='cuda:1')
Storing RECOVERY transition: reward=-0.0064 (scaled=-0.0064), steps=1
Reward stats updated: mean 0.0165 -> 0.0164, std: 0.1358
Collected 259 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=3.4985, Q2 Loss=3.4985, Entropy=0.6496, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8404
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=1.0252, Q2 Loss=1.0252, Entropy=0.6768, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4361
SAC Update 3/5: Actor Loss=-0.0059, Q1 Loss=1.1074, Q2 Loss=1.1074, Entropy=0.6763, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8812
SAC Update 4/5: Actor Loss=-0.0061, Q1 Loss=0.6706, Q2 Loss=0.6706, Entropy=0.6582, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4138
SAC Update 5/5: Actor Loss=-0.0068, Q1 Loss=4.2848, Q2 Loss=4.2848, Entropy=0.6765, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4979

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (20.2%)
Q1 update: 0.07s (17.1%)
Q2 update: 0.06s (15.6%)
Actor update: 0.13s (32.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007110
Q1 loss: 2.117285
Q2 loss: 2.117285
Current threshold: -149.3089
Global Scale Offset: 215.2272
Reward stats: mean=0.0164, std=0.1358, count=259
----------------------------------------------
SAC Update - Actor Loss: -0.0071, Q1 Loss: 2.1173, Q2 Loss: 2.1173, Entropy: 0.6675, Mean TD Error: 3.0139, Threshold: -149.3089
Original likelihood: -112.16802978515625
Adjusted likelihood: -112.16802978515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5681)
State is out of distribution
Final likelihood: tensor([-2.5173, -2.6307, -3.4509, -3.6170, -3.9064, -4.4753, -4.4949, -5.1279,
        -5.2113, -5.4857, -5.5527, -5.6964, -5.8978, -6.9932, -7.0161, -7.1990],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.5173, -2.6307, -3.4509, -3.6170, -3.9064, -4.4753, -4.4949, -5.1279,
        -5.2113, -5.4857, -5.5527, -5.6964, -5.8978, -6.9932, -7.0161, -7.1990],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.9545
1 mode projection succeeded
New goal: tensor([ 0.0167,  0.5557,  0.5516,  0.5273, -0.0542,  0.4768,  0.8807,  0.8557,
         1.2663,  0.2978,  0.2254,  1.1566,  0.0049,  0.0119,  0.0334],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -92.61085510253906
Adjusted likelihood: -92.61085510253906
Likelihood residual: 0.0
Original likelihood: -166.4295196533203
Adjusted likelihood: -166.4295196533203
Likelihood residual: 0.0
{'index': 166.4295196533203, 'thumb_middle': 92.61085510253906}
Current yaw: tensor([ 0.0271, -0.0332, -0.1432], device='cuda:1')
7 thumb_middle
tensor([ 0.0482,  0.5479,  0.5342,  0.6262, -0.0262,  0.5089,  0.9099,  0.9654,
         1.2894,  0.2357,  0.2457,  0.9778,  0.0271, -0.0332, -0.1432, -2.7478],
       device='cuda:1')
Solve time for step 1 9.229507255018689
Current ori: tensor([ 0.0271, -0.0332, -0.1432], device='cuda:1')
Index force: tensor([0.5497, 0.5803, 0.5920, 0.5007], device='cuda:1')
tensor([ 0.0086,  0.5399,  0.5494,  0.5493, -0.1202,  0.4756,  0.8554,  0.8696,
         1.2249,  0.2592,  0.1440,  1.0788,  0.0187, -0.0134, -0.1432, -2.8298],
       device='cuda:1')
Solve time for step 2 3.7343549440265633
Current ori: tensor([ 0.0187, -0.0134, -0.1432], device='cuda:1')
Index force: tensor([0.5717, 0.5852, 0.5000], device='cuda:1')
tensor([ 0.0200,  0.5413,  0.5640,  0.5368, -0.1116,  0.4853,  0.8606,  0.8463,
         1.2002,  0.2798,  0.1313,  1.1061,  0.0174, -0.0194, -0.1432, -2.8194],
       device='cuda:1')
Solve time for step 3 3.5835717549780384
Current ori: tensor([ 0.0174, -0.0194, -0.1432], device='cuda:1')
Index force: tensor([0.6024, 0.6064], device='cuda:1')
tensor([-0.0112,  0.5537,  0.5366,  0.5040, -0.1327,  0.4741,  0.8555,  0.8382,
         1.2175,  0.2799,  0.1320,  1.1164,  0.0101, -0.0037, -0.1432, -2.8600],
       device='cuda:1')
Solve time for step 4 3.3713615090237
Current ori: tensor([ 0.0101, -0.0037, -0.1432], device='cuda:1')
Index force: tensor([0.6009], device='cuda:1')
Storing RECOVERY transition: reward=-0.0080 (scaled=-0.0080), steps=1
Reward stats updated: mean 0.0164 -> 0.0163, std: 0.1355
Collected 260 transitions for RL
SAC Update 1/5: Actor Loss=-0.0054, Q1 Loss=0.7247, Q2 Loss=0.7247, Entropy=0.6623, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4657
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=0.8801, Q2 Loss=0.8801, Entropy=0.6910, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6144
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.8694, Q2 Loss=0.8694, Entropy=0.6809, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4708
SAC Update 4/5: Actor Loss=-0.0062, Q1 Loss=0.7272, Q2 Loss=0.7272, Entropy=0.6814, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6356
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=0.9464, Q2 Loss=0.9464, Entropy=0.6754, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1761

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (23.3%)
Q1 update: 0.06s (17.4%)
Q2 update: 0.06s (19.0%)
Actor update: 0.12s (36.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007637
Q1 loss: 0.829567
Q2 loss: 0.829567
Current threshold: -149.3075
Global Scale Offset: 230.4916
Reward stats: mean=0.0163, std=0.1355, count=260
----------------------------------------------
SAC Update - Actor Loss: -0.0076, Q1 Loss: 0.8296, Q2 Loss: 0.8296, Entropy: 0.6782, Mean TD Error: 0.4725, Threshold: -149.3075
Original likelihood: -57.70885467529297
Adjusted likelihood: -57.70885467529297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6536)
Current yaw: tensor([ 0.0157,  0.0063, -0.1400], device='cuda:1')
8 turn
Sampling time 5.063765586994123
tensor([-0.0315,  0.5407,  0.5269,  0.5248, -0.0808,  0.5124,  0.8930,  0.8593,
         1.2925,  0.2994,  0.1920,  1.1551,  0.0157,  0.0063, -0.1400, -2.9007],
       device='cuda:1')
Original likelihood: -62.157867431640625
Adjusted likelihood: -62.157867431640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6465)
State is out of distribution
Final likelihood: tensor([ -5.7431,  -5.9903,  -6.0863,  -6.2542,  -6.8510,  -7.0480,  -7.6545,
         -7.6578,  -8.3023,  -9.1246,  -9.2250,  -9.9271, -10.5967, -11.2250,
        -13.5250, -18.9920], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -5.7431,  -5.9903,  -6.0863,  -6.2542,  -6.8510,  -7.0480,  -7.6545,
         -7.6578,  -8.3023,  -9.1246,  -9.2250,  -9.9271, -10.5967, -11.2250,
        -13.5250, -18.9920], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.0127
1 mode projection succeeded
New goal: tensor([ 1.1613e-02,  5.7290e-01,  5.2141e-01,  5.3234e-01, -8.4429e-02,
         4.7237e-01,  9.0762e-01,  9.2218e-01,  1.2541e+00,  3.2797e-01,
         2.3301e-01,  1.1513e+00,  7.4786e-04,  1.2704e-02, -6.3772e-02],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -90.05261993408203
Adjusted likelihood: -90.05261993408203
Likelihood residual: 0.0
Original likelihood: -66.074462890625
Adjusted likelihood: -66.074462890625
Likelihood residual: 0.0
{'index': 66.074462890625, 'thumb_middle': 90.05261993408203}
Current yaw: tensor([ 0.0157,  0.0063, -0.1400], device='cuda:1')
9 index
tensor([-0.0315,  0.5407,  0.5269,  0.5248, -0.0808,  0.5124,  0.8930,  0.8593,
         1.2925,  0.2994,  0.1920,  1.1551,  0.0157,  0.0063, -0.1400, -2.9007],
       device='cuda:1')
Solve time for step 1 11.69404749199748
Current ori: tensor([ 0.0157,  0.0063, -0.1400], device='cuda:1')
Middle force: tensor([0.5223, 0.5625, 0.5615, 0.5401], device='cuda:1')
Thumb force: tensor([0.5274, 0.5525, 0.5406, 0.6360], device='cuda:1')
tensor([ 0.0479,  0.5059,  0.4706,  0.5072, -0.0918,  0.5041,  0.8907,  0.8864,
         1.2849,  0.3157,  0.2143,  1.1317,  0.0171,  0.0118, -0.1603, -1.2780],
       device='cuda:1')
Solve time for step 2 4.477191484998912
Current ori: tensor([ 0.0171,  0.0118, -0.1603], device='cuda:1')
Middle force: tensor([0.5583, 0.5583, 0.5374], device='cuda:1')
Thumb force: tensor([0.5486, 0.5383, 0.6314], device='cuda:1')
tensor([ 0.0552,  0.5100,  0.4723,  0.5089, -0.0964,  0.4949,  0.8949,  0.9054,
         1.2790,  0.3233,  0.2222,  1.1365,  0.0221,  0.0137, -0.1615, -0.2417],
       device='cuda:1')
Solve time for step 3 4.044292119971942
Current ori: tensor([ 0.0221,  0.0137, -0.1615], device='cuda:1')
Middle force: tensor([0.5264, 0.5139], device='cuda:1')
Thumb force: tensor([0.5309, 0.5447], device='cuda:1')
tensor([ 0.0564,  0.5101,  0.4704,  0.5086, -0.0935,  0.5037,  0.8876,  0.8955,
         1.2979,  0.2995,  0.2083,  1.1263,  0.0163,  0.0127, -0.1746,  0.3660],
       device='cuda:1')
Solve time for step 4 4.4455230589956045
Current ori: tensor([ 0.0163,  0.0127, -0.1746], device='cuda:1')
Middle force: tensor([0.5126], device='cuda:1')
Thumb force: tensor([0.5390], device='cuda:1')
Storing RECOVERY transition: reward=0.0458 (scaled=0.0458), steps=0
Reward stats updated: mean 0.0163 -> 0.0164, std: 0.1353
Collected 261 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.8223, Q2 Loss=0.8223, Entropy=0.6891, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5578
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=1.2074, Q2 Loss=1.2074, Entropy=0.6787, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0054
SAC Update 3/5: Actor Loss=-0.0098, Q1 Loss=1.0209, Q2 Loss=1.0209, Entropy=0.6854, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4115
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=1.3699, Q2 Loss=1.3699, Entropy=0.6903, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1738
SAC Update 5/5: Actor Loss=-0.0064, Q1 Loss=1.1140, Q2 Loss=1.1140, Entropy=0.6735, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0540

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.09s (24.6%)
Q1 update: 0.06s (17.8%)
Q2 update: 0.06s (17.9%)
Actor update: 0.13s (36.1%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008003
Q1 loss: 1.106902
Q2 loss: 1.106902
Current threshold: -149.3061
Global Scale Offset: 246.2203
Reward stats: mean=0.0164, std=0.1353, count=261
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 1.1069, Q2 Loss: 1.1069, Entropy: 0.6834, Mean TD Error: 1.2405, Threshold: -149.3061
Original likelihood: -47.65957260131836
Adjusted likelihood: -47.65957260131836
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6593)
State is out of distribution
Final likelihood: tensor([ -2.3176,  -2.4187,  -2.5456,  -3.4939,  -3.7453,  -3.7689,  -4.2325,
         -4.4793,  -4.6153,  -5.1795,  -5.4294,  -5.9635,  -6.3328,  -7.4418,
        -10.5813, -11.4039], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.3176,  -2.4187,  -2.5456,  -3.4939,  -3.7453,  -3.7689,  -4.2325,
         -4.4793,  -4.6153,  -5.1795,  -5.4294,  -5.9635,  -6.3328,  -7.4418,
        -10.5813, -11.4039], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2468
1 mode projection succeeded
New goal: tensor([ 0.0133,  0.5647,  0.5292,  0.5450, -0.0726,  0.5049,  0.8549,  0.8646,
         1.2433,  0.3446,  0.2202,  1.1987,  0.0054,  0.0153, -0.1907],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -87.3191146850586
Adjusted likelihood: -87.3191146850586
Likelihood residual: 0.0
Original likelihood: -83.32252502441406
Adjusted likelihood: -83.32252502441406
Likelihood residual: 0.0
{'index': 83.32252502441406, 'thumb_middle': 87.3191146850586}
Current yaw: tensor([ 0.0179,  0.0149, -0.1860], device='cuda:1')
10 index
tensor([ 0.0032,  0.5730,  0.5136,  0.5284, -0.0986,  0.4962,  0.8959,  0.9020,
         1.2796,  0.3323,  0.2174,  1.1355,  0.0179,  0.0149, -0.1860,  0.4894],
       device='cuda:1')
Solve time for step 1 11.532818359031808
Current ori: tensor([ 0.0179,  0.0149, -0.1860], device='cuda:1')
Middle force: tensor([0.5685, 0.5415, 0.5534, 0.5979], device='cuda:1')
Thumb force: tensor([0.5496, 0.5861, 0.5661, 0.5295], device='cuda:1')
tensor([ 0.0581,  0.5044,  0.4771,  0.5201, -0.0935,  0.5055,  0.8883,  0.8958,
         1.2829,  0.3292,  0.2140,  1.1205,  0.0125,  0.0125, -0.2010,  0.3206],
       device='cuda:1')
Solve time for step 2 4.743854214029852
Current ori: tensor([ 0.0125,  0.0125, -0.2010], device='cuda:1')
Middle force: tensor([0.5393, 0.5506, 0.5930], device='cuda:1')
Thumb force: tensor([0.5781, 0.5628, 0.5273], device='cuda:1')
tensor([ 0.0634,  0.5071,  0.4766,  0.5194, -0.0810,  0.5114,  0.8905,  0.8972,
         1.2764,  0.3329,  0.1992,  1.1360,  0.0121,  0.0042, -0.2049,  0.1615],
       device='cuda:1')
Solve time for step 3 4.613060285046231
Current ori: tensor([ 0.0121,  0.0042, -0.2049], device='cuda:1')
Middle force: tensor([0.5479, 0.5043], device='cuda:1')
Thumb force: tensor([0.5660, 0.5613], device='cuda:1')
tensor([ 0.0645,  0.5070,  0.4775,  0.5202, -0.0861,  0.5156,  0.8942,  0.8992,
         1.2600,  0.3560,  0.2093,  1.1377,  0.0131,  0.0037, -0.2029,  0.0074],
       device='cuda:1')
Solve time for step 4 4.209753051050939
Current ori: tensor([ 0.0131,  0.0037, -0.2029], device='cuda:1')
Middle force: tensor([0.5031], device='cuda:1')
Thumb force: tensor([0.5497], device='cuda:1')
Storing RECOVERY transition: reward=0.0712 (scaled=0.0712), steps=0
Reward stats updated: mean 0.0164 -> 0.0166, std: 0.1351
Collected 262 transitions for RL
SAC Update 1/5: Actor Loss=-0.0070, Q1 Loss=1.1162, Q2 Loss=1.1162, Entropy=0.6855, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7610
SAC Update 2/5: Actor Loss=-0.0059, Q1 Loss=0.7432, Q2 Loss=0.7432, Entropy=0.6766, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2873
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.0011, Q2 Loss=1.0011, Entropy=0.6920, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2783
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.7902, Q2 Loss=0.7902, Entropy=0.6712, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1170
SAC Update 5/5: Actor Loss=-0.0062, Q1 Loss=0.9574, Q2 Loss=0.9574, Entropy=0.6786, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7229

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.8%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (36.7%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006957
Q1 loss: 0.921599
Q2 loss: 0.921599
Current threshold: -149.3045
Global Scale Offset: 262.2455
Reward stats: mean=0.0166, std=0.1351, count=262
----------------------------------------------
SAC Update - Actor Loss: -0.0070, Q1 Loss: 0.9216, Q2 Loss: 0.9216, Entropy: 0.6808, Mean TD Error: 1.0333, Threshold: -149.3045
Original likelihood: -57.897621154785156
Adjusted likelihood: -57.897621154785156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6356)
Current yaw: tensor([ 0.0079,  0.0022, -0.2109], device='cuda:1')
11 turn
Sampling time 5.094204351014923
tensor([ 0.0151,  0.5701,  0.5217,  0.5413, -0.0826,  0.5240,  0.8887,  0.8867,
         1.2882,  0.3186,  0.1827,  1.1409,  0.0079,  0.0022, -0.2109, -0.0307],
       device='cuda:1')
Original likelihood: -55.319923400878906
Adjusted likelihood: -55.319923400878906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6392)
State is out of distribution
Final likelihood: tensor([-2.9177, -3.0749, -3.1474, -3.2169, -3.2854, -3.6073, -3.6471, -3.7234,
        -3.9740, -4.5662, -4.5668, -4.6590, -4.8153, -4.9482, -5.3905, -7.0815],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9177, -3.0749, -3.1474, -3.2169, -3.2854, -3.6073, -3.6471, -3.7234,
        -3.9740, -4.5662, -4.5668, -4.6590, -4.8153, -4.9482, -5.3905, -7.0815],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.1638
1 mode projection succeeded
New goal: tensor([ 0.0127,  0.5649,  0.5288,  0.5438, -0.0727,  0.5059,  0.8540,  0.8653,
         1.2430,  0.3454,  0.2208,  1.1986,  0.0054,  0.0153, -0.0944],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -77.56076049804688
Adjusted likelihood: -77.56076049804688
Likelihood residual: 0.0
Original likelihood: -94.9760513305664
Adjusted likelihood: -94.9760513305664
Likelihood residual: 0.0
{'index': 94.9760513305664, 'thumb_middle': 77.56076049804688}
Current yaw: tensor([ 0.0079,  0.0022, -0.2109], device='cuda:1')
12 thumb_middle
tensor([ 0.0151,  0.5701,  0.5217,  0.5413, -0.0826,  0.5240,  0.8887,  0.8867,
         1.2882,  0.3186,  0.1827,  1.1409,  0.0079,  0.0022, -0.2109, -0.0307],
       device='cuda:1')
Solve time for step 1 9.418514569988474
Current ori: tensor([ 0.0079,  0.0022, -0.2109], device='cuda:1')
Index force: tensor([0.5712, 0.5928, 0.5911, 0.5886], device='cuda:1')
tensor([-0.0043,  0.5750,  0.5081,  0.5215, -0.1558,  0.4889,  0.8297,  0.8263,
         1.2106,  0.3228,  0.1372,  1.1505,  0.0064,  0.0129, -0.2109, -0.0661],
       device='cuda:1')
Solve time for step 2 3.9780002780025825
Current ori: tensor([ 0.0064,  0.0129, -0.2109], device='cuda:1')
Index force: tensor([0.5834, 0.5834, 0.5810], device='cuda:1')
tensor([-0.0131,  0.5667,  0.5084,  0.5287, -0.1760,  0.4914,  0.8200,  0.8597,
         1.1991,  0.3270,  0.1471,  1.1660,  0.0091,  0.0177, -0.2109, -0.0716],
       device='cuda:1')
Solve time for step 3 3.6708990310435183
Current ori: tensor([ 0.0091,  0.0177, -0.2109], device='cuda:1')
Index force: tensor([0.5743, 0.5732], device='cuda:1')
tensor([-0.0097,  0.5514,  0.5279,  0.5382, -0.1742,  0.5041,  0.8079,  0.8525,
         1.1983,  0.3237,  0.1496,  1.1607,  0.0137,  0.0160, -0.2109, -0.0595],
       device='cuda:1')
Solve time for step 4 3.8684772169799544
Current ori: tensor([ 0.0137,  0.0160, -0.2109], device='cuda:1')
Index force: tensor([0.5662], device='cuda:1')
Storing RECOVERY transition: reward=0.0063 (scaled=0.0063), steps=0
Reward stats updated: mean 0.0166 -> 0.0166, std: 0.1348
Collected 263 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6787, Q2 Loss=0.6787, Entropy=0.6749, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3642
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.5997, Q2 Loss=0.5997, Entropy=0.6735, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1043
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=0.8258, Q2 Loss=0.8258, Entropy=0.6800, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4186
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.8363, Q2 Loss=0.8363, Entropy=0.6817, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9603
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8074, Q2 Loss=0.8074, Entropy=0.6821, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4195

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (22.1%)
Q1 update: 0.06s (18.3%)
Q2 update: 0.06s (18.0%)
Actor update: 0.14s (38.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007470
Q1 loss: 0.749592
Q2 loss: 0.749592
Current threshold: -149.3040
Global Scale Offset: 276.5351
Reward stats: mean=0.0166, std=0.1348, count=263
----------------------------------------------
SAC Update - Actor Loss: -0.0075, Q1 Loss: 0.7496, Q2 Loss: 0.7496, Entropy: 0.6784, Mean TD Error: 0.6534, Threshold: -149.3040
Original likelihood: -45.30271911621094
Adjusted likelihood: -45.30271911621094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6459)
Current yaw: tensor([ 0.0111,  0.0142, -0.2175], device='cuda:1')
13 turn
Sampling time 5.141555019014049
tensor([-0.0076,  0.5632,  0.5194,  0.5258, -0.1052,  0.5500,  0.8560,  0.8589,
         1.2530,  0.3439,  0.2145,  1.1918,  0.0111,  0.0142, -0.2175, -0.0297],
       device='cuda:1')
Original likelihood: -48.507896423339844
Adjusted likelihood: -48.507896423339844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6416)
State is out of distribution
Final likelihood: tensor([-2.5339, -2.8097, -2.9308, -3.0230, -3.0772, -3.1918, -3.6037, -3.9189,
        -4.2981, -4.8969, -4.9215, -5.4604, -5.7811, -6.1162, -6.3307, -6.3401],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.5339, -2.8097, -2.9308, -3.0230, -3.0772, -3.1918, -3.6037, -3.9189,
        -4.2981, -4.8969, -4.9215, -5.4604, -5.7811, -6.1162, -6.3307, -6.3401],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3271
1 mode projection succeeded
New goal: tensor([ 0.0130,  0.5650,  0.5281,  0.5449, -0.0722,  0.5056,  0.8543,  0.8656,
         1.2431,  0.3440,  0.2206,  1.1987,  0.0054,  0.0151, -0.2791],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -74.80044555664062
Adjusted likelihood: -74.80044555664062
Likelihood residual: 0.0
Original likelihood: -64.11257934570312
Adjusted likelihood: -64.11257934570312
Likelihood residual: 0.0
{'index': 64.11257934570312, 'thumb_middle': 74.80044555664062}
Current yaw: tensor([ 0.0111,  0.0142, -0.2175], device='cuda:1')
14 index
tensor([-0.0076,  0.5632,  0.5194,  0.5258, -0.1052,  0.5500,  0.8560,  0.8589,
         1.2530,  0.3439,  0.2145,  1.1918,  0.0111,  0.0142, -0.2175, -0.0297],
       device='cuda:1')
Solve time for step 1 11.064535781973973
Current ori: tensor([ 0.0111,  0.0142, -0.2175], device='cuda:1')
Middle force: tensor([0.5342, 0.5704, 0.5008, 0.5929], device='cuda:1')
Thumb force: tensor([0.5942, 0.6135, 0.5969, 0.5338], device='cuda:1')
tensor([ 0.0552,  0.5052,  0.4757,  0.5164, -0.1140,  0.5395,  0.8635,  0.8628,
         1.2891,  0.3027,  0.2024,  1.1776,  0.0100,  0.0197, -0.2476, -0.0487],
       device='cuda:1')
Solve time for step 2 4.430522571958136
Current ori: tensor([ 0.0100,  0.0197, -0.2476], device='cuda:1')
Middle force: tensor([0.5692, 0.5008, 0.5892], device='cuda:1')
Thumb force: tensor([0.6027, 0.6017, 0.5309], device='cuda:1')
tensor([ 0.0580,  0.5046,  0.4753,  0.5189, -0.1151,  0.5499,  0.8515,  0.8492,
         1.3603,  0.2020,  0.1602,  1.1754,  0.0029,  0.0216, -0.2561, -0.0373],
       device='cuda:1')
Solve time for step 3 4.311168894986622
Current ori: tensor([ 0.0029,  0.0216, -0.2561], device='cuda:1')
Middle force: tensor([0.5006, 0.5841], device='cuda:1')
Thumb force: tensor([0.5926, 0.5274], device='cuda:1')
tensor([ 0.0584,  0.5039,  0.4753,  0.5210, -0.1020,  0.5444,  0.8642,  0.8667,
         1.2529,  0.3624,  0.2022,  1.1873,  0.0065,  0.0113, -0.2739,  0.0183],
       device='cuda:1')
Solve time for step 4 4.199539772002026
Current ori: tensor([ 0.0065,  0.0113, -0.2739], device='cuda:1')
Middle force: tensor([0.5059], device='cuda:1')
Thumb force: tensor([0.5272], device='cuda:1')
Storing RECOVERY transition: reward=0.0481 (scaled=0.0481), steps=0
Reward stats updated: mean 0.0166 -> 0.0167, std: 0.1346
Collected 264 transitions for RL
SAC Update 1/5: Actor Loss=-0.0096, Q1 Loss=0.9665, Q2 Loss=0.9665, Entropy=0.6891, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4803
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.7522, Q2 Loss=0.7522, Entropy=0.6777, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2411
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=1.1696, Q2 Loss=1.1696, Entropy=0.6872, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3949
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=0.7401, Q2 Loss=0.7401, Entropy=0.6921, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1527
SAC Update 5/5: Actor Loss=-0.0130, Q1 Loss=7.3000, Q2 Loss=7.3000, Entropy=0.6708, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2969

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.0%)
Q1 update: 0.07s (17.8%)
Q2 update: 0.07s (18.0%)
Actor update: 0.14s (38.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009194
Q1 loss: 2.185671
Q2 loss: 2.185671
Current threshold: -149.3041
Global Scale Offset: 290.5053
Reward stats: mean=0.0167, std=0.1346, count=264
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 2.1857, Q2 Loss: 2.1857, Entropy: 0.6834, Mean TD Error: 1.1132, Threshold: -149.3041
Original likelihood: -52.27254104614258
Adjusted likelihood: -52.27254104614258
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6302)
Current yaw: tensor([ 0.0101,  0.0147, -0.2656], device='cuda:1')
15 turn
Sampling time 5.338016140041873
tensor([ 0.0059,  0.5661,  0.5199,  0.5419, -0.1097,  0.5412,  0.8682,  0.8700,
         1.2597,  0.3550,  0.1924,  1.2112,  0.0101,  0.0147, -0.2656,  0.0183],
       device='cuda:1')
Original likelihood: -51.42356872558594
Adjusted likelihood: -51.42356872558594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6313)
State is out of distribution
Final likelihood: tensor([-3.5131, -3.9211, -4.4265, -4.4523, -4.7380, -4.8261, -4.8303, -5.1395,
        -5.1580, -5.1875, -5.1950, -5.7657, -5.9998, -6.1579, -6.2987, -7.9101],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.5131, -3.9211, -4.4265, -4.4523, -4.7380, -4.8261, -4.8303, -5.1395,
        -5.1580, -5.1875, -5.1950, -5.7657, -5.9998, -6.1579, -6.2987, -7.9101],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2200
1 mode projection succeeded
New goal: tensor([ 0.0131,  0.5645,  0.5285,  0.5454, -0.0728,  0.5046,  0.8557,  0.8651,
         1.2439,  0.3439,  0.2194,  1.2002,  0.0054,  0.0152, -0.2747],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -64.80902099609375
Adjusted likelihood: -64.80902099609375
Likelihood residual: 0.0
Original likelihood: -64.7957763671875
Adjusted likelihood: -64.7957763671875
Likelihood residual: 0.0
{'index': 64.7957763671875, 'thumb_middle': 64.80902099609375}
Current yaw: tensor([ 0.0101,  0.0147, -0.2656], device='cuda:1')
16 index
tensor([ 0.0059,  0.5661,  0.5199,  0.5419, -0.1097,  0.5412,  0.8682,  0.8700,
         1.2597,  0.3550,  0.1924,  1.2112,  0.0101,  0.0147, -0.2656,  0.0183],
       device='cuda:1')
Solve time for step 1 11.208871974027716
Current ori: tensor([ 0.0101,  0.0147, -0.2656], device='cuda:1')
Middle force: tensor([0.5770, 0.5655, 0.5841, 0.5492], device='cuda:1')
Thumb force: tensor([0.5887, 0.5778, 0.5557, 0.5344], device='cuda:1')
tensor([ 0.0586,  0.5052,  0.4777,  0.5218, -0.1203,  0.5267,  0.8785,  0.8794,
         1.2725,  0.3434,  0.2004,  1.1940,  0.0118,  0.0207, -0.2883,  0.6420],
       device='cuda:1')
Solve time for step 2 4.862179702031426
Current ori: tensor([ 0.0118,  0.0207, -0.2883], device='cuda:1')
Middle force: tensor([0.5625, 0.5792, 0.5447], device='cuda:1')
Thumb force: tensor([0.5678, 0.5517, 0.5308], device='cuda:1')
tensor([ 0.0585,  0.5043,  0.4748,  0.5210, -0.1096,  0.5327,  0.8791,  0.8770,
         1.2752,  0.3388,  0.1849,  1.1957,  0.0084,  0.0136, -0.3054,  0.9728],
       device='cuda:1')
Solve time for step 3 4.737830199999735
Current ori: tensor([ 0.0084,  0.0136, -0.3054], device='cuda:1')
Middle force: tensor([0.5328, 0.5539], device='cuda:1')
Thumb force: tensor([0.5599, 0.5343], device='cuda:1')
tensor([ 0.0584,  0.5049,  0.4756,  0.5206, -0.1144,  0.5316,  0.8801,  0.8794,
         1.2729,  0.3458,  0.1865,  1.2001,  0.0088,  0.0157, -0.3060,  1.0939],
       device='cuda:1')
Solve time for step 4 4.519169841951225
Current ori: tensor([ 0.0088,  0.0157, -0.3060], device='cuda:1')
Middle force: tensor([0.5667], device='cuda:1')
Thumb force: tensor([0.5962], device='cuda:1')
Storing RECOVERY transition: reward=0.0357 (scaled=0.0357), steps=0
Reward stats updated: mean 0.0167 -> 0.0168, std: 0.1343
Collected 265 transitions for RL
SAC Update 1/5: Actor Loss=-0.0119, Q1 Loss=0.8391, Q2 Loss=0.8391, Entropy=0.6789, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5909
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=1.5115, Q2 Loss=1.5115, Entropy=0.6907, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2094
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.0744, Q2 Loss=1.0744, Entropy=0.6787, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9616
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.7380, Q2 Loss=0.7380, Entropy=0.6715, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4342
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.9256, Q2 Loss=1.9256, Entropy=0.6915, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8231

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.6%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.6%)
Actor update: 0.16s (39.4%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010177
Q1 loss: 1.217730
Q2 loss: 1.217730
Current threshold: -149.3043
Global Scale Offset: 297.5272
Reward stats: mean=0.0168, std=0.1343, count=265
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.2177, Q2 Loss: 1.2177, Entropy: 0.6823, Mean TD Error: 1.0038, Threshold: -149.3043
Original likelihood: -52.92329406738281
Adjusted likelihood: -52.92329406738281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6264)
State is out of distribution
Final likelihood: tensor([-3.1338, -3.2399, -4.2234, -4.2377, -4.5995, -4.8241, -5.0423, -5.2504,
        -5.2549, -5.4292, -5.5249, -5.6006, -5.6728, -6.2114, -6.7557, -7.0546],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.1338, -3.2399, -4.2234, -4.2377, -4.5995, -4.8241, -5.0423, -5.2504,
        -5.2549, -5.4292, -5.5249, -5.6006, -5.6728, -6.2114, -6.7557, -7.0546],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.1285
1 mode projection succeeded
New goal: tensor([ 0.0219,  0.5353,  0.5573,  0.5853, -0.0731,  0.4925,  0.8484,  0.9305,
         1.2835,  0.3096,  0.1842,  1.2038,  0.0050,  0.0146, -0.1685],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -86.7001953125
Adjusted likelihood: -86.7001953125
Likelihood residual: 0.0
Original likelihood: -70.34471893310547
Adjusted likelihood: -70.34471893310547
Likelihood residual: 0.0
{'index': 70.34471893310547, 'thumb_middle': 86.7001953125}
Current yaw: tensor([ 0.0064,  0.0158, -0.3013], device='cuda:1')
17 index
tensor([ 0.0081,  0.5687,  0.5196,  0.5406, -0.1137,  0.5374,  0.8742,  0.8725,
         1.2737,  0.3453,  0.1867,  1.1960,  0.0064,  0.0158, -0.3013,  1.0978],
       device='cuda:1')
Solve time for step 1 12.094792480987962
Current ori: tensor([ 0.0064,  0.0158, -0.3013], device='cuda:1')
Middle force: tensor([0.5602, 0.5171, 0.5091, 0.5649], device='cuda:1')
Thumb force: tensor([0.5777, 0.5678, 0.5268, 0.5463], device='cuda:1')
tensor([ 0.0629,  0.4828,  0.5011,  0.5543, -0.1168,  0.5266,  0.8706,  0.9298,
         1.2942,  0.3170,  0.1688,  1.2101,  0.0131,  0.0153, -0.3320,  1.2759],
       device='cuda:1')
Solve time for step 2 4.503836154995952
Current ori: tensor([ 0.0131,  0.0153, -0.3320], device='cuda:1')
Middle force: tensor([0.5160, 0.5083, 0.5624], device='cuda:1')
Thumb force: tensor([0.5615, 0.5254, 0.5435], device='cuda:1')
tensor([ 0.0641,  0.4814,  0.5053,  0.5572, -0.1311,  0.5205,  0.8654,  0.9336,
         1.3062,  0.3067,  0.1821,  1.1958,  0.0142,  0.0252, -0.3288,  1.2599],
       device='cuda:1')
Solve time for step 3 4.738202298001852
Current ori: tensor([ 0.0142,  0.0252, -0.3288], device='cuda:1')
Middle force: tensor([0.5036, 0.5755], device='cuda:1')
Thumb force: tensor([0.5669, 0.5771], device='cuda:1')
tensor([ 0.0647,  0.4799,  0.5061,  0.5577, -0.1217,  0.5203,  0.8710,  0.9401,
         1.3021,  0.3087,  0.1688,  1.2096,  0.0150,  0.0183, -0.3389,  1.1301],
       device='cuda:1')
Solve time for step 4 4.691098063020036
Current ori: tensor([ 0.0150,  0.0183, -0.3389], device='cuda:1')
Middle force: tensor([0.5515], device='cuda:1')
Thumb force: tensor([0.5313], device='cuda:1')
Storing RECOVERY transition: reward=0.0701 (scaled=0.0701), steps=0
Reward stats updated: mean 0.0168 -> 0.0170, std: 0.1341
Collected 266 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7915, Q2 Loss=0.7915, Entropy=0.6872, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5527
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=0.9895, Q2 Loss=0.9895, Entropy=0.6914, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1328
SAC Update 3/5: Actor Loss=-0.0129, Q1 Loss=1.2314, Q2 Loss=1.2314, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7220
SAC Update 4/5: Actor Loss=-0.0065, Q1 Loss=1.2790, Q2 Loss=1.2790, Entropy=0.6859, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9531
SAC Update 5/5: Actor Loss=-0.0069, Q1 Loss=0.8031, Q2 Loss=0.8031, Entropy=0.6788, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7497

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.7%)
Q1 update: 0.08s (20.3%)
Q2 update: 0.08s (20.0%)
Actor update: 0.15s (39.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008944
Q1 loss: 1.018908
Q2 loss: 1.018908
Current threshold: -149.3038
Global Scale Offset: 305.8128
Reward stats: mean=0.0170, std=0.1341, count=266
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.0189, Q2 Loss: 1.0189, Entropy: 0.6873, Mean TD Error: 1.4221, Threshold: -149.3038
Original likelihood: -67.82906341552734
Adjusted likelihood: -67.82906341552734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6046)
Current yaw: tensor([ 0.0099,  0.0177, -0.3358], device='cuda:1')
18 turn
Sampling time 5.091524905990809
tensor([ 0.0161,  0.5392,  0.5487,  0.5803, -0.1200,  0.5318,  0.8607,  0.9284,
         1.3069,  0.3031,  0.1656,  1.2008,  0.0099,  0.0177, -0.3358,  1.0550],
       device='cuda:1')
Original likelihood: -69.00785827636719
Adjusted likelihood: -69.00785827636719
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6031)
Solve time for step 1 15.775975429976825
Current ori: tensor([ 0.0099,  0.0177, -0.3358], device='cuda:1')
Middle force: tensor([0.5407, 0.6848, 0.5353, 0.5294, 0.5768, 0.8452, 0.6064, 0.8229, 0.7229,
        0.5101, 0.7391, 0.6023], device='cuda:1')
Thumb force: tensor([0.5887, 0.7717, 1.1295, 0.5760, 0.7645, 1.0389, 0.6070, 0.5671, 0.6086,
        0.5590, 0.7286, 0.6484], device='cuda:1')
Index force: tensor([0.6445, 0.6934, 0.5433, 0.5645, 0.5232, 0.5384, 0.6070, 0.5031, 0.5812,
        0.6946, 0.7458, 0.6127], device='cuda:1')
Storing NORMAL transition: reward=0.0286 (scaled=0.0286), steps=1
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.1339
Collected 267 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=1.0207, Q2 Loss=1.0207, Entropy=0.6842, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4321
SAC Update 2/5: Actor Loss=-0.0060, Q1 Loss=0.6510, Q2 Loss=0.6510, Entropy=0.6767, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6294
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.3977, Q2 Loss=1.3977, Entropy=0.6858, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2036
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=2.6500, Q2 Loss=2.6500, Entropy=0.6873, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2058
SAC Update 5/5: Actor Loss=-0.0136, Q1 Loss=0.9527, Q2 Loss=0.9527, Entropy=0.6766, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3848

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.8%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (38.4%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009420
Q1 loss: 1.334395
Q2 loss: 1.334395
Current threshold: -149.3027
Global Scale Offset: 316.3014
Reward stats: mean=0.0170, std=0.1339, count=267
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.3344, Q2 Loss: 1.3344, Entropy: 0.6821, Mean TD Error: 1.5711, Threshold: -149.3027
tensor([ 0.1259,  0.5555,  0.6070,  0.6229, -0.2230,  0.5011,  0.9722,  1.0685,
         1.3151,  0.3084,  0.1800,  1.2000,  0.0190,  0.0303, -0.3653, -0.3475],
       device='cuda:1')
Original likelihood: -205.55661010742188
Adjusted likelihood: -205.55661010742188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4297)
State is out of distribution
Final likelihood: tensor([-2.6578, -3.1263, -3.3600, -3.7408, -3.8410, -4.7272, -4.7657, -5.2918,
        -5.4109, -5.6216, -5.8561, -5.9444, -6.1856, -6.2172, -7.1703, -9.1195],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.6578, -3.1263, -3.3600, -3.7408, -3.8410, -4.7272, -4.7657, -5.2918,
        -5.4109, -5.6216, -5.8561, -5.9444, -6.1856, -6.2172, -7.1703, -9.1195],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.1898
1 mode projection succeeded
New goal: tensor([ 0.0575,  0.5405,  0.5707,  0.6121, -0.0663,  0.4969,  0.8549,  0.8746,
         1.2311,  0.3613,  0.2776,  1.0887,  0.0044,  0.0142, -1.9869],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -136.6222686767578
Adjusted likelihood: -136.6222686767578
Likelihood residual: 0.0
Original likelihood: -138.31982421875
Adjusted likelihood: -138.31982421875
Likelihood residual: 0.0
{'index': 138.31982421875, 'thumb_middle': 136.6222686767578}
Current yaw: tensor([ 0.0190,  0.0303, -0.3653], device='cuda:1')
19 thumb_middle
tensor([ 0.1259,  0.5555,  0.6070,  0.6229, -0.2230,  0.5011,  0.9722,  1.0685,
         1.3151,  0.3084,  0.1800,  1.2000,  0.0190,  0.0303, -0.3653, -0.3475],
       device='cuda:1')
Solve time for step 1 9.875031917996239
Current ori: tensor([ 0.0190,  0.0303, -0.3653], device='cuda:1')
Index force: tensor([0.5601, 0.5002, 0.6103, 0.5044], device='cuda:1')
tensor([ 0.1224,  0.5567,  0.5910,  0.6442, -0.2098,  0.4707,  0.8282,  0.8814,
         1.2109,  0.3350,  0.2113,  1.0902,  0.0194,  0.0305, -0.3653, -0.2880],
       device='cuda:1')
Solve time for step 2 3.8494731310056522
Current ori: tensor([ 0.0194,  0.0305, -0.3653], device='cuda:1')
Index force: tensor([0.5715, 0.6026, 0.6003], device='cuda:1')
tensor([ 0.1096,  0.5720,  0.5757,  0.6093, -0.2023,  0.4799,  0.8178,  0.8547,
         1.2046,  0.3425,  0.2160,  1.0748,  0.0134,  0.0360, -0.3653, -0.3127],
       device='cuda:1')
Solve time for step 3 3.9373621030244976
Current ori: tensor([ 0.0134,  0.0360, -0.3653], device='cuda:1')
Index force: tensor([0.5936, 0.5928], device='cuda:1')
tensor([ 0.1182,  0.5661,  0.5848,  0.6242, -0.1926,  0.4819,  0.8139,  0.8483,
         1.1994,  0.3445,  0.2148,  1.0696,  0.0157,  0.0317, -0.3653, -0.2954],
       device='cuda:1')
Solve time for step 4 3.642449873033911
Current ori: tensor([ 0.0157,  0.0317, -0.3653], device='cuda:1')
Index force: tensor([0.5670], device='cuda:1')
Storing RECOVERY transition: reward=0.0120 (scaled=0.0120), steps=1
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.1336
Collected 268 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=1.9179, Q2 Loss=1.9179, Entropy=0.6910, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2210
SAC Update 2/5: Actor Loss=-0.0061, Q1 Loss=0.6045, Q2 Loss=0.6045, Entropy=0.6851, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0574
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.4084, Q2 Loss=1.4084, Entropy=0.6910, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0977
SAC Update 4/5: Actor Loss=-0.0107, Q1 Loss=16.0599, Q2 Loss=16.0599, Entropy=0.6780, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9475
SAC Update 5/5: Actor Loss=-0.0064, Q1 Loss=3.2573, Q2 Loss=3.2573, Entropy=0.6816, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3594

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.9%)
Q1 update: 0.08s (19.3%)
Q2 update: 0.07s (18.7%)
Actor update: 0.16s (39.2%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008881
Q1 loss: 4.649622
Q2 loss: 4.649622
Current threshold: -149.3018
Global Scale Offset: 325.6794
Reward stats: mean=0.0170, std=0.1336, count=268
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 4.6496, Q2 Loss: 4.6496, Entropy: 0.6854, Mean TD Error: 2.7366, Threshold: -149.3018
Original likelihood: -111.99629211425781
Adjusted likelihood: -111.99629211425781
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5454)
State is out of distribution
Final likelihood: tensor([-2.9053, -3.0576, -3.2874, -3.3970, -3.5768, -3.6980, -3.7308, -4.0236,
        -4.0626, -4.4534, -4.7009, -4.9027, -5.4419, -5.7797, -5.9061, -6.2350],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9053, -3.0576, -3.2874, -3.3970, -3.5768, -3.6980, -3.7308, -4.0236,
        -4.0626, -4.4534, -4.7009, -4.9027, -5.4419, -5.7797, -5.9061, -6.2350],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3224
1 mode projection succeeded
New goal: tensor([ 0.0905,  0.5440,  0.6046,  0.5967, -0.0740,  0.5121,  0.8139,  0.9443,
         1.2756,  0.2939,  0.2035,  1.1887,  0.0054,  0.0142, -1.2509],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -131.35687255859375
Adjusted likelihood: -131.35687255859375
Likelihood residual: 0.0
Original likelihood: -87.90071105957031
Adjusted likelihood: -87.90071105957031
Likelihood residual: 0.0
{'index': 87.90071105957031, 'thumb_middle': 131.35687255859375}
Current yaw: tensor([ 0.0105,  0.0291, -0.3770], device='cuda:1')
20 index
tensor([ 0.1190,  0.5865,  0.5660,  0.6086, -0.1270,  0.5396,  0.8454,  0.8635,
         1.2677,  0.3674,  0.2647,  1.0783,  0.0105,  0.0291, -0.3770, -0.2608],
       device='cuda:1')
Solve time for step 1 12.192911987018306
Current ori: tensor([ 0.0105,  0.0291, -0.3770], device='cuda:1')
Middle force: tensor([0.5003, 0.5479, 0.5087, 0.5028], device='cuda:1')
Thumb force: tensor([0.5928, 0.5754, 0.5726, 0.5997], device='cuda:1')
tensor([ 0.1384,  0.4951,  0.5497,  0.5759, -0.1256,  0.5473,  0.8163,  0.9167,
         1.3316,  0.2903,  0.2031,  1.1051,  0.0112,  0.0272, -0.4130,  2.0028],
       device='cuda:1')
Solve time for step 2 4.873558812018018
Current ori: tensor([ 0.0112,  0.0272, -0.4130], device='cuda:1')
Middle force: tensor([0.5456, 0.5077, 0.5022], device='cuda:1')
Thumb force: tensor([0.5691, 0.5686, 0.5940], device='cuda:1')
tensor([ 0.1357,  0.4907,  0.5529,  0.5727, -0.1068,  0.5514,  0.8208,  0.9331,
         1.3221,  0.2933,  0.1767,  1.1413,  0.0143,  0.0140, -0.4204,  3.3096],
       device='cuda:1')
Solve time for step 3 4.722676743986085
Current ori: tensor([ 0.0143,  0.0140, -0.4204], device='cuda:1')
Middle force: tensor([0.5504, 0.5396], device='cuda:1')
Thumb force: tensor([0.5843, 0.5365], device='cuda:1')
tensor([ 0.1339,  0.4908,  0.5538,  0.5730, -0.1011,  0.5476,  0.8281,  0.9447,
         1.3129,  0.2983,  0.1688,  1.1673,  0.0201,  0.0094, -0.4122,  4.1184],
       device='cuda:1')
Solve time for step 4 4.188987940957304
Current ori: tensor([ 0.0201,  0.0094, -0.4122], device='cuda:1')
Middle force: tensor([0.5011], device='cuda:1')
Thumb force: tensor([0.5737], device='cuda:1')
Storing RECOVERY transition: reward=0.0551 (scaled=0.0551), steps=1
Reward stats updated: mean 0.0170 -> 0.0172, std: 0.1334
Collected 269 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.9372, Q2 Loss=0.9372, Entropy=0.6869, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2220
SAC Update 2/5: Actor Loss=-0.0152, Q1 Loss=15.9803, Q2 Loss=15.9803, Entropy=0.6743, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1113
SAC Update 3/5: Actor Loss=-0.0122, Q1 Loss=1.2612, Q2 Loss=1.2612, Entropy=0.6913, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7317
SAC Update 4/5: Actor Loss=-0.0067, Q1 Loss=0.8794, Q2 Loss=0.8794, Entropy=0.6754, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8166
SAC Update 5/5: Actor Loss=-0.0065, Q1 Loss=1.9243, Q2 Loss=1.9243, Entropy=0.6856, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0796

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (20.1%)
Q1 update: 0.07s (18.6%)
Q2 update: 0.08s (19.2%)
Actor update: 0.15s (38.7%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009973
Q1 loss: 4.196472
Q2 loss: 4.196472
Current threshold: -149.3016
Global Scale Offset: 337.0425
Reward stats: mean=0.0172, std=0.1334, count=269
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 4.1965, Q2 Loss: 4.1965, Entropy: 0.6827, Mean TD Error: 2.3923, Threshold: -149.3016
Original likelihood: -65.26872253417969
Adjusted likelihood: -65.26872253417969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5980)
Marked last transition as done (final step)
{}

Trial 19
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 5.2763807399896905
tensor([ 1.2682e-01,  5.7475e-01,  6.0391e-01,  5.8590e-01, -1.1224e-01,
         5.1029e-01,  9.2960e-01,  8.9090e-01,  1.2605e+00,  2.7357e-01,
         2.0068e-01,  1.2339e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:1')
Original likelihood: -105.38694763183594
Adjusted likelihood: -105.38694763183594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5516)
Solve time for step 1 15.528020123951137
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([0.6056, 0.4812, 0.4926, 0.5755, 1.0611, 0.5662, 0.6860, 0.5127, 0.4837,
        0.5084, 0.5862, 0.4990], device='cuda:1')
Thumb force: tensor([0.7867, 0.7121, 2.6245, 0.6116, 1.2271, 0.6198, 0.7630, 0.6304, 0.5064,
        0.5094, 0.5833, 0.6136], device='cuda:1')
Index force: tensor([0.5935, 0.6444, 0.5501, 0.6180, 0.7208, 0.5504, 0.5007, 0.5473, 0.7444,
        0.5053, 0.5817, 0.7246], device='cuda:1')
Storing NORMAL transition: reward=0.0113 (scaled=0.0113), steps=1
Reward stats updated: mean 0.0172 -> 0.0171, std: 0.1331
Collected 270 transitions for RL
SAC Update 1/5: Actor Loss=-0.0063, Q1 Loss=0.6276, Q2 Loss=0.6276, Entropy=0.6833, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3940
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=6.1242, Q2 Loss=6.1242, Entropy=0.6878, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9968
SAC Update 3/5: Actor Loss=-0.0063, Q1 Loss=1.0519, Q2 Loss=1.0519, Entropy=0.6767, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8833
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.0135, Q2 Loss=1.0135, Entropy=0.6860, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5894
SAC Update 5/5: Actor Loss=-0.0125, Q1 Loss=1.3287, Q2 Loss=1.3287, Entropy=0.6911, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8083

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.06s (17.7%)
Q1 update: 0.07s (18.8%)
Q2 update: 0.07s (18.1%)
Actor update: 0.15s (42.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008635
Q1 loss: 2.029180
Q2 loss: 2.029180
Current threshold: -149.3018
Global Scale Offset: 350.4079
Reward stats: mean=0.0171, std=0.1331, count=270
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 2.0292, Q2 Loss: 2.0292, Entropy: 0.6850, Mean TD Error: 1.7343, Threshold: -149.3018
tensor([ 0.1186,  0.5906,  0.5267,  0.6755, -0.1602,  0.5502,  0.9150,  0.8756,
         1.2544,  0.3604,  0.2020,  1.2065, -0.0225,  0.0241, -0.0410,  1.1600],
       device='cuda:1')
Original likelihood: -132.43215942382812
Adjusted likelihood: -132.43215942382812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5191)
Solve time for step 2 6.128241654951125
Current ori: tensor([-0.0225,  0.0241, -0.0410], device='cuda:1')
Middle force: tensor([0.5102, 0.5043, 0.5699, 1.0358, 0.5649, 0.6750, 0.5109, 0.5029, 0.5078,
        0.5838, 0.5005], device='cuda:1')
Thumb force: tensor([0.7131, 2.5715, 0.6062, 1.2196, 0.6144, 0.7665, 0.6323, 0.5054, 0.5097,
        0.5817, 0.6292], device='cuda:1')
Index force: tensor([0.6357, 0.5464, 0.6119, 0.7100, 0.5473, 0.5005, 0.5425, 0.7668, 0.5044,
        0.5769, 0.7315], device='cuda:1')
Storing NORMAL transition: reward=0.0166 (scaled=0.0166), steps=1
Reward stats updated: mean 0.0171 -> 0.0171, std: 0.1329
Collected 271 transitions for RL
SAC Update 1/5: Actor Loss=-0.0065, Q1 Loss=1.9748, Q2 Loss=1.9748, Entropy=0.6859, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1296
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=2.5855, Q2 Loss=2.5855, Entropy=0.6886, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2438
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=10.0488, Q2 Loss=10.0488, Entropy=0.6823, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.8417
SAC Update 4/5: Actor Loss=-0.0113, Q1 Loss=1.6186, Q2 Loss=1.6186, Entropy=0.6865, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2972
SAC Update 5/5: Actor Loss=-0.0067, Q1 Loss=0.6647, Q2 Loss=0.6647, Entropy=0.6909, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1928

------ SAC Update Summary (5 iterations) ------
Total time: 0.36s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (21.1%)
Q1 update: 0.07s (18.5%)
Q2 update: 0.07s (18.4%)
Actor update: 0.14s (38.7%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008023
Q1 loss: 3.378464
Q2 loss: 3.378464
Current threshold: -149.3013
Global Scale Offset: 365.3341
Reward stats: mean=0.0171, std=0.1329, count=271
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 3.3785, Q2 Loss: 3.3785, Entropy: 0.6868, Mean TD Error: 3.7410, Threshold: -149.3013
tensor([ 0.0643,  0.5329,  0.4535,  0.6330, -0.1292,  0.5422,  0.9878,  0.6880,
         1.3595,  0.2138,  0.1230,  1.1836, -0.0478,  0.0179, -0.0592,  2.0058],
       device='cuda:1')
Original likelihood: -147.96861267089844
Adjusted likelihood: -147.96861267089844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5014)
Solve time for step 3 5.582807250961196
Current ori: tensor([-0.0478,  0.0179, -0.0592], device='cuda:1')
Middle force: tensor([0.5043, 0.5781, 1.0449, 0.5682, 0.6838, 0.5156, 0.5026, 0.5141, 0.5926,
        0.5011], device='cuda:1')
Thumb force: tensor([2.4991, 0.5844, 1.1729, 0.6070, 0.7383, 0.6032, 0.5042, 0.5053, 0.5686,
        0.5806], device='cuda:1')
Index force: tensor([0.5424, 0.6099, 0.7049, 0.5425, 0.5005, 0.5361, 0.7810, 0.5040, 0.5735,
        0.7072], device='cuda:1')
Storing NORMAL transition: reward=0.0057 (scaled=0.0057), steps=1
Reward stats updated: mean 0.0171 -> 0.0171, std: 0.1327
Collected 272 transitions for RL
SAC Update 1/5: Actor Loss=-0.0098, Q1 Loss=1.2555, Q2 Loss=1.2555, Entropy=0.6849, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0462
SAC Update 2/5: Actor Loss=-0.0139, Q1 Loss=1.1854, Q2 Loss=1.1854, Entropy=0.6923, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2471
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=0.9646, Q2 Loss=0.9646, Entropy=0.6884, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4659
SAC Update 4/5: Actor Loss=-0.0112, Q1 Loss=1.3137, Q2 Loss=1.3137, Entropy=0.6856, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7786
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=1.2112, Q2 Loss=1.2112, Entropy=0.6869, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0889

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.7%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (38.6%)
Target update: 0.01s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010736
Q1 loss: 1.186065
Q2 loss: 1.186065
Current threshold: -149.3000
Global Scale Offset: 381.8175
Reward stats: mean=0.0171, std=0.1327, count=272
----------------------------------------------
SAC Update - Actor Loss: -0.0107, Q1 Loss: 1.1861, Q2 Loss: 1.1861, Entropy: 0.6876, Mean TD Error: 0.7254, Threshold: -149.3000
tensor([ 0.0517,  0.5145,  0.5405,  0.7268, -0.0828,  0.4353,  0.9367,  0.5564,
         1.3853,  0.4233,  0.0571,  1.1136, -0.0393,  0.0326, -0.0649,  1.9352],
       device='cuda:1')
Original likelihood: -133.43905639648438
Adjusted likelihood: -133.43905639648438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5165)
Solve time for step 4 5.5401276589836925
Current ori: tensor([-0.0393,  0.0326, -0.0649], device='cuda:1')
Middle force: tensor([0.5057, 0.5953, 0.5251, 0.5311, 0.8399, 0.5602, 0.5127, 0.5409, 0.5052],
       device='cuda:1')
Thumb force: tensor([0.8469, 0.5019, 0.5649, 0.5450, 0.5442, 0.5472, 0.6040, 0.6243, 0.5948],
       device='cuda:1')
Index force: tensor([0.6454, 0.7160, 0.5704, 0.5135, 0.5934, 0.6091, 0.6460, 0.5971, 0.7186],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0019 (scaled=-0.0019), steps=1
Reward stats updated: mean 0.0171 -> 0.0170, std: 0.1324
Collected 273 transitions for RL
SAC Update 1/5: Actor Loss=-0.0067, Q1 Loss=0.6258, Q2 Loss=0.6258, Entropy=0.6904, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0949
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=1.2561, Q2 Loss=1.2561, Entropy=0.6715, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8843
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.0676, Q2 Loss=1.0676, Entropy=0.6875, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3478
SAC Update 4/5: Actor Loss=-0.0064, Q1 Loss=0.7114, Q2 Loss=0.7114, Entropy=0.6876, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3122
SAC Update 5/5: Actor Loss=-0.0123, Q1 Loss=1.3065, Q2 Loss=1.3065, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8776

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (22.1%)
Q1 update: 0.06s (18.8%)
Q2 update: 0.06s (17.7%)
Actor update: 0.13s (38.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009118
Q1 loss: 0.993475
Q2 loss: 0.993475
Current threshold: -149.2985
Global Scale Offset: 400.5167
Reward stats: mean=0.0170, std=0.1324, count=273
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9935, Q2 Loss: 0.9935, Entropy: 0.6859, Mean TD Error: 0.5033, Threshold: -149.2985
tensor([ 0.0787,  0.3770,  0.7357,  0.7464, -0.0525,  0.5318,  0.8485,  0.7195,
         1.3988,  0.3986,  0.0337,  1.1291, -0.0184,  0.0148, -0.0609,  1.7268],
       device='cuda:1')
Original likelihood: -122.46173858642578
Adjusted likelihood: -122.46173858642578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5266)
State is out of distribution
Final likelihood: tensor([ -2.7655,  -3.5810,  -3.5922,  -3.8958,  -4.9064,  -5.2155,  -5.5739,
         -5.8734,  -5.9362,  -5.9731,  -6.2570,  -6.7270,  -6.7904,  -7.0645,
         -7.5693, -11.2335], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.7655,  -3.5810,  -3.5922,  -3.8958,  -4.9064,  -5.2155,  -5.5739,
         -5.8734,  -5.9362,  -5.9731,  -6.2570,  -6.7270,  -6.7904,  -7.0645,
         -7.5693, -11.2335], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.8097
1 mode projection succeeded
New goal: tensor([ 0.0469,  0.5138,  0.6252,  0.5578, -0.0554,  0.5011,  0.8236,  0.8962,
         1.2925,  0.2833,  0.1929,  1.1763, -0.0017,  0.0142,  0.9252],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -98.09661865234375
Adjusted likelihood: -98.09661865234375
Likelihood residual: 0.0
Original likelihood: -135.53311157226562
Adjusted likelihood: -135.53311157226562
Likelihood residual: 0.0
{'index': 135.53311157226562, 'thumb_middle': 98.09661865234375}
Current yaw: tensor([-0.0184,  0.0148, -0.0609], device='cuda:1')
2 thumb_middle
tensor([ 0.0787,  0.3770,  0.7357,  0.7464, -0.0525,  0.5318,  0.8485,  0.7195,
         1.3988,  0.3986,  0.0337,  1.1291, -0.0184,  0.0148, -0.0609,  1.7268],
       device='cuda:1')
Solve time for step 1 9.721414180006832
Current ori: tensor([-0.0184,  0.0148, -0.0609], device='cuda:1')
Index force: tensor([0.6274, 0.6071, 0.5052, 0.6242], device='cuda:1')
tensor([ 0.0625,  0.4149,  0.7065,  0.6748, -0.1470,  0.4823,  0.7959,  0.8474,
         1.2655,  0.2824,  0.0917,  1.1379, -0.0348,  0.0329, -0.0610,  1.5889],
       device='cuda:1')
Solve time for step 2 4.005897022027057
Current ori: tensor([-0.0348,  0.0329, -0.0610], device='cuda:1')
Index force: tensor([0.5056, 0.6165, 0.6065], device='cuda:1')
tensor([ 0.0547,  0.4218,  0.7009,  0.6523, -0.1740,  0.4719,  0.7844,  0.8722,
         1.2642,  0.2657,  0.1194,  1.1511, -0.0355,  0.0543, -0.0610,  1.4419],
       device='cuda:1')
Solve time for step 3 3.7127300029969774
Current ori: tensor([-0.0355,  0.0543, -0.0610], device='cuda:1')
Index force: tensor([0.5999, 0.5913], device='cuda:1')
tensor([ 0.0506,  0.4671,  0.6588,  0.6085, -0.1913,  0.4671,  0.7802,  0.8674,
         1.2721,  0.2660,  0.1328,  1.1537, -0.0462,  0.0673, -0.0610,  1.3321],
       device='cuda:1')
Solve time for step 4 3.585038668010384
Current ori: tensor([-0.0462,  0.0673, -0.0610], device='cuda:1')
Index force: tensor([0.5700], device='cuda:1')
Storing RECOVERY transition: reward=0.0171 (scaled=0.0043), steps=4
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.1322
Collected 274 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=1.1992, Q2 Loss=1.1992, Entropy=0.6879, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1858
SAC Update 2/5: Actor Loss=-0.0107, Q1 Loss=1.3321, Q2 Loss=1.3321, Entropy=0.6857, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9954
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=0.9287, Q2 Loss=0.9287, Entropy=0.6927, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4013
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=1.4229, Q2 Loss=1.4229, Entropy=0.6925, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8942
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.8133, Q2 Loss=0.8133, Entropy=0.6921, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4916

------ SAC Update Summary (5 iterations) ------
Total time: 0.38s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (17.6%)
Q1 update: 0.08s (20.0%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (40.1%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009898
Q1 loss: 1.139210
Q2 loss: 1.139210
Current threshold: -149.2966
Global Scale Offset: 418.0455
Reward stats: mean=0.0170, std=0.1322, count=274
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.1392, Q2 Loss: 1.1392, Entropy: 0.6902, Mean TD Error: 0.9937, Threshold: -149.2966
Original likelihood: -143.87030029296875
Adjusted likelihood: -143.87030029296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5052)
State is out of distribution
Final likelihood: tensor([ -3.5679,  -4.1683,  -6.2403,  -6.6513,  -6.7979,  -8.2968,  -8.7012,
         -8.7120,  -9.0164,  -9.3641,  -9.3790, -12.2863, -12.4205, -13.2397,
        -16.8041, -18.6714], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -3.5679,  -4.1683,  -6.2403,  -6.6513,  -6.7979,  -8.2968,  -8.7012,
         -8.7120,  -9.0164,  -9.3641,  -9.3790, -12.2863, -12.4205, -13.2397,
        -16.8041, -18.6714], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -9.6448
1 mode projection succeeded
New goal: tensor([ 0.0582,  0.5437,  0.5528,  0.6342, -0.0107,  0.5155,  0.8597,  0.7456,
         1.3937,  0.1380,  0.1116,  1.1296, -0.0229, -0.0024,  0.0313],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -108.66223907470703
Adjusted likelihood: -108.66223907470703
Likelihood residual: 0.0
Original likelihood: -100.72356414794922
Adjusted likelihood: -100.72356414794922
Likelihood residual: 0.0
{'index': 100.72356414794922, 'thumb_middle': 108.66223907470703}
Current yaw: tensor([-0.0548,  0.0538, -0.0837], device='cuda:1')
3 index
tensor([ 0.0609,  0.4980,  0.6345,  0.5939, -0.1194,  0.5096,  0.8052,  0.8806,
         1.3394,  0.2967,  0.1780,  1.1620, -0.0548,  0.0538, -0.0837,  1.4423],
       device='cuda:1')
Solve time for step 1 11.330959245038684
Current ori: tensor([-0.0548,  0.0538, -0.0837], device='cuda:1')
Middle force: tensor([0.5105, 0.5279, 0.5372, 0.6138], device='cuda:1')
Thumb force: tensor([0.5044, 0.5406, 0.5425, 0.5801], device='cuda:1')
tensor([ 0.0951,  0.4777,  0.5113,  0.6011, -0.1103,  0.4929,  0.8703,  0.8010,
         1.4172,  0.1877,  0.1012,  1.1867, -0.0673,  0.0506, -0.1156,  0.7852],
       device='cuda:1')
Solve time for step 2 4.483435012982227
Current ori: tensor([-0.0673,  0.0506, -0.1156], device='cuda:1')
Middle force: tensor([0.5252, 0.5346, 0.6081], device='cuda:1')
Thumb force: tensor([0.5379, 0.5401, 0.5792], device='cuda:1')
tensor([ 0.0932,  0.4848,  0.5047,  0.6022, -0.0865,  0.5262,  0.8647,  0.7596,
         1.4201,  0.1704,  0.0724,  1.1831, -0.0820,  0.0349, -0.1177,  0.6010],
       device='cuda:1')
Solve time for step 3 4.467272892012261
Current ori: tensor([-0.0820,  0.0349, -0.1177], device='cuda:1')
Middle force: tensor([0.6004, 0.5527], device='cuda:1')
Thumb force: tensor([0.5336, 0.5006], device='cuda:1')
tensor([ 0.0924,  0.4868,  0.5005,  0.6047, -0.0790,  0.5295,  0.8681,  0.7567,
         1.4090,  0.1839,  0.0665,  1.1956, -0.0817,  0.0292, -0.1125,  0.8636],
       device='cuda:1')
Solve time for step 4 4.484462246997282
Current ori: tensor([-0.0817,  0.0292, -0.1125], device='cuda:1')
Middle force: tensor([0.5379], device='cuda:1')
Thumb force: tensor([0.5824], device='cuda:1')
Storing RECOVERY transition: reward=0.0492 (scaled=0.0123), steps=4
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.1319
Collected 275 transitions for RL
SAC Update 1/5: Actor Loss=-0.0133, Q1 Loss=1.1430, Q2 Loss=1.1430, Entropy=0.6814, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4891
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=1.0059, Q2 Loss=1.0059, Entropy=0.6907, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9454
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8363, Q2 Loss=0.8363, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5490
SAC Update 4/5: Actor Loss=-0.0095, Q1 Loss=0.8778, Q2 Loss=0.8778, Entropy=0.6900, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0788
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.8462, Q2 Loss=0.8462, Entropy=0.6894, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2397

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.06s (17.3%)
Q1 update: 0.07s (19.6%)
Q2 update: 0.07s (19.3%)
Actor update: 0.15s (40.8%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009605
Q1 loss: 0.941829
Q2 loss: 0.941829
Current threshold: -149.2949
Global Scale Offset: 431.0667
Reward stats: mean=0.0170, std=0.1319, count=275
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 0.9418, Q2 Loss: 0.9418, Entropy: 0.6888, Mean TD Error: 0.4604, Threshold: -149.2949
Original likelihood: -115.77105712890625
Adjusted likelihood: -115.77105712890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5309)
Current yaw: tensor([-0.0840,  0.0318, -0.1188], device='cuda:1')
4 turn
Sampling time 5.259438073961064
tensor([ 0.0493,  0.5440,  0.5385,  0.6280, -0.0821,  0.5264,  0.8704,  0.7591,
         1.4347,  0.1480,  0.0442,  1.2053, -0.0840,  0.0318, -0.1188,  1.0009],
       device='cuda:1')
Original likelihood: -119.59918212890625
Adjusted likelihood: -119.59918212890625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5274)
State is out of distribution
Final likelihood: tensor([ -6.0577,  -6.8044,  -6.8625,  -6.9011,  -7.0839,  -7.1356,  -7.2776,
         -8.0481,  -8.3966,  -8.4278,  -8.4955,  -8.6007,  -8.6649,  -8.9908,
         -9.2932, -13.6013], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -6.0577,  -6.8044,  -6.8625,  -6.9011,  -7.0839,  -7.1356,  -7.2776,
         -8.0481,  -8.3966,  -8.4278,  -8.4955,  -8.6007,  -8.6649,  -8.9908,
         -9.2932, -13.6013], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -8.1651
1 mode projection succeeded
New goal: tensor([ 0.0495,  0.5822,  0.4992,  0.6201, -0.0315,  0.4829,  0.8916,  0.8255,
         1.3312,  0.2964,  0.1552,  1.0715, -0.0294,  0.0023, -0.3207],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -104.3687973022461
Adjusted likelihood: -104.3687973022461
Likelihood residual: 0.0
Original likelihood: -104.41767120361328
Adjusted likelihood: -104.41767120361328
Likelihood residual: 0.0
{'index': 104.41767120361328, 'thumb_middle': 104.3687973022461}
Current yaw: tensor([-0.0840,  0.0318, -0.1188], device='cuda:1')
5 thumb_middle
tensor([ 0.0493,  0.5440,  0.5385,  0.6280, -0.0821,  0.5264,  0.8704,  0.7591,
         1.4347,  0.1480,  0.0442,  1.2053, -0.0840,  0.0318, -0.1188,  1.0009],
       device='cuda:1')
Solve time for step 1 9.521138828014955
Current ori: tensor([-0.0840,  0.0318, -0.1188], device='cuda:1')
Index force: tensor([0.5843, 0.5886, 0.5739, 0.5940], device='cuda:1')
tensor([ 0.0468,  0.5512,  0.5230,  0.6337, -0.1529,  0.4580,  0.8624,  0.8021,
         1.3131,  0.2551,  0.0788,  1.0653, -0.0851,  0.0417, -0.1188,  0.9057],
       device='cuda:1')
Solve time for step 2 4.0160476750461385
Current ori: tensor([-0.0851,  0.0417, -0.1188], device='cuda:1')
Index force: tensor([0.5784, 0.5678, 0.5862], device='cuda:1')
tensor([ 0.0679,  0.5660,  0.5115,  0.6562, -0.1280,  0.4537,  0.8534,  0.8166,
         1.3031,  0.2783,  0.0727,  1.0463, -0.0866,  0.0264, -0.1188,  0.9476],
       device='cuda:1')
Solve time for step 3 3.9548343389760703
Current ori: tensor([-0.0866,  0.0264, -0.1188], device='cuda:1')
Index force: tensor([0.5583, 0.5779], device='cuda:1')
tensor([ 0.0800,  0.5717,  0.5161,  0.6545, -0.1208,  0.4636,  0.8596,  0.8095,
         1.2898,  0.2625,  0.0820,  1.0453, -0.0880,  0.0161, -0.1188,  0.9904],
       device='cuda:1')
Solve time for step 4 3.8868317020242102
Current ori: tensor([-0.0880,  0.0161, -0.1188], device='cuda:1')
Index force: tensor([0.5570], device='cuda:1')
Storing RECOVERY transition: reward=0.0121 (scaled=0.0121), steps=0
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.1317
Collected 276 transitions for RL
SAC Update 1/5: Actor Loss=-0.0128, Q1 Loss=1.2561, Q2 Loss=1.2561, Entropy=0.6920, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5415
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=0.8453, Q2 Loss=0.8453, Entropy=0.6912, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4572
SAC Update 3/5: Actor Loss=-0.0087, Q1 Loss=1.4370, Q2 Loss=1.4370, Entropy=0.6695, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2494
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=1.0032, Q2 Loss=1.0032, Entropy=0.6885, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3936
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.4904, Q2 Loss=1.4904, Entropy=0.6901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7454

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.07s (20.0%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.06s (18.4%)
Actor update: 0.12s (37.8%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009604
Q1 loss: 1.206406
Q2 loss: 1.206406
Current threshold: -149.2933
Global Scale Offset: 446.7405
Reward stats: mean=0.0170, std=0.1317, count=276
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.2064, Q2 Loss: 1.2064, Entropy: 0.6863, Mean TD Error: 1.0774, Threshold: -149.2933
Original likelihood: -91.58187866210938
Adjusted likelihood: -91.58187866210938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5512)
State is out of distribution
Final likelihood: tensor([ -6.1043,  -6.8141,  -7.1481,  -7.1873,  -7.3938,  -7.5796,  -7.6210,
         -7.6690,  -7.7773,  -7.9662,  -8.1103,  -8.2424,  -8.8710,  -9.1804,
         -9.8350, -10.7512], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -6.1043,  -6.8141,  -7.1481,  -7.1873,  -7.3938,  -7.5796,  -7.6210,
         -7.6690,  -7.7773,  -7.9662,  -8.1103,  -8.2424,  -8.8710,  -9.1804,
         -9.8350, -10.7512], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -8.0157
1 mode projection succeeded
New goal: tensor([ 0.0494,  0.5826,  0.4970,  0.6224, -0.0315,  0.4847,  0.8898,  0.8256,
         1.3301,  0.2974,  0.1567,  1.0704, -0.0295,  0.0022, -0.0123],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -97.765625
Adjusted likelihood: -97.765625
Likelihood residual: 0.0
Original likelihood: -77.26278686523438
Adjusted likelihood: -77.26278686523438
Likelihood residual: 0.0
{'index': 77.26278686523438, 'thumb_middle': 97.765625}
Current yaw: tensor([-0.0857,  0.0151, -0.1306], device='cuda:1')
6 index
tensor([ 0.0637,  0.5574,  0.5244,  0.6459, -0.0570,  0.5115,  0.8886,  0.8309,
         1.3592,  0.3027,  0.1191,  1.0565, -0.0857,  0.0151, -0.1306,  1.0819],
       device='cuda:1')
Solve time for step 1 11.395694967010058
Current ori: tensor([-0.0857,  0.0151, -0.1306], device='cuda:1')
Middle force: tensor([0.5098, 0.5850, 0.5663, 0.5671], device='cuda:1')
Thumb force: tensor([0.5005, 0.5257, 0.6180, 0.5733], device='cuda:1')
tensor([ 0.0891,  0.5234,  0.4538,  0.6003, -0.0685,  0.5333,  0.9039,  0.8267,
         1.3789,  0.2743,  0.1127,  1.0293, -0.1095,  0.0170, -0.0895,  1.2981],
       device='cuda:1')
Solve time for step 2 4.574202513031196
Current ori: tensor([-0.1095,  0.0170, -0.0895], device='cuda:1')
Middle force: tensor([0.5794, 0.5618, 0.5638], device='cuda:1')
Thumb force: tensor([0.5238, 0.6131, 0.5695], device='cuda:1')
tensor([ 0.0828,  0.5309,  0.4504,  0.5945, -0.0585,  0.5448,  0.9344,  0.8530,
         1.3631,  0.2997,  0.1073,  1.0419, -0.1371,  0.0147, -0.0636,  1.7072],
       device='cuda:1')
Solve time for step 3 4.4071137820137665
Current ori: tensor([-0.1371,  0.0147, -0.0636], device='cuda:1')
Middle force: tensor([0.5147, 0.5362], device='cuda:1')
Thumb force: tensor([0.5988, 0.5697], device='cuda:1')
tensor([ 0.0794,  0.5437,  0.4535,  0.5945, -0.0545,  0.5695,  0.9540,  0.8637,
         1.3718,  0.3197,  0.0832,  1.0355, -0.1754,  0.0164, -0.0584,  2.0554],
       device='cuda:1')
Solve time for step 4 4.3567996300407685
Current ori: tensor([-0.1754,  0.0164, -0.0584], device='cuda:1')
Middle force: tensor([0.5440], device='cuda:1')
Thumb force: tensor([0.5860], device='cuda:1')
Storing RECOVERY transition: reward=-0.1702 (scaled=-0.1702), steps=0
Reward stats updated: mean 0.0170 -> 0.0163, std: 0.1319
Collected 277 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=1.0464, Q2 Loss=1.0464, Entropy=0.6898, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4629
SAC Update 2/5: Actor Loss=-0.0118, Q1 Loss=1.2296, Q2 Loss=1.2296, Entropy=0.6876, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4354
SAC Update 3/5: Actor Loss=-0.0066, Q1 Loss=0.6766, Q2 Loss=0.6766, Entropy=0.6893, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2164
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=1.0843, Q2 Loss=1.0843, Entropy=0.6922, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7764
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.9914, Q2 Loss=0.9914, Entropy=0.6826, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8164

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (22.9%)
Q1 update: 0.06s (17.7%)
Q2 update: 0.06s (17.8%)
Actor update: 0.13s (37.4%)
Target update: 0.01s (2.0%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008648
Q1 loss: 1.005640
Q2 loss: 1.005640
Current threshold: -149.2917
Global Scale Offset: 464.2712
Reward stats: mean=0.0163, std=0.1319, count=277
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.0056, Q2 Loss: 1.0056, Entropy: 0.6883, Mean TD Error: 0.7415, Threshold: -149.2917
Original likelihood: -956.1343994140625
Adjusted likelihood: -956.1343994140625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0416)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 20
Loaded trajectory sampler
Current yaw: tensor([-0.0007,  0.0148, -0.0295], device='cuda:1')
Current yaw: tensor([-0.0007,  0.0148, -0.0295], device='cuda:1')
1 turn
Sampling time 5.212438528018538
tensor([ 1.5314e-01,  5.9259e-01,  5.9137e-01,  6.1346e-01, -1.3640e-01,
         5.6982e-01,  8.9077e-01,  8.9059e-01,  1.2477e+00,  2.8045e-01,
         2.3069e-01,  1.1935e+00, -6.9173e-04,  1.4781e-02, -2.9531e-02,
         1.4929e-01], device='cuda:1')
Original likelihood: -106.95858764648438
Adjusted likelihood: -106.95858764648438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5362)
State is out of distribution
Final likelihood: tensor([-2.4514, -2.8189, -3.0677, -3.1159, -3.5000, -3.5985, -3.8159, -3.8493,
        -4.2807, -4.3186, -4.3327, -4.4225, -4.4495, -4.5089, -4.6977, -5.2041],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.4514, -2.8189, -3.0677, -3.1159, -3.5000, -3.5985, -3.8159, -3.8493,
        -4.2807, -4.3186, -4.3327, -4.4225, -4.4495, -4.5089, -4.6977, -5.2041],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -3.9020
1 mode projection succeeded
New goal: tensor([ 0.0394,  0.5358,  0.5421,  0.6481, -0.0565,  0.5216,  0.8119,  0.8573,
         1.2741,  0.3057,  0.2129,  1.1675,  0.0040,  0.0146, -0.7099],
       device='cuda:1')
tensor([[0.0034]], device='cuda:1') tensor([[0.0014]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -77.25044250488281
Adjusted likelihood: -77.25044250488281
Likelihood residual: 0.0
Original likelihood: -138.12271118164062
Adjusted likelihood: -138.12271118164062
Likelihood residual: 0.0
{'index': 138.12271118164062, 'thumb_middle': 77.25044250488281}
Current yaw: tensor([-0.0007,  0.0148, -0.0295], device='cuda:1')
2 thumb_middle
tensor([ 1.5314e-01,  5.9259e-01,  5.9137e-01,  6.1346e-01, -1.3640e-01,
         5.6982e-01,  8.9077e-01,  8.9059e-01,  1.2477e+00,  2.8045e-01,
         2.3069e-01,  1.1935e+00, -6.9173e-04,  1.4781e-02, -2.9531e-02,
         1.4929e-01], device='cuda:1')
Solve time for step 1 9.573296048969496
Current ori: tensor([-0.0007,  0.0148, -0.0295], device='cuda:1')
Index force: tensor([0.5619, 0.5684, 0.5035, 0.6004], device='cuda:1')
tensor([ 0.1212,  0.5562,  0.5801,  0.6675, -0.1898,  0.5007,  0.7775,  0.8359,
         1.2392,  0.2782,  0.1631,  1.1489,  0.0105,  0.0318, -0.0293,  0.2164],
       device='cuda:1')
Solve time for step 2 3.827923444972839
Current ori: tensor([ 0.0105,  0.0318, -0.0293], device='cuda:1')
Index force: tensor([0.5614, 0.5001, 0.5726], device='cuda:1')
tensor([ 0.0962,  0.5381,  0.5544,  0.7182, -0.1977,  0.4917,  0.7674,  0.8353,
         1.2617,  0.2874,  0.1515,  1.1475,  0.0195,  0.0468, -0.0293,  0.1970],
       device='cuda:1')
Solve time for step 3 3.6722899530432187
Current ori: tensor([ 0.0195,  0.0468, -0.0293], device='cuda:1')
Index force: tensor([0.5001, 0.5578], device='cuda:1')
tensor([ 0.0929,  0.5448,  0.5526,  0.6962, -0.1971,  0.4967,  0.7593,  0.8196,
         1.2642,  0.2902,  0.1503,  1.1488,  0.0163,  0.0483, -0.0293,  0.1832],
       device='cuda:1')
Solve time for step 4 3.7958143139840104
Current ori: tensor([ 0.0163,  0.0483, -0.0293], device='cuda:1')
Index force: tensor([0.5391], device='cuda:1')
Storing RECOVERY transition: reward=0.0213 (scaled=0.0213), steps=0
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.1317
Collected 278 transitions for RL
SAC Update 1/5: Actor Loss=-0.0115, Q1 Loss=1.0248, Q2 Loss=1.0248, Entropy=0.6929, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1037
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=1.9956, Q2 Loss=1.9956, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5261
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.9373, Q2 Loss=0.9373, Entropy=0.6839, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8413
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.8184, Q2 Loss=0.8184, Entropy=0.6773, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6034
SAC Update 5/5: Actor Loss=-0.0098, Q1 Loss=0.9554, Q2 Loss=0.9554, Entropy=0.6921, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5504

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (17.9%)
Q1 update: 0.07s (19.2%)
Q2 update: 0.07s (19.0%)
Actor update: 0.15s (41.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009337
Q1 loss: 1.146286
Q2 loss: 1.146286
Current threshold: -149.2903
Global Scale Offset: 481.4679
Reward stats: mean=0.0163, std=0.1317, count=278
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.1463, Q2 Loss: 1.1463, Entropy: 0.6878, Mean TD Error: 0.9250, Threshold: -149.2903
Original likelihood: -179.54083251953125
Adjusted likelihood: -179.54083251953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4750)
State is out of distribution
Final likelihood: tensor([-2.8879, -2.9575, -3.0473, -3.0745, -3.4821, -3.6342, -3.7129, -3.7949,
        -3.8030, -3.8031, -3.9788, -4.5353, -5.3828, -5.8091, -6.0740, -6.7905],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8879, -2.9575, -3.0473, -3.0745, -3.4821, -3.6342, -3.7129, -3.7949,
        -3.8030, -3.8031, -3.9788, -4.5353, -5.3828, -5.8091, -6.0740, -6.7905],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.1730
1 mode projection succeeded
New goal: tensor([ 0.0910,  0.5437,  0.6045,  0.5994, -0.0742,  0.5125,  0.8146,  0.9459,
         1.2745,  0.2956,  0.2043,  1.1886,  0.0053,  0.0142,  1.6245],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -101.74557495117188
Adjusted likelihood: -101.74557495117188
Likelihood residual: 0.0
Original likelihood: -104.9293441772461
Adjusted likelihood: -104.9293441772461
Likelihood residual: 0.0
{'index': 104.9293441772461, 'thumb_middle': 101.74557495117188}
Current yaw: tensor([ 0.0102,  0.0429, -0.0526], device='cuda:1')
3 thumb_middle
tensor([ 0.0987,  0.5589,  0.5616,  0.6529, -0.1256,  0.5434,  0.7927,  0.8583,
         1.3250,  0.3223,  0.2028,  1.1460,  0.0102,  0.0429, -0.0526,  0.2343],
       device='cuda:1')
Solve time for step 1 9.398449980013538
Current ori: tensor([ 0.0102,  0.0429, -0.0526], device='cuda:1')
Index force: tensor([0.5560, 0.5667, 0.5707, 0.5031], device='cuda:1')
tensor([ 0.1206,  0.5550,  0.6038,  0.6230, -0.1791,  0.4816,  0.7733,  0.9082,
         1.2475,  0.2751,  0.1349,  1.1633,  0.0071,  0.0312, -0.0526,  0.2342],
       device='cuda:1')
Solve time for step 2 3.90012728900183
Current ori: tensor([ 0.0071,  0.0312, -0.0526], device='cuda:1')
Index force: tensor([0.5000, 0.5860, 0.5898], device='cuda:1')
tensor([ 0.1148,  0.5631,  0.5953,  0.6053, -0.1963,  0.4814,  0.7703,  0.9161,
         1.2507,  0.2777,  0.1363,  1.1633,  0.0041,  0.0340, -0.0526,  0.2175],
       device='cuda:1')
Solve time for step 3 3.930843123001978
Current ori: tensor([ 0.0041,  0.0340, -0.0526], device='cuda:1')
Index force: tensor([0.5350, 0.5641], device='cuda:1')
tensor([ 0.1171,  0.5701,  0.5925,  0.5978, -0.1920,  0.4902,  0.7689,  0.9146,
         1.2499,  0.2657,  0.1340,  1.1603,  0.0017,  0.0322, -0.0526,  0.2195],
       device='cuda:1')
Solve time for step 4 3.5404985490022227
Current ori: tensor([ 0.0017,  0.0322, -0.0526], device='cuda:1')
Index force: tensor([0.5491], device='cuda:1')
Storing RECOVERY transition: reward=0.0262 (scaled=0.0262), steps=0
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.1315
Collected 279 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7898, Q2 Loss=0.7898, Entropy=0.6914, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7082
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.6248, Q2 Loss=0.6248, Entropy=0.6916, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0874
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.1131, Q2 Loss=1.1131, Entropy=0.6912, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7462
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.7813, Q2 Loss=0.7813, Entropy=0.6877, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3275
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=0.7838, Q2 Loss=0.7838, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9450

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.6%)
Q1 update: 0.07s (18.5%)
Q2 update: 0.06s (17.3%)
Actor update: 0.14s (39.0%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008041
Q1 loss: 0.818558
Q2 loss: 0.818558
Current threshold: -149.2893
Global Scale Offset: 498.2275
Reward stats: mean=0.0163, std=0.1315, count=279
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 0.8186, Q2 Loss: 0.8186, Entropy: 0.6910, Mean TD Error: 0.7629, Threshold: -149.2893
Original likelihood: -140.29791259765625
Adjusted likelihood: -140.29791259765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5072)
State is out of distribution
Final likelihood: tensor([-3.0860, -3.2231, -3.4068, -3.4181, -3.4485, -3.6664, -3.8401, -4.0596,
        -4.1619, -4.4959, -4.7227, -5.0542, -5.0926, -5.2512, -6.3046, -6.5545],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.0860, -3.2231, -3.4068, -3.4181, -3.4485, -3.6664, -3.8401, -4.0596,
        -4.1619, -4.4959, -4.7227, -5.0542, -5.0926, -5.2512, -6.3046, -6.5545],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3616
1 mode projection succeeded
New goal: tensor([ 0.0908,  0.5444,  0.6034,  0.5986, -0.0740,  0.5116,  0.8147,  0.9471,
         1.2751,  0.2956,  0.2045,  1.1883,  0.0052,  0.0142, -0.3835],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -111.50550842285156
Adjusted likelihood: -111.50550842285156
Likelihood residual: 0.0
Original likelihood: -81.76683044433594
Adjusted likelihood: -81.76683044433594
Likelihood residual: 0.0
{'index': 81.76683044433594, 'thumb_middle': 111.50550842285156}
Current yaw: tensor([ 0.0052,  0.0343, -0.0567], device='cuda:1')
4 index
tensor([ 0.1127,  0.5588,  0.5994,  0.6060, -0.1235,  0.5303,  0.8042,  0.9345,
         1.3055,  0.3075,  0.1953,  1.1909,  0.0052,  0.0343, -0.0567,  0.2474],
       device='cuda:1')
Solve time for step 1 11.56115292996401
Current ori: tensor([ 0.0052,  0.0343, -0.0567], device='cuda:1')
Middle force: tensor([0.5697, 0.5410, 0.5819, 0.5581], device='cuda:1')
Thumb force: tensor([0.5642, 0.5699, 0.5335, 0.6204], device='cuda:1')
tensor([ 0.1370,  0.4912,  0.5528,  0.5757, -0.1236,  0.5235,  0.8146,  0.9449,
         1.3162,  0.2956,  0.1925,  1.1764,  0.0048,  0.0328, -0.0872,  2.7049],
       device='cuda:1')
Solve time for step 2 4.836606321041472
Current ori: tensor([ 0.0048,  0.0328, -0.0872], device='cuda:1')
Middle force: tensor([0.5382, 0.5785, 0.5559], device='cuda:1')
Thumb force: tensor([0.5649, 0.5320, 0.6162], device='cuda:1')
tensor([ 0.1371,  0.4903,  0.5526,  0.5757, -0.1081,  0.5272,  0.8210,  0.9497,
         1.3113,  0.2954,  0.1729,  1.1943,  0.0049,  0.0222, -0.0984,  4.1521],
       device='cuda:1')
Solve time for step 3 4.570590539020486
Current ori: tensor([ 0.0049,  0.0222, -0.0984], device='cuda:1')
Middle force: tensor([0.5731, 0.6062], device='cuda:1')
Thumb force: tensor([0.5504, 0.5503], device='cuda:1')
tensor([ 1.3646e-01,  4.8997e-01,  5.5295e-01,  5.7397e-01, -1.0286e-01,
         5.3253e-01,  8.2399e-01,  9.5013e-01,  1.3001e+00,  3.0755e-01,
         1.7036e-01,  1.1998e+00,  4.6125e-03,  1.7076e-02, -9.9687e-02,
         5.0933e+00], device='cuda:1')
Solve time for step 4 4.573246904008556
Current ori: tensor([ 0.0046,  0.0171, -0.0997], device='cuda:1')
Middle force: tensor([0.5180], device='cuda:1')
Thumb force: tensor([0.5964], device='cuda:1')
Storing RECOVERY transition: reward=0.0629 (scaled=0.0629), steps=0
Reward stats updated: mean 0.0163 -> 0.0165, std: 0.1313
Collected 280 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.0406, Q2 Loss=1.0406, Entropy=0.6920, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6736
SAC Update 2/5: Actor Loss=-0.0129, Q1 Loss=1.2778, Q2 Loss=1.2778, Entropy=0.6921, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6027
SAC Update 3/5: Actor Loss=-0.0124, Q1 Loss=1.3061, Q2 Loss=1.3061, Entropy=0.6924, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8356
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=0.7026, Q2 Loss=0.7026, Entropy=0.6907, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9211
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.7148, Q2 Loss=0.7148, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4284

------ SAC Update Summary (5 iterations) ------
Total time: 0.35s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (19.1%)
Q1 update: 0.07s (19.1%)
Q2 update: 0.07s (19.1%)
Actor update: 0.14s (39.4%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010078
Q1 loss: 1.008382
Q2 loss: 1.008382
Current threshold: -149.2885
Global Scale Offset: 513.7616
Reward stats: mean=0.0165, std=0.1313, count=280
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0084, Q2 Loss: 1.0084, Entropy: 0.6921, Mean TD Error: 0.6923, Threshold: -149.2885
Original likelihood: -62.99165344238281
Adjusted likelihood: -62.99165344238281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5665)
State is out of distribution
Final likelihood: tensor([-3.1693, -3.2053, -3.2828, -3.6074, -3.7167, -3.7311, -3.8394, -3.8783,
        -3.9081, -4.0163, -4.0230, -4.1199, -4.1657, -5.1424, -5.3169, -6.2342],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-3.1693, -3.2053, -3.2828, -3.6074, -3.7167, -3.7311, -3.8394, -3.8783,
        -3.9081, -4.0163, -4.0230, -4.1199, -4.1657, -5.1424, -5.3169, -6.2342],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.0848
1 mode projection succeeded
New goal: tensor([ 0.0905,  0.5443,  0.6041,  0.5990, -0.0740,  0.5117,  0.8157,  0.9459,
         1.2751,  0.2944,  0.2046,  1.1889,  0.0054,  0.0142, -0.0638],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -67.67721557617188
Adjusted likelihood: -67.67721557617188
Likelihood residual: 0.0
Original likelihood: -62.84048843383789
Adjusted likelihood: -62.84048843383789
Likelihood residual: 0.0
{'index': 62.84048843383789, 'thumb_middle': 67.67721557617188}
Current yaw: tensor([ 0.0033,  0.0199, -0.0927], device='cuda:1')
5 index
tensor([ 8.6110e-02,  5.4879e-01,  5.9525e-01,  5.9421e-01, -1.0764e-01,
         5.3579e-01,  8.1989e-01,  9.4440e-01,  1.3041e+00,  3.0357e-01,
         1.7348e-01,  1.1942e+00,  3.2846e-03,  1.9881e-02, -9.2674e-02,
         5.3052e+00], device='cuda:1')
Solve time for step 1 11.985581778979395
Current ori: tensor([ 0.0033,  0.0199, -0.0927], device='cuda:1')
Middle force: tensor([0.5843, 0.5481, 0.5354, 0.5539], device='cuda:1')
Thumb force: tensor([0.5567, 0.5340, 0.6615, 0.5618], device='cuda:1')
tensor([ 1.3675e-01,  4.9144e-01,  5.5264e-01,  5.7473e-01, -1.0804e-01,
         5.2391e-01,  8.3123e-01,  9.5946e-01,  1.3096e+00,  2.9979e-01,
         1.7426e-01,  1.1858e+00,  5.3456e-03,  1.9719e-02, -1.2309e-01,
         5.7551e+00], device='cuda:1')
Solve time for step 2 4.563637282000855
Current ori: tensor([ 0.0053,  0.0197, -0.1231], device='cuda:1')
Middle force: tensor([0.5457, 0.5330, 0.5509], device='cuda:1')
Thumb force: tensor([0.5310, 0.6570, 0.5598], device='cuda:1')
tensor([ 1.3842e-01,  4.9037e-01,  5.5386e-01,  5.7456e-01, -9.3909e-02,
         5.3678e-01,  8.2776e-01,  9.5047e-01,  1.3019e+00,  3.0670e-01,
         1.6345e-01,  1.1871e+00,  7.1742e-04,  1.0801e-02, -1.2895e-01,
         6.0807e+00], device='cuda:1')
Solve time for step 3 4.422480212990195
Current ori: tensor([ 0.0007,  0.0108, -0.1290], device='cuda:1')
Middle force: tensor([0.5062, 0.6132], device='cuda:1')
Thumb force: tensor([0.6213, 0.5278], device='cuda:1')
tensor([ 0.1362,  0.4892,  0.5530,  0.5757, -0.1052,  0.5193,  0.8388,  0.9664,
         1.3085,  0.2993,  0.1710,  1.1906,  0.0075,  0.0173, -0.1317, -6.2628],
       device='cuda:1')
Solve time for step 4 4.691041951009538
Current ori: tensor([ 0.0075,  0.0173, -0.1317], device='cuda:1')
Middle force: tensor([0.6046], device='cuda:1')
Thumb force: tensor([0.5223], device='cuda:1')
Storing RECOVERY transition: reward=0.0976 (scaled=0.0976), steps=0
Reward stats updated: mean 0.0165 -> 0.0168, std: 0.1311
Collected 281 transitions for RL
SAC Update 1/5: Actor Loss=-0.0063, Q1 Loss=1.2355, Q2 Loss=1.2355, Entropy=0.6887, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0583
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=1.3496, Q2 Loss=1.3496, Entropy=0.6898, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1055
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=1.0941, Q2 Loss=1.0941, Entropy=0.6918, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9538
SAC Update 4/5: Actor Loss=-0.0105, Q1 Loss=1.5854, Q2 Loss=1.5854, Entropy=0.6924, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6792
SAC Update 5/5: Actor Loss=-0.0066, Q1 Loss=0.6812, Q2 Loss=0.6812, Entropy=0.6859, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7735

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.08s (21.8%)
Q1 update: 0.07s (18.3%)
Q2 update: 0.07s (17.9%)
Actor update: 0.14s (38.1%)
Target update: 0.01s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008599
Q1 loss: 1.189140
Q2 loss: 1.189140
Current threshold: -149.2879
Global Scale Offset: 528.5750
Reward stats: mean=0.0168, std=0.1311, count=281
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1891, Q2 Loss: 1.1891, Entropy: 0.6897, Mean TD Error: 1.9141, Threshold: -149.2879
Original likelihood: -64.93452453613281
Adjusted likelihood: -64.93452453613281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5632)
Current yaw: tensor([ 0.0004,  0.0131, -0.1271], device='cuda:1')
6 turn
Sampling time 5.077873464033473
tensor([ 8.8505e-02,  5.5136e-01,  5.9461e-01,  5.9359e-01, -9.9248e-02,
         5.3809e-01,  8.2801e-01,  9.4758e-01,  1.3072e+00,  3.0128e-01,
         1.6471e-01,  1.1833e+00,  3.9414e-04,  1.3107e-02, -1.2713e-01,
        -6.2174e+00], device='cuda:1')
Original likelihood: -59.01068115234375
Adjusted likelihood: -59.01068115234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5676)
Solve time for step 1 15.945605249027722
Current ori: tensor([ 0.0004,  0.0131, -0.1271], device='cuda:1')
Middle force: tensor([1.3068, 0.5103, 0.5030, 0.5226, 0.6114, 0.6122, 1.0792, 0.8184, 0.8318,
        0.6126, 0.5577, 0.5297], device='cuda:1')
Thumb force: tensor([1.8985, 2.0019, 1.4311, 0.5629, 1.1104, 0.8016, 1.4843, 0.5802, 0.7242,
        0.7003, 0.5591, 0.6001], device='cuda:1')
Index force: tensor([0.5693, 0.8585, 0.7969, 0.6554, 0.5796, 0.5598, 0.5959, 0.5309, 0.5961,
        0.5739, 0.6758, 0.7025], device='cuda:1')
Storing NORMAL transition: reward=0.1463 (scaled=0.1463), steps=1
Reward stats updated: mean 0.0168 -> 0.0172, std: 0.1311
Collected 282 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7513, Q2 Loss=0.7513, Entropy=0.6921, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7651
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=1.3119, Q2 Loss=1.3119, Entropy=0.6891, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7297
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.8756, Q2 Loss=0.8756, Entropy=0.6927, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7665
SAC Update 4/5: Actor Loss=-0.0060, Q1 Loss=0.6194, Q2 Loss=0.6194, Entropy=0.6880, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0930
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=1.1312, Q2 Loss=1.1312, Entropy=0.6912, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5231

------ SAC Update Summary (5 iterations) ------
Total time: 0.39s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.07s (19.4%)
Q1 update: 0.08s (19.5%)
Q2 update: 0.07s (18.7%)
Actor update: 0.15s (39.3%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008673
Q1 loss: 0.937892
Q2 loss: 0.937892
Current threshold: -149.2872
Global Scale Offset: 544.2446
Reward stats: mean=0.0172, std=0.1311, count=282
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 0.9379, Q2 Loss: 0.9379, Entropy: 0.6906, Mean TD Error: 0.7755, Threshold: -149.2872
tensor([ 5.3738e-02,  5.6372e-01,  5.8359e-01,  5.0477e-01, -3.7236e-02,
         3.4070e-01,  9.3601e-01,  1.2298e+00,  1.3549e+00,  1.9456e-01,
         1.6643e-01,  1.1458e+00,  3.0585e-02,  3.6072e-03, -2.7455e-01,
        -5.2377e+00], device='cuda:1')
Original likelihood: -113.8150634765625
Adjusted likelihood: -113.8150634765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5259)
State is out of distribution
Final likelihood: tensor([-2.8356, -3.9171, -4.2636, -4.5242, -4.5989, -4.9379, -5.0910, -5.0956,
        -5.3632, -5.4804, -5.5272, -5.6586, -5.7224, -5.7240, -7.6000, -7.7900],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8356, -3.9171, -4.2636, -4.5242, -4.5989, -4.9379, -5.0910, -5.0956,
        -5.3632, -5.4804, -5.5272, -5.6586, -5.7224, -5.7240, -7.6000, -7.7900],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -5.2581
1 mode projection succeeded
New goal: tensor([ 0.0217,  0.5347,  0.5576,  0.5856, -0.0724,  0.4909,  0.8485,  0.9316,
         1.2846,  0.3071,  0.1842,  1.2017,  0.0052,  0.0145, -1.2871],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -99.34092712402344
Adjusted likelihood: -99.34092712402344
Likelihood residual: 0.0
Original likelihood: -135.76820373535156
Adjusted likelihood: -135.76820373535156
Likelihood residual: 0.0
{'index': 135.76820373535156, 'thumb_middle': 99.34092712402344}
Current yaw: tensor([ 0.0306,  0.0036, -0.2746], device='cuda:1')
7 thumb_middle
tensor([ 5.3738e-02,  5.6372e-01,  5.8359e-01,  5.0477e-01, -3.7236e-02,
         3.4070e-01,  9.3601e-01,  1.2298e+00,  1.3549e+00,  1.9456e-01,
         1.6643e-01,  1.1458e+00,  3.0585e-02,  3.6072e-03, -2.7455e-01,
        -5.2377e+00], device='cuda:1')
Solve time for step 1 10.016306097968481
Current ori: tensor([ 0.0306,  0.0036, -0.2746], device='cuda:1')
Index force: tensor([0.5818, 0.5783, 0.5694, 0.5878], device='cuda:1')
tensor([ 0.0276,  0.5609,  0.5487,  0.5354, -0.1729,  0.4382,  0.8319,  0.9652,
         1.2562,  0.2752,  0.1139,  1.1693,  0.0337,  0.0176, -0.2745, -5.2674],
       device='cuda:1')
Solve time for step 2 3.8072956500109285
Current ori: tensor([ 0.0337,  0.0176, -0.2745], device='cuda:1')
Index force: tensor([0.5682, 0.5617, 0.5800], device='cuda:1')
tensor([ 0.0309,  0.5565,  0.5434,  0.5635, -0.1848,  0.4792,  0.8235,  0.9166,
         1.2510,  0.2751,  0.1123,  1.1712,  0.0374,  0.0165, -0.2745, -5.2510],
       device='cuda:1')
Solve time for step 3 3.8762941880268045
Current ori: tensor([ 0.0374,  0.0165, -0.2745], device='cuda:1')
Index force: tensor([0.5498, 0.5693], device='cuda:1')
tensor([ 0.0267,  0.5550,  0.5403,  0.5661, -0.1810,  0.4711,  0.8226,  0.9058,
         1.2471,  0.2926,  0.1091,  1.1819,  0.0380,  0.0187, -0.2745, -5.2549],
       device='cuda:1')
Solve time for step 4 3.597240510978736
Current ori: tensor([ 0.0380,  0.0187, -0.2745], device='cuda:1')
Index force: tensor([0.5543], device='cuda:1')
Storing RECOVERY transition: reward=-0.0017 (scaled=-0.0017), steps=1
Reward stats updated: mean 0.0172 -> 0.0172, std: 0.1309
Collected 283 transitions for RL
SAC Update 1/5: Actor Loss=-0.0068, Q1 Loss=1.1673, Q2 Loss=1.1673, Entropy=0.6909, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0574
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=0.8305, Q2 Loss=0.8305, Entropy=0.6878, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7181
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.0473, Q2 Loss=1.0473, Entropy=0.6908, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6324
SAC Update 4/5: Actor Loss=-0.0106, Q1 Loss=0.8578, Q2 Loss=0.8578, Entropy=0.6892, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6425
SAC Update 5/5: Actor Loss=-0.0065, Q1 Loss=0.8122, Q2 Loss=0.8122, Entropy=0.6883, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0086

------ SAC Update Summary (5 iterations) ------
Total time: 0.37s, Avg iteration: 0.07s
Sampling: 0.00s (0.4%)
Target Q: 0.07s (18.0%)
Q1 update: 0.07s (19.0%)
Q2 update: 0.07s (19.8%)
Actor update: 0.15s (40.2%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008516
Q1 loss: 0.943029
Q2 loss: 0.943029
Current threshold: -149.2865
Global Scale Offset: 557.6717
Reward stats: mean=0.0172, std=0.1309, count=283
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9430, Q2 Loss: 0.9430, Entropy: 0.6894, Mean TD Error: 1.8118, Threshold: -149.2865
Original likelihood: -106.4479751586914
Adjusted likelihood: -106.4479751586914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5305)
Current yaw: tensor([ 0.0412,  0.0219, -0.2745], device='cuda:1')
8 turn
Sampling time 5.290873800986446
tensor([ 0.0192,  0.5488,  0.5343,  0.5812, -0.1234,  0.5246,  0.8510,  0.9373,
         1.3211,  0.3044,  0.1677,  1.2095,  0.0412,  0.0219, -0.2745, -5.2222],
       device='cuda:1')
Original likelihood: -97.5690689086914
Adjusted likelihood: -97.5690689086914
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5369)
State is out of distribution
Final likelihood: tensor([ -2.8611,  -3.3163,  -3.6351,  -3.9848,  -4.8492,  -5.1091,  -5.6101,
         -5.8601,  -6.0007,  -6.2932,  -6.3678,  -6.5661,  -6.9775,  -7.1452,
        -10.6174, -13.8388], device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([ -2.8611,  -3.3163,  -3.6351,  -3.9848,  -4.8492,  -5.1091,  -5.6101,
         -5.8601,  -6.0007,  -6.2932,  -6.3678,  -6.5661,  -6.9775,  -7.1452,
        -10.6174, -13.8388], device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -6.1895
1 mode projection succeeded
New goal: tensor([ 0.0648,  0.5774,  0.5290,  0.6083, -0.0931,  0.4885,  0.8897,  0.9331,
         1.2725,  0.3418,  0.2058,  1.1532,  0.0056,  0.0136, -0.5216],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -97.70719909667969
Adjusted likelihood: -97.70719909667969
Likelihood residual: 0.0
Original likelihood: -88.72293090820312
Adjusted likelihood: -88.72293090820312
Likelihood residual: 0.0
{'index': 88.72293090820312, 'thumb_middle': 97.70719909667969}
Current yaw: tensor([ 0.0412,  0.0219, -0.2745], device='cuda:1')
9 index
tensor([ 0.0192,  0.5488,  0.5343,  0.5812, -0.1234,  0.5246,  0.8510,  0.9373,
         1.3211,  0.3044,  0.1677,  1.2095,  0.0412,  0.0219, -0.2745, -5.2222],
       device='cuda:1')
Solve time for step 1 11.356585778994486
Current ori: tensor([ 0.0412,  0.0219, -0.2745], device='cuda:1')
Middle force: tensor([0.5378, 0.5138, 0.5228, 0.5599], device='cuda:1')
Thumb force: tensor([0.5055, 0.5120, 0.5824, 0.6180], device='cuda:1')
tensor([ 0.0955,  0.5141,  0.4852,  0.5833, -0.1253,  0.5139,  0.8728,  0.9185,
         1.3059,  0.3306,  0.1908,  1.1738,  0.0376,  0.0228, -0.3058, -6.1288],
       device='cuda:1')
Solve time for step 2 4.499914933985565
Current ori: tensor([ 0.0376,  0.0228, -0.3058], device='cuda:1')
Middle force: tensor([0.5113, 0.5199, 0.5559], device='cuda:1')
Thumb force: tensor([0.5104, 0.5769, 0.6132], device='cuda:1')
tensor([ 0.1054,  0.5200,  0.4820,  0.5862, -0.1242,  0.5216,  0.8686,  0.9025,
         1.3042,  0.3356,  0.1940,  1.1596,  0.0321,  0.0227, -0.3071,  5.7659],
       device='cuda:1')
Solve time for step 3 4.43396679603029
Current ori: tensor([ 0.0321,  0.0227, -0.3071], device='cuda:1')
Middle force: tensor([0.5349, 0.5491], device='cuda:1')
Thumb force: tensor([0.5170, 0.6010], device='cuda:1')
tensor([ 0.1055,  0.5189,  0.4829,  0.5869, -0.1177,  0.5229,  0.8713,  0.9060,
         1.2962,  0.3438,  0.1917,  1.1628,  0.0322,  0.0181, -0.3143,  5.3949],
       device='cuda:1')
Solve time for step 4 4.291118305991404
Current ori: tensor([ 0.0322,  0.0181, -0.3143], device='cuda:1')
Middle force: tensor([0.5249], device='cuda:1')
Thumb force: tensor([0.5247], device='cuda:1')
Storing RECOVERY transition: reward=0.0224 (scaled=0.0224), steps=0
Reward stats updated: mean 0.0172 -> 0.0172, std: 0.1307
Collected 284 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7098, Q2 Loss=0.7098, Entropy=0.6927, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4391
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8257, Q2 Loss=0.8257, Entropy=0.6859, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7879
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.0580, Q2 Loss=1.0580, Entropy=0.6895, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3571
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=2.8120, Q2 Loss=2.8120, Entropy=0.6895, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3763
SAC Update 5/5: Actor Loss=-0.0070, Q1 Loss=0.6245, Q2 Loss=0.6245, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5861

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.3%)
Q1 update: 0.08s (19.4%)
Q2 update: 0.08s (18.8%)
Actor update: 0.16s (39.3%)
Target update: 0.01s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007980
Q1 loss: 1.205986
Q2 loss: 1.205986
Current threshold: -149.2858
Global Scale Offset: 571.3531
Reward stats: mean=0.0172, std=0.1307, count=284
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 1.2060, Q2 Loss: 1.2060, Entropy: 0.6901, Mean TD Error: 1.5093, Threshold: -149.2858
Original likelihood: -72.37855529785156
Adjusted likelihood: -72.37855529785156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5534)
Current yaw: tensor([ 0.0301,  0.0162, -0.2960], device='cuda:1')
10 turn
Sampling time 5.271788184007164
tensor([ 0.0585,  0.5765,  0.5218,  0.6047, -0.1132,  0.5316,  0.8645,  0.8952,
         1.2916,  0.3480,  0.1889,  1.1682,  0.0301,  0.0162, -0.2960,  5.3273],
       device='cuda:1')
Original likelihood: -69.28016662597656
Adjusted likelihood: -69.28016662597656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5555)
State is out of distribution
Final likelihood: tensor([-2.8741, -3.0574, -3.1396, -3.3543, -3.6142, -3.6207, -3.8798, -3.9733,
        -4.2670, -4.3079, -5.0187, -5.1268, -5.5285, -5.8692, -5.8760, -6.1685],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.8741, -3.0574, -3.1396, -3.3543, -3.6142, -3.6207, -3.8798, -3.9733,
        -4.2670, -4.3079, -5.0187, -5.1268, -5.5285, -5.8692, -5.8760, -6.1685],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -4.3548
1 mode projection succeeded
New goal: tensor([ 0.0778,  0.5834,  0.5382,  0.5955, -0.0751,  0.5234,  0.8307,  0.9020,
         1.2595,  0.3520,  0.2252,  1.1319,  0.0040,  0.0115, -0.2858],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -80.18107604980469
Adjusted likelihood: -80.18107604980469
Likelihood residual: 0.0
Original likelihood: -84.8743896484375
Adjusted likelihood: -84.8743896484375
Likelihood residual: 0.0
{'index': 84.8743896484375, 'thumb_middle': 80.18107604980469}
Current yaw: tensor([ 0.0301,  0.0162, -0.2960], device='cuda:1')
11 thumb_middle
tensor([ 0.0585,  0.5765,  0.5218,  0.6047, -0.1132,  0.5316,  0.8645,  0.8952,
         1.2916,  0.3480,  0.1889,  1.1682,  0.0301,  0.0162, -0.2960,  5.3273],
       device='cuda:1')
Solve time for step 1 9.95435004401952
Current ori: tensor([ 0.0301,  0.0162, -0.2960], device='cuda:1')
Index force: tensor([0.5762, 0.5787, 0.5973, 0.5820], device='cuda:1')
tensor([ 0.0605,  0.5954,  0.5150,  0.5706, -0.1719,  0.5058,  0.8024,  0.8767,
         1.2214,  0.3356,  0.1507,  1.1100,  0.0230,  0.0144, -0.2959,  5.3010],
       device='cuda:1')
Solve time for step 2 4.0894609310198575
Current ori: tensor([ 0.0230,  0.0144, -0.2959], device='cuda:1')
Index force: tensor([0.5721, 0.5917, 0.5773], device='cuda:1')
tensor([ 0.0564,  0.5914,  0.5133,  0.5773, -0.1807,  0.5108,  0.7952,  0.8794,
         1.2232,  0.3358,  0.1512,  1.1065,  0.0245,  0.0169, -0.2959,  5.2988],
       device='cuda:1')
Solve time for step 3 4.007625533035025
Current ori: tensor([ 0.0245,  0.0169, -0.2959], device='cuda:1')
Index force: tensor([0.5829, 0.5707], device='cuda:1')
tensor([ 0.0729,  0.5897,  0.5238,  0.5922, -0.1729,  0.5210,  0.8014,  0.8781,
         1.2159,  0.3321,  0.1470,  1.1045,  0.0262,  0.0086, -0.2959,  5.3286],
       device='cuda:1')
Solve time for step 4 3.6340853279689327
Current ori: tensor([ 0.0262,  0.0086, -0.2959], device='cuda:1')
Index force: tensor([0.5546], device='cuda:1')
Storing RECOVERY transition: reward=0.0025 (scaled=0.0025), steps=0
Reward stats updated: mean 0.0172 -> 0.0171, std: 0.1304
Collected 285 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8314, Q2 Loss=0.8314, Entropy=0.6922, Time=0.10sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7806
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=1.0924, Q2 Loss=1.0924, Entropy=0.6919, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0963
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.4814, Q2 Loss=1.4814, Entropy=0.6874, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8172
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=3.4021, Q2 Loss=3.4021, Entropy=0.6903, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5004
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.7022, Q2 Loss=0.7022, Entropy=0.6923, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3351

------ SAC Update Summary (5 iterations) ------
Total time: 0.40s, Avg iteration: 0.08s
Sampling: 0.00s (0.5%)
Target Q: 0.08s (19.5%)
Q1 update: 0.08s (19.1%)
Q2 update: 0.08s (19.0%)
Actor update: 0.16s (39.4%)
Target update: 0.01s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008822
Q1 loss: 1.501910
Q2 loss: 1.501910
Current threshold: -149.2849
Global Scale Offset: 585.0400
Reward stats: mean=0.0171, std=0.1304, count=285
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.5019, Q2 Loss: 1.5019, Entropy: 0.6908, Mean TD Error: 1.7059, Threshold: -149.2849
Original likelihood: -68.2507553100586
Adjusted likelihood: -68.2507553100586
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5549)
State is out of distribution
Final likelihood: tensor([-2.9620, -3.0743, -3.5392, -3.6281, -3.6671, -3.7049, -3.7870, -3.7928,
        -3.8040, -4.0433, -4.1331, -4.1460, -4.3366, -4.8388, -4.9178, -5.1529],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final likelihood: tensor([-2.9620, -3.0743, -3.5392, -3.6281, -3.6671, -3.7049, -3.7870, -3.7928,
        -3.8040, -4.0433, -4.1331, -4.1460, -4.3366, -4.8388, -4.9178, -5.1529],
       device='cuda:1', grad_fn=<IndexBackward0>)
Final projection likelihood: -3.9705
1 mode projection succeeded
New goal: tensor([ 0.0774,  0.5827,  0.5388,  0.5953, -0.0750,  0.5238,  0.8308,  0.9012,
         1.2592,  0.3503,  0.2246,  1.1322,  0.0040,  0.0116, -0.2937],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -77.21460723876953
Adjusted likelihood: -77.21460723876953
Likelihood residual: 0.0
