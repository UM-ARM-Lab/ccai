Importing module 'gym_38' (/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
PyTorch version 2.4.1+cu121
Device count 2
/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
No ROS install found, continuing
CCAI_PATH /home/abhinav/Documents/ccai
Not connected to PVD
Physics Engine: PhysX
Physics Device: cpu
GPU Pipeline: disabled
Using VHACD cache directory '/home/abhinav/.isaacgym/vhacd'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/base_ns.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/link_1.0.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/ft_c.stl'
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]

Trial 1
Loaded trajectory sampler
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
1 turn
Sampling time 3.7815153759729583
tensor([ 1.5538e-01,  6.1090e-01,  5.7053e-01,  6.0998e-01, -1.1557e-01,
         5.3958e-01,  8.8539e-01,  9.3525e-01,  1.2574e+00,  2.2958e-01,
         2.3280e-01,  1.2081e+00,  5.5207e-05,  1.3631e-02, -4.8130e-02,
         4.4650e-01], device='cuda:1')
Original likelihood: -19.054738998413086
Adjusted likelihood: -19.054738998413086
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.6837951829948
Current ori: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Middle force: tensor([0.5791, 0.5709, 1.1438, 0.5580, 1.1024, 0.6482, 0.5358, 0.5249, 0.5829,
        0.5540, 0.5206, 0.5708], device='cuda:1')
Thumb force: tensor([0.8664, 0.8197, 0.7561, 1.0166, 0.9685, 0.6757, 0.5213, 0.5700, 0.5453,
        0.6043, 0.5627, 0.5500], device='cuda:1')
Index force: tensor([0.5978, 0.6008, 0.5560, 0.5699, 0.7921, 0.5254, 1.0088, 0.5495, 0.5799,
        0.6410, 0.5969, 0.5416], device='cuda:1')
Storing NORMAL transition: reward=0.0014 (scaled=0.0014), steps=1
Reward stats updated: mean 0.0000 -> 0.0014, std: 0.0000
Collected 1 transitions for RL
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:1')
Original likelihood: -33.53627395629883
Adjusted likelihood: -33.53627395629883
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0268)
State is out of distribution
Projection step: 0, Loss: 34.35027313232422
Projection step: 1, Loss: 29.099729537963867
Projection step: 2, Loss: 26.991527557373047
Projection step: 3, Loss: 25.764873504638672
Projection step: 4, Loss: 23.53175163269043
Projection step: 5, Loss: 20.392465591430664
Projection step: 6, Loss: 21.663925170898438
Projection step: 7, Loss: 20.9437198638916
Projection step: 8, Loss: 16.31324577331543
Projection step: 9, Loss: 16.232877731323242
Projection step: 10, Loss: 14.254530906677246
Final likelihood: tensor([-13.6021, -12.1652, -16.5882, -16.5739, -11.3720, -15.9999, -17.4104,
        -15.4567, -11.9681, -13.5928, -10.5148, -12.2766, -13.5226, -17.9277,
        -15.1772, -13.9245])
Final projection likelihood: -14.2545
1 mode projection succeeded
New goal: tensor([ 0.1550,  0.6027,  0.5125,  0.5472, -0.0919,  0.4683,  0.8355,  1.0997,
         1.2831,  0.3535,  0.1974,  1.0819,  0.0030,  0.0129, -2.3615],
       device='cuda:1')
tensor([[0.0068]], device='cuda:1') tensor([[0.0077]], device='cuda:1') tensor([[0.0106]], device='cuda:1')
Original likelihood: -24.68484878540039
Adjusted likelihood: -24.68484878540039
Likelihood residual: 0.0
Original likelihood: -20.608436584472656
Adjusted likelihood: -20.608436584472656
Likelihood residual: 0.0
{'index': 20.608436584472656, 'thumb_middle': 24.68484878540039}
Current yaw: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:1')
2 index
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:1')
Solve time for step 1 11.169281788985245
Current ori: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:1')
Middle force: tensor([0.5953, 0.5054, 0.5774, 0.5885], device='cuda:1')
Thumb force: tensor([0.5662, 0.5216, 0.5847, 0.5614], device='cuda:1')
tensor([ 0.2030,  0.5897,  0.4704,  0.5625, -0.1570,  0.5427,  0.8624,  1.0828,
         1.2919,  0.2658,  0.2338,  1.1029, -0.0040,  0.0128, -0.0952, -1.3779],
       device='cuda:1')
Solve time for step 2 2.580613824975444
Current ori: tensor([-0.0040,  0.0128, -0.0952], device='cuda:1')
Middle force: tensor([0.5051, 0.5753, 0.5866], device='cuda:1')
Thumb force: tensor([0.5201, 0.5828, 0.5593], device='cuda:1')
tensor([ 0.1872,  0.5878,  0.4837,  0.5401, -0.1600,  0.5509,  0.8618,  1.0896,
         1.2668,  0.3100,  0.2336,  1.1184, -0.0071,  0.0111, -0.1078, -1.7153],
       device='cuda:1')
Solve time for step 3 2.27061345599941
Current ori: tensor([-0.0071,  0.0111, -0.1078], device='cuda:1')
Middle force: tensor([0.5745, 0.5836], device='cuda:1')
Thumb force: tensor([0.5760, 0.5566], device='cuda:1')
tensor([ 0.1844,  0.5865,  0.4869,  0.5391, -0.1576,  0.5609,  0.8526,  1.0770,
         1.2854,  0.2875,  0.2168,  1.1192, -0.0136,  0.0108, -0.1061, -1.9042],
       device='cuda:1')
Solve time for step 4 2.1527842420036905
Current ori: tensor([-0.0136,  0.0108, -0.1061], device='cuda:1')
Middle force: tensor([0.5095], device='cuda:1')
Thumb force: tensor([0.5553], device='cuda:1')
Storing RECOVERY transition: reward=0.0601 (scaled=0.0601), steps=1
Reward stats updated: mean 0.0014 -> 0.0307, std: 0.0293
Collected 2 transitions for RL
Original likelihood: -21.992385864257812
Adjusted likelihood: -21.992385864257812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0169,  0.0163, -0.1100], device='cuda:1')
3 turn
Sampling time 3.850816963997204
tensor([ 0.1266,  0.6438,  0.5249,  0.5536, -0.1669,  0.5612,  0.8518,  1.0770,
         1.2776,  0.3139,  0.2197,  1.1263, -0.0169,  0.0163, -0.1100, -1.9308],
       device='cuda:1')
Original likelihood: -23.851118087768555
Adjusted likelihood: -23.851118087768555
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Solve time for step 1 14.317853446002118
Current ori: tensor([-0.0169,  0.0163, -0.1100], device='cuda:1')
Middle force: tensor([0.5766, 1.6180, 0.4823, 0.5019, 0.6344, 1.6031, 0.5648, 0.4524, 0.5582,
        0.5204, 0.5518, 0.4698], device='cuda:1')
Thumb force: tensor([0.8519, 0.9159, 0.4726, 1.0005, 0.8920, 1.0886, 0.7136, 0.5522, 1.0186,
        0.8978, 0.6833, 0.6238], device='cuda:1')
Index force: tensor([0.5140, 0.7289, 0.8049, 0.6286, 0.5062, 0.5236, 0.5142, 0.7300, 0.5348,
        0.5370, 0.5066, 0.6514], device='cuda:1')
Storing NORMAL transition: reward=-0.2051 (scaled=-0.2051), steps=1
Reward stats updated: mean 0.0307 -> -0.0479, std: 0.1137
Collected 3 transitions for RL
tensor([ 0.0531,  0.6427,  0.4310,  0.5942, -0.2088,  0.6364,  0.7503,  0.8756,
         1.2620,  0.3524,  0.2354,  1.3030, -0.0132,  0.0612,  0.0929, -2.3134],
       device='cuda:1')
Original likelihood: -29.780637741088867
Adjusted likelihood: -29.780637741088867
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5476)
Solve time for step 2 2.8730682210007217
Current ori: tensor([-0.0132,  0.0612,  0.0929], device='cuda:1')
Middle force: tensor([1.6051, 0.5036, 0.5018, 0.6296, 1.5831, 0.5638, 0.4849, 0.5590, 0.5190,
        0.5516, 0.4887], device='cuda:1')
Thumb force: tensor([0.9048, 0.5027, 1.0333, 0.8967, 1.0928, 0.7088, 0.5726, 1.0096, 0.8999,
        0.6854, 0.6438], device='cuda:1')
Index force: tensor([0.7183, 0.8119, 0.6209, 0.5058, 0.5224, 0.5139, 0.7378, 0.5333, 0.5366,
        0.5060, 0.6913], device='cuda:1')
Storing NORMAL transition: reward=-0.0457 (scaled=-0.0457), steps=1
Reward stats updated: mean -0.0479 -> -0.0473, std: 0.0985
Collected 4 transitions for RL
tensor([ 0.0513,  0.6167,  0.4670,  0.5929, -0.2041,  0.6641,  0.7070,  0.8941,
         1.3708,  0.1979,  0.1489,  1.3702, -0.0112,  0.0579,  0.1390, -2.2942],
       device='cuda:1')
Original likelihood: -26.495479583740234
Adjusted likelihood: -26.495479583740234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9721)
Solve time for step 3 2.7328432710201014
Current ori: tensor([-0.0112,  0.0579,  0.1390], device='cuda:1')
Middle force: tensor([0.5011, 1.3662, 0.6176, 0.5011, 0.5571, 0.5012, 0.5257, 0.5204, 0.5017,
        0.5203], device='cuda:1')
Thumb force: tensor([1.3079, 0.6918, 0.5357, 0.9804, 1.0733, 0.5160, 0.8890, 0.5504, 0.5893,
        0.5592], device='cuda:1')
Index force: tensor([0.7127, 0.7129, 0.5294, 0.6263, 0.6654, 0.5669, 0.5758, 0.5639, 0.6236,
        0.5447], device='cuda:1')
Storing NORMAL transition: reward=0.0476 (scaled=0.0476), steps=1
Reward stats updated: mean -0.0473 -> -0.0283, std: 0.0959
Collected 5 transitions for RL
tensor([ 0.0818,  0.6790,  0.4294,  0.5379, -0.1783,  0.6558,  0.7750,  0.8069,
         1.3751,  0.3092, -0.0069,  1.4187, -0.0286,  0.0404,  0.0920, -2.2432],
       device='cuda:1')
Original likelihood: -28.059471130371094
Adjusted likelihood: -28.059471130371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8552)
Solve time for step 4 2.8135065079841297
Current ori: tensor([-0.0286,  0.0404,  0.0920], device='cuda:1')
Middle force: tensor([1.3420, 0.6167, 0.5010, 0.5471, 0.5011, 0.5245, 0.5188, 0.5016, 0.5196],
       device='cuda:1')
Thumb force: tensor([0.6787, 0.5332, 0.9781, 1.0938, 0.5159, 0.8814, 0.5483, 0.5838, 0.5570],
       device='cuda:1')
Index force: tensor([0.7082, 0.5286, 0.6177, 0.6481, 0.5628, 0.5723, 0.5619, 0.6192, 0.5424],
       device='cuda:1')
Storing NORMAL transition: reward=-0.1036 (scaled=-0.1036), steps=1
Reward stats updated: mean -0.0283 -> -0.0409, std: 0.0920
Collected 6 transitions for RL
tensor([ 0.0242,  0.5968,  0.5211,  0.4808, -0.1719,  0.6805,  0.7520,  0.7642,
         1.3128,  0.3197,  0.0164,  1.4084, -0.0207,  0.0405,  0.1960, -2.1189],
       device='cuda:1')
Original likelihood: -26.177181243896484
Adjusted likelihood: -26.177181243896484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9815)
Solve time for step 5 2.503735840000445
Current ori: tensor([-0.0207,  0.0405,  0.1960], device='cuda:1')
Middle force: tensor([0.6128, 0.5015, 0.5465, 0.5013, 0.5244, 0.5177, 0.5025, 0.5193],
       device='cuda:1')
Thumb force: tensor([0.5306, 0.9494, 1.0676, 0.5129, 0.8659, 0.5452, 0.5664, 0.5540],
       device='cuda:1')
Index force: tensor([0.5289, 0.6098, 0.6453, 0.5644, 0.5710, 0.5593, 0.6160, 0.5399],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0058 (scaled=-0.0058), steps=1
Reward stats updated: mean -0.0409 -> -0.0359, std: 0.0860
Collected 7 transitions for RL
tensor([ 0.0414,  0.5761,  0.5532,  0.5209, -0.1600,  0.6838,  0.7402,  0.8083,
         1.3211,  0.3582,  0.0499,  1.3811, -0.0134,  0.0301,  0.2024, -2.0903],
       device='cuda:1')
Original likelihood: -23.7495174407959
Adjusted likelihood: -23.7495174407959
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 6 2.422204561007675
Current ori: tensor([-0.0134,  0.0301,  0.2024], device='cuda:1')
Middle force: tensor([0.5019, 0.5451, 0.5012, 0.5237, 0.5165, 0.5027, 0.5187],
       device='cuda:1')
Thumb force: tensor([0.9333, 1.0537, 0.5113, 0.8536, 0.5422, 0.5573, 0.5513],
       device='cuda:1')
Index force: tensor([0.6005, 0.6379, 0.5637, 0.5696, 0.5568, 0.6107, 0.5374],
       device='cuda:1')
Storing NORMAL transition: reward=0.0409 (scaled=0.0409), steps=1
Reward stats updated: mean -0.0359 -> -0.0263, std: 0.0844
Collected 8 transitions for RL
tensor([ 0.0480,  0.5569,  0.5696,  0.5525, -0.1600,  0.6683,  0.7465,  0.8564,
         1.3127,  0.3703,  0.0540,  1.3815, -0.0067,  0.0272,  0.1617, -2.0292],
       device='cuda:1')
Original likelihood: -23.88544464111328
Adjusted likelihood: -23.88544464111328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Solve time for step 7 2.320258024003124
Current ori: tensor([-0.0067,  0.0272,  0.1617], device='cuda:1')
Middle force: tensor([0.5429, 0.5011, 0.5229, 0.5156, 0.5026, 0.5181], device='cuda:1')
Thumb force: tensor([1.0359, 0.5103, 0.8436, 0.5397, 0.5524, 0.5491], device='cuda:1')
Index force: tensor([0.6319, 0.5628, 0.5681, 0.5548, 0.6067, 0.5354], device='cuda:1')
Storing NORMAL transition: reward=-0.1585 (scaled=-0.1585), steps=1
Reward stats updated: mean -0.0263 -> -0.0410, std: 0.0897
Collected 9 transitions for RL
tensor([ 0.1991,  0.5769,  0.6234,  0.5341, -0.0935,  0.7580,  0.7014,  0.7967,
         1.2064,  0.3389,  0.1221,  1.3939, -0.0031, -0.0183,  0.3205, -2.1595],
       device='cuda:1')
Original likelihood: -31.000213623046875
Adjusted likelihood: -31.000213623046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2926)
State is out of distribution
Projection step: 0, Loss: 35.52392578125
Projection step: 1, Loss: 29.126785278320312
Projection step: 2, Loss: 26.142414093017578
Projection step: 3, Loss: 23.416976928710938
Projection step: 4, Loss: 22.171537399291992
Projection step: 5, Loss: 20.710323333740234
Projection step: 6, Loss: 21.335369110107422
Projection step: 7, Loss: 20.31352996826172
Projection step: 8, Loss: 19.777320861816406
Projection step: 9, Loss: 18.835254669189453
Projection step: 10, Loss: 18.370197296142578
Projection step: 11, Loss: 17.597644805908203
Projection step: 12, Loss: 17.878406524658203
Projection step: 13, Loss: 16.799510955810547
Projection step: 14, Loss: 16.774377822875977
Final likelihood: tensor([-18.4553, -18.4061, -15.6097, -16.7064, -17.6584, -14.7682, -13.5852,
        -16.5680, -15.5684, -17.1999, -16.3317, -13.8696, -15.2620, -15.9498,
        -16.7709, -17.8919])
Final projection likelihood: -16.2876
1 mode projection succeeded
New goal: tensor([ 0.1159,  0.5335,  0.5869,  0.7222, -0.0532,  0.6187,  0.8711,  0.7597,
         1.3338,  0.2787,  0.1597,  1.1391, -0.0039, -0.0127, -2.8919],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0069]], device='cuda:1')
Original likelihood: -21.183692932128906
Adjusted likelihood: -21.183692932128906
Likelihood residual: 0.0
{'index': 21.183692932128906, 'thumb_middle': inf}
Current yaw: tensor([-0.0031, -0.0183,  0.3205], device='cuda:1')
4 index
tensor([ 0.1991,  0.5769,  0.6234,  0.5341, -0.0935,  0.7580,  0.7014,  0.7967,
         1.2064,  0.3389,  0.1221,  1.3939, -0.0031, -0.0183,  0.3205, -2.1595],
       device='cuda:1')
Solve time for step 1 11.53313071001321
Current ori: tensor([-0.0031, -0.0183,  0.3205], device='cuda:1')
Middle force: tensor([0.5665, 0.5263, 0.5031, 0.5942], device='cuda:1')
Thumb force: tensor([0.5895, 0.5103, 0.5320, 0.5723], device='cuda:1')
tensor([ 0.1943,  0.4998,  0.5557,  0.6569, -0.1094,  0.7142,  0.7996,  0.7154,
         1.2481,  0.2951,  0.1068,  1.3612, -0.0129, -0.0124,  0.2799, -2.1750],
       device='cuda:1')
Solve time for step 2 2.286200700007612
Current ori: tensor([-0.0129, -0.0124,  0.2799], device='cuda:1')
Middle force: tensor([0.5248, 0.5027, 0.5926], device='cuda:1')
Thumb force: tensor([0.5101, 0.5317, 0.5703], device='cuda:1')
tensor([ 1.8028e-01,  4.9755e-01,  5.4621e-01,  6.8424e-01, -1.2297e-01,
         7.0100e-01,  8.1502e-01,  6.9786e-01,  1.2677e+00,  2.7618e-01,
         1.1838e-01,  1.3414e+00, -1.3328e-02, -1.9251e-03,  2.7527e-01,
        -2.2832e+00], device='cuda:1')
Solve time for step 3 2.2028805699956138
Current ori: tensor([-0.0133, -0.0019,  0.2753], device='cuda:1')
Middle force: tensor([0.5026, 0.5911], device='cuda:1')
Thumb force: tensor([0.5290, 0.5682], device='cuda:1')
tensor([ 0.1783,  0.4990,  0.5457,  0.6912, -0.1329,  0.6927,  0.8172,  0.7003,
         1.2821,  0.2635,  0.1263,  1.3262, -0.0134,  0.0056,  0.2640, -2.3888],
       device='cuda:1')
Solve time for step 4 1.9134946159902029
Current ori: tensor([-0.0134,  0.0056,  0.2640], device='cuda:1')
Middle force: tensor([0.5759], device='cuda:1')
Thumb force: tensor([0.5196], device='cuda:1')
Storing RECOVERY transition: reward=0.0481 (scaled=0.0069), steps=7
Reward stats updated: mean -0.0410 -> -0.0362, std: 0.0863
Collected 10 transitions for RL
Original likelihood: -22.01620101928711
Adjusted likelihood: -22.01620101928711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0135,  0.0194,  0.2723], device='cuda:1')
5 turn
Sampling time 3.800108760013245
tensor([ 0.1183,  0.5391,  0.5778,  0.7156, -0.1496,  0.6874,  0.8142,  0.6910,
         1.2930,  0.2596,  0.1520,  1.3006, -0.0135,  0.0194,  0.2723, -2.4226],
       device='cuda:1')
Original likelihood: -22.31058120727539
Adjusted likelihood: -22.31058120727539
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.402515351015609
Current ori: tensor([-0.0135,  0.0194,  0.2723], device='cuda:1')
Middle force: tensor([0.6030, 0.7303, 0.5324, 1.4093, 0.5455, 0.4934, 0.6891, 0.5719, 0.5715,
        0.5561, 0.5558, 0.6680], device='cuda:1')
Thumb force: tensor([1.4954, 0.7123, 2.0914, 1.0585, 1.9118, 0.5040, 0.8769, 0.5418, 0.5933,
        0.5731, 1.2373, 0.7958], device='cuda:1')
Index force: tensor([0.8616, 0.7466, 0.5504, 0.8398, 0.6901, 0.7831, 0.5414, 0.5688, 0.5643,
        0.6050, 0.5286, 0.7967], device='cuda:1')
Storing NORMAL transition: reward=0.3044 (scaled=0.3044), steps=1
Reward stats updated: mean -0.0362 -> -0.0052, std: 0.1279
Collected 11 transitions for RL
tensor([ 0.1216,  0.4152,  0.6641,  0.8855, -0.1795,  0.6526,  0.7429,  0.9006,
         1.3715,  0.2855,  0.2025,  1.0510,  0.0185,  0.0398, -0.0359, -1.7017],
       device='cuda:1')
Original likelihood: -31.882400512695312
Adjusted likelihood: -31.882400512695312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1522)
State is out of distribution
Projection step: 0, Loss: 33.29016876220703
Projection step: 1, Loss: 29.202922821044922
Projection step: 2, Loss: 27.397478103637695
Projection step: 3, Loss: 25.352310180664062
Projection step: 4, Loss: 22.942584991455078
Projection step: 5, Loss: 21.508224487304688
Projection step: 6, Loss: 19.680763244628906
Projection step: 7, Loss: 18.449111938476562
Projection step: 8, Loss: 16.830270767211914
Projection step: 9, Loss: 14.95635986328125
Final likelihood: tensor([-19.1046, -11.7217, -18.7686, -13.1144, -14.9511, -14.6365, -16.3630,
        -14.8889, -16.8411, -14.8564, -14.0073, -15.9622, -11.8625, -14.8613,
        -13.1464, -14.2157])
Final projection likelihood: -14.9564
1 mode projection succeeded
New goal: tensor([ 0.0931,  0.5059,  0.6003,  0.6848, -0.0987,  0.5764,  0.8784,  0.8334,
         1.3408,  0.3335,  0.2076,  1.1322,  0.0144,  0.0203, -0.4613],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -22.29737091064453
Adjusted likelihood: -22.29737091064453
Likelihood residual: 0.0
Original likelihood: -20.38369369506836
Adjusted likelihood: -20.38369369506836
Likelihood residual: 0.0
{'index': 20.38369369506836, 'thumb_middle': 22.29737091064453}
Current yaw: tensor([ 0.0185,  0.0398, -0.0359], device='cuda:1')
6 index
tensor([ 0.1216,  0.4152,  0.6641,  0.8855, -0.1795,  0.6526,  0.7429,  0.9006,
         1.3715,  0.2855,  0.2025,  1.0510,  0.0185,  0.0398, -0.0359, -1.7017],
       device='cuda:1')
Solve time for step 1 11.807581370987464
Current ori: tensor([ 0.0185,  0.0398, -0.0359], device='cuda:1')
Middle force: tensor([0.5058, 0.5705, 0.5862, 0.5657], device='cuda:1')
Thumb force: tensor([0.5961, 0.6078, 0.5416, 0.5972], device='cuda:1')
tensor([ 0.1427,  0.4419,  0.5708,  0.6994, -0.1654,  0.6053,  0.8518,  0.8423,
         1.3499,  0.3167,  0.1821,  1.0892,  0.0263,  0.0266, -0.0614, -5.6103],
       device='cuda:1')
Solve time for step 2 2.3279040869965684
Current ori: tensor([ 0.0263,  0.0266, -0.0614], device='cuda:1')
Middle force: tensor([0.5814, 0.5784, 0.5679], device='cuda:1')
Thumb force: tensor([0.5187, 0.5455, 0.6025], device='cuda:1')
tensor([ 0.1412,  0.4640,  0.5670,  0.6697, -0.1719,  0.6029,  0.8709,  0.8287,
         1.3541,  0.3093,  0.1790,  1.0980,  0.0300,  0.0273, -0.0620,  4.4607],
       device='cuda:1')
Solve time for step 3 2.258892611018382
Current ori: tensor([ 0.0300,  0.0273, -0.0620], device='cuda:1')
Middle force: tensor([0.5660, 0.5150], device='cuda:1')
Thumb force: tensor([0.5847, 0.5735], device='cuda:1')
tensor([ 0.1374,  0.4683,  0.5640,  0.6635, -0.1563,  0.6232,  0.8588,  0.7971,
         1.3519,  0.3195,  0.1709,  1.0726,  0.0177,  0.0193, -0.0840,  3.1132],
       device='cuda:1')
Solve time for step 4 2.355722899985267
Current ori: tensor([ 0.0177,  0.0193, -0.0840], device='cuda:1')
Middle force: tensor([0.5336], device='cuda:1')
Thumb force: tensor([0.5933], device='cuda:1')
Storing RECOVERY transition: reward=0.0545 (scaled=0.0545), steps=1
Reward stats updated: mean -0.0052 -> -0.0003, std: 0.1236
Collected 12 transitions for RL
Original likelihood: -20.124542236328125
Adjusted likelihood: -20.124542236328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0189,  0.0249, -0.0890], device='cuda:1')
7 turn
Sampling time 3.7649527519824915
tensor([ 0.0860,  0.5140,  0.5968,  0.6852, -0.1680,  0.6197,  0.8611,  0.8032,
         1.3586,  0.3245,  0.1596,  1.0921,  0.0189,  0.0249, -0.0890,  2.8804],
       device='cuda:1')
Original likelihood: -23.426551818847656
Adjusted likelihood: -23.426551818847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Solve time for step 1 15.274519708007574
Current ori: tensor([ 0.0189,  0.0249, -0.0890], device='cuda:1')
Middle force: tensor([1.3603, 0.5033, 0.5007, 0.5271, 0.5672, 0.5826, 1.0730, 0.8320, 0.7581,
        0.5876, 0.5079, 0.9225], device='cuda:1')
Thumb force: tensor([1.9527, 1.9718, 1.4212, 0.5584, 1.1142, 0.8144, 1.4608, 0.5709, 0.7551,
        0.7090, 0.6567, 0.5400], device='cuda:1')
Index force: tensor([0.5582, 0.8321, 0.8389, 0.6255, 0.5626, 0.5485, 0.5861, 0.5189, 0.5722,
        0.5714, 0.6773, 0.6102], device='cuda:1')
Storing NORMAL transition: reward=-0.1919 (scaled=-0.1919), steps=1
Reward stats updated: mean -0.0003 -> -0.0150, std: 0.1292
Collected 13 transitions for RL
tensor([ 0.0531,  0.5415,  0.5500,  0.6456, -0.1636,  0.7465,  0.6566,  0.7881,
         1.3620,  0.4040,  0.0865,  1.2152,  0.0094,  0.0401,  0.1026,  2.6532],
       device='cuda:1')
Original likelihood: -31.92347526550293
Adjusted likelihood: -31.92347526550293
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1470)
State is out of distribution
Projection step: 0, Loss: 29.08354377746582
Projection step: 1, Loss: 29.487548828125
Projection step: 2, Loss: 27.09225845336914
Projection step: 3, Loss: 26.403461456298828
Projection step: 4, Loss: 24.293298721313477
Projection step: 5, Loss: 24.835206985473633
Projection step: 6, Loss: 23.694494247436523
Projection step: 7, Loss: 22.399494171142578
Projection step: 8, Loss: 21.720458984375
Projection step: 9, Loss: 20.088430404663086
Projection step: 10, Loss: 19.37499237060547
Projection step: 11, Loss: 16.89690589904785
Projection step: 12, Loss: 16.281957626342773
Projection step: 13, Loss: 15.534308433532715
Projection step: 14, Loss: 12.305910110473633
Final likelihood: tensor([-11.5119, -14.3234, -14.1426,  -8.4898, -13.7858, -14.8640,  -8.7311,
        -12.7362, -14.2625, -13.6687, -14.1317, -14.3333, -11.5608,  -9.5134,
        -11.9604,  -8.8791])
Final projection likelihood: -12.3059
1 mode projection succeeded
New goal: tensor([ 0.0778,  0.5747,  0.5217,  0.6605, -0.0674,  0.5723,  0.8017,  0.8192,
         1.2950,  0.3794,  0.1826,  1.1746,  0.0090,  0.0144, -1.3006],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -16.832542419433594
Adjusted likelihood: -16.832542419433594
Likelihood residual: 0.0
Original likelihood: -24.100582122802734
Adjusted likelihood: -24.100582122802734
Likelihood residual: 0.0
{'index': 24.100582122802734, 'thumb_middle': 16.832542419433594}
Current yaw: tensor([0.0094, 0.0401, 0.1026], device='cuda:1')
8 thumb_middle
tensor([ 0.0531,  0.5415,  0.5500,  0.6456, -0.1636,  0.7465,  0.6566,  0.7881,
         1.3620,  0.4040,  0.0865,  1.2152,  0.0094,  0.0401,  0.1026,  2.6532],
       device='cuda:1')
Solve time for step 1 9.786266198003432
Current ori: tensor([0.0094, 0.0401, 0.1026], device='cuda:1')
Index force: tensor([0.5565, 0.5913, 0.5773, 0.5030], device='cuda:1')
tensor([ 0.0491,  0.5521,  0.5134,  0.6764, -0.1997,  0.5883,  0.7203,  0.7669,
         1.2890,  0.3774,  0.0792,  1.1584,  0.0104,  0.0453,  0.1027,  2.6014],
       device='cuda:1')
Solve time for step 2 2.088128000992583
Current ori: tensor([0.0104, 0.0453, 0.1027], device='cuda:1')
Index force: tensor([0.5522, 0.5698, 0.5924], device='cuda:1')
tensor([ 0.0600,  0.5657,  0.5145,  0.6576, -0.1979,  0.5748,  0.7496,  0.7808,
         1.2868,  0.3705,  0.0800,  1.1401,  0.0053,  0.0389,  0.1027,  2.6113],
       device='cuda:1')
Solve time for step 3 2.0422919200209435
Current ori: tensor([0.0053, 0.0389, 0.1027], device='cuda:1')
Index force: tensor([0.5674, 0.5910], device='cuda:1')
tensor([ 7.0804e-02,  5.8047e-01,  5.1298e-01,  6.4073e-01, -1.9381e-01,
         5.6906e-01,  7.6007e-01,  7.8965e-01,  1.2827e+00,  3.7299e-01,
         7.6043e-02,  1.1321e+00,  2.8761e-04,  3.2336e-02,  1.0266e-01,
         2.6217e+00], device='cuda:1')
Solve time for step 4 1.8673133550037164
Current ori: tensor([0.0003, 0.0323, 0.1027], device='cuda:1')
Index force: tensor([0.5872], device='cuda:1')
Storing RECOVERY transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean -0.0150 -> -0.0138, std: 0.1246
Collected 14 transitions for RL
Original likelihood: -27.937313079833984
Adjusted likelihood: -27.937313079833984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8698)
Current yaw: tensor([0.0022, 0.0336, 0.1012], device='cuda:1')
9 turn
Sampling time 3.8622239459946286
tensor([ 6.7691e-02,  5.7696e-01,  5.1090e-01,  6.4867e-01, -1.4072e-01,
         6.0653e-01,  7.9408e-01,  8.0808e-01,  1.3452e+00,  3.8419e-01,
         1.2600e-01,  1.1607e+00,  2.1745e-03,  3.3559e-02,  1.0122e-01,
         2.6350e+00], device='cuda:1')
Original likelihood: -24.83979034423828
Adjusted likelihood: -24.83979034423828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9976)
Solve time for step 1 14.951131985988468
Current ori: tensor([0.0022, 0.0336, 0.1012], device='cuda:1')
Middle force: tensor([0.5283, 0.6836, 0.5542, 0.5026, 0.7640, 1.0305, 0.5774, 0.5660, 0.5178,
        0.5577, 0.5866, 0.6035], device='cuda:1')
Thumb force: tensor([0.8484, 0.6137, 1.4841, 2.2584, 0.8369, 1.6676, 0.5916, 0.6607, 0.5342,
        1.5291, 0.5933, 0.5880], device='cuda:1')
Index force: tensor([0.5108, 0.8397, 0.5905, 0.5968, 0.5821, 0.5797, 0.5823, 0.5261, 0.4956,
        0.7944, 0.5868, 0.5969], device='cuda:1')
Storing NORMAL transition: reward=0.0021 (scaled=0.0021), steps=1
Reward stats updated: mean -0.0138 -> -0.0127, std: 0.1205
Collected 15 transitions for RL
tensor([ 0.0132,  0.6033,  0.4668,  0.5644, -0.1713,  0.6625,  0.6282,  0.8813,
         1.3947,  0.3989,  0.1001,  1.1489, -0.0088,  0.0634,  0.0963,  2.5226],
       device='cuda:1')
Original likelihood: -32.314239501953125
Adjusted likelihood: -32.314239501953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1033)
State is out of distribution
Projection step: 0, Loss: 32.673744201660156
Projection step: 1, Loss: 30.421112060546875
Projection step: 2, Loss: 30.440046310424805
Projection step: 3, Loss: 28.80477523803711
Projection step: 4, Loss: 28.069440841674805
Projection step: 5, Loss: 27.613283157348633
Projection step: 6, Loss: 25.628707885742188
Projection step: 7, Loss: 25.672225952148438
Projection step: 8, Loss: 24.21630096435547
Projection step: 9, Loss: 23.39441680908203
Projection step: 10, Loss: 23.003293991088867
Projection step: 11, Loss: 22.255292892456055
Projection step: 12, Loss: 21.658275604248047
Projection step: 13, Loss: 19.096372604370117
Projection step: 14, Loss: 20.302265167236328
Final likelihood: tensor([-19.8989, -19.9601, -20.0753, -20.1345, -18.6436, -19.7866, -20.1526,
        -19.3690, -20.6838, -16.3043, -19.3251, -16.7188, -20.0481, -20.1370,
        -20.0514, -19.3997])
Final projection likelihood: -19.4180
1 mode projection succeeded
New goal: tensor([ 0.0405,  0.5986,  0.4843,  0.6164, -0.0834,  0.6340,  0.5558,  0.9328,
         1.3476,  0.2371,  0.1370,  1.1398, -0.0262,  0.0387, -0.9335],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -24.99622917175293
Adjusted likelihood: -24.99622917175293
Likelihood residual: 0.0
Original likelihood: -26.771387100219727
Adjusted likelihood: -26.771387100219727
Likelihood residual: 0.0
{'index': 26.771387100219727, 'thumb_middle': 24.99622917175293}
Current yaw: tensor([-0.0088,  0.0634,  0.0963], device='cuda:1')
10 thumb_middle
tensor([ 0.0132,  0.6033,  0.4668,  0.5644, -0.1713,  0.6625,  0.6282,  0.8813,
         1.3947,  0.3989,  0.1001,  1.1489, -0.0088,  0.0634,  0.0963,  2.5226],
       device='cuda:1')
Solve time for step 1 8.916787840018515
Current ori: tensor([-0.0088,  0.0634,  0.0963], device='cuda:1')
Index force: tensor([0.5616, 0.6118, 0.5761, 0.5948], device='cuda:1')
tensor([ 0.0066,  0.6028,  0.4591,  0.5673, -0.2032,  0.6310,  0.5472,  0.9027,
         1.3471,  0.2611,  0.0904,  1.1268, -0.0080,  0.0673,  0.0963,  2.5142],
       device='cuda:1')
Solve time for step 2 1.953422381018754
Current ori: tensor([-0.0080,  0.0673,  0.0963], device='cuda:1')
Index force: tensor([0.6063, 0.5724, 0.5901], device='cuda:1')
tensor([ 0.0216,  0.6149,  0.4428,  0.5927, -0.1947,  0.6387,  0.5512,  0.9141,
         1.3499,  0.2348,  0.0829,  1.1206, -0.0094,  0.0588,  0.0963,  2.5385],
       device='cuda:1')
Solve time for step 3 1.9042901450011414
Current ori: tensor([-0.0094,  0.0588,  0.0963], device='cuda:1')
Index force: tensor([0.5800, 0.5870], device='cuda:1')
tensor([ 0.0365,  0.6088,  0.4622,  0.5985, -0.1970,  0.6528,  0.5547,  0.9077,
         1.3512,  0.2307,  0.0696,  1.1173, -0.0084,  0.0506,  0.0963,  2.5619],
       device='cuda:1')
Solve time for step 4 1.8297383559984155
Current ori: tensor([-0.0084,  0.0506,  0.0963], device='cuda:1')
Index force: tensor([0.5773], device='cuda:1')
Storing RECOVERY transition: reward=0.0053 (scaled=0.0053), steps=1
Reward stats updated: mean -0.0127 -> -0.0116, std: 0.1167
Collected 16 transitions for RL
Original likelihood: -28.24967384338379
Adjusted likelihood: -28.24967384338379
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8302)
Current yaw: tensor([-0.0084,  0.0420,  0.0931], device='cuda:1')
11 turn
Sampling time 3.7074340359831695
tensor([ 0.0504,  0.6092,  0.4730,  0.6022, -0.1238,  0.6880,  0.5694,  0.9237,
         1.4108,  0.2519,  0.1114,  1.1358, -0.0084,  0.0420,  0.0931,  2.6011],
       device='cuda:1')
Original likelihood: -28.148941040039062
Adjusted likelihood: -28.148941040039062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8438)
Solve time for step 1 14.63475437098532
Current ori: tensor([-0.0084,  0.0420,  0.0931], device='cuda:1')
Middle force: tensor([0.5114, 0.6541, 0.5514, 0.5061, 0.7034, 0.9382, 0.5547, 0.5368, 0.5913,
        0.5262, 0.5574, 0.5671], device='cuda:1')
Thumb force: tensor([0.8811, 0.6066, 1.3405, 2.0232, 0.7565, 1.5050, 0.5864, 0.7024, 0.5295,
        1.3352, 0.5413, 0.5845], device='cuda:1')
Index force: tensor([0.5487, 0.8731, 0.6029, 0.5603, 0.5767, 0.5770, 0.5675, 0.5116, 0.4967,
        0.7446, 0.6881, 0.5436], device='cuda:1')
Storing NORMAL transition: reward=-0.0220 (scaled=-0.0220), steps=1
Reward stats updated: mean -0.0116 -> -0.0122, std: 0.1133
Collected 17 transitions for RL
tensor([ 0.1100,  0.6591,  0.4970,  0.5154, -0.0229,  0.7700,  0.5993,  0.8228,
         1.2337,  0.4053, -0.0581,  1.0838, -0.0252, -0.0347,  0.1151,  3.0419],
       device='cuda:1')
Original likelihood: -28.624679565429688
Adjusted likelihood: -28.624679565429688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7735)
Solve time for step 2 2.8975460380024742
Current ori: tensor([-0.0252, -0.0347,  0.1151], device='cuda:1')
Middle force: tensor([0.7118, 0.5584, 0.5044, 0.7451, 1.0065, 0.5911, 0.5443, 0.5889, 0.5755,
        0.5060, 0.6519], device='cuda:1')
Thumb force: tensor([0.5956, 1.5223, 2.3296, 0.8167, 1.7375, 0.5741, 0.7089, 0.5428, 1.4560,
        0.5981, 0.5420], device='cuda:1')
Index force: tensor([0.8681, 0.5911, 0.5870, 0.5808, 0.5847, 0.5732, 0.5001, 0.5018, 0.7164,
        0.6247, 0.5803], device='cuda:1')
Storing NORMAL transition: reward=-0.0088 (scaled=-0.0088), steps=1
Reward stats updated: mean -0.0122 -> -0.0120, std: 0.1101
Collected 18 transitions for RL
tensor([ 0.1149,  0.6184,  0.5352,  0.4892, -0.0610,  0.7534,  0.6622,  0.8121,
         1.1946,  0.4216,  0.0794,  1.0806, -0.0621, -0.0877,  0.1151,  2.7580],
       device='cuda:1')
Original likelihood: -34.54179763793945
Adjusted likelihood: -34.54179763793945
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0066)
State is out of distribution
Projection step: 0, Loss: 33.82936096191406
Projection step: 1, Loss: 32.72820281982422
Projection step: 2, Loss: 31.112857818603516
Projection step: 3, Loss: 29.922954559326172
Projection step: 4, Loss: 28.045772552490234
Projection step: 5, Loss: 26.607070922851562
Projection step: 6, Loss: 25.566865921020508
Projection step: 7, Loss: 25.01058578491211
Projection step: 8, Loss: 24.41122817993164
Projection step: 9, Loss: 23.74388313293457
Projection step: 10, Loss: 23.073204040527344
Projection step: 11, Loss: 22.608051300048828
Projection step: 12, Loss: 22.107311248779297
Projection step: 13, Loss: 21.58841323852539
Projection step: 14, Loss: 20.974794387817383
Final likelihood: tensor([-20.9284, -20.2799, -20.4779, -20.6876, -20.7360, -20.1354, -20.5391,
        -20.3625, -20.2379, -21.2532, -20.1562, -20.6910, -20.5410, -20.4790,
        -20.2795, -20.7378])
Final projection likelihood: -20.5326
1 mode projection succeeded
New goal: tensor([ 1.3664e-01,  5.5801e-01,  5.8945e-01,  6.0697e-01, -8.0045e-04,
         6.7699e-01,  8.0054e-01,  8.4695e-01,  1.2845e+00,  3.3348e-01,
         5.8888e-02,  1.1283e+00, -4.9348e-02, -6.7273e-02, -5.4648e-01],
       device='cuda:1')
tensor([[0.0055]], device='cuda:1') tensor([[0.0114]], device='cuda:1') tensor([[0.0045]], device='cuda:1')
Original likelihood: -22.091232299804688
Adjusted likelihood: -22.091232299804688
Likelihood residual: 0.0
Original likelihood: -21.368125915527344
Adjusted likelihood: -21.368125915527344
Likelihood residual: 0.0
{'index': 21.368125915527344, 'thumb_middle': 22.091232299804688}
Current yaw: tensor([-0.0621, -0.0877,  0.1151], device='cuda:1')
12 index
tensor([ 0.1149,  0.6184,  0.5352,  0.4892, -0.0610,  0.7534,  0.6622,  0.8121,
         1.1946,  0.4216,  0.0794,  1.0806, -0.0621, -0.0877,  0.1151,  2.7580],
       device='cuda:1')
Solve time for step 1 10.558253214985598
Current ori: tensor([-0.0621, -0.0877,  0.1151], device='cuda:1')
Middle force: tensor([0.6015, 0.5923, 0.5340, 0.5929], device='cuda:1')
Thumb force: tensor([0.5988, 0.5797, 0.5197, 0.5855], device='cuda:1')
tensor([ 0.1685,  0.5231,  0.5398,  0.5576, -0.0466,  0.7490,  0.7833,  0.8326,
         1.2749,  0.3035,  0.0639,  1.1022, -0.0596, -0.0731,  0.1072,  2.5869],
       device='cuda:1')
Solve time for step 2 2.218137494986877
Current ori: tensor([-0.0596, -0.0731,  0.1072], device='cuda:1')
Middle force: tensor([0.5899, 0.5327, 0.5910], device='cuda:1')
Thumb force: tensor([0.5749, 0.5186, 0.5827], device='cuda:1')
tensor([ 0.1705,  0.5232,  0.5491,  0.5766, -0.0558,  0.7492,  0.8037,  0.8344,
         1.2805,  0.2954,  0.0540,  1.1023, -0.0673, -0.0750,  0.1204,  2.4942],
       device='cuda:1')
Solve time for step 3 2.1888467709941324
Current ori: tensor([-0.0673, -0.0750,  0.1204], device='cuda:1')
Middle force: tensor([0.5323, 0.5896], device='cuda:1')
Thumb force: tensor([0.5175, 0.5807], device='cuda:1')
tensor([ 0.1687,  0.5287,  0.5522,  0.5811, -0.0438,  0.7589,  0.8038,  0.8306,
         1.2710,  0.3097,  0.0425,  1.1008, -0.0710, -0.0856,  0.1025,  2.5279],
       device='cuda:1')
Solve time for step 4 2.116806199977873
Current ori: tensor([-0.0710, -0.0856,  0.1025], device='cuda:1')
Middle force: tensor([0.5294], device='cuda:1')
Thumb force: tensor([0.5306], device='cuda:1')
Storing RECOVERY transition: reward=-0.0009 (scaled=-0.0005), steps=2
Reward stats updated: mean -0.0120 -> -0.0114, std: 0.1072
Collected 19 transitions for RL
Original likelihood: -34.56585693359375
Adjusted likelihood: -34.56585693359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0064)
State is out of distribution
Projection step: 0, Loss: 34.80281066894531
Projection step: 1, Loss: 32.551795959472656
Projection step: 2, Loss: 31.782337188720703
Projection step: 3, Loss: 30.86007308959961
Projection step: 4, Loss: 30.225866317749023
Projection step: 5, Loss: 29.730051040649414
Projection step: 6, Loss: 29.051525115966797
Projection step: 7, Loss: 28.636215209960938
Projection step: 8, Loss: 27.996158599853516
Projection step: 9, Loss: 28.740768432617188
Projection step: 10, Loss: 27.864225387573242
Projection step: 11, Loss: 29.53515625
Projection step: 12, Loss: 27.025184631347656
Projection step: 13, Loss: 28.52665901184082
Projection step: 14, Loss: 27.178550720214844
Final likelihood: tensor([-25.2896, -25.2414, -31.1858, -24.1683, -25.5640, -24.9463, -33.0221,
        -25.7783, -25.1630, -25.0729, -29.3417, -25.1305, -25.4193, -25.0959,
        -28.8517, -25.5639])
Final projection likelihood: -26.5522
1 mode projection succeeded
New goal: tensor([ 0.1698,  0.4804,  0.6784,  0.7106,  0.0020,  0.7095,  0.8277,  0.7841,
         1.3190,  0.2600,  0.0208,  1.0346, -0.0830, -0.0767, -0.0686],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0020]], device='cuda:1')
Original likelihood: -30.09099006652832
Adjusted likelihood: -30.09099006652832
Likelihood residual: 0.0
Original likelihood: -34.08270263671875
Adjusted likelihood: -34.08270263671875
Likelihood residual: 0.0
{'index': 34.08270263671875, 'thumb_middle': 30.09099006652832}
Current yaw: tensor([-0.0891, -0.0974,  0.1107], device='cuda:1')
13 thumb_middle
tensor([ 0.1244,  0.5827,  0.5912,  0.6057, -0.0492,  0.7727,  0.8244,  0.8422,
         1.2824,  0.2930,  0.0094,  1.0983, -0.0891, -0.0974,  0.1107,  2.6404],
       device='cuda:1')
Solve time for step 1 9.067291621002369
Current ori: tensor([-0.0891, -0.0974,  0.1107], device='cuda:1')
Index force: tensor([0.4988, 0.5000, 0.6551, 0.5006], device='cuda:1')
tensor([ 0.1067,  0.5738,  0.5910,  0.6036, -0.0757,  0.6936,  0.7949,  0.7879,
         1.2790,  0.2471, -0.0803,  1.0003, -0.1714, -0.1762,  0.1406,  2.2442],
       device='cuda:1')
Solve time for step 2 2.014466579974396
Current ori: tensor([-0.1714, -0.1762,  0.1406], device='cuda:1')
Index force: tensor([0.6042, 0.6064, 0.6029], device='cuda:1')
tensor([ 0.0719,  0.5841,  0.6974,  0.6770, -0.0536,  0.7213,  0.8186,  0.7808,
         1.2673,  0.2364, -0.1447,  0.9636, -0.2488, -0.2333,  0.2499,  2.2333],
       device='cuda:1')
Solve time for step 3 1.8831894939939957
Current ori: tensor([-0.2488, -0.2333,  0.2499], device='cuda:1')
Index force: tensor([0.5977, 0.5993], device='cuda:1')
tensor([ 0.0416,  0.6648,  0.7223,  0.6832, -0.0282,  0.7586,  0.8373,  0.7842,
         1.2615,  0.2382, -0.1890,  0.9384, -0.3853, -0.2906,  0.3899,  2.3142],
       device='cuda:1')
Solve time for step 4 1.9621677309914958
Current ori: tensor([-0.3853, -0.2906,  0.3899], device='cuda:1')
Index force: tensor([0.5474], device='cuda:1')
Storing RECOVERY transition: reward=-0.7475 (scaled=-0.3738), steps=2
Reward stats updated: mean -0.0114 -> -0.0295, std: 0.1309
Collected 20 transitions for RL
Original likelihood: -770.598388671875
Adjusted likelihood: -770.598388671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 2
Loaded trajectory sampler
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
1 turn
Sampling time 3.955372733005788
tensor([ 0.1479,  0.6005,  0.5797,  0.6059, -0.1236,  0.5446,  0.8891,  0.9433,
         1.2300,  0.2942,  0.2475,  1.1776, -0.0020,  0.0145, -0.0306,  0.2450],
       device='cuda:1')
Original likelihood: -20.109432220458984
Adjusted likelihood: -20.109432220458984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.037535548995947
Current ori: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
Middle force: tensor([0.5207, 0.5006, 1.2931, 1.3042, 0.5227, 0.5396, 0.5043, 0.6073, 0.5677,
        0.5722, 0.5778, 0.5691], device='cuda:1')
Thumb force: tensor([0.7651, 0.6014, 1.1844, 1.0950, 0.8208, 0.8874, 0.5113, 0.5274, 0.7066,
        0.5642, 0.5688, 0.8365], device='cuda:1')
Index force: tensor([0.5015, 0.6188, 0.5912, 0.5283, 0.9815, 0.5370, 0.6198, 0.5607, 0.5844,
        0.5977, 0.5620, 0.5691], device='cuda:1')
Storing NORMAL transition: reward=-0.0013 (scaled=-0.0013), steps=1
Reward stats updated: mean -0.0295 -> -0.0282, std: 0.1279
Collected 21 transitions for RL
tensor([ 0.2134,  0.5840,  0.6345,  0.6815, -0.1651,  0.5914,  0.7590,  0.9763,
         1.3371,  0.0712,  0.0766,  1.2767,  0.0081, -0.0259, -0.0298,  0.4644],
       device='cuda:1')
Original likelihood: -35.466033935546875
Adjusted likelihood: -35.466033935546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0014)
State is out of distribution
Projection step: 0, Loss: 35.121307373046875
Projection step: 1, Loss: 29.604976654052734
Projection step: 2, Loss: 25.726181030273438
Projection step: 3, Loss: 24.304080963134766
Projection step: 4, Loss: 23.468673706054688
Projection step: 5, Loss: 22.369239807128906
Projection step: 6, Loss: 20.826631546020508
Projection step: 7, Loss: 20.681175231933594
Projection step: 8, Loss: 18.73346519470215
Projection step: 9, Loss: 18.081298828125
Projection step: 10, Loss: 17.257610321044922
Projection step: 11, Loss: 17.899356842041016
Projection step: 12, Loss: 16.447736740112305
Projection step: 13, Loss: 15.61177921295166
Projection step: 14, Loss: 16.09217071533203
Final likelihood: tensor([-13.6928, -14.1537, -14.9831, -14.3604, -13.4341, -16.1585, -16.0683,
        -16.6989, -12.8289, -13.5991, -15.2092, -16.0537, -16.7873, -14.0993,
        -18.3837, -15.6309])
Final projection likelihood: -15.1339
1 mode projection succeeded
New goal: tensor([ 1.2547e-01,  5.3391e-01,  6.2397e-01,  6.6523e-01, -5.0607e-02,
         5.9049e-01,  9.0485e-01,  7.7668e-01,  1.3712e+00,  2.0640e-01,
         1.4051e-01,  1.1284e+00,  1.4851e-03, -2.0614e-02, -1.9214e+00],
       device='cuda:1')
tensor([[0.0056]], device='cuda:1') tensor([[0.0123]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -19.921672821044922
Adjusted likelihood: -19.921672821044922
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 19.921672821044922}
Current yaw: tensor([ 0.0081, -0.0259, -0.0298], device='cuda:1')
2 thumb_middle
tensor([ 0.2134,  0.5840,  0.6345,  0.6815, -0.1651,  0.5914,  0.7590,  0.9763,
         1.3371,  0.0712,  0.0766,  1.2767,  0.0081, -0.0259, -0.0298,  0.4644],
       device='cuda:1')
Solve time for step 1 9.449130405002506
Current ori: tensor([ 0.0081, -0.0259, -0.0298], device='cuda:1')
Index force: tensor([0.5515, 0.5954, 0.5905, 0.5901], device='cuda:1')
tensor([ 0.1719,  0.5828,  0.6099,  0.6435, -0.1824,  0.5650,  0.8285,  0.7998,
         1.3301,  0.1578,  0.0456,  1.1134,  0.0036, -0.0033, -0.0298,  0.3953],
       device='cuda:1')
Solve time for step 2 1.9758947459922638
Current ori: tensor([ 0.0036, -0.0033, -0.0298], device='cuda:1')
Index force: tensor([0.5911, 0.5878, 0.5873], device='cuda:1')
tensor([ 0.1783,  0.5681,  0.6268,  0.6624, -0.1799,  0.5704,  0.8557,  0.7693,
         1.3386,  0.1855,  0.0311,  1.0987,  0.0085, -0.0056, -0.0298,  0.4115],
       device='cuda:1')
Solve time for step 3 1.8138683619908988
Current ori: tensor([ 0.0085, -0.0056, -0.0298], device='cuda:1')
Index force: tensor([0.5810, 0.5817], device='cuda:1')
tensor([ 0.1794,  0.5626,  0.6335,  0.6660, -0.1824,  0.5779,  0.8706,  0.7375,
         1.3341,  0.1817,  0.0417,  1.0930,  0.0101, -0.0058, -0.0298,  0.4151],
       device='cuda:1')
Solve time for step 4 1.8574091809859965
Current ori: tensor([ 0.0101, -0.0058, -0.0298], device='cuda:1')
Index force: tensor([0.5462], device='cuda:1')
Storing RECOVERY transition: reward=0.0068 (scaled=0.0068), steps=1
Reward stats updated: mean -0.0282 -> -0.0266, std: 0.1252
Collected 22 transitions for RL
Original likelihood: -21.483596801757812
Adjusted likelihood: -21.483596801757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0148,  0.0066, -0.0361], device='cuda:1')
3 turn
Sampling time 3.8446836860093754
tensor([ 0.1555,  0.5421,  0.6365,  0.6646, -0.1362,  0.5996,  0.9101,  0.7676,
         1.4083,  0.1986,  0.1072,  1.1130,  0.0148,  0.0066, -0.0361,  0.3726],
       device='cuda:1')
Original likelihood: -23.050399780273438
Adjusted likelihood: -23.050399780273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 15.061070449999534
Current ori: tensor([ 0.0148,  0.0066, -0.0361], device='cuda:1')
Middle force: tensor([1.8030, 1.3758, 0.5079, 0.5206, 0.8879, 0.4984, 0.4924, 0.5688, 0.4892,
        0.5222, 0.5498, 0.5799], device='cuda:1')
Thumb force: tensor([0.8709, 0.5246, 1.0633, 0.5973, 1.7005, 0.7159, 1.6730, 1.1048, 0.5503,
        0.6038, 0.6156, 0.6521], device='cuda:1')
Index force: tensor([0.6690, 1.0205, 1.0201, 0.6223, 0.8366, 0.6385, 0.6782, 0.5623, 0.7807,
        0.6397, 0.6628, 0.5981], device='cuda:1')
Storing NORMAL transition: reward=-0.0841 (scaled=-0.0841), steps=1
Reward stats updated: mean -0.0266 -> -0.0291, std: 0.1230
Collected 23 transitions for RL
tensor([ 0.1049,  0.4853,  0.6797,  0.6259, -0.1420,  0.6225,  0.7650,  0.7742,
         1.5000,  0.0344,  0.2113,  0.9642,  0.0174,  0.0453,  0.0463,  0.4760],
       device='cuda:1')
Original likelihood: -31.597423553466797
Adjusted likelihood: -31.597423553466797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1917)
State is out of distribution
Projection step: 0, Loss: 31.805389404296875
Projection step: 1, Loss: 28.869342803955078
Projection step: 2, Loss: 25.848377227783203
Projection step: 3, Loss: 24.009952545166016
Projection step: 4, Loss: 23.465442657470703
Projection step: 5, Loss: 19.491722106933594
Projection step: 6, Loss: 18.211090087890625
Projection step: 7, Loss: 17.865821838378906
Projection step: 8, Loss: 15.784648895263672
Projection step: 9, Loss: 16.82115364074707
Projection step: 10, Loss: 15.534000396728516
Projection step: 11, Loss: 15.691734313964844
Projection step: 12, Loss: 15.729633331298828
Projection step: 13, Loss: 13.740055084228516
Final likelihood: tensor([-13.6307, -13.8757, -11.7589, -15.9203,  -9.8809, -16.9073, -16.1880,
        -13.4385, -14.6510, -11.0638, -13.3789, -18.0221, -14.2542, -10.2119,
        -13.5668, -13.0919])
Final projection likelihood: -13.7401
1 mode projection succeeded
New goal: tensor([ 0.0739,  0.5781,  0.5633,  0.5637, -0.0901,  0.5589,  0.8562,  0.7888,
         1.4227,  0.1684,  0.2424,  1.1433,  0.0166,  0.0175, -1.7138],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -20.45164680480957
Adjusted likelihood: -20.45164680480957
Likelihood residual: 0.0
{'index': 20.45164680480957, 'thumb_middle': inf}
Current yaw: tensor([0.0174, 0.0453, 0.0463], device='cuda:1')
4 index
tensor([ 0.1049,  0.4853,  0.6797,  0.6259, -0.1420,  0.6225,  0.7650,  0.7742,
         1.5000,  0.0344,  0.2113,  0.9642,  0.0174,  0.0453,  0.0463,  0.4760],
       device='cuda:1')
Solve time for step 1 11.137650268996367
Current ori: tensor([0.0174, 0.0453, 0.0463], device='cuda:1')
Middle force: tensor([0.5321, 0.6163, 0.5777, 0.5585], device='cuda:1')
Thumb force: tensor([0.5772, 0.5715, 0.6228, 0.5656], device='cuda:1')
tensor([ 0.1238,  0.5018,  0.5395,  0.5551, -0.1392,  0.5743,  0.8385,  0.7909,
         1.4503,  0.1089,  0.2163,  1.0129,  0.0362,  0.0396,  0.0358,  0.8137],
       device='cuda:1')
Solve time for step 2 2.466392425005324
Current ori: tensor([0.0362, 0.0396, 0.0358], device='cuda:1')
Middle force: tensor([0.6136, 0.5752, 0.5561], device='cuda:1')
Thumb force: tensor([0.5672, 0.6196, 0.5632], device='cuda:1')
tensor([ 0.1151,  0.5162,  0.5253,  0.5487, -0.1162,  0.5822,  0.8490,  0.7835,
         1.4235,  0.1349,  0.1971,  1.0431,  0.0360,  0.0245,  0.0386,  0.7995],
       device='cuda:1')
Solve time for step 3 2.3130424130067695
Current ori: tensor([0.0360, 0.0245, 0.0386], device='cuda:1')
Middle force: tensor([0.5349, 0.5549], device='cuda:1')
Thumb force: tensor([0.5661, 0.5655], device='cuda:1')
tensor([ 0.1166,  0.5201,  0.5249,  0.5479, -0.1034,  0.5845,  0.8554,  0.7873,
         1.4157,  0.1368,  0.1795,  1.0648,  0.0369,  0.0145,  0.0325,  0.5715],
       device='cuda:1')
Solve time for step 4 2.32010645698756
Current ori: tensor([0.0369, 0.0145, 0.0325], device='cuda:1')
Middle force: tensor([0.5361], device='cuda:1')
Thumb force: tensor([0.5641], device='cuda:1')
Storing RECOVERY transition: reward=0.0033 (scaled=0.0033), steps=1
Reward stats updated: mean -0.0291 -> -0.0278, std: 0.1206
Collected 24 transitions for RL
Original likelihood: -16.830093383789062
Adjusted likelihood: -16.830093383789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([0.0363, 0.0125, 0.0438], device='cuda:1')
5 turn
Sampling time 4.093057634017896
tensor([ 0.0722,  0.5734,  0.5601,  0.5611, -0.0992,  0.5906,  0.8515,  0.7816,
         1.4079,  0.1463,  0.1770,  1.0724,  0.0363,  0.0125,  0.0438,  0.4969],
       device='cuda:1')
Original likelihood: -19.1491756439209
Adjusted likelihood: -19.1491756439209
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.265934402996209
Current ori: tensor([0.0363, 0.0125, 0.0438], device='cuda:1')
Middle force: tensor([0.7288, 2.3203, 0.8589, 0.4971, 0.7492, 0.5223, 0.5841, 0.9115, 0.5447,
        0.5632, 0.5353, 0.5718], device='cuda:1')
Thumb force: tensor([0.9719, 0.7503, 0.5715, 1.0515, 0.5435, 1.2648, 0.5024, 0.7989, 1.2411,
        0.5870, 0.6138, 0.5633], device='cuda:1')
Index force: tensor([0.9670, 0.9862, 0.5552, 0.7624, 0.6022, 0.5793, 0.5046, 0.8404, 0.5472,
        0.6504, 0.6721, 0.5938], device='cuda:1')
Storing NORMAL transition: reward=-0.0028 (scaled=-0.0028), steps=1
Reward stats updated: mean -0.0278 -> -0.0268, std: 0.1183
Collected 25 transitions for RL
tensor([ 0.0893,  0.4721,  0.6378,  0.7145, -0.0632,  0.5632,  0.7875,  0.8133,
         1.4615, -0.0520,  0.2478,  1.0923,  0.0739,  0.0145,  0.0425,  0.5663],
       device='cuda:1')
Original likelihood: -30.439090728759766
Adjusted likelihood: -30.439090728759766
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4053)
State is out of distribution
Projection step: 0, Loss: 29.699417114257812
Projection step: 1, Loss: 26.997920989990234
Projection step: 2, Loss: 25.243576049804688
Projection step: 3, Loss: 24.699291229248047
Projection step: 4, Loss: 24.302730560302734
Projection step: 5, Loss: 24.090927124023438
Projection step: 6, Loss: 22.20049476623535
Projection step: 7, Loss: 21.69377326965332
Projection step: 8, Loss: 21.7053165435791
Projection step: 9, Loss: 21.9636173248291
Projection step: 10, Loss: 19.99930763244629
Projection step: 11, Loss: 19.938112258911133
Projection step: 12, Loss: 19.86478614807129
Projection step: 13, Loss: 18.948360443115234
Projection step: 14, Loss: 18.38916015625
Final likelihood: tensor([-16.7274, -18.9417, -15.9836, -20.2655, -16.1241, -19.3878, -18.4577,
        -18.0140, -16.2890, -16.2372, -16.5996, -16.9226, -15.6493, -15.9550,
        -19.4992, -20.2269])
Final projection likelihood: -17.5800
1 mode projection succeeded
New goal: tensor([ 6.4419e-02,  5.5137e-01,  5.7122e-01,  5.9391e-01, -6.5293e-02,
         4.8732e-01,  8.9716e-01,  9.0428e-01,  1.3967e+00,  1.0169e-01,
         2.0849e-01,  1.1920e+00,  5.6556e-02,  6.0892e-04, -1.1392e+00],
       device='cuda:1')
tensor([[0.0033]], device='cuda:1') tensor([[0.0045]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -21.629796981811523
Adjusted likelihood: -21.629796981811523
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.629796981811523}
Current yaw: tensor([0.0739, 0.0145, 0.0425], device='cuda:1')
6 thumb_middle
tensor([ 0.0893,  0.4721,  0.6378,  0.7145, -0.0632,  0.5632,  0.7875,  0.8133,
         1.4615, -0.0520,  0.2478,  1.0923,  0.0739,  0.0145,  0.0425,  0.5663],
       device='cuda:1')
Solve time for step 1 8.944019426999148
Current ori: tensor([0.0739, 0.0145, 0.0425], device='cuda:1')
Index force: tensor([0.5750, 0.6025, 0.6160, 0.5040], device='cuda:1')
tensor([ 0.0930,  0.5032,  0.6223,  0.6665, -0.1569,  0.4757,  0.8362,  0.8582,
         1.3580,  0.0294,  0.1273,  1.1255,  0.0620,  0.0099,  0.0425,  0.5431],
       device='cuda:1')
Solve time for step 2 2.0605043929826934
Current ori: tensor([0.0620, 0.0099, 0.0425], device='cuda:1')
Index force: tensor([0.5966, 0.6125, 0.5020], device='cuda:1')
tensor([ 0.0856,  0.4593,  0.6581,  0.6994, -0.1778,  0.4770,  0.8570,  0.8732,
         1.3689,  0.0564,  0.1077,  1.1392,  0.0756,  0.0162,  0.0425,  0.5576],
       device='cuda:1')
Solve time for step 3 1.866492166009266
Current ori: tensor([0.0756, 0.0162, 0.0425], device='cuda:1')
Index force: tensor([0.6049, 0.5006], device='cuda:1')
tensor([ 0.0827,  0.4368,  0.6688,  0.7334, -0.1806,  0.4703,  0.8554,  0.8768,
         1.3789,  0.0640,  0.1047,  1.1433,  0.0842,  0.0202,  0.0425,  0.5737],
       device='cuda:1')
Solve time for step 4 1.8886092690227088
Current ori: tensor([0.0842, 0.0202, 0.0425], device='cuda:1')
Index force: tensor([0.5006], device='cuda:1')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0061), steps=1
Reward stats updated: mean -0.0268 -> -0.0255, std: 0.1161
Collected 26 transitions for RL
Original likelihood: -31.82577133178711
Adjusted likelihood: -31.82577133178711
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1596)
State is out of distribution
Projection step: 0, Loss: 30.792964935302734
Projection step: 1, Loss: 29.25713348388672
Projection step: 2, Loss: 28.12660789489746
Projection step: 3, Loss: 26.176376342773438
Projection step: 4, Loss: 24.972869873046875
Projection step: 5, Loss: 24.61292839050293
Projection step: 6, Loss: 24.05622673034668
Projection step: 7, Loss: 24.37217140197754
Projection step: 8, Loss: 23.38869857788086
Projection step: 9, Loss: 23.146968841552734
Projection step: 10, Loss: 22.034902572631836
Projection step: 11, Loss: 22.261600494384766
Projection step: 12, Loss: 21.574169158935547
Projection step: 13, Loss: 21.471866607666016
Projection step: 14, Loss: 21.20694351196289
Final likelihood: tensor([-21.3576, -20.5399, -18.9246, -18.8423, -17.2457, -18.2354, -20.5561,
        -19.7359, -21.9592, -19.4177, -20.6140, -21.9031, -23.1160, -24.1085,
        -18.2369, -20.3834])
Final projection likelihood: -20.3235
1 mode projection succeeded
New goal: tensor([ 0.0701,  0.5387,  0.5736,  0.6252, -0.0600,  0.4763,  0.9071,  0.9560,
         1.3728,  0.1452,  0.2130,  1.2302,  0.0637, -0.0017, -1.0915],
       device='cuda:1')
tensor([[0.0031]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -22.987342834472656
Adjusted likelihood: -22.987342834472656
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.987342834472656}
Current yaw: tensor([0.0813, 0.0117, 0.0354], device='cuda:1')
7 thumb_middle
tensor([ 0.0806,  0.4408,  0.6796,  0.6943, -0.1012,  0.5176,  0.9042,  0.8979,
         1.4330,  0.0985,  0.1512,  1.1762,  0.0813,  0.0117,  0.0354,  0.4675],
       device='cuda:1')
Solve time for step 1 9.159874839999247
Current ori: tensor([0.0813, 0.0117, 0.0354], device='cuda:1')
Index force: tensor([0.5801, 0.5670, 0.5621, 0.5744], device='cuda:1')
tensor([ 0.0747,  0.4984,  0.6180,  0.6530, -0.1809,  0.4567,  0.8636,  0.9081,
         1.3339,  0.0934,  0.0997,  1.1802,  0.0634,  0.0187,  0.0354,  0.4674],
       device='cuda:1')
Solve time for step 2 2.0837863789929543
Current ori: tensor([0.0634, 0.0187, 0.0354], device='cuda:1')
Index force: tensor([0.5614, 0.5576, 0.5693], device='cuda:1')
tensor([ 0.0751,  0.5355,  0.5793,  0.6300, -0.1776,  0.4432,  0.8713,  0.9143,
         1.3438,  0.0875,  0.0947,  1.1623,  0.0525,  0.0165,  0.0354,  0.4486],
       device='cuda:1')
Solve time for step 3 1.8154970659816172
Current ori: tensor([0.0525, 0.0165, 0.0354], device='cuda:1')
Index force: tensor([0.5516, 0.5636], device='cuda:1')
tensor([ 0.0799,  0.5472,  0.5665,  0.6328, -0.1855,  0.4598,  0.8693,  0.9263,
         1.3275,  0.0896,  0.1022,  1.1730,  0.0501,  0.0138,  0.0354,  0.4496],
       device='cuda:1')
Solve time for step 4 1.7153685049852356
Current ori: tensor([0.0501, 0.0138, 0.0354], device='cuda:1')
Index force: tensor([0.5593], device='cuda:1')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0056), steps=1
Reward stats updated: mean -0.0255 -> -0.0248, std: 0.1140
Collected 27 transitions for RL
Original likelihood: -25.59756088256836
Adjusted likelihood: -25.59756088256836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9919)
Current yaw: tensor([0.0570, 0.0195, 0.0501], device='cuda:1')
8 turn
Sampling time 3.861002063000342
tensor([ 0.0682,  0.5155,  0.6025,  0.6255, -0.1347,  0.5055,  0.9065,  0.9302,
         1.4040,  0.1244,  0.1539,  1.2098,  0.0570,  0.0195,  0.0501,  0.4612],
       device='cuda:1')
Original likelihood: -24.630956649780273
Adjusted likelihood: -24.630956649780273
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9983)
Solve time for step 1 14.774303495010827
Current ori: tensor([0.0570, 0.0195, 0.0501], device='cuda:1')
Middle force: tensor([0.8515, 1.3986, 0.6898, 0.5112, 0.5281, 0.7255, 0.5441, 0.5981, 0.5882,
        0.5587, 0.5517, 0.5896], device='cuda:1')
Thumb force: tensor([1.5894, 1.4941, 0.5706, 0.5429, 0.8947, 2.0178, 1.0165, 0.5914, 0.5602,
        0.6521, 0.5149, 0.6356], device='cuda:1')
Index force: tensor([1.0810, 1.4279, 1.0028, 0.6300, 1.2602, 0.7394, 0.5276, 0.6065, 0.6278,
        0.6332, 0.8587, 0.5542], device='cuda:1')
Storing NORMAL transition: reward=0.1341 (scaled=0.1341), steps=1
Reward stats updated: mean -0.0248 -> -0.0191, std: 0.1158
Collected 28 transitions for RL
tensor([ 0.1219,  0.5914,  0.5426,  0.6225, -0.0842,  0.4783,  0.9698,  1.0790,
         1.1681,  0.4661,  0.4360,  0.8368,  0.0726, -0.0256, -0.0881, -0.0883],
       device='cuda:1')
Original likelihood: -33.291046142578125
Adjusted likelihood: -33.291046142578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0363)
State is out of distribution
Projection step: 0, Loss: 33.441776275634766
Projection step: 1, Loss: 30.774147033691406
Projection step: 2, Loss: 27.58551025390625
Projection step: 3, Loss: 25.254514694213867
Projection step: 4, Loss: 24.89581298828125
Projection step: 5, Loss: 22.879512786865234
Projection step: 6, Loss: 21.572925567626953
Projection step: 7, Loss: 21.708820343017578
Projection step: 8, Loss: 19.69021224975586
Projection step: 9, Loss: 19.990169525146484
Projection step: 10, Loss: 19.504070281982422
Projection step: 11, Loss: 18.7689208984375
Projection step: 12, Loss: 18.931148529052734
Projection step: 13, Loss: 17.922067642211914
Projection step: 14, Loss: 17.992332458496094
Final likelihood: tensor([-18.9798, -16.8267, -16.8102, -18.8603, -19.1212, -20.2971, -18.4605,
        -18.8081, -15.5999, -17.0775, -19.6548, -18.9839, -18.7667, -18.7703,
        -19.4135, -19.6702])
Final projection likelihood: -18.5063
1 mode projection succeeded
New goal: tensor([ 0.0705,  0.5371,  0.6216,  0.5641, -0.0593,  0.4906,  0.9155,  0.8819,
         1.2780,  0.2736,  0.2320,  1.1481,  0.0585, -0.0124, -1.0794],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -25.369243621826172
Adjusted likelihood: -25.369243621826172
Likelihood residual: 0.0
Original likelihood: -30.034015655517578
Adjusted likelihood: -30.034015655517578
Likelihood residual: 0.0
{'index': 30.034015655517578, 'thumb_middle': 25.369243621826172}
Current yaw: tensor([ 0.0726, -0.0256, -0.0881], device='cuda:1')
9 thumb_middle
tensor([ 0.1219,  0.5914,  0.5426,  0.6225, -0.0842,  0.4783,  0.9698,  1.0790,
         1.1681,  0.4661,  0.4360,  0.8368,  0.0726, -0.0256, -0.0881, -0.0883],
       device='cuda:1')
Solve time for step 1 9.09212702998775
Current ori: tensor([ 0.0726, -0.0256, -0.0881], device='cuda:1')
Index force: tensor([0.5880, 0.5934, 0.6003, 0.6038], device='cuda:1')
tensor([ 0.1160,  0.5643,  0.6028,  0.5664, -0.1365,  0.4690,  0.8952,  0.9076,
         1.2133,  0.3087,  0.1919,  1.0380,  0.0734, -0.0236, -0.0881, -0.1107],
       device='cuda:1')
Solve time for step 2 1.9492290409980342
Current ori: tensor([ 0.0734, -0.0236, -0.0881], device='cuda:1')
Index force: tensor([0.5888, 0.5983, 0.6013], device='cuda:1')
tensor([ 0.0774,  0.5204,  0.6232,  0.5700, -0.1648,  0.4810,  0.8842,  0.8686,
         1.2558,  0.2792,  0.1644,  1.0884,  0.0826, -0.0038, -0.0881, -0.1375],
       device='cuda:1')
Solve time for step 3 1.8919290810008533
Current ori: tensor([ 0.0826, -0.0038, -0.0881], device='cuda:1')
Index force: tensor([0.5912, 0.5958], device='cuda:1')
tensor([ 0.0858,  0.5304,  0.6222,  0.5608, -0.1554,  0.4951,  0.8864,  0.8626,
         1.2593,  0.2625,  0.1445,  1.0965,  0.0796, -0.0084, -0.0881, -0.1361],
       device='cuda:1')
Solve time for step 4 1.8312632199958898
Current ori: tensor([ 0.0796, -0.0084, -0.0881], device='cuda:1')
Index force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=0.0176 (scaled=0.0176), steps=1
Reward stats updated: mean -0.0191 -> -0.0178, std: 0.1140
Collected 29 transitions for RL
Original likelihood: -25.371501922607422
Adjusted likelihood: -25.371501922607422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9942)
Current yaw: tensor([ 0.0791, -0.0155, -0.1069], device='cuda:1')
10 turn
Sampling time 3.8061560319911223
tensor([ 0.0855,  0.5372,  0.6308,  0.5211, -0.0816,  0.5399,  0.9360,  0.8944,
         1.3087,  0.2799,  0.1962,  1.1387,  0.0791, -0.0155, -0.1069, -0.1638],
       device='cuda:1')
Original likelihood: -23.94284439086914
Adjusted likelihood: -23.94284439086914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 1 13.52901629099506
Current ori: tensor([ 0.0791, -0.0155, -0.1069], device='cuda:1')
Middle force: tensor([0.5316, 1.0601, 0.5633, 0.5489, 0.9072, 1.3395, 0.6023, 0.5462, 0.5324,
        0.5450, 0.5813, 0.5540], device='cuda:1')
Thumb force: tensor([1.2255, 1.0287, 0.6237, 0.5769, 0.5467, 0.5220, 0.5953, 1.2157, 0.5858,
        0.5344, 1.0796, 0.5910], device='cuda:1')
Index force: tensor([0.6870, 1.2761, 0.5763, 0.5511, 0.9171, 0.8270, 0.5559, 0.5174, 0.5567,
        0.5110, 0.6013, 0.6237], device='cuda:1')
Storing NORMAL transition: reward=0.0388 (scaled=0.0388), steps=1
Reward stats updated: mean -0.0178 -> -0.0159, std: 0.1125
Collected 30 transitions for RL
tensor([ 0.0254,  0.5948,  0.5066,  0.4988, -0.1974,  0.6003,  0.9086,  0.9488,
         1.5000, -0.0112,  0.2025,  1.0188,  0.0762,  0.0129, -0.1456,  0.0520],
       device='cuda:1')
Original likelihood: -34.973777770996094
Adjusted likelihood: -34.973777770996094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0033)
State is out of distribution
Projection step: 0, Loss: 34.69280242919922
Projection step: 1, Loss: 31.99830436706543
Projection step: 2, Loss: 29.693904876708984
Projection step: 3, Loss: 27.48882484436035
Projection step: 4, Loss: 26.93377685546875
Projection step: 5, Loss: 26.35245132446289
Projection step: 6, Loss: 25.821048736572266
Projection step: 7, Loss: 24.07985496520996
Projection step: 8, Loss: 23.747657775878906
Projection step: 9, Loss: 23.6871337890625
Projection step: 10, Loss: 23.337099075317383
Projection step: 11, Loss: 24.159469604492188
Projection step: 12, Loss: 21.865510940551758
Projection step: 13, Loss: 21.17896842956543
Projection step: 14, Loss: 22.189502716064453
Final likelihood: tensor([-20.7816, -21.0210, -19.2058, -20.2484, -21.1073, -19.8889, -24.3144,
        -18.3893, -22.1262, -19.3641, -19.6312, -20.6528, -23.6429, -19.7544,
        -22.5339, -19.1050])
Final projection likelihood: -20.7355
1 mode projection succeeded
New goal: tensor([ 0.0535,  0.5976,  0.5313,  0.5089, -0.0954,  0.5058,  0.8470,  0.8807,
         1.4400,  0.0726,  0.2368,  1.1336,  0.0584,  0.0094, -1.0654],
       device='cuda:1')
tensor([[0.0036]], device='cuda:1') tensor([[0.0031]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -26.322341918945312
Adjusted likelihood: -26.322341918945312
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 26.322341918945312}
Current yaw: tensor([ 0.0762,  0.0129, -0.1456], device='cuda:1')
11 thumb_middle
tensor([ 0.0254,  0.5948,  0.5066,  0.4988, -0.1974,  0.6003,  0.9086,  0.9488,
         1.5000, -0.0112,  0.2025,  1.0188,  0.0762,  0.0129, -0.1456,  0.0520],
       device='cuda:1')
Solve time for step 1 8.811377934005577
Current ori: tensor([ 0.0762,  0.0129, -0.1456], device='cuda:1')
Index force: tensor([0.5655, 0.5759, 0.5873, 0.5879], device='cuda:1')
tensor([ 0.0225,  0.5855,  0.5211,  0.4866, -0.1980,  0.5082,  0.8297,  0.8828,
         1.3932,  0.0119,  0.1428,  1.0771,  0.1104,  0.0401, -0.1456,  0.6499],
       device='cuda:1')
Solve time for step 2 1.86786014601239
Current ori: tensor([ 0.1104,  0.0401, -0.1456], device='cuda:1')
Index force: tensor([0.5721, 0.5838, 0.5842], device='cuda:1')
tensor([ 0.0383,  0.6019,  0.5049,  0.5030, -0.1946,  0.5112,  0.8236,  0.8559,
         1.4103,  0.0169,  0.1401,  1.0841,  0.1065,  0.0297, -0.1456,  0.6885],
       device='cuda:1')
Solve time for step 3 1.8078071429918054
Current ori: tensor([ 0.1065,  0.0297, -0.1456], device='cuda:1')
Index force: tensor([0.5779, 0.5787], device='cuda:1')
tensor([ 0.0393,  0.5968,  0.5149,  0.4997, -0.1878,  0.5120,  0.8130,  0.8437,
         1.4097,  0.0317,  0.1378,  1.0987,  0.1075,  0.0294, -0.1456,  0.6751],
       device='cuda:1')
Solve time for step 4 1.7531329799967352
Current ori: tensor([ 0.1075,  0.0294, -0.1456], device='cuda:1')
Index force: tensor([0.5520], device='cuda:1')
Storing RECOVERY transition: reward=0.0080 (scaled=0.0080), steps=1
Reward stats updated: mean -0.0159 -> -0.0152, std: 0.1108
Collected 31 transitions for RL
Original likelihood: -39.164249420166016
Adjusted likelihood: -39.164249420166016
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 39.12425994873047
Projection step: 1, Loss: 34.9864501953125
Projection step: 2, Loss: 33.4539794921875
Projection step: 3, Loss: 33.83557891845703
Projection step: 4, Loss: 31.583646774291992
Projection step: 5, Loss: 32.500709533691406
Projection step: 6, Loss: 32.78016662597656
Projection step: 7, Loss: 31.422191619873047
Projection step: 8, Loss: 30.823070526123047
Projection step: 9, Loss: 31.45081329345703
Projection step: 10, Loss: 29.98592758178711
Projection step: 11, Loss: 30.1392765045166
Projection step: 12, Loss: 30.065570831298828
Projection step: 13, Loss: 29.017982482910156
Projection step: 14, Loss: 27.852142333984375
Final likelihood: tensor([-27.2745, -26.7564, -33.8687, -27.4019, -30.3375, -28.0805, -30.4240,
        -27.2230, -29.3441, -27.7941, -25.2676, -31.3746, -30.1236, -29.4140,
        -26.2086, -26.8508])
Final projection likelihood: -28.6090
1 mode projection succeeded
New goal: tensor([ 0.0589,  0.6219,  0.5233,  0.4950, -0.0924,  0.4984,  0.8474,  0.8618,
         1.4303,  0.0772,  0.2270,  1.1520,  0.0859,  0.0165, -0.3596],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -34.3476676940918
Adjusted likelihood: -34.3476676940918
Likelihood residual: 0.0
Original likelihood: -33.199066162109375
Adjusted likelihood: -33.199066162109375
Likelihood residual: 0.0
{'index': 33.199066162109375, 'thumb_middle': 34.3476676940918}
Current yaw: tensor([ 0.1049,  0.0246, -0.1596], device='cuda:1')
12 index
tensor([ 0.0282,  0.6126,  0.4907,  0.4779, -0.1136,  0.5579,  0.8759,  0.8835,
         1.4745,  0.0689,  0.1874,  1.1314,  0.1049,  0.0246, -0.1596,  0.5779],
       device='cuda:1')
Solve time for step 1 10.658896883018315
Current ori: tensor([ 0.1049,  0.0246, -0.1596], device='cuda:1')
Middle force: tensor([0.5753, 0.5384, 0.5212, 0.5555], device='cuda:1')
Thumb force: tensor([0.5556, 0.6057, 0.5362, 0.5774], device='cuda:1')
tensor([ 0.0701,  0.4751,  0.4782,  0.4967, -0.1109,  0.5920,  0.8774,  0.8583,
         1.4717,  0.0863,  0.1801,  1.1063,  0.1030,  0.0157, -0.1422, -0.8247],
       device='cuda:1')
Solve time for step 2 2.241571502003353
Current ori: tensor([ 0.1030,  0.0157, -0.1422], device='cuda:1')
Middle force: tensor([0.5363, 0.5205, 0.5540], device='cuda:1')
Thumb force: tensor([0.6031, 0.5355, 0.5758], device='cuda:1')
tensor([ 0.0783,  0.4840,  0.4851,  0.5004, -0.1102,  0.6470,  0.8884,  0.8449,
         1.5000,  0.0783,  0.1828,  1.0892,  0.1534,  0.0107, -0.1311, -1.7603],
       device='cuda:1')
Solve time for step 3 2.204253470990807
Current ori: tensor([ 0.1534,  0.0107, -0.1311], device='cuda:1')
Middle force: tensor([0.5195, 0.5529], device='cuda:1')
Thumb force: tensor([0.5344, 0.5729], device='cuda:1')
tensor([ 0.0679,  0.4511,  0.4846,  0.5046, -0.1066,  0.7095,  0.9020,  0.8334,
         1.5000,  0.1086,  0.2044,  1.0577,  0.2490,  0.0197, -0.1421, -1.8229],
       device='cuda:1')
Solve time for step 4 2.1063466370105743
Current ori: tensor([ 0.2490,  0.0197, -0.1421], device='cuda:1')
Middle force: tensor([0.5499], device='cuda:1')
Thumb force: tensor([0.5666], device='cuda:1')
Storing RECOVERY transition: reward=-0.0328 (scaled=-0.0328), steps=1
Reward stats updated: mean -0.0152 -> -0.0157, std: 0.1091
Collected 32 transitions for RL
Original likelihood: -50.13987350463867
Adjusted likelihood: -50.13987350463867
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 54.73640441894531
Projection step: 1, Loss: 48.29065704345703
Projection step: 2, Loss: 50.773712158203125
Projection step: 3, Loss: 47.98579025268555
Projection step: 4, Loss: 47.62361145019531
Projection step: 5, Loss: 44.35319519042969
Projection step: 6, Loss: 47.15406036376953
Projection step: 7, Loss: 43.248023986816406
Projection step: 8, Loss: 42.61030197143555
Projection step: 9, Loss: 42.901920318603516
Projection step: 10, Loss: 43.228675842285156
Projection step: 11, Loss: 43.62891387939453
Projection step: 12, Loss: 42.58087921142578
Projection step: 13, Loss: 40.858333587646484
Projection step: 14, Loss: 41.22229766845703
Final likelihood: tensor([-32.1734, -36.5942, -39.1988, -32.9356, -38.6130, -40.0123, -40.9499,
        -42.4368, -40.3322, -41.9646, -44.1150, -38.7184, -44.5006, -35.6188,
        -46.3084, -38.8233])
Final projection likelihood: -39.5809
1 mode projection failed, trying anyway
New goal: tensor([ 0.0603,  0.4992,  0.6348,  0.7108, -0.0769,  0.6091,  0.8715,  1.0605,
         1.4653, -0.0312,  0.2987,  0.9046,  0.2316,  0.0196,  0.2401],
       device='cuda:1')
tensor([[0.0076]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0007]], device='cuda:1')
Original likelihood: -46.165225982666016
Adjusted likelihood: -46.165225982666016
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 46.165225982666016}
Current yaw: tensor([ 0.2437,  0.0179, -0.1672], device='cuda:1')
13 thumb_middle
tensor([ 0.0789,  0.4987,  0.5629,  0.5088, -0.0859,  0.7418,  0.9185,  0.8858,
         1.5000,  0.1421,  0.2402,  1.1049,  0.2437,  0.0179, -0.1672, -1.9635],
       device='cuda:1')
Solve time for step 1 9.252226698998129
Current ori: tensor([ 0.2437,  0.0179, -0.1672], device='cuda:1')
Index force: tensor([0.6026, 0.5483, 0.5897, 0.5878], device='cuda:1')
tensor([ 0.0909,  0.5001,  0.6398,  0.6688, -0.2097,  0.5229,  0.8678,  1.0164,
         1.4672, -0.0192,  0.3077,  1.0119,  0.2430,  0.0185, -0.1896, -1.9981],
       device='cuda:1')
Solve time for step 2 2.035115954000503
Current ori: tensor([ 0.2430,  0.0185, -0.1896], device='cuda:1')
Index force: tensor([0.5471, 0.5865, 0.5847], device='cuda:1')
tensor([ 0.0914,  0.4993,  0.6498,  0.7004, -0.2195,  0.5241,  0.8632,  1.0379,
         1.4890, -0.0353,  0.3081,  0.9861,  0.2437,  0.0224, -0.2087, -2.0051],
       device='cuda:1')
Solve time for step 3 1.9399256339820568
Current ori: tensor([ 0.2437,  0.0224, -0.2087], device='cuda:1')
Index force: tensor([0.5835, 0.5821], device='cuda:1')
tensor([ 0.0978,  0.5037,  0.6590,  0.7099, -0.2207,  0.5254,  0.8655,  1.0482,
         1.4887, -0.0464,  0.3242,  0.9863,  0.2430,  0.0243, -0.2207, -1.9622],
       device='cuda:1')
Solve time for step 4 1.8380945989920292
Current ori: tensor([ 0.2430,  0.0243, -0.2207], device='cuda:1')
Index force: tensor([0.5424], device='cuda:1')
Storing RECOVERY transition: reward=-0.0147 (scaled=-0.0147), steps=1
Reward stats updated: mean -0.0157 -> -0.0157, std: 0.1074
Collected 33 transitions for RL
Original likelihood: -52.745826721191406
Adjusted likelihood: -52.745826721191406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 52.89751434326172
Projection step: 1, Loss: 48.29430389404297
Projection step: 2, Loss: 50.42451095581055
Projection step: 3, Loss: 44.46583557128906
Projection step: 4, Loss: 44.72224807739258
Projection step: 5, Loss: 43.11896514892578
Projection step: 6, Loss: 44.15802764892578
Projection step: 7, Loss: 43.13597106933594
Projection step: 8, Loss: 43.149391174316406
Projection step: 9, Loss: 45.80150604248047
Projection step: 10, Loss: 43.39213562011719
Projection step: 11, Loss: 41.99568176269531
Projection step: 12, Loss: 42.19350051879883
Projection step: 13, Loss: 39.44574737548828
Projection step: 14, Loss: 41.17203140258789
Final likelihood: tensor([-37.8036, -49.0154, -38.9701, -45.9846, -38.7297, -32.6150, -36.8479,
        -39.2638, -41.8988, -39.7630, -37.5757, -39.3277, -36.2831, -50.6406,
        -71.9057, -33.3909])
Final projection likelihood: -41.8760
1 mode projection failed, trying anyway
New goal: tensor([ 0.0583,  0.4364,  0.6438,  0.8319, -0.0807,  0.5761,  0.8593,  1.1463,
         1.4990, -0.1238,  0.4569,  0.7679,  0.2334,  0.0263,  0.4067],
       device='cuda:1')
tensor([[0.0042]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0006]], device='cuda:1')
Original likelihood: -49.066017150878906
Adjusted likelihood: -49.066017150878906
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 49.066017150878906}
Current yaw: tensor([ 0.2453,  0.0261, -0.1890], device='cuda:1')
14 thumb_middle
tensor([ 6.8566e-02,  4.9641e-01,  6.6650e-01,  7.2642e-01, -1.1141e-01,
         6.3338e-01,  9.1467e-01,  1.0838e+00,  1.5000e+00,  4.3874e-04,
         4.4392e-01,  1.0085e+00,  2.4530e-01,  2.6073e-02, -1.8901e-01,
        -1.9648e+00], device='cuda:1')
Solve time for step 1 9.099669242015807
Current ori: tensor([ 0.2453,  0.0261, -0.1890], device='cuda:1')
Index force: tensor([0.6039, 0.5477, 0.5984, 0.5472], device='cuda:1')
tensor([ 0.0776,  0.5000,  0.6686,  0.7878, -0.2205,  0.4683,  0.8461,  1.1105,
         1.4890, -0.1050,  0.4566,  0.8784,  0.2447,  0.0273, -0.2056, -1.9872],
       device='cuda:1')
Solve time for step 2 1.9793474979815073
Current ori: tensor([ 0.2447,  0.0273, -0.2056], device='cuda:1')
Index force: tensor([0.5459, 0.5951, 0.5451], device='cuda:1')
tensor([ 0.0746,  0.4969,  0.6632,  0.8136, -0.2303,  0.4676,  0.8412,  1.1277,
         1.5000, -0.1050,  0.4534,  0.8457,  0.2457,  0.0308, -0.2257, -2.0227],
       device='cuda:1')
Solve time for step 3 1.8901118509820662
Current ori: tensor([ 0.2457,  0.0308, -0.2257], device='cuda:1')
Index force: tensor([0.5912, 0.5431], device='cuda:1')
tensor([ 0.0777,  0.4976,  0.6555,  0.8243, -0.2378,  0.4742,  0.8357,  1.1236,
         1.5000, -0.1050,  0.4523,  0.8267,  0.2462,  0.0354, -0.2524, -2.0497],
       device='cuda:1')
Solve time for step 4 1.8360394079936668
Current ori: tensor([ 0.2462,  0.0354, -0.2524], device='cuda:1')
Index force: tensor([0.5844], device='cuda:1')
Storing RECOVERY transition: reward=0.0416 (scaled=0.0416), steps=1
Reward stats updated: mean -0.0157 -> -0.0140, std: 0.1062
Collected 34 transitions for RL
Original likelihood: -48.09690475463867
Adjusted likelihood: -48.09690475463867
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 52.87355041503906
Projection step: 1, Loss: 47.51847839355469
Projection step: 2, Loss: 49.88755798339844
Projection step: 3, Loss: 47.507667541503906
Projection step: 4, Loss: 46.697265625
Projection step: 5, Loss: 45.390167236328125
Projection step: 6, Loss: 45.09895324707031
Projection step: 7, Loss: 45.10978317260742
Projection step: 8, Loss: 45.019649505615234
Projection step: 9, Loss: 43.81177520751953
Projection step: 10, Loss: 40.990684509277344
Projection step: 11, Loss: 44.28413772583008
Projection step: 12, Loss: 42.29447555541992
Projection step: 13, Loss: 41.72649383544922
Projection step: 14, Loss: 40.359771728515625
Final likelihood: tensor([-35.6088, -36.2688, -35.4818, -52.5535, -37.2901, -34.7762, -39.0095,
        -57.2865, -40.8765, -36.4394, -36.7003, -37.0433, -62.7420, -33.8819,
        -43.7731, -38.0284])
Final projection likelihood: -41.1100
1 mode projection failed, trying anyway
New goal: tensor([ 0.0548,  0.4176,  0.6336,  0.8718, -0.0866,  0.5612,  0.8520,  1.1847,
         1.5172, -0.1652,  0.5601,  0.6554,  0.2347,  0.0313,  0.3983],
       device='cuda:1')
tensor([[0.0045]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0005]], device='cuda:1')
Original likelihood: -49.15222930908203
Adjusted likelihood: -49.15222930908203
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 49.15222930908203}
Current yaw: tensor([ 0.2472,  0.0317, -0.2566], device='cuda:1')
15 thumb_middle
tensor([ 0.0601,  0.4962,  0.6465,  0.8231, -0.1177,  0.5952,  0.8861,  1.1646,
         1.5000, -0.0699,  0.5745,  0.8717,  0.2472,  0.0317, -0.2566, -2.0133],
       device='cuda:1')
Solve time for step 1 9.068492536986014
Current ori: tensor([ 0.2472,  0.0317, -0.2566], device='cuda:1')
Index force: tensor([0.5990, 0.5862, 0.5941, 0.5749], device='cuda:1')
tensor([ 0.0727,  0.4949,  0.6511,  0.8618, -0.2270,  0.4310,  0.8295,  1.1544,
         1.5000, -0.1050,  0.5631,  0.7678,  0.2628,  0.0753, -0.2851, -1.9784],
       device='cuda:1')
Solve time for step 2 1.9549516609986313
Current ori: tensor([ 0.2628,  0.0753, -0.2851], device='cuda:1')
Index force: tensor([0.5830, 0.5903, 0.5711], device='cuda:1')
tensor([ 0.0765,  0.4950,  0.6559,  0.8732, -0.2542,  0.3930,  0.8356,  1.1711,
         1.5000, -0.1050,  0.5638,  0.7406,  0.2728,  0.0868, -0.3210, -1.8523],
       device='cuda:1')
Solve time for step 3 1.917207327001961
Current ori: tensor([ 0.2728,  0.0868, -0.3210], device='cuda:1')
Index force: tensor([0.6032, 0.5856], device='cuda:1')
tensor([ 0.0695,  0.4920,  0.6720,  0.8778, -0.2467,  0.4233,  0.8596,  1.1971,
         1.5000, -0.1050,  0.5934,  0.7113,  0.2818,  0.0956, -0.3480, -1.8597],
       device='cuda:1')
Solve time for step 4 1.8385692450101487
Current ori: tensor([ 0.2818,  0.0956, -0.3480], device='cuda:1')
Index force: tensor([0.5781], device='cuda:1')
Storing RECOVERY transition: reward=0.0773 (scaled=0.0773), steps=1
Reward stats updated: mean -0.0140 -> -0.0114, std: 0.1058
Collected 35 transitions for RL
Original likelihood: -92.24685668945312
Adjusted likelihood: -92.24685668945312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 85.74958801269531
Projection step: 1, Loss: 85.35060119628906
Projection step: 2, Loss: 81.00108337402344
Projection step: 3, Loss: 85.32994842529297
Projection step: 4, Loss: 83.10118103027344
Projection step: 5, Loss: 85.55224609375
Projection step: 6, Loss: 80.50159454345703
Projection step: 7, Loss: 79.87449645996094
Projection step: 8, Loss: 82.41030883789062
Projection step: 9, Loss: 86.00701904296875
Projection step: 10, Loss: 81.47050476074219
Projection step: 11, Loss: 80.20632934570312
Projection step: 12, Loss: 80.05842590332031
Projection step: 13, Loss: 77.9114761352539
Projection step: 14, Loss: 80.38563537597656
Final likelihood: tensor([ -57.9105,  -67.7557,  -96.4832,  -82.6210,  -54.7517,  -71.8068,
         -77.5300,  -70.2072,  -62.6809,  -97.6142,  -81.1510,  -85.8310,
        -106.9238,  -73.2307,  -77.1105,  -90.0924])
Final projection likelihood: -78.3563
1 mode projection failed, trying anyway
New goal: tensor([ 9.6930e-02,  4.3022e-01,  6.9708e-01,  9.3330e-01, -1.8739e-01,
         4.8152e-01,  9.6213e-01,  1.2274e+00,  1.4213e+00,  1.0110e-03,
         7.3354e-01,  6.3539e-01,  2.6971e-01,  9.7887e-02,  2.3826e-01],
       device='cuda:1')
tensor([[0.0087]], device='cuda:1') tensor([[0.0015]], device='cuda:1') tensor([[-0.0002]], device='cuda:1')
Original likelihood: -88.00569915771484
Adjusted likelihood: -88.00569915771484
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 88.00569915771484}
Current yaw: tensor([ 0.2765,  0.0898, -0.3363], device='cuda:1')
16 thumb_middle
tensor([ 0.0981,  0.5050,  0.6690,  0.8853, -0.2129,  0.4448,  0.8365,  1.1870,
         1.5000, -0.0602,  0.7135,  0.7399,  0.2765,  0.0898, -0.3363, -1.8625],
       device='cuda:1')
Solve time for step 1 9.150289498007623
Current ori: tensor([ 0.2765,  0.0898, -0.3363], device='cuda:1')
Index force: tensor([0.5258, 0.6006, 0.6061, 0.5818], device='cuda:1')
tensor([ 0.0894,  0.5051,  0.6992,  0.9265, -0.3238,  0.2393,  0.9467,  1.2304,
         1.4303, -0.0287,  0.7104,  0.6598,  0.2907,  0.1027, -0.3822, -1.8723],
       device='cuda:1')
Solve time for step 2 1.8905204049951863
Current ori: tensor([ 0.2907,  0.1027, -0.3822], device='cuda:1')
Index force: tensor([0.5831, 0.5450, 0.5275], device='cuda:1')
tensor([ 0.0851,  0.5114,  0.7678,  0.9371, -0.3233,  0.2160,  0.9755,  1.2458,
         1.4438, -0.0091,  0.7204,  0.6440,  0.3082,  0.1119, -0.3814, -1.8537],
       device='cuda:1')
Solve time for step 3 1.795326446997933
Current ori: tensor([ 0.3082,  0.1119, -0.3814], device='cuda:1')
Index force: tensor([0.5365, 0.5242], device='cuda:1')
tensor([ 0.0900,  0.5136,  0.7354,  0.9347, -0.3287,  0.2738,  0.9659,  1.2434,
         1.4530,  0.0046,  0.7291,  0.6500,  0.3064,  0.1106, -0.3715, -1.8563],
       device='cuda:1')
Solve time for step 4 1.8467850379820447
Current ori: tensor([ 0.3064,  0.1106, -0.3715], device='cuda:1')
Index force: tensor([0.5200], device='cuda:1')
Storing RECOVERY transition: reward=0.0743 (scaled=0.0743), steps=1
Reward stats updated: mean -0.0114 -> -0.0090, std: 0.1053
Collected 36 transitions for RL
Original likelihood: -134.2907257080078
Adjusted likelihood: -134.2907257080078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 142.917724609375
Projection step: 1, Loss: 129.9779052734375
Projection step: 2, Loss: 129.45333862304688
Projection step: 3, Loss: 123.04048156738281
Projection step: 4, Loss: 129.48135375976562
Projection step: 5, Loss: 127.37245178222656
Projection step: 6, Loss: 124.47071838378906
Projection step: 7, Loss: 118.58416748046875
Projection step: 8, Loss: 122.55307006835938
Projection step: 9, Loss: 119.60417175292969
Projection step: 10, Loss: 121.7318115234375
Projection step: 11, Loss: 123.42282104492188
Projection step: 12, Loss: 122.42251586914062
Projection step: 13, Loss: 123.84989929199219
Projection step: 14, Loss: 120.4875259399414
Final likelihood: tensor([-150.1040, -130.1587, -111.1563, -149.2559, -127.8770, -120.2192,
         -99.7054, -158.3454, -120.3114, -138.8991, -128.9895, -138.2354,
        -144.2894, -123.9055, -109.2911, -149.1553])
Final projection likelihood: -131.2437
1 mode projection failed, trying anyway
New goal: tensor([ 0.0815,  0.5152,  0.7375,  0.9541, -0.2851,  0.3315,  1.0588,  1.2852,
         1.4068,  0.1043,  0.8010,  0.7335,  0.2960,  0.1101, -0.1128],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0009]], device='cuda:1') tensor([[-0.0006]], device='cuda:1')
Original likelihood: -129.69027709960938
Adjusted likelihood: -129.69027709960938
Likelihood residual: 0.0
Original likelihood: -129.71371459960938
Adjusted likelihood: -129.71371459960938
Likelihood residual: 0.0
{'index': 129.71371459960938, 'thumb_middle': 129.69027709960938}
Current yaw: tensor([ 0.3014,  0.1052, -0.3627], device='cuda:1')
17 thumb_middle
tensor([ 0.1222,  0.5256,  0.7177,  0.9182, -0.2913,  0.3087,  0.9463,  1.2529,
         1.5000,  0.0504,  0.8048,  0.6847,  0.3014,  0.1052, -0.3627, -1.8969],
       device='cuda:1')
Solve time for step 1 9.664045156998327
Current ori: tensor([ 0.3014,  0.1052, -0.3627], device='cuda:1')
Index force: tensor([0.6550, 0.6249, 0.6011, 0.5700], device='cuda:1')
tensor([ 0.1095,  0.5217,  0.7350,  0.9528, -0.3137,  0.1299,  0.9772,  1.2457,
         1.3949,  0.0508,  0.7503,  0.7027,  0.3133,  0.1125, -0.3738, -2.0650],
       device='cuda:1')
Solve time for step 2 2.0269798299996182
Current ori: tensor([ 0.3133,  0.1125, -0.3738], device='cuda:1')
Index force: tensor([0.6144, 0.5785, 0.5718], device='cuda:1')
tensor([ 0.1134,  0.5235,  0.7343,  0.9638, -0.3079,  0.1232,  1.0024,  1.2679,
         1.3907,  0.0697,  0.7485,  0.7237,  0.3143,  0.1116, -0.3820, -2.1448],
       device='cuda:1')
Solve time for step 3 1.9700460250023752
Current ori: tensor([ 0.3143,  0.1116, -0.3820], device='cuda:1')
Index force: tensor([0.5805, 0.5663], device='cuda:1')
tensor([ 0.1126,  0.5240,  0.7454,  0.9603, -0.3050,  0.1312,  0.9960,  1.2852,
         1.4011,  0.0739,  0.7455,  0.7093,  0.3136,  0.1114, -0.3781, -2.1199],
       device='cuda:1')
Solve time for step 4 1.8217129329859745
Current ori: tensor([ 0.3136,  0.1114, -0.3781], device='cuda:1')
Index force: tensor([0.5543], device='cuda:1')
Storing RECOVERY transition: reward=0.0711 (scaled=0.0711), steps=1
Reward stats updated: mean -0.0090 -> -0.0068, std: 0.1047
Collected 37 transitions for RL
Original likelihood: -139.51486206054688
Adjusted likelihood: -139.51486206054688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 141.57337951660156
Projection step: 1, Loss: 143.94448852539062
Projection step: 2, Loss: 138.74925231933594
Projection step: 3, Loss: 143.19656372070312
Projection step: 4, Loss: 136.84530639648438
Projection step: 5, Loss: 142.83560180664062
Projection step: 6, Loss: 138.69577026367188
Projection step: 7, Loss: 134.7362060546875
Projection step: 8, Loss: 137.2077178955078
Projection step: 9, Loss: 138.02764892578125
Projection step: 10, Loss: 134.10794067382812
Projection step: 11, Loss: 143.37661743164062
Projection step: 12, Loss: 144.25997924804688
Projection step: 13, Loss: 133.41067504882812
Projection step: 14, Loss: 136.09825134277344
Final likelihood: tensor([ -97.0638, -114.0904, -138.9124, -151.7220, -122.0853, -114.7000,
        -148.2543, -131.5297, -125.6636, -165.5756, -184.9339, -154.3452,
        -147.3624, -158.1395, -100.2617, -182.4064])
Final projection likelihood: -139.8154
1 mode projection failed, trying anyway
New goal: tensor([ 0.0877,  0.5350,  0.7509,  1.0149, -0.3065,  0.1966,  1.0730,  1.3089,
         1.3553,  0.1382,  0.8150,  0.8462,  0.3076,  0.1133, -0.1383],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[-0.0005]], device='cuda:1')
Original likelihood: -127.34902954101562
Adjusted likelihood: -127.34902954101562
Likelihood residual: 0.0
Original likelihood: -130.46261596679688
Adjusted likelihood: -130.46261596679688
Likelihood residual: 0.0
{'index': 130.46261596679688, 'thumb_middle': 127.34902954101562}
Current yaw: tensor([ 0.3116,  0.1097, -0.3713], device='cuda:1')
18 thumb_middle
tensor([ 0.1217,  0.5277,  0.7298,  0.9607, -0.3018,  0.1751,  0.9961,  1.2716,
         1.4446,  0.1017,  0.8009,  0.7589,  0.3116,  0.1097, -0.3713, -2.1410],
       device='cuda:1')
Solve time for step 1 9.201755792979384
Current ori: tensor([ 0.3116,  0.1097, -0.3713], device='cuda:1')
Index force: tensor([0.7099, 0.5480, 0.6148, 0.5853], device='cuda:1')
tensor([ 0.0981,  0.5170,  0.7294,  1.0055, -0.3476, -0.0530,  0.9712,  1.2087,
         1.3361,  0.0898,  0.7525,  0.8033,  0.3210,  0.1165, -0.3810, -2.2075],
       device='cuda:1')
Solve time for step 2 1.9650940370047465
Current ori: tensor([ 0.3210,  0.1165, -0.3810], device='cuda:1')
Index force: tensor([0.5404, 0.6103, 0.5810], device='cuda:1')
tensor([ 0.0892,  0.5144,  0.7313,  1.0178, -0.3383, -0.0413,  1.0030,  1.2347,
         1.3307,  0.0979,  0.7441,  0.8106,  0.3230,  0.1178, -0.3794, -2.2404],
       device='cuda:1')
Solve time for step 3 1.8955693269963376
Current ori: tensor([ 0.3230,  0.1178, -0.3794], device='cuda:1')
Index force: tensor([0.6169, 0.5772], device='cuda:1')
tensor([ 0.0779,  0.5091,  0.7307,  1.0150, -0.3231, -0.0370,  1.0062,  1.2456,
         1.3389,  0.1036,  0.7462,  0.8193,  0.3332,  0.1222, -0.4274, -2.3167],
       device='cuda:1')
Solve time for step 4 1.848492664983496
Current ori: tensor([ 0.3332,  0.1222, -0.4274], device='cuda:1')
Index force: tensor([0.5570], device='cuda:1')
Storing RECOVERY transition: reward=0.0718 (scaled=0.0718), steps=1
Reward stats updated: mean -0.0068 -> -0.0048, std: 0.1040
Collected 38 transitions for RL
Original likelihood: -153.471435546875
Adjusted likelihood: -153.471435546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 169.5150604248047
Projection step: 1, Loss: 153.6837158203125
Projection step: 2, Loss: 182.96054077148438
Projection step: 3, Loss: 171.33409118652344
Projection step: 4, Loss: 157.905029296875
Projection step: 5, Loss: 161.8096923828125
Projection step: 6, Loss: 173.80775451660156
Projection step: 7, Loss: 156.5491943359375
Projection step: 8, Loss: 159.17724609375
Projection step: 9, Loss: 160.11972045898438
Projection step: 10, Loss: 164.88442993164062
Projection step: 11, Loss: 171.04376220703125
Projection step: 12, Loss: 166.9150390625
Projection step: 13, Loss: 170.79220581054688
Projection step: 14, Loss: 166.39337158203125
Final likelihood: tensor([-133.4650, -163.8158, -129.8424, -181.5998, -165.3934, -140.7381,
        -152.0340, -174.9880, -216.8505, -206.3934, -221.9837, -191.7431,
        -179.5091, -194.4733, -161.6021, -122.8310])
Final projection likelihood: -171.0789
1 mode projection failed, trying anyway
New goal: tensor([ 0.0680,  0.5242,  0.7328,  1.0719, -0.3213,  0.0635,  1.0915,  1.3215,
         1.3060,  0.1494,  0.8142,  0.9484,  0.3242,  0.1206, -0.1832],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[-0.0004]], device='cuda:1')
Original likelihood: -153.46795654296875
Adjusted likelihood: -153.46795654296875
Likelihood residual: 0.0
Original likelihood: -154.29718017578125
Adjusted likelihood: -154.29718017578125
Likelihood residual: 0.0
{'index': 154.29718017578125, 'thumb_middle': 153.46795654296875}
Current yaw: tensor([ 0.3252,  0.1182, -0.3939], device='cuda:1')
19 thumb_middle
tensor([ 0.0893,  0.5128,  0.7179,  1.0156, -0.3150,  0.0556,  1.0276,  1.2904,
         1.3851,  0.1432,  0.8040,  0.8529,  0.3252,  0.1182, -0.3939, -2.3210],
       device='cuda:1')
Solve time for step 1 9.041984401992522
Current ori: tensor([ 0.3252,  0.1182, -0.3939], device='cuda:1')
Index force: tensor([0.5160, 0.5387, 0.5430, 0.5562], device='cuda:1')
tensor([ 8.8797e-02,  5.0369e-01,  8.1616e-01,  1.0615e+00, -3.5908e-01,
        -3.9473e-04,  1.0314e+00,  1.2496e+00,  1.2793e+00,  9.8218e-02,
         7.6524e-01,  9.0359e-01,  3.5317e-01,  1.3170e-01, -4.3770e-01,
        -2.3233e+00], device='cuda:1')
Solve time for step 2 2.0415528240264393
Current ori: tensor([ 0.3532,  0.1317, -0.4377], device='cuda:1')
Index force: tensor([0.5362, 0.5367, 0.5519], device='cuda:1')
tensor([ 0.0753,  0.5304,  0.8327,  1.0603, -0.3422, -0.0329,  1.0576,  1.2842,
         1.2871,  0.1190,  0.7605,  0.9157,  0.3628,  0.1499, -0.5043, -2.4273],
       device='cuda:1')
Solve time for step 3 1.926063961989712
Current ori: tensor([ 0.3628,  0.1499, -0.5043], device='cuda:1')
Index force: tensor([0.5339, 0.5457], device='cuda:1')
tensor([ 0.0319,  0.5904,  0.7577,  1.0775, -0.3243, -0.0285,  1.0538,  1.2796,
         1.2903,  0.1107,  0.7790,  0.9360,  0.3638,  0.1490, -0.5458, -2.3396],
       device='cuda:1')
Solve time for step 4 1.939348592015449
Current ori: tensor([ 0.3638,  0.1490, -0.5458], device='cuda:1')
Index force: tensor([0.5744], device='cuda:1')
Storing RECOVERY transition: reward=0.0927 (scaled=0.0927), steps=1
Reward stats updated: mean -0.0048 -> -0.0023, std: 0.1038
Collected 39 transitions for RL
Original likelihood: -241.67835998535156
Adjusted likelihood: -241.67835998535156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 217.1096649169922
Projection step: 1, Loss: 220.96917724609375
Projection step: 2, Loss: 229.111083984375
Projection step: 3, Loss: 225.8529815673828
Projection step: 4, Loss: 225.29966735839844
Projection step: 5, Loss: 228.68472290039062
Projection step: 6, Loss: 220.36036682128906
Projection step: 7, Loss: 228.4629364013672
Projection step: 8, Loss: 233.69619750976562
Projection step: 9, Loss: 225.71377563476562
Projection step: 10, Loss: 236.57015991210938
Projection step: 11, Loss: 234.32064819335938
Projection step: 12, Loss: 231.3959503173828
Projection step: 13, Loss: 223.90570068359375
Projection step: 14, Loss: 235.67605590820312
Final likelihood: tensor([-246.5248, -268.2237, -237.0094, -286.6572, -248.4954, -199.1107,
        -227.8626, -239.9846, -248.5783, -222.4900, -246.2567, -276.8413,
        -219.3823, -213.7549, -256.1362, -193.1947])
Final projection likelihood: -239.4064
1 mode projection failed, trying anyway
New goal: tensor([-0.0056,  0.6558,  0.7572,  1.1092, -0.2779, -0.0120,  1.0585,  1.2913,
         1.3024,  0.1975,  0.8496,  1.0213,  0.3687,  0.1515, -0.5793],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[-0.0051]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -236.42034912109375
Adjusted likelihood: -236.42034912109375
Likelihood residual: 0.0
Original likelihood: -217.599609375
Adjusted likelihood: -217.599609375
Likelihood residual: 0.0
{'index': 217.599609375, 'thumb_middle': 236.42034912109375}
Current yaw: tensor([ 0.3684,  0.1512, -0.6329], device='cuda:1')
20 index
tensor([ 0.0037,  0.6491,  0.7644,  1.0753, -0.2726, -0.0127,  1.0226,  1.2797,
         1.3516,  0.1896,  0.8481,  0.9667,  0.3684,  0.1512, -0.6329, -1.9524],
       device='cuda:1')
Solve time for step 1 10.679472291027196
Current ori: tensor([ 0.3684,  0.1512, -0.6329], device='cuda:1')
Middle force: tensor([0.5100, 0.5941, 0.5678, 0.6036], device='cuda:1')
Thumb force: tensor([0.5855, 0.5785, 0.5759, 0.5314], device='cuda:1')
tensor([ 0.2942,  0.8849,  0.7908,  1.1125, -0.2766, -0.0269,  1.0172,  1.2447,
         1.3597,  0.2135,  0.8642,  0.9137,  0.3730,  0.1575, -0.6913, -1.8780],
       device='cuda:1')
Solve time for step 2 2.2853959140193183
Current ori: tensor([ 0.3730,  0.1575, -0.6913], device='cuda:1')
Middle force: tensor([0.5944, 0.5660, 0.6021], device='cuda:1')
Thumb force: tensor([0.5758, 0.5744, 0.5315], device='cuda:1')
tensor([ 0.3399,  0.9676,  0.7950,  1.1196, -0.2878, -0.0192,  0.9829,  1.2854,
         1.4025,  0.2106,  0.8536,  0.8699,  0.3733,  0.1601, -0.7090, -1.8054],
       device='cuda:1')
Solve time for step 3 2.2623249760072213
Current ori: tensor([ 0.3733,  0.1601, -0.7090], device='cuda:1')
Middle force: tensor([0.5596, 0.5993], device='cuda:1')
Thumb force: tensor([0.5729, 0.5306], device='cuda:1')
tensor([ 0.2978,  0.8702,  0.8035,  1.1255, -0.2906, -0.0267,  0.9929,  1.2424,
         1.4124,  0.2233,  0.8315,  0.8880,  0.3748,  0.1627, -0.7267, -1.8173],
       device='cuda:1')
Solve time for step 4 2.1628027159895282
Current ori: tensor([ 0.3748,  0.1627, -0.7267], device='cuda:1')
Middle force: tensor([0.5426], device='cuda:1')
Thumb force: tensor([0.5698], device='cuda:1')
Storing RECOVERY transition: reward=0.0507 (scaled=0.0507), steps=1
Reward stats updated: mean -0.0023 -> -0.0009, std: 0.1029
Collected 40 transitions for RL
Original likelihood: -247.8555908203125
Adjusted likelihood: -247.8555908203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 257.3600769042969
Projection step: 1, Loss: 267.7328796386719
Projection step: 2, Loss: 271.0938415527344
Projection step: 3, Loss: 262.92999267578125
Projection step: 4, Loss: 259.33441162109375
Projection step: 5, Loss: 267.1480712890625
Projection step: 6, Loss: 264.204345703125
Projection step: 7, Loss: 270.55615234375
Projection step: 8, Loss: 261.73040771484375
Projection step: 9, Loss: 265.2559814453125
Projection step: 10, Loss: 255.08984375
Projection step: 11, Loss: 261.0619201660156
Projection step: 12, Loss: 257.2094421386719
Projection step: 13, Loss: 266.0999450683594
Projection step: 14, Loss: 267.60107421875
Final likelihood: tensor([-252.0896, -274.5204, -267.3964, -298.7319, -265.6452, -301.4807,
        -255.5118, -257.6480, -295.5317, -250.9907, -253.3366, -271.0233,
        -247.7435, -264.9933, -226.5047, -269.5812])
Final projection likelihood: -265.7956
1 mode projection failed, trying anyway
New goal: tensor([-0.0355,  0.7744,  0.8064,  1.1570, -0.1943, -0.0188,  0.9460,  1.1718,
         1.3654,  0.2807,  0.8293,  0.9718,  0.3890,  0.1806, -0.7068],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 3
Loaded trajectory sampler
Current yaw: tensor([-0.0021,  0.0145, -0.0311], device='cuda:1')
Current yaw: tensor([-0.0021,  0.0145, -0.0311], device='cuda:1')
1 turn
Sampling time 3.7093615329940803
tensor([ 0.1175,  0.6192,  0.5525,  0.5482, -0.1179,  0.5593,  0.8782,  0.8861,
         1.2157,  0.2793,  0.2581,  1.2236, -0.0021,  0.0145, -0.0311,  0.2435],
       device='cuda:1')
Original likelihood: -18.620670318603516
Adjusted likelihood: -18.620670318603516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.437274485011585
Current ori: tensor([-0.0021,  0.0145, -0.0311], device='cuda:1')
Middle force: tensor([0.5504, 0.5745, 1.1804, 0.5667, 1.1496, 0.6449, 0.5327, 0.5326, 0.5129,
        0.5110, 0.5849, 0.6038], device='cuda:1')
Thumb force: tensor([0.8523, 0.8460, 0.7633, 1.0204, 0.9402, 0.6385, 0.5205, 0.8499, 0.5348,
        0.5822, 0.5941, 0.5851], device='cuda:1')
Index force: tensor([0.6030, 0.6070, 0.5511, 0.5709, 0.7983, 0.5323, 1.0120, 0.9378, 0.5943,
        0.5525, 0.5870, 0.5824], device='cuda:1')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0009 -> -0.0006, std: 0.1016
Collected 41 transitions for RL
tensor([ 0.1450,  0.6725,  0.5372,  0.4776, -0.1118,  0.5281,  0.8831,  0.9802,
         1.2204,  0.2009,  0.3060,  1.2064,  0.0191,  0.0021, -0.0444, -0.3259],
       device='cuda:1')
Original likelihood: -22.162843704223633
Adjusted likelihood: -22.162843704223633
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9535333219973836
Current ori: tensor([ 0.0191,  0.0021, -0.0444], device='cuda:1')
Middle force: tensor([0.5710, 1.1724, 0.5632, 1.1306, 0.6394, 0.5325, 0.5387, 0.5115, 0.5093,
        0.5846, 0.6024], device='cuda:1')
Thumb force: tensor([0.8287, 0.7520, 1.0031, 0.9245, 0.6353, 0.5182, 0.8105, 0.5346, 0.5767,
        0.5867, 0.5802], device='cuda:1')
Index force: tensor([0.5996, 0.5469, 0.5671, 0.7912, 0.5307, 0.9984, 0.9198, 0.5905, 0.5517,
        0.5836, 0.5783], device='cuda:1')
Storing NORMAL transition: reward=0.1017 (scaled=0.1017), steps=1
Reward stats updated: mean -0.0006 -> 0.0018, std: 0.1016
Collected 42 transitions for RL
tensor([ 0.0212,  0.6397,  0.4821,  0.3956, -0.1008,  0.5199,  0.8932,  0.9928,
         1.2717,  0.1190,  0.3642,  0.9953,  0.0069, -0.0025, -0.1458, -0.6105],
       device='cuda:1')
Original likelihood: -20.129549026489258
Adjusted likelihood: -20.129549026489258
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.9203026320028584
Current ori: tensor([ 0.0069, -0.0025, -0.1458], device='cuda:1')
Middle force: tensor([0.5009, 0.5505, 0.6873, 1.6632, 0.5072, 0.6192, 0.5433, 0.5990, 0.5811,
        0.5744], device='cuda:1')
Thumb force: tensor([0.5870, 0.5938, 0.5717, 1.4985, 0.5513, 1.2089, 0.8979, 0.9350, 0.6511,
        0.5528], device='cuda:1')
Index force: tensor([1.1111, 0.5754, 0.5163, 0.5563, 0.6504, 0.6820, 0.5022, 0.5478, 0.5682,
        0.5841], device='cuda:1')
Storing NORMAL transition: reward=-0.0255 (scaled=-0.0255), steps=1
Reward stats updated: mean 0.0018 -> 0.0012, std: 0.1005
Collected 43 transitions for RL
tensor([ 0.0488,  0.6211,  0.5330,  0.4134, -0.0800,  0.5338,  0.9108,  0.9938,
         1.1618,  0.2472,  0.3932,  0.8796,  0.0127, -0.0227, -0.1210, -0.5720],
       device='cuda:1')
Original likelihood: -28.156009674072266
Adjusted likelihood: -28.156009674072266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8428)
Solve time for step 4 2.537418133986648
Current ori: tensor([ 0.0127, -0.0227, -0.1210], device='cuda:1')
Middle force: tensor([0.5214, 0.5157, 0.5737, 0.5051, 0.6594, 0.5575, 0.5689, 0.5590, 0.5593],
       device='cuda:1')
Thumb force: tensor([0.6981, 0.5367, 0.8624, 0.7443, 0.9162, 0.5879, 0.5721, 0.5131, 0.5212],
       device='cuda:1')
Index force: tensor([0.7412, 0.5899, 0.5749, 0.5086, 0.5069, 0.5640, 0.6254, 0.7301, 0.5772],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0286 (scaled=-0.0286), steps=1
Reward stats updated: mean 0.0012 -> 0.0005, std: 0.0995
Collected 44 transitions for RL
tensor([ 0.0537,  0.6311,  0.5189,  0.4186, -0.0790,  0.5499,  0.9064,  0.9625,
         1.2172,  0.1999,  0.3643,  0.9415,  0.0106, -0.0247, -0.0924, -0.6109],
       device='cuda:1')
Original likelihood: -23.341289520263672
Adjusted likelihood: -23.341289520263672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 5 2.324602410022635
Current ori: tensor([ 0.0106, -0.0247, -0.0924], device='cuda:1')
Middle force: tensor([0.5156, 0.5733, 0.5052, 0.6615, 0.5555, 0.5681, 0.5621, 0.5580],
       device='cuda:1')
Thumb force: tensor([0.5337, 0.8518, 0.7354, 0.9072, 0.5843, 0.5685, 0.5119, 0.5203],
       device='cuda:1')
Index force: tensor([0.5835, 0.5714, 0.5073, 0.5060, 0.5623, 0.6206, 0.7173, 0.5745],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0765 (scaled=-0.0765), steps=1
Reward stats updated: mean 0.0005 -> -0.0012, std: 0.0990
Collected 45 transitions for RL
tensor([ 4.4431e-03,  6.3977e-01,  4.4663e-01,  4.5023e-01, -1.0912e-01,
         5.6309e-01,  8.9579e-01,  8.4697e-01,  1.1626e+00,  1.6742e-01,
         2.8130e-01,  9.6165e-01,  9.5905e-03,  5.8350e-04, -1.5224e-02,
        -7.3186e-01], device='cuda:1')
Original likelihood: -24.31522560119629
Adjusted likelihood: -24.31522560119629
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9990)
Solve time for step 6 2.2174935940129217
Current ori: tensor([ 0.0096,  0.0006, -0.0152], device='cuda:1')
Middle force: tensor([0.5697, 0.5048, 0.6567, 0.5535, 0.5669, 0.5629, 0.5565],
       device='cuda:1')
Thumb force: tensor([0.8408, 0.7325, 0.9015, 0.5812, 0.5652, 0.5111, 0.5196],
       device='cuda:1')
Index force: tensor([0.5685, 0.5067, 0.5055, 0.5612, 0.6175, 0.7092, 0.5721],
       device='cuda:1')
Storing NORMAL transition: reward=0.0064 (scaled=0.0064), steps=1
Reward stats updated: mean -0.0012 -> -0.0010, std: 0.0979
Collected 46 transitions for RL
tensor([ 0.0496,  0.6281,  0.4826,  0.4710, -0.1083,  0.6491,  0.9777,  0.8977,
         1.2057,  0.2390,  0.2374,  1.0115, -0.0077, -0.0689, -0.0261, -0.0689],
       device='cuda:1')
Original likelihood: -28.698528289794922
Adjusted likelihood: -28.698528289794922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7612)
Solve time for step 7 2.1324543840019032
Current ori: tensor([-0.0077, -0.0689, -0.0261], device='cuda:1')
Middle force: tensor([0.5056, 0.6791, 0.5526, 0.5695, 0.5767, 0.5568], device='cuda:1')
Thumb force: tensor([0.7207, 0.8875, 0.5784, 0.5620, 0.5101, 0.5184], device='cuda:1')
Index force: tensor([0.5051, 0.5043, 0.5584, 0.6078, 0.6791, 0.5686], device='cuda:1')
Storing NORMAL transition: reward=-0.0275 (scaled=-0.0275), steps=1
Reward stats updated: mean -0.0010 -> -0.0016, std: 0.0970
Collected 47 transitions for RL
tensor([ 0.0936,  0.6028,  0.4669,  0.3983, -0.0744,  0.7001,  0.9052,  0.9950,
         1.1488,  0.1603,  0.2668,  1.0495,  0.0095, -0.0978, -0.0027,  0.4050],
       device='cuda:1')
Original likelihood: -35.691688537597656
Adjusted likelihood: -35.691688537597656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0009)
State is out of distribution
Projection step: 0, Loss: 35.657440185546875
Projection step: 1, Loss: 33.32387924194336
Projection step: 2, Loss: 33.57294845581055
Projection step: 3, Loss: 29.971038818359375
Projection step: 4, Loss: 28.59658432006836
Projection step: 5, Loss: 28.072172164916992
Projection step: 6, Loss: 32.313175201416016
Projection step: 7, Loss: 27.775957107543945
Projection step: 8, Loss: 27.36300277709961
Projection step: 9, Loss: 26.27666664123535
Projection step: 10, Loss: 24.974334716796875
Projection step: 11, Loss: 25.082252502441406
Projection step: 12, Loss: 24.68141746520996
Projection step: 13, Loss: 23.94163703918457
Projection step: 14, Loss: 22.69820785522461
Final likelihood: tensor([-21.6572, -24.3200, -20.8915, -19.4601, -22.1204, -22.9541, -22.9590,
        -22.6492, -20.4656, -24.1732, -21.0187, -27.1215, -23.1277, -19.7152,
        -23.0697, -22.3705])
Final projection likelihood: -22.3796
1 mode projection succeeded
New goal: tensor([ 0.0978,  0.5451,  0.5847,  0.6065,  0.0042,  0.6209,  0.8287,  0.7982,
         1.3203,  0.2362,  0.2040,  0.9748,  0.0025, -0.0738, -1.0916],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0103]], device='cuda:1')
Original likelihood: -32.91196060180664
Adjusted likelihood: -32.91196060180664
Likelihood residual: 0.0
{'index': 32.91196060180664, 'thumb_middle': inf}
Current yaw: tensor([ 0.0095, -0.0978, -0.0027], device='cuda:1')
2 index
tensor([ 0.0936,  0.6028,  0.4669,  0.3983, -0.0744,  0.7001,  0.9052,  0.9950,
         1.1488,  0.1603,  0.2668,  1.0495,  0.0095, -0.0978, -0.0027,  0.4050],
       device='cuda:1')
Solve time for step 1 10.915815082000336
Current ori: tensor([ 0.0095, -0.0978, -0.0027], device='cuda:1')
Middle force: tensor([0.5924, 0.5552, 0.5461, 0.5437], device='cuda:1')
Thumb force: tensor([0.5791, 0.5660, 0.5784, 0.5560], device='cuda:1')
tensor([ 0.1181,  0.5217,  0.5206,  0.5373, -0.0663,  0.7156,  0.9257,  0.8933,
         1.1891,  0.1152,  0.2544,  0.9810, -0.0170, -0.1034, -0.0103,  0.7551],
       device='cuda:1')
Solve time for step 2 2.3050314679858275
Current ori: tensor([-0.0170, -0.1034, -0.0103], device='cuda:1')
Middle force: tensor([0.5512, 0.5449, 0.5422], device='cuda:1')
Thumb force: tensor([0.5651, 0.5759, 0.5540], device='cuda:1')
tensor([ 0.1192,  0.5142,  0.5355,  0.5678, -0.0714,  0.7238,  0.9308,  0.8721,
         1.1953,  0.1117,  0.2574,  0.9485, -0.0276, -0.1043, -0.0179,  1.2953],
       device='cuda:1')
Solve time for step 3 2.2192886339908
Current ori: tensor([-0.0276, -0.1043, -0.0179], device='cuda:1')
Middle force: tensor([0.5408, 0.5404], device='cuda:1')
Thumb force: tensor([0.5748, 0.5516], device='cuda:1')
tensor([ 0.1178,  0.5148,  0.5417,  0.5733, -0.0654,  0.7281,  0.9320,  0.8688,
         1.1846,  0.1259,  0.2512,  0.9503, -0.0292, -0.1094, -0.0262,  2.1552],
       device='cuda:1')
Solve time for step 4 2.155036498006666
Current ori: tensor([-0.0292, -0.1094, -0.0262], device='cuda:1')
Middle force: tensor([0.5893], device='cuda:1')
Thumb force: tensor([0.5841], device='cuda:1')
Storing RECOVERY transition: reward=0.0235 (scaled=0.0034), steps=7
Reward stats updated: mean -0.0016 -> -0.0015, std: 0.0959
Collected 48 transitions for RL
Original likelihood: -36.22749328613281
Adjusted likelihood: -36.22749328613281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0003)
State is out of distribution
Projection step: 0, Loss: 36.86150360107422
Projection step: 1, Loss: 34.40857696533203
Projection step: 2, Loss: 33.52772521972656
Projection step: 3, Loss: 32.08576202392578
Projection step: 4, Loss: 31.95557403564453
Projection step: 5, Loss: 29.294103622436523
Projection step: 6, Loss: 32.14479064941406
Projection step: 7, Loss: 31.385894775390625
Projection step: 8, Loss: 27.877403259277344
Projection step: 9, Loss: 27.71733856201172
Projection step: 10, Loss: 26.677745819091797
Projection step: 11, Loss: 28.236467361450195
Projection step: 12, Loss: 27.6234188079834
Projection step: 13, Loss: 26.92749786376953
Projection step: 14, Loss: 25.631717681884766
Final likelihood: tensor([-23.2981, -22.6656, -23.3186, -33.7593, -24.3672, -21.7176, -23.5221,
        -28.7192, -40.3575, -31.9247, -32.3131, -22.0999, -22.8742, -23.2108,
        -24.7000, -23.0239])
Final projection likelihood: -26.3670
1 mode projection succeeded
New goal: tensor([ 0.1193,  0.4908,  0.6705,  0.6111, -0.0172,  0.6840,  0.8889,  0.7832,
         1.3503,  0.2647,  0.1292,  0.9001, -0.0335, -0.1014, -0.7389],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0020]], device='cuda:1')
Original likelihood: -28.420520782470703
Adjusted likelihood: -28.420520782470703
Likelihood residual: 0.0
Original likelihood: -45.39406967163086
Adjusted likelihood: -45.39406967163086
Likelihood residual: 0.0
{'index': 45.39406967163086, 'thumb_middle': 28.420520782470703}
Current yaw: tensor([-0.0441, -0.1203, -0.0331], device='cuda:1')
3 thumb_middle
tensor([ 0.0851,  0.5734,  0.5872,  0.5986, -0.0717,  0.7517,  0.9407,  0.8667,
         1.1954,  0.1103,  0.2213,  0.9447, -0.0441, -0.1203, -0.0331,  1.7626],
       device='cuda:1')
Solve time for step 1 9.434847086988157
Current ori: tensor([-0.0441, -0.1203, -0.0331], device='cuda:1')
Index force: tensor([0.5826, 0.5937, 0.6002, 0.5974], device='cuda:1')
tensor([ 0.0705,  0.5662,  0.7096,  0.6251, -0.0813,  0.6914,  0.8845,  0.7851,
         1.2441,  0.2110,  0.0155,  0.8451, -0.1000, -0.2125, -0.0408,  2.2556],
       device='cuda:1')
Solve time for step 2 2.0408858949958812
Current ori: tensor([-0.1000, -0.2125, -0.0408], device='cuda:1')
Index force: tensor([0.5833, 0.5957, 0.5911], device='cuda:1')
tensor([ 0.0319,  0.5965,  0.7394,  0.6565, -0.0598,  0.7195,  0.8955,  0.7860,
         1.2381,  0.2237, -0.0687,  0.8036, -0.1440, -0.2703, -0.0305,  3.2684],
       device='cuda:1')
Solve time for step 3 1.9666096209839452
Current ori: tensor([-0.1440, -0.2703, -0.0305], device='cuda:1')
Index force: tensor([0.5358, 0.5479], device='cuda:1')
tensor([-0.0049,  0.6341,  0.7921,  0.6688, -0.0568,  0.7593,  0.9082,  0.7909,
         1.2364,  0.2214, -0.1276,  0.7871, -0.1731, -0.3076,  0.0070,  3.4533],
       device='cuda:1')
Solve time for step 4 1.8157775169820525
Current ori: tensor([-0.1731, -0.3076,  0.0070], device='cuda:1')
Index force: tensor([0.5376], device='cuda:1')
Storing RECOVERY transition: reward=-0.1338 (scaled=-0.0191), steps=7
Reward stats updated: mean -0.0015 -> -0.0018, std: 0.0950
Collected 49 transitions for RL
Original likelihood: -208.82591247558594
Adjusted likelihood: -208.82591247558594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 220.8329620361328
Projection step: 1, Loss: 214.66302490234375
Projection step: 2, Loss: 233.82394409179688
Projection step: 3, Loss: 228.45663452148438
Projection step: 4, Loss: 212.66822814941406
Projection step: 5, Loss: 221.61566162109375
Projection step: 6, Loss: 225.70449829101562
Projection step: 7, Loss: 223.25582885742188
Projection step: 8, Loss: 223.4007568359375
Projection step: 9, Loss: 213.46551513671875
Projection step: 10, Loss: 221.5032196044922
Projection step: 11, Loss: 217.78164672851562
Projection step: 12, Loss: 223.40284729003906
Projection step: 13, Loss: 215.41595458984375
Projection step: 14, Loss: 226.09523010253906
Final likelihood: tensor([-130.8775, -243.1706, -214.4733, -227.3017, -240.8570, -218.2010,
        -215.4284, -221.8684, -216.4639, -243.8185, -219.8023, -190.4294,
        -229.1223, -210.8218, -235.9666, -245.4185])
Final projection likelihood: -219.0013
1 mode projection failed, trying anyway
New goal: tensor([-0.0159,  0.6998,  0.8126,  0.7162,  0.0572,  0.8567,  0.9404,  0.7968,
         1.2333,  0.2552, -0.1078,  0.8356, -0.1911, -0.2772,  0.1620],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0113]], device='cuda:1') tensor([[0.0134]], device='cuda:1')
Original likelihood: -223.46240234375
Adjusted likelihood: -223.46240234375
Likelihood residual: 0.0
Original likelihood: -165.16529846191406
Adjusted likelihood: -165.16529846191406
Likelihood residual: 0.0
{'index': 165.16529846191406, 'thumb_middle': 223.46240234375}
Current yaw: tensor([-0.1934, -0.2780,  0.0516], device='cuda:1')
4 index
tensor([-0.0336,  0.7078,  0.8211,  0.6963,  0.0694,  0.8835,  0.9222,  0.7639,
         1.2451,  0.2362, -0.1047,  0.7973, -0.1934, -0.2780,  0.0516,  2.7715],
       device='cuda:1')
Solve time for step 1 11.057566120987758
Current ori: tensor([-0.1934, -0.2780,  0.0516], device='cuda:1')
Middle force: tensor([0.5718, 0.5597, 0.5303, 0.5096], device='cuda:1')
Thumb force: tensor([0.5697, 0.5175, 0.5609, 0.5787], device='cuda:1')
tensor([-0.0709,  0.6818,  0.8007,  0.7044,  0.0955,  0.9660,  0.9248,  0.7446,
         1.2314,  0.2632, -0.1207,  0.8375, -0.2006, -0.2794,  0.1449,  2.3320],
       device='cuda:1')
Solve time for step 2 2.256271487014601
Current ori: tensor([-0.2006, -0.2794,  0.1449], device='cuda:1')
Middle force: tensor([0.5515, 0.5279, 0.5079], device='cuda:1')
Thumb force: tensor([0.5176, 0.5596, 0.5782], device='cuda:1')
tensor([-0.0569,  0.7202,  0.8198,  0.7116,  0.0932,  1.0418,  0.9416,  0.7430,
         1.2347,  0.2607, -0.1599,  0.8015, -0.2413, -0.3083,  0.2396,  2.5202],
       device='cuda:1')
Solve time for step 3 2.1934045949892607
Current ori: tensor([-0.2413, -0.3083,  0.2396], device='cuda:1')
Middle force: tensor([0.5242, 0.5061], device='cuda:1')
Thumb force: tensor([0.5548, 0.5782], device='cuda:1')
tensor([-0.0512,  0.7669,  0.8213,  0.7033,  0.0934,  1.0940,  0.9437,  0.7398,
         1.2551,  0.2176, -0.1647,  0.7058, -0.3129, -0.3267,  0.3651,  2.5446],
       device='cuda:1')
Solve time for step 4 2.140767295990372
Current ori: tensor([-0.3129, -0.3267,  0.3651], device='cuda:1')
Middle force: tensor([0.5040], device='cuda:1')
Thumb force: tensor([0.5752], device='cuda:1')
Storing RECOVERY transition: reward=-0.6914 (scaled=-0.0988), steps=7
Reward stats updated: mean -0.0018 -> -0.0038, std: 0.0950
Collected 50 transitions for RL
Original likelihood: -440.7535095214844
Adjusted likelihood: -440.7535095214844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 4
Loaded trajectory sampler
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
1 turn
Sampling time 3.8177992069977336
tensor([ 1.0985e-01,  6.3268e-01,  5.3615e-01,  5.2828e-01, -1.0033e-01,
         5.5535e-01,  8.5900e-01,  8.9148e-01,  1.2380e+00,  3.0683e-01,
         2.2876e-01,  1.1836e+00, -1.1403e-03,  1.4469e-02, -3.0450e-02,
         5.5898e-02], device='cuda:1')
Original likelihood: -15.65234661102295
Adjusted likelihood: -15.65234661102295
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.183660869981395
Current ori: tensor([-0.0011,  0.0145, -0.0305], device='cuda:1')
Middle force: tensor([0.5208, 0.4966, 1.2606, 1.2722, 0.5822, 0.5357, 0.5043, 0.5752, 0.5590,
        0.5731, 0.6016, 0.6102], device='cuda:1')
Thumb force: tensor([0.7172, 0.5880, 1.1813, 1.0875, 0.6756, 0.8587, 0.5272, 1.1801, 0.6434,
        0.5909, 0.6044, 0.6064], device='cuda:1')
Index force: tensor([0.5091, 0.6681, 0.5827, 0.5351, 0.9045, 0.5433, 0.5886, 0.4978, 0.5228,
        0.6052, 0.6100, 0.6081], device='cuda:1')
Storing NORMAL transition: reward=-0.0400 (scaled=-0.0400), steps=1
Reward stats updated: mean -0.0038 -> -0.0045, std: 0.0942
Collected 51 transitions for RL
tensor([ 0.1506,  0.6813,  0.5439,  0.4423, -0.1105,  0.4929,  0.8650,  1.0080,
         1.3196,  0.1820,  0.1553,  1.2535, -0.0071,  0.0049,  0.0097, -0.4035],
       device='cuda:1')
Original likelihood: -21.27909278869629
Adjusted likelihood: -21.27909278869629
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.8576444310019724
Current ori: tensor([-0.0071,  0.0049,  0.0097], device='cuda:1')
Middle force: tensor([0.5006, 1.2428, 1.2642, 0.5631, 0.5325, 0.5036, 0.5696, 0.5552, 0.5677,
        0.5925, 0.6069], device='cuda:1')
Thumb force: tensor([0.5829, 1.1621, 1.0675, 0.6876, 0.8521, 0.5305, 1.1677, 0.6394, 0.5907,
        0.6061, 0.6038], device='cuda:1')
Index force: tensor([0.6588, 0.5798, 0.5329, 0.9031, 0.5430, 0.5822, 0.5004, 0.5214, 0.6015,
        0.6082, 0.6046], device='cuda:1')
Storing NORMAL transition: reward=-0.0584 (scaled=-0.0584), steps=1
Reward stats updated: mean -0.0045 -> -0.0055, std: 0.0936
Collected 52 transitions for RL
tensor([ 1.4185e-01,  6.5802e-01,  5.6324e-01,  4.6736e-01, -9.8395e-02,
         5.1354e-01,  8.6042e-01,  1.0058e+00,  1.2183e+00,  2.8186e-01,
         2.5421e-01,  1.2208e+00, -9.7635e-05,  6.4721e-03,  6.8092e-02,
        -3.6467e-01], device='cuda:1')
Original likelihood: -17.37194061279297
Adjusted likelihood: -17.37194061279297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.590038187976461
Current ori: tensor([-9.7635e-05,  6.4721e-03,  6.8092e-02], device='cuda:1')
Middle force: tensor([1.2258, 1.2586, 0.5504, 0.5308, 0.5033, 0.5670, 0.5522, 0.5645, 0.5886,
        0.6041], device='cuda:1')
Thumb force: tensor([1.1361, 1.0458, 0.6910, 0.8425, 0.5293, 1.1523, 0.6352, 0.5880, 0.6029,
        0.6003], device='cuda:1')
Index force: tensor([0.5748, 0.5299, 0.9062, 0.5418, 0.5792, 0.5003, 0.5202, 0.5986, 0.6061,
        0.6015], device='cuda:1')
Storing NORMAL transition: reward=-0.0962 (scaled=-0.0962), steps=1
Reward stats updated: mean -0.0055 -> -0.0072, std: 0.0935
Collected 53 transitions for RL
tensor([ 0.0854,  0.6853,  0.4393,  0.4964, -0.2038,  0.4503,  0.8866,  1.0308,
         1.3113,  0.2016,  0.3091,  1.2593,  0.0331,  0.0645,  0.1607, -1.4600],
       device='cuda:1')
Original likelihood: -33.86119842529297
Adjusted likelihood: -33.86119842529297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0176)
State is out of distribution
Projection step: 0, Loss: 33.386146545410156
Projection step: 1, Loss: 29.587425231933594
Projection step: 2, Loss: 27.414215087890625
Projection step: 3, Loss: 26.236778259277344
Projection step: 4, Loss: 25.28759002685547
Projection step: 5, Loss: 25.687732696533203
Projection step: 6, Loss: 23.676010131835938
Projection step: 7, Loss: 23.31537628173828
Projection step: 8, Loss: 22.347347259521484
Projection step: 9, Loss: 21.026424407958984
Projection step: 10, Loss: 20.536039352416992
Projection step: 11, Loss: 20.581087112426758
Projection step: 12, Loss: 18.10441017150879
Projection step: 13, Loss: 18.743688583374023
Projection step: 14, Loss: 18.419296264648438
Final likelihood: tensor([-17.6277, -16.5774, -14.5251, -14.3401, -13.5232, -17.5451, -19.7091,
        -15.1559, -19.6445, -16.4822, -17.0426, -15.7288, -19.9198, -14.1963,
        -17.6624, -19.2068])
Final projection likelihood: -16.8054
1 mode projection succeeded
New goal: tensor([ 0.0641,  0.6574,  0.4473,  0.5370, -0.1190,  0.4453,  0.8472,  0.9125,
         1.3200,  0.1666,  0.2128,  1.1458,  0.0344,  0.0314, -2.1623],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -27.96064567565918
Adjusted likelihood: -27.96064567565918
Likelihood residual: 0.0
Original likelihood: -30.750675201416016
Adjusted likelihood: -30.750675201416016
Likelihood residual: 0.0
{'index': 30.750675201416016, 'thumb_middle': 27.96064567565918}
Current yaw: tensor([0.0331, 0.0645, 0.1607], device='cuda:1')
2 thumb_middle
tensor([ 0.0854,  0.6853,  0.4393,  0.4964, -0.2038,  0.4503,  0.8866,  1.0308,
         1.3113,  0.2016,  0.3091,  1.2593,  0.0331,  0.0645,  0.1607, -1.4600],
       device='cuda:1')
Solve time for step 1 8.4342627839942
Current ori: tensor([0.0331, 0.0645, 0.1607], device='cuda:1')
Index force: tensor([0.5469, 0.5799, 0.5891, 0.5843], device='cuda:1')
tensor([ 0.1032,  0.7026,  0.4333,  0.4971, -0.2224,  0.4313,  0.8356,  0.9241,
         1.3089,  0.1586,  0.1767,  1.1439,  0.0279,  0.0545,  0.1607, -1.4277],
       device='cuda:1')
Solve time for step 2 2.130507330002729
Current ori: tensor([0.0279, 0.0545, 0.1607], device='cuda:1')
Index force: tensor([0.5750, 0.5859, 0.5813], device='cuda:1')
tensor([ 0.1079,  0.7033,  0.4391,  0.4934, -0.2192,  0.4421,  0.8405,  0.9063,
         1.3286,  0.1594,  0.1512,  1.1239,  0.0272,  0.0518,  0.1607, -1.4241],
       device='cuda:1')
Solve time for step 3 1.7433118319895584
Current ori: tensor([0.0272, 0.0518, 0.1607], device='cuda:1')
Index force: tensor([0.5812, 0.5777], device='cuda:1')
tensor([ 0.0971,  0.7063,  0.4245,  0.4909, -0.2241,  0.4437,  0.8385,  0.9024,
         1.3374,  0.1596,  0.1486,  1.1257,  0.0275,  0.0573,  0.1607, -1.4454],
       device='cuda:1')
Solve time for step 4 1.6911309210117906
Current ori: tensor([0.0275, 0.0573, 0.1607], device='cuda:1')
Index force: tensor([0.5684], device='cuda:1')
Storing RECOVERY transition: reward=0.0004 (scaled=0.0001), steps=3
Reward stats updated: mean -0.0072 -> -0.0071, std: 0.0927
Collected 54 transitions for RL
Original likelihood: -27.279434204101562
Adjusted likelihood: -27.279434204101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9312)
Current yaw: tensor([0.0315, 0.0531, 0.1613], device='cuda:1')
3 turn
Sampling time 3.8324707279971335
tensor([ 0.0974,  0.6943,  0.4365,  0.5028, -0.1632,  0.4791,  0.8713,  0.9214,
         1.3972,  0.1902,  0.1962,  1.1647,  0.0315,  0.0531,  0.1613, -1.5550],
       device='cuda:1')
Original likelihood: -27.9627685546875
Adjusted likelihood: -27.9627685546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8669)
Solve time for step 1 14.035140904015861
Current ori: tensor([0.0315, 0.0531, 0.1613], device='cuda:1')
Middle force: tensor([0.6866, 0.7220, 0.4932, 0.5893, 1.4907, 0.4777, 0.4310, 0.4764, 0.5731,
        0.6920, 0.5266, 0.4538], device='cuda:1')
Thumb force: tensor([1.7145, 0.5372, 1.3070, 3.0723, 1.1917, 0.5117, 0.7942, 0.5222, 0.5328,
        0.5151, 1.6127, 0.6076], device='cuda:1')
Index force: tensor([0.5053, 0.5123, 0.7429, 0.7741, 0.6636, 0.6328, 0.6655, 0.5205, 0.5454,
        0.5271, 0.5624, 0.5602], device='cuda:1')
Storing NORMAL transition: reward=0.0280 (scaled=0.0280), steps=1
Reward stats updated: mean -0.0071 -> -0.0065, std: 0.0919
Collected 55 transitions for RL
tensor([ 0.1235,  0.8041,  0.2961,  0.4410, -0.1867,  0.3930,  0.9343,  1.1414,
         1.3377,  0.5140,  0.2780,  0.8703,  0.0040,  0.0483,  0.1346, -1.4444],
       device='cuda:1')
Original likelihood: -40.175201416015625
Adjusted likelihood: -40.175201416015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 42.69850540161133
Projection step: 1, Loss: 35.7834587097168
Projection step: 2, Loss: 34.13372802734375
Projection step: 3, Loss: 29.36545181274414
Projection step: 4, Loss: 27.930870056152344
Projection step: 5, Loss: 24.206645965576172
Projection step: 6, Loss: 21.778152465820312
Projection step: 7, Loss: 19.553993225097656
Projection step: 8, Loss: 17.91434097290039
Projection step: 9, Loss: 17.018123626708984
Projection step: 10, Loss: 15.702469825744629
Projection step: 11, Loss: 14.700859069824219
Final likelihood: tensor([-17.4113, -11.1854, -15.1739, -16.4639, -14.2214, -13.2862, -14.4578,
        -14.7260, -13.3695, -14.2718, -13.0517, -15.0612, -17.0872, -15.7085,
        -12.7429, -16.9948])
Final projection likelihood: -14.7009
1 mode projection succeeded
New goal: tensor([ 0.0996,  0.7263,  0.3805,  0.4473, -0.1044,  0.3698,  0.7286,  1.1489,
         1.3058,  0.3276,  0.1500,  1.0777, -0.0038,  0.0202, -2.8388],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0043]], device='cuda:1') tensor([[0.0033]], device='cuda:1')
Original likelihood: -29.06077766418457
Adjusted likelihood: -29.06077766418457
Likelihood residual: 0.0
Original likelihood: -19.21828842163086
Adjusted likelihood: -19.21828842163086
Likelihood residual: 0.0
{'index': 19.21828842163086, 'thumb_middle': 29.06077766418457}
Current yaw: tensor([0.0040, 0.0483, 0.1346], device='cuda:1')
4 index
tensor([ 0.1235,  0.8041,  0.2961,  0.4410, -0.1867,  0.3930,  0.9343,  1.1414,
         1.3377,  0.5140,  0.2780,  0.8703,  0.0040,  0.0483,  0.1346, -1.4444],
       device='cuda:1')
Solve time for step 1 10.648705660016276
Current ori: tensor([0.0040, 0.0483, 0.1346], device='cuda:1')
Middle force: tensor([0.5789, 0.5938, 0.5488, 0.5348], device='cuda:1')
Thumb force: tensor([0.5535, 0.5237, 0.5428, 0.5941], device='cuda:1')
tensor([ 0.1572,  0.6664,  0.3195,  0.4401, -0.1409,  0.4574,  0.8742,  1.2093,
         1.4043,  0.3986,  0.1480,  0.9757,  0.0039,  0.0262,  0.1257, -1.9139],
       device='cuda:1')
Solve time for step 2 2.306701954017626
Current ori: tensor([0.0039, 0.0262, 0.1257], device='cuda:1')
Middle force: tensor([0.5904, 0.5035, 0.5955], device='cuda:1')
Thumb force: tensor([0.5701, 0.5271, 0.5384], device='cuda:1')
tensor([ 1.5348e-01,  6.6359e-01,  3.3557e-01,  4.4120e-01, -1.2235e-01,
         4.7686e-01,  8.5870e-01,  1.2170e+00,  1.4154e+00,  3.7412e-01,
         1.0872e-01,  1.0047e+00, -7.4865e-05,  1.5093e-02,  1.2130e-01,
        -2.0825e+00], device='cuda:1')
Solve time for step 3 2.2017913100135047
Current ori: tensor([-7.4865e-05,  1.5093e-02,  1.2130e-01], device='cuda:1')
Middle force: tensor([0.5300, 0.5710], device='cuda:1')
Thumb force: tensor([0.6004, 0.5843], device='cuda:1')
tensor([ 0.1468,  0.6616,  0.3413,  0.4404, -0.1113,  0.4886,  0.8523,  1.2129,
         1.4174,  0.3750,  0.0886,  1.0139, -0.0055,  0.0092,  0.1121, -2.1254],
       device='cuda:1')
Solve time for step 4 2.1680042430234607
Current ori: tensor([-0.0055,  0.0092,  0.1121], device='cuda:1')
Middle force: tensor([0.5899], device='cuda:1')
Thumb force: tensor([0.5340], device='cuda:1')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0061), steps=1
Reward stats updated: mean -0.0065 -> -0.0062, std: 0.0911
Collected 56 transitions for RL
Original likelihood: -19.52094841003418
Adjusted likelihood: -19.52094841003418
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0094,  0.0070,  0.1307], device='cuda:1')
5 turn
Sampling time 3.709901535999961
tensor([ 0.0942,  0.7392,  0.3843,  0.4526, -0.1080,  0.4998,  0.8423,  1.2013,
         1.4165,  0.3739,  0.0825,  1.0176, -0.0094,  0.0070,  0.1307, -2.1538],
       device='cuda:1')
Original likelihood: -19.027751922607422
Adjusted likelihood: -19.027751922607422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.360482866002712
Current ori: tensor([-0.0094,  0.0070,  0.1307], device='cuda:1')
Middle force: tensor([0.5960, 0.5621, 1.1686, 0.5820, 1.2512, 0.6450, 0.5500, 0.5472, 0.5220,
        0.8984, 0.7378, 0.6595], device='cuda:1')
Thumb force: tensor([0.9266, 0.8468, 0.7749, 1.0452, 0.8389, 0.6239, 0.5210, 0.9202, 0.5398,
        0.5220, 0.6751, 0.5874], device='cuda:1')
Index force: tensor([0.5904, 0.6056, 0.5740, 0.5837, 0.8111, 0.5210, 0.9996, 0.9261, 0.5866,
        0.5893, 0.7341, 0.5772], device='cuda:1')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0062 -> -0.0059, std: 0.0904
Collected 57 transitions for RL
tensor([ 0.0939,  0.7401,  0.3881,  0.4198, -0.1158,  0.4023,  0.7914,  1.2694,
         1.4245,  0.4466,  0.0304,  1.0695, -0.0119,  0.0090,  0.1174, -2.1425],
       device='cuda:1')
Original likelihood: -18.787456512451172
Adjusted likelihood: -18.787456512451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.016033061023336
Current ori: tensor([-0.0119,  0.0090,  0.1174], device='cuda:1')
Middle force: tensor([0.5600, 1.1577, 0.5801, 1.2418, 0.6380, 0.5511, 0.5442, 0.5212, 0.8884,
        0.7294, 0.6549], device='cuda:1')
Thumb force: tensor([0.8357, 0.7676, 1.0333, 0.8260, 0.6241, 0.5188, 0.9154, 0.5377, 0.5208,
        0.6726, 0.5853], device='cuda:1')
Index force: tensor([0.5999, 0.5740, 0.5813, 0.8121, 0.5206, 0.9891, 0.9242, 0.5847, 0.5904,
        0.7322, 0.5770], device='cuda:1')
Storing NORMAL transition: reward=0.0793 (scaled=0.0793), steps=1
Reward stats updated: mean -0.0059 -> -0.0044, std: 0.0903
Collected 58 transitions for RL
tensor([ 0.1283,  0.7419,  0.4226,  0.4458, -0.0807,  0.3866,  1.0606,  1.2506,
         1.4332,  0.4296,  0.0202,  1.0458, -0.0100, -0.0065,  0.0381, -1.8706],
       device='cuda:1')
Original likelihood: -23.920928955078125
Adjusted likelihood: -23.920928955078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 3 3.0149469500174746
Current ori: tensor([-0.0100, -0.0065,  0.0381], device='cuda:1')
Middle force: tensor([1.1494, 0.5812, 1.2604, 0.6295, 0.5551, 0.5426, 0.5194, 0.8981, 0.7191,
        0.6604], device='cuda:1')
Thumb force: tensor([0.7553, 1.0198, 0.7953, 0.6272, 0.5170, 0.9147, 0.5386, 0.5180, 0.6784,
        0.5799], device='cuda:1')
Index force: tensor([0.5696, 0.5772, 0.8067, 0.5196, 0.9736, 0.9120, 0.5804, 0.5877, 0.7238,
        0.5738], device='cuda:1')
Storing NORMAL transition: reward=-0.0149 (scaled=-0.0149), steps=1
Reward stats updated: mean -0.0044 -> -0.0046, std: 0.0895
Collected 59 transitions for RL
tensor([-0.0352,  0.5830,  0.4899,  0.4772, -0.1547,  0.3407,  1.0735,  1.2635,
         1.4963,  0.4322, -0.0486,  0.9028,  0.0048,  0.0349,  0.0518, -2.5379],
       device='cuda:1')
Original likelihood: -33.05419921875
Adjusted likelihood: -33.05419921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.0478)
Solve time for step 4 2.9077369130100124
Current ori: tensor([0.0048, 0.0349, 0.0518], device='cuda:1')
Middle force: tensor([1.4043, 0.5693, 0.5012, 0.7351, 0.5015, 0.9441, 0.6932, 0.5831, 0.6750],
       device='cuda:1')
Thumb force: tensor([0.9051, 1.7125, 0.5002, 0.8725, 0.5418, 0.6004, 0.9902, 0.5386, 0.5615],
       device='cuda:1')
Index force: tensor([0.8694, 0.6084, 0.7729, 0.5440, 0.7384, 0.8970, 0.5262, 0.6009, 0.5564],
       device='cuda:1')
Storing NORMAL transition: reward=0.0207 (scaled=0.0207), steps=1
Reward stats updated: mean -0.0046 -> -0.0042, std: 0.0888
Collected 60 transitions for RL
tensor([-4.9784e-04,  5.9604e-01,  4.9423e-01,  4.8392e-01, -1.1315e-01,
         3.7431e-01,  1.0665e+00,  1.2428e+00,  1.5000e+00,  3.7763e-01,
        -2.0677e-02,  9.3125e-01, -9.6329e-03,  1.1439e-02,  3.2224e-02,
        -2.5552e+00], device='cuda:1')
Original likelihood: -25.430377960205078
Adjusted likelihood: -25.430377960205078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9937)
Solve time for step 5 2.8138162629911676
Current ori: tensor([-0.0096,  0.0114,  0.0322], device='cuda:1')
Middle force: tensor([0.5668, 0.5010, 0.7366, 0.5019, 0.9752, 0.6984, 0.5818, 0.6774],
       device='cuda:1')
Thumb force: tensor([1.6819, 0.5001, 0.8612, 0.5352, 0.5756, 0.9723, 0.5363, 0.5582],
       device='cuda:1')
Index force: tensor([0.6027, 0.7849, 0.5412, 0.7232, 0.8916, 0.5247, 0.5976, 0.5531],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0138 (scaled=-0.0138), steps=1
Reward stats updated: mean -0.0042 -> -0.0043, std: 0.0881
Collected 61 transitions for RL
tensor([ 0.0281,  0.5788,  0.4932,  0.5976, -0.0368,  0.3799,  1.0026,  1.2437,
         1.4912,  0.4472, -0.0610,  1.0410, -0.0216, -0.0065,  0.0457, -2.4805],
       device='cuda:1')
Original likelihood: -21.037921905517578
Adjusted likelihood: -21.037921905517578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 2.720907714974601
Current ori: tensor([-0.0216, -0.0065,  0.0457], device='cuda:1')
Middle force: tensor([1.4822, 0.5417, 0.5989, 0.5341, 0.5277, 0.5190, 0.5845],
       device='cuda:1')
Thumb force: tensor([0.9502, 0.6872, 0.5061, 0.9200, 0.8115, 0.9659, 0.5846],
       device='cuda:1')
Index force: tensor([0.5154, 0.5060, 0.5336, 0.5229, 0.5450, 0.5160, 0.5995],
       device='cuda:1')
Storing NORMAL transition: reward=0.0013 (scaled=0.0013), steps=1
Reward stats updated: mean -0.0043 -> -0.0043, std: 0.0874
Collected 62 transitions for RL
tensor([ 0.0280,  0.5841,  0.4819,  0.6040, -0.0368,  0.4064,  0.9594,  1.2640,
         1.5000,  0.4166, -0.0533,  1.0095, -0.0289, -0.0061,  0.0440, -2.5051],
       device='cuda:1')
Original likelihood: -23.018217086791992
Adjusted likelihood: -23.018217086791992
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 7 2.553250155004207
Current ori: tensor([-0.0289, -0.0061,  0.0440], device='cuda:1')
Middle force: tensor([0.5407, 0.6001, 0.5328, 0.5264, 0.5175, 0.5818], device='cuda:1')
Thumb force: tensor([0.6781, 0.5057, 0.9087, 0.8037, 0.9562, 0.5818], device='cuda:1')
Index force: tensor([0.5054, 0.5312, 0.5211, 0.5434, 0.5158, 0.5972], device='cuda:1')
Storing NORMAL transition: reward=-0.0080 (scaled=-0.0080), steps=1
Reward stats updated: mean -0.0043 -> -0.0043, std: 0.0867
Collected 63 transitions for RL
tensor([ 0.0294,  0.5809,  0.4838,  0.6117, -0.0368,  0.4163,  0.9371,  1.2836,
         1.5000,  0.4078, -0.0516,  1.0091, -0.0281, -0.0067,  0.0521, -2.5113],
       device='cuda:1')
Original likelihood: -21.53998565673828
Adjusted likelihood: -21.53998565673828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 8 2.481348836008692
Current ori: tensor([-0.0281, -0.0067,  0.0521], device='cuda:1')
Middle force: tensor([0.5981, 0.5308, 0.5251, 0.5164, 0.5788], device='cuda:1')
Thumb force: tensor([0.5052, 0.8992, 0.7958, 0.9487, 0.5795], device='cuda:1')
Index force: tensor([0.5297, 0.5195, 0.5422, 0.5152, 0.5950], device='cuda:1')
Storing NORMAL transition: reward=-0.0237 (scaled=-0.0237), steps=1
Reward stats updated: mean -0.0043 -> -0.0046, std: 0.0860
Collected 64 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0827, Q2 Loss=1.0827, Entropy=0.0015, Time=0.11sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0270
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0793, Q2 Loss=1.0793, Entropy=0.0131, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0504
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0741, Q2 Loss=1.0741, Entropy=0.0119, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0394
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.0686, Q2 Loss=1.0686, Entropy=0.3496, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0042
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.0643, Q2 Loss=1.0643, Entropy=0.3299, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0160

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (18.8%)
Q1 update: 0.08s (23.6%)
Q2 update: 0.06s (18.6%)
Actor update: 0.12s (36.3%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000135
Q1 loss: 1.073785
Q2 loss: 1.073786
Current threshold: -29.9903
Global Scale Offset: 1.0425
Reward stats: mean=-0.0046, std=0.0860, count=64
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0738, Q2 Loss: 1.0738, Entropy: 0.1412, Mean TD Error: 0.0274, Threshold: -29.9903
tensor([ 0.0112,  0.5065,  0.5285,  0.6917, -0.0744,  0.4834,  0.7981,  1.2547,
         1.5000,  0.3434,  0.0221,  0.9301, -0.0393,  0.0164,  0.0748, -2.9485],
       device='cuda:1')
Original likelihood: -16.368247985839844
Adjusted likelihood: -16.368247985839844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 9 2.0494687120080926
Current ori: tensor([-0.0393,  0.0164,  0.0748], device='cuda:1')
Middle force: tensor([0.5296, 0.5234, 0.5155, 0.5784], device='cuda:1')
Thumb force: tensor([0.8837, 0.7921, 0.9387, 0.5766], device='cuda:1')
Index force: tensor([0.5178, 0.5417, 0.5149, 0.5917], device='cuda:1')
Storing NORMAL transition: reward=-0.1468 (scaled=-0.1468), steps=1
Reward stats updated: mean -0.0046 -> -0.0068, std: 0.0871
Collected 65 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=1.0601, Q2 Loss=1.0601, Entropy=0.3676, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0290
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0555, Q2 Loss=1.0555, Entropy=0.0167, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0238
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0509, Q2 Loss=1.0509, Entropy=0.0195, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0090
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0507, Q2 Loss=1.0507, Entropy=0.0873, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0823
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0420, Q2 Loss=1.0420, Entropy=0.0151, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0047

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.0%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.3%)
Actor update: 0.13s (41.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000135
Q1 loss: 1.051856
Q2 loss: 1.051857
Current threshold: -29.9771
Global Scale Offset: 1.0801
Reward stats: mean=-0.0068, std=0.0871, count=65
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0519, Q2 Loss: 1.0519, Entropy: 0.1012, Mean TD Error: 0.0298, Threshold: -29.9771
tensor([-0.0183,  0.5195,  0.4745,  0.7215, -0.2265,  0.5130,  0.8220,  1.1355,
         1.4999,  0.3600,  0.0357,  1.0288, -0.0293,  0.0709,  0.2187, -3.4912],
       device='cuda:1')
Original likelihood: -28.364227294921875
Adjusted likelihood: -28.364227294921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7976)
State is out of distribution
Projection step: 0, Loss: 28.138681411743164
Projection step: 1, Loss: 28.221012115478516
Projection step: 2, Loss: 26.746501922607422
Projection step: 3, Loss: 25.336271286010742
Projection step: 4, Loss: 24.704593658447266
Projection step: 5, Loss: 24.483535766601562
Projection step: 6, Loss: 22.213150024414062
Projection step: 7, Loss: 22.08816909790039
Projection step: 8, Loss: 22.388269424438477
Projection step: 9, Loss: 20.53347396850586
Projection step: 10, Loss: 21.244979858398438
Projection step: 11, Loss: 20.250877380371094
Projection step: 12, Loss: 20.32944107055664
Projection step: 13, Loss: 19.06203842163086
Projection step: 14, Loss: 19.792701721191406
Final likelihood: tensor([-18.6074, -15.9718, -17.0258, -17.0948, -20.1121, -17.1405, -17.4257,
        -18.8260, -18.3725, -19.1751, -18.4451, -16.6858, -19.2928, -17.3938,
        -17.2807, -19.4388])
Final projection likelihood: -18.0180
1 mode projection succeeded
New goal: tensor([ 0.0126,  0.5738,  0.5026,  0.6305, -0.1326,  0.4744,  0.7731,  0.9669,
         1.4239,  0.2802,  0.0940,  1.1164, -0.0352,  0.0494, -0.3984],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -21.958465576171875
Adjusted likelihood: -21.958465576171875
Likelihood residual: 0.0
{'index': 21.958465576171875, 'thumb_middle': inf}
Current yaw: tensor([-0.0293,  0.0709,  0.2187], device='cuda:1')
6 index
tensor([-0.0183,  0.5195,  0.4745,  0.7215, -0.2265,  0.5130,  0.8220,  1.1355,
         1.4999,  0.3600,  0.0357,  1.0288, -0.0293,  0.0709,  0.2187, -3.4912],
       device='cuda:1')
Solve time for step 1 11.574998669995693
Current ori: tensor([-0.0293,  0.0709,  0.2187], device='cuda:1')
Middle force: tensor([0.5698, 0.5446, 0.5922, 0.5033], device='cuda:1')
Thumb force: tensor([0.5430, 0.5641, 0.5986, 0.5286], device='cuda:1')
tensor([ 0.0608,  0.4991,  0.4426,  0.6212, -0.2104,  0.5160,  0.8618,  1.0789,
         1.5000,  0.3480,  0.0089,  1.0457, -0.0381,  0.0593,  0.2438, -3.6298],
       device='cuda:1')
Solve time for step 2 2.478904572024476
Current ori: tensor([-0.0381,  0.0593,  0.2438], device='cuda:1')
Middle force: tensor([0.5435, 0.5890, 0.5029], device='cuda:1')
Thumb force: tensor([0.5613, 0.5969, 0.5278], device='cuda:1')
tensor([ 0.0682,  0.5115,  0.4483,  0.6079, -0.1922,  0.5286,  0.8692,  1.0499,
         1.4999,  0.3409, -0.0076,  1.0453, -0.0464,  0.0480,  0.2430, -4.0164],
       device='cuda:1')
Solve time for step 3 2.416834812000161
Current ori: tensor([-0.0464,  0.0480,  0.2430], device='cuda:1')
Middle force: tensor([0.5358, 0.5347], device='cuda:1')
Thumb force: tensor([0.5841, 0.5676], device='cuda:1')
tensor([ 0.0710,  0.5161,  0.4517,  0.6029, -0.1763,  0.5444,  0.8659,  1.0328,
         1.4999,  0.3355, -0.0206,  1.0412, -0.0543,  0.0382,  0.2395, -4.5779],
       device='cuda:1')
Solve time for step 4 2.308068166981684
Current ori: tensor([-0.0543,  0.0382,  0.2395], device='cuda:1')
Middle force: tensor([0.5019], device='cuda:1')
Thumb force: tensor([0.5250], device='cuda:1')
Storing RECOVERY transition: reward=-0.0138 (scaled=-0.0015), steps=9
Reward stats updated: mean -0.0068 -> -0.0067, std: 0.0865
Collected 66 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=1.0376, Q2 Loss=1.0376, Entropy=0.2574, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0054
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0619, Q2 Loss=1.0619, Entropy=0.0429, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2224
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0374, Q2 Loss=1.0374, Entropy=0.0035, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1225
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0335, Q2 Loss=1.0335, Entropy=0.0019, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1440
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0198, Q2 Loss=1.0198, Entropy=0.0163, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0130

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.3%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000049
Q1 loss: 1.038019
Q2 loss: 1.038019
Current threshold: -29.9779
Global Scale Offset: 1.1171
Reward stats: mean=-0.0067, std=0.0865, count=66
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0380, Q2 Loss: 1.0380, Entropy: 0.0644, Mean TD Error: 0.1015, Threshold: -29.9779
Original likelihood: -24.691455841064453
Adjusted likelihood: -24.691455841064453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9962)
Current yaw: tensor([-0.0556,  0.0309,  0.2341], device='cuda:1')
7 turn
Sampling time 3.719958701985888
tensor([ 0.0332,  0.5762,  0.4901,  0.6227, -0.1658,  0.5496,  0.8681,  1.0309,
         1.4999,  0.3304, -0.0323,  1.0478, -0.0556,  0.0309,  0.2341, -4.7186],
       device='cuda:1')
Original likelihood: -24.118614196777344
Adjusted likelihood: -24.118614196777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9984)
Solve time for step 1 15.3430408470158
Current ori: tensor([-0.0556,  0.0309,  0.2341], device='cuda:1')
Middle force: tensor([0.6124, 0.7396, 0.6685, 0.5985, 0.6307, 0.5990, 0.7660, 0.5860, 0.6643,
        0.5821, 0.5847, 0.6269], device='cuda:1')
Thumb force: tensor([0.6006, 2.2514, 1.7739, 0.7443, 1.5441, 0.5279, 0.6733, 0.5129, 0.6033,
        0.5947, 0.7716, 0.5912], device='cuda:1')
Index force: tensor([0.6081, 0.7225, 0.5358, 0.5681, 1.1616, 0.6249, 0.6165, 0.5463, 0.5159,
        0.6594, 0.6076, 0.5935], device='cuda:1')
Storing NORMAL transition: reward=-0.0195 (scaled=-0.0195), steps=1
Reward stats updated: mean -0.0067 -> -0.0069, std: 0.0859
Collected 67 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0163, Q2 Loss=1.0163, Entropy=0.0476, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0373
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=1.0108, Q2 Loss=1.0108, Entropy=0.2163, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0158
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0257, Q2 Loss=1.0257, Entropy=0.0003, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1649
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=1.0035, Q2 Loss=1.0035, Entropy=0.2565, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0569
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.9971, Q2 Loss=0.9971, Entropy=0.2823, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0045

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.06s (20.9%)
Actor update: 0.12s (43.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000137
Q1 loss: 1.010699
Q2 loss: 1.010699
Current threshold: -29.9714
Global Scale Offset: 1.1566
Reward stats: mean=-0.0069, std=0.0859, count=67
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0107, Q2 Loss: 1.0107, Entropy: 0.1606, Mean TD Error: 0.0559, Threshold: -29.9714
tensor([ 0.0290,  0.4650,  0.4020,  0.7367, -0.1417,  0.4708,  0.8937,  0.9411,
         1.4883,  0.3448, -0.0509,  1.0753, -0.1379,  0.0770,  0.2341,  6.0916],
       device='cuda:1')
Original likelihood: -33.455970764160156
Adjusted likelihood: -33.455970764160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0433)
State is out of distribution
Projection step: 0, Loss: 32.338218688964844
Projection step: 1, Loss: 31.57577896118164
Projection step: 2, Loss: 29.290634155273438
Projection step: 3, Loss: 28.709766387939453
Projection step: 4, Loss: 29.04327964782715
Projection step: 5, Loss: 30.644617080688477
Projection step: 6, Loss: 31.44383430480957
Projection step: 7, Loss: 30.380474090576172
Projection step: 8, Loss: 30.11587142944336
Projection step: 9, Loss: 30.1605167388916
Projection step: 10, Loss: 28.485015869140625
Projection step: 11, Loss: 29.25395965576172
Projection step: 12, Loss: 28.22627067565918
Projection step: 13, Loss: 27.90178680419922
Projection step: 14, Loss: 27.313854217529297
Final likelihood: tensor([-19.1984, -26.5309, -28.1929, -27.5487, -28.7328, -28.0968, -24.6789,
        -28.5068, -36.1164, -28.2577, -28.2944, -28.3671, -27.4732, -25.3068,
        -28.0504, -27.1855])
Final projection likelihood: -27.5336
1 mode projection succeeded
New goal: tensor([ 0.0396,  0.5568,  0.5032,  0.7010, -0.1001,  0.4179,  0.8557,  0.8276,
         1.4631,  0.2666,  0.0897,  1.0585, -0.1263,  0.0629, -0.1319],
       device='cuda:1')
tensor([[0.0048]], device='cuda:1') tensor([[0.0055]], device='cuda:1') tensor([[0.0155]], device='cuda:1')
Original likelihood: -29.544696807861328
Adjusted likelihood: -29.544696807861328
Likelihood residual: 0.0
Original likelihood: -27.359554290771484
Adjusted likelihood: -27.359554290771484
Likelihood residual: 0.0
{'index': 27.359554290771484, 'thumb_middle': 29.544696807861328}
Current yaw: tensor([-0.1379,  0.0770,  0.2341], device='cuda:1')
8 index
tensor([ 0.0290,  0.4650,  0.4020,  0.7367, -0.1417,  0.4708,  0.8937,  0.9411,
         1.4883,  0.3448, -0.0509,  1.0753, -0.1379,  0.0770,  0.2341,  6.0916],
       device='cuda:1')
Solve time for step 1 11.74906363201444
Current ori: tensor([-0.1379,  0.0770,  0.2341], device='cuda:1')
Middle force: tensor([0.5729, 0.5315, 0.5542, 0.5722], device='cuda:1')
Thumb force: tensor([0.5309, 0.5683, 0.5184, 0.5665], device='cuda:1')
tensor([ 8.0561e-02,  5.1193e-01,  4.5469e-01,  6.9233e-01, -1.3238e-01,
         5.0189e-01,  9.2228e-01,  8.8139e-01,  1.5000e+00,  3.1316e-01,
        -1.4449e-03,  1.0525e+00, -3.4537e-01,  1.9084e-01,  2.3408e-01,
         5.8546e+00], device='cuda:1')
Solve time for step 2 2.507461016997695
Current ori: tensor([-0.3454,  0.1908,  0.2341], device='cuda:1')
Middle force: tensor([0.5315, 0.5533, 0.5681], device='cuda:1')
Thumb force: tensor([0.5617, 0.5176, 0.5654], device='cuda:1')
tensor([ 0.0261,  0.6008,  0.5038,  0.6958, -0.1200,  0.5622,  0.9295,  0.8535,
         1.5000,  0.3326,  0.0215,  1.0967, -0.8078,  0.4179,  0.2341, -4.8649],
       device='cuda:1')
Solve time for step 3 2.428198056004476
Current ori: tensor([-0.8078,  0.4179,  0.2341], device='cuda:1')
Middle force: tensor([0.5045, 0.5120], device='cuda:1')
Thumb force: tensor([0.5208, 0.6094], device='cuda:1')
tensor([-0.0960,  0.7265,  0.5123,  0.6667, -0.1850,  0.8445,  0.9936,  0.8234,
         1.5000,  0.3767, -0.0745,  1.2069, -1.5371,  0.6005,  0.2342, -4.2328],
       device='cuda:1')
Solve time for step 4 2.176071564987069
Current ori: tensor([-1.5371,  0.6005,  0.2342], device='cuda:1')
Middle force: tensor([0.5131], device='cuda:1')
Thumb force: tensor([0.6057], device='cuda:1')
Storing RECOVERY transition: reward=-1.5477 (scaled=-1.5477), steps=1
Reward stats updated: mean -0.0069 -> -0.0296, std: 0.2041
Collected 68 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.9938, Q2 Loss=0.9938, Entropy=0.2267, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0410
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=0.6911, Q2 Loss=0.6911, Entropy=0.3666, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0475
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.9869, Q2 Loss=0.9869, Entropy=0.2555, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0873
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9798, Q2 Loss=0.9798, Entropy=0.0874, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0368
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9802, Q2 Loss=0.9802, Entropy=0.0067, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0911

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.4%)
Target Q: 0.05s (15.0%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.06s (19.8%)
Actor update: 0.13s (42.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000211
Q1 loss: 0.926353
Q2 loss: 0.926353
Current threshold: -29.9542
Global Scale Offset: 1.2073
Reward stats: mean=-0.0296, std=0.2041, count=68
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.9264, Q2 Loss: 0.9264, Entropy: 0.1886, Mean TD Error: 0.0607, Threshold: -29.9542
Original likelihood: -1257.615478515625
Adjusted likelihood: -1257.615478515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 5
Loaded trajectory sampler
Current yaw: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:1')
Current yaw: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:1')
1 turn
Sampling time 3.813684842985822
tensor([ 1.1862e-01,  5.8357e-01,  5.5730e-01,  6.3811e-01, -1.4982e-01,
         5.6667e-01,  8.9692e-01,  9.4111e-01,  1.2318e+00,  2.8931e-01,
         2.2487e-01,  1.2394e+00,  3.7755e-04,  1.4106e-02, -4.7386e-02,
         4.7066e-01], device='cuda:1')
Original likelihood: -22.04679298400879
Adjusted likelihood: -22.04679298400879
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 14.960005283006467
Current ori: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:1')
Middle force: tensor([0.7119, 0.7369, 0.5340, 0.5240, 0.6297, 0.9929, 0.9794, 0.5898, 0.5003,
        0.5926, 1.1975, 0.8369], device='cuda:1')
Thumb force: tensor([0.5656, 2.3532, 0.6302, 1.5267, 1.0500, 0.8617, 1.9689, 0.6001, 0.7159,
        0.6070, 0.6276, 1.4898], device='cuda:1')
Index force: tensor([0.6001, 0.5019, 0.6093, 0.5589, 0.5723, 0.5169, 0.5750, 0.6159, 0.7249,
        0.6300, 0.5521, 0.5614], device='cuda:1')
Storing NORMAL transition: reward=0.0193 (scaled=0.0193), steps=1
Reward stats updated: mean -0.0296 -> -0.0289, std: 0.2027
Collected 69 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8741, Q2 Loss=0.8741, Entropy=0.0376, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2160
SAC Update 2/5: Actor Loss=-0.0027, Q1 Loss=0.9671, Q2 Loss=0.9671, Entropy=0.1298, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0527
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9649, Q2 Loss=0.9649, Entropy=0.0178, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0701
SAC Update 4/5: Actor Loss=-0.0020, Q1 Loss=0.9562, Q2 Loss=0.9562, Entropy=0.6052, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0039
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.9521, Q2 Loss=0.9521, Entropy=0.1014, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0280

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.1%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000946
Q1 loss: 0.942882
Q2 loss: 0.942882
Current threshold: -29.9389
Global Scale Offset: 1.2020
Reward stats: mean=-0.0289, std=0.2027, count=69
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 0.9429, Q2 Loss: 0.9429, Entropy: 0.1784, Mean TD Error: 0.0741, Threshold: -29.9389
tensor([ 0.0871,  0.5119,  0.6275,  0.6353, -0.1828,  0.5494,  0.8304,  1.0720,
         1.2759,  0.2468,  0.2451,  1.2361,  0.0166,  0.0315, -0.0677,  0.5113],
       device='cuda:1')
Original likelihood: -28.7143497467041
Adjusted likelihood: -28.7143497467041
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7210)
Solve time for step 2 2.819150958006503
Current ori: tensor([ 0.0166,  0.0315, -0.0677], device='cuda:1')
Middle force: tensor([0.5716, 1.2048, 0.5577, 1.1265, 0.6410, 0.5358, 0.5744, 0.5044, 0.8044,
        0.6138, 0.6039], device='cuda:1')
Thumb force: tensor([0.8670, 0.7925, 1.0611, 1.0943, 0.6560, 0.5330, 0.8312, 0.5253, 0.5554,
        0.6094, 0.5812], device='cuda:1')
Index force: tensor([0.5995, 0.5479, 0.5683, 0.8165, 0.5056, 1.0219, 0.9113, 0.5914, 0.5995,
        0.5409, 0.5927], device='cuda:1')
Storing NORMAL transition: reward=-0.0120 (scaled=-0.0120), steps=1
Reward stats updated: mean -0.0289 -> -0.0286, std: 0.2013
Collected 70 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.7024, Q2 Loss=0.7024, Entropy=0.3609, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0486
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=1.5135, Q2 Loss=1.5135, Entropy=0.2839, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7767
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6895, Q2 Loss=0.6895, Entropy=0.0052, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0803
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7730, Q2 Loss=0.7730, Entropy=0.0031, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0448
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.7582, Q2 Loss=0.7582, Entropy=0.3389, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7842

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000134
Q1 loss: 0.887317
Q2 loss: 0.887317
Current threshold: -29.9408
Global Scale Offset: 1.1936
Reward stats: mean=-0.0286, std=0.2013, count=70
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.8873, Q2 Loss: 0.8873, Entropy: 0.1984, Mean TD Error: 0.3469, Threshold: -29.9408
tensor([ 0.0635,  0.5373,  0.5569,  0.6551, -0.2519,  0.6505,  0.7456,  1.0571,
         1.2650,  0.3515,  0.2134,  1.3137,  0.0083,  0.0548, -0.0574,  0.2827],
       device='cuda:1')
Original likelihood: -40.05778121948242
Adjusted likelihood: -40.05778121948242
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 40.51410675048828
Projection step: 1, Loss: 37.43949890136719
Projection step: 2, Loss: 34.31560516357422
Projection step: 3, Loss: 32.2720947265625
Projection step: 4, Loss: 29.146177291870117
Projection step: 5, Loss: 27.248554229736328
Projection step: 6, Loss: 28.468486785888672
Projection step: 7, Loss: 25.026599884033203
Projection step: 8, Loss: 23.776947021484375
Projection step: 9, Loss: 21.723190307617188
Projection step: 10, Loss: 19.715259552001953
Projection step: 11, Loss: 18.374561309814453
Projection step: 12, Loss: 16.42828941345215
Projection step: 13, Loss: 14.972879409790039
Final likelihood: tensor([-14.7841, -14.5378, -14.2946, -17.9289, -14.8341, -15.2297, -14.6153,
        -14.8022, -14.6608, -14.7744, -12.2935, -14.7071, -14.4751, -14.7946,
        -18.1929, -14.6412])
Final projection likelihood: -14.9729
1 mode projection succeeded
New goal: tensor([ 0.0712,  0.5345,  0.5719,  0.6685, -0.1187,  0.5805,  0.7803,  0.8766,
         1.2971,  0.2849,  0.1663,  1.1999, -0.0030,  0.0255, -0.6705],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -24.498046875
Adjusted likelihood: -24.498046875
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 24.498046875}
Current yaw: tensor([ 0.0083,  0.0548, -0.0574], device='cuda:1')
2 thumb_middle
tensor([ 0.0635,  0.5373,  0.5569,  0.6551, -0.2519,  0.6505,  0.7456,  1.0571,
         1.2650,  0.3515,  0.2134,  1.3137,  0.0083,  0.0548, -0.0574,  0.2827],
       device='cuda:1')
Solve time for step 1 9.120416577003198
Current ori: tensor([ 0.0083,  0.0548, -0.0574], device='cuda:1')
Index force: tensor([0.5745, 0.5684, 0.5778, 0.6008], device='cuda:1')
tensor([ 0.0597,  0.5356,  0.5614,  0.6438, -0.2594,  0.5980,  0.7517,  0.8947,
         1.2700,  0.2913,  0.1319,  1.2113,  0.0083,  0.0567, -0.0574,  0.2840],
       device='cuda:1')
Solve time for step 2 2.0437612120003905
Current ori: tensor([ 0.0083,  0.0567, -0.0574], device='cuda:1')
Index force: tensor([0.5632, 0.5728, 0.5967], device='cuda:1')
tensor([ 0.0753,  0.5444,  0.5618,  0.6492, -0.2455,  0.6072,  0.7671,  0.8736,
         1.2844,  0.2744,  0.1105,  1.1872,  0.0061,  0.0477, -0.0574,  0.3077],
       device='cuda:1')
Solve time for step 3 1.8954166889889166
Current ori: tensor([ 0.0061,  0.0477, -0.0574], device='cuda:1')
Index force: tensor([0.5655, 0.5892], device='cuda:1')
tensor([ 0.0920,  0.5526,  0.5632,  0.6562, -0.2315,  0.6098,  0.7671,  0.8581,
         1.2861,  0.2735,  0.0944,  1.1767,  0.0043,  0.0382, -0.0574,  0.3326],
       device='cuda:1')
Solve time for step 4 1.8378704649803694
Current ori: tensor([ 0.0043,  0.0382, -0.0574], device='cuda:1')
Index force: tensor([0.5655], device='cuda:1')
Storing RECOVERY transition: reward=0.0024 (scaled=0.0012), steps=2
Reward stats updated: mean -0.0286 -> -0.0282, std: 0.1999
Collected 71 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.6430, Q2 Loss=0.6430, Entropy=0.5926, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0360
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8615, Q2 Loss=0.8615, Entropy=0.0071, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0200
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6308, Q2 Loss=0.6308, Entropy=0.3027, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0249
SAC Update 4/5: Actor Loss=-0.0006, Q1 Loss=0.6339, Q2 Loss=0.6339, Entropy=0.3547, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0319
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8634, Q2 Loss=0.8634, Entropy=0.1146, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8108

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000301
Q1 loss: 0.726523
Q2 loss: 0.726523
Current threshold: -29.9303
Global Scale Offset: 1.1947
Reward stats: mean=-0.0282, std=0.1999, count=71
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.7265, Q2 Loss: 0.7265, Entropy: 0.2743, Mean TD Error: 0.1847, Threshold: -29.9303
Original likelihood: -25.918514251708984
Adjusted likelihood: -25.918514251708984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9731)
Current yaw: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:1')
3 turn
Sampling time 3.7213264089950826
tensor([ 0.0854,  0.5580,  0.5512,  0.6530, -0.1777,  0.6301,  0.7858,  0.8670,
         1.3605,  0.2975,  0.1305,  1.2016,  0.0045,  0.0380, -0.0583,  0.3594],
       device='cuda:1')
Original likelihood: -29.604450225830078
Adjusted likelihood: -29.604450225830078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5622)
State is out of distribution
Projection step: 0, Loss: 28.766324996948242
Projection step: 1, Loss: 27.382972717285156
Projection step: 2, Loss: 26.164113998413086
Projection step: 3, Loss: 24.97966766357422
Projection step: 4, Loss: 21.51034927368164
Projection step: 5, Loss: 20.810766220092773
Projection step: 6, Loss: 17.198556900024414
Projection step: 7, Loss: 15.160356521606445
Projection step: 8, Loss: 12.264278411865234
Final likelihood: tensor([-12.0678, -16.5578,  -9.1679, -13.1694,  -9.7286, -12.3747, -21.9303,
         -9.5241,  -8.9822, -11.4606, -14.7476,  -8.9133, -16.4380,  -9.6353,
         -9.2136, -12.3171])
Final projection likelihood: -12.2643
1 mode projection succeeded
New goal: tensor([ 0.0835,  0.5591,  0.5657,  0.6296, -0.0918,  0.5988,  0.8113,  0.8004,
         1.3023,  0.3185,  0.1835,  1.1923,  0.0017,  0.0176, -0.8986],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -19.324491500854492
Adjusted likelihood: -19.324491500854492
Likelihood residual: 0.0
Original likelihood: -19.966533660888672
Adjusted likelihood: -19.966533660888672
Likelihood residual: 0.0
{'index': 19.966533660888672, 'thumb_middle': 19.324491500854492}
Current yaw: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:1')
4 thumb_middle
tensor([ 0.0854,  0.5580,  0.5512,  0.6530, -0.1777,  0.6301,  0.7858,  0.8670,
         1.3605,  0.2975,  0.1305,  1.2016,  0.0045,  0.0380, -0.0583,  0.3594],
       device='cuda:1')
Solve time for step 1 9.100650142005179
Current ori: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:1')
Index force: tensor([0.5566, 0.5845, 0.5824, 0.5693], device='cuda:1')
tensor([ 0.0825,  0.5546,  0.5606,  0.6370, -0.2269,  0.5985,  0.7650,  0.7922,
         1.2826,  0.3186,  0.0999,  1.1561,  0.0039,  0.0407, -0.0582,  0.3211],
       device='cuda:1')
Solve time for step 2 2.001879215007648
Current ori: tensor([ 0.0039,  0.0407, -0.0582], device='cuda:1')
Index force: tensor([0.5791, 0.5780, 0.5653], device='cuda:1')
tensor([ 0.0995,  0.5567,  0.5840,  0.6191, -0.2091,  0.5928,  0.7784,  0.7812,
         1.2670,  0.2961,  0.1043,  1.1633,  0.0015,  0.0307, -0.0582,  0.3433],
       device='cuda:1')
Solve time for step 3 1.8805366560118273
Current ori: tensor([ 0.0015,  0.0307, -0.0582], device='cuda:1')
Index force: tensor([0.5712, 0.5835], device='cuda:1')
tensor([ 1.0104e-01,  5.6556e-01,  5.7172e-01,  6.2228e-01, -2.1018e-01,
         5.9547e-01,  7.7978e-01,  7.7966e-01,  1.2707e+00,  2.9440e-01,
         9.5246e-02,  1.1644e+00, -2.6768e-04,  2.9610e-02, -5.8194e-02,
         3.4546e-01], device='cuda:1')
Solve time for step 4 1.8402842319919728
Current ori: tensor([-0.0003,  0.0296, -0.0582], device='cuda:1')
Index force: tensor([0.5563], device='cuda:1')
Storing RECOVERY transition: reward=0.0082 (scaled=0.0082), steps=0
Reward stats updated: mean -0.0282 -> -0.0277, std: 0.1985
Collected 72 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7550, Q2 Loss=0.7550, Entropy=0.0386, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2250
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9024, Q2 Loss=0.9024, Entropy=0.0170, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1405
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.9018, Q2 Loss=0.9018, Entropy=0.2313, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0373
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9000, Q2 Loss=0.9000, Entropy=0.0231, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0717
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7165, Q2 Loss=0.7165, Entropy=0.1148, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7810

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (21.6%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (17.4%)
Actor update: 0.08s (37.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000047
Q1 loss: 0.835133
Q2 loss: 0.835133
Current threshold: -29.9225
Global Scale Offset: 1.2005
Reward stats: mean=-0.0277, std=0.1985, count=72
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8351, Q2 Loss: 0.8351, Entropy: 0.0850, Mean TD Error: 0.2511, Threshold: -29.9225
Original likelihood: -23.811656951904297
Adjusted likelihood: -23.811656951904297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9983)
Current yaw: tensor([-0.0002,  0.0198, -0.0655], device='cuda:1')
5 turn
Sampling time 3.7496724810043816
tensor([ 1.1561e-01,  5.7158e-01,  5.7363e-01,  6.3138e-01, -1.4479e-01,
         6.4165e-01,  8.1408e-01,  7.9200e-01,  1.3349e+00,  3.3087e-01,
         1.2893e-01,  1.1770e+00, -2.0352e-04,  1.9776e-02, -6.5467e-02,
         4.3854e-01], device='cuda:1')
Original likelihood: -20.09916877746582
Adjusted likelihood: -20.09916877746582
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.140601210005116
Current ori: tensor([-0.0002,  0.0198, -0.0655], device='cuda:1')
Middle force: tensor([0.5175, 0.6713, 0.5564, 0.5037, 0.7699, 1.0816, 0.5875, 0.5622, 0.5414,
        0.5585, 0.6147, 0.5900], device='cuda:1')
Thumb force: tensor([0.8690, 0.6713, 1.6177, 2.4745, 0.8789, 1.7510, 0.5940, 0.7061, 0.5664,
        1.6251, 0.5385, 0.5704], device='cuda:1')
Index force: tensor([0.5038, 0.8620, 0.5953, 0.6056, 0.5845, 0.5852, 0.5875, 0.5166, 0.4904,
        0.8261, 0.7435, 0.5397], device='cuda:1')
Storing NORMAL transition: reward=-0.0964 (scaled=-0.0964), steps=1
Reward stats updated: mean -0.0277 -> -0.0286, std: 0.1973
Collected 73 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6163, Q2 Loss=0.6163, Entropy=0.0228, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0869
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.5307, Q2 Loss=0.5307, Entropy=0.3429, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0062
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8808, Q2 Loss=0.8808, Entropy=0.0230, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0784
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7956, Q2 Loss=0.7956, Entropy=0.0068, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1507
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9948, Q2 Loss=0.9948, Entropy=0.0968, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8696

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.9%)
Actor update: 0.10s (42.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000041
Q1 loss: 0.763648
Q2 loss: 0.763648
Current threshold: -29.9204
Global Scale Offset: 1.2073
Reward stats: mean=-0.0286, std=0.1973, count=73
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.7636, Q2 Loss: 0.7636, Entropy: 0.0985, Mean TD Error: 0.2384, Threshold: -29.9204
tensor([ 0.0858,  0.5186,  0.6071,  0.6515, -0.1180,  0.6718,  0.7751,  0.8271,
         1.2250,  0.4341,  0.1723,  1.2538,  0.0125,  0.0033,  0.0312,  1.0702],
       device='cuda:1')
Original likelihood: -23.491607666015625
Adjusted likelihood: -23.491607666015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9989)
Solve time for step 2 2.9321974590129685
Current ori: tensor([0.0125, 0.0033, 0.0312], device='cuda:1')
Middle force: tensor([0.6807, 0.5548, 0.5047, 0.7655, 1.0669, 0.5951, 0.5650, 0.5454, 0.5940,
        0.6313, 0.5894], device='cuda:1')
Thumb force: tensor([0.6368, 1.5843, 2.4064, 0.8637, 1.7144, 0.5794, 0.6880, 0.5554, 1.5553,
        0.5248, 0.5670], device='cuda:1')
Index force: tensor([0.8580, 0.5915, 0.5948, 0.5813, 0.5822, 0.5859, 0.5162, 0.5024, 0.7829,
        0.7570, 0.5378], device='cuda:1')
Storing NORMAL transition: reward=0.0110 (scaled=0.0110), steps=1
Reward stats updated: mean -0.0286 -> -0.0281, std: 0.1960
Collected 74 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8405, Q2 Loss=0.8405, Entropy=0.1164, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8096
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.6714, Q2 Loss=0.6714, Entropy=0.3069, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0521
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7976, Q2 Loss=0.7976, Entropy=0.1173, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7991
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9906, Q2 Loss=0.9906, Entropy=0.0981, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8696
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.6604, Q2 Loss=0.6604, Entropy=0.2861, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7767

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000117
Q1 loss: 0.792091
Q2 loss: 0.792091
Current threshold: -29.9249
Global Scale Offset: 1.2186
Reward stats: mean=-0.0281, std=0.1960, count=74
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7921, Q2 Loss: 0.7921, Entropy: 0.1850, Mean TD Error: 0.6614, Threshold: -29.9249
tensor([ 0.0786,  0.5412,  0.5839,  0.6229, -0.1220,  0.6854,  0.7516,  0.8238,
         1.2570,  0.3985,  0.1522,  1.2395,  0.0043,  0.0064,  0.0202,  1.0468],
       device='cuda:1')
Original likelihood: -23.495243072509766
Adjusted likelihood: -23.495243072509766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9988)
Solve time for step 3 2.7866495279886294
Current ori: tensor([0.0043, 0.0064, 0.0202], device='cuda:1')
Middle force: tensor([0.5531, 0.5053, 0.7596, 1.0521, 0.5979, 0.5646, 0.5472, 0.6048, 0.6417,
        0.5877], device='cuda:1')
Thumb force: tensor([1.5493, 2.3461, 0.8498, 1.6792, 0.5720, 0.6800, 0.5493, 1.5155, 0.5190,
        0.5643], device='cuda:1')
Index force: tensor([0.5865, 0.5836, 0.5783, 0.5792, 0.5823, 0.5155, 0.5022, 0.7626, 0.7561,
        0.5361], device='cuda:1')
Storing NORMAL transition: reward=0.0151 (scaled=0.0151), steps=1
Reward stats updated: mean -0.0281 -> -0.0275, std: 0.1948
Collected 75 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6490, Q2 Loss=0.6490, Entropy=0.0086, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1035
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7165, Q2 Loss=0.7165, Entropy=0.0108, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0621
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.7619, Q2 Loss=0.7619, Entropy=0.3458, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0704
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5775, Q2 Loss=0.5775, Entropy=0.0295, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0427
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.7630, Q2 Loss=0.7630, Entropy=0.1038, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0721

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000141
Q1 loss: 0.693579
Q2 loss: 0.693579
Current threshold: -29.9260
Global Scale Offset: 1.2316
Reward stats: mean=-0.0275, std=0.1948, count=75
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6936, Q2 Loss: 0.6936, Entropy: 0.0997, Mean TD Error: 0.0702, Threshold: -29.9260
tensor([ 0.1979,  0.5433,  0.6130,  0.7863, -0.0669,  0.6477,  0.7141,  0.7510,
         1.2797,  0.4390,  0.0787,  1.3586,  0.0116,  0.0185,  0.0047,  1.3116],
       device='cuda:1')
Original likelihood: -25.721298217773438
Adjusted likelihood: -25.721298217773438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9760)
Solve time for step 4 2.6131421090103686
Current ori: tensor([0.0116, 0.0185, 0.0047], device='cuda:1')
Middle force: tensor([0.5042, 0.7414, 1.0284, 0.5728, 0.5519, 0.5326, 0.5212, 0.5963, 0.5804],
       device='cuda:1')
Thumb force: tensor([2.3056, 0.8475, 1.6520, 0.5903, 0.7039, 0.5697, 1.5818, 0.5380, 0.5642],
       device='cuda:1')
Index force: tensor([0.5873, 0.5770, 0.5761, 0.5801, 0.5143, 0.5023, 0.8587, 0.7243, 0.5361],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0311 (scaled=-0.0311), steps=1
Reward stats updated: mean -0.0275 -> -0.0276, std: 0.1935
Collected 76 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5696, Q2 Loss=0.5696, Entropy=0.0820, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0511
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6100, Q2 Loss=0.6100, Entropy=0.0122, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1617
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6272, Q2 Loss=0.6272, Entropy=0.0978, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7750
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.6501, Q2 Loss=0.6501, Entropy=0.3459, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0228
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6172, Q2 Loss=0.6172, Entropy=0.0980, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2023

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000087
Q1 loss: 0.614791
Q2 loss: 0.614791
Current threshold: -29.9220
Global Scale Offset: 1.2446
Reward stats: mean=-0.0276, std=0.1935, count=76
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6148, Q2 Loss: 0.6148, Entropy: 0.1272, Mean TD Error: 0.2426, Threshold: -29.9220
tensor([ 0.2775,  0.6641,  0.6794,  0.7451, -0.1102,  0.6516,  0.5985,  0.7660,
         1.3308,  0.4064,  0.0838,  1.3866,  0.0205,  0.0636,  0.0327, -0.3627],
       device='cuda:1')
Original likelihood: -47.03728103637695
Adjusted likelihood: -47.03728103637695
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 45.79708480834961
Projection step: 1, Loss: 39.544612884521484
Projection step: 2, Loss: 37.34223556518555
Projection step: 3, Loss: 34.108619689941406
Projection step: 4, Loss: 32.237091064453125
Projection step: 5, Loss: 30.644744873046875
Projection step: 6, Loss: 28.299041748046875
Projection step: 7, Loss: 27.631298065185547
Projection step: 8, Loss: 25.402244567871094
Projection step: 9, Loss: 25.022811889648438
Projection step: 10, Loss: 22.22777557373047
Projection step: 11, Loss: 22.367420196533203
Projection step: 12, Loss: 21.31842803955078
Projection step: 13, Loss: 19.955347061157227
Projection step: 14, Loss: 17.9100341796875
Final likelihood: tensor([-14.5556, -14.5062, -17.3840, -15.3583, -17.0567, -19.3132, -15.9535,
        -18.9364, -15.8516, -16.2157, -26.2601, -27.0896, -21.6307, -15.7131,
        -21.0785, -17.7657])
Final projection likelihood: -18.4168
1 mode projection succeeded
New goal: tensor([ 0.1624,  0.6280,  0.6479,  0.6496, -0.0411,  0.6058,  0.6669,  0.8084,
         1.2916,  0.2633,  0.2654,  1.0960,  0.0282,  0.0295,  1.4556],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0033]], device='cuda:1')
Original likelihood: -35.43546676635742
Adjusted likelihood: -35.43546676635742
Likelihood residual: 0.0
{'index': 35.43546676635742, 'thumb_middle': inf}
Current yaw: tensor([0.0205, 0.0636, 0.0327], device='cuda:1')
6 index
tensor([ 0.2775,  0.6641,  0.6794,  0.7451, -0.1102,  0.6516,  0.5985,  0.7660,
         1.3308,  0.4064,  0.0838,  1.3866,  0.0205,  0.0636,  0.0327, -0.3627],
       device='cuda:1')
Solve time for step 1 10.712930237990804
Current ori: tensor([0.0205, 0.0636, 0.0327], device='cuda:1')
Middle force: tensor([0.5222, 0.5251, 0.5259, 0.6053], device='cuda:1')
Thumb force: tensor([0.5832, 0.6289, 0.5639, 0.5870], device='cuda:1')
tensor([ 2.7011e-01,  5.4992e-01,  5.7749e-01,  6.3592e-01, -1.2245e-01,
         6.3695e-01,  6.2118e-01,  7.6220e-01,  1.3314e+00,  4.2555e-01,
         1.0395e-01,  1.3425e+00,  1.8313e-02,  6.8612e-02,  4.8965e-04,
        -5.0823e-01], device='cuda:1')
Solve time for step 2 2.2870073259982746
Current ori: tensor([0.0183, 0.0686, 0.0005], device='cuda:1')
Middle force: tensor([0.5243, 0.5252, 0.6031], device='cuda:1')
Thumb force: tensor([0.6255, 0.5623, 0.5856], device='cuda:1')
tensor([ 0.2406,  0.5468,  0.5708,  0.6143, -0.1227,  0.6485,  0.6111,  0.7393,
         1.3344,  0.4281,  0.1104,  1.3113,  0.0089,  0.0695, -0.0203, -0.3925],
       device='cuda:1')
Solve time for step 3 2.189111921004951
Current ori: tensor([ 0.0089,  0.0695, -0.0203], device='cuda:1')
Middle force: tensor([0.5011, 0.5005], device='cuda:1')
Thumb force: tensor([0.5342, 0.5029], device='cuda:1')
tensor([ 0.2362,  0.5487,  0.5687,  0.6126, -0.1256,  0.6386,  0.6177,  0.7552,
         1.3279,  0.4397,  0.1194,  1.3090,  0.0119,  0.0709, -0.0345, -0.1241],
       device='cuda:1')
Solve time for step 4 2.1200757040060125
Current ori: tensor([ 0.0119,  0.0709, -0.0345], device='cuda:1')
Middle force: tensor([0.5239], device='cuda:1')
Thumb force: tensor([0.5647], device='cuda:1')
Storing RECOVERY transition: reward=0.0786 (scaled=0.0196), steps=4
Reward stats updated: mean -0.0276 -> -0.0270, std: 0.1923
Collected 77 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7493, Q2 Loss=0.7493, Entropy=0.1078, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7931
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7644, Q2 Loss=0.7644, Entropy=0.0090, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0202
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9392, Q2 Loss=0.9392, Entropy=0.1080, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8529
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7793, Q2 Loss=0.7793, Entropy=0.0388, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0881
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7786, Q2 Loss=0.7786, Entropy=0.0271, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0651

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.7%)
Actor update: 0.10s (42.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000014
Q1 loss: 0.802180
Q2 loss: 0.802180
Current threshold: -29.9179
Global Scale Offset: 1.2575
Reward stats: mean=-0.0270, std=0.1923, count=77
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8022, Q2 Loss: 0.8022, Entropy: 0.0582, Mean TD Error: 0.3639, Threshold: -29.9179
Original likelihood: -41.03282165527344
Adjusted likelihood: -41.03282165527344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 41.25262451171875
Projection step: 1, Loss: 39.13014221191406
Projection step: 2, Loss: 39.3917121887207
Projection step: 3, Loss: 37.11122131347656
Projection step: 4, Loss: 37.2869873046875
Projection step: 5, Loss: 35.360496520996094
Projection step: 6, Loss: 34.47090530395508
Projection step: 7, Loss: 33.645057678222656
Projection step: 8, Loss: 31.691394805908203
Projection step: 9, Loss: 32.503334045410156
Projection step: 10, Loss: 30.54273796081543
Projection step: 11, Loss: 29.181140899658203
Projection step: 12, Loss: 26.507884979248047
Projection step: 13, Loss: 24.495336532592773
Projection step: 14, Loss: 23.92270851135254
Final likelihood: tensor([-26.8569, -18.8028, -20.5441, -25.4169, -20.8384, -28.6782, -18.3183,
        -21.2733, -20.7429, -21.5871, -28.4827, -26.6146, -21.7928, -28.6615,
        -20.2529, -19.9940])
Final projection likelihood: -23.0536
1 mode projection succeeded
New goal: tensor([ 0.0786,  0.5875,  0.5638,  0.6641, -0.0631,  0.6427,  0.6128,  0.7850,
         1.2969,  0.2414,  0.2261,  1.1797, -0.0051,  0.0379,  1.4649],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -34.386436462402344
Adjusted likelihood: -34.386436462402344
Likelihood residual: 0.0
Original likelihood: -32.447391510009766
Adjusted likelihood: -32.447391510009766
Likelihood residual: 0.0
{'index': 32.447391510009766, 'thumb_middle': 34.386436462402344}
Current yaw: tensor([ 0.0120,  0.0726, -0.0473], device='cuda:1')
7 index
tensor([ 0.1825,  0.5928,  0.6055,  0.6311, -0.1283,  0.6341,  0.6204,  0.7596,
         1.3287,  0.4441,  0.1175,  1.3127,  0.0120,  0.0726, -0.0473, -0.0381],
       device='cuda:1')
Solve time for step 1 11.702262373000849
Current ori: tensor([ 0.0120,  0.0726, -0.0473], device='cuda:1')
Middle force: tensor([0.5625, 0.5885, 0.5523, 0.5395], device='cuda:1')
Thumb force: tensor([0.5204, 0.5624, 0.5932, 0.5748], device='cuda:1')
tensor([ 0.1482,  0.5110,  0.5107,  0.6279, -0.1403,  0.6428,  0.6137,  0.7817,
         1.3602,  0.4123,  0.0939,  1.3022,  0.0091,  0.0742, -0.0553,  3.5541],
       device='cuda:1')
Solve time for step 2 2.488187562994426
Current ori: tensor([ 0.0091,  0.0742, -0.0553], device='cuda:1')
Middle force: tensor([0.5888, 0.5502, 0.5384], device='cuda:1')
Thumb force: tensor([0.5571, 0.5913, 0.5724], device='cuda:1')
tensor([ 1.3276e-01,  5.1551e-01,  5.0074e-01,  6.2630e-01, -1.4206e-01,
         6.5738e-01,  5.9572e-01,  7.6323e-01,  1.3778e+00,  3.9389e-01,
         8.8851e-02,  1.2746e+00, -6.7516e-04,  7.6190e-02, -7.4747e-02,
         5.8531e+00], device='cuda:1')
Solve time for step 3 2.4273958599951584
Current ori: tensor([-0.0007,  0.0762, -0.0747], device='cuda:1')
Middle force: tensor([0.5173, 0.5253], device='cuda:1')
Thumb force: tensor([0.6159, 0.5308], device='cuda:1')
tensor([ 0.1277,  0.5142,  0.5014,  0.6264, -0.1487,  0.6652,  0.5823,  0.7518,
         1.3891,  0.3826,  0.0914,  1.2568, -0.0054,  0.0809, -0.0787, -5.1183],
       device='cuda:1')
Solve time for step 4 2.2921956840145867
Current ori: tensor([-0.0054,  0.0809, -0.0787], device='cuda:1')
Middle force: tensor([0.5054], device='cuda:1')
Thumb force: tensor([0.5823], device='cuda:1')
Storing RECOVERY transition: reward=0.1395 (scaled=0.0349), steps=4
Reward stats updated: mean -0.0270 -> -0.0262, std: 0.1912
Collected 78 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6856, Q2 Loss=0.6856, Entropy=0.0413, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1966
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.7286, Q2 Loss=0.7286, Entropy=0.5339, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0068
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.7766, Q2 Loss=0.7766, Entropy=0.2555, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0223
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5932, Q2 Loss=0.5932, Entropy=0.0054, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1134
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5685, Q2 Loss=0.5685, Entropy=0.0129, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0832

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.8%)
Q1 update: 0.06s (19.2%)
Q2 update: 0.06s (19.1%)
Actor update: 0.13s (43.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000147
Q1 loss: 0.670476
Q2 loss: 0.670476
Current threshold: -29.9132
Global Scale Offset: 1.2772
Reward stats: mean=-0.0262, std=0.1912, count=78
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6705, Q2 Loss: 0.6705, Entropy: 0.1698, Mean TD Error: 0.0845, Threshold: -29.9132
Original likelihood: -36.6815299987793
Adjusted likelihood: -36.6815299987793
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0010)
State is out of distribution
Projection step: 0, Loss: 33.43932342529297
Projection step: 1, Loss: 34.038856506347656
Projection step: 2, Loss: 33.76802444458008
Projection step: 3, Loss: 32.943359375
Projection step: 4, Loss: 31.60259246826172
Projection step: 5, Loss: 32.15339660644531
Projection step: 6, Loss: 32.51292419433594
Projection step: 7, Loss: 29.716001510620117
Projection step: 8, Loss: 29.688297271728516
Projection step: 9, Loss: 28.78410530090332
Projection step: 10, Loss: 27.82025718688965
Projection step: 11, Loss: 27.05736541748047
Projection step: 12, Loss: 25.181123733520508
Projection step: 13, Loss: 25.214242935180664
Projection step: 14, Loss: 24.261873245239258
Final likelihood: tensor([-21.7481, -26.4314, -23.8857, -21.5114, -21.4198, -24.0280, -23.4483,
        -23.2321, -24.7363, -23.8155, -21.5915, -21.4820, -24.4471, -20.6438,
        -25.0177, -23.2508])
Final projection likelihood: -23.1681
1 mode projection succeeded
New goal: tensor([ 0.0434,  0.5876,  0.5231,  0.6297, -0.1053,  0.6814,  0.5256,  0.8648,
         1.3505,  0.2953,  0.0967,  1.1984, -0.0241,  0.0510, -0.7689],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -25.661888122558594
Adjusted likelihood: -25.661888122558594
Likelihood residual: 0.0
Original likelihood: -28.219247817993164
Adjusted likelihood: -28.219247817993164
Likelihood residual: 0.0
{'index': 28.219247817993164, 'thumb_middle': 25.661888122558594}
Current yaw: tensor([-0.0030,  0.0808, -0.1100], device='cuda:1')
8 thumb_middle
tensor([ 8.2110e-02,  5.6211e-01,  5.3879e-01,  6.4780e-01, -1.5078e-01,
         6.5198e-01,  5.9415e-01,  7.7577e-01,  1.3903e+00,  4.0014e-01,
         7.7657e-02,  1.2691e+00, -3.0151e-03,  8.0778e-02, -1.0997e-01,
        -4.8089e+00], device='cuda:1')
Solve time for step 1 9.869013326999266
Current ori: tensor([-0.0030,  0.0808, -0.1100], device='cuda:1')
Index force: tensor([0.5777, 0.5981, 0.5777, 0.5780], device='cuda:1')
tensor([ 7.4963e-02,  5.6538e-01,  5.2621e-01,  6.4701e-01, -2.0639e-01,
         6.6286e-01,  4.9353e-01,  8.2437e-01,  1.3632e+00,  2.9810e-01,
         4.6424e-02,  1.2012e+00, -1.9304e-04,  8.8931e-02, -1.0995e-01,
        -4.8838e+00], device='cuda:1')
Solve time for step 2 2.145028829021612
Current ori: tensor([-0.0002,  0.0889, -0.1100], device='cuda:1')
Index force: tensor([0.5920, 0.5731, 0.5726], device='cuda:1')
tensor([ 0.0902,  0.5754,  0.5351,  0.6323, -0.2034,  0.6798,  0.5028,  0.8189,
         1.3594,  0.2822,  0.0455,  1.1973, -0.0051,  0.0795, -0.1100, -4.8585],
       device='cuda:1')
Solve time for step 3 2.056953851977596
Current ori: tensor([-0.0051,  0.0795, -0.1100], device='cuda:1')
Index force: tensor([0.5676, 0.5673], device='cuda:1')
tensor([ 0.1060,  0.5899,  0.5284,  0.6373, -0.1970,  0.6815,  0.4992,  0.8469,
         1.3478,  0.2939,  0.0483,  1.1812, -0.0092,  0.0698, -0.1100, -4.8353],
       device='cuda:1')
Solve time for step 4 2.0401071259984747
Current ori: tensor([-0.0092,  0.0698, -0.1100], device='cuda:1')
Index force: tensor([0.5674], device='cuda:1')
Storing RECOVERY transition: reward=0.1439 (scaled=0.0360), steps=4
Reward stats updated: mean -0.0262 -> -0.0254, std: 0.1901
Collected 79 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9716, Q2 Loss=0.9716, Entropy=0.1083, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8696
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.6166, Q2 Loss=0.6166, Entropy=0.3723, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0407
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=0.5681, Q2 Loss=0.5681, Entropy=0.3449, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2000
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8095, Q2 Loss=0.8095, Entropy=0.1339, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8124
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6562, Q2 Loss=0.6562, Entropy=0.0447, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2048

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.9%)
Q1 update: 0.07s (21.1%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (40.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000249
Q1 loss: 0.724391
Q2 loss: 0.724391
Current threshold: -29.9142
Global Scale Offset: 1.2968
Reward stats: mean=-0.0254, std=0.1901, count=79
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.7244, Q2 Loss: 0.7244, Entropy: 0.2008, Mean TD Error: 0.4255, Threshold: -29.9142
Original likelihood: -32.718788146972656
Adjusted likelihood: -32.718788146972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.1020)
Current yaw: tensor([-0.0083,  0.0808, -0.1145], device='cuda:1')
9 turn
Sampling time 3.7347574589948636
tensor([ 0.0750,  0.5828,  0.5247,  0.6071, -0.1735,  0.7136,  0.5077,  0.8787,
         1.4242,  0.2982,  0.1020,  1.2104, -0.0083,  0.0808, -0.1145, -4.7620],
       device='cuda:1')
Original likelihood: -32.027767181396484
Adjusted likelihood: -32.027767181396484
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1692)
State is out of distribution
Projection step: 0, Loss: 33.26559066772461
Projection step: 1, Loss: 32.301109313964844
Projection step: 2, Loss: 30.73636245727539
Projection step: 3, Loss: 31.510082244873047
Projection step: 4, Loss: 29.953128814697266
Projection step: 5, Loss: 28.96884536743164
Projection step: 6, Loss: 29.417938232421875
Projection step: 7, Loss: 28.490381240844727
Projection step: 8, Loss: 27.518083572387695
Projection step: 9, Loss: 26.316144943237305
Projection step: 10, Loss: 26.03505516052246
Projection step: 11, Loss: 25.784225463867188
Projection step: 12, Loss: 25.491676330566406
Projection step: 13, Loss: 24.104812622070312
Projection step: 14, Loss: 23.12638282775879
Final likelihood: tensor([-24.6172, -25.0255, -24.1322, -25.2114, -23.0340, -21.4533, -28.3448,
        -25.3966, -24.6837, -28.1465, -20.5019, -21.5023, -24.0826, -22.3025,
        -24.5856, -24.4972])
Final projection likelihood: -24.2198
1 mode projection succeeded
New goal: tensor([ 0.0363,  0.5908,  0.5311,  0.5981, -0.1089,  0.6990,  0.4871,  0.8696,
         1.3737,  0.2246,  0.1052,  1.1857, -0.0262,  0.0533, -0.9080],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -27.340959548950195
Adjusted likelihood: -27.340959548950195
Likelihood residual: 0.0
Original likelihood: -24.9483699798584
Adjusted likelihood: -24.9483699798584
Likelihood residual: 0.0
{'index': 24.9483699798584, 'thumb_middle': 27.340959548950195}
Current yaw: tensor([-0.0083,  0.0808, -0.1145], device='cuda:1')
10 index
tensor([ 0.0750,  0.5828,  0.5247,  0.6071, -0.1735,  0.7136,  0.5077,  0.8787,
         1.4242,  0.2982,  0.1020,  1.2104, -0.0083,  0.0808, -0.1145, -4.7620],
       device='cuda:1')
Solve time for step 1 11.824722817982547
Current ori: tensor([-0.0083,  0.0808, -0.1145], device='cuda:1')
Middle force: tensor([0.5262, 0.5552, 0.5628, 0.5854], device='cuda:1')
Thumb force: tensor([0.5121, 0.6123, 0.5212, 0.5987], device='cuda:1')
tensor([ 0.0888,  0.5117,  0.4700,  0.5706, -0.1812,  0.7159,  0.5049,  0.8812,
         1.4585,  0.2472,  0.0864,  1.1989, -0.0117,  0.0840, -0.1284, -2.7647],
       device='cuda:1')
Solve time for step 2 2.161395942006493
Current ori: tensor([-0.0117,  0.0840, -0.1284], device='cuda:1')
Middle force: tensor([0.5536, 0.5613, 0.5826], device='cuda:1')
Thumb force: tensor([0.6073, 0.5197, 0.5963], device='cuda:1')
tensor([ 0.0861,  0.5222,  0.4663,  0.5668, -0.1637,  0.7415,  0.4854,  0.8594,
         1.4556,  0.2438,  0.0700,  1.1990, -0.0215,  0.0741, -0.1224, -1.6065],
       device='cuda:1')
Solve time for step 3 2.461141626990866
Current ori: tensor([-0.0215,  0.0741, -0.1224], device='cuda:1')
Middle force: tensor([0.5072, 0.5056], device='cuda:1')
Thumb force: tensor([0.5855, 0.5902], device='cuda:1')
tensor([ 0.0867,  0.5245,  0.4696,  0.5659, -0.1598,  0.7400,  0.4895,  0.8632,
         1.4400,  0.2837,  0.0707,  1.1949, -0.0224,  0.0713, -0.1374, -0.6096],
       device='cuda:1')
Solve time for step 4 2.381931096984772
Current ori: tensor([-0.0224,  0.0713, -0.1374], device='cuda:1')
Middle force: tensor([0.5269], device='cuda:1')
Thumb force: tensor([0.5807], device='cuda:1')
Storing RECOVERY transition: reward=0.0107 (scaled=0.0107), steps=0
Reward stats updated: mean -0.0254 -> -0.0249, std: 0.1890
Collected 80 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.5119, Q2 Loss=0.5119, Entropy=0.2328, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0440
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.6120, Q2 Loss=0.6120, Entropy=0.4440, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0350
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7208, Q2 Loss=0.7208, Entropy=0.0310, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0854
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5510, Q2 Loss=0.5510, Entropy=0.0134, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1035
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6446, Q2 Loss=0.6446, Entropy=0.0131, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0703

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.2%)
Q1 update: 0.07s (20.6%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (41.8%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000186
Q1 loss: 0.608089
Q2 loss: 0.608089
Current threshold: -29.9238
Global Scale Offset: 1.3150
Reward stats: mean=-0.0249, std=0.1890, count=80
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.6081, Q2 Loss: 0.6081, Entropy: 0.1469, Mean TD Error: 0.0676, Threshold: -29.9238
Original likelihood: -29.726451873779297
Adjusted likelihood: -29.726451873779297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5352)
Current yaw: tensor([-0.0258,  0.0789, -0.1256], device='cuda:1')
11 turn
Sampling time 3.721319219999714
tensor([ 0.0315,  0.5804,  0.5048,  0.5816, -0.1708,  0.7472,  0.4787,  0.8440,
         1.4690,  0.2518,  0.0554,  1.1866, -0.0258,  0.0789, -0.1256, -0.3701],
       device='cuda:1')
Original likelihood: -29.278501510620117
Adjusted likelihood: -29.278501510620117
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6138)
State is out of distribution
Projection step: 0, Loss: 29.56389617919922
Projection step: 1, Loss: 29.830810546875
Projection step: 2, Loss: 30.731149673461914
Projection step: 3, Loss: 28.58568572998047
Projection step: 4, Loss: 27.69013214111328
Projection step: 5, Loss: 28.427928924560547
Projection step: 6, Loss: 27.422077178955078
Projection step: 7, Loss: 27.109092712402344
Projection step: 8, Loss: 26.726261138916016
Projection step: 9, Loss: 25.558679580688477
Projection step: 10, Loss: 25.5457706451416
Projection step: 11, Loss: 24.776588439941406
Projection step: 12, Loss: 25.772113800048828
Projection step: 13, Loss: 24.641433715820312
Projection step: 14, Loss: 24.781150817871094
Final likelihood: tensor([-20.7163, -20.2896, -20.2858, -21.0749, -20.9625, -24.5424, -24.0802,
        -23.5249, -21.5419, -24.0084, -21.4379, -20.3662, -23.9884, -21.3222,
        -22.6306, -24.0631])
Final projection likelihood: -22.1772
1 mode projection succeeded
New goal: tensor([ 0.0373,  0.5867,  0.5274,  0.6140, -0.1063,  0.6893,  0.4798,  0.8829,
         1.4071,  0.2249,  0.0995,  1.1504, -0.0330,  0.0557, -0.6771],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -25.024795532226562
Adjusted likelihood: -25.024795532226562
Likelihood residual: 0.0
Original likelihood: -24.423948287963867
Adjusted likelihood: -24.423948287963867
Likelihood residual: 0.0
{'index': 24.423948287963867, 'thumb_middle': 25.024795532226562}
Current yaw: tensor([-0.0258,  0.0789, -0.1256], device='cuda:1')
12 index
tensor([ 0.0315,  0.5804,  0.5048,  0.5816, -0.1708,  0.7472,  0.4787,  0.8440,
         1.4690,  0.2518,  0.0554,  1.1866, -0.0258,  0.0789, -0.1256, -0.3701],
       device='cuda:1')
Solve time for step 1 11.765522319008596
Current ori: tensor([-0.0258,  0.0789, -0.1256], device='cuda:1')
Middle force: tensor([0.5105, 0.5410, 0.5569, 0.5471], device='cuda:1')
Thumb force: tensor([0.5957, 0.5441, 0.6376, 0.6356], device='cuda:1')
tensor([ 0.0838,  0.5123,  0.4630,  0.5768, -0.1684,  0.7377,  0.4842,  0.8735,
         1.4659,  0.2549,  0.0536,  1.1922, -0.0212,  0.0764, -0.1440, -0.2383],
       device='cuda:1')
Solve time for step 2 2.2854053670016583
Current ori: tensor([-0.0212,  0.0764, -0.1440], device='cuda:1')
Middle force: tensor([0.5840, 0.5494, 0.5442], device='cuda:1')
Thumb force: tensor([0.5751, 0.5795, 0.5668], device='cuda:1')
tensor([ 0.0817,  0.5211,  0.4594,  0.5837, -0.1731,  0.7434,  0.4814,  0.8670,
         1.4646,  0.2589,  0.0577,  1.1873, -0.0237,  0.0781, -0.1344,  0.1539],
       device='cuda:1')
Solve time for step 3 2.218601314991247
Current ori: tensor([-0.0237,  0.0781, -0.1344], device='cuda:1')
Middle force: tensor([0.5536, 0.5018], device='cuda:1')
Thumb force: tensor([0.5648, 0.5919], device='cuda:1')
tensor([ 0.0809,  0.5224,  0.4607,  0.5874, -0.1625,  0.7576,  0.4724,  0.8517,
         1.4678,  0.2481,  0.0447,  1.1852, -0.0302,  0.0720, -0.1357,  0.6338],
       device='cuda:1')
Solve time for step 4 2.1436719539924525
Current ori: tensor([-0.0302,  0.0720, -0.1357], device='cuda:1')
Middle force: tensor([0.5014], device='cuda:1')
Thumb force: tensor([0.5824], device='cuda:1')
Storing RECOVERY transition: reward=0.0217 (scaled=0.0217), steps=0
Reward stats updated: mean -0.0249 -> -0.0244, std: 0.1879
Collected 81 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=0.6367, Q2 Loss=0.6367, Entropy=0.3810, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1983
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.6331, Q2 Loss=0.6331, Entropy=0.2919, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0525
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.6320, Q2 Loss=0.6320, Entropy=0.2757, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0532
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8096, Q2 Loss=0.8096, Entropy=0.1150, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8157
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9810, Q2 Loss=0.9810, Entropy=0.1230, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8762

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.5%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000223
Q1 loss: 0.738465
Q2 loss: 0.738465
Current threshold: -29.9325
Global Scale Offset: 1.3351
Reward stats: mean=-0.0244, std=0.1879, count=81
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.7385, Q2 Loss: 0.7385, Entropy: 0.2373, Mean TD Error: 0.3992, Threshold: -29.9325
Original likelihood: -29.565500259399414
Adjusted likelihood: -29.565500259399414
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5646)
State is out of distribution
Projection step: 0, Loss: 28.845489501953125
Projection step: 1, Loss: 28.271533966064453
Projection step: 2, Loss: 28.34674644470215
Projection step: 3, Loss: 26.782737731933594
Projection step: 4, Loss: 27.48028564453125
Projection step: 5, Loss: 26.20978355407715
Projection step: 6, Loss: 25.895648956298828
Projection step: 7, Loss: 26.33550262451172
Projection step: 8, Loss: 25.27570343017578
Projection step: 9, Loss: 24.82526397705078
Projection step: 10, Loss: 23.994922637939453
Projection step: 11, Loss: 23.522130966186523
Projection step: 12, Loss: 22.938610076904297
Projection step: 13, Loss: 21.74787139892578
Projection step: 14, Loss: 22.573673248291016
Final likelihood: tensor([-19.7952, -20.4592, -23.2865, -18.6724, -21.9439, -23.3422, -23.4574,
        -21.2506, -22.4112, -22.6329, -22.6850, -23.2643, -22.8371, -23.5093,
        -24.7294, -24.4666])
Final projection likelihood: -22.4215
1 mode projection succeeded
New goal: tensor([ 0.0398,  0.5829,  0.5141,  0.6290, -0.0992,  0.6810,  0.4978,  0.8965,
         1.4093,  0.2121,  0.0956,  1.1513, -0.0332,  0.0503, -0.6874],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -21.48856544494629
Adjusted likelihood: -21.48856544494629
Likelihood residual: 0.0
Original likelihood: -25.639055252075195
Adjusted likelihood: -25.639055252075195
Likelihood residual: 0.0
{'index': 25.639055252075195, 'thumb_middle': 21.48856544494629}
Current yaw: tensor([-0.0264,  0.0733, -0.1468], device='cuda:1')
13 thumb_middle
tensor([ 0.0352,  0.5743,  0.5055,  0.6041, -0.1653,  0.7474,  0.4796,  0.8678,
         1.4672,  0.2651,  0.0362,  1.1965, -0.0264,  0.0733, -0.1468,  0.7536],
       device='cuda:1')
Solve time for step 1 9.583299165999051
Current ori: tensor([-0.0264,  0.0733, -0.1468], device='cuda:1')
Index force: tensor([0.5898, 0.5850, 0.5818, 0.5649], device='cuda:1')
tensor([ 0.0403,  0.5976,  0.4865,  0.5864, -0.2009,  0.6970,  0.4741,  0.8724,
         1.3895,  0.2102,  0.0298,  1.1408, -0.0328,  0.0711, -0.1468,  0.7366],
       device='cuda:1')
Solve time for step 2 1.9607225679792464
Current ori: tensor([-0.0328,  0.0711, -0.1468], device='cuda:1')
Index force: tensor([0.5822, 0.5804, 0.5636], device='cuda:1')
tensor([ 0.0513,  0.6064,  0.4883,  0.5788, -0.1973,  0.7060,  0.4779,  0.8750,
         1.3943,  0.1943,  0.0238,  1.1331, -0.0361,  0.0643, -0.1468,  0.7484],
       device='cuda:1')
Solve time for step 3 1.8886199030093849
Current ori: tensor([-0.0361,  0.0643, -0.1468], device='cuda:1')
Index force: tensor([0.5767, 0.5612], device='cuda:1')
tensor([ 0.0516,  0.5947,  0.4945,  0.5990, -0.1980,  0.7065,  0.4799,  0.8746,
         1.3987,  0.1930,  0.0215,  1.1305, -0.0320,  0.0643, -0.1468,  0.7564],
       device='cuda:1')
Solve time for step 4 1.8425991880067158
Current ori: tensor([-0.0320,  0.0643, -0.1468], device='cuda:1')
Index force: tensor([0.5475], device='cuda:1')
Storing RECOVERY transition: reward=0.0238 (scaled=0.0238), steps=0
Reward stats updated: mean -0.0244 -> -0.0238, std: 0.1868
Collected 82 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5416, Q2 Loss=0.5416, Entropy=0.0044, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0451
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6456, Q2 Loss=0.6456, Entropy=0.0065, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1116
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.5130, Q2 Loss=0.5130, Entropy=0.2431, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0496
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.4310, Q2 Loss=0.4310, Entropy=0.5941, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0230
SAC Update 5/5: Actor Loss=-0.0025, Q1 Loss=0.5246, Q2 Loss=0.5246, Entropy=0.1584, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1132

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (39.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000628
Q1 loss: 0.531170
Q2 loss: 0.531170
Current threshold: -29.9343
Global Scale Offset: 1.3488
Reward stats: mean=-0.0238, std=0.1868, count=82
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 0.5312, Q2 Loss: 0.5312, Entropy: 0.2013, Mean TD Error: 0.0685, Threshold: -29.9343
Original likelihood: -26.225662231445312
Adjusted likelihood: -26.225662231445312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9487)
Current yaw: tensor([-0.0286,  0.0565, -0.1469], device='cuda:1')
14 turn
Sampling time 3.8310267819906585
tensor([ 0.0599,  0.5751,  0.5172,  0.6241, -0.1380,  0.7302,  0.5090,  0.8740,
         1.4541,  0.2277,  0.0625,  1.1581, -0.0286,  0.0565, -0.1469,  0.8182],
       device='cuda:1')
Original likelihood: -24.676931381225586
Adjusted likelihood: -24.676931381225586
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9897)
Solve time for step 1 14.205085561028682
Current ori: tensor([-0.0286,  0.0565, -0.1469], device='cuda:1')
Middle force: tensor([0.5296, 0.6461, 0.5591, 0.5041, 0.6879, 0.9265, 0.5922, 0.5790, 0.8327,
        0.5254, 1.0281, 0.6536], device='cuda:1')
Thumb force: tensor([0.8443, 0.7415, 1.4663, 2.2634, 0.8174, 1.6056, 0.6066, 0.5038, 0.5891,
        1.0549, 0.5665, 0.7551], device='cuda:1')
Index force: tensor([0.5338, 0.8928, 0.6173, 0.6195, 0.6056, 0.5995, 0.5911, 0.5816, 0.6366,
        0.5307, 0.5123, 0.7313], device='cuda:1')
Storing NORMAL transition: reward=0.0262 (scaled=0.0262), steps=1
Reward stats updated: mean -0.0238 -> -0.0232, std: 0.1858
Collected 83 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4648, Q2 Loss=0.4648, Entropy=0.0355, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0514
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5035, Q2 Loss=0.5035, Entropy=0.0632, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1027
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6838, Q2 Loss=0.6838, Entropy=0.0345, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0945
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5314, Q2 Loss=0.5314, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0548
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.5329, Q2 Loss=0.5329, Entropy=0.2737, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0930

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.1%)
Q1 update: 0.06s (20.7%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (39.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000058
Q1 loss: 0.543249
Q2 loss: 0.543249
Current threshold: -29.9223
Global Scale Offset: 1.3365
Reward stats: mean=-0.0232, std=0.1858, count=83
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.5432, Q2 Loss: 0.5432, Entropy: 0.0814, Mean TD Error: 0.0793, Threshold: -29.9223
tensor([ 0.0790,  0.5451,  0.5663,  0.6448, -0.1288,  0.6824,  0.6033,  0.8476,
         1.4151,  0.3020,  0.0766,  1.1582, -0.0201,  0.0472, -0.1718,  0.8698],
       device='cuda:1')
Original likelihood: -26.026817321777344
Adjusted likelihood: -26.026817321777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9578)
Solve time for step 2 2.9791590069944505
Current ori: tensor([-0.0201,  0.0472, -0.1718], device='cuda:1')
Middle force: tensor([0.6370, 0.5570, 0.5035, 0.6809, 0.9097, 0.5882, 0.5760, 0.8217, 0.5237,
        1.0167, 0.6482], device='cuda:1')
Thumb force: tensor([0.7319, 1.4258, 2.2075, 0.8067, 1.5668, 0.6034, 0.5032, 0.5860, 1.0532,
        0.5638, 0.7500], device='cuda:1')
Index force: tensor([0.8803, 0.6150, 0.6144, 0.6013, 0.5955, 0.5885, 0.5798, 0.6339, 0.5271,
        0.5113, 0.7257], device='cuda:1')
Storing NORMAL transition: reward=0.0657 (scaled=0.0657), steps=1
Reward stats updated: mean -0.0232 -> -0.0221, std: 0.1849
Collected 84 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5578, Q2 Loss=0.5578, Entropy=0.0105, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0938
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6501, Q2 Loss=0.6501, Entropy=0.0337, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0861
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5855, Q2 Loss=0.5855, Entropy=0.0336, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0562
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.6007, Q2 Loss=0.6007, Entropy=0.2442, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0758
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7683, Q2 Loss=0.7683, Entropy=0.1446, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8093

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000054
Q1 loss: 0.632495
Q2 loss: 0.632495
Current threshold: -29.9144
Global Scale Offset: 1.3367
Reward stats: mean=-0.0221, std=0.1849, count=84
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6325, Q2 Loss: 0.6325, Entropy: 0.0933, Mean TD Error: 0.2242, Threshold: -29.9144
tensor([ 0.0922,  0.4874,  0.5873,  0.7860, -0.1734,  0.6350,  0.7520,  0.8795,
         1.3949,  0.4119,  0.0552,  1.1797,  0.0025,  0.0410, -0.2368,  1.0130],
       device='cuda:1')
Original likelihood: -29.469680786132812
Adjusted likelihood: -29.469680786132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5781)
Solve time for step 3 2.8018925369833596
Current ori: tensor([ 0.0025,  0.0410, -0.2368], device='cuda:1')
Middle force: tensor([0.5546, 0.5034, 0.6753, 0.8962, 0.5852, 0.5751, 0.8183, 0.5221, 1.0101,
        0.6465], device='cuda:1')
Thumb force: tensor([1.3859, 2.1494, 0.7963, 1.5301, 0.6004, 0.5027, 0.5829, 1.0564, 0.5619,
        0.7468], device='cuda:1')
Index force: tensor([0.6096, 0.6057, 0.5979, 0.5920, 0.5854, 0.5770, 0.6276, 0.5230, 0.5099,
        0.7148], device='cuda:1')
Storing NORMAL transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean -0.0221 -> -0.0218, std: 0.1838
Collected 85 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4587, Q2 Loss=0.4587, Entropy=0.1150, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1001
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.4655, Q2 Loss=0.4655, Entropy=0.3530, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0808
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7671, Q2 Loss=0.7671, Entropy=0.1452, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8096
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7663, Q2 Loss=0.7663, Entropy=0.1455, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8096
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7156, Q2 Loss=0.7156, Entropy=0.1459, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7990

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.8%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.06s (20.2%)
Actor update: 0.13s (41.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000072
Q1 loss: 0.634633
Q2 loss: 0.634633
Current threshold: -29.9099
Global Scale Offset: 1.3462
Reward stats: mean=-0.0218, std=0.1838, count=85
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6346, Q2 Loss: 0.6346, Entropy: 0.1809, Mean TD Error: 0.5198, Threshold: -29.9099
tensor([ 0.1338,  0.4909,  0.6116,  0.8101, -0.2423,  0.6261,  0.8022,  0.8555,
         1.3189,  0.5764,  0.0737,  1.1631,  0.0040,  0.0175, -0.2370,  1.0688],
       device='cuda:1')
Original likelihood: -34.456336975097656
Adjusted likelihood: -34.456336975097656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.0225)
Solve time for step 4 2.83997736001038
Current ori: tensor([ 0.0040,  0.0175, -0.2370], device='cuda:1')
Middle force: tensor([0.5031, 0.6711, 0.8849, 0.5826, 0.5744, 0.8153, 0.5207, 1.0034, 0.6448],
       device='cuda:1')
Thumb force: tensor([2.1002, 0.7871, 1.4962, 0.5976, 0.5023, 0.5804, 1.0592, 0.5608, 0.7465],
       device='cuda:1')
Index force: tensor([0.6007, 0.5948, 0.5885, 0.5824, 0.5737, 0.6212, 0.5195, 0.5086, 0.7020],
       device='cuda:1')
Storing NORMAL transition: reward=0.0956 (scaled=0.0956), steps=1
Reward stats updated: mean -0.0218 -> -0.0205, std: 0.1832
Collected 86 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9655, Q2 Loss=0.9655, Entropy=0.1197, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8695
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.5305, Q2 Loss=0.5305, Entropy=0.3042, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0528
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9651, Q2 Loss=0.9651, Entropy=0.1206, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8695
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8782, Q2 Loss=0.8782, Entropy=0.1419, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8407
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6022, Q2 Loss=0.6022, Entropy=0.0352, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0861

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.8%)
Actor update: 0.10s (42.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000092
Q1 loss: 0.788301
Q2 loss: 0.788301
Current threshold: -29.9049
Global Scale Offset: 1.3621
Reward stats: mean=-0.0205, std=0.1832, count=86
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7883, Q2 Loss: 0.7883, Entropy: 0.1443, Mean TD Error: 0.5438, Threshold: -29.9049
tensor([ 8.0647e-02,  3.4613e-01,  6.9591e-01,  7.6829e-01, -7.8808e-02,
         6.5214e-01,  8.9160e-01,  8.3113e-01,  1.3440e+00,  5.6863e-01,
         1.5778e-03,  1.1532e+00,  7.0432e-04, -4.7797e-02, -3.3567e-01,
         7.1943e-01], device='cuda:1')
Original likelihood: -29.25591468811035
Adjusted likelihood: -29.25591468811035
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6117)
State is out of distribution
Projection step: 0, Loss: 38.39354705810547
Projection step: 1, Loss: 23.859575271606445
Projection step: 2, Loss: 23.507736206054688
Projection step: 3, Loss: 22.79886817932129
Projection step: 4, Loss: 27.83688735961914
Projection step: 5, Loss: 21.7982177734375
Projection step: 6, Loss: 18.515907287597656
Projection step: 7, Loss: 16.46761131286621
Projection step: 8, Loss: 13.608561515808105
Final likelihood: tensor([-17.9415, -17.0150, -15.4278, -10.8083, -10.7943, -10.5412, -16.3937,
        -11.2265, -13.2640, -19.5016, -16.8898, -11.9478, -12.1318, -11.8648,
        -10.9678, -11.0210])
Final projection likelihood: -13.6086
1 mode projection succeeded
New goal: tensor([ 9.2103e-02,  4.0923e-01,  6.9665e-01,  8.2538e-01, -2.3547e-02,
         5.8492e-01,  8.3599e-01,  8.1766e-01,  1.3542e+00,  3.6820e-01,
         1.1359e-01,  1.0191e+00, -8.8162e-04, -3.8912e-02, -1.0363e+00],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0064]], device='cuda:1')
Original likelihood: -27.078594207763672
Adjusted likelihood: -27.078594207763672
Likelihood residual: 0.0
{'index': 27.078594207763672, 'thumb_middle': inf}
Current yaw: tensor([ 0.0007, -0.0478, -0.3357], device='cuda:1')
15 index
tensor([ 8.0647e-02,  3.4613e-01,  6.9591e-01,  7.6829e-01, -7.8808e-02,
         6.5214e-01,  8.9160e-01,  8.3113e-01,  1.3440e+00,  5.6863e-01,
         1.5778e-03,  1.1532e+00,  7.0432e-04, -4.7797e-02, -3.3567e-01,
         7.1943e-01], device='cuda:1')
Solve time for step 1 10.596940725983586
Current ori: tensor([ 0.0007, -0.0478, -0.3357], device='cuda:1')
Middle force: tensor([0.5177, 0.5311, 0.5328, 0.5497], device='cuda:1')
Thumb force: tensor([0.5455, 0.6601, 0.5665, 0.6166], device='cuda:1')
tensor([ 0.1380,  0.3423,  0.6350,  0.7779, -0.0924,  0.6854,  0.8958,  0.8323,
         1.3794,  0.5151, -0.0348,  1.1325, -0.0090, -0.0563, -0.3821, -4.3478],
       device='cuda:1')
Solve time for step 2 2.2394051469746046
Current ori: tensor([-0.0090, -0.0563, -0.3821], device='cuda:1')
Middle force: tensor([0.5295, 0.5310, 0.5472], device='cuda:1')
Thumb force: tensor([0.6582, 0.5652, 0.6147], device='cuda:1')
tensor([ 0.1410,  0.3563,  0.6321,  0.7787, -0.1074,  0.6976,  0.8877,  0.8302,
         1.3988,  0.4821, -0.0373,  1.1182, -0.0076, -0.0515, -0.4131,  0.2114],
       device='cuda:1')
Solve time for step 3 2.187802308006212
Current ori: tensor([-0.0076, -0.0515, -0.4131], device='cuda:1')
Middle force: tensor([0.5291, 0.5446], device='cuda:1')
Thumb force: tensor([0.5626, 0.6132], device='cuda:1')
tensor([ 0.1393,  0.3590,  0.6314,  0.7801, -0.1209,  0.7308,  0.8950,  0.8165,
         1.4091,  0.4693, -0.0569,  1.1207, -0.0080, -0.0599, -0.4512,  2.9934],
       device='cuda:1')
Solve time for step 4 2.092187079018913
Current ori: tensor([-0.0080, -0.0599, -0.4512], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5823], device='cuda:1')
Storing RECOVERY transition: reward=0.1025 (scaled=0.0256), steps=4
Reward stats updated: mean -0.0205 -> -0.0199, std: 0.1822
Collected 87 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.7215, Q2 Loss=0.7215, Entropy=0.3597, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8014
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.4054, Q2 Loss=0.4054, Entropy=0.3416, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0517
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5182, Q2 Loss=0.5182, Entropy=0.0362, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0644
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4985, Q2 Loss=0.4985, Entropy=0.0372, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0583
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5062, Q2 Loss=0.5062, Entropy=0.1121, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0426

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000121
Q1 loss: 0.529970
Q2 loss: 0.529970
Current threshold: -29.9079
Global Scale Offset: 1.3808
Reward stats: mean=-0.0199, std=0.1822, count=87
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.5300, Q2 Loss: 0.5300, Entropy: 0.1774, Mean TD Error: 0.2037, Threshold: -29.9079
Original likelihood: -33.61072540283203
Adjusted likelihood: -33.61072540283203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0545)
State is out of distribution
Projection step: 0, Loss: 31.380678176879883
Projection step: 1, Loss: 28.986129760742188
Projection step: 2, Loss: 27.815828323364258
Projection step: 3, Loss: 26.249675750732422
Projection step: 4, Loss: 24.335235595703125
Projection step: 5, Loss: 23.42859649658203
Projection step: 6, Loss: 23.494029998779297
Projection step: 7, Loss: 25.529144287109375
Projection step: 8, Loss: 22.991222381591797
Projection step: 9, Loss: 22.975101470947266
Projection step: 10, Loss: 18.702594757080078
Projection step: 11, Loss: 20.10958480834961
Projection step: 12, Loss: 17.654224395751953
Projection step: 13, Loss: 16.423255920410156
Projection step: 14, Loss: 16.183029174804688
Final likelihood: tensor([-22.4905, -20.0077, -17.7493, -12.4248, -12.1932, -17.1032, -19.3250,
        -12.4771, -18.0932, -21.8266, -17.1119, -19.7936, -17.8274, -18.1549,
        -11.7384, -12.4017])
Final projection likelihood: -16.9199
1 mode projection succeeded
New goal: tensor([ 0.1255,  0.4364,  0.6683,  0.8468, -0.0165,  0.6336,  0.8469,  0.8081,
         1.4059,  0.2836,  0.1036,  0.9636, -0.0110, -0.0509, -1.7540],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -21.353343963623047
Adjusted likelihood: -21.353343963623047
Likelihood residual: 0.0
Original likelihood: -25.61994743347168
Adjusted likelihood: -25.61994743347168
Likelihood residual: 0.0
{'index': 25.61994743347168, 'thumb_middle': 21.353343963623047}
Current yaw: tensor([-0.0028, -0.0645, -0.4438], device='cuda:1')
16 thumb_middle
tensor([ 9.7714e-02,  4.0684e-01,  6.7575e-01,  8.0933e-01, -1.1723e-01,
         7.3527e-01,  8.9621e-01,  8.1876e-01,  1.3995e+00,  4.8812e-01,
        -8.0677e-02,  1.1716e+00, -2.7860e-03, -6.4468e-02, -4.4377e-01,
         3.5481e+00], device='cuda:1')
Solve time for step 1 9.11439633599366
Current ori: tensor([-0.0028, -0.0645, -0.4438], device='cuda:1')
Index force: tensor([0.5282, 0.5003, 0.5816, 0.5722], device='cuda:1')
tensor([ 0.0951,  0.4075,  0.6578,  0.8411, -0.1198,  0.6558,  0.8098,  0.7947,
         1.3479,  0.3176, -0.0157,  0.9653,  0.0113, -0.0659, -0.4437,  3.6418],
       device='cuda:1')
Solve time for step 2 1.9830188179912511
Current ori: tensor([ 0.0113, -0.0659, -0.4437], device='cuda:1')
Index force: tensor([0.5002, 0.5686, 0.5428], device='cuda:1')
tensor([ 0.0966,  0.4185,  0.6499,  0.8310, -0.1162,  0.6545,  0.8214,  0.7952,
         1.3466,  0.2754,  0.0127,  0.9306,  0.0264, -0.0707, -0.4437,  3.8164],
       device='cuda:1')
Solve time for step 3 1.8094512360112276
Current ori: tensor([ 0.0264, -0.0707, -0.4437], device='cuda:1')
Index force: tensor([0.5665, 0.5597], device='cuda:1')
tensor([ 0.0868,  0.4155,  0.6469,  0.8317, -0.1167,  0.6565,  0.8218,  0.7923,
         1.3623,  0.2941,  0.0051,  0.9258,  0.0396, -0.0631, -0.4437,  3.9433],
       device='cuda:1')
Solve time for step 4 1.7053132080181967
Current ori: tensor([ 0.0396, -0.0631, -0.4437], device='cuda:1')
Index force: tensor([0.5562], device='cuda:1')
Storing RECOVERY transition: reward=0.0898 (scaled=0.0225), steps=4
Reward stats updated: mean -0.0199 -> -0.0195, std: 0.1812
Collected 88 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.5647, Q2 Loss=0.5647, Entropy=0.3264, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0172
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9645, Q2 Loss=0.9645, Entropy=0.1262, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8695
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=0.3881, Q2 Loss=0.3881, Entropy=0.3723, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0475
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.4939, Q2 Loss=0.4939, Entropy=0.3052, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0153
SAC Update 5/5: Actor Loss=-0.0017, Q1 Loss=0.4454, Q2 Loss=0.4454, Entropy=0.0747, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1504

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (19.9%)
Actor update: 0.09s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000511
Q1 loss: 0.571322
Q2 loss: 0.571322
Current threshold: -29.9079
Global Scale Offset: 1.3970
Reward stats: mean=-0.0195, std=0.1812, count=88
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.5713, Q2 Loss: 0.5713, Entropy: 0.2409, Mean TD Error: 0.2200, Threshold: -29.9079
Original likelihood: -31.1456298828125
Adjusted likelihood: -31.1456298828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2977)
Current yaw: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:1')
17 turn
Sampling time 4.0410023749864195
tensor([ 0.0770,  0.4154,  0.6387,  0.8273, -0.0530,  0.7051,  0.8714,  0.8053,
         1.4303,  0.2692,  0.0798,  0.9891,  0.0531, -0.0618, -0.4358,  4.1426],
       device='cuda:1')
Original likelihood: -31.424076080322266
Adjusted likelihood: -31.424076080322266
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2576)
State is out of distribution
Projection step: 0, Loss: 32.057655334472656
Projection step: 1, Loss: 29.748050689697266
Projection step: 2, Loss: 29.048614501953125
Projection step: 3, Loss: 31.108379364013672
Projection step: 4, Loss: 28.02730941772461
Projection step: 5, Loss: 27.01410675048828
Projection step: 6, Loss: 27.669986724853516
Projection step: 7, Loss: 25.761695861816406
Projection step: 8, Loss: 25.497196197509766
Projection step: 9, Loss: 24.292530059814453
Projection step: 10, Loss: 23.699602127075195
Projection step: 11, Loss: 23.8857479095459
Projection step: 12, Loss: 22.770450592041016
Projection step: 13, Loss: 22.604957580566406
Projection step: 14, Loss: 24.081748962402344
Final likelihood: tensor([-23.8511, -24.7534, -23.9777, -23.7814, -21.2859, -23.8883, -21.1434,
        -21.3014, -25.6533, -23.6743, -20.8467, -19.9083, -21.7305, -24.2596,
        -20.5401, -20.8597])
Final projection likelihood: -22.5909
1 mode projection succeeded
New goal: tensor([ 0.0796,  0.4411,  0.6306,  0.8331, -0.0155,  0.5688,  0.7926,  0.8779,
         1.3781,  0.1232,  0.1653,  1.0187,  0.0452, -0.0457, -1.6852],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -29.90496826171875
Adjusted likelihood: -29.90496826171875
Likelihood residual: 0.0
Original likelihood: -29.783342361450195
Adjusted likelihood: -29.783342361450195
Likelihood residual: 0.0
{'index': 29.783342361450195, 'thumb_middle': 29.90496826171875}
Current yaw: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:1')
18 index
tensor([ 0.0770,  0.4154,  0.6387,  0.8273, -0.0530,  0.7051,  0.8714,  0.8053,
         1.4303,  0.2692,  0.0798,  0.9891,  0.0531, -0.0618, -0.4358,  4.1426],
       device='cuda:1')
Solve time for step 1 11.651839040016057
Current ori: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:1')
Middle force: tensor([0.5786, 0.5878, 0.5002, 0.5484], device='cuda:1')
Thumb force: tensor([0.6225, 0.5417, 0.6711, 0.5921], device='cuda:1')
tensor([ 0.1384,  0.3865,  0.5787,  0.7994, -0.0726,  0.7264,  0.8644,  0.8659,
         1.4668,  0.1948,  0.0768,  1.0080,  0.0793, -0.0632, -0.5091,  5.2785],
       device='cuda:1')
Solve time for step 2 2.4538235400104895
Current ori: tensor([ 0.0793, -0.0632, -0.5091], device='cuda:1')
Middle force: tensor([0.5287, 0.5498, 0.5553], device='cuda:1')
Thumb force: tensor([0.6273, 0.5586, 0.5143], device='cuda:1')
tensor([ 0.1393,  0.3972,  0.5797,  0.7987, -0.0903,  0.7659,  0.8742,  0.8780,
         1.5000,  0.2001,  0.1020,  1.0150,  0.1791, -0.0860, -0.5433,  5.7812],
       device='cuda:1')
Solve time for step 3 2.3488468830182683
Current ori: tensor([ 0.1791, -0.0860, -0.5433], device='cuda:1')
Middle force: tensor([0.5485, 0.5529], device='cuda:1')
Thumb force: tensor([0.5554, 0.5139], device='cuda:1')
tensor([ 0.1358,  0.3943,  0.5767,  0.7974, -0.0872,  0.8174,  0.8847,  0.8678,
         1.5000,  0.2089,  0.1401,  1.0020,  0.3549, -0.2381, -0.5338, -5.6625],
       device='cuda:1')
Solve time for step 4 2.3282037659955677
Current ori: tensor([ 0.3549, -0.2381, -0.5338], device='cuda:1')
Middle force: tensor([0.5501], device='cuda:1')
Thumb force: tensor([0.5128], device='cuda:1')
Storing RECOVERY transition: reward=-0.0853 (scaled=-0.0853), steps=0
Reward stats updated: mean -0.0195 -> -0.0202, std: 0.1803
Collected 89 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7978, Q2 Loss=0.7978, Entropy=0.1575, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8201
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.4409, Q2 Loss=0.4409, Entropy=0.0425, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1091
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.5198, Q2 Loss=0.5198, Entropy=0.3400, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2288
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.2122, Q2 Loss=1.2122, Entropy=0.1732, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9604
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.4186, Q2 Loss=0.4186, Entropy=0.0342, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1122

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.1%)
Q1 update: 0.07s (21.3%)
Q2 update: 0.06s (19.9%)
Actor update: 0.13s (39.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000063
Q1 loss: 0.677868
Q2 loss: 0.677868
Current threshold: -29.9063
Global Scale Offset: 1.3942
Reward stats: mean=-0.0202, std=0.1803, count=89
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6779, Q2 Loss: 0.6779, Entropy: 0.1495, Mean TD Error: 0.4461, Threshold: -29.9063
Original likelihood: -140.80587768554688
Adjusted likelihood: -140.80587768554688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 145.72457885742188
Projection step: 1, Loss: 151.5804443359375
Projection step: 2, Loss: 142.0841064453125
Projection step: 3, Loss: 126.47792053222656
Projection step: 4, Loss: 146.00772094726562
Projection step: 5, Loss: 159.45899963378906
Projection step: 6, Loss: 138.83468627929688
Projection step: 7, Loss: 130.99090576171875
Projection step: 8, Loss: 127.83878326416016
Projection step: 9, Loss: 138.35040283203125
Projection step: 10, Loss: 136.6075897216797
Projection step: 11, Loss: 142.45840454101562
Projection step: 12, Loss: 122.89604187011719
Projection step: 13, Loss: 144.81658935546875
Projection step: 14, Loss: 153.27420043945312
Final likelihood: tensor([-140.3564, -178.8408,  -82.3420, -178.4984, -206.0172, -123.9068,
         -90.0331,  -88.6029,  -80.5595, -103.8876, -123.9157, -127.2570,
         -85.9272, -132.3414, -101.1331, -103.9276])
Final projection likelihood: -121.7217
1 mode projection failed, trying anyway
New goal: tensor([ 0.2219,  0.6035,  0.8102,  0.9971, -0.0838,  0.8784,  1.0574,  1.1294,
         1.4328,  0.2167,  0.1545,  1.0867,  0.3528, -0.2440, -0.6778],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0131]], device='cuda:1') tensor([[0.0039]], device='cuda:1')
Original likelihood: -129.3427734375
Adjusted likelihood: -129.3427734375
Likelihood residual: 0.0
Original likelihood: -162.24855041503906
Adjusted likelihood: -162.24855041503906
Likelihood residual: 0.0
{'index': 162.24855041503906, 'thumb_middle': 129.3427734375}
Current yaw: tensor([ 0.3545, -0.2465, -0.5213], device='cuda:1')
19 thumb_middle
tensor([ 0.2068,  0.6122,  0.9012,  1.0363, -0.1093,  0.9347,  1.0485,  0.9727,
         1.4975,  0.2161,  0.1834,  1.0800,  0.3545, -0.2465, -0.5213, -4.9915],
       device='cuda:1')
Solve time for step 1 9.372858361020917
Current ori: tensor([ 0.3545, -0.2465, -0.5213], device='cuda:1')
Index force: tensor([0.5713, 0.5695, 0.5783, 0.5757], device='cuda:1')
tensor([ 0.1566,  0.6781,  0.8314,  0.9987, -0.0635,  0.9102,  1.0253,  1.0813,
         1.3555,  0.2408,  0.0385,  1.0852,  0.3678, -0.3149, -0.4033, -5.9140],
       device='cuda:1')
Solve time for step 2 1.9783022140036337
Current ori: tensor([ 0.3678, -0.3149, -0.4033], device='cuda:1')
Index force: tensor([0.5872, 0.5861, 0.5362], device='cuda:1')
tensor([ 0.1133,  0.7491,  0.8244,  1.0003, -0.0692,  0.9151,  1.0287,  1.0973,
         1.3312,  0.2530, -0.0185,  1.0799,  0.3733, -0.3320, -0.3774,  4.2558],
       device='cuda:1')
Solve time for step 3 1.905111461004708
Current ori: tensor([ 0.3733, -0.3320, -0.3774], device='cuda:1')
Index force: tensor([0.5804, 0.5328], device='cuda:1')
tensor([ 4.0193e-02,  7.3533e-01,  8.3145e-01,  1.0001e+00, -6.0047e-02,
         9.4290e-01,  1.0471e+00,  1.1099e+00,  1.3311e+00,  2.4544e-01,
         2.8767e-03,  1.0827e+00,  3.7251e-01, -3.2937e-01, -3.9063e-01,
         3.6048e+00], device='cuda:1')
Solve time for step 4 1.8402446010150015
Current ori: tensor([ 0.3725, -0.3294, -0.3906], device='cuda:1')
Index force: tensor([0.5271], device='cuda:1')
Storing RECOVERY transition: reward=-0.1335 (scaled=-0.1335), steps=0
Reward stats updated: mean -0.0202 -> -0.0215, std: 0.1797
Collected 90 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.4210, Q2 Loss=0.4210, Entropy=0.1058, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0424
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5375, Q2 Loss=0.5375, Entropy=0.0320, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1153
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.3200, Q2 Loss=0.3200, Entropy=0.6235, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0683
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9684, Q2 Loss=0.9684, Entropy=0.1284, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8695
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9887, Q2 Loss=0.9887, Entropy=0.1344, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8761

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (17.9%)
Actor update: 0.11s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000141
Q1 loss: 0.647099
Q2 loss: 0.647099
Current threshold: -29.9102
Global Scale Offset: 1.4028
Reward stats: mean=-0.0215, std=0.1797, count=90
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6471, Q2 Loss: 0.6471, Entropy: 0.2048, Mean TD Error: 0.3943, Threshold: -29.9102
Original likelihood: -251.4168701171875
Adjusted likelihood: -251.4168701171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 261.9917907714844
Projection step: 1, Loss: 257.3747253417969
Projection step: 2, Loss: 262.4371337890625
Projection step: 3, Loss: 268.9215087890625
Projection step: 4, Loss: 266.2644348144531
Projection step: 5, Loss: 267.0500793457031
Projection step: 6, Loss: 255.0829620361328
Projection step: 7, Loss: 256.066162109375
Projection step: 8, Loss: 267.22698974609375
Projection step: 9, Loss: 262.9731140136719
Projection step: 10, Loss: 264.887451171875
Projection step: 11, Loss: 260.18572998046875
Projection step: 12, Loss: 266.8400573730469
Projection step: 13, Loss: 260.22979736328125
Projection step: 14, Loss: 247.1296844482422
Final likelihood: tensor([-259.2088, -287.0862, -267.4745, -277.0126, -294.6457, -307.8029,
        -288.9540, -216.7143, -251.4799, -291.2364, -251.6089, -220.9162,
        -316.7063, -258.6685, -233.4395, -285.5615])
Final projection likelihood: -269.2823
1 mode projection failed, trying anyway
New goal: tensor([ 0.0063,  0.7095,  0.8531,  1.0062, -0.0366,  1.0158,  1.0909,  1.1589,
         1.3358,  0.2358,  0.0881,  1.0907,  0.3643, -0.3031, -0.4561],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0044]], device='cuda:1')
Original likelihood: -286.8419189453125
Adjusted likelihood: -286.8419189453125
Likelihood residual: 0.0
{'index': 286.8419189453125, 'thumb_middle': inf}
Current yaw: tensor([ 0.3639, -0.3013, -0.4937], device='cuda:1')
20 index
tensor([-0.0171,  0.7078,  0.8341,  1.0004, -0.0342,  1.0180,  1.1054,  1.1318,
         1.3651,  0.2192,  0.0889,  1.0742,  0.3639, -0.3013, -0.4937,  5.1589],
       device='cuda:1')
Solve time for step 1 11.245243451994611
Current ori: tensor([ 0.3639, -0.3013, -0.4937], device='cuda:1')
Middle force: tensor([0.5375, 0.5972, 0.7561, 0.6556], device='cuda:1')
Thumb force: tensor([0.6056, 0.5629, 0.6847, 0.6688], device='cuda:1')
tensor([ 0.2125,  0.8002,  0.8882,  1.0114,  0.0167,  1.0654,  1.0662,  1.0705,
         1.3562,  0.2649,  0.0698,  1.0862,  0.3674, -0.3114, -0.4744,  5.4796],
       device='cuda:1')
Solve time for step 2 2.239951277995715
Current ori: tensor([ 0.3674, -0.3114, -0.4744], device='cuda:1')
Middle force: tensor([0.5974, 0.7656, 0.6569], device='cuda:1')
Thumb force: tensor([0.5603, 0.6891, 0.6761], device='cuda:1')
tensor([ 0.2074,  0.8227,  0.8928,  1.0147,  0.0324,  1.0885,  1.0392,  1.0442,
         1.3502,  0.2864,  0.1029,  1.0850,  0.3671, -0.3106, -0.4783,  4.5382],
       device='cuda:1')
Solve time for step 3 2.182629827002529
Current ori: tensor([ 0.3671, -0.3106, -0.4783], device='cuda:1')
Middle force: tensor([0.5449, 0.7513], device='cuda:1')
Thumb force: tensor([0.5011, 0.7319], device='cuda:1')
tensor([ 0.1467,  0.8375,  0.8964,  1.0163,  0.0437,  1.1025,  1.0484,  0.9850,
         1.3471,  0.3066,  0.1099,  1.0870,  0.3677, -0.3125, -0.4675,  4.4936],
       device='cuda:1')
Solve time for step 4 2.1074462279793806
Current ori: tensor([ 0.3677, -0.3125, -0.4675], device='cuda:1')
Middle force: tensor([0.7353], device='cuda:1')
Thumb force: tensor([0.7193], device='cuda:1')
Storing RECOVERY transition: reward=-0.1050 (scaled=-0.1050), steps=0
Reward stats updated: mean -0.0215 -> -0.0224, std: 0.1789
Collected 91 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.5039, Q2 Loss=0.5039, Entropy=0.3420, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2387
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5053, Q2 Loss=0.5053, Entropy=0.0396, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0261
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.5142, Q2 Loss=0.5142, Entropy=0.3348, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7767
SAC Update 4/5: Actor Loss=-0.0035, Q1 Loss=0.5319, Q2 Loss=0.5319, Entropy=0.0678, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0900
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3954, Q2 Loss=0.3954, Entropy=0.0350, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1122

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000770
Q1 loss: 0.490142
Q2 loss: 0.490142
Current threshold: -29.9112
Global Scale Offset: 1.3967
Reward stats: mean=-0.0224, std=0.1789, count=91
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.4901, Q2 Loss: 0.4901, Entropy: 0.1638, Mean TD Error: 0.2488, Threshold: -29.9112
Original likelihood: -256.0112609863281
Adjusted likelihood: -256.0112609863281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 244.74966430664062
Projection step: 1, Loss: 260.1533203125
Projection step: 2, Loss: 252.63577270507812
Projection step: 3, Loss: 260.64556884765625
Projection step: 4, Loss: 222.92385864257812
Projection step: 5, Loss: 227.28598022460938
Projection step: 6, Loss: 254.71034240722656
Projection step: 7, Loss: 250.38455200195312
Projection step: 8, Loss: 244.6908721923828
Projection step: 9, Loss: 271.9207458496094
Projection step: 10, Loss: 269.43365478515625
Projection step: 11, Loss: 261.5471496582031
Projection step: 12, Loss: 236.15342712402344
Projection step: 13, Loss: 236.4338836669922
Projection step: 14, Loss: 245.71958923339844
Final likelihood: tensor([-207.0230, -160.5325, -272.2800, -214.9737, -324.7193, -174.2272,
        -308.4478, -321.1648, -237.7814, -223.6480, -233.1326, -307.2557,
        -310.1527, -319.3407, -280.9267, -267.5866])
Final projection likelihood: -260.1996
1 mode projection failed, trying anyway
New goal: tensor([ 0.0113,  0.8324,  0.9158,  1.0232, -0.0085,  1.0585,  1.0291,  1.1351,
         1.3173,  0.2768,  0.1727,  1.1081,  0.3624, -0.2989, -0.5259],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 6
Loaded trajectory sampler
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
1 turn
Sampling time 3.7986881569959223
tensor([ 1.4334e-01,  5.6925e-01,  6.0823e-01,  6.2445e-01, -1.1775e-01,
         5.3601e-01,  9.1375e-01,  8.7344e-01,  1.2355e+00,  2.8775e-01,
         2.7602e-01,  1.1182e+00,  5.8629e-04,  1.4505e-02, -4.4825e-02,
         4.1213e-02], device='cuda:1')
Original likelihood: -20.801170349121094
Adjusted likelihood: -20.801170349121094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.848640351992799
Current ori: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
Middle force: tensor([0.7039, 0.7984, 0.5282, 0.5222, 0.6304, 0.9772, 1.0235, 0.5884, 0.5007,
        0.5004, 0.5692, 0.5525], device='cuda:1')
Thumb force: tensor([0.6108, 2.3932, 0.6417, 1.5203, 1.0503, 0.9016, 1.9556, 0.6022, 0.7502,
        0.6399, 0.6001, 0.6562], device='cuda:1')
Index force: tensor([0.5836, 0.5029, 0.5938, 0.5637, 0.5761, 0.5189, 0.5891, 0.6169, 0.7193,
        0.7069, 0.6308, 0.5515], device='cuda:1')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0224 -> -0.0220, std: 0.1780
Collected 92 transitions for RL
SAC Update 1/5: Actor Loss=-0.0018, Q1 Loss=0.3786, Q2 Loss=0.3786, Entropy=0.3054, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0493
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6564, Q2 Loss=0.6564, Entropy=0.1302, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7941
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.2969, Q2 Loss=0.2969, Entropy=0.0371, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0077
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7897, Q2 Loss=0.7897, Entropy=0.1506, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8201
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3721, Q2 Loss=0.3721, Entropy=0.0345, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0711

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.2%)
Actor update: 0.12s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000369
Q1 loss: 0.498712
Q2 loss: 0.498712
Current threshold: -29.8966
Global Scale Offset: 1.3559
Reward stats: mean=-0.0220, std=0.1780, count=92
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.4987, Q2 Loss: 0.4987, Entropy: 0.1316, Mean TD Error: 0.3485, Threshold: -29.8966
tensor([ 0.1104,  0.5885,  0.5389,  0.6443, -0.1253,  0.6029,  0.8045,  0.8885,
         1.3444,  0.1579,  0.2419,  1.0549, -0.0198,  0.0150, -0.0584,  0.8222],
       device='cuda:1')
Original likelihood: -19.763938903808594
Adjusted likelihood: -19.763938903808594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9336721590079833
Current ori: tensor([-0.0198,  0.0150, -0.0584], device='cuda:1')
Middle force: tensor([0.6388, 0.5006, 1.6263, 0.5107, 0.5020, 0.5311, 0.5074, 0.9283, 1.5655,
        0.5613, 0.5239], device='cuda:1')
Thumb force: tensor([1.7074, 0.7068, 0.9878, 0.5926, 0.5273, 0.8771, 1.0811, 0.7182, 0.9261,
        0.5728, 0.6268], device='cuda:1')
Index force: tensor([0.6993, 0.6982, 0.5112, 0.5206, 0.7871, 0.5995, 0.5479, 0.5631, 0.5184,
        0.5724, 0.6373], device='cuda:1')
Storing NORMAL transition: reward=-0.1434 (scaled=-0.1434), steps=1
Reward stats updated: mean -0.0220 -> -0.0233, std: 0.1775
Collected 93 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.4704, Q2 Loss=0.4704, Entropy=0.3167, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1018
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7506, Q2 Loss=0.7506, Entropy=0.1189, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8119
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.4973, Q2 Loss=0.4973, Entropy=0.5378, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0934
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4146, Q2 Loss=0.4146, Entropy=0.0662, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0098
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3126, Q2 Loss=0.3126, Entropy=0.0139, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0912

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.2%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000160
Q1 loss: 0.489107
Q2 loss: 0.489107
Current threshold: -29.8923
Global Scale Offset: 1.3414
Reward stats: mean=-0.0233, std=0.1775, count=93
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.4891, Q2 Loss: 0.4891, Entropy: 0.2107, Mean TD Error: 0.2216, Threshold: -29.8923
tensor([ 0.1065,  0.4899,  0.6138,  0.7515, -0.1661,  0.6362,  0.7949,  0.7874,
         1.3334,  0.1593,  0.2720,  1.1483,  0.0048,  0.0391,  0.0844,  0.5771],
       device='cuda:1')
Original likelihood: -29.069351196289062
Adjusted likelihood: -29.069351196289062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6420)
Solve time for step 3 2.7217294040019624
Current ori: tensor([0.0048, 0.0391, 0.0844], device='cuda:1')
Middle force: tensor([0.5010, 1.6158, 0.5095, 0.5018, 0.5294, 0.5067, 0.9253, 1.5535, 0.5601,
        0.5210], device='cuda:1')
Thumb force: tensor([0.7351, 0.9777, 0.6031, 0.5412, 0.8778, 1.0842, 0.7146, 0.9225, 0.5715,
        0.6367], device='cuda:1')
Index force: tensor([0.6994, 0.5113, 0.5181, 0.7798, 0.5957, 0.5458, 0.5608, 0.5176, 0.5709,
        0.6331], device='cuda:1')
Storing NORMAL transition: reward=0.0263 (scaled=0.0263), steps=1
Reward stats updated: mean -0.0233 -> -0.0228, std: 0.1766
Collected 94 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.4693, Q2 Loss=0.4693, Entropy=0.2811, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0713
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.4533, Q2 Loss=0.4533, Entropy=0.2936, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1213
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4349, Q2 Loss=0.4349, Entropy=0.0076, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1356
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.3803, Q2 Loss=0.3803, Entropy=0.2641, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0872
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.3987, Q2 Loss=0.3987, Entropy=0.3684, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0502

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (39.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000347
Q1 loss: 0.427315
Q2 loss: 0.427315
Current threshold: -29.8973
Global Scale Offset: 1.3418
Reward stats: mean=-0.0228, std=0.1766, count=94
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.4273, Q2 Loss: 0.4273, Entropy: 0.2430, Mean TD Error: 0.0931, Threshold: -29.8973
tensor([ 0.1230,  0.4862,  0.6164,  0.7730, -0.2637,  0.6396,  0.8378,  0.6192,
         1.2593,  0.3279,  0.3241,  1.0807, -0.0205,  0.0565,  0.0565,  1.1188],
       device='cuda:1')
Original likelihood: -33.87950134277344
Adjusted likelihood: -33.87950134277344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0393)
State is out of distribution
Projection step: 0, Loss: 35.68170928955078
Projection step: 1, Loss: 32.45433807373047
Projection step: 2, Loss: 29.865875244140625
Projection step: 3, Loss: 27.131492614746094
Projection step: 4, Loss: 25.831462860107422
Projection step: 5, Loss: 24.121803283691406
Projection step: 6, Loss: 23.25824737548828
Projection step: 7, Loss: 23.19424819946289
Projection step: 8, Loss: 22.473400115966797
Projection step: 9, Loss: 21.141326904296875
Projection step: 10, Loss: 19.79559326171875
Projection step: 11, Loss: 20.30338478088379
Projection step: 12, Loss: 18.940786361694336
Projection step: 13, Loss: 19.05742645263672
Projection step: 14, Loss: 18.443531036376953
Final likelihood: tensor([-18.0796, -21.3037, -18.5499, -21.7683, -17.6946, -20.6624, -15.7822,
        -20.1512, -18.6264, -18.2798, -19.3429, -20.6627, -17.6120, -18.7766,
        -15.9468, -16.5416])
Final projection likelihood: -18.7363
1 mode projection succeeded
New goal: tensor([ 0.0755,  0.5143,  0.6023,  0.6371, -0.1167,  0.5976,  0.8182,  0.7491,
         1.3394,  0.2259,  0.2341,  1.1397, -0.0282,  0.0374,  1.0120],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0089]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -22.775609970092773
Adjusted likelihood: -22.775609970092773
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.775609970092773}
Current yaw: tensor([-0.0205,  0.0565,  0.0565], device='cuda:1')
2 thumb_middle
tensor([ 0.1230,  0.4862,  0.6164,  0.7730, -0.2637,  0.6396,  0.8378,  0.6192,
         1.2593,  0.3279,  0.3241,  1.0807, -0.0205,  0.0565,  0.0565,  1.1188],
       device='cuda:1')
Solve time for step 1 9.248096834984608
Current ori: tensor([-0.0205,  0.0565,  0.0565], device='cuda:1')
Index force: tensor([0.5999, 0.5883, 0.5712, 0.6055], device='cuda:1')
tensor([ 0.1059,  0.5149,  0.6112,  0.6737, -0.2424,  0.6055,  0.8031,  0.7018,
         1.2862,  0.2235,  0.1847,  1.1001, -0.0317,  0.0672,  0.0564,  1.0347],
       device='cuda:1')
Solve time for step 2 2.0020659620058723
Current ori: tensor([-0.0317,  0.0672,  0.0564], device='cuda:1')
Index force: tensor([0.5842, 0.5684, 0.6028], device='cuda:1')
tensor([ 0.1080,  0.5383,  0.6030,  0.6308, -0.2380,  0.6139,  0.8008,  0.7187,
         1.3093,  0.2062,  0.1569,  1.1033, -0.0378,  0.0675,  0.0564,  0.9980],
       device='cuda:1')
Solve time for step 3 1.923661506996723
Current ori: tensor([-0.0378,  0.0675,  0.0564], device='cuda:1')
Index force: tensor([0.5650, 0.5999], device='cuda:1')
tensor([ 0.1134,  0.5416,  0.6046,  0.6296, -0.2381,  0.6166,  0.8012,  0.7252,
         1.3179,  0.2046,  0.1445,  1.1034, -0.0409,  0.0623,  0.0564,  1.0363],
       device='cuda:1')
Solve time for step 4 1.7914798659912776
Current ori: tensor([-0.0409,  0.0623,  0.0564], device='cuda:1')
Index force: tensor([0.5915], device='cuda:1')
Storing RECOVERY transition: reward=0.0214 (scaled=0.0071), steps=3
Reward stats updated: mean -0.0228 -> -0.0224, std: 0.1757
Collected 95 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.3104, Q2 Loss=0.3104, Entropy=0.3259, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0535
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.4144, Q2 Loss=0.4144, Entropy=0.0336, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0546
SAC Update 3/5: Actor Loss=-0.0025, Q1 Loss=0.3709, Q2 Loss=0.3709, Entropy=0.3163, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0584
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9905, Q2 Loss=0.9905, Entropy=0.1175, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8696
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.2669, Q2 Loss=0.2669, Entropy=0.2028, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0127

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000554
Q1 loss: 0.470639
Q2 loss: 0.470639
Current threshold: -29.8944
Global Scale Offset: 1.3285
Reward stats: mean=-0.0224, std=0.1757, count=95
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 0.4706, Q2 Loss: 0.4706, Entropy: 0.1992, Mean TD Error: 0.2098, Threshold: -29.8944
Original likelihood: -25.230144500732422
Adjusted likelihood: -25.230144500732422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9810)
Current yaw: tensor([-0.0446,  0.0507,  0.0342], device='cuda:1')
3 turn
Sampling time 3.740702572016744
tensor([ 0.1086,  0.5273,  0.6128,  0.6457, -0.1888,  0.6376,  0.8199,  0.7399,
         1.3766,  0.2279,  0.1787,  1.1211, -0.0446,  0.0507,  0.0342,  1.2117],
       device='cuda:1')
Original likelihood: -26.269283294677734
Adjusted likelihood: -26.269283294677734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9467)
Solve time for step 1 14.232651641999837
Current ori: tensor([-0.0446,  0.0507,  0.0342], device='cuda:1')
Middle force: tensor([0.5628, 0.5881, 0.5218, 0.5351, 0.5930, 1.3518, 0.5462, 0.5561, 0.5230,
        0.5439, 0.5272, 0.7262], device='cuda:1')
Thumb force: tensor([0.5948, 0.5738, 0.8458, 0.8802, 0.5824, 0.8760, 1.3477, 0.8393, 0.6300,
        1.0541, 0.6242, 1.1471], device='cuda:1')
Index force: tensor([0.6033, 0.5243, 0.5648, 0.5749, 0.5870, 0.5015, 0.6051, 0.5621, 0.6036,
        0.5663, 0.5731, 0.5209], device='cuda:1')
Storing NORMAL transition: reward=0.0634 (scaled=0.0634), steps=1
Reward stats updated: mean -0.0224 -> -0.0216, std: 0.1750
Collected 96 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.3716, Q2 Loss=0.3716, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0917
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.3017, Q2 Loss=0.3017, Entropy=0.3586, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0832
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.3391, Q2 Loss=0.3391, Entropy=0.4408, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0356
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.5890, Q2 Loss=0.5890, Entropy=0.3703, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7874
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.4074, Q2 Loss=0.4074, Entropy=0.2568, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0349

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000255
Q1 loss: 0.401753
Q2 loss: 0.401753
Current threshold: -29.8868
Global Scale Offset: 1.3212
Reward stats: mean=-0.0216, std=0.1750, count=96
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.4018, Q2 Loss: 0.4018, Entropy: 0.2853, Mean TD Error: 0.2066, Threshold: -29.8868
tensor([ 0.1246,  0.5137,  0.6221,  0.6951, -0.1807,  0.6042,  0.8605,  0.8261,
         1.3861,  0.2121,  0.1631,  1.0996, -0.0407,  0.0376, -0.0282,  1.3595],
       device='cuda:1')
Original likelihood: -22.855815887451172
Adjusted likelihood: -22.855815887451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9992)
Solve time for step 2 2.9047753229970112
Current ori: tensor([-0.0407,  0.0376, -0.0282], device='cuda:1')
Middle force: tensor([0.5817, 0.5194, 0.5344, 0.5896, 1.3393, 0.5443, 0.5526, 0.5218, 0.5413,
        0.5266, 0.7201], device='cuda:1')
Thumb force: tensor([0.5631, 0.8362, 0.8668, 0.5779, 0.8640, 1.3320, 0.8306, 0.6244, 1.0423,
        0.6159, 1.1402], device='cuda:1')
Index force: tensor([0.5224, 0.5628, 0.5726, 0.5833, 0.5011, 0.6029, 0.5605, 0.6010, 0.5638,
        0.5710, 0.5196], device='cuda:1')
Storing NORMAL transition: reward=-0.0003 (scaled=-0.0003), steps=1
Reward stats updated: mean -0.0216 -> -0.0213, std: 0.1741
Collected 97 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9376, Q2 Loss=0.9376, Entropy=0.1192, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8529
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1999, Q2 Loss=1.1999, Entropy=0.1086, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9258
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4843, Q2 Loss=0.4843, Entropy=0.1384, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7777
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.2523, Q2 Loss=0.2523, Entropy=0.2672, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0139
SAC Update 5/5: Actor Loss=-0.0039, Q1 Loss=0.3893, Q2 Loss=0.3893, Entropy=0.0622, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1504

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000841
Q1 loss: 0.652685
Q2 loss: 0.652685
Current threshold: -29.8740
Global Scale Offset: 1.3163
Reward stats: mean=-0.0213, std=0.1741, count=97
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.6527, Q2 Loss: 0.6527, Entropy: 0.1391, Mean TD Error: 0.5441, Threshold: -29.8740
tensor([ 0.1000,  0.5022,  0.5620,  0.8029, -0.2214,  0.5466,  0.9231,  0.7749,
         1.3256,  0.2533,  0.1940,  1.0762, -0.0278,  0.0511, -0.0282,  1.3657],
       device='cuda:1')
Original likelihood: -29.165691375732422
Adjusted likelihood: -29.165691375732422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6245)
Solve time for step 3 2.6084511960216332
Current ori: tensor([-0.0278,  0.0511, -0.0282], device='cuda:1')
Middle force: tensor([0.5171, 0.5354, 0.5888, 1.3254, 0.5433, 0.5494, 0.5209, 0.5390, 0.5258,
        0.7156], device='cuda:1')
Thumb force: tensor([0.8091, 0.8482, 0.5732, 0.8556, 1.3168, 0.8209, 0.6168, 1.0301, 0.6095,
        1.1308], device='cuda:1')
Index force: tensor([0.5663, 0.5770, 0.5865, 0.5007, 0.6004, 0.5589, 0.5998, 0.5617, 0.5691,
        0.5186], device='cuda:1')
Storing NORMAL transition: reward=0.1229 (scaled=0.1229), steps=1
Reward stats updated: mean -0.0213 -> -0.0199, std: 0.1738
Collected 98 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.3572, Q2 Loss=0.3572, Entropy=0.0307, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0971
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3179, Q2 Loss=0.3179, Entropy=0.0264, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0568
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.2348, Q2 Loss=0.2348, Entropy=0.6314, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0659
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.7002, Q2 Loss=0.7002, Entropy=0.1976, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8039
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3667, Q2 Loss=0.3667, Entropy=0.0281, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1093

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.7%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000100
Q1 loss: 0.395344
Q2 loss: 0.395344
Current threshold: -29.8476
Global Scale Offset: 1.2889
Reward stats: mean=-0.0199, std=0.1738, count=98
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.3953, Q2 Loss: 0.3953, Entropy: 0.1828, Mean TD Error: 0.2266, Threshold: -29.8476
tensor([ 0.0748,  0.4825,  0.5892,  0.7506, -0.2416,  0.5115,  0.9279,  0.9462,
         1.4162,  0.3469,  0.1533,  1.0172, -0.0261,  0.0693, -0.1556,  1.4527],
       device='cuda:1')
Original likelihood: -31.810470581054688
Adjusted likelihood: -31.810470581054688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.1859)
Solve time for step 4 2.487278143002186
Current ori: tensor([-0.0261,  0.0693, -0.1556], device='cuda:1')
Middle force: tensor([0.5334, 0.5866, 1.3068, 0.5427, 0.5452, 0.5199, 0.5370, 0.5263, 0.7031],
       device='cuda:1')
Thumb force: tensor([0.8343, 0.5688, 0.8436, 1.3041, 0.8196, 0.6198, 1.0242, 0.6013, 1.1472],
       device='cuda:1')
Index force: tensor([0.5774, 0.5880, 0.5006, 0.5977, 0.5560, 0.5912, 0.5583, 0.5666, 0.5156],
       device='cuda:1')
Storing NORMAL transition: reward=0.1672 (scaled=0.1672), steps=1
Reward stats updated: mean -0.0199 -> -0.0180, std: 0.1740
Collected 99 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.3151, Q2 Loss=0.3151, Entropy=0.2466, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1800
SAC Update 2/5: Actor Loss=-0.0029, Q1 Loss=0.3448, Q2 Loss=0.3448, Entropy=0.0444, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0679
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.3297, Q2 Loss=0.3297, Entropy=0.3419, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0508
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7326, Q2 Loss=0.7326, Entropy=0.1203, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8093
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.3341, Q2 Loss=0.3341, Entropy=0.3461, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0468

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.6%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000967
Q1 loss: 0.411244
Q2 loss: 0.411244
Current threshold: -29.8188
Global Scale Offset: 1.2499
Reward stats: mean=-0.0180, std=0.1740, count=99
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 0.4112, Q2 Loss: 0.4112, Entropy: 0.2199, Mean TD Error: 0.2309, Threshold: -29.8188
tensor([ 0.1475,  0.5466,  0.5919,  0.7102, -0.1777,  0.6077,  0.8105,  1.0355,
         1.4626,  0.2603,  0.0972,  0.9182, -0.0573,  0.0257, -0.3264,  1.8873],
       device='cuda:1')
Original likelihood: -26.110210418701172
Adjusted likelihood: -26.110210418701172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9578)
Solve time for step 5 2.3811338920204435
Current ori: tensor([-0.0573,  0.0257, -0.3264], device='cuda:1')
Middle force: tensor([0.5018, 0.7523, 0.6175, 0.6425, 0.6917, 1.9985, 0.6218, 0.5010],
       device='cuda:1')
Thumb force: tensor([0.5169, 0.6628, 1.4146, 0.8737, 0.6737, 1.3446, 1.4312, 0.5276],
       device='cuda:1')
Index force: tensor([0.6054, 0.6662, 0.9728, 0.5274, 0.6913, 0.9428, 0.7148, 0.6635],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0045 (scaled=-0.0045), steps=1
Reward stats updated: mean -0.0180 -> -0.0178, std: 0.1731
Collected 100 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=7.9262, Q2 Loss=7.9262, Entropy=0.1842, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.4541
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6220, Q2 Loss=0.6220, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4974
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=12.1489, Q2 Loss=12.1489, Entropy=0.0992, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9601
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=4.7610, Q2 Loss=4.7610, Entropy=0.0898, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.5263
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.2802, Q2 Loss=0.2802, Entropy=0.0275, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2099

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.7%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000016
Q1 loss: 5.147648
Q2 loss: 5.147648
Current threshold: -29.7989
Global Scale Offset: 1.2269
Reward stats: mean=-0.0178, std=0.1731, count=100
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.1476, Q2 Loss: 5.1476, Entropy: 0.0803, Mean TD Error: 2.9296, Threshold: -29.7989
tensor([ 0.1167,  0.5146,  0.5776,  0.7650, -0.2632,  0.6527,  0.9656,  1.0363,
         1.4314,  0.3430, -0.0187,  0.8755, -0.0536,  0.0178, -0.3194,  2.0827],
       device='cuda:1')
Original likelihood: -33.44108200073242
Adjusted likelihood: -33.44108200073242
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0430)
State is out of distribution
Projection step: 0, Loss: 30.947595596313477
Projection step: 1, Loss: 32.2514762878418
Projection step: 2, Loss: 30.388893127441406
Projection step: 3, Loss: 29.04608917236328
Projection step: 4, Loss: 26.93030548095703
Projection step: 5, Loss: 25.156301498413086
Projection step: 6, Loss: 22.88422393798828
Projection step: 7, Loss: 21.760156631469727
Projection step: 8, Loss: 21.45447540283203
Projection step: 9, Loss: 19.495370864868164
Projection step: 10, Loss: 19.00483512878418
Projection step: 11, Loss: 19.143735885620117
Projection step: 12, Loss: 17.077392578125
Projection step: 13, Loss: 16.339582443237305
Projection step: 14, Loss: 16.08873748779297
Final likelihood: tensor([-16.5163, -15.6969, -18.8512, -21.6795, -14.8475, -17.2337, -20.9239,
        -15.2461, -17.1839, -17.6378, -18.1103, -13.8977, -16.5737, -18.4025,
        -13.4329, -17.3726])
Final projection likelihood: -17.1004
1 mode projection succeeded
New goal: tensor([ 0.0897,  0.5308,  0.5202,  0.8165, -0.0689,  0.6306,  0.7459,  0.8997,
         1.4468,  0.2017,  0.1194,  0.9728, -0.0546,  0.0137,  0.3562],
       device='cuda:1')
tensor([[0.0147]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -18.768985748291016
Adjusted likelihood: -18.768985748291016
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.768985748291016}
Current yaw: tensor([-0.0536,  0.0178, -0.3194], device='cuda:1')
4 thumb_middle
tensor([ 0.1167,  0.5146,  0.5776,  0.7650, -0.2632,  0.6527,  0.9656,  1.0363,
         1.4314,  0.3430, -0.0187,  0.8755, -0.0536,  0.0178, -0.3194,  2.0827],
       device='cuda:1')
Solve time for step 1 8.473553666990483
Current ori: tensor([-0.0536,  0.0178, -0.3194], device='cuda:1')
Index force: tensor([0.5891, 0.5816, 0.5856, 0.5692], device='cuda:1')
tensor([ 0.1159,  0.5295,  0.5417,  0.7923, -0.2220,  0.6110,  0.7372,  0.9071,
         1.4036,  0.2030,  0.0267,  0.9344, -0.0547,  0.0217, -0.3182,  2.0350],
       device='cuda:1')
Solve time for step 2 1.8452514329983387
Current ori: tensor([-0.0547,  0.0217, -0.3182], device='cuda:1')
Index force: tensor([0.5754, 0.5801, 0.5645], device='cuda:1')
tensor([ 0.1171,  0.5290,  0.5290,  0.8227, -0.2075,  0.6208,  0.7096,  0.8840,
         1.4114,  0.1821,  0.0291,  0.9350, -0.0515,  0.0211, -0.3182,  2.0364],
       device='cuda:1')
Solve time for step 3 1.7591790120059159
Current ori: tensor([-0.0515,  0.0211, -0.3182], device='cuda:1')
Index force: tensor([0.5782, 0.5811], device='cuda:1')
tensor([ 0.1233,  0.5279,  0.5292,  0.8376, -0.2020,  0.6318,  0.6913,  0.8934,
         1.4123,  0.1631,  0.0249,  0.9476, -0.0497,  0.0172, -0.3182,  2.0468],
       device='cuda:1')
Solve time for step 4 1.6982581600022968
Current ori: tensor([-0.0497,  0.0172, -0.3182], device='cuda:1')
Index force: tensor([0.5703], device='cuda:1')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0003), steps=5
Reward stats updated: mean -0.0178 -> -0.0177, std: 0.1722
Collected 101 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.2517, Q2 Loss=0.2517, Entropy=0.4352, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1331
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=4.1831, Q2 Loss=4.1831, Entropy=0.0964, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.4495
SAC Update 3/5: Actor Loss=-0.0043, Q1 Loss=0.9949, Q2 Loss=0.9949, Entropy=0.0360, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7036
SAC Update 4/5: Actor Loss=-0.0026, Q1 Loss=1.1771, Q2 Loss=1.1771, Entropy=0.0395, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8345
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.5722, Q2 Loss=0.5722, Entropy=0.2546, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3561

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.8%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.1%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001557
Q1 loss: 1.435826
Q2 loss: 1.435826
Current threshold: -29.7615
Global Scale Offset: 1.1857
Reward stats: mean=-0.0177, std=0.1722, count=101
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 1.4358, Q2 Loss: 1.4358, Entropy: 0.1723, Mean TD Error: 1.2954, Threshold: -29.7615
Original likelihood: -20.657955169677734
Adjusted likelihood: -20.657955169677734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0528,  0.0239, -0.3215], device='cuda:1')
5 turn
Sampling time 3.9993086729955394
tensor([ 0.0814,  0.5234,  0.5088,  0.8097, -0.1503,  0.6684,  0.7385,  0.8810,
         1.4737,  0.1945,  0.0773,  0.9686, -0.0528,  0.0239, -0.3215,  2.1973],
       device='cuda:1')
Original likelihood: -19.568397521972656
Adjusted likelihood: -19.568397521972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.401201216998743
Current ori: tensor([-0.0528,  0.0239, -0.3215], device='cuda:1')
Middle force: tensor([0.5831, 2.1879, 0.5098, 0.5539, 0.5904, 0.5899, 0.5687, 0.5463, 0.6967,
        0.5884, 0.8037, 0.5768], device='cuda:1')
Thumb force: tensor([0.6110, 0.5869, 1.8072, 0.5086, 0.8952, 0.6032, 1.3433, 0.6206, 0.5204,
        0.5385, 0.5992, 0.6205], device='cuda:1')
Index force: tensor([0.6085, 1.2568, 0.5421, 0.6756, 0.5915, 0.6175, 0.5831, 0.6398, 0.5792,
        0.6026, 0.5301, 0.6305], device='cuda:1')
Storing NORMAL transition: reward=-0.0704 (scaled=-0.0704), steps=1
Reward stats updated: mean -0.0177 -> -0.0182, std: 0.1715
Collected 102 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.6709, Q2 Loss=0.6709, Entropy=0.3490, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5743
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0652, Q2 Loss=1.0652, Entropy=0.0853, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5466
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.3371, Q2 Loss=0.3371, Entropy=0.0315, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3614
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=20.2047, Q2 Loss=20.2047, Entropy=0.0803, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0049
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=0.4745, Q2 Loss=0.4745, Entropy=0.3912, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1229

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.9%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000366
Q1 loss: 4.550473
Q2 loss: 4.550473
Current threshold: -29.7156
Global Scale Offset: 1.1421
Reward stats: mean=-0.0182, std=0.1715, count=102
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 4.5505, Q2 Loss: 4.5505, Entropy: 0.1874, Mean TD Error: 1.3220, Threshold: -29.7156
tensor([ 0.0580,  0.4265,  0.5560,  0.9482, -0.1131,  0.6301,  0.7317,  0.8477,
         1.4357,  0.1223,  0.1082,  1.1207, -0.0131,  0.0228, -0.2485,  2.3633],
       device='cuda:1')
Original likelihood: -19.32400894165039
Adjusted likelihood: -19.32400894165039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.886396880989196
Current ori: tensor([-0.0131,  0.0228, -0.2485], device='cuda:1')
Middle force: tensor([2.1624, 0.5097, 0.5547, 0.5890, 0.5936, 0.5643, 0.5453, 0.6898, 0.5870,
        0.7942, 0.5753], device='cuda:1')
Thumb force: tensor([0.5829, 1.7776, 0.5074, 0.8866, 0.5914, 1.3322, 0.6096, 0.5195, 0.5356,
        0.5978, 0.6119], device='cuda:1')
Index force: tensor([1.2340, 0.5427, 0.6725, 0.5888, 0.6188, 0.5809, 0.6424, 0.5773, 0.6007,
        0.5293, 0.6327], device='cuda:1')
Storing NORMAL transition: reward=0.0139 (scaled=0.0139), steps=1
Reward stats updated: mean -0.0182 -> -0.0179, std: 0.1707
Collected 103 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.4765, Q2 Loss=0.4765, Entropy=0.2539, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4047
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3239, Q2 Loss=0.3239, Entropy=0.0791, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1970
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=13.3066, Q2 Loss=13.3066, Entropy=0.3219, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7325
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8452, Q2 Loss=0.8452, Entropy=0.0063, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7026
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=14.8317, Q2 Loss=14.8317, Entropy=0.0660, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8320

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000103
Q1 loss: 5.956774
Q2 loss: 5.956774
Current threshold: -29.6798
Global Scale Offset: 1.1200
Reward stats: mean=-0.0179, std=0.1707, count=103
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 5.9568, Q2 Loss: 5.9568, Entropy: 0.1454, Mean TD Error: 2.1738, Threshold: -29.6798
tensor([ 0.0128,  0.4355,  0.5427,  0.8727, -0.1197,  0.5687,  0.7475,  0.9459,
         1.3357,  0.2262,  0.2216,  1.0520, -0.0089,  0.0345, -0.2629,  3.0475],
       device='cuda:1')
Original likelihood: -22.534061431884766
Adjusted likelihood: -22.534061431884766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Solve time for step 3 2.7139424740162212
Current ori: tensor([-0.0089,  0.0345, -0.2629], device='cuda:1')
Middle force: tensor([0.5090, 0.5629, 0.5890, 0.6045, 0.5606, 0.5521, 0.6956, 0.5858, 0.7992,
        0.5752], device='cuda:1')
Thumb force: tensor([1.7504, 0.5057, 0.8783, 0.5758, 1.3182, 0.5888, 0.5161, 0.5333, 0.5850,
        0.6035], device='cuda:1')
Index force: tensor([0.5421, 0.6675, 0.5875, 0.6199, 0.5804, 0.6426, 0.5770, 0.5971, 0.5301,
        0.6341], device='cuda:1')
Storing NORMAL transition: reward=0.0398 (scaled=0.0398), steps=1
Reward stats updated: mean -0.0179 -> -0.0173, std: 0.1699
Collected 104 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4260, Q2 Loss=0.4260, Entropy=0.0008, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4002
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=2.6573, Q2 Loss=2.6573, Entropy=0.3877, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.5378
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5320, Q2 Loss=0.5320, Entropy=0.0469, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1328
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6961, Q2 Loss=0.6961, Entropy=0.0004, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5064
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=5.6604, Q2 Loss=5.6604, Entropy=0.0644, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6993

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000090
Q1 loss: 1.994376
Q2 loss: 1.994376
Current threshold: -29.6620
Global Scale Offset: 1.1091
Reward stats: mean=-0.0173, std=0.1699, count=104
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.9944, Q2 Loss: 1.9944, Entropy: 0.1000, Mean TD Error: 2.0553, Threshold: -29.6620
tensor([ 0.0329,  0.4288,  0.5763,  0.8513, -0.1558,  0.6017,  0.7459,  0.9070,
         1.4738,  0.0332,  0.2580,  0.8854, -0.0239,  0.0456, -0.3040,  2.2500],
       device='cuda:1')
Original likelihood: -27.00912857055664
Adjusted likelihood: -27.00912857055664
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9109)
Solve time for step 4 2.6359718379972037
Current ori: tensor([-0.0239,  0.0456, -0.3040], device='cuda:1')
Middle force: tensor([0.5578, 0.5891, 0.5922, 0.5581, 0.5426, 0.6898, 0.5832, 0.7918, 0.5717],
       device='cuda:1')
Thumb force: tensor([0.5054, 0.8697, 0.5839, 1.3028, 0.5978, 0.5160, 0.5321, 0.5896, 0.6020],
       device='cuda:1')
Index force: tensor([0.6671, 0.5930, 0.6173, 0.5818, 0.6404, 0.5720, 0.5943, 0.5269, 0.6339],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0047 (scaled=-0.0047), steps=1
Reward stats updated: mean -0.0173 -> -0.0172, std: 0.1691
Collected 105 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4465, Q2 Loss=0.4465, Entropy=0.0094, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6390
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.4947, Q2 Loss=0.4947, Entropy=0.2395, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2908
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=7.0423, Q2 Loss=7.0423, Entropy=0.4077, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6081
SAC Update 4/5: Actor Loss=-0.0034, Q1 Loss=0.5805, Q2 Loss=0.5805, Entropy=0.3675, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4171
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.2135, Q2 Loss=3.2135, Entropy=0.0686, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.5312

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000856
Q1 loss: 2.355508
Q2 loss: 2.355508
Current threshold: -29.6404
Global Scale Offset: 1.0953
Reward stats: mean=-0.0172, std=0.1691, count=105
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 2.3555, Q2 Loss: 2.3555, Entropy: 0.2186, Mean TD Error: 2.0972, Threshold: -29.6404
tensor([ 0.0901,  0.4991,  0.4966,  0.9198, -0.1611,  0.6384,  0.8093,  0.8589,
         1.4369,  0.0260,  0.2626,  0.8926, -0.0362,  0.0200, -0.2984,  2.0543],
       device='cuda:1')
Original likelihood: -24.54458999633789
Adjusted likelihood: -24.54458999633789
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9955)
Solve time for step 5 2.4568560569896363
Current ori: tensor([-0.0362,  0.0200, -0.2984], device='cuda:1')
Middle force: tensor([0.5877, 0.5837, 0.5551, 0.5365, 0.6840, 0.5806, 0.7877, 0.5689],
       device='cuda:1')
Thumb force: tensor([0.8612, 0.5875, 1.2914, 0.6032, 0.5155, 0.5307, 0.5895, 0.6014],
       device='cuda:1')
Index force: tensor([0.5916, 0.6173, 0.5809, 0.6389, 0.5701, 0.5913, 0.5251, 0.6313],
       device='cuda:1')
Storing NORMAL transition: reward=0.0226 (scaled=0.0226), steps=1
Reward stats updated: mean -0.0172 -> -0.0168, std: 0.1684
Collected 106 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9263, Q2 Loss=0.9263, Entropy=0.1530, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5560
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=2.1063, Q2 Loss=2.1063, Entropy=0.0148, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0709
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2625, Q2 Loss=1.2625, Entropy=0.0176, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2167
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=6.7186, Q2 Loss=6.7186, Entropy=0.4021, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6311
SAC Update 5/5: Actor Loss=-0.0021, Q1 Loss=1.1208, Q2 Loss=1.1208, Entropy=0.1932, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7468

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000571
Q1 loss: 2.426874
Q2 loss: 2.426874
Current threshold: -29.6085
Global Scale Offset: 1.0757
Reward stats: mean=-0.0168, std=0.1684, count=106
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 2.4269, Q2 Loss: 2.4269, Entropy: 0.1561, Mean TD Error: 1.6443, Threshold: -29.6085
tensor([ 0.0938,  0.4502,  0.6060,  0.8420, -0.1543,  0.6443,  0.7910,  0.9189,
         1.3181,  0.2155,  0.3179,  0.8706, -0.0323,  0.0142, -0.3207,  2.2032],
       device='cuda:1')
Original likelihood: -21.189117431640625
Adjusted likelihood: -21.189117431640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 2.3147391059901565
Current ori: tensor([-0.0323,  0.0142, -0.3207], device='cuda:1')
Middle force: tensor([0.5784, 0.5523, 0.5356, 0.6809, 0.5794, 0.7864, 0.5672],
       device='cuda:1')
Thumb force: tensor([0.5869, 1.2800, 0.5994, 0.5147, 0.5292, 0.5869, 0.5990],
       device='cuda:1')
Index force: tensor([0.6176, 0.5810, 0.6373, 0.5692, 0.5886, 0.5239, 0.6297],
       device='cuda:1')
Storing NORMAL transition: reward=0.0756 (scaled=0.0756), steps=1
Reward stats updated: mean -0.0168 -> -0.0160, std: 0.1678
Collected 107 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=4.9813, Q2 Loss=4.9813, Entropy=0.0640, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8414
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=38.7454, Q2 Loss=38.7454, Entropy=0.0537, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8362
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=13.4868, Q2 Loss=13.4868, Entropy=0.0680, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0106
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=4.5959, Q2 Loss=4.5959, Entropy=0.0543, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7439
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=20.5434, Q2 Loss=20.5434, Entropy=0.0661, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6295

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.3%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000012
Q1 loss: 16.470557
Q2 loss: 16.470557
Current threshold: -29.5768
Global Scale Offset: 1.0584
Reward stats: mean=-0.0160, std=0.1678, count=107
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 16.4706, Q2 Loss: 16.4706, Entropy: 0.0612, Mean TD Error: 5.0123, Threshold: -29.5768
tensor([ 0.1033,  0.4337,  0.6085,  0.9002, -0.1518,  0.6219,  0.8070,  0.9725,
         1.3841,  0.1114,  0.2846,  0.8585, -0.0221,  0.0094, -0.3957,  2.2682],
       device='cuda:1')
Original likelihood: -22.61855125427246
Adjusted likelihood: -22.61855125427246
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 7 2.327311692002695
Current ori: tensor([-0.0221,  0.0094, -0.3957], device='cuda:1')
Middle force: tensor([1.2893, 0.6809, 0.8125, 0.5291, 0.5215, 0.5512], device='cuda:1')
Thumb force: tensor([0.5441, 0.7032, 0.5481, 0.5145, 0.5849, 0.5612], device='cuda:1')
Index force: tensor([0.5351, 0.5248, 0.5313, 0.5592, 0.6010, 0.5571], device='cuda:1')
Storing NORMAL transition: reward=0.0780 (scaled=0.0780), steps=1
Reward stats updated: mean -0.0160 -> -0.0151, std: 0.1673
Collected 108 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.5679, Q2 Loss=0.5679, Entropy=0.2595, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5423
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=12.4538, Q2 Loss=12.4538, Entropy=0.0650, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0267
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=9.4843, Q2 Loss=9.4843, Entropy=0.3091, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8448
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4722, Q2 Loss=0.4722, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2967
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7660, Q2 Loss=0.7660, Entropy=0.0014, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3719

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.4%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.06s (20.1%)
Actor update: 0.12s (41.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000099
Q1 loss: 4.748851
Q2 loss: 4.748851
Current threshold: -29.5531
Global Scale Offset: 1.0516
Reward stats: mean=-0.0151, std=0.1673, count=108
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 4.7489, Q2 Loss: 4.7489, Entropy: 0.1270, Mean TD Error: 2.2165, Threshold: -29.5531
tensor([ 0.1095,  0.4156,  0.6174,  0.9466, -0.1499,  0.5987,  0.8288,  1.0355,
         1.3922,  0.0967,  0.2821,  0.8514, -0.0118,  0.0037, -0.4733,  2.4347],
       device='cuda:1')
Original likelihood: -21.98615837097168
Adjusted likelihood: -21.98615837097168
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 8 2.2078395550197456
Current ori: tensor([-0.0118,  0.0037, -0.4733], device='cuda:1')
Middle force: tensor([0.6694, 0.8041, 0.5271, 0.5238, 0.5502], device='cuda:1')
Thumb force: tensor([0.6947, 0.5450, 0.5130, 0.5748, 0.5575], device='cuda:1')
Index force: tensor([0.5230, 0.5294, 0.5566, 0.5946, 0.5545], device='cuda:1')
Storing NORMAL transition: reward=0.0229 (scaled=0.0229), steps=1
Reward stats updated: mean -0.0151 -> -0.0147, std: 0.1666
Collected 109 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9163, Q2 Loss=0.9163, Entropy=0.0050, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9579
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.4602, Q2 Loss=0.4602, Entropy=0.0041, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2283
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.4880, Q2 Loss=0.4880, Entropy=0.3422, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1242
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=4.0286, Q2 Loss=4.0286, Entropy=0.0477, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8843
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.4209, Q2 Loss=0.4209, Entropy=0.0026, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1672

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000035
Q1 loss: 1.262805
Q2 loss: 1.262805
Current threshold: -29.5368
Global Scale Offset: 1.0484
Reward stats: mean=-0.0147, std=0.1666, count=109
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2628, Q2 Loss: 1.2628, Entropy: 0.0803, Mean TD Error: 1.2724, Threshold: -29.5368
tensor([ 0.0737,  0.3986,  0.5535,  1.0431, -0.1120,  0.6063,  0.8234,  1.1147,
         1.3840,  0.0284,  0.3208,  0.7881,  0.0045, -0.0270, -0.4970,  2.8693],
       device='cuda:1')
Original likelihood: -22.37079620361328
Adjusted likelihood: -22.37079620361328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 9 2.1247786479943898
Current ori: tensor([ 0.0045, -0.0270, -0.4970], device='cuda:1')
Middle force: tensor([0.5630, 1.0611, 0.5528, 0.5020], device='cuda:1')
Thumb force: tensor([0.5006, 1.2859, 0.5416, 0.5599], device='cuda:1')
Index force: tensor([0.5916, 0.5264, 0.5350, 0.5594], device='cuda:1')
Storing NORMAL transition: reward=-0.0034 (scaled=-0.0034), steps=1
Reward stats updated: mean -0.0147 -> -0.0146, std: 0.1658
Collected 110 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7428, Q2 Loss=0.7428, Entropy=0.0073, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7122
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=0.4759, Q2 Loss=0.4759, Entropy=0.3464, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3156
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5786, Q2 Loss=0.5786, Entropy=0.0076, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3110
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.5435, Q2 Loss=0.5435, Entropy=0.3487, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6846
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5457, Q2 Loss=0.5457, Entropy=0.0098, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0688

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.6%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000295
Q1 loss: 0.577292
Q2 loss: 0.577292
Current threshold: -29.5356
Global Scale Offset: 1.0467
Reward stats: mean=-0.0146, std=0.1658, count=110
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.5773, Q2 Loss: 0.5773, Entropy: 0.1440, Mean TD Error: 0.4184, Threshold: -29.5356
tensor([ 7.5032e-02,  3.2158e-01,  6.3937e-01,  1.0602e+00, -1.0729e-01,
         5.5151e-01,  9.0828e-01,  1.2119e+00,  1.2516e+00, -5.8849e-04,
         3.2693e-01,  8.5151e-01,  5.3503e-02, -4.3559e-02, -4.9932e-01,
         3.1377e+00], device='cuda:1')
Original likelihood: -31.02983856201172
Adjusted likelihood: -31.02983856201172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2145)
State is out of distribution
Projection step: 0, Loss: 31.950477600097656
Projection step: 1, Loss: 30.597335815429688
Projection step: 2, Loss: 26.973217010498047
Projection step: 3, Loss: 26.709449768066406
Projection step: 4, Loss: 25.407073974609375
Projection step: 5, Loss: 23.635234832763672
Projection step: 6, Loss: 23.13979721069336
Projection step: 7, Loss: 23.293724060058594
Projection step: 8, Loss: 22.321338653564453
Projection step: 9, Loss: 21.457294464111328
Projection step: 10, Loss: 21.72982406616211
Projection step: 11, Loss: 20.735383987426758
Projection step: 12, Loss: 20.09845733642578
Projection step: 13, Loss: 21.077163696289062
Projection step: 14, Loss: 20.062564849853516
Final likelihood: tensor([-21.0990, -17.2132, -17.5122, -22.6660, -25.0046, -23.6436, -18.0624,
        -17.0831, -26.0280, -23.6572, -25.2392, -18.5541, -18.0785, -22.5619,
        -17.1380, -17.7401])
Final projection likelihood: -20.7051
1 mode projection succeeded
New goal: tensor([ 0.0399,  0.3926,  0.6053,  0.9771, -0.0331,  0.5333,  0.7906,  1.0441,
         1.3692,  0.0753,  0.2561,  0.8060,  0.0455, -0.0312, -1.2769],
       device='cuda:1')
tensor([[0.0127]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -20.428760528564453
Adjusted likelihood: -20.428760528564453
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.428760528564453}
Current yaw: tensor([ 0.0535, -0.0436, -0.4993], device='cuda:1')
6 thumb_middle
tensor([ 7.5032e-02,  3.2158e-01,  6.3937e-01,  1.0602e+00, -1.0729e-01,
         5.5151e-01,  9.0828e-01,  1.2119e+00,  1.2516e+00, -5.8849e-04,
         3.2693e-01,  8.5151e-01,  5.3503e-02, -4.3559e-02, -4.9932e-01,
         3.1377e+00], device='cuda:1')
Solve time for step 1 9.326904084009584
Current ori: tensor([ 0.0535, -0.0436, -0.4993], device='cuda:1')
Index force: tensor([0.6004, 0.5999, 0.5969, 0.6056], device='cuda:1')
tensor([ 0.0445,  0.3591,  0.6021,  0.9918, -0.1363,  0.5295,  0.7780,  1.0544,
         1.3256,  0.0433,  0.2304,  0.8054,  0.0455, -0.0359, -0.4993,  3.2048],
       device='cuda:1')
Solve time for step 2 2.027140188991325
Current ori: tensor([ 0.0455, -0.0359, -0.4993], device='cuda:1')
Index force: tensor([0.5947, 0.5940, 0.6007], device='cuda:1')
tensor([ 0.0429,  0.3752,  0.5931,  0.9663, -0.1334,  0.5563,  0.7686,  1.0266,
         1.3484,  0.0582,  0.2042,  0.7903,  0.0422, -0.0373, -0.4993,  3.2253],
       device='cuda:1')
Solve time for step 3 1.898067103989888
Current ori: tensor([ 0.0422, -0.0373, -0.4993], device='cuda:1')
Index force: tensor([0.5886, 0.5960], device='cuda:1')
tensor([ 0.0430,  0.3672,  0.6010,  0.9708, -0.1295,  0.5647,  0.7665,  1.0224,
         1.3564,  0.0557,  0.1971,  0.7943,  0.0448, -0.0371, -0.4993,  3.2267],
       device='cuda:1')
Solve time for step 4 1.8139266910147853
Current ori: tensor([ 0.0448, -0.0371, -0.4993], device='cuda:1')
Index force: tensor([0.5876], device='cuda:1')
Storing RECOVERY transition: reward=-0.0122 (scaled=-0.0014), steps=9
Reward stats updated: mean -0.0146 -> -0.0145, std: 0.1651
Collected 111 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=2.2354, Q2 Loss=2.2354, Entropy=0.2730, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1286
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9645, Q2 Loss=0.9645, Entropy=0.0003, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6248
SAC Update 3/5: Actor Loss=-0.0020, Q1 Loss=1.3865, Q2 Loss=1.3865, Entropy=0.1929, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0011
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.6415, Q2 Loss=0.6415, Entropy=0.3439, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0826
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.6956, Q2 Loss=2.6956, Entropy=0.0535, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6998

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000582
Q1 loss: 1.584699
Q2 loss: 1.584699
Current threshold: -29.5366
Global Scale Offset: 1.0403
Reward stats: mean=-0.0145, std=0.1651, count=111
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 1.5847, Q2 Loss: 1.5847, Entropy: 0.1727, Mean TD Error: 1.7074, Threshold: -29.5366
Original likelihood: -27.62156105041504
Adjusted likelihood: -27.62156105041504
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8457)
Current yaw: tensor([ 0.0498, -0.0230, -0.4845], device='cuda:1')
7 turn
Sampling time 4.009961616015062
tensor([ 0.0060,  0.3550,  0.5931,  0.9579, -0.0849,  0.6048,  0.8039,  1.0444,
         1.4237,  0.0838,  0.2758,  0.8423,  0.0498, -0.0230, -0.4845,  3.2241],
       device='cuda:1')
Original likelihood: -26.906089782714844
Adjusted likelihood: -26.906089782714844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9191)
Solve time for step 1 14.333972369000548
Current ori: tensor([ 0.0498, -0.0230, -0.4845], device='cuda:1')
Middle force: tensor([1.0394, 0.6463, 0.7097, 0.5182, 1.0315, 0.7044, 0.8846, 1.1713, 0.9611,
        0.6211, 0.5814, 0.5365], device='cuda:1')
Thumb force: tensor([0.6424, 0.5756, 0.5313, 0.4984, 0.5778, 1.2696, 1.2366, 0.5631, 0.5628,
        0.5371, 0.6206, 0.5893], device='cuda:1')
Index force: tensor([0.9795, 0.5499, 0.6126, 0.6176, 0.7621, 0.5271, 0.7258, 0.5316, 0.5162,
        0.5496, 0.5880, 0.6423], device='cuda:1')
Storing NORMAL transition: reward=0.0907 (scaled=0.0907), steps=1
Reward stats updated: mean -0.0145 -> -0.0136, std: 0.1646
Collected 112 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.8565, Q2 Loss=0.8565, Entropy=0.2249, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4935
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=1.0081, Q2 Loss=1.0081, Entropy=0.1765, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8005
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7212, Q2 Loss=0.7212, Entropy=0.1448, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7570
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7814, Q2 Loss=0.7814, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4015
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.1047, Q2 Loss=1.1047, Entropy=0.2283, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4578

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (18.5%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000369
Q1 loss: 0.894368
Q2 loss: 0.894368
Current threshold: -29.5315
Global Scale Offset: 1.0295
Reward stats: mean=-0.0136, std=0.1646, count=112
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.8944, Q2 Loss: 0.8944, Entropy: 0.1549, Mean TD Error: 0.7821, Threshold: -29.5315
tensor([-0.0036,  0.3292,  0.6609,  0.8844, -0.2012,  0.6402,  0.8875,  1.0691,
         1.3703,  0.2768,  0.2956,  0.8159,  0.0524, -0.0119, -0.5756,  3.3612],
       device='cuda:1')
Original likelihood: -32.378135681152344
Adjusted likelihood: -32.378135681152344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0636)
State is out of distribution
Projection step: 0, Loss: 32.543155670166016
Projection step: 1, Loss: 29.560583114624023
Projection step: 2, Loss: 28.960765838623047
Projection step: 3, Loss: 26.916709899902344
Projection step: 4, Loss: 25.878215789794922
Projection step: 5, Loss: 23.03164291381836
Projection step: 6, Loss: 23.02325439453125
Projection step: 7, Loss: 21.941499710083008
Projection step: 8, Loss: 20.59259033203125
Projection step: 9, Loss: 21.241504669189453
Projection step: 10, Loss: 20.19687271118164
Projection step: 11, Loss: 19.11502456665039
Projection step: 12, Loss: 18.260906219482422
Projection step: 13, Loss: 18.50098419189453
Projection step: 14, Loss: 17.500530242919922
Final likelihood: tensor([-16.8523, -19.2197, -16.2816, -14.2495, -17.5379, -16.2799, -16.2615,
        -19.6580, -18.2359, -16.3635, -14.7893, -17.2771, -17.8564, -19.6660,
        -19.5556, -16.5063])
Final projection likelihood: -17.2869
1 mode projection succeeded
New goal: tensor([ 0.0081,  0.4259,  0.5773,  0.8993, -0.0752,  0.5306,  0.7862,  0.9765,
         1.3049,  0.1737,  0.2299,  0.9156,  0.0402, -0.0113, -1.5280],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -20.854307174682617
Adjusted likelihood: -20.854307174682617
Likelihood residual: 0.0
Original likelihood: -31.089069366455078
Adjusted likelihood: -31.089069366455078
Likelihood residual: 0.0
{'index': 31.089069366455078, 'thumb_middle': 20.854307174682617}
Current yaw: tensor([ 0.0524, -0.0119, -0.5756], device='cuda:1')
8 thumb_middle
tensor([-0.0036,  0.3292,  0.6609,  0.8844, -0.2012,  0.6402,  0.8875,  1.0691,
         1.3703,  0.2768,  0.2956,  0.8159,  0.0524, -0.0119, -0.5756,  3.3612],
       device='cuda:1')
Solve time for step 1 9.642045991000487
Current ori: tensor([ 0.0524, -0.0119, -0.5756], device='cuda:1')
Index force: tensor([0.5840, 0.5946, 0.6068, 0.6011], device='cuda:1')
tensor([ 8.4655e-04,  3.7766e-01,  6.0207e-01,  8.8122e-01, -1.6129e-01,
         5.5904e-01,  7.7077e-01,  9.6637e-01,  1.2882e+00,  1.9045e-01,
         2.1044e-01,  8.8910e-01,  4.8981e-02, -1.6180e-02, -5.7557e-01,
         3.4005e+00], device='cuda:1')
Solve time for step 2 1.9425447340181563
Current ori: tensor([ 0.0490, -0.0162, -0.5756], device='cuda:1')
Index force: tensor([0.5885, 0.6023, 0.5956], device='cuda:1')
tensor([ 0.0123,  0.3905,  0.5799,  0.9074, -0.1432,  0.5684,  0.7733,  0.9540,
         1.2922,  0.1717,  0.1947,  0.9045,  0.0492, -0.0215, -0.5756,  3.4183],
       device='cuda:1')
Solve time for step 3 1.9004672210139688
Current ori: tensor([ 0.0492, -0.0215, -0.5756], device='cuda:1')
Index force: tensor([0.5959, 0.5900], device='cuda:1')
tensor([-0.0056,  0.4079,  0.5505,  0.8876, -0.1498,  0.5699,  0.7534,  0.9457,
         1.3106,  0.1650,  0.1951,  0.8918,  0.0653, -0.0153, -0.5756,  3.6302],
       device='cuda:1')
Solve time for step 4 1.918521817016881
Current ori: tensor([ 0.0653, -0.0153, -0.5756], device='cuda:1')
Index force: tensor([0.5778], device='cuda:1')
Storing RECOVERY transition: reward=-0.0240 (scaled=-0.0240), steps=1
Reward stats updated: mean -0.0136 -> -0.0137, std: 0.1639
Collected 113 transitions for RL
SAC Update 1/5: Actor Loss=-0.0008, Q1 Loss=1.1018, Q2 Loss=1.1018, Entropy=0.3557, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2135
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.8089, Q2 Loss=0.8089, Entropy=0.3413, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7065
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5060, Q2 Loss=0.5060, Entropy=0.0020, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1899
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=8.1298, Q2 Loss=8.1298, Entropy=0.3039, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9539
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6295, Q2 Loss=0.6295, Entropy=0.1238, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3559

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (17.3%)
Actor update: 0.11s (40.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000318
Q1 loss: 2.235208
Q2 loss: 2.235208
Current threshold: -29.5303
Global Scale Offset: 1.0242
Reward stats: mean=-0.0137, std=0.1639, count=113
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 2.2352, Q2 Loss: 2.2352, Entropy: 0.2253, Mean TD Error: 1.4839, Threshold: -29.5303
Original likelihood: -29.80963897705078
Adjusted likelihood: -29.80963897705078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4403)
Current yaw: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:1')
9 turn
Sampling time 3.7080182019853964
tensor([-0.0423,  0.3884,  0.5474,  0.8876, -0.0652,  0.6050,  0.7792,  0.9438,
         1.3720,  0.1884,  0.2644,  0.9729,  0.0711, -0.0050, -0.5538,  3.5317],
       device='cuda:1')
Original likelihood: -31.179811477661133
Adjusted likelihood: -31.179811477661133
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1875)
State is out of distribution
Projection step: 0, Loss: 31.705272674560547
Projection step: 1, Loss: 27.466955184936523
Projection step: 2, Loss: 27.20793914794922
Projection step: 3, Loss: 25.099300384521484
Projection step: 4, Loss: 24.665884017944336
Projection step: 5, Loss: 23.266925811767578
Projection step: 6, Loss: 22.266277313232422
Projection step: 7, Loss: 21.909976959228516
Projection step: 8, Loss: 21.527462005615234
Projection step: 9, Loss: 21.612689971923828
Projection step: 10, Loss: 20.81258201599121
Projection step: 11, Loss: 20.756513595581055
Projection step: 12, Loss: 20.26268768310547
Projection step: 13, Loss: 20.381927490234375
Projection step: 14, Loss: 19.684803009033203
Final likelihood: tensor([-21.8171, -21.4760, -20.2846, -22.1918, -19.2524, -19.3489, -21.8207,
        -15.6613, -21.5972, -16.0477, -21.8461, -14.5737, -19.4084, -21.3888,
        -21.0513, -19.2699])
Final projection likelihood: -19.8147
1 mode projection succeeded
New goal: tensor([ 0.0211,  0.4459,  0.5475,  0.8511, -0.0584,  0.5188,  0.7992,  0.9335,
         1.3252,  0.1694,  0.2247,  1.1007,  0.0555, -0.0125, -1.8538],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -24.169052124023438
Adjusted likelihood: -24.169052124023438
Likelihood residual: 0.0
Original likelihood: -31.08992576599121
Adjusted likelihood: -31.08992576599121
Likelihood residual: 0.0
{'index': 31.08992576599121, 'thumb_middle': 24.169052124023438}
Current yaw: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:1')
10 thumb_middle
tensor([-0.0423,  0.3884,  0.5474,  0.8876, -0.0652,  0.6050,  0.7792,  0.9438,
         1.3720,  0.1884,  0.2644,  0.9729,  0.0711, -0.0050, -0.5538,  3.5317],
       device='cuda:1')
Solve time for step 1 8.881723009981215
Current ori: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:1')
Index force: tensor([0.5879, 0.5909, 0.5976, 0.5889], device='cuda:1')
tensor([-0.0390,  0.4147,  0.5365,  0.8370, -0.1405,  0.5480,  0.7614,  0.9101,
         1.2859,  0.1414,  0.1663,  1.0517,  0.1160,  0.0219, -0.5538,  4.1038],
       device='cuda:1')
Solve time for step 2 1.9899990929989144
Current ori: tensor([ 0.1160,  0.0219, -0.5538], device='cuda:1')
Index force: tensor([0.5864, 0.5935, 0.5857], device='cuda:1')
tensor([-0.0219,  0.4217,  0.5392,  0.8393, -0.1497,  0.5530,  0.7635,  0.9041,
         1.3009,  0.1500,  0.1658,  1.0810,  0.1302,  0.0666, -0.5538,  4.7209],
       device='cuda:1')
Solve time for step 3 1.8994016259966884
Current ori: tensor([ 0.1302,  0.0666, -0.5538], device='cuda:1')
Index force: tensor([0.5904, 0.5803], device='cuda:1')
tensor([-0.0109,  0.4324,  0.5355,  0.8361, -0.1937,  0.5315,  0.7471,  0.8910,
         1.3275,  0.1578,  0.1950,  1.1010,  0.1354,  0.1016, -0.5537,  5.0581],
       device='cuda:1')
Solve time for step 4 1.7058935319946613
Current ori: tensor([ 0.1354,  0.1016, -0.5537], device='cuda:1')
Index force: tensor([0.5897], device='cuda:1')
Storing RECOVERY transition: reward=-0.0503 (scaled=-0.0503), steps=0
Reward stats updated: mean -0.0137 -> -0.0140, std: 0.1632
Collected 114 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4325, Q2 Loss=0.4325, Entropy=0.2476, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1684
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6755, Q2 Loss=0.6755, Entropy=0.0611, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1547
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9335, Q2 Loss=0.9335, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5263
SAC Update 4/5: Actor Loss=-0.0014, Q1 Loss=0.5213, Q2 Loss=0.5213, Entropy=0.0150, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3515
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6653, Q2 Loss=0.6653, Entropy=0.0267, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4715

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.06s (19.8%)
Actor update: 0.11s (38.9%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000298
Q1 loss: 0.645650
Q2 loss: 0.645650
Current threshold: -29.5244
Global Scale Offset: 1.0184
Reward stats: mean=-0.0140, std=0.1632, count=114
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.6457, Q2 Loss: 0.6457, Entropy: 0.0701, Mean TD Error: 0.5345, Threshold: -29.5244
Original likelihood: -14.584827423095703
Adjusted likelihood: -14.584827423095703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.1446,  0.0701, -0.5214], device='cuda:1')
11 turn
Sampling time 3.7196869970066473
tensor([-1.1657e-03,  4.4718e-01,  5.3040e-01,  8.2734e-01, -1.3575e-01,
         5.5642e-01,  7.7600e-01,  9.0432e-01,  1.4128e+00,  1.9317e-01,
         2.9409e-01,  1.1532e+00,  1.4464e-01,  7.0098e-02, -5.2144e-01,
         4.5785e+00], device='cuda:1')
Original likelihood: -23.137542724609375
Adjusted likelihood: -23.137542724609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 1 14.932876887003658
Current ori: tensor([ 0.1446,  0.0701, -0.5214], device='cuda:1')
Middle force: tensor([0.7922, 1.2294, 0.8746, 1.3565, 0.6182, 0.5419, 0.5430, 0.7769, 0.5528,
        0.6007, 1.2996, 1.1684], device='cuda:1')
Thumb force: tensor([0.6962, 3.4091, 1.1300, 1.9742, 0.5874, 0.8296, 1.4691, 0.6183, 0.5598,
        1.2851, 1.4392, 1.0633], device='cuda:1')
Index force: tensor([0.8885, 0.7810, 0.9690, 0.7112, 0.5262, 0.5632, 0.5845, 0.7229, 0.5717,
        0.5572, 0.5435, 0.5648], device='cuda:1')
Storing NORMAL transition: reward=-0.0048 (scaled=-0.0048), steps=1
Reward stats updated: mean -0.0140 -> -0.0139, std: 0.1625
Collected 115 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5112, Q2 Loss=0.5112, Entropy=0.0031, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2205
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.9911, Q2 Loss=0.9911, Entropy=0.2397, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0908
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.7294, Q2 Loss=0.7294, Entropy=0.1707, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6412
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.6445, Q2 Loss=0.6445, Entropy=0.3462, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3220
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9745, Q2 Loss=0.9745, Entropy=0.0057, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5560

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.5%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.05s (18.5%)
Actor update: 0.12s (42.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000359
Q1 loss: 0.770138
Q2 loss: 0.770138
Current threshold: -29.5188
Global Scale Offset: 1.0085
Reward stats: mean=-0.0139, std=0.1625, count=115
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.7701, Q2 Loss: 0.7701, Entropy: 0.1531, Mean TD Error: 0.5661, Threshold: -29.5188
tensor([ 0.0427,  0.5127,  0.4851,  0.8418, -0.0223,  0.5205,  0.7992,  1.0954,
         1.4768,  0.1367,  0.2442,  1.1414,  0.2099,  0.0383, -0.5353,  3.8431],
       device='cuda:1')
Original likelihood: -34.505332946777344
Adjusted likelihood: -34.505332946777344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0033)
State is out of distribution
Projection step: 0, Loss: 35.135894775390625
Projection step: 1, Loss: 32.15284729003906
Projection step: 2, Loss: 32.802268981933594
Projection step: 3, Loss: 32.06580352783203
Projection step: 4, Loss: 31.751930236816406
Projection step: 5, Loss: 29.941471099853516
Projection step: 6, Loss: 31.04615020751953
Projection step: 7, Loss: 29.16326141357422
Projection step: 8, Loss: 29.71560287475586
Projection step: 9, Loss: 29.672348022460938
Projection step: 10, Loss: 29.42508316040039
Projection step: 11, Loss: 30.00337791442871
Projection step: 12, Loss: 27.68798828125
Projection step: 13, Loss: 28.23143768310547
Projection step: 14, Loss: 27.851055145263672
Final likelihood: tensor([-30.7495, -31.2438, -24.7368, -26.8312, -24.9281, -25.2628, -29.7284,
        -24.1983, -33.7134, -24.5792, -27.2442, -34.1433, -21.2332, -22.2374,
        -32.0631, -30.7410])
Final projection likelihood: -27.7271
1 mode projection succeeded
New goal: tensor([ 0.0560,  0.4649,  0.5522,  0.8668, -0.0610,  0.4607,  0.8269,  1.1461,
         1.4791,  0.1168,  0.2702,  1.0190,  0.1980,  0.0420,  0.4685],
       device='cuda:1')
tensor([[0.0061]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -36.98125457763672
Adjusted likelihood: -36.98125457763672
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 36.98125457763672}
Current yaw: tensor([ 0.2099,  0.0383, -0.5353], device='cuda:1')
12 thumb_middle
tensor([ 0.0427,  0.5127,  0.4851,  0.8418, -0.0223,  0.5205,  0.7992,  1.0954,
         1.4768,  0.1367,  0.2442,  1.1414,  0.2099,  0.0383, -0.5353,  3.8431],
       device='cuda:1')
Solve time for step 1 9.574897518003127
Current ori: tensor([ 0.2099,  0.0383, -0.5353], device='cuda:1')
Index force: tensor([0.5698, 0.6077, 0.5320, 0.5165], device='cuda:1')
tensor([ 0.0394,  0.4781,  0.5266,  1.0715, -0.1680,  0.4592,  0.7695,  1.0846,
         1.4608,  0.1177,  0.2304,  1.0381,  0.2573,  0.0748, -0.5353,  3.2584],
       device='cuda:1')
Solve time for step 2 1.9750209930061828
Current ori: tensor([ 0.2573,  0.0748, -0.5353], device='cuda:1')
Index force: tensor([0.6027, 0.5288, 0.5158], device='cuda:1')
tensor([ 0.0443,  0.4851,  0.6445,  1.0625, -0.1965,  0.4287,  0.7759,  1.1156,
         1.4882,  0.1016,  0.2445,  1.0408,  0.2773,  0.0918, -0.5446,  3.0640],
       device='cuda:1')
Solve time for step 3 1.8910660289984662
Current ori: tensor([ 0.2773,  0.0918, -0.5446], device='cuda:1')
Index force: tensor([0.5123, 0.5064], device='cuda:1')
tensor([ 0.0347,  0.4977,  0.7527,  1.1328, -0.2099,  0.4071,  0.8171,  1.1480,
         1.5000,  0.1140,  0.2624,  1.0521,  0.2783,  0.0936, -0.5644,  3.2272],
       device='cuda:1')
Solve time for step 4 1.8238049240026157
Current ori: tensor([ 0.2783,  0.0936, -0.5644], device='cuda:1')
Index force: tensor([0.5056], device='cuda:1')
Storing RECOVERY transition: reward=-0.0092 (scaled=-0.0092), steps=1
Reward stats updated: mean -0.0139 -> -0.0139, std: 0.1618
Collected 116 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9803, Q2 Loss=0.9803, Entropy=0.0128, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1892
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.5816, Q2 Loss=0.5816, Entropy=0.2703, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2913
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8720, Q2 Loss=0.8720, Entropy=0.0023, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7159
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.9728, Q2 Loss=0.9728, Entropy=0.2592, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5532
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7203, Q2 Loss=0.7203, Entropy=0.0025, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1496

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (17.9%)
Actor update: 0.11s (40.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000096
Q1 loss: 0.825413
Q2 loss: 0.825413
Current threshold: -29.5133
Global Scale Offset: 1.0035
Reward stats: mean=-0.0139, std=0.1618, count=116
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.8254, Q2 Loss: 0.8254, Entropy: 0.1094, Mean TD Error: 0.5798, Threshold: -29.5133
Original likelihood: -65.99370574951172
Adjusted likelihood: -65.99370574951172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 70.69413757324219
Projection step: 1, Loss: 71.3258285522461
Projection step: 2, Loss: 67.35197448730469
Projection step: 3, Loss: 64.05184936523438
Projection step: 4, Loss: 64.01667022705078
Projection step: 5, Loss: 66.59686279296875
Projection step: 6, Loss: 63.62362289428711
Projection step: 7, Loss: 61.750732421875
Projection step: 8, Loss: 64.64228057861328
Projection step: 9, Loss: 61.54415512084961
Projection step: 10, Loss: 61.21806335449219
Projection step: 11, Loss: 57.31605529785156
Projection step: 12, Loss: 62.810359954833984
Projection step: 13, Loss: 57.780181884765625
Projection step: 14, Loss: 58.195648193359375
Final likelihood: tensor([-60.6524, -66.7190, -58.8270, -62.3143, -58.3210, -56.0940, -59.6372,
        -68.0002, -47.7047, -43.3027, -56.0876, -58.8703, -55.8331, -44.2732,
        -50.3054, -49.0339])
Final projection likelihood: -55.9985
1 mode projection failed, trying anyway
New goal: tensor([ 0.0787,  0.3824,  0.7075,  1.0521, -0.0847,  0.4121,  0.8424,  1.1042,
         1.4479,  0.0771,  0.3830,  0.8703,  0.2476,  0.0708,  0.1435],
       device='cuda:1')
tensor([[0.0063]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0003]], device='cuda:1')
Original likelihood: -72.78695678710938
Adjusted likelihood: -72.78695678710938
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 72.78695678710938}
Current yaw: tensor([ 0.2583,  0.0700, -0.5512], device='cuda:1')
13 thumb_middle
tensor([ 0.0783,  0.5103,  0.7116,  1.0551, -0.1017,  0.4402,  0.8522,  1.1241,
         1.5000,  0.1599,  0.3401,  1.0967,  0.2583,  0.0700, -0.5512,  3.2296],
       device='cuda:1')
Solve time for step 1 9.190479165001307
Current ori: tensor([ 0.2583,  0.0700, -0.5512], device='cuda:1')
Index force: tensor([0.5932, 0.5741, 0.5718, 0.5951], device='cuda:1')
tensor([ 0.0662,  0.5023,  0.7101,  1.3544, -0.2261,  0.2038,  0.8357,  1.1339,
         1.4458,  0.0624,  0.3985,  0.9952,  0.2748,  0.0892, -0.5921,  3.3147],
       device='cuda:1')
Solve time for step 2 1.9727621460042428
Current ori: tensor([ 0.2748,  0.0892, -0.5921], device='cuda:1')
Index force: tensor([0.5707, 0.5665, 0.5916], device='cuda:1')
tensor([ 0.0575,  0.4881,  0.8175,  1.3018, -0.2177,  0.2064,  0.8501,  1.1402,
         1.4561,  0.0734,  0.4262,  0.9575,  0.2931,  0.1064, -0.5994,  1.4630],
       device='cuda:1')
Solve time for step 3 1.8843280439905357
Current ori: tensor([ 0.2931,  0.1064, -0.5994], device='cuda:1')
Index force: tensor([0.5601, 0.5419], device='cuda:1')
tensor([ 0.0720,  0.4838,  0.8549,  1.3684, -0.1962,  0.2199,  0.8346,  1.1285,
         1.4862,  0.0899,  0.4259,  0.9348,  0.2905,  0.1040, -0.5931,  1.4508],
       device='cuda:1')
Solve time for step 4 1.8302763529936783
Current ori: tensor([ 0.2905,  0.1040, -0.5931], device='cuda:1')
Index force: tensor([0.5365], device='cuda:1')
Storing RECOVERY transition: reward=-0.0433 (scaled=-0.0433), steps=1
Reward stats updated: mean -0.0139 -> -0.0141, std: 0.1611
Collected 117 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7443, Q2 Loss=0.7443, Entropy=0.0128, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3768
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=2.2657, Q2 Loss=2.2657, Entropy=0.0210, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2065
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7417, Q2 Loss=0.7417, Entropy=0.0127, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5747
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=8.1044, Q2 Loss=8.1044, Entropy=0.0404, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0449
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=0.8688, Q2 Loss=0.8688, Entropy=0.3463, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7575

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000114
Q1 loss: 2.544990
Q2 loss: 2.544990
Current threshold: -29.5063
Global Scale Offset: 1.0021
Reward stats: mean=-0.0141, std=0.1611, count=117
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.5450, Q2 Loss: 2.5450, Entropy: 0.0867, Mean TD Error: 1.5921, Threshold: -29.5063
Original likelihood: -87.33621215820312
Adjusted likelihood: -87.33621215820312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 90.28713989257812
Projection step: 1, Loss: 85.83444213867188
Projection step: 2, Loss: 78.69992065429688
Projection step: 3, Loss: 84.14848327636719
Projection step: 4, Loss: 87.04833221435547
Projection step: 5, Loss: 77.72960662841797
Projection step: 6, Loss: 87.83259582519531
Projection step: 7, Loss: 80.4742660522461
Projection step: 8, Loss: 79.84191131591797
Projection step: 9, Loss: 77.86969757080078
Projection step: 10, Loss: 83.38493347167969
Projection step: 11, Loss: 81.62541961669922
Projection step: 12, Loss: 78.99092102050781
Projection step: 13, Loss: 81.49510192871094
Projection step: 14, Loss: 74.82062530517578
Final likelihood: tensor([-90.0373, -80.0009, -84.3739, -64.1176, -65.0035, -69.3503, -92.1647,
        -70.5570, -89.4682, -64.7109, -65.7598, -99.5196, -94.9152, -82.9506,
        -61.5822, -74.3472])
Final projection likelihood: -78.0537
1 mode projection failed, trying anyway
New goal: tensor([ 0.0970,  0.3995,  0.7326,  1.1974, -0.0999,  0.3608,  0.9441,  1.1344,
         1.3954,  0.1374,  0.5990,  0.8623,  0.2709,  0.0998,  0.1284],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[-6.4283e-05]], device='cuda:1')
Original likelihood: -86.00855255126953
Adjusted likelihood: -86.00855255126953
Likelihood residual: 0.0
Original likelihood: -70.04255676269531
Adjusted likelihood: -70.04255676269531
Likelihood residual: 0.0
{'index': 70.04255676269531, 'thumb_middle': 86.00855255126953}
Current yaw: tensor([ 0.2779,  0.0926, -0.5262], device='cuda:1')
14 index
tensor([ 0.0798,  0.4956,  0.8003,  1.1774, -0.1253,  0.2790,  0.8066,  1.0923,
         1.5000,  0.1196,  0.5458,  0.9738,  0.2779,  0.0926, -0.5262,  0.9892],
       device='cuda:1')
Solve time for step 1 9.751187392015709
Current ori: tensor([ 0.2779,  0.0926, -0.5262], device='cuda:1')
Middle force: tensor([0.5579, 0.6108, 0.5449, 0.6005], device='cuda:1')
Thumb force: tensor([0.5873, 0.5981, 0.5222, 0.5971], device='cuda:1')
tensor([ 0.0680,  0.2015,  0.7421,  1.1715, -0.1061,  0.3124,  0.7352,  1.1403,
         1.4630,  0.1706,  0.5833,  0.8838,  0.2652,  0.0923, -0.5680, -0.3296],
       device='cuda:1')
Solve time for step 2 2.2707904939888977
Current ori: tensor([ 0.2652,  0.0923, -0.5680], device='cuda:1')
Middle force: tensor([0.6074, 0.5435, 0.5974], device='cuda:1')
Thumb force: tensor([0.5930, 0.5209, 0.5953], device='cuda:1')
tensor([ 0.0586,  0.0827,  0.7056,  1.1472, -0.1073,  0.2954,  0.7849,  1.1325,
         1.4612,  0.1772,  0.5949,  0.8587,  0.2650,  0.0924, -0.6003, -1.1466],
       device='cuda:1')
Solve time for step 3 2.2112787279766053
Current ori: tensor([ 0.2650,  0.0924, -0.6003], device='cuda:1')
Middle force: tensor([0.5414, 0.5950], device='cuda:1')
Thumb force: tensor([0.5193, 0.5946], device='cuda:1')
tensor([ 0.1066,  0.1694,  0.7048,  1.1445, -0.0872,  0.3360,  0.7138,  1.1351,
         1.4658,  0.1644,  0.5773,  0.8738,  0.2596,  0.0887, -0.5743, -0.7474],
       device='cuda:1')
Solve time for step 4 2.1382675920031033
Current ori: tensor([ 0.2596,  0.0887, -0.5743], device='cuda:1')
Middle force: tensor([0.5902], device='cuda:1')
Thumb force: tensor([0.5871], device='cuda:1')
Storing RECOVERY transition: reward=0.0008 (scaled=0.0008), steps=1
Reward stats updated: mean -0.0141 -> -0.0140, std: 0.1604
Collected 118 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.6556, Q2 Loss=0.6556, Entropy=0.3471, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2885
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=62.2718, Q2 Loss=62.2718, Entropy=0.0796, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.5590
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.2412, Q2 Loss=2.2412, Entropy=0.0207, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1673
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.8747, Q2 Loss=1.8747, Entropy=0.0452, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7818
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6138, Q2 Loss=0.6138, Entropy=0.0106, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4599

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.4%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (43.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000138
Q1 loss: 13.531408
Q2 loss: 13.531408
Current threshold: -29.5052
Global Scale Offset: 1.0030
Reward stats: mean=-0.0140, std=0.1604, count=118
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 13.5314, Q2 Loss: 13.5314, Entropy: 0.1006, Mean TD Error: 3.2513, Threshold: -29.5052
Original likelihood: -63.83238983154297
Adjusted likelihood: -63.83238983154297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 71.43931579589844
Projection step: 1, Loss: 67.08299255371094
Projection step: 2, Loss: 63.95230484008789
Projection step: 3, Loss: 66.51763153076172
Projection step: 4, Loss: 64.95880889892578
Projection step: 5, Loss: 65.32156372070312
Projection step: 6, Loss: 65.81878662109375
Projection step: 7, Loss: 60.449424743652344
Projection step: 8, Loss: 59.772666931152344
Projection step: 9, Loss: 58.13189697265625
Projection step: 10, Loss: 61.43025588989258
Projection step: 11, Loss: 60.260841369628906
Projection step: 12, Loss: 57.4674072265625
Projection step: 13, Loss: 58.29674530029297
Projection step: 14, Loss: 57.28838348388672
Final likelihood: tensor([-78.7232, -58.2619, -61.4943, -51.7465, -50.2041, -42.1789, -58.1616,
        -55.4589, -53.4654, -57.7555, -58.6762, -64.4729, -67.7730, -54.7307,
        -53.7154, -58.9255])
Final projection likelihood: -57.8590
1 mode projection failed, trying anyway
New goal: tensor([ 0.1054,  0.3193,  0.7776,  1.1267, -0.0247,  0.3382,  0.9124,  1.1629,
         1.3327,  0.1741,  0.6256,  0.7057,  0.2543,  0.0766,  0.5921],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0033]], device='cuda:1') tensor([[0.0008]], device='cuda:1')
Original likelihood: -67.55211639404297
Adjusted likelihood: -67.55211639404297
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 67.55211639404297}
Current yaw: tensor([ 0.2645,  0.0735, -0.5664], device='cuda:1')
15 thumb_middle
tensor([ 0.0875,  0.4501,  0.7928,  1.2023, -0.0291,  0.3253,  0.8376,  1.1451,
         1.4270,  0.1875,  0.5549,  0.9425,  0.2645,  0.0735, -0.5664, -0.2390],
       device='cuda:1')
Solve time for step 1 9.492081061005592
Current ori: tensor([ 0.2645,  0.0735, -0.5664], device='cuda:1')
Index force: tensor([0.5777, 0.5994, 0.5627, 0.5392], device='cuda:1')
tensor([ 0.0516,  0.4962,  0.7702,  1.2058, -0.1905,  0.1826,  0.8256,  1.1308,
         1.3152,  0.1380,  0.6183,  0.7746,  0.2951,  0.1076, -0.5871,  0.1732],
       device='cuda:1')
Solve time for step 2 1.9792549939884339
Current ori: tensor([ 0.2951,  0.1076, -0.5871], device='cuda:1')
Index force: tensor([0.5941, 0.5572, 0.5359], device='cuda:1')
tensor([ 0.0458,  0.4618,  0.8653,  1.3358, -0.1847,  0.1361,  0.8352,  1.1515,
         1.3391,  0.1388,  0.6496,  0.7569,  0.3172,  0.1204, -0.6024,  0.2002],
       device='cuda:1')
Solve time for step 3 1.885852113016881
Current ori: tensor([ 0.3172,  0.1204, -0.6024], device='cuda:1')
Index force: tensor([0.5516, 0.5318], device='cuda:1')
tensor([ 0.0696,  0.4578,  0.9058,  1.2643, -0.1276,  0.1371,  0.8558,  1.1537,
         1.3545,  0.1684,  0.6601,  0.7419,  0.3172,  0.1185, -0.6385, -0.2410],
       device='cuda:1')
Solve time for step 4 1.8490503989742137
Current ori: tensor([ 0.3172,  0.1185, -0.6385], device='cuda:1')
Index force: tensor([0.5298], device='cuda:1')
Storing RECOVERY transition: reward=0.0230 (scaled=0.0230), steps=1
Reward stats updated: mean -0.0140 -> -0.0137, std: 0.1598
Collected 119 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=59.4222, Q2 Loss=59.4222, Entropy=0.0798, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.5992
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.4932, Q2 Loss=0.4932, Entropy=0.1723, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5697
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.4254, Q2 Loss=0.4254, Entropy=0.0160, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1180
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5988, Q2 Loss=0.5988, Entropy=0.0003, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3231
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=0.6815, Q2 Loss=0.6815, Entropy=0.3495, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3127

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.4%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (41.1%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000138
Q1 loss: 12.324213
Q2 loss: 12.324213
Current threshold: -29.5051
Global Scale Offset: 1.0038
Reward stats: mean=-0.0137, std=0.1598, count=119
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 12.3242, Q2 Loss: 12.3242, Entropy: 0.1236, Mean TD Error: 2.1845, Threshold: -29.5051
Original likelihood: -112.19380187988281
Adjusted likelihood: -112.19380187988281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 123.61676025390625
Projection step: 1, Loss: 133.29429626464844
Projection step: 2, Loss: 124.97979736328125
Projection step: 3, Loss: 132.92625427246094
Projection step: 4, Loss: 123.36845397949219
Projection step: 5, Loss: 126.0335922241211
Projection step: 6, Loss: 117.93647003173828
Projection step: 7, Loss: 119.2008056640625
Projection step: 8, Loss: 126.42008972167969
Projection step: 9, Loss: 124.80508422851562
Projection step: 10, Loss: 126.34687042236328
Projection step: 11, Loss: 115.23507690429688
Projection step: 12, Loss: 118.14060974121094
Projection step: 13, Loss: 119.92463684082031
Projection step: 14, Loss: 123.5223617553711
Final likelihood: tensor([-103.0056, -138.4044, -116.4920,  -93.6060, -107.9508, -114.7550,
        -103.3765, -167.4718, -111.2891, -124.6628, -165.2671, -120.4263,
        -117.3089, -104.5527, -137.2013,  -87.3359])
Final projection likelihood: -119.5691
1 mode projection failed, trying anyway
New goal: tensor([ 0.0824,  0.4445,  0.8636,  1.1751, -0.0469,  0.1731,  1.0241,  1.1885,
         1.3236,  0.2182,  0.7779,  0.8276,  0.3061,  0.1169, -0.3992],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[-0.0001]], device='cuda:1')
Original likelihood: -115.24596405029297
Adjusted likelihood: -115.24596405029297
Likelihood residual: 0.0
Original likelihood: -137.71542358398438
Adjusted likelihood: -137.71542358398438
Likelihood residual: 0.0
{'index': 137.71542358398438, 'thumb_middle': 115.24596405029297}
Current yaw: tensor([ 0.3109,  0.1120, -0.6313], device='cuda:1')
16 thumb_middle
tensor([ 0.1110,  0.4730,  0.8785,  1.1634, -0.0486,  0.1465,  0.8913,  1.1424,
         1.4041,  0.1747,  0.7701,  0.7991,  0.3109,  0.1120, -0.6313,  0.0018],
       device='cuda:1')
Solve time for step 1 9.209382644010475
Current ori: tensor([ 0.3109,  0.1120, -0.6313], device='cuda:1')
Index force: tensor([0.5942, 0.6827, 0.5410, 0.5949], device='cuda:1')
tensor([ 0.1141,  0.4864,  1.0119,  1.1551, -0.1123, -0.0589,  0.8123,  1.0440,
         1.3088,  0.1731,  0.7378,  0.8066,  0.4058,  0.2128, -0.6341, -1.1110],
       device='cuda:1')
Solve time for step 2 1.9827303260099143
Current ori: tensor([ 0.4058,  0.2128, -0.6341], device='cuda:1')
Index force: tensor([0.6680, 0.5376, 0.5898], device='cuda:1')
tensor([-0.0281,  0.5375,  0.9427,  1.1647, -0.0259, -0.1960,  0.8050,  1.0310,
         1.3599,  0.2406,  0.7305,  0.8287,  0.4117,  0.2089, -0.5967, -0.3738],
       device='cuda:1')
Solve time for step 3 1.8982683810172603
Current ori: tensor([ 0.4117,  0.2089, -0.5967], device='cuda:1')
Index force: tensor([0.6534, 0.5892], device='cuda:1')
tensor([-0.1324,  0.5716,  0.8961,  1.1678,  0.0165, -0.1959,  0.9168,  1.0976,
         1.4014,  0.2858,  0.7355,  0.8369,  0.4104,  0.2097, -0.6080,  0.3687],
       device='cuda:1')
Solve time for step 4 1.815477498981636
Current ori: tensor([ 0.4104,  0.2097, -0.6080], device='cuda:1')
Index force: tensor([0.5861], device='cuda:1')
Storing RECOVERY transition: reward=-0.0825 (scaled=-0.0825), steps=1
Reward stats updated: mean -0.0137 -> -0.0143, std: 0.1593
Collected 120 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.8217, Q2 Loss=0.8217, Entropy=0.2569, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3846
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7002, Q2 Loss=0.7002, Entropy=0.0109, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5782
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=7.5729, Q2 Loss=7.5729, Entropy=0.0456, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1501
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=1.0462, Q2 Loss=1.0462, Entropy=0.1693, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8354
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.6937, Q2 Loss=0.6937, Entropy=0.2117, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2887

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.1%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.06s (18.9%)
Actor update: 0.12s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000360
Q1 loss: 2.166941
Q2 loss: 2.166941
Current threshold: -29.5061
Global Scale Offset: 1.0026
Reward stats: mean=-0.0143, std=0.1593, count=120
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 2.1669, Q2 Loss: 2.1669, Entropy: 0.1389, Mean TD Error: 1.4474, Threshold: -29.5061
Original likelihood: -312.88165283203125
Adjusted likelihood: -312.88165283203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 7
Loaded trajectory sampler
Current yaw: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
Current yaw: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
1 turn
Sampling time 3.730674596998142
tensor([ 1.3920e-01,  6.0533e-01,  5.4579e-01,  6.4185e-01, -1.3683e-01,
         5.5199e-01,  9.3034e-01,  8.6387e-01,  1.2154e+00,  2.9797e-01,
         2.4734e-01,  1.2222e+00, -2.4727e-04,  1.4505e-02, -4.4007e-02,
         2.1850e-01], device='cuda:1')
Original likelihood: -20.09292221069336
Adjusted likelihood: -20.09292221069336
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.757413818006171
Current ori: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
Middle force: tensor([0.5685, 0.5756, 1.2286, 0.5691, 1.1812, 0.6502, 0.5379, 0.5266, 0.5122,
        0.5791, 0.4914, 0.4975], device='cuda:1')
Thumb force: tensor([0.8904, 0.8658, 0.7594, 1.0493, 0.9838, 0.6657, 0.5215, 0.8930, 0.5375,
        0.5795, 0.5748, 0.6539], device='cuda:1')
Index force: tensor([0.5948, 0.6082, 0.5542, 0.5751, 0.8257, 0.5326, 1.0312, 0.9479, 0.5807,
        0.6039, 0.6914, 0.7827], device='cuda:1')
Storing NORMAL transition: reward=0.0523 (scaled=0.0523), steps=1
Reward stats updated: mean -0.0143 -> -0.0137, std: 0.1587
Collected 121 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.7118, Q2 Loss=0.7118, Entropy=0.1594, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3189
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.8730, Q2 Loss=0.8730, Entropy=0.2600, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4614
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5197, Q2 Loss=0.5197, Entropy=0.2399, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1186
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=2.1071, Q2 Loss=2.1071, Entropy=0.0100, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3423
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1964, Q2 Loss=1.1964, Entropy=0.0100, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3130

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.8%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.2%)
Actor update: 0.08s (37.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000068
Q1 loss: 1.081608
Q2 loss: 1.081608
Current threshold: -29.5020
Global Scale Offset: 1.0012
Reward stats: mean=-0.0137, std=0.1587, count=121
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0816, Q2 Loss: 1.0816, Entropy: 0.1359, Mean TD Error: 0.7108, Threshold: -29.5020
tensor([ 0.0258,  0.5424,  0.5689,  0.5513, -0.2673,  0.5130,  0.9251,  0.9736,
         1.3966,  0.1699,  0.2303,  1.1798,  0.0102,  0.0740, -0.1021,  0.1913],
       device='cuda:1')
Original likelihood: -45.711830139160156
Adjusted likelihood: -45.711830139160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 44.08378601074219
Projection step: 1, Loss: 39.92668533325195
Projection step: 2, Loss: 38.757171630859375
Projection step: 3, Loss: 35.46804428100586
Projection step: 4, Loss: 32.890872955322266
Projection step: 5, Loss: 31.727718353271484
Projection step: 6, Loss: 29.369356155395508
Projection step: 7, Loss: 28.516115188598633
Projection step: 8, Loss: 27.440044403076172
Projection step: 9, Loss: 26.80885887145996
Projection step: 10, Loss: 26.488723754882812
Projection step: 11, Loss: 25.430625915527344
Projection step: 12, Loss: 23.26296615600586
Projection step: 13, Loss: 23.244674682617188
Projection step: 14, Loss: 22.565824508666992
Final likelihood: tensor([-19.2039, -21.7134, -19.0933, -21.0782, -21.8377, -20.5425, -18.8153,
        -21.5204, -21.1085, -23.7820, -23.6189, -23.3317, -19.2468, -20.7487,
        -15.4758, -20.5565])
Final projection likelihood: -20.7296
1 mode projection succeeded
New goal: tensor([ 0.0110,  0.5492,  0.5011,  0.6619, -0.1332,  0.5251,  0.8054,  0.7931,
         1.3092,  0.1590,  0.1818,  1.1848, -0.0041,  0.0422, -0.6210],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -33.324920654296875
Adjusted likelihood: -33.324920654296875
Likelihood residual: 0.0
Original likelihood: -22.102222442626953
Adjusted likelihood: -22.102222442626953
Likelihood residual: 0.0
{'index': 22.102222442626953, 'thumb_middle': 33.324920654296875}
Current yaw: tensor([ 0.0102,  0.0740, -0.1021], device='cuda:1')
2 index
tensor([ 0.0258,  0.5424,  0.5689,  0.5513, -0.2673,  0.5130,  0.9251,  0.9736,
         1.3966,  0.1699,  0.2303,  1.1798,  0.0102,  0.0740, -0.1021,  0.1913],
       device='cuda:1')
Solve time for step 1 10.704890795983374
Current ori: tensor([ 0.0102,  0.0740, -0.1021], device='cuda:1')
Middle force: tensor([0.5719, 0.5699, 0.6214, 0.5726], device='cuda:1')
Thumb force: tensor([0.5033, 0.6253, 0.5302, 0.5773], device='cuda:1')
tensor([ 0.0589,  0.4892,  0.4644,  0.6078, -0.2359,  0.5387,  0.9208,  0.9199,
         1.3806,  0.1864,  0.2098,  1.1658, -0.0103,  0.0587, -0.1078,  0.5437],
       device='cuda:1')
Solve time for step 2 2.21290253099869
Current ori: tensor([-0.0103,  0.0587, -0.1078], device='cuda:1')
Middle force: tensor([0.5664, 0.6175, 0.5707], device='cuda:1')
Thumb force: tensor([0.6203, 0.5290, 0.5739], device='cuda:1')
tensor([ 0.0583,  0.4970,  0.4556,  0.6283, -0.2129,  0.5647,  0.9125,  0.8835,
         1.3943,  0.1639,  0.1717,  1.1598, -0.0293,  0.0459, -0.1245,  0.8111],
       device='cuda:1')
Solve time for step 3 2.1411675539857242
Current ori: tensor([-0.0293,  0.0459, -0.1245], device='cuda:1')
Middle force: tensor([0.6133, 0.5680], device='cuda:1')
Thumb force: tensor([0.5262, 0.5711], device='cuda:1')
tensor([ 0.0630,  0.5048,  0.4505,  0.6299, -0.1917,  0.5895,  0.8997,  0.8695,
         1.3834,  0.1685,  0.1477,  1.1708, -0.0391,  0.0312, -0.1166,  1.0255],
       device='cuda:1')
Solve time for step 4 2.1202657149988227
Current ori: tensor([-0.0391,  0.0312, -0.1166], device='cuda:1')
Middle force: tensor([0.5085], device='cuda:1')
Thumb force: tensor([0.5768], device='cuda:1')
Storing RECOVERY transition: reward=0.0015 (scaled=0.0015), steps=1
Reward stats updated: mean -0.0137 -> -0.0136, std: 0.1581
Collected 122 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7005, Q2 Loss=0.7005, Entropy=0.0014, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0333
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=8.1735, Q2 Loss=8.1735, Entropy=0.0395, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2739
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1754, Q2 Loss=1.1754, Entropy=0.0002, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2142
SAC Update 4/5: Actor Loss=-0.0018, Q1 Loss=1.0785, Q2 Loss=1.0785, Entropy=0.4264, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8565
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7472, Q2 Loss=0.7472, Entropy=0.0010, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3100

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.7%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (19.0%)
Actor update: 0.10s (42.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000366
Q1 loss: 2.375013
Q2 loss: 2.375013
Current threshold: -29.4931
Global Scale Offset: 0.9980
Reward stats: mean=-0.0136, std=0.1581, count=122
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 2.3750, Q2 Loss: 2.3750, Entropy: 0.0937, Mean TD Error: 1.7376, Threshold: -29.4931
Original likelihood: -23.459754943847656
Adjusted likelihood: -23.459754943847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Current yaw: tensor([-0.0419,  0.0340, -0.1007], device='cuda:1')
3 turn
Sampling time 3.7011364409991074
tensor([ 0.0177,  0.5593,  0.4860,  0.6507, -0.1971,  0.5954,  0.8956,  0.8642,
         1.3821,  0.1734,  0.1545,  1.1635, -0.0419,  0.0340, -0.1007,  1.0556],
       device='cuda:1')
Original likelihood: -25.18692398071289
Adjusted likelihood: -25.18692398071289
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9909)
Solve time for step 1 14.365322362020379
Current ori: tensor([-0.0419,  0.0340, -0.1007], device='cuda:1')
Middle force: tensor([0.9494, 0.5750, 0.6352, 0.6371, 0.8615, 0.5752, 0.9867, 1.7223, 1.1021,
        0.5463, 0.7621, 0.5400], device='cuda:1')
Thumb force: tensor([0.7770, 0.9786, 0.5487, 1.1516, 0.5674, 0.7339, 0.5923, 0.8660, 0.5130,
        0.9609, 0.5532, 0.6382], device='cuda:1')
Index force: tensor([1.1981, 0.5376, 0.8317, 0.7732, 0.6643, 0.5974, 0.5004, 0.9786, 0.6069,
        0.6128, 0.8500, 0.5198], device='cuda:1')
Storing NORMAL transition: reward=0.1002 (scaled=0.1002), steps=1
Reward stats updated: mean -0.0136 -> -0.0127, std: 0.1578
Collected 123 transitions for RL
SAC Update 1/5: Actor Loss=-0.0008, Q1 Loss=0.5006, Q2 Loss=0.5006, Entropy=0.3426, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1488
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.6199, Q2 Loss=0.6199, Entropy=0.1525, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3594
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.8022, Q2 Loss=1.8022, Entropy=0.0262, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3624
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=1.1119, Q2 Loss=1.1119, Entropy=0.2086, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9023
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=6.5493, Q2 Loss=6.5493, Entropy=0.2998, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1529

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.2%)
Actor update: 0.10s (42.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000265
Q1 loss: 2.116771
Q2 loss: 2.116771
Current threshold: -29.4713
Global Scale Offset: 0.9942
Reward stats: mean=-0.0127, std=0.1578, count=123
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 2.1168, Q2 Loss: 2.1168, Entropy: 0.2059, Mean TD Error: 1.5852, Threshold: -29.4713
tensor([ 0.0436,  0.5158,  0.5507,  0.6889, -0.1866,  0.5699,  0.9190,  0.9398,
         1.3713,  0.1829,  0.1487,  1.1506, -0.0301,  0.0211, -0.1997,  1.1753],
       device='cuda:1')
Original likelihood: -23.89817237854004
Adjusted likelihood: -23.89817237854004
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9989)
Solve time for step 2 2.9297928039741237
Current ori: tensor([-0.0301,  0.0211, -0.1997], device='cuda:1')
Middle force: tensor([0.5685, 0.6380, 0.6354, 0.8592, 0.5743, 0.9784, 1.6931, 1.0965, 0.5461,
        0.7625, 0.5388], device='cuda:1')
Thumb force: tensor([0.9540, 0.5418, 1.1229, 0.5616, 0.7255, 0.5865, 0.8524, 0.5119, 0.9508,
        0.5477, 0.6332], device='cuda:1')
Index force: tensor([0.5366, 0.8268, 0.7618, 0.6594, 0.5926, 0.5003, 0.9603, 0.6026, 0.6065,
        0.8457, 0.5184], device='cuda:1')
Storing NORMAL transition: reward=0.0072 (scaled=0.0072), steps=1
Reward stats updated: mean -0.0127 -> -0.0125, std: 0.1571
Collected 124 transitions for RL
SAC Update 1/5: Actor Loss=-0.0058, Q1 Loss=1.1393, Q2 Loss=1.1393, Entropy=0.0231, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8105
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.9157, Q2 Loss=0.9157, Entropy=0.3468, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6326
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9837, Q2 Loss=0.9837, Entropy=0.0123, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8357
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=0.5051, Q2 Loss=0.5051, Entropy=0.4475, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6077
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5641, Q2 Loss=0.5641, Entropy=0.0050, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2662

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (19.0%)
Actor update: 0.10s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001536
Q1 loss: 0.821572
Q2 loss: 0.821572
Current threshold: -29.4337
Global Scale Offset: 0.9578
Reward stats: mean=-0.0125, std=0.1571, count=124
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 0.8216, Q2 Loss: 0.8216, Entropy: 0.1669, Mean TD Error: 0.6305, Threshold: -29.4337
tensor([ 0.1068,  0.4827,  0.5202,  0.5129, -0.1398,  0.6158,  0.9146,  0.9437,
         1.2926,  0.1420,  0.2059,  1.0817, -0.0601, -0.0185, -0.2100,  2.3714],
       device='cuda:1')
Original likelihood: -31.869375228881836
Adjusted likelihood: -31.869375228881836
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0843)
State is out of distribution
Projection step: 0, Loss: 33.59942626953125
Projection step: 1, Loss: 29.358890533447266
Projection step: 2, Loss: 21.697792053222656
Projection step: 3, Loss: 16.703994750976562
Projection step: 4, Loss: 14.757264137268066
Final likelihood: tensor([-15.0837, -14.8102, -15.2854, -14.5703, -14.5741, -14.0840, -14.1443,
        -14.8160, -14.0028, -14.0135, -14.8272, -17.1379, -14.6602, -15.1723,
        -14.4163, -14.5181])
Final projection likelihood: -14.7573
1 mode projection succeeded
New goal: tensor([ 0.0903,  0.5217,  0.5879,  0.6324, -0.0775,  0.6510,  0.8373,  0.9093,
         1.3456,  0.2373,  0.1425,  0.9699, -0.0605, -0.0120, -0.8494],
       device='cuda:1')
tensor([[0.0039]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0139]], device='cuda:1')
Original likelihood: -21.24686050415039
Adjusted likelihood: -21.24686050415039
Likelihood residual: 0.0
Original likelihood: -29.041728973388672
Adjusted likelihood: -29.041728973388672
Likelihood residual: 0.0
{'index': 29.041728973388672, 'thumb_middle': 21.24686050415039}
Current yaw: tensor([-0.0601, -0.0185, -0.2100], device='cuda:1')
4 thumb_middle
tensor([ 0.1068,  0.4827,  0.5202,  0.5129, -0.1398,  0.6158,  0.9146,  0.9437,
         1.2926,  0.1420,  0.2059,  1.0817, -0.0601, -0.0185, -0.2100,  2.3714],
       device='cuda:1')
Solve time for step 1 9.632551763002994
Current ori: tensor([-0.0601, -0.0185, -0.2100], device='cuda:1')
Index force: tensor([0.5893, 0.5945, 0.5803, 0.5929], device='cuda:1')
tensor([ 0.0548,  0.5383,  0.5705,  0.5864, -0.2009,  0.6155,  0.8299,  0.9057,
         1.2977,  0.1940,  0.0873,  0.9608, -0.0792, -0.0123, -0.2100,  2.4940],
       device='cuda:1')
Solve time for step 2 1.9720870299788658
Current ori: tensor([-0.0792, -0.0123, -0.2100], device='cuda:1')
Index force: tensor([0.5882, 0.5760, 0.5996], device='cuda:1')
tensor([ 0.0517,  0.5198,  0.5763,  0.6218, -0.1946,  0.6222,  0.7996,  0.8929,
         1.3170,  0.2160,  0.0631,  0.9705, -0.0747, -0.0041, -0.2100,  2.4221],
       device='cuda:1')
Solve time for step 3 1.923155077995034
Current ori: tensor([-0.0747, -0.0041, -0.2100], device='cuda:1')
Index force: tensor([0.5696, 0.5938], device='cuda:1')
tensor([ 0.0603,  0.5176,  0.5824,  0.6313, -0.2065,  0.6364,  0.8041,  0.8909,
         1.3266,  0.2082,  0.0666,  0.9439, -0.0790,  0.0035, -0.2100,  2.3218],
       device='cuda:1')
Solve time for step 4 1.8317196340067312
Current ori: tensor([-0.0790,  0.0035, -0.2100], device='cuda:1')
Index force: tensor([0.5843], device='cuda:1')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0008), steps=2
Reward stats updated: mean -0.0125 -> -0.0124, std: 0.1565
Collected 125 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.5522, Q2 Loss=0.5522, Entropy=0.3451, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1018
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6838, Q2 Loss=0.6838, Entropy=0.0324, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2454
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7990, Q2 Loss=0.7990, Entropy=0.1450, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5093
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=5.7236, Q2 Loss=5.7236, Entropy=0.0300, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1342
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7377, Q2 Loss=0.7377, Entropy=0.0096, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5654

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.6%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000040
Q1 loss: 1.699271
Q2 loss: 1.699271
Current threshold: -29.4178
Global Scale Offset: 0.9354
Reward stats: mean=-0.0124, std=0.1565, count=125
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.6993, Q2 Loss: 1.6993, Entropy: 0.1124, Mean TD Error: 1.3112, Threshold: -29.4178
Original likelihood: -22.028554916381836
Adjusted likelihood: -22.028554916381836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0761, -0.0164, -0.2142], device='cuda:1')
5 turn
Sampling time 3.866763694997644
tensor([ 0.0724,  0.5202,  0.5778,  0.6535, -0.1395,  0.6769,  0.8406,  0.8965,
         1.3790,  0.2444,  0.1073,  0.9713, -0.0761, -0.0164, -0.2142,  2.4122],
       device='cuda:1')
Original likelihood: -22.420997619628906
Adjusted likelihood: -22.420997619628906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.220123857987346
Current ori: tensor([-0.0761, -0.0164, -0.2142], device='cuda:1')
Middle force: tensor([0.5940, 0.5549, 1.3805, 0.5764, 0.6577, 0.8097, 0.5345, 0.5967, 0.8944,
        0.5508, 0.6639, 0.5621], device='cuda:1')
Thumb force: tensor([0.5904, 1.0823, 0.9321, 1.1202, 0.5407, 0.5772, 0.5894, 0.5670, 0.5565,
        0.6144, 0.5601, 0.9530], device='cuda:1')
Index force: tensor([0.6120, 0.5099, 1.3149, 0.5674, 0.6141, 0.6146, 0.6023, 0.5592, 0.5113,
        0.6517, 0.5762, 0.5544], device='cuda:1')
Storing NORMAL transition: reward=-0.0413 (scaled=-0.0413), steps=1
Reward stats updated: mean -0.0124 -> -0.0126, std: 0.1559
Collected 126 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8184, Q2 Loss=0.8184, Entropy=0.0029, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3636
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8118, Q2 Loss=0.8118, Entropy=0.0031, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0801
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6630, Q2 Loss=0.6630, Entropy=0.0223, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4130
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8852, Q2 Loss=0.8852, Entropy=0.0029, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6533
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2467, Q2 Loss=1.2467, Entropy=0.0096, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8901

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (38.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000001
Q1 loss: 0.885019
Q2 loss: 0.885019
Current threshold: -29.4084
Global Scale Offset: 0.9226
Reward stats: mean=-0.0126, std=0.1559, count=126
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8850, Q2 Loss: 0.8850, Entropy: 0.0082, Mean TD Error: 0.6800, Threshold: -29.4084
tensor([ 4.0312e-02,  4.7442e-01,  5.9658e-01,  6.8247e-01, -1.5996e-01,
         6.8184e-01,  7.8117e-01,  9.7134e-01,  1.3943e+00,  2.1522e-01,
         1.0879e-01,  1.0122e+00, -6.1653e-02, -1.2214e-03, -1.7053e-01,
         2.3859e+00], device='cuda:1')
Original likelihood: -20.09174346923828
Adjusted likelihood: -20.09174346923828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9479140720213763
Current ori: tensor([-0.0617, -0.0012, -0.1705], device='cuda:1')
Middle force: tensor([0.5525, 1.3610, 0.5734, 0.6565, 0.8034, 0.5330, 0.5949, 0.8870, 0.5500,
        0.6586, 0.5593], device='cuda:1')
Thumb force: tensor([1.0633, 0.9129, 1.0968, 0.5391, 0.5747, 0.5863, 0.5641, 0.5541, 0.6089,
        0.5579, 0.9399], device='cuda:1')
Index force: tensor([0.5091, 1.2836, 0.5659, 0.6111, 0.6094, 0.5994, 0.5577, 0.5104, 0.6456,
        0.5732, 0.5521], device='cuda:1')
Storing NORMAL transition: reward=-0.0010 (scaled=-0.0010), steps=1
Reward stats updated: mean -0.0126 -> -0.0125, std: 0.1553
Collected 127 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0827, Q2 Loss=1.0827, Entropy=0.0012, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8611
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=27.3009, Q2 Loss=27.3009, Entropy=0.0264, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0355
SAC Update 3/5: Actor Loss=-0.0020, Q1 Loss=0.6199, Q2 Loss=0.6199, Entropy=0.0735, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3699
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.7943, Q2 Loss=0.7943, Entropy=0.3457, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3803
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.7703, Q2 Loss=0.7703, Entropy=0.3390, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3977

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.6%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (20.0%)
Actor update: 0.11s (40.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000735
Q1 loss: 6.113615
Q2 loss: 6.113615
Current threshold: -29.3982
Global Scale Offset: 0.9079
Reward stats: mean=-0.0125, std=0.1553, count=127
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 6.1136, Q2 Loss: 6.1136, Entropy: 0.1572, Mean TD Error: 1.4089, Threshold: -29.3982
tensor([ 0.0172,  0.5265,  0.5268,  0.6417, -0.1380,  0.6612,  0.8186,  1.0035,
         1.3216,  0.2449,  0.1636,  0.9547, -0.0433, -0.0208, -0.1682,  2.7990],
       device='cuda:1')
Original likelihood: -23.610050201416016
Adjusted likelihood: -23.610050201416016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 3 2.7509830339986365
Current ori: tensor([-0.0433, -0.0208, -0.1682], device='cuda:1')
Middle force: tensor([1.3065, 0.5963, 0.6759, 0.7925, 0.6341, 0.6339, 0.9095, 0.5975, 0.6056,
        0.5555], device='cuda:1')
Thumb force: tensor([0.8808, 1.0266, 0.5191, 0.5684, 0.5639, 0.5387, 0.7383, 0.5992, 0.5741,
        0.6860], device='cuda:1')
Index force: tensor([1.2035, 0.5845, 0.6136, 0.5980, 0.5786, 0.5058, 0.5058, 0.6054, 0.5922,
        0.5315], device='cuda:1')
Storing NORMAL transition: reward=-0.0165 (scaled=-0.0165), steps=1
Reward stats updated: mean -0.0125 -> -0.0126, std: 0.1547
Collected 128 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=5.5306, Q2 Loss=5.5306, Entropy=0.2050, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1969
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6243, Q2 Loss=0.6243, Entropy=0.0022, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3180
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7825, Q2 Loss=0.7825, Entropy=0.0162, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5878
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9362, Q2 Loss=0.9362, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6435
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0598, Q2 Loss=1.0598, Entropy=0.0020, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5655

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (19.2%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000026
Q1 loss: 1.786680
Q2 loss: 1.786680
Current threshold: -29.3886
Global Scale Offset: 0.8961
Reward stats: mean=-0.0126, std=0.1547, count=128
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.7867, Q2 Loss: 1.7867, Entropy: 0.0451, Mean TD Error: 1.4623, Threshold: -29.3886
tensor([-0.0366,  0.4263,  0.5583,  0.7212, -0.0194,  0.5579,  0.8477,  1.0323,
         1.2998,  0.1603,  0.1257,  1.1121, -0.0797, -0.0481, -0.1572,  4.9272],
       device='cuda:1')
Original likelihood: -27.000024795532227
Adjusted likelihood: -27.000024795532227
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9218)
Solve time for step 4 2.6035138729785103
Current ori: tensor([-0.0797, -0.0481, -0.1572], device='cuda:1')
Middle force: tensor([0.5994, 0.6769, 0.8000, 0.6315, 0.6424, 0.9165, 0.6032, 0.5994, 0.5604],
       device='cuda:1')
Thumb force: tensor([0.9974, 0.5181, 0.5636, 0.5611, 0.5342, 0.7293, 0.5900, 0.5707, 0.6693],
       device='cuda:1')
Index force: tensor([0.5737, 0.6124, 0.5864, 0.5754, 0.5053, 0.5049, 0.5982, 0.5903, 0.5271],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0447 (scaled=-0.0447), steps=1
Reward stats updated: mean -0.0126 -> -0.0128, std: 0.1541
Collected 129 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6409, Q2 Loss=0.6409, Entropy=0.0887, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4829
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.5367, Q2 Loss=0.5367, Entropy=0.1351, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6517
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8848, Q2 Loss=0.8848, Entropy=0.0043, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1297
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5062, Q2 Loss=0.5062, Entropy=0.0013, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0963
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7620, Q2 Loss=0.7620, Entropy=0.0881, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4674

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.4%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (39.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000067
Q1 loss: 0.666105
Q2 loss: 0.666105
Current threshold: -29.3805
Global Scale Offset: 0.8890
Reward stats: mean=-0.0128, std=0.1541, count=129
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.6661, Q2 Loss: 0.6661, Entropy: 0.0635, Mean TD Error: 0.3656, Threshold: -29.3805
tensor([ 0.0234,  0.3546,  0.6435,  0.8090, -0.0319,  0.6124,  0.7926,  0.9725,
         1.2894,  0.2104,  0.1941,  1.0273, -0.0991, -0.0245, -0.1133,  5.9670],
       device='cuda:1')
Original likelihood: -21.82085609436035
Adjusted likelihood: -21.82085609436035
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.3074785389762837
Current ori: tensor([-0.0991, -0.0245, -0.1133], device='cuda:1')
Middle force: tensor([0.6548, 0.8093, 0.6295, 0.6411, 0.6010, 0.6638, 1.0638, 0.5262],
       device='cuda:1')
Thumb force: tensor([0.5051, 0.5495, 0.5467, 0.5696, 0.5480, 0.5082, 1.6385, 0.5050],
       device='cuda:1')
Index force: tensor([0.6407, 0.6649, 0.5863, 0.5060, 0.5676, 0.5970, 0.6065, 0.6305],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0335 (scaled=-0.0335), steps=1
Reward stats updated: mean -0.0128 -> -0.0130, std: 0.1535
Collected 130 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=5.3877, Q2 Loss=5.3877, Entropy=0.0264, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2248
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=26.7839, Q2 Loss=26.7839, Entropy=0.1584, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1015
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6080, Q2 Loss=0.6080, Entropy=0.1375, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3277
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6789, Q2 Loss=0.6789, Entropy=0.0018, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4112
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7200, Q2 Loss=0.7200, Entropy=0.0060, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2911

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000035
Q1 loss: 6.835693
Q2 loss: 6.835693
Current threshold: -29.3731
Global Scale Offset: 0.8864
Reward stats: mean=-0.0130, std=0.1535, count=130
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 6.8357, Q2 Loss: 6.8357, Entropy: 0.0660, Mean TD Error: 2.2713, Threshold: -29.3731
tensor([ 0.0111,  0.4041,  0.6859,  0.8105, -0.0316,  0.6521,  0.7745,  1.0394,
         1.2813,  0.2970,  0.2579,  0.8448, -0.2233, -0.0206, -0.1103, -5.5796],
       device='cuda:1')
Original likelihood: -77.42262268066406
Adjusted likelihood: -77.42262268066406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 70.10929870605469
Projection step: 1, Loss: 66.0263442993164
Projection step: 2, Loss: 62.483978271484375
Projection step: 3, Loss: 59.45088195800781
Projection step: 4, Loss: 62.61861038208008
Projection step: 5, Loss: 56.50301742553711
Projection step: 6, Loss: 59.55727767944336
Projection step: 7, Loss: 62.633018493652344
Projection step: 8, Loss: 56.48341369628906
Projection step: 9, Loss: 61.55780792236328
Projection step: 10, Loss: 49.58818817138672
Projection step: 11, Loss: 63.11908721923828
Projection step: 12, Loss: 47.88855743408203
Projection step: 13, Loss: 52.73097229003906
Projection step: 14, Loss: 50.92747116088867
Final likelihood: tensor([-42.4835, -38.4450, -37.0463, -34.6196, -69.4955, -37.6082, -49.8783,
        -80.3889, -60.5965, -39.6278, -88.3101, -71.7740, -45.7198, -53.5017,
        -43.0149, -53.3732])
Final projection likelihood: -52.8677
1 mode projection failed, trying anyway
New goal: tensor([ 0.0321,  0.3650,  0.6472,  0.7978, -0.0220,  0.6284,  0.7182,  1.0718,
         1.2851,  0.3575,  0.2994,  0.7526, -0.2142, -0.0168,  0.2527],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0094]], device='cuda:1') tensor([[0.0167]], device='cuda:1')
Original likelihood: -30.93341064453125
Adjusted likelihood: -30.93341064453125
Likelihood residual: 0.0
Original likelihood: -43.271915435791016
Adjusted likelihood: -43.271915435791016
Likelihood residual: 0.0
{'index': 43.271915435791016, 'thumb_middle': 30.93341064453125}
Current yaw: tensor([-0.2233, -0.0206, -0.1103], device='cuda:1')
6 thumb_middle
tensor([ 0.0111,  0.4041,  0.6859,  0.8105, -0.0316,  0.6521,  0.7745,  1.0394,
         1.2813,  0.2970,  0.2579,  0.8448, -0.2233, -0.0206, -0.1103, -5.5796],
       device='cuda:1')
Solve time for step 1 9.210519921995001
Current ori: tensor([-0.2233, -0.0206, -0.1103], device='cuda:1')
Index force: tensor([0.6033, 0.5876, 0.5812, 0.5902], device='cuda:1')
tensor([-0.0165,  0.5306,  0.6555,  0.7416, -0.0959,  0.6118,  0.7119,  1.0535,
         1.2403,  0.3248,  0.2310,  0.7488, -0.5555, -0.0492, -0.1103, -3.9996],
       device='cuda:1')
Solve time for step 2 2.0801477920031175
Current ori: tensor([-0.5555, -0.0492, -0.1103], device='cuda:1')
Index force: tensor([0.5747, 0.5663, 0.5699], device='cuda:1')
tensor([-0.1481,  0.7022,  0.7175,  0.7624, -0.0811,  0.6625,  0.7149,  1.0540,
         1.2596,  0.3369,  0.2266,  0.7337, -1.2455, -0.0892, -0.1104, -3.7517],
       device='cuda:1')
Solve time for step 3 2.011159363988554
Current ori: tensor([-1.2455, -0.0892, -0.1104], device='cuda:1')
Index force: tensor([0.5572, 0.5669], device='cuda:1')
tensor([-0.3055,  0.8637,  0.8478,  0.8731, -0.1824,  0.7322,  0.7876,  1.0825,
         1.2822,  0.3455,  0.2286,  0.7343, -1.9466, -0.0837, -0.1104, -4.3474],
       device='cuda:1')
Solve time for step 4 1.8404110069968738
Current ori: tensor([-1.9466, -0.0837, -0.1104], device='cuda:1')
Index force: tensor([0.5683], device='cuda:1')
Storing RECOVERY transition: reward=-1.5271 (scaled=-0.3054), steps=5
Reward stats updated: mean -0.0130 -> -0.0152, std: 0.1550
Collected 131 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.3167, Q2 Loss=1.3167, Entropy=0.1298, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0258
SAC Update 2/5: Actor Loss=-0.0012, Q1 Loss=0.7743, Q2 Loss=0.7743, Entropy=0.6814, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5438
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7821, Q2 Loss=0.7821, Entropy=0.0397, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2322
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0356, Q2 Loss=1.0356, Entropy=0.0022, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3981
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=5.6966, Q2 Loss=5.6966, Entropy=0.0229, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2405

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (18.4%)
Actor update: 0.11s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000252
Q1 loss: 1.921047
Q2 loss: 1.921047
Current threshold: -29.3591
Global Scale Offset: 0.8857
Reward stats: mean=-0.0152, std=0.1550, count=131
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.9210, Q2 Loss: 1.9210, Entropy: 0.1752, Mean TD Error: 2.4881, Threshold: -29.3591
Original likelihood: -1314.1201171875
Adjusted likelihood: -1314.1201171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 8
Loaded trajectory sampler
Current yaw: tensor([-0.0005,  0.0146, -0.0441], device='cuda:1')
Current yaw: tensor([-0.0005,  0.0146, -0.0441], device='cuda:1')
1 turn
Sampling time 3.694341398018878
tensor([ 1.5217e-01,  6.0147e-01,  5.9594e-01,  5.7909e-01, -1.3719e-01,
         5.6182e-01,  9.0028e-01,  9.0761e-01,  1.2494e+00,  3.2971e-01,
         1.9584e-01,  1.2101e+00, -4.7459e-04,  1.4550e-02, -4.4092e-02,
         2.0146e-01], device='cuda:1')
Original likelihood: -22.11953353881836
Adjusted likelihood: -22.11953353881836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.394226191012422
Current ori: tensor([-0.0005,  0.0146, -0.0441], device='cuda:1')
Middle force: tensor([1.1657, 1.7415, 0.8343, 0.5212, 0.5852, 0.8914, 1.1568, 0.5112, 0.8192,
        0.5402, 0.5448, 0.5704], device='cuda:1')
Thumb force: tensor([0.9042, 1.4268, 0.5700, 0.5551, 0.5337, 1.3027, 0.6633, 0.5620, 0.6759,
        0.6488, 0.7676, 0.6643], device='cuda:1')
Index force: tensor([0.9117, 1.7924, 0.5638, 0.5941, 0.5955, 0.8266, 0.5440, 0.5789, 0.5283,
        0.6539, 0.6307, 0.5992], device='cuda:1')
Storing NORMAL transition: reward=0.0500 (scaled=0.0500), steps=1
Reward stats updated: mean -0.0152 -> -0.0147, std: 0.1546
Collected 132 transitions for RL
SAC Update 1/5: Actor Loss=-0.0068, Q1 Loss=6.3906, Q2 Loss=6.3906, Entropy=0.0256, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3161
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7999, Q2 Loss=0.7999, Entropy=0.0069, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4251
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8118, Q2 Loss=0.8118, Entropy=0.0015, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3896
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=3.1078, Q2 Loss=3.1078, Entropy=0.1181, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0416
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=25.3945, Q2 Loss=25.3945, Entropy=0.0177, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1684

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (18.3%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001367
Q1 loss: 7.300887
Q2 loss: 7.300887
Current threshold: -29.3222
Global Scale Offset: 0.8530
Reward stats: mean=-0.0147, std=0.1546, count=132
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 7.3009, Q2 Loss: 7.3009, Entropy: 0.0339, Mean TD Error: 3.2682, Threshold: -29.3222
tensor([ 1.6008e-01,  6.6178e-01,  5.8220e-01,  4.5963e-01, -9.8518e-02,
         5.6722e-01,  8.4975e-01,  1.0151e+00,  1.2922e+00,  2.1012e-01,
         2.0646e-01,  1.1249e+00,  2.3920e-05, -1.2670e-02, -9.4011e-02,
         3.0618e-01], device='cuda:1')
Original likelihood: -20.70499038696289
Adjusted likelihood: -20.70499038696289
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9425140150124207
Current ori: tensor([ 2.3920e-05, -1.2670e-02, -9.4011e-02], device='cuda:1')
Middle force: tensor([1.7397, 0.8300, 0.5219, 0.5858, 0.8975, 1.1486, 0.5104, 0.8180, 0.5403,
        0.5435, 0.5712], device='cuda:1')
Thumb force: tensor([1.3665, 0.5674, 0.5477, 0.5308, 1.2745, 0.6601, 0.5549, 0.6698, 0.6369,
        0.7601, 0.6541], device='cuda:1')
Index force: tensor([1.7813, 0.5630, 0.5968, 0.5958, 0.8300, 0.5429, 0.5842, 0.5274, 0.6575,
        0.6288, 0.5991], device='cuda:1')
Storing NORMAL transition: reward=0.3666 (scaled=0.3666), steps=1
Reward stats updated: mean -0.0147 -> -0.0118, std: 0.1575
Collected 133 transitions for RL
SAC Update 1/5: Actor Loss=-0.0053, Q1 Loss=0.9304, Q2 Loss=0.9304, Entropy=0.0038, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5464
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=1.3085, Q2 Loss=1.3085, Entropy=0.3470, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8943
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2998, Q2 Loss=1.2998, Entropy=0.0157, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9626
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5898, Q2 Loss=0.5898, Entropy=0.0002, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3085
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2929, Q2 Loss=1.2929, Entropy=0.0005, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9895

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001177
Q1 loss: 1.084269
Q2 loss: 1.084269
Current threshold: -29.2756
Global Scale Offset: 0.8136
Reward stats: mean=-0.0118, std=0.1575, count=133
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 1.0843, Q2 Loss: 1.0843, Entropy: 0.0734, Mean TD Error: 1.5403, Threshold: -29.2756
tensor([ 0.2657,  0.6962,  0.6071,  0.5628,  0.0249,  0.4847,  1.0087,  1.1983,
         1.3494,  0.1216,  0.1231,  1.0053,  0.0164, -0.0868, -0.5069,  1.2688],
       device='cuda:1')
Original likelihood: -36.44587326049805
Adjusted likelihood: -36.44587326049805
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.974761962890625
Projection step: 1, Loss: 35.71065139770508
Projection step: 2, Loss: 34.49565505981445
Projection step: 3, Loss: 32.334938049316406
Projection step: 4, Loss: 31.536020278930664
Projection step: 5, Loss: 33.09632110595703
Projection step: 6, Loss: 31.008508682250977
Projection step: 7, Loss: 30.539165496826172
Projection step: 8, Loss: 30.276710510253906
Projection step: 9, Loss: 28.364749908447266
Projection step: 10, Loss: 30.107254028320312
Projection step: 11, Loss: 29.668481826782227
Projection step: 12, Loss: 26.275005340576172
Projection step: 13, Loss: 27.11135482788086
Projection step: 14, Loss: 26.743511199951172
Final likelihood: tensor([-23.4565, -22.5850, -24.2468, -26.3297, -32.7206, -22.9794, -24.8052,
        -22.0467, -26.1194, -26.6343, -23.3967, -29.5016, -27.4549, -29.1042,
        -22.4841, -24.3320])
Final projection likelihood: -25.5123
1 mode projection succeeded
New goal: tensor([ 0.1708,  0.5736,  0.5854,  0.7202,  0.0351,  0.5144,  0.7697,  1.0006,
         1.3448,  0.1048,  0.0759,  1.0094,  0.0098, -0.0690, -1.3808],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -30.436431884765625
Adjusted likelihood: -30.436431884765625
Likelihood residual: 0.0
Original likelihood: -30.001842498779297
Adjusted likelihood: -30.001842498779297
Likelihood residual: 0.0
{'index': 30.001842498779297, 'thumb_middle': 30.436431884765625}
Current yaw: tensor([ 0.0164, -0.0868, -0.5069], device='cuda:1')
2 index
tensor([ 0.2657,  0.6962,  0.6071,  0.5628,  0.0249,  0.4847,  1.0087,  1.1983,
         1.3494,  0.1216,  0.1231,  1.0053,  0.0164, -0.0868, -0.5069,  1.2688],
       device='cuda:1')
Solve time for step 1 10.626787935005268
Current ori: tensor([ 0.0164, -0.0868, -0.5069], device='cuda:1')
Middle force: tensor([0.5552, 0.5013, 0.5013, 0.5518], device='cuda:1')
Thumb force: tensor([0.5366, 0.5568, 0.5975, 0.5234], device='cuda:1')
tensor([ 0.2536,  0.5580,  0.5372,  0.6604,  0.0307,  0.5466,  0.9647,  1.1653,
         1.3539,  0.1092,  0.1052,  0.9650, -0.0063, -0.1000, -0.5155,  1.9166],
       device='cuda:1')
Solve time for step 2 2.329717028012965
Current ori: tensor([-0.0063, -0.1000, -0.5155], device='cuda:1')
Middle force: tensor([0.5011, 0.5010, 0.5501], device='cuda:1')
Thumb force: tensor([0.5524, 0.5946, 0.5219], device='cuda:1')
tensor([ 0.2407,  0.5494,  0.5363,  0.6765,  0.0349,  0.5696,  0.9460,  1.1442,
         1.3679,  0.0813,  0.0920,  0.9494, -0.0178, -0.1041, -0.5134,  2.8224],
       device='cuda:1')
Solve time for step 3 2.2022328049934004
Current ori: tensor([-0.0178, -0.1041, -0.5134], device='cuda:1')
Middle force: tensor([0.5008, 0.5483], device='cuda:1')
Thumb force: tensor([0.5906, 0.5207], device='cuda:1')
tensor([ 0.2378,  0.5480,  0.5343,  0.6851,  0.0341,  0.5833,  0.9337,  1.1358,
         1.3805,  0.0547,  0.0873,  0.9380, -0.0230, -0.1053, -0.5092,  3.7757],
       device='cuda:1')
Solve time for step 4 2.150527468009386
Current ori: tensor([-0.0230, -0.1053, -0.5092], device='cuda:1')
Middle force: tensor([0.5444], device='cuda:1')
Thumb force: tensor([0.5180], device='cuda:1')
Storing RECOVERY transition: reward=-0.0241 (scaled=-0.0120), steps=2
Reward stats updated: mean -0.0118 -> -0.0118, std: 0.1569
Collected 134 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6894, Q2 Loss=0.6894, Entropy=0.0165, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2999
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0532, Q2 Loss=1.0532, Entropy=0.0808, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1254
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=12.5493, Q2 Loss=12.5493, Entropy=0.0117, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1015
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.6468, Q2 Loss=0.6468, Entropy=0.2635, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2926
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.6058, Q2 Loss=0.6058, Entropy=0.4015, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4495

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000090
Q1 loss: 3.108889
Q2 loss: 3.108889
Current threshold: -29.2444
Global Scale Offset: 0.7919
Reward stats: mean=-0.0118, std=0.1569, count=134
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 3.1089, Q2 Loss: 3.1089, Entropy: 0.1548, Mean TD Error: 1.8538, Threshold: -29.2444
Original likelihood: -26.592050552368164
Adjusted likelihood: -26.592050552368164
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9575)
Current yaw: tensor([-0.0246, -0.1135, -0.5063], device='cuda:1')
3 turn
Sampling time 3.7426545660127886
tensor([ 0.1937,  0.5990,  0.5730,  0.7086,  0.0442,  0.5944,  0.9317,  1.1292,
         1.3588,  0.0902,  0.0772,  0.9520, -0.0246, -0.1135, -0.5063,  3.9554],
       device='cuda:1')
Original likelihood: -30.058128356933594
Adjusted likelihood: -30.058128356933594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2987)
State is out of distribution
Projection step: 0, Loss: 31.68462371826172
Projection step: 1, Loss: 32.20042419433594
Projection step: 2, Loss: 30.531879425048828
Projection step: 3, Loss: 30.88848114013672
Projection step: 4, Loss: 31.19092559814453
Projection step: 5, Loss: 31.347766876220703
Projection step: 6, Loss: 28.036212921142578
Projection step: 7, Loss: 29.166404724121094
Projection step: 8, Loss: 30.133831024169922
Projection step: 9, Loss: 28.079490661621094
Projection step: 10, Loss: 28.76105308532715
Projection step: 11, Loss: 28.89119529724121
Projection step: 12, Loss: 27.542503356933594
Projection step: 13, Loss: 27.04068374633789
Projection step: 14, Loss: 26.789306640625
Final likelihood: tensor([-28.1927, -28.4019, -23.6734, -22.5625, -23.1415, -24.3347, -26.5400,
        -27.2225, -28.6401, -27.8019, -26.9933, -27.0519, -27.0567, -25.4014,
        -30.3250, -28.2725])
Final projection likelihood: -26.6007
1 mode projection succeeded
New goal: tensor([ 0.1570,  0.5450,  0.5335,  0.8235,  0.0422,  0.6035,  0.8334,  0.8413,
         1.3567,  0.1218,  0.1205,  0.8327, -0.0229, -0.0941, -1.6827],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -27.300296783447266
Adjusted likelihood: -27.300296783447266
Likelihood residual: 0.0
Original likelihood: -37.97383117675781
Adjusted likelihood: -37.97383117675781
Likelihood residual: 0.0
{'index': 37.97383117675781, 'thumb_middle': 27.300296783447266}
Current yaw: tensor([-0.0246, -0.1135, -0.5063], device='cuda:1')
4 thumb_middle
tensor([ 0.1937,  0.5990,  0.5730,  0.7086,  0.0442,  0.5944,  0.9317,  1.1292,
         1.3588,  0.0902,  0.0772,  0.9520, -0.0246, -0.1135, -0.5063,  3.9554],
       device='cuda:1')
Solve time for step 1 9.073153941979399
Current ori: tensor([-0.0246, -0.1135, -0.5063], device='cuda:1')
Index force: tensor([0.5936, 0.6140, 0.6037, 0.5837], device='cuda:1')
tensor([ 0.1725,  0.5805,  0.5395,  0.7779, -0.0352,  0.5996,  0.8301,  0.8925,
         1.3217,  0.1045,  0.0526,  0.8454, -0.0083, -0.1013, -0.5064,  4.0399],
       device='cuda:1')
Solve time for step 2 2.065168082015589
Current ori: tensor([-0.0083, -0.1013, -0.5064], device='cuda:1')
Index force: tensor([0.6068, 0.5991, 0.5833], device='cuda:1')
tensor([ 1.3838e-01,  5.5725e-01,  5.2592e-01,  7.9598e-01, -5.8040e-02,
         6.1285e-01,  8.1197e-01,  8.3783e-01,  1.3485e+00,  1.1143e-01,
         6.8258e-02,  8.2779e-01,  9.1730e-04, -8.1397e-02, -5.0640e-01,
         4.0416e+00], device='cuda:1')
Solve time for step 3 1.8771223509975243
Current ori: tensor([ 0.0009, -0.0814, -0.5064], device='cuda:1')
Index force: tensor([0.5913, 0.5763], device='cuda:1')
tensor([ 1.5589e-01,  5.7556e-01,  5.2205e-01,  7.9012e-01, -5.3287e-02,
         6.3453e-01,  8.1722e-01,  8.3286e-01,  1.3443e+00,  1.0787e-01,
         5.7168e-02,  8.1984e-01, -8.9725e-04, -9.2387e-02, -5.0640e-01,
         4.0644e+00], device='cuda:1')
Solve time for step 4 1.844243308994919
Current ori: tensor([-0.0009, -0.0924, -0.5064], device='cuda:1')
Index force: tensor([0.5673], device='cuda:1')
Storing RECOVERY transition: reward=0.0048 (scaled=0.0048), steps=0
Reward stats updated: mean -0.0118 -> -0.0117, std: 0.1563
Collected 135 transitions for RL
SAC Update 1/5: Actor Loss=-0.0011, Q1 Loss=0.5360, Q2 Loss=0.5360, Entropy=0.6327, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1614
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.6264, Q2 Loss=0.6264, Entropy=0.0960, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7343
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6545, Q2 Loss=0.6545, Entropy=0.0101, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4705
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.6463, Q2 Loss=0.6463, Entropy=0.3283, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2601
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=4.6853, Q2 Loss=4.6853, Entropy=0.1408, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1488

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (39.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000418
Q1 loss: 1.429690
Q2 loss: 1.429690
Current threshold: -29.2095
Global Scale Offset: 0.7784
Reward stats: mean=-0.0117, std=0.1563, count=135
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.4297, Q2 Loss: 1.4297, Entropy: 0.2416, Mean TD Error: 1.5550, Threshold: -29.2095
Original likelihood: -30.375625610351562
Adjusted likelihood: -30.375625610351562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2216)
State is out of distribution
Projection step: 0, Loss: 29.57032012939453
Projection step: 1, Loss: 28.772655487060547
Projection step: 2, Loss: 27.68463706970215
Projection step: 3, Loss: 26.46776580810547
Projection step: 4, Loss: 27.345678329467773
Projection step: 5, Loss: 25.846817016601562
Projection step: 6, Loss: 24.69365692138672
Projection step: 7, Loss: 25.82805061340332
Projection step: 8, Loss: 23.239164352416992
Projection step: 9, Loss: 24.669023513793945
Projection step: 10, Loss: 23.272987365722656
Projection step: 11, Loss: 21.636695861816406
Projection step: 12, Loss: 22.543045043945312
Projection step: 13, Loss: 22.20905113220215
Projection step: 14, Loss: 21.56932258605957
Final likelihood: tensor([-17.7514, -22.1005, -18.9916, -19.4117, -19.4431, -19.3667, -20.9293,
        -19.6330, -18.9844, -27.2366, -23.9344, -20.2697, -18.3202, -24.8900,
        -18.7754, -24.7896])
Final projection likelihood: -20.9267
1 mode projection succeeded
New goal: tensor([ 0.1220,  0.5020,  0.5767,  0.7976,  0.0265,  0.6299,  0.8703,  0.6955,
         1.4293,  0.1265,  0.1907,  0.9679, -0.0062, -0.0734, -1.4583],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -23.43689727783203
Adjusted likelihood: -23.43689727783203
Likelihood residual: 0.0
Original likelihood: -27.484031677246094
Adjusted likelihood: -27.484031677246094
Likelihood residual: 0.0
{'index': 27.484031677246094, 'thumb_middle': 23.43689727783203}
Current yaw: tensor([ 0.0006, -0.0939, -0.5068], device='cuda:1')
5 thumb_middle
tensor([ 1.5281e-01,  5.9411e-01,  5.0453e-01,  7.6681e-01,  2.2862e-03,
         6.8770e-01,  8.6292e-01,  8.5026e-01,  1.4070e+00,  1.3230e-01,
         1.1845e-01,  8.6092e-01,  6.4385e-04, -9.3908e-02, -5.0675e-01,
         4.0858e+00], device='cuda:1')
Solve time for step 1 9.14188063700567
Current ori: tensor([ 0.0006, -0.0939, -0.5068], device='cuda:1')
Index force: tensor([0.5909, 0.5684, 0.6272, 0.5073], device='cuda:1')
tensor([ 0.1403,  0.4989,  0.5895,  0.8334, -0.0487,  0.6418,  0.8357,  0.7138,
         1.3443,  0.0954,  0.0652,  0.8909,  0.0260, -0.0789, -0.5067,  4.0543],
       device='cuda:1')
Solve time for step 2 2.07120615299209
Current ori: tensor([ 0.0260, -0.0789, -0.5067], device='cuda:1')
Index force: tensor([0.5004, 0.5932, 0.5863], device='cuda:1')
tensor([ 0.1400,  0.5001,  0.5935,  0.8193, -0.0449,  0.6468,  0.8312,  0.6820,
         1.3554,  0.0788,  0.0483,  0.9197,  0.0229, -0.0793, -0.5067,  4.0388],
       device='cuda:1')
Solve time for step 3 1.9106656569929328
Current ori: tensor([ 0.0229, -0.0793, -0.5067], device='cuda:1')
Index force: tensor([0.5849, 0.5789], device='cuda:1')
tensor([ 0.1078,  0.5171,  0.5571,  0.7830, -0.0909,  0.6574,  0.8321,  0.6807,
         1.3538,  0.0836,  0.0707,  0.9040,  0.0122, -0.0619, -0.5067,  4.0071],
       device='cuda:1')
Solve time for step 4 1.828211359999841
Current ori: tensor([ 0.0122, -0.0619, -0.5067], device='cuda:1')
Index force: tensor([0.5729], device='cuda:1')
Storing RECOVERY transition: reward=0.0120 (scaled=0.0120), steps=0
Reward stats updated: mean -0.0117 -> -0.0115, std: 0.1557
Collected 136 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3941, Q2 Loss=1.3941, Entropy=0.0004, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4993
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=1.0719, Q2 Loss=1.0719, Entropy=0.0016, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6194
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7997, Q2 Loss=0.7997, Entropy=0.0020, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5826
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8973, Q2 Loss=0.8973, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2935
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7261, Q2 Loss=0.7261, Entropy=0.0012, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3356

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001472
Q1 loss: 0.977814
Q2 loss: 0.977814
Current threshold: -29.1647
Global Scale Offset: 0.7496
Reward stats: mean=-0.0115, std=0.1557, count=136
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 0.9778, Q2 Loss: 0.9778, Entropy: 0.0010, Mean TD Error: 0.8661, Threshold: -29.1647
Original likelihood: -25.276744842529297
Adjusted likelihood: -25.276744842529297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9957)
Current yaw: tensor([ 0.0151, -0.0529, -0.5085], device='cuda:1')
6 turn
Sampling time 3.7308620430121664
tensor([ 0.0842,  0.4996,  0.5649,  0.7679, -0.0361,  0.6694,  0.8902,  0.7011,
         1.4270,  0.1133,  0.1196,  0.9568,  0.0151, -0.0529, -0.5085,  4.0530],
       device='cuda:1')
Original likelihood: -22.5918025970459
Adjusted likelihood: -22.5918025970459
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.26626004499849
Current ori: tensor([ 0.0151, -0.0529, -0.5085], device='cuda:1')
Middle force: tensor([0.6283, 1.0674, 1.1527, 1.0630, 0.8932, 0.6413, 0.5414, 0.6679, 0.6234,
        0.7710, 0.5186, 0.5672], device='cuda:1')
Thumb force: tensor([1.7088, 0.5198, 0.5599, 0.6399, 0.7850, 0.5443, 0.9238, 0.5708, 0.5925,
        0.8103, 0.5618, 0.8982], device='cuda:1')
Index force: tensor([0.6358, 0.9111, 0.6178, 0.9775, 0.7665, 0.6317, 0.5978, 0.5565, 0.5795,
        0.6184, 0.5411, 0.5113], device='cuda:1')
Storing NORMAL transition: reward=0.0355 (scaled=0.0355), steps=1
Reward stats updated: mean -0.0115 -> -0.0112, std: 0.1552
Collected 137 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0679, Q2 Loss=1.0679, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3689
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=23.8421, Q2 Loss=23.8421, Entropy=0.0065, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1000
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6371, Q2 Loss=0.6371, Entropy=0.2908, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3427
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.1553, Q2 Loss=1.1553, Entropy=0.1179, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9530
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=7.8400, Q2 Loss=7.8400, Entropy=0.0063, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5742

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.9%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000025
Q1 loss: 6.908478
Q2 loss: 6.908478
Current threshold: -29.1338
Global Scale Offset: 0.7294
Reward stats: mean=-0.0112, std=0.1552, count=137
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 6.9085, Q2 Loss: 6.9085, Entropy: 0.0843, Mean TD Error: 2.6678, Threshold: -29.1338
tensor([ 0.1396,  0.4370,  0.7670,  0.6214,  0.0339,  0.7971,  0.7259,  0.8041,
         1.3408,  0.1955,  0.1386,  0.8852,  0.0060, -0.1072, -0.5531,  4.0397],
       device='cuda:1')
Original likelihood: -27.429126739501953
Adjusted likelihood: -27.429126739501953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8800)
Solve time for step 2 2.867027734988369
Current ori: tensor([ 0.0060, -0.1072, -0.5531], device='cuda:1')
Middle force: tensor([1.0646, 1.1387, 1.0951, 0.9081, 0.6453, 0.5405, 0.6768, 0.6290, 0.7809,
        0.5189, 0.5659], device='cuda:1')
Thumb force: tensor([0.5181, 0.5576, 0.6246, 0.7668, 0.5417, 0.9143, 0.5646, 0.5875, 0.8004,
        0.5589, 0.8886], device='cuda:1')
Index force: tensor([0.9018, 0.6176, 0.9360, 0.7472, 0.6226, 0.5944, 0.5513, 0.5730, 0.6088,
        0.5387, 0.5104], device='cuda:1')
Storing NORMAL transition: reward=0.0776 (scaled=0.0776), steps=1
Reward stats updated: mean -0.0112 -> -0.0106, std: 0.1548
Collected 138 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4926, Q2 Loss=0.4926, Entropy=0.1840, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3175
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=45.9676, Q2 Loss=45.9676, Entropy=0.0106, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.9277
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=5.6153, Q2 Loss=5.6153, Entropy=0.0159, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3214
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7979, Q2 Loss=0.7979, Entropy=0.0004, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2827
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=11.6664, Q2 Loss=11.6664, Entropy=0.0049, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1817

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 12.907948
Q2 loss: 12.907948
Current threshold: -29.1151
Global Scale Offset: 0.7180
Reward stats: mean=-0.0106, std=0.1548, count=138
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 12.9079, Q2 Loss: 12.9079, Entropy: 0.0431, Mean TD Error: 4.4062, Threshold: -29.1151
tensor([ 0.1066,  0.4614,  0.7383,  0.5493, -0.1170,  0.8907,  0.6803,  0.9258,
         1.3417,  0.3089,  0.2199,  0.7231, -0.0098, -0.0858, -0.6279,  4.0354],
       device='cuda:1')
Original likelihood: -24.574277877807617
Adjusted likelihood: -24.574277877807617
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9992)
Solve time for step 3 2.755257081007585
Current ori: tensor([-0.0098, -0.0858, -0.6279], device='cuda:1')
Middle force: tensor([1.1227, 1.0982, 0.9222, 0.6460, 0.5405, 0.6769, 0.6296, 0.7827, 0.5185,
        0.5638], device='cuda:1')
Thumb force: tensor([0.5556, 0.6229, 0.7628, 0.5407, 0.9027, 0.5623, 0.5857, 0.7972, 0.5585,
        0.8799], device='cuda:1')
Index force: tensor([0.6162, 0.9108, 0.7201, 0.6146, 0.5910, 0.5473, 0.5677, 0.6000, 0.5356,
        0.5096], device='cuda:1')
Storing NORMAL transition: reward=0.0723 (scaled=0.0723), steps=1
Reward stats updated: mean -0.0106 -> -0.0100, std: 0.1544
Collected 139 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5690, Q2 Loss=0.5690, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1844
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6146, Q2 Loss=0.6146, Entropy=0.0033, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4628
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1990, Q2 Loss=1.1990, Entropy=0.0110, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8375
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9806, Q2 Loss=0.9806, Entropy=0.0006, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8335
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=4.7560, Q2 Loss=4.7560, Entropy=0.1067, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2862

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.7%)
Q1 update: 0.04s (18.1%)
Q2 update: 0.05s (19.8%)
Actor update: 0.10s (41.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000011
Q1 loss: 1.623855
Q2 loss: 1.623855
Current threshold: -29.1041
Global Scale Offset: 0.7115
Reward stats: mean=-0.0100, std=0.1544, count=139
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.6239, Q2 Loss: 1.6239, Entropy: 0.0243, Mean TD Error: 1.5209, Threshold: -29.1041
tensor([ 0.0705,  0.4381,  0.7227,  0.5977, -0.1306,  0.8761,  0.7187,  0.9339,
         1.3700,  0.2758,  0.2440,  0.6383, -0.0113, -0.0847, -0.7020,  4.2153],
       device='cuda:1')
Original likelihood: -23.24654197692871
Adjusted likelihood: -23.24654197692871
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.617353337001987
Current ori: tensor([-0.0113, -0.0847, -0.7020], device='cuda:1')
Middle force: tensor([1.0991, 0.9422, 0.6494, 0.5400, 0.6812, 0.6310, 0.7855, 0.5182, 0.5614],
       device='cuda:1')
Thumb force: tensor([0.6158, 0.7535, 0.5392, 0.8920, 0.5588, 0.5832, 0.7923, 0.5579, 0.8733],
       device='cuda:1')
Index force: tensor([0.8885, 0.6951, 0.6069, 0.5883, 0.5425, 0.5622, 0.5925, 0.5325, 0.5088],
       device='cuda:1')
Storing NORMAL transition: reward=0.0150 (scaled=0.0150), steps=1
Reward stats updated: mean -0.0100 -> -0.0098, std: 0.1539
Collected 140 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7905, Q2 Loss=0.7905, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4355
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=5.7579, Q2 Loss=5.7579, Entropy=0.0044, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4308
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9235, Q2 Loss=0.9235, Entropy=0.0007, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2913
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8719, Q2 Loss=0.8719, Entropy=0.0028, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3861
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0258, Q2 Loss=1.0258, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4754

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.873893
Q2 loss: 1.873893
Current threshold: -29.0983
Global Scale Offset: 0.7080
Reward stats: mean=-0.0098, std=0.1539, count=140
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.8739, Q2 Loss: 1.8739, Entropy: 0.0016, Mean TD Error: 1.6038, Threshold: -29.0983
tensor([-0.1032,  0.3955,  0.7778,  0.6182, -0.1330,  0.9494,  0.6541,  0.7760,
         1.4214,  0.2000,  0.2678,  0.4874, -0.0433, -0.0786, -0.7187,  3.6065],
       device='cuda:1')
Original likelihood: -43.04231262207031
Adjusted likelihood: -43.04231262207031
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 39.26008224487305
Projection step: 1, Loss: 36.36212158203125
Projection step: 2, Loss: 34.66961669921875
Projection step: 3, Loss: 30.28909683227539
Projection step: 4, Loss: 27.483850479125977
Projection step: 5, Loss: 25.7027645111084
Projection step: 6, Loss: 25.05489730834961
Projection step: 7, Loss: 23.536008834838867
Projection step: 8, Loss: 23.11277198791504
Projection step: 9, Loss: 21.729915618896484
Projection step: 10, Loss: 21.995054244995117
Projection step: 11, Loss: 20.77588653564453
Projection step: 12, Loss: 21.154081344604492
Projection step: 13, Loss: 21.608129501342773
Projection step: 14, Loss: 20.92821502685547
Final likelihood: tensor([-20.1920, -18.9826, -23.7330, -23.0927, -20.5405, -23.2009, -21.6802,
        -19.5739, -24.1769, -17.4208, -19.7226, -18.1866, -23.7468, -17.4987,
        -17.9226, -25.2465])
Final projection likelihood: -20.9323
1 mode projection succeeded
New goal: tensor([-0.0123,  0.3412,  0.8643,  0.6044, -0.0824,  0.7498,  0.6119,  1.0949,
         1.4230,  0.0704,  0.2463,  0.4133, -0.0271, -0.0714, -0.2316],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -34.05963897705078
Adjusted likelihood: -34.05963897705078
Likelihood residual: 0.0
Original likelihood: -27.273462295532227
Adjusted likelihood: -27.273462295532227
Likelihood residual: 0.0
{'index': 27.273462295532227, 'thumb_middle': 34.05963897705078}
Current yaw: tensor([-0.0433, -0.0786, -0.7187], device='cuda:1')
7 index
tensor([-0.1032,  0.3955,  0.7778,  0.6182, -0.1330,  0.9494,  0.6541,  0.7760,
         1.4214,  0.2000,  0.2678,  0.4874, -0.0433, -0.0786, -0.7187,  3.6065],
       device='cuda:1')
Solve time for step 1 10.752456679008901
Current ori: tensor([-0.0433, -0.0786, -0.7187], device='cuda:1')
Middle force: tensor([0.5314, 0.5030, 0.5967, 0.5474], device='cuda:1')
Thumb force: tensor([0.5911, 0.5893, 0.5630, 0.6508], device='cuda:1')
tensor([-0.0523,  0.2976,  0.7665,  0.5622, -0.1435,  0.9593,  0.5816,  0.9415,
         1.4512,  0.1267,  0.2481,  0.5288, -0.0258, -0.0772, -0.7535,  3.7478],
       device='cuda:1')
Solve time for step 2 2.3445096549985465
Current ori: tensor([-0.0258, -0.0772, -0.7535], device='cuda:1')
Middle force: tensor([0.5028, 0.5950, 0.5457], device='cuda:1')
Thumb force: tensor([0.5869, 0.5618, 0.6501], device='cuda:1')
tensor([-0.0379,  0.2916,  0.7779,  0.5558, -0.1472,  0.9508,  0.5856,  0.9657,
         1.4630,  0.0999,  0.2435,  0.5413, -0.0195, -0.0754, -0.7664,  3.8857],
       device='cuda:1')
Solve time for step 3 2.200293119996786
Current ori: tensor([-0.0195, -0.0754, -0.7664], device='cuda:1')
Middle force: tensor([0.5063, 0.5737], device='cuda:1')
Thumb force: tensor([0.5283, 0.6179], device='cuda:1')
tensor([-0.0366,  0.2962,  0.7822,  0.5540, -0.1602,  0.9649,  0.5872,  0.9721,
         1.4730,  0.0915,  0.2276,  0.5401, -0.0229, -0.0776, -0.7865,  4.0082],
       device='cuda:1')
Solve time for step 4 2.1451253129926044
Current ori: tensor([-0.0229, -0.0776, -0.7865], device='cuda:1')
Middle force: tensor([0.5715], device='cuda:1')
Thumb force: tensor([0.6091], device='cuda:1')
Storing RECOVERY transition: reward=0.0860 (scaled=0.0215), steps=4
Reward stats updated: mean -0.0098 -> -0.0096, std: 0.1534
Collected 141 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9223, Q2 Loss=0.9223, Entropy=0.0001, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4201
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.5796, Q2 Loss=1.5796, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1246
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8438, Q2 Loss=0.8438, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2728
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=9.2476, Q2 Loss=9.2476, Entropy=0.0041, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9789
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.3042, Q2 Loss=1.3042, Entropy=0.0045, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0157

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.3%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 2.779502
Q2 loss: 2.779502
Current threshold: -29.0949
Global Scale Offset: 0.7059
Reward stats: mean=-0.0096, std=0.1534, count=141
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.7795, Q2 Loss: 2.7795, Entropy: 0.0018, Mean TD Error: 2.5624, Threshold: -29.0949
Original likelihood: -29.9794921875
Adjusted likelihood: -29.9794921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2662)
State is out of distribution
Projection step: 0, Loss: 29.549814224243164
Projection step: 1, Loss: 27.290191650390625
Projection step: 2, Loss: 25.66147804260254
Projection step: 3, Loss: 23.838871002197266
Projection step: 4, Loss: 23.681976318359375
Projection step: 5, Loss: 22.108989715576172
Projection step: 6, Loss: 21.580345153808594
Projection step: 7, Loss: 21.065032958984375
Projection step: 8, Loss: 20.635677337646484
Projection step: 9, Loss: 20.83822250366211
Projection step: 10, Loss: 20.07497215270996
Projection step: 11, Loss: 20.992761611938477
Projection step: 12, Loss: 20.036991119384766
Projection step: 13, Loss: 19.661579132080078
Projection step: 14, Loss: 19.489688873291016
Final likelihood: tensor([-19.9044, -18.8944, -24.1223, -18.0819, -18.5854, -19.1388, -18.7773,
        -18.2105, -19.5767, -22.3688, -28.5050, -18.8637, -17.7889, -20.4081,
        -21.8525, -19.0803])
Final projection likelihood: -20.2600
1 mode projection succeeded
New goal: tensor([ 0.0040,  0.3346,  0.8719,  0.6454, -0.0948,  0.7768,  0.5837,  1.1170,
         1.4657, -0.0030,  0.2785,  0.4133, -0.0150, -0.0624, -0.7925],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0018]], device='cuda:1')
Original likelihood: -25.088428497314453
Adjusted likelihood: -25.088428497314453
Likelihood residual: 0.0
Original likelihood: -26.5814208984375
Adjusted likelihood: -26.5814208984375
Likelihood residual: 0.0
{'index': 26.5814208984375, 'thumb_middle': 25.088428497314453}
Current yaw: tensor([-0.0191, -0.0693, -0.8031], device='cuda:1')
8 thumb_middle
tensor([-0.0489,  0.3434,  0.8226,  0.5782, -0.1767,  0.9647,  0.5889,  0.9734,
         1.4818,  0.0827,  0.2452,  0.5170, -0.0191, -0.0693, -0.8031,  4.0576],
       device='cuda:1')
Solve time for step 1 8.542851369013079
Current ori: tensor([-0.0191, -0.0693, -0.8031], device='cuda:1')
Index force: tensor([0.5027, 0.5503, 0.5885, 0.6012], device='cuda:1')
tensor([-0.0535,  0.3816,  0.8205,  0.5904, -0.1899,  0.8203,  0.5561,  1.0559,
         1.4370, -0.0185,  0.2193,  0.4202, -0.0421, -0.1565, -0.8064,  4.2414],
       device='cuda:1')
Solve time for step 2 1.9940441960061435
Current ori: tensor([-0.0421, -0.1565, -0.8064], device='cuda:1')
Index force: tensor([0.5670, 0.5765, 0.5874], device='cuda:1')
tensor([-0.0672,  0.4056,  0.8853,  0.6556, -0.1607,  0.8348,  0.5869,  1.0836,
         1.4151, -0.0276,  0.1761,  0.3914, -0.0538, -0.2015, -0.8317,  4.1695],
       device='cuda:1')
Solve time for step 3 1.965802592021646
Current ori: tensor([-0.0538, -0.2015, -0.8317], device='cuda:1')
Index force: tensor([0.5838, 0.5851], device='cuda:1')
tensor([-0.0952,  0.4375,  0.9473,  0.6688, -0.1300,  0.8416,  0.5838,  1.0885,
         1.3942, -0.0318,  0.1455,  0.3811, -0.0599, -0.2341, -0.8454,  3.9869],
       device='cuda:1')
Solve time for step 4 1.8829799889936112
Current ori: tensor([-0.0599, -0.2341, -0.8454], device='cuda:1')
Index force: tensor([0.5702], device='cuda:1')
Storing RECOVERY transition: reward=0.0715 (scaled=0.0179), steps=4
Reward stats updated: mean -0.0096 -> -0.0094, std: 0.1528
Collected 142 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.6287, Q2 Loss=1.6287, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6792
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7101, Q2 Loss=0.7101, Entropy=0.0554, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8785
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9985, Q2 Loss=0.9985, Entropy=0.0084, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1928
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6570, Q2 Loss=0.6570, Entropy=0.0002, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3452
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.8488, Q2 Loss=0.8488, Entropy=0.2799, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0968

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.0%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (18.8%)
Actor update: 0.10s (42.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000043
Q1 loss: 0.968636
Q2 loss: 0.968636
Current threshold: -29.0931
Global Scale Offset: 0.7051
Reward stats: mean=-0.0094, std=0.1528, count=142
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9686, Q2 Loss: 0.9686, Entropy: 0.0688, Mean TD Error: 0.6385, Threshold: -29.0931
Original likelihood: -36.6937370300293
Adjusted likelihood: -36.6937370300293
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.36101531982422
Projection step: 1, Loss: 38.98040008544922
Projection step: 2, Loss: 33.99947738647461
Projection step: 3, Loss: 32.52606201171875
Projection step: 4, Loss: 37.9703369140625
Projection step: 5, Loss: 37.23118209838867
Projection step: 6, Loss: 33.79536819458008
Projection step: 7, Loss: 37.48210144042969
Projection step: 8, Loss: 36.40816116333008
Projection step: 9, Loss: 36.904441833496094
Projection step: 10, Loss: 36.397239685058594
Projection step: 11, Loss: 36.028587341308594
Projection step: 12, Loss: 32.831787109375
Projection step: 13, Loss: 36.537174224853516
Projection step: 14, Loss: 36.195709228515625
Final likelihood: tensor([-39.2446, -24.1684, -39.2284, -32.8780, -40.2803, -29.9325, -21.9356,
        -32.8254, -37.1952, -35.9222, -34.1612, -32.7997, -36.8496, -23.6515,
        -37.2218, -31.5585])
Final projection likelihood: -33.1158
1 mode projection failed, trying anyway
New goal: tensor([-0.0628,  0.3624,  0.9072,  0.5830, -0.0273,  0.8608,  0.5876,  1.3483,
         1.4824, -0.0486,  0.1403,  0.2786, -0.0412, -0.1727,  0.1416],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0035]], device='cuda:1')
Original likelihood: -36.478111267089844
Adjusted likelihood: -36.478111267089844
Likelihood residual: 0.0
{'index': 36.478111267089844, 'thumb_middle': inf}
Current yaw: tensor([-0.0449, -0.1838, -0.8619], device='cuda:1')
9 index
tensor([-1.1012e-01,  4.8577e-01,  9.8834e-01,  6.9825e-01, -1.6288e-03,
         9.4491e-01,  6.1999e-01,  1.0860e+00,  1.4256e+00, -2.7872e-02,
         2.0135e-01,  3.9210e-01, -4.4945e-02, -1.8383e-01, -8.6191e-01,
         3.9560e+00], device='cuda:1')
Solve time for step 1 11.497606874996563
Current ori: tensor([-0.0449, -0.1838, -0.8619], device='cuda:1')
Middle force: tensor([0.5735, 0.5077, 0.5171, 0.5606], device='cuda:1')
Thumb force: tensor([0.5909, 0.5145, 0.6428, 0.6325], device='cuda:1')
tensor([-0.1259,  0.4424,  0.9099,  0.5886, -0.0157,  0.9920,  0.5278,  1.1731,
         1.4359, -0.0638,  0.1991,  0.3786, -0.0425, -0.1836, -0.8868,  4.0640],
       device='cuda:1')
Solve time for step 2 2.305667110020295
Current ori: tensor([-0.0425, -0.1836, -0.8868], device='cuda:1')
Middle force: tensor([0.5071, 0.5163, 0.5590], device='cuda:1')
Thumb force: tensor([0.5137, 0.6416, 0.6304], device='cuda:1')
tensor([-0.1285,  0.4543,  0.9050,  0.5815, -0.0126,  0.9952,  0.5204,  1.1938,
         1.4325, -0.0576,  0.1949,  0.3865, -0.0397, -0.1871, -0.9075,  4.1816],
       device='cuda:1')
Solve time for step 3 2.2101958590210415
Current ori: tensor([-0.0397, -0.1871, -0.9075], device='cuda:1')
Middle force: tensor([0.5157, 0.5578], device='cuda:1')
Thumb force: tensor([0.6352, 0.6274], device='cuda:1')
tensor([-0.1375,  0.4405,  0.9032,  0.5774, -0.0193,  0.9928,  0.5215,  1.2015,
         1.4400, -0.0699,  0.1980,  0.4006, -0.0303, -0.1819, -0.9301,  4.2462],
       device='cuda:1')
Solve time for step 4 2.136771307006711
Current ori: tensor([-0.0303, -0.1819, -0.9301], device='cuda:1')
Middle force: tensor([0.5559], device='cuda:1')
Thumb force: tensor([0.5251], device='cuda:1')
Storing RECOVERY transition: reward=0.1250 (scaled=0.0313), steps=4
Reward stats updated: mean -0.0094 -> -0.0091, std: 0.1523
Collected 143 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3464, Q2 Loss=1.3464, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5231
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7134, Q2 Loss=0.7134, Entropy=0.0393, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6864
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=4.8181, Q2 Loss=4.8181, Entropy=0.1191, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3771
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5536, Q2 Loss=0.5536, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1883
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.5740, Q2 Loss=1.5740, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1171

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000016
Q1 loss: 1.801109
Q2 loss: 1.801109
Current threshold: -29.0928
Global Scale Offset: 0.7053
Reward stats: mean=-0.0091, std=0.1523, count=143
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.8011, Q2 Loss: 1.8011, Entropy: 0.0317, Mean TD Error: 1.7784, Threshold: -29.0928
Original likelihood: -30.492868423461914
Adjusted likelihood: -30.492868423461914
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1614)
State is out of distribution
Projection step: 0, Loss: 35.890193939208984
Projection step: 1, Loss: 32.301578521728516
Projection step: 2, Loss: 33.31915283203125
Projection step: 3, Loss: 34.31829833984375
Projection step: 4, Loss: 36.343223571777344
Projection step: 5, Loss: 33.49570083618164
Projection step: 6, Loss: 33.84206771850586
Projection step: 7, Loss: 32.7987060546875
Projection step: 8, Loss: 30.508169174194336
Projection step: 9, Loss: 32.7527961730957
Projection step: 10, Loss: 33.893009185791016
Projection step: 11, Loss: 35.89411163330078
Projection step: 12, Loss: 33.837581634521484
Projection step: 13, Loss: 35.87825012207031
Projection step: 14, Loss: 35.630985260009766
Final likelihood: tensor([-39.7425, -27.6969, -38.1032, -40.3704, -38.2657, -26.4359, -28.5087,
        -36.1804, -39.0740, -31.0348, -38.8823, -37.0036, -38.1804, -35.8111,
        -38.8265, -32.7699])
Final projection likelihood: -35.4304
1 mode projection failed, trying anyway
New goal: tensor([-0.0486,  0.3825,  0.9310,  0.5426, -0.0412,  0.8944,  0.5340,  1.3693,
         1.4924, -0.0960,  0.1442,  0.3015, -0.0262, -0.1722,  0.0016],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -37.30690002441406
Adjusted likelihood: -37.30690002441406
Likelihood residual: 0.0
Original likelihood: -40.11930847167969
Adjusted likelihood: -40.11930847167969
Likelihood residual: 0.0
{'index': 40.11930847167969, 'thumb_middle': 37.30690002441406}
Current yaw: tensor([-0.0250, -0.1846, -0.9566], device='cuda:1')
10 thumb_middle
tensor([-0.0626,  0.4808,  0.9748,  0.6309, -0.0357,  1.0113,  0.5240,  1.1983,
         1.4374, -0.0652,  0.1952,  0.4116, -0.0250, -0.1846, -0.9566,  4.2780],
       device='cuda:1')
Solve time for step 1 9.08950479599298
Current ori: tensor([-0.0250, -0.1846, -0.9566], device='cuda:1')
Index force: tensor([0.5440, 0.5018, 0.5280, 0.5651], device='cuda:1')
tensor([-0.0742,  0.5164,  1.0338,  0.6123, -0.1016,  0.9283,  0.4885,  1.3013,
         1.3928, -0.1032,  0.0640,  0.3190, -0.0492, -0.2928, -0.9791,  4.2904],
       device='cuda:1')
Solve time for step 2 1.9827348820108455
Current ori: tensor([-0.0492, -0.2928, -0.9791], device='cuda:1')
Index force: tensor([0.5488, 0.5428, 0.5479], device='cuda:1')
tensor([-0.0938,  0.5791,  1.0773,  0.6163, -0.0953,  0.9556,  0.4967,  1.3371,
         1.3756, -0.1050,  0.0081,  0.2905, -0.0758, -0.3295, -0.9422,  4.1980],
       device='cuda:1')
Solve time for step 3 1.8770478870137595
Current ori: tensor([-0.0758, -0.3295, -0.9422], device='cuda:1')
Index force: tensor([0.5223, 0.5558], device='cuda:1')
tensor([-0.1095,  0.6101,  1.0980,  0.6111, -0.0849,  0.9682,  0.5111,  1.3423,
         1.3655, -0.1050, -0.0258,  0.2772, -0.0952, -0.3517, -0.8977,  4.0700],
       device='cuda:1')
Solve time for step 4 1.9471478240157012
Current ori: tensor([-0.0952, -0.3517, -0.8977], device='cuda:1')
Index force: tensor([0.5303], device='cuda:1')
Storing RECOVERY transition: reward=0.0035 (scaled=0.0009), steps=4
Reward stats updated: mean -0.0091 -> -0.0090, std: 0.1518
Collected 144 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0291, Q2 Loss=1.0291, Entropy=0.0004, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3250
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=0.8133, Q2 Loss=0.8133, Entropy=0.3472, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5731
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.5289, Q2 Loss=1.5289, Entropy=0.1316, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0817
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0554, Q2 Loss=1.0554, Entropy=0.0007, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3945
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8929, Q2 Loss=0.8929, Entropy=0.0058, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2483

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.6%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (19.7%)
Actor update: 0.13s (40.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000134
Q1 loss: 1.063897
Q2 loss: 1.063897
Current threshold: -29.0969
Global Scale Offset: 0.7062
Reward stats: mean=-0.0090, std=0.1518, count=144
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0639, Q2 Loss: 1.0639, Entropy: 0.0971, Mean TD Error: 1.5245, Threshold: -29.0969
Original likelihood: -187.2327117919922
Adjusted likelihood: -187.2327117919922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 187.2115478515625
Projection step: 1, Loss: 188.74282836914062
Projection step: 2, Loss: 165.02394104003906
Projection step: 3, Loss: 184.84165954589844
Projection step: 4, Loss: 186.96527099609375
Projection step: 5, Loss: 197.66336059570312
Projection step: 6, Loss: 167.69873046875
Projection step: 7, Loss: 192.6730499267578
Projection step: 8, Loss: 193.12020874023438
Projection step: 9, Loss: 183.3916015625
Projection step: 10, Loss: 173.63653564453125
Projection step: 11, Loss: 167.2928009033203
Projection step: 12, Loss: 188.8999481201172
Projection step: 13, Loss: 166.0551300048828
Projection step: 14, Loss: 217.69293212890625
Final likelihood: tensor([-277.8381, -147.3712, -210.0152, -101.3632, -123.2908, -147.2043,
        -124.5838, -174.1866, -221.1640, -208.1460, -219.3032, -219.0053,
        -241.5130, -185.5909, -280.6451, -196.6138])
Final projection likelihood: -192.3647
1 mode projection failed, trying anyway
New goal: tensor([-0.1182,  0.6397,  1.0942,  0.6453,  0.0066,  1.0372,  0.5987,  1.4093,
         1.3624, -0.0793,  0.0589,  0.2569, -0.0759, -0.2914, -0.5385],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0053]], device='cuda:1') tensor([[0.0077]], device='cuda:1')
Original likelihood: -200.58160400390625
Adjusted likelihood: -200.58160400390625
Likelihood residual: 0.0
Original likelihood: -201.93496704101562
Adjusted likelihood: -201.93496704101562
Likelihood residual: 0.0
{'index': 201.93496704101562, 'thumb_middle': 200.58160400390625}
Current yaw: tensor([-0.0784, -0.2921, -0.9198], device='cuda:1')
11 thumb_middle
tensor([-0.1261,  0.6471,  1.1053,  0.6329,  0.0066,  1.0858,  0.5727,  1.3667,
         1.3985, -0.1014,  0.0583,  0.2705, -0.0784, -0.2921, -0.9198,  4.0723],
       device='cuda:1')
Solve time for step 1 9.177791352994973
Current ori: tensor([-0.0784, -0.2921, -0.9198], device='cuda:1')
Index force: tensor([0.5905, 0.5626, 0.5522, 0.5589], device='cuda:1')
tensor([-0.1448,  0.7192,  1.1211,  0.6402, -0.0831,  1.0110,  0.5489,  1.3813,
         1.3429, -0.0855, -0.0262,  0.2410, -0.1239, -0.3685, -0.8786,  4.0419],
       device='cuda:1')
Solve time for step 2 1.972067740978673
Current ori: tensor([-0.1239, -0.3685, -0.8786], device='cuda:1')
Index force: tensor([0.5597, 0.5474, 0.5537], device='cuda:1')
tensor([-0.1500,  0.7533,  1.1382,  0.6526, -0.0783,  1.0408,  0.5583,  1.3884,
         1.3278, -0.0847, -0.0849,  0.2302, -0.1495, -0.4065, -0.8197,  3.9272],
       device='cuda:1')
Solve time for step 3 2.0226144310145173
Current ori: tensor([-0.1495, -0.4065, -0.8197], device='cuda:1')
Index force: tensor([0.5382, 0.5452], device='cuda:1')
tensor([-0.1785,  0.8491,  1.1472,  0.6326, -0.0643,  1.0734,  0.5656,  1.3807,
         1.3146, -0.0778, -0.1308,  0.2148, -0.1738, -0.4390, -0.7560,  3.7977],
       device='cuda:1')
Solve time for step 4 1.8416938240115996
Current ori: tensor([-0.1738, -0.4390, -0.7560], device='cuda:1')
Index force: tensor([0.5452], device='cuda:1')
Storing RECOVERY transition: reward=-0.2165 (scaled=-0.0541), steps=4
Reward stats updated: mean -0.0090 -> -0.0093, std: 0.1513
Collected 145 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5349, Q2 Loss=0.5349, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1804
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6192, Q2 Loss=0.6192, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3340
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9753, Q2 Loss=0.9753, Entropy=0.0043, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1940
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.9589, Q2 Loss=0.9589, Entropy=0.3468, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3222
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7998, Q2 Loss=0.7998, Entropy=0.0248, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2217

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.6%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (41.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000137
Q1 loss: 0.777604
Q2 loss: 0.777604
Current threshold: -29.0965
Global Scale Offset: 0.7070
Reward stats: mean=-0.0093, std=0.1513, count=145
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7776, Q2 Loss: 0.7776, Entropy: 0.0752, Mean TD Error: 0.4505, Threshold: -29.0965
Original likelihood: -359.79473876953125
Adjusted likelihood: -359.79473876953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 9
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
1 turn
Sampling time 3.939106214005733
tensor([ 1.5548e-01,  6.4337e-01,  5.5985e-01,  5.4186e-01, -1.3858e-01,
         5.4865e-01,  9.1466e-01,  9.1279e-01,  1.2574e+00,  2.3009e-01,
         2.5068e-01,  1.1761e+00, -9.0228e-04,  1.4547e-02, -4.3402e-02,
         1.9825e-01], device='cuda:1')
Original likelihood: -22.721664428710938
Adjusted likelihood: -22.721664428710938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.452739425003529
Current ori: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
Middle force: tensor([0.5086, 0.6559, 0.5296, 0.5094, 0.7824, 1.1017, 0.5855, 0.5453, 0.5118,
        0.5488, 0.5162, 0.5517], device='cuda:1')
Thumb force: tensor([0.8531, 0.7629, 1.6423, 2.5458, 0.8960, 1.8035, 0.6070, 0.6817, 0.5644,
        1.6567, 0.5934, 0.5880], device='cuda:1')
Index force: tensor([0.5136, 0.9096, 0.5933, 0.6042, 0.5828, 0.6121, 0.5924, 0.5060, 0.4818,
        0.7812, 0.5936, 0.6063], device='cuda:1')
Storing NORMAL transition: reward=0.0011 (scaled=0.0011), steps=1
Reward stats updated: mean -0.0093 -> -0.0093, std: 0.1508
Collected 146 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5460, Q2 Loss=0.5460, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0753
SAC Update 2/5: Actor Loss=-0.0017, Q1 Loss=0.9076, Q2 Loss=0.9076, Entropy=0.0640, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7513
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7489, Q2 Loss=0.7489, Entropy=0.0035, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4326
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.0368, Q2 Loss=1.0368, Entropy=0.0988, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8572
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1632, Q2 Loss=1.1632, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2504

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.3%)
Actor update: 0.12s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000349
Q1 loss: 0.880499
Q2 loss: 0.880499
Current threshold: -29.0841
Global Scale Offset: 0.7039
Reward stats: mean=-0.0093, std=0.1508, count=146
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.8805, Q2 Loss: 0.8805, Entropy: 0.0333, Mean TD Error: 0.6734, Threshold: -29.0841
tensor([ 0.1628,  0.6160,  0.6014,  0.5466, -0.1899,  0.5248,  0.9127,  0.9352,
         1.1994,  0.3076,  0.1740,  1.2096,  0.0046,  0.0078, -0.0444,  0.2283],
       device='cuda:1')
Original likelihood: -30.101184844970703
Adjusted likelihood: -30.101184844970703
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2360)
State is out of distribution
Projection step: 0, Loss: 30.806459426879883
Projection step: 1, Loss: 25.769094467163086
Projection step: 2, Loss: 21.18636703491211
Projection step: 3, Loss: 17.443477630615234
Projection step: 4, Loss: 14.84675121307373
Final likelihood: tensor([-13.8581, -14.5094,  -9.5582,  -9.9642, -16.2966, -14.9377, -20.1050,
        -11.9731, -18.3551, -15.3642, -13.3428, -20.0827, -16.3165, -17.0503,
        -12.3343, -13.4999])
Final projection likelihood: -14.8468
1 mode projection succeeded
New goal: tensor([ 0.1221,  0.5997,  0.5518,  0.5657, -0.1059,  0.5519,  0.8894,  0.9390,
         1.2762,  0.3192,  0.2119,  1.1650,  0.0031,  0.0120, -1.0764],
       device='cuda:1')
tensor([[0.0097]], device='cuda:1') tensor([[0.0072]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -18.01412582397461
Adjusted likelihood: -18.01412582397461
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.01412582397461}
Current yaw: tensor([ 0.0046,  0.0078, -0.0444], device='cuda:1')
2 thumb_middle
tensor([ 0.1628,  0.6160,  0.6014,  0.5466, -0.1899,  0.5248,  0.9127,  0.9352,
         1.1994,  0.3076,  0.1740,  1.2096,  0.0046,  0.0078, -0.0444,  0.2283],
       device='cuda:1')
Solve time for step 1 9.400625496986322
Current ori: tensor([ 0.0046,  0.0078, -0.0444], device='cuda:1')
Index force: tensor([0.5821, 0.6004, 0.5742, 0.6033], device='cuda:1')
tensor([ 0.1456,  0.6286,  0.5637,  0.5525, -0.2288,  0.5164,  0.8532,  0.9150,
         1.2265,  0.2993,  0.1311,  1.1457,  0.0020,  0.0167, -0.0444,  0.2101],
       device='cuda:1')
Solve time for step 2 2.132448154006852
Current ori: tensor([ 0.0020,  0.0167, -0.0444], device='cuda:1')
Index force: tensor([0.5943, 0.5707, 0.5986], device='cuda:1')
tensor([ 0.1313,  0.6260,  0.5514,  0.5538, -0.2342,  0.5232,  0.8475,  0.9092,
         1.2502,  0.3045,  0.1255,  1.1328,  0.0030,  0.0250, -0.0444,  0.1861],
       device='cuda:1')
Solve time for step 3 2.024442405003356
Current ori: tensor([ 0.0030,  0.0250, -0.0444], device='cuda:1')
Index force: tensor([0.5651, 0.5929], device='cuda:1')
tensor([ 0.1436,  0.6292,  0.5546,  0.5642, -0.2305,  0.5297,  0.8492,  0.9137,
         1.2489,  0.3030,  0.1188,  1.1292,  0.0028,  0.0182, -0.0444,  0.2075],
       device='cuda:1')
Solve time for step 4 1.9739930039795581
Current ori: tensor([ 0.0028,  0.0182, -0.0444], device='cuda:1')
Index force: tensor([0.5555], device='cuda:1')
Storing RECOVERY transition: reward=-0.0083 (scaled=-0.0083), steps=1
Reward stats updated: mean -0.0093 -> -0.0092, std: 0.1503
Collected 147 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.0218, Q2 Loss=1.0218, Entropy=0.1542, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6252
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=3.8479, Q2 Loss=3.8479, Entropy=0.0042, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3612
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=4.6714, Q2 Loss=4.6714, Entropy=0.1199, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4499
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.9615, Q2 Loss=0.9615, Entropy=0.1248, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2999
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=1.1681, Q2 Loss=1.1681, Entropy=0.3479, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2235

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (18.1%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000159
Q1 loss: 2.334157
Q2 loss: 2.334157
Current threshold: -29.0784
Global Scale Offset: 0.7027
Reward stats: mean=-0.0092, std=0.1503, count=147
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 2.3342, Q2 Loss: 2.3342, Entropy: 0.1502, Mean TD Error: 3.3919, Threshold: -29.0784
Original likelihood: -25.185707092285156
Adjusted likelihood: -25.185707092285156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9971)
Current yaw: tensor([ 0.0046,  0.0345, -0.0371], device='cuda:1')
3 turn
Sampling time 3.798619580018567
tensor([ 0.1109,  0.6218,  0.5362,  0.5538, -0.1838,  0.5605,  0.8833,  0.9080,
         1.3025,  0.3241,  0.2051,  1.1634,  0.0046,  0.0345, -0.0371,  0.1948],
       device='cuda:1')
Original likelihood: -25.85553741455078
Adjusted likelihood: -25.85553741455078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9888)
Solve time for step 1 14.3889278100105
Current ori: tensor([ 0.0046,  0.0345, -0.0371], device='cuda:1')
Middle force: tensor([1.3301, 0.5075, 0.4957, 0.5055, 0.5976, 0.5430, 1.1099, 0.8327, 0.7839,
        0.5804, 0.4908, 0.5046], device='cuda:1')
Thumb force: tensor([1.9550, 1.9486, 1.4042, 0.5848, 1.1549, 0.7909, 1.4350, 0.5537, 0.7831,
        0.7054, 0.6435, 0.9952], device='cuda:1')
Index force: tensor([0.5543, 0.8099, 0.7711, 0.5879, 0.5295, 0.5253, 0.5513, 0.5183, 0.5747,
        0.5485, 0.6284, 0.5439], device='cuda:1')
Storing NORMAL transition: reward=-0.1102 (scaled=-0.1102), steps=1
Reward stats updated: mean -0.0092 -> -0.0099, std: 0.1500
Collected 148 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.7252, Q2 Loss=0.7252, Entropy=0.3746, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3663
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5379, Q2 Loss=0.5379, Entropy=0.2725, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0366
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=1.0766, Q2 Loss=1.0766, Entropy=0.3461, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7157
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6018, Q2 Loss=0.6018, Entropy=0.0308, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6041
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0262, Q2 Loss=1.0262, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4776

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (14.9%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.5%)
Actor update: 0.13s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000174
Q1 loss: 0.793538
Q2 loss: 0.793538
Current threshold: -29.0810
Global Scale Offset: 0.7032
Reward stats: mean=-0.0099, std=0.1500, count=148
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.7935, Q2 Loss: 0.7935, Entropy: 0.2048, Mean TD Error: 0.4401, Threshold: -29.0810
tensor([ 0.1283,  0.6594,  0.4820,  0.6008, -0.1244,  0.7125,  0.7097,  0.7446,
         1.3077,  0.2703,  0.1742,  1.1999, -0.0120,  0.0211,  0.0737,  0.1858],
       device='cuda:1')
Original likelihood: -24.777271270751953
Adjusted likelihood: -24.777271270751953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9988)
Solve time for step 2 3.218030892981915
Current ori: tensor([-0.0120,  0.0211,  0.0737], device='cuda:1')
Middle force: tensor([0.5064, 0.5007, 0.5047, 0.5932, 0.5376, 1.0900, 0.8225, 0.7706, 0.5757,
        0.4982, 0.5041], device='cuda:1')
Thumb force: tensor([1.9123, 1.3715, 0.5855, 1.1363, 0.7904, 1.4064, 0.5515, 0.7798, 0.7015,
        0.6678, 0.9943], device='cuda:1')
Index force: tensor([0.7994, 0.7715, 0.5864, 0.5279, 0.5232, 0.5491, 0.5173, 0.5713, 0.5465,
        0.6415, 0.5411], device='cuda:1')
Storing NORMAL transition: reward=-0.0141 (scaled=-0.0141), steps=1
Reward stats updated: mean -0.0099 -> -0.0100, std: 0.1495
Collected 149 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2776, Q2 Loss=1.2776, Entropy=0.0003, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5025
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5988, Q2 Loss=0.5988, Entropy=0.0004, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2069
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7254, Q2 Loss=0.7254, Entropy=0.0045, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3870
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=2.2989, Q2 Loss=2.2989, Entropy=0.0041, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2257
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.1497, Q2 Loss=1.1497, Entropy=0.3888, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6492

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.1%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (20.5%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000065
Q1 loss: 1.210083
Q2 loss: 1.210083
Current threshold: -29.0793
Global Scale Offset: 0.7038
Reward stats: mean=-0.0100, std=0.1495, count=149
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2101, Q2 Loss: 1.2101, Entropy: 0.0796, Mean TD Error: 1.5943, Threshold: -29.0793
tensor([ 0.1411,  0.6273,  0.5071,  0.6584, -0.1229,  0.7631,  0.6422,  0.7632,
         1.2708,  0.3252,  0.1579,  1.2858, -0.0020,  0.0195,  0.0880,  0.1911],
       device='cuda:1')
Original likelihood: -26.613327026367188
Adjusted likelihood: -26.613327026367188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9594)
Solve time for step 3 3.0482605549914297
Current ori: tensor([-0.0020,  0.0195,  0.0880], device='cuda:1')
Middle force: tensor([0.5006, 0.5041, 0.5892, 0.5334, 1.0693, 0.8122, 0.7605, 0.5726, 0.4999,
        0.5036], device='cuda:1')
Thumb force: tensor([1.3469, 0.5848, 1.1189, 0.7889, 1.3831, 0.5503, 0.7733, 0.6955, 0.6720,
        0.9947], device='cuda:1')
Index force: tensor([0.7602, 0.5825, 0.5263, 0.5211, 0.5466, 0.5160, 0.5681, 0.5445, 0.6520,
        0.5383], device='cuda:1')
Storing NORMAL transition: reward=0.1480 (scaled=0.1480), steps=1
Reward stats updated: mean -0.0100 -> -0.0089, std: 0.1496
Collected 150 transitions for RL
SAC Update 1/5: Actor Loss=-0.0036, Q1 Loss=1.7791, Q2 Loss=1.7791, Entropy=0.0616, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6360
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0895, Q2 Loss=1.0895, Entropy=0.0398, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5444
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.3088, Q2 Loss=1.3088, Entropy=0.0954, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0721
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.9930, Q2 Loss=0.9930, Entropy=0.3237, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1340
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6842, Q2 Loss=0.6842, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2220

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.0%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.07s (20.2%)
Actor update: 0.14s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000823
Q1 loss: 1.170905
Q2 loss: 1.170905
Current threshold: -29.0561
Global Scale Offset: 0.6957
Reward stats: mean=-0.0089, std=0.1496, count=150
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 1.1709, Q2 Loss: 1.1709, Entropy: 0.1041, Mean TD Error: 0.7217, Threshold: -29.0561
tensor([ 0.1492,  0.6087,  0.5099,  0.7216, -0.2443,  0.8190,  0.6527,  0.6762,
         1.3037,  0.7014,  0.0886,  1.1829,  0.0043,  0.0191, -0.0602,  0.4116],
       device='cuda:1')
Original likelihood: -37.70468521118164
Adjusted likelihood: -37.70468521118164
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.54027557373047
Projection step: 1, Loss: 33.20654296875
Projection step: 2, Loss: 35.790733337402344
Projection step: 3, Loss: 30.502607345581055
Projection step: 4, Loss: 27.382179260253906
Projection step: 5, Loss: 26.73214340209961
Projection step: 6, Loss: 23.223066329956055
Projection step: 7, Loss: 22.573532104492188
Projection step: 8, Loss: 20.661909103393555
Projection step: 9, Loss: 18.69223403930664
Projection step: 10, Loss: 18.545726776123047
Projection step: 11, Loss: 16.713577270507812
Projection step: 12, Loss: 15.751834869384766
Projection step: 13, Loss: 14.497112274169922
Final likelihood: tensor([-14.4403, -14.7825, -13.6146, -13.4984, -13.4973, -14.0745, -17.2620,
        -13.4973, -14.5084, -14.2237, -14.9724, -13.9729, -13.6495, -16.2727,
        -15.1119, -14.5754])
Final projection likelihood: -14.4971
1 mode projection succeeded
New goal: tensor([ 1.1492e-01,  5.6256e-01,  5.3533e-01,  7.9835e-01, -9.3450e-02,
         6.6939e-01,  8.6474e-01,  7.2704e-01,  1.3489e+00,  4.4954e-01,
         1.6021e-01,  1.2146e+00,  1.7309e-03,  1.5251e-02,  1.8581e+00],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0100]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -21.05061912536621
Adjusted likelihood: -21.05061912536621
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.05061912536621}
Current yaw: tensor([ 0.0043,  0.0191, -0.0602], device='cuda:1')
4 thumb_middle
tensor([ 0.1492,  0.6087,  0.5099,  0.7216, -0.2443,  0.8190,  0.6527,  0.6762,
         1.3037,  0.7014,  0.0886,  1.1829,  0.0043,  0.0191, -0.0602,  0.4116],
       device='cuda:1')
Solve time for step 1 9.921627959993202
Current ori: tensor([ 0.0043,  0.0191, -0.0602], device='cuda:1')
Index force: tensor([0.5302, 0.5063, 0.5941, 0.5983], device='cuda:1')
tensor([ 0.1471,  0.6078,  0.4981,  0.7400, -0.2400,  0.6750,  0.7773,  0.6961,
         1.2761,  0.4877,  0.0437,  1.1573,  0.0061,  0.0203, -0.0602,  0.4317],
       device='cuda:1')
Solve time for step 2 2.1464128519874066
Current ori: tensor([ 0.0061,  0.0203, -0.0602], device='cuda:1')
Index force: tensor([0.5060, 0.5904, 0.5952], device='cuda:1')
tensor([ 0.1487,  0.6058,  0.4993,  0.7464, -0.2397,  0.6633,  0.8076,  0.6898,
         1.2902,  0.4500,  0.0362,  1.1545,  0.0071,  0.0196, -0.0602,  0.4355],
       device='cuda:1')
Solve time for step 3 2.066864638007246
Current ori: tensor([ 0.0071,  0.0196, -0.0602], device='cuda:1')
Index force: tensor([0.5847, 0.5911], device='cuda:1')
tensor([ 0.1424,  0.5637,  0.5321,  0.7845, -0.2416,  0.6602,  0.8138,  0.6933,
         1.2992,  0.4392,  0.0375,  1.1563,  0.0199,  0.0253, -0.0602,  0.4375],
       device='cuda:1')
Solve time for step 4 2.013495449995389
Current ori: tensor([ 0.0199,  0.0253, -0.0602], device='cuda:1')
Index force: tensor([0.5818], device='cuda:1')
Storing RECOVERY transition: reward=-0.0147 (scaled=-0.0049), steps=3
Reward stats updated: mean -0.0089 -> -0.0089, std: 0.1491
Collected 151 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=0.6209, Q2 Loss=0.6209, Entropy=0.2868, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3570
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0288, Q2 Loss=1.0288, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1942
SAC Update 3/5: Actor Loss=-0.0098, Q1 Loss=0.7478, Q2 Loss=0.7478, Entropy=0.0856, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8767
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.0398, Q2 Loss=1.0398, Entropy=0.1867, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5170
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.3537, Q2 Loss=1.3537, Entropy=0.2762, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5763

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (19.4%)
Q2 update: 0.05s (18.8%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002098
Q1 loss: 0.958181
Q2 loss: 0.958181
Current threshold: -29.0178
Global Scale Offset: 0.6736
Reward stats: mean=-0.0089, std=0.1491, count=151
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 0.9582, Q2 Loss: 0.9582, Entropy: 0.1671, Mean TD Error: 0.9043, Threshold: -29.0178
Original likelihood: -28.430347442626953
Adjusted likelihood: -28.430347442626953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6661)
Current yaw: tensor([ 0.0250,  0.0353, -0.0469], device='cuda:1')
5 turn
Sampling time 3.727144584991038
tensor([ 0.1121,  0.5595,  0.5145,  0.7700, -0.1948,  0.6860,  0.8449,  0.7116,
         1.3543,  0.4471,  0.0948,  1.1941,  0.0250,  0.0353, -0.0469,  0.2747],
       device='cuda:1')
Original likelihood: -26.30911636352539
Adjusted likelihood: -26.30911636352539
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9760)
Solve time for step 1 14.382840987003874
Current ori: tensor([ 0.0250,  0.0353, -0.0469], device='cuda:1')
Middle force: tensor([0.6794, 0.6527, 0.5386, 0.5677, 1.4359, 0.4943, 0.4878, 0.5071, 0.5034,
        0.6873, 0.8635, 0.5873], device='cuda:1')
Thumb force: tensor([1.6083, 0.5525, 1.3443, 3.0780, 1.1393, 0.5428, 0.7340, 0.5424, 0.5514,
        0.9409, 0.5301, 0.6047], device='cuda:1')
Index force: tensor([0.5184, 0.5196, 0.7138, 0.7308, 0.5805, 0.6911, 0.7346, 0.5971, 0.5472,
        0.5579, 0.5310, 0.6140], device='cuda:1')
Storing NORMAL transition: reward=0.0237 (scaled=0.0237), steps=1
Reward stats updated: mean -0.0089 -> -0.0087, std: 0.1486
Collected 152 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7286, Q2 Loss=0.7286, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5347
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6188, Q2 Loss=0.6188, Entropy=0.0439, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2251
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=3.0605, Q2 Loss=3.0605, Entropy=0.0022, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3408
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8705, Q2 Loss=0.8705, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1595
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=9.1264, Q2 Loss=9.1264, Entropy=0.0019, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1761

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.1%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (19.5%)
Actor update: 0.13s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000004
Q1 loss: 2.880960
Q2 loss: 2.880960
Current threshold: -28.9806
Global Scale Offset: 0.6522
Reward stats: mean=-0.0087, std=0.1486, count=152
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.8810, Q2 Loss: 2.8810, Entropy: 0.0096, Mean TD Error: 2.6872, Threshold: -28.9806
tensor([ 0.0772,  0.5107,  0.5690,  0.7257, -0.2063,  0.6407,  0.7893,  0.9750,
         1.4625,  0.4176,  0.0032,  0.9707,  0.0512,  0.0342, -0.0726, -0.4668],
       device='cuda:1')
Original likelihood: -34.945281982421875
Adjusted likelihood: -34.945281982421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 33.53411865234375
Projection step: 1, Loss: 31.959087371826172
Projection step: 2, Loss: 30.406883239746094
Projection step: 3, Loss: 28.806610107421875
Projection step: 4, Loss: 27.162841796875
Projection step: 5, Loss: 26.02215576171875
Projection step: 6, Loss: 24.810718536376953
Projection step: 7, Loss: 23.450660705566406
Projection step: 8, Loss: 21.932247161865234
Projection step: 9, Loss: 20.98836326599121
Projection step: 10, Loss: 19.962848663330078
Projection step: 11, Loss: 19.68155288696289
Projection step: 12, Loss: 18.73366928100586
Projection step: 13, Loss: 17.875625610351562
Projection step: 14, Loss: 15.93958854675293
Final likelihood: tensor([-14.7753, -13.9051, -16.4801, -15.8474, -15.0448, -14.3477, -15.9061,
        -14.9663, -15.3318, -16.9909, -15.4572, -19.2134, -13.4285, -15.4532,
        -14.7072, -19.1861])
Final projection likelihood: -15.6901
1 mode projection succeeded
New goal: tensor([ 0.0599,  0.5709,  0.5408,  0.6093, -0.0958,  0.5249,  0.7723,  0.8500,
         1.4069,  0.3527,  0.1597,  1.0677,  0.0354,  0.0239, -1.8485],
       device='cuda:1')
tensor([[0.0120]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -20.203536987304688
Adjusted likelihood: -20.203536987304688
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.203536987304688}
Current yaw: tensor([ 0.0512,  0.0342, -0.0726], device='cuda:1')
6 thumb_middle
tensor([ 0.0772,  0.5107,  0.5690,  0.7257, -0.2063,  0.6407,  0.7893,  0.9750,
         1.4625,  0.4176,  0.0032,  0.9707,  0.0512,  0.0342, -0.0726, -0.4668],
       device='cuda:1')
Solve time for step 1 9.348264343017945
Current ori: tensor([ 0.0512,  0.0342, -0.0726], device='cuda:1')
Index force: tensor([0.5457, 0.5862, 0.5013, 0.5548], device='cuda:1')
tensor([ 0.0741,  0.5052,  0.5902,  0.6933, -0.2105,  0.5566,  0.7456,  0.8636,
         1.3958,  0.3732,  0.0494,  1.0124,  0.0493,  0.0358, -0.0726, -0.4778],
       device='cuda:1')
Solve time for step 2 2.1287961439811625
Current ori: tensor([ 0.0493,  0.0358, -0.0726], device='cuda:1')
Index force: tensor([0.5942, 0.5015, 0.5559], device='cuda:1')
tensor([ 0.0704,  0.5106,  0.5663,  0.7202, -0.2021,  0.5512,  0.7479,  0.8444,
         1.4011,  0.3624,  0.0430,  1.0244,  0.0506,  0.0381, -0.0726, -0.4751],
       device='cuda:1')
Solve time for step 3 1.9242274099960923
Current ori: tensor([ 0.0506,  0.0381, -0.0726], device='cuda:1')
Index force: tensor([0.5013, 0.5509], device='cuda:1')
tensor([ 0.0643,  0.5216,  0.5630,  0.6840, -0.2018,  0.5354,  0.7539,  0.8435,
         1.3972,  0.3552,  0.0556,  1.0195,  0.0448,  0.0402, -0.0726, -0.4975],
       device='cuda:1')
Solve time for step 4 2.023780350020388
Current ori: tensor([ 0.0448,  0.0402, -0.0726], device='cuda:1')
Index force: tensor([0.5415], device='cuda:1')
Storing RECOVERY transition: reward=0.0024 (scaled=0.0024), steps=1
Reward stats updated: mean -0.0087 -> -0.0086, std: 0.1481
Collected 153 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=9.1764, Q2 Loss=9.1764, Entropy=0.0018, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1968
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7893, Q2 Loss=0.7893, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3754
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.6953, Q2 Loss=0.6953, Entropy=0.6831, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5078
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9159, Q2 Loss=0.9159, Entropy=0.0289, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1996
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7259, Q2 Loss=0.7259, Entropy=0.0539, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4812

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.2%)
Q1 update: 0.07s (20.4%)
Q2 update: 0.07s (20.3%)
Actor update: 0.13s (41.2%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000155
Q1 loss: 2.460569
Q2 loss: 2.460569
Current threshold: -28.9533
Global Scale Offset: 0.6400
Reward stats: mean=-0.0086, std=0.1481, count=153
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 2.4606, Q2 Loss: 2.4606, Entropy: 0.1536, Mean TD Error: 1.5521, Threshold: -28.9533
Original likelihood: -24.18977165222168
Adjusted likelihood: -24.18977165222168
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Current yaw: tensor([ 0.0357,  0.0374, -0.0739], device='cuda:1')
7 turn
Sampling time 3.7412084199895617
tensor([ 0.0506,  0.5523,  0.5340,  0.6334, -0.1284,  0.5758,  0.7898,  0.8521,
         1.4406,  0.3582,  0.1011,  1.0671,  0.0357,  0.0374, -0.0739, -0.5274],
       device='cuda:1')
Original likelihood: -23.62618637084961
Adjusted likelihood: -23.62618637084961
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.798302582988981
Current ori: tensor([ 0.0357,  0.0374, -0.0739], device='cuda:1')
Middle force: tensor([0.5169, 0.5668, 0.5158, 0.9814, 0.5335, 0.4759, 0.5844, 0.5343, 0.7729,
        0.5740, 0.5242, 0.5183], device='cuda:1')
Thumb force: tensor([0.7502, 1.7658, 0.5750, 1.2599, 0.8747, 0.5825, 0.5503, 0.5480, 0.6565,
        0.5798, 0.5716, 0.5759], device='cuda:1')
Index force: tensor([0.9547, 0.7402, 0.5562, 0.5296, 0.5419, 0.6423, 0.4783, 0.6168, 0.7688,
        0.5981, 0.6512, 0.6409], device='cuda:1')
Storing NORMAL transition: reward=0.0332 (scaled=0.0332), steps=1
Reward stats updated: mean -0.0086 -> -0.0083, std: 0.1477
Collected 154 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0442, Q2 Loss=1.0442, Entropy=0.1037, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6743
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.5797, Q2 Loss=0.5797, Entropy=0.2438, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6219
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7760, Q2 Loss=0.7760, Entropy=0.0077, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4466
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9689, Q2 Loss=0.9689, Entropy=0.0020, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1932
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7237, Q2 Loss=0.7237, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4087

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.8%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.07s (20.6%)
Actor update: 0.14s (41.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000050
Q1 loss: 0.818483
Q2 loss: 0.818483
Current threshold: -28.9372
Global Scale Offset: 0.6338
Reward stats: mean=-0.0083, std=0.1477, count=154
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8185, Q2 Loss: 0.8185, Entropy: 0.0714, Mean TD Error: 0.4689, Threshold: -28.9372
tensor([ 0.0679,  0.5745,  0.5110,  0.6505, -0.1190,  0.6055,  0.7484,  0.8753,
         1.4342,  0.3901,  0.0969,  1.0527,  0.0308,  0.0304, -0.1064, -0.4997],
       device='cuda:1')
Original likelihood: -22.160686492919922
Adjusted likelihood: -22.160686492919922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.147970380989136
Current ori: tensor([ 0.0308,  0.0304, -0.1064], device='cuda:1')
Middle force: tensor([0.5592, 0.5161, 0.9568, 0.5302, 0.4984, 0.5832, 0.5313, 0.7485, 0.5675,
        0.5182, 0.5161], device='cuda:1')
Thumb force: tensor([1.7169, 0.5644, 1.2328, 0.8601, 0.5899, 0.5505, 0.5454, 0.6596, 0.5772,
        0.5731, 0.5742], device='cuda:1')
Index force: tensor([0.7219, 0.5545, 0.5267, 0.5390, 0.6498, 0.5020, 0.6135, 0.7522, 0.5963,
        0.6473, 0.6357], device='cuda:1')
Storing NORMAL transition: reward=0.1091 (scaled=0.1091), steps=1
Reward stats updated: mean -0.0083 -> -0.0076, std: 0.1475
Collected 155 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1014, Q2 Loss=1.1014, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7536
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=22.7863, Q2 Loss=22.7863, Entropy=0.0013, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6156
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9612, Q2 Loss=0.9612, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6850
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=22.4287, Q2 Loss=22.4287, Entropy=0.0014, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3583
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=8.8561, Q2 Loss=8.8561, Entropy=0.0012, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.2298

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.2%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 11.226728
Q2 loss: 11.226728
Current threshold: -28.9281
Global Scale Offset: 0.6302
Reward stats: mean=-0.0076, std=0.1475, count=155
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 11.2267, Q2 Loss: 11.2267, Entropy: 0.0008, Mean TD Error: 3.7285, Threshold: -28.9281
tensor([ 0.0862,  0.5950,  0.4975,  0.6554, -0.1105,  0.5827,  0.7672,  0.9344,
         1.4782,  0.3141,  0.0803,  0.9947,  0.0270,  0.0185, -0.2150, -0.3340],
       device='cuda:1')
Original likelihood: -19.140541076660156
Adjusted likelihood: -19.140541076660156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 3.016363390022889
Current ori: tensor([ 0.0270,  0.0185, -0.2150], device='cuda:1')
Middle force: tensor([0.5014, 0.9305, 0.5287, 0.5004, 0.5659, 0.5256, 0.7499, 0.5819, 1.1139,
        0.5612], device='cuda:1')
Thumb force: tensor([0.5762, 1.1694, 0.8314, 0.5825, 0.5377, 0.5416, 0.6663, 0.5363, 0.5399,
        0.5981], device='cuda:1')
Index force: tensor([0.5313, 0.5215, 0.5353, 0.6385, 0.5013, 0.5952, 0.7499, 0.5339, 0.5951,
        0.5545], device='cuda:1')
Storing NORMAL transition: reward=0.0783 (scaled=0.0783), steps=1
Reward stats updated: mean -0.0076 -> -0.0070, std: 0.1472
Collected 156 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=4.7832, Q2 Loss=4.7832, Entropy=0.0012, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6276
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1281, Q2 Loss=1.1281, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6580
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=4.9155, Q2 Loss=4.9155, Entropy=0.0644, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6627
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7559, Q2 Loss=0.7559, Entropy=0.0003, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7438
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6872, Q2 Loss=0.6872, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5830

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (18.2%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000006
Q1 loss: 2.453972
Q2 loss: 2.453972
Current threshold: -28.9231
Global Scale Offset: 0.6282
Reward stats: mean=-0.0070, std=0.1472, count=156
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.4540, Q2 Loss: 2.4540, Entropy: 0.0132, Mean TD Error: 2.6550, Threshold: -28.9231
tensor([ 0.0601,  0.5851,  0.4646,  0.6819, -0.0573,  0.5542,  0.8616,  0.9572,
         1.4427,  0.3353,  0.1246,  0.9261,  0.0436, -0.0234, -0.2959, -1.2061],
       device='cuda:1')
Original likelihood: -23.808265686035156
Adjusted likelihood: -23.808265686035156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.6552992700017057
Current ori: tensor([ 0.0436, -0.0234, -0.2959], device='cuda:1')
Middle force: tensor([1.3420, 1.2204, 0.6672, 0.5803, 0.7204, 0.5080, 0.5205, 0.5016, 0.5020],
       device='cuda:1')
Thumb force: tensor([0.6301, 0.9391, 1.0169, 0.8078, 0.5637, 0.5522, 0.5042, 0.5956, 0.5213],
       device='cuda:1')
Index force: tensor([0.5150, 0.8534, 0.7623, 0.5223, 0.5086, 0.5226, 0.5988, 0.6374, 0.6970],
       device='cuda:1')
Storing NORMAL transition: reward=0.0003 (scaled=0.0003), steps=1
Reward stats updated: mean -0.0070 -> -0.0070, std: 0.1467
Collected 157 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=21.8288, Q2 Loss=21.8288, Entropy=0.0014, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2750
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=5.0230, Q2 Loss=5.0230, Entropy=0.0012, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7152
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.7821, Q2 Loss=0.7821, Entropy=0.3054, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3252
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.9682, Q2 Loss=0.9682, Entropy=0.3363, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2762
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.3514, Q2 Loss=1.3514, Entropy=0.1141, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5827

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000186
Q1 loss: 5.990680
Q2 loss: 5.990680
Current threshold: -28.9259
Global Scale Offset: 0.6276
Reward stats: mean=-0.0070, std=0.1467, count=157
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 5.9907, Q2 Loss: 5.9907, Entropy: 0.1517, Mean TD Error: 2.8348, Threshold: -28.9259
tensor([ 0.1180,  0.6856,  0.4223,  0.5878, -0.0499,  0.6361,  0.8062,  0.9455,
         1.4566,  0.1592,  0.2171,  0.8280,  0.0692, -0.0442, -0.3035, -0.0689],
       device='cuda:1')
Original likelihood: -33.11876678466797
Adjusted likelihood: -33.11876678466797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0006)
State is out of distribution
Projection step: 0, Loss: 33.30616760253906
Projection step: 1, Loss: 30.59035873413086
Projection step: 2, Loss: 30.87163543701172
Projection step: 3, Loss: 30.015941619873047
Projection step: 4, Loss: 28.548267364501953
Projection step: 5, Loss: 26.249797821044922
Projection step: 6, Loss: 25.27979278564453
Projection step: 7, Loss: 26.72219467163086
Projection step: 8, Loss: 25.6639461517334
Projection step: 9, Loss: 24.467876434326172
Projection step: 10, Loss: 23.311119079589844
Projection step: 11, Loss: 22.73554229736328
Projection step: 12, Loss: 22.008329391479492
Projection step: 13, Loss: 23.311100006103516
Projection step: 14, Loss: 22.732040405273438
Final likelihood: tensor([-19.4128, -19.5308, -24.6306, -21.7321, -21.3347, -19.8281, -21.9292,
        -21.3040, -22.8256, -22.4846, -20.8947, -20.9733, -18.6660, -18.8677,
        -20.5944, -17.7001])
Final projection likelihood: -20.7943
1 mode projection succeeded
New goal: tensor([ 0.0770,  0.5387,  0.5826,  0.5745, -0.0457,  0.5431,  0.8569,  0.8887,
         1.4049,  0.1614,  0.2421,  1.2470,  0.0589, -0.0311, -0.6366],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0046]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -29.634483337402344
Adjusted likelihood: -29.634483337402344
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 29.634483337402344}
Current yaw: tensor([ 0.0692, -0.0442, -0.3035], device='cuda:1')
8 thumb_middle
tensor([ 0.1180,  0.6856,  0.4223,  0.5878, -0.0499,  0.6361,  0.8062,  0.9455,
         1.4566,  0.1592,  0.2171,  0.8280,  0.0692, -0.0442, -0.3035, -0.0689],
       device='cuda:1')
Solve time for step 1 9.689895228977548
Current ori: tensor([ 0.0692, -0.0442, -0.3035], device='cuda:1')
Index force: tensor([0.5257, 0.6190, 0.5935, 0.5928], device='cuda:1')
tensor([ 0.1122,  0.6469,  0.5126,  0.5056, -0.1104,  0.5713,  0.8135,  0.8731,
         1.3051,  0.0989,  0.1040,  1.0854,  0.0687, -0.0436, -0.3035, -0.1029],
       device='cuda:1')
Solve time for step 2 2.1693606229964644
Current ori: tensor([ 0.0687, -0.0436, -0.3035], device='cuda:1')
Index force: tensor([0.6093, 0.5885, 0.5885], device='cuda:1')
tensor([ 0.0907,  0.5808,  0.5621,  0.5582, -0.1269,  0.5650,  0.8347,  0.8535,
         1.3140,  0.1239,  0.0862,  1.1377,  0.0946, -0.0410, -0.3035, -0.2217],
       device='cuda:1')
Solve time for step 3 1.9355312410043553
Current ori: tensor([ 0.0946, -0.0410, -0.3035], device='cuda:1')
Index force: tensor([0.5810, 0.5834], device='cuda:1')
tensor([ 0.0548,  0.5424,  0.5831,  0.5654, -0.1555,  0.5689,  0.8378,  0.8608,
         1.3266,  0.1044,  0.0972,  1.1671,  0.1200, -0.0156, -0.3035,  0.0257],
       device='cuda:1')
Solve time for step 4 2.0313359779829625
Current ori: tensor([ 0.1200, -0.0156, -0.3035], device='cuda:1')
Index force: tensor([0.5743], device='cuda:1')
Storing RECOVERY transition: reward=-0.0390 (scaled=-0.0098), steps=4
Reward stats updated: mean -0.0070 -> -0.0070, std: 0.1463
Collected 158 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0921, Q2 Loss=1.0921, Entropy=0.0001, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5282
SAC Update 2/5: Actor Loss=-0.0025, Q1 Loss=1.0428, Q2 Loss=1.0428, Entropy=0.0699, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8441
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6797, Q2 Loss=0.6797, Entropy=0.1270, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1510
SAC Update 4/5: Actor Loss=-0.0043, Q1 Loss=1.7362, Q2 Loss=1.7362, Entropy=0.0347, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6599
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0857, Q2 Loss=1.0857, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4741

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.7%)
Q1 update: 0.07s (21.6%)
Q2 update: 0.06s (18.4%)
Actor update: 0.13s (41.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001383
Q1 loss: 1.127306
Q2 loss: 1.127306
Current threshold: -28.9084
Global Scale Offset: 0.6192
Reward stats: mean=-0.0070, std=0.1463, count=158
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 1.1273, Q2 Loss: 1.1273, Entropy: 0.0463, Mean TD Error: 0.9314, Threshold: -28.9084
Original likelihood: -28.64185333251953
Adjusted likelihood: -28.64185333251953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5820)
State is out of distribution
Projection step: 0, Loss: 30.614648818969727
Projection step: 1, Loss: 30.701128005981445
Projection step: 2, Loss: 29.236757278442383
Projection step: 3, Loss: 27.62273406982422
Projection step: 4, Loss: 28.375606536865234
Projection step: 5, Loss: 26.974628448486328
Projection step: 6, Loss: 25.92884063720703
Projection step: 7, Loss: 26.503124237060547
Projection step: 8, Loss: 26.01309585571289
Projection step: 9, Loss: 26.297679901123047
Projection step: 10, Loss: 24.821903228759766
Projection step: 11, Loss: 24.145591735839844
Projection step: 12, Loss: 24.94371795654297
Projection step: 13, Loss: 25.413806915283203
Projection step: 14, Loss: 24.132061004638672
Final likelihood: tensor([-22.3850, -19.3445, -23.7409, -24.8560, -22.0290, -22.0994, -22.9641,
        -22.2066, -20.2437, -18.9736, -27.6209, -23.7402, -26.7355, -26.7136,
        -20.8832, -23.0022])
Final projection likelihood: -22.9712
1 mode projection succeeded
New goal: tensor([ 0.0657,  0.5549,  0.6065,  0.5942, -0.0633,  0.5332,  0.8346,  0.9642,
         1.4046,  0.0622,  0.2373,  1.2225,  0.1686, -0.0227,  0.3246],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0073]], device='cuda:1') tensor([[0.0014]], device='cuda:1')
Original likelihood: -34.99803161621094
Adjusted likelihood: -34.99803161621094
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 34.99803161621094}
Current yaw: tensor([ 0.1785, -0.0271, -0.3043], device='cuda:1')
9 thumb_middle
tensor([ 0.0128,  0.5716,  0.5683,  0.5554, -0.0452,  0.6384,  0.8695,  0.8876,
         1.4057,  0.1379,  0.1774,  1.2483,  0.1785, -0.0271, -0.3043,  0.3582],
       device='cuda:1')
Solve time for step 1 9.59744337000302
Current ori: tensor([ 0.1785, -0.0271, -0.3043], device='cuda:1')
Index force: tensor([0.5882, 0.5607, 0.5836, 0.5541], device='cuda:1')
tensor([ 0.0274,  0.6115,  0.6515,  0.6073, -0.0824,  0.5839,  0.8353,  0.9257,
         1.3553,  0.0457,  0.1377,  1.1844,  0.2386, -0.1076, -0.2729,  1.5196],
       device='cuda:1')
Solve time for step 2 1.9606241190049332
Current ori: tensor([ 0.2386, -0.1076, -0.2729], device='cuda:1')
Index force: tensor([0.5567, 0.5803, 0.5479], device='cuda:1')
tensor([ 0.0064,  0.6488,  0.8194,  0.7663, -0.0316,  0.6243,  0.8723,  0.9737,
         1.3594,  0.0327,  0.1255,  1.1801,  0.3539, -0.2554, -0.2326,  3.2563],
       device='cuda:1')
Solve time for step 3 1.8975400229974184
Current ori: tensor([ 0.3539, -0.2554, -0.2326], device='cuda:1')
Index force: tensor([0.5753, 0.5450], device='cuda:1')
tensor([-0.0069,  0.7119,  0.7607,  0.7095,  0.0715,  0.6924,  0.9512,  1.0056,
         1.3586,  0.0396,  0.1150,  1.1840,  0.3595, -0.2897, -0.1278,  5.3685],
       device='cuda:1')
Solve time for step 4 1.9246975019923411
Current ori: tensor([ 0.3595, -0.2897, -0.1278], device='cuda:1')
Index force: tensor([0.5777], device='cuda:1')
Storing RECOVERY transition: reward=-0.2719 (scaled=-0.0680), steps=4
Reward stats updated: mean -0.0070 -> -0.0074, std: 0.1459
Collected 159 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=4.0300, Q2 Loss=4.0300, Entropy=0.1145, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6153
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.7405, Q2 Loss=1.7405, Entropy=0.0012, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3288
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6614, Q2 Loss=0.6614, Entropy=0.0021, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2713
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.8719, Q2 Loss=3.8719, Entropy=0.0569, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6138
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9702, Q2 Loss=0.9702, Entropy=0.0020, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8400

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000017
Q1 loss: 2.254824
Q2 loss: 2.254824
Current threshold: -28.8823
Global Scale Offset: 0.6089
Reward stats: mean=-0.0074, std=0.1459, count=159
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.2548, Q2 Loss: 2.2548, Entropy: 0.0354, Mean TD Error: 3.5339, Threshold: -28.8823
Original likelihood: -186.07421875
Adjusted likelihood: -186.07421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 183.9090576171875
Projection step: 1, Loss: 173.65289306640625
Projection step: 2, Loss: 174.71929931640625
Projection step: 3, Loss: 182.74310302734375
Projection step: 4, Loss: 175.94769287109375
Projection step: 5, Loss: 191.56100463867188
Projection step: 6, Loss: 171.11642456054688
Projection step: 7, Loss: 196.7687530517578
Projection step: 8, Loss: 184.07012939453125
Projection step: 9, Loss: 187.58926391601562
Projection step: 10, Loss: 190.63475036621094
Projection step: 11, Loss: 185.89547729492188
Projection step: 12, Loss: 200.08847045898438
Projection step: 13, Loss: 185.82571411132812
Projection step: 14, Loss: 171.74737548828125
Final likelihood: tensor([-144.8445, -206.1161, -135.4242, -133.0153, -169.4207, -203.3907,
        -183.3592, -173.9721, -233.2604, -191.2007, -150.8323, -167.4105,
        -168.4661, -203.9922, -228.6934, -185.1563])
Final projection likelihood: -179.9097
1 mode projection failed, trying anyway
New goal: tensor([ 0.0369,  0.8231,  0.6624,  0.6574,  0.1691,  0.8001,  1.0778,  1.1486,
         1.3151,  0.0851,  0.1799,  1.2976,  0.3578, -0.2809, -0.2403],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0136]], device='cuda:1') tensor([[0.0043]], device='cuda:1')
Original likelihood: -138.39662170410156
Adjusted likelihood: -138.39662170410156
Likelihood residual: 0.0
Original likelihood: -205.63131713867188
Adjusted likelihood: -205.63131713867188
Likelihood residual: 0.0
{'index': 205.63131713867188, 'thumb_middle': 138.39662170410156}
Current yaw: tensor([ 0.3573, -0.2791, -0.2403], device='cuda:1')
10 thumb_middle
tensor([-0.0101,  0.8434,  0.6825,  0.6473,  0.1854,  0.8224,  1.0749,  1.0612,
         1.3585,  0.0331,  0.1810,  1.2791,  0.3573, -0.2791, -0.2403,  5.4861],
       device='cuda:1')
Solve time for step 1 9.1827451059944
Current ori: tensor([ 0.3573, -0.2791, -0.2403], device='cuda:1')
Index force: tensor([0.5843, 0.5827, 0.5690, 0.5835], device='cuda:1')
tensor([-0.0228,  1.0441,  0.6883,  0.6587,  0.1510,  0.8089,  1.0509,  1.1204,
         1.2410,  0.0874,  0.0546,  1.2832,  0.3776, -0.3416, -0.1239,  3.9735],
       device='cuda:1')
Solve time for step 2 2.0543843180057593
Current ori: tensor([ 0.3776, -0.3416, -0.1239], device='cuda:1')
Index force: tensor([0.5810, 0.5660, 0.5806], device='cuda:1')
tensor([-0.0447,  1.0575,  0.7042,  0.6488,  0.1295,  0.8118,  1.0755,  1.1348,
         1.2370,  0.1014,  0.0440,  1.3016,  0.3789, -0.3451, -0.1327,  4.0206],
       device='cuda:1')
Solve time for step 3 1.774996057007229
Current ori: tensor([ 0.3789, -0.3451, -0.1327], device='cuda:1')
Index force: tensor([0.5887, 0.5898], device='cuda:1')
tensor([-0.0627,  1.0615,  0.7014,  0.6509,  0.1125,  0.8038,  1.0895,  1.1461,
         1.2342,  0.1063,  0.0218,  1.3028,  0.3806, -0.3487, -0.1472,  4.8643],
       device='cuda:1')
Solve time for step 4 1.8661575889855158
Current ori: tensor([ 0.3806, -0.3487, -0.1472], device='cuda:1')
Index force: tensor([0.5870], device='cuda:1')
Storing RECOVERY transition: reward=-0.3322 (scaled=-0.0831), steps=4
Reward stats updated: mean -0.0074 -> -0.0078, std: 0.1456
Collected 160 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.9174, Q2 Loss=1.9174, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.9184
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.9009, Q2 Loss=1.9009, Entropy=0.0019, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5154
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.7765, Q2 Loss=1.7765, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6544
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9670, Q2 Loss=0.9670, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1866
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1443, Q2 Loss=1.1443, Entropy=0.0523, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5695

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.7%)
Actor update: 0.10s (43.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000004
Q1 loss: 1.541235
Q2 loss: 1.541235
Current threshold: -28.8673
Global Scale Offset: 0.6030
Reward stats: mean=-0.0078, std=0.1456, count=160
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.5412, Q2 Loss: 1.5412, Entropy: 0.0109, Mean TD Error: 1.1689, Threshold: -28.8673
Original likelihood: -285.5453796386719
Adjusted likelihood: -285.5453796386719
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 291.2297668457031
Projection step: 1, Loss: 294.2872619628906
Projection step: 2, Loss: 291.5613708496094
Projection step: 3, Loss: 279.366455078125
Projection step: 4, Loss: 285.90618896484375
Projection step: 5, Loss: 290.19085693359375
Projection step: 6, Loss: 291.4075927734375
Projection step: 7, Loss: 297.65576171875
Projection step: 8, Loss: 296.410888671875
Projection step: 9, Loss: 297.26824951171875
Projection step: 10, Loss: 284.3062438964844
Projection step: 11, Loss: 304.22576904296875
Projection step: 12, Loss: 282.2465515136719
Projection step: 13, Loss: 288.3907470703125
Projection step: 14, Loss: 295.7366943359375
Final likelihood: tensor([-337.5720, -246.8415, -342.3575, -341.3138, -238.3952, -276.5832,
        -300.0193, -296.4031, -343.0885, -264.1824, -308.6845, -264.9323,
        -305.2997, -228.8029, -280.5481, -240.1109])
Final projection likelihood: -288.4459
1 mode projection failed, trying anyway
New goal: tensor([-0.0533,  1.0651,  0.7150,  0.6574,  0.1279,  0.8509,  1.1342,  1.1832,
         1.2628,  0.0543,  0.0466,  1.2861,  0.3719, -0.3278, -0.1480],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0116]], device='cuda:1') tensor([[0.0052]], device='cuda:1')
Original likelihood: -237.27816772460938
Adjusted likelihood: -237.27816772460938
Likelihood residual: 0.0
Original likelihood: -253.01239013671875
Adjusted likelihood: -253.01239013671875
Likelihood residual: 0.0
{'index': 253.01239013671875, 'thumb_middle': 237.27816772460938}
Current yaw: tensor([ 0.3718, -0.3264, -0.1955], device='cuda:1')
11 thumb_middle
tensor([-0.0670,  1.0673,  0.7008,  0.6504,  0.1275,  0.8477,  1.1453,  1.1695,
         1.2851,  0.0448,  0.0488,  1.2785,  0.3718, -0.3264, -0.1955,  4.6707],
       device='cuda:1')
Solve time for step 1 9.061822403018596
Current ori: tensor([ 0.3718, -0.3264, -0.1955], device='cuda:1')
Index force: tensor([0.5969, 0.5849, 0.5838, 0.5965], device='cuda:1')
tensor([-0.0871,  1.1219,  0.6914,  0.6456,  0.1028,  0.8875,  1.1605,  1.1755,
         1.2505,  0.1088, -0.1018,  1.2976,  0.3803, -0.3518, -0.2255,  4.2850],
       device='cuda:1')
Solve time for step 2 1.9369109879771713
Current ori: tensor([ 0.3803, -0.3518, -0.2255], device='cuda:1')
Index force: tensor([0.5827, 0.5804, 0.5928], device='cuda:1')
tensor([-0.1069,  1.1348,  0.6901,  0.6361,  0.0827,  0.8889,  1.1780,  1.1851,
         1.2460,  0.1078, -0.1153,  1.2968,  0.3811, -0.3538, -0.2142,  4.5192],
       device='cuda:1')
Solve time for step 3 1.8746556550031528
Current ori: tensor([ 0.3811, -0.3538, -0.2142], device='cuda:1')
Index force: tensor([0.5755, 0.5880], device='cuda:1')
tensor([-0.1133,  1.1248,  0.6878,  0.6370,  0.0776,  0.8751,  1.1819,  1.1896,
         1.2487,  0.0886, -0.0655,  1.2861,  0.3793, -0.3486, -0.2310,  4.7044],
       device='cuda:1')
Solve time for step 4 1.8195926189946476
Current ori: tensor([ 0.3793, -0.3486, -0.2310], device='cuda:1')
Index force: tensor([0.5640], device='cuda:1')
Storing RECOVERY transition: reward=-0.2505 (scaled=-0.0626), steps=4
Reward stats updated: mean -0.0078 -> -0.0082, std: 0.1452
Collected 161 transitions for RL
SAC Update 1/5: Actor Loss=-0.0014, Q1 Loss=0.8993, Q2 Loss=0.8993, Entropy=0.2725, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4195
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9934, Q2 Loss=0.9934, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4407
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1887, Q2 Loss=1.1887, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3734
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.4427, Q2 Loss=1.4427, Entropy=0.0802, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0559
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9465, Q2 Loss=0.9465, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5728

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000297
Q1 loss: 1.094123
Q2 loss: 1.094123
Current threshold: -28.8465
Global Scale Offset: 0.5983
Reward stats: mean=-0.0082, std=0.1452, count=161
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.0941, Q2 Loss: 1.0941, Entropy: 0.0706, Mean TD Error: 0.9725, Threshold: -28.8465
Original likelihood: -280.388671875
Adjusted likelihood: -280.388671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 305.5470275878906
Projection step: 1, Loss: 307.98712158203125
Projection step: 2, Loss: 308.23248291015625
Projection step: 3, Loss: 307.1505126953125
Projection step: 4, Loss: 299.72869873046875
Projection step: 5, Loss: 298.2210388183594
Projection step: 6, Loss: 307.5561828613281
Projection step: 7, Loss: 296.7406005859375
Projection step: 8, Loss: 291.87249755859375
Projection step: 9, Loss: 306.56475830078125
Projection step: 10, Loss: 286.9059753417969
Projection step: 11, Loss: 298.58087158203125
Projection step: 12, Loss: 290.42828369140625
Projection step: 13, Loss: 310.93878173828125
Projection step: 14, Loss: 296.32257080078125
Final likelihood: tensor([-297.7661, -311.5197, -282.1330, -265.8792, -335.8965, -348.7229,
        -309.1959, -373.0683, -276.9019, -224.7347, -308.9819, -344.7952,
        -287.7945, -275.8817, -285.5671, -301.2794])
Final projection likelihood: -301.8823
1 mode projection failed, trying anyway
New goal: tensor([-0.1118,  1.1487,  0.7144,  0.6486,  0.0658,  0.9103,  1.2003,  1.2107,
         1.2675,  0.0443, -0.0101,  1.2750,  0.3720, -0.3298, -0.3086],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0051]], device='cuda:1') tensor([[0.0051]], device='cuda:1')
Original likelihood: -264.3438720703125
Adjusted likelihood: -264.3438720703125
Likelihood residual: 0.0
Original likelihood: -308.639404296875
Adjusted likelihood: -308.639404296875
Likelihood residual: 0.0
{'index': 308.639404296875, 'thumb_middle': 264.3438720703125}
Current yaw: tensor([ 0.3719, -0.3284, -0.3469], device='cuda:1')
12 thumb_middle
tensor([-0.1259,  1.1516,  0.6999,  0.6414,  0.0644,  0.9069,  1.2111,  1.1990,
         1.2898,  0.0351, -0.0084,  1.2663,  0.3719, -0.3284, -0.3469,  4.6309],
       device='cuda:1')
Solve time for step 1 9.590633693005657
Current ori: tensor([ 0.3719, -0.3284, -0.3469], device='cuda:1')
Index force: tensor([0.5865, 0.5962, 0.5799, 0.5826], device='cuda:1')
tensor([-0.1445,  1.1573,  0.6680,  0.6246,  0.0422,  0.9035,  1.1876,  1.1920,
         1.2360,  0.0641, -0.1123,  1.2663,  0.3809, -0.3541, -0.3248,  4.5802],
       device='cuda:1')
Solve time for step 2 1.9480980439984705
Current ori: tensor([ 0.3809, -0.3541, -0.3248], device='cuda:1')
Index force: tensor([0.5920, 0.5751, 0.5778], device='cuda:1')
tensor([-0.1605,  1.2060,  0.6717,  0.6343,  0.0232,  0.9399,  1.2165,  1.1919,
         1.2378,  0.0556, -0.0990,  1.2652,  0.3803, -0.3524, -0.3323,  4.6847],
       device='cuda:1')
Solve time for step 3 1.9052979240077548
Current ori: tensor([ 0.3803, -0.3524, -0.3323], device='cuda:1')
Index force: tensor([0.5709, 0.5729], device='cuda:1')
tensor([-0.1590,  1.2118,  0.6559,  0.6339,  0.0239,  0.9440,  1.2081,  1.1847,
         1.2359,  0.0616, -0.1078,  1.2808,  0.3810, -0.3539, -0.3356,  4.6714],
       device='cuda:1')
Solve time for step 4 1.736263599974336
Current ori: tensor([ 0.3810, -0.3539, -0.3356], device='cuda:1')
Index force: tensor([0.5629], device='cuda:1')
Storing RECOVERY transition: reward=-0.2232 (scaled=-0.0558), steps=4
Reward stats updated: mean -0.0082 -> -0.0085, std: 0.1448
Collected 162 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=3.6015, Q2 Loss=3.6015, Entropy=0.0006, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6160
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.3953, Q2 Loss=1.3953, Entropy=0.0857, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3411
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7218, Q2 Loss=0.7218, Entropy=0.0015, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5130
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.8330, Q2 Loss=0.8330, Entropy=0.3340, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4800
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=1.0331, Q2 Loss=1.0331, Entropy=0.3363, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6912

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000218
Q1 loss: 1.516931
Q2 loss: 1.516931
Current threshold: -28.8355
Global Scale Offset: 0.5959
Reward stats: mean=-0.0085, std=0.1448, count=162
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.5169, Q2 Loss: 1.5169, Entropy: 0.1516, Mean TD Error: 2.5283, Threshold: -28.8355
Original likelihood: -300.00396728515625
Adjusted likelihood: -300.00396728515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 10
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.7148821970040444
tensor([ 0.1358,  0.5839,  0.6118,  0.5633, -0.1158,  0.4948,  0.9529,  0.9000,
         1.2092,  0.3472,  0.2695,  1.1459, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -19.304445266723633
Adjusted likelihood: -19.304445266723633
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.134503570006927
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([0.7087, 1.8035, 0.6675, 0.5443, 0.8445, 0.5675, 0.5625, 0.5674, 0.5014,
        0.5835, 1.2622, 0.5996], device='cuda:1')
Thumb force: tensor([0.6086, 1.6750, 1.8747, 1.5114, 1.0554, 0.7164, 0.5193, 0.5152, 0.5839,
        1.2612, 1.1405, 0.6132], device='cuda:1')
Index force: tensor([0.7115, 1.3673, 0.5830, 0.5028, 1.2962, 0.6008, 0.5025, 0.6041, 0.6582,
        0.6196, 0.5209, 0.6315], device='cuda:1')
Storing NORMAL transition: reward=0.1076 (scaled=0.1076), steps=1
Reward stats updated: mean -0.0085 -> -0.0078, std: 0.1446
Collected 163 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1112, Q2 Loss=1.1112, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5343
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.1218, Q2 Loss=1.1218, Entropy=0.1941, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7761
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5655, Q2 Loss=0.5655, Entropy=0.0014, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1906
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0746, Q2 Loss=1.0746, Entropy=0.0014, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4832
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6785, Q2 Loss=0.6785, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6718

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.4%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (19.7%)
Actor update: 0.13s (40.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000028
Q1 loss: 0.910318
Q2 loss: 0.910318
Current threshold: -28.8258
Global Scale Offset: 0.5949
Reward stats: mean=-0.0078, std=0.1446, count=163
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9103, Q2 Loss: 0.9103, Entropy: 0.0394, Mean TD Error: 0.5312, Threshold: -28.8258
tensor([ 0.1330,  0.6252,  0.5672,  0.5347, -0.1208,  0.5044,  0.8929,  1.0186,
         1.2498,  0.3205,  0.2791,  1.0403, -0.0130,  0.0099, -0.1386,  0.4114],
       device='cuda:1')
Original likelihood: -16.412521362304688
Adjusted likelihood: -16.412521362304688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.1042720669938717
Current ori: tensor([-0.0130,  0.0099, -0.1386], device='cuda:1')
Middle force: tensor([1.7788, 0.6649, 0.5428, 0.8292, 0.5650, 0.5597, 0.5639, 0.5014, 0.5810,
        1.2547, 0.5975], device='cuda:1')
Thumb force: tensor([1.6383, 1.8437, 1.4867, 1.0433, 0.7094, 0.5184, 0.5150, 0.5762, 1.2427,
        1.1261, 0.6095], device='cuda:1')
Index force: tensor([1.3457, 0.5778, 0.5025, 1.2785, 0.5986, 0.5023, 0.6011, 0.6559, 0.6163,
        0.5203, 0.6291], device='cuda:1')
Storing NORMAL transition: reward=0.2534 (scaled=0.2534), steps=1
Reward stats updated: mean -0.0078 -> -0.0062, std: 0.1456
Collected 164 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6731, Q2 Loss=0.6731, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1616
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=21.0141, Q2 Loss=21.0141, Entropy=0.0005, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6849
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=21.3884, Q2 Loss=21.3884, Entropy=0.0005, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1856
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0519, Q2 Loss=1.0519, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6373
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9616, Q2 Loss=0.9616, Entropy=0.0698, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6562

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.9%)
Q1 update: 0.05s (17.8%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (39.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000006
Q1 loss: 9.017820
Q2 loss: 9.017820
Current threshold: -28.8195
Global Scale Offset: 0.5945
Reward stats: mean=-0.0062, std=0.1456, count=164
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 9.0178, Q2 Loss: 9.0178, Entropy: 0.0142, Mean TD Error: 2.6651, Threshold: -28.8195
tensor([ 0.1974,  0.7160,  0.5010,  0.5600, -0.0395,  0.5179,  0.9074,  1.1272,
         1.3142,  0.3386,  0.1834,  0.9211, -0.0291, -0.0353, -0.3983,  0.7937],
       device='cuda:1')
Original likelihood: -26.063583374023438
Adjusted likelihood: -26.063583374023438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9863)
Solve time for step 3 2.781336189014837
Current ori: tensor([-0.0291, -0.0353, -0.3983], device='cuda:1')
Middle force: tensor([0.6626, 0.5389, 0.8316, 0.5617, 0.5553, 0.5592, 0.5018, 0.5769, 1.2546,
        0.5956], device='cuda:1')
Thumb force: tensor([1.8234, 1.4623, 1.0150, 0.7009, 0.5181, 0.5148, 0.5642, 1.2256, 1.1042,
        0.6049], device='cuda:1')
Index force: tensor([0.5699, 0.5025, 1.2512, 0.5972, 0.5020, 0.5968, 0.6526, 0.6143, 0.5199,
        0.6262], device='cuda:1')
Storing NORMAL transition: reward=0.0214 (scaled=0.0214), steps=1
Reward stats updated: mean -0.0062 -> -0.0060, std: 0.1452
Collected 165 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7201, Q2 Loss=0.7201, Entropy=0.0363, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4347
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8173, Q2 Loss=0.8173, Entropy=0.0821, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6177
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2475, Q2 Loss=1.2475, Entropy=0.0254, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7295
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=2.7197, Q2 Loss=2.7197, Entropy=0.0005, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5030
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.3704, Q2 Loss=1.3704, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6541

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.7%)
Q1 update: 0.05s (18.5%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000005
Q1 loss: 1.375011
Q2 loss: 1.375011
Current threshold: -28.8148
Global Scale Offset: 0.5945
Reward stats: mean=-0.0060, std=0.1452, count=165
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3750, Q2 Loss: 1.3750, Entropy: 0.0289, Mean TD Error: 1.7878, Threshold: -28.8148
tensor([ 0.1642,  0.6648,  0.5348,  0.5559,  0.0082,  0.5271,  0.9495,  1.1167,
         1.3157,  0.3103,  0.1044,  0.9995, -0.0236, -0.0698, -0.4339,  1.2035],
       device='cuda:1')
Original likelihood: -25.045974731445312
Adjusted likelihood: -25.045974731445312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9987)
Solve time for step 4 2.6494621349847876
Current ori: tensor([-0.0236, -0.0698, -0.4339], device='cuda:1')
Middle force: tensor([0.5627, 0.5289, 0.5093, 0.5608, 0.5013, 0.5317, 0.7293, 0.6540, 0.5356],
       device='cuda:1')
Thumb force: tensor([1.1490, 0.5294, 0.5186, 1.7866, 0.5381, 0.7470, 0.5640, 0.9502, 0.8303],
       device='cuda:1')
Index force: tensor([0.5515, 0.5787, 0.6974, 0.5768, 0.8205, 0.5726, 0.5514, 0.5608, 0.5040],
       device='cuda:1')
Storing NORMAL transition: reward=0.0521 (scaled=0.0521), steps=1
Reward stats updated: mean -0.0060 -> -0.0056, std: 0.1448
Collected 166 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9055, Q2 Loss=0.9055, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5310
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=0.9289, Q2 Loss=0.9289, Entropy=0.0239, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7792
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.9603, Q2 Loss=1.9603, Entropy=0.0005, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4234
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.3957, Q2 Loss=3.3957, Entropy=0.0005, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6148
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1630, Q2 Loss=1.1630, Entropy=0.0445, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6105

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.2%)
Actor update: 0.12s (42.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000424
Q1 loss: 1.670689
Q2 loss: 1.670689
Current threshold: -28.8025
Global Scale Offset: 0.5907
Reward stats: mean=-0.0056, std=0.1448, count=166
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.6707, Q2 Loss: 1.6707, Entropy: 0.0139, Mean TD Error: 2.5918, Threshold: -28.8025
tensor([ 0.1805,  0.6297,  0.6202,  0.5194,  0.0238,  0.5212,  0.9269,  1.3045,
         1.2516,  0.5341,  0.1850,  0.9043, -0.0166, -0.0790, -0.5925,  1.3808],
       device='cuda:1')
Original likelihood: -30.958402633666992
Adjusted likelihood: -30.958402633666992
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0416)
State is out of distribution
Projection step: 0, Loss: 35.01734161376953
Projection step: 1, Loss: 30.29983901977539
Projection step: 2, Loss: 30.41592788696289
Projection step: 3, Loss: 26.650571823120117
Projection step: 4, Loss: 27.868396759033203
Projection step: 5, Loss: 25.147483825683594
Projection step: 6, Loss: 24.860118865966797
Projection step: 7, Loss: 24.02627182006836
Projection step: 8, Loss: 22.990449905395508
Projection step: 9, Loss: 22.264156341552734
Projection step: 10, Loss: 22.11086654663086
Projection step: 11, Loss: 21.22413444519043
Projection step: 12, Loss: 21.502338409423828
Projection step: 13, Loss: 20.546649932861328
Projection step: 14, Loss: 20.84795379638672
Final likelihood: tensor([-19.5893, -21.7314, -20.2902, -22.0270, -19.4917, -20.2502, -20.2274,
        -21.8058, -20.1146, -17.1090, -23.6664, -21.2717, -18.0173, -17.2016,
        -22.4230, -19.9693])
Final projection likelihood: -20.3241
1 mode projection succeeded
New goal: tensor([ 0.1069,  0.5704,  0.5496,  0.6542,  0.0137,  0.5237,  0.7304,  1.0673,
         1.3118,  0.3277,  0.0917,  0.9517, -0.0199, -0.0554, -1.0645],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -27.446712493896484
Adjusted likelihood: -27.446712493896484
Likelihood residual: 0.0
Original likelihood: -27.613231658935547
Adjusted likelihood: -27.613231658935547
Likelihood residual: 0.0
{'index': 27.613231658935547, 'thumb_middle': 27.446712493896484}
Current yaw: tensor([-0.0166, -0.0790, -0.5925], device='cuda:1')
2 thumb_middle
tensor([ 0.1805,  0.6297,  0.6202,  0.5194,  0.0238,  0.5212,  0.9269,  1.3045,
         1.2516,  0.5341,  0.1850,  0.9043, -0.0166, -0.0790, -0.5925,  1.3808],
       device='cuda:1')
Solve time for step 1 9.169740284007275
Current ori: tensor([-0.0166, -0.0790, -0.5925], device='cuda:1')
Index force: tensor([0.5842, 0.5994, 0.6075, 0.5033], device='cuda:1')
tensor([ 0.1719,  0.6041,  0.5893,  0.6289, -0.0617,  0.5389,  0.7618,  1.1184,
         1.2638,  0.3599,  0.0619,  0.9403, -0.0027, -0.0699, -0.5880,  1.3888],
       device='cuda:1')
Solve time for step 2 1.9557061050145421
Current ori: tensor([-0.0027, -0.0699, -0.5880], device='cuda:1')
Index force: tensor([0.5930, 0.6049, 0.5010], device='cuda:1')
tensor([ 0.1469,  0.5535,  0.5948,  0.6999, -0.0792,  0.5624,  0.7174,  1.0628,
         1.3195,  0.3424,  0.0500,  0.9315,  0.0136, -0.0519, -0.5880,  1.3932],
       device='cuda:1')
Solve time for step 3 1.9447585040179547
Current ori: tensor([ 0.0136, -0.0519, -0.5880], device='cuda:1')
Index force: tensor([0.5001, 0.5933], device='cuda:1')
tensor([ 0.1437,  0.5698,  0.5818,  0.6742, -0.0817,  0.5577,  0.7199,  1.0648,
         1.3155,  0.3076,  0.0544,  0.9411,  0.0068, -0.0513, -0.5880,  1.3768],
       device='cuda:1')
Solve time for step 4 1.7918185519811232
Current ori: tensor([ 0.0068, -0.0513, -0.5880], device='cuda:1')
Index force: tensor([0.5863], device='cuda:1')
Storing RECOVERY transition: reward=0.0304 (scaled=0.0076), steps=4
Reward stats updated: mean -0.0056 -> -0.0056, std: 0.1444
Collected 167 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=3.3653, Q2 Loss=3.3653, Entropy=0.1982, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6295
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.9701, Q2 Loss=1.9701, Entropy=0.0544, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4426
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6672, Q2 Loss=0.6672, Entropy=0.0002, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6936
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9508, Q2 Loss=0.9508, Entropy=0.0509, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3696
SAC Update 5/5: Actor Loss=-0.0024, Q1 Loss=0.9839, Q2 Loss=0.9839, Entropy=0.0415, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8065

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.06s (20.9%)
Actor update: 0.12s (42.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000522
Q1 loss: 1.587462
Q2 loss: 1.587462
Current threshold: -28.7877
Global Scale Offset: 0.5872
Reward stats: mean=-0.0056, std=0.1444, count=167
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.5875, Q2 Loss: 1.5875, Entropy: 0.0690, Mean TD Error: 2.5884, Threshold: -28.7877
Original likelihood: -21.84706687927246
Adjusted likelihood: -21.84706687927246
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0025, -0.0458, -0.5914], device='cuda:1')
3 turn
Sampling time 3.7273699899960775
tensor([ 0.1277,  0.5960,  0.5457,  0.6427, -0.0178,  0.6087,  0.7453,  1.0775,
         1.3743,  0.3373,  0.1009,  0.9729, -0.0025, -0.0458, -0.5914,  1.3607],
       device='cuda:1')
Original likelihood: -19.144126892089844
Adjusted likelihood: -19.144126892089844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.076580117020058
Current ori: tensor([-0.0025, -0.0458, -0.5914], device='cuda:1')
Middle force: tensor([0.6566, 0.5442, 0.5804, 0.8249, 0.5831, 0.7272, 0.5682, 0.6109, 0.9934,
        0.5345, 0.6412, 0.7167], device='cuda:1')
Thumb force: tensor([0.5408, 0.5400, 0.6120, 1.2684, 0.6082, 0.5614, 0.8356, 0.6123, 0.7365,
        1.3789, 0.8633, 1.0328], device='cuda:1')
Index force: tensor([0.7273, 0.5791, 0.5922, 0.5697, 0.5959, 0.6123, 0.5777, 0.6076, 0.5537,
        0.5560, 0.7109, 0.5441], device='cuda:1')
Storing NORMAL transition: reward=-0.0048 (scaled=-0.0048), steps=1
Reward stats updated: mean -0.0056 -> -0.0056, std: 0.1439
Collected 168 transitions for RL
SAC Update 1/5: Actor Loss=-0.0130, Q1 Loss=1.2605, Q2 Loss=1.2605, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3930
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9693, Q2 Loss=0.9693, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6499
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7947, Q2 Loss=0.7947, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7412
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6405, Q2 Loss=0.6405, Entropy=0.0727, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3850
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.3931, Q2 Loss=1.3931, Entropy=0.3284, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9322

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002802
Q1 loss: 1.011618
Q2 loss: 1.011618
Current threshold: -28.7291
Global Scale Offset: 0.5547
Reward stats: mean=-0.0056, std=0.1439, count=168
----------------------------------------------
SAC Update - Actor Loss: -0.0028, Q1 Loss: 1.0116, Q2 Loss: 1.0116, Entropy: 0.0802, Mean TD Error: 0.8203, Threshold: -28.7291
tensor([ 0.2497,  0.7263,  0.4980,  0.6552, -0.0865,  0.7022,  0.7983,  1.0750,
         1.3456,  0.2618,  0.0470,  1.0027, -0.0066, -0.1070, -0.5955,  1.3966],
       device='cuda:1')
Original likelihood: -31.408105850219727
Adjusted likelihood: -31.408105850219727
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0121)
State is out of distribution
Projection step: 0, Loss: 34.57405471801758
Projection step: 1, Loss: 31.39131736755371
Projection step: 2, Loss: 32.05657196044922
Projection step: 3, Loss: 32.96466064453125
Projection step: 4, Loss: 31.47630500793457
Projection step: 5, Loss: 30.813255310058594
Projection step: 6, Loss: 31.457361221313477
Projection step: 7, Loss: 32.467403411865234
Projection step: 8, Loss: 29.682880401611328
Projection step: 9, Loss: 31.161617279052734
Projection step: 10, Loss: 29.565597534179688
Projection step: 11, Loss: 29.43185806274414
Projection step: 12, Loss: 29.2575740814209
Projection step: 13, Loss: 29.113445281982422
Projection step: 14, Loss: 27.074411392211914
Final likelihood: tensor([-26.3690, -18.1935, -25.5313, -22.6582, -27.5213, -19.7209, -27.2809,
        -26.4172, -28.1096, -20.4456, -27.7146, -34.2493, -27.3691, -26.5124,
        -26.2434, -19.8132])
Final projection likelihood: -25.2593
1 mode projection succeeded
New goal: tensor([ 0.2013,  0.6099,  0.5267,  0.7145, -0.0137,  0.6687,  0.8374,  0.9657,
         1.3522,  0.1781,  0.0635,  1.0509, -0.0145, -0.0882, -2.1757],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0078]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -28.74211883544922
Adjusted likelihood: -28.74211883544922
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 28.74211883544922}
Current yaw: tensor([-0.0066, -0.1070, -0.5955], device='cuda:1')
4 thumb_middle
tensor([ 0.2497,  0.7263,  0.4980,  0.6552, -0.0865,  0.7022,  0.7983,  1.0750,
         1.3456,  0.2618,  0.0470,  1.0027, -0.0066, -0.1070, -0.5955,  1.3966],
       device='cuda:1')
Solve time for step 1 9.187511319993064
Current ori: tensor([-0.0066, -0.1070, -0.5955], device='cuda:1')
Index force: tensor([0.5707, 0.5679, 0.5597, 0.5909], device='cuda:1')
tensor([ 0.2136,  0.6619,  0.5283,  0.6872, -0.1223,  0.6450,  0.7935,  0.9613,
         1.2986,  0.1836,  0.0044,  1.0225,  0.0052, -0.0804, -0.5955,  1.3676],
       device='cuda:1')
Solve time for step 2 1.992061085999012
Current ori: tensor([ 0.0052, -0.0804, -0.5955], device='cuda:1')
Index force: tensor([0.5630, 0.5567, 0.5869], device='cuda:1')
tensor([ 0.2244,  0.6721,  0.5271,  0.6867, -0.1232,  0.6803,  0.7910,  0.9325,
         1.3238,  0.1578, -0.0309,  1.0264,  0.0044, -0.0874, -0.5955,  1.3800],
       device='cuda:1')
Solve time for step 3 1.905477759981295
Current ori: tensor([ 0.0044, -0.0874, -0.5955], device='cuda:1')
Index force: tensor([0.5528, 0.5831], device='cuda:1')
tensor([ 0.2196,  0.6532,  0.5356,  0.7093, -0.1222,  0.6781,  0.7845,  0.9256,
         1.3234,  0.1601, -0.0139,  1.0165,  0.0100, -0.0824, -0.5955,  1.3867],
       device='cuda:1')
Solve time for step 4 1.8488070429884829
Current ori: tensor([ 0.0100, -0.0824, -0.5955], device='cuda:1')
Index force: tensor([0.5795], device='cuda:1')
Storing RECOVERY transition: reward=0.0115 (scaled=0.0115), steps=1
Reward stats updated: mean -0.0056 -> -0.0055, std: 0.1435
Collected 169 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9562, Q2 Loss=0.9562, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4589
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.7174, Q2 Loss=0.7174, Entropy=0.3315, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4005
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=3.7130, Q2 Loss=3.7130, Entropy=0.0225, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7379
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.1277, Q2 Loss=1.1277, Entropy=0.3097, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2200
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8277, Q2 Loss=0.8277, Entropy=0.0600, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5379

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.9%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (39.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000144
Q1 loss: 1.468391
Q2 loss: 1.468391
Current threshold: -28.6860
Global Scale Offset: 0.5364
Reward stats: mean=-0.0055, std=0.1435, count=169
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.4684, Q2 Loss: 1.4684, Entropy: 0.1447, Mean TD Error: 1.4710, Threshold: -28.6860
Original likelihood: -28.743507385253906
Adjusted likelihood: -28.743507385253906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4802)
Current yaw: tensor([ 0.0042, -0.0714, -0.6011], device='cuda:1')
5 turn
Sampling time 3.7390701940166764
tensor([ 0.1980,  0.6592,  0.5135,  0.6880, -0.0735,  0.7199,  0.8167,  0.9498,
         1.3820,  0.1748,  0.0526,  1.0645,  0.0042, -0.0714, -0.6011,  1.3523],
       device='cuda:1')
Original likelihood: -28.57032012939453
Adjusted likelihood: -28.57032012939453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5397)
Solve time for step 1 14.379309554991778
Current ori: tensor([ 0.0042, -0.0714, -0.6011], device='cuda:1')
Middle force: tensor([0.5529, 0.6957, 0.5585, 0.5291, 0.8600, 0.5528, 0.5306, 0.5362, 0.6005,
        0.6214, 0.5041, 0.5536], device='cuda:1')
Thumb force: tensor([0.6170, 1.9822, 1.6090, 0.5299, 0.6355, 0.5548, 1.0620, 0.5117, 0.7280,
        0.6001, 1.0620, 1.0786], device='cuda:1')
Index force: tensor([0.6197, 0.7294, 0.5497, 0.5296, 0.5670, 0.5840, 0.5833, 0.5491, 0.6179,
        0.5848, 0.7997, 0.5621], device='cuda:1')
Storing NORMAL transition: reward=-0.0717 (scaled=-0.0717), steps=1
Reward stats updated: mean -0.0055 -> -0.0059, std: 0.1432
Collected 170 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1399, Q2 Loss=1.1399, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7207
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0601, Q2 Loss=1.0601, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3816
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6976, Q2 Loss=0.6976, Entropy=0.3059, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1104
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0017, Q2 Loss=1.0017, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9214
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6005, Q2 Loss=0.6005, Entropy=0.0235, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4492

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.8%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.7%)
Actor update: 0.10s (43.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000017
Q1 loss: 0.899969
Q2 loss: 0.899969
Current threshold: -28.6629
Global Scale Offset: 0.5262
Reward stats: mean=-0.0059, std=0.1432, count=170
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9000, Q2 Loss: 0.9000, Entropy: 0.0659, Mean TD Error: 0.5166, Threshold: -28.6629
tensor([ 0.1649,  0.5637,  0.5064,  0.7855, -0.1959,  0.6766,  0.8142,  0.9986,
         1.3655,  0.2490,  0.1873,  1.0736,  0.0543,  0.0024, -0.5270,  1.4777],
       device='cuda:1')
Original likelihood: -35.73114013671875
Adjusted likelihood: -35.73114013671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 35.53169250488281
Projection step: 1, Loss: 31.010276794433594
Projection step: 2, Loss: 28.672962188720703
Projection step: 3, Loss: 25.571189880371094
Projection step: 4, Loss: 24.182979583740234
Projection step: 5, Loss: 22.466541290283203
Projection step: 6, Loss: 20.870193481445312
Projection step: 7, Loss: 21.232940673828125
Projection step: 8, Loss: 20.161630630493164
Projection step: 9, Loss: 18.917495727539062
Projection step: 10, Loss: 20.359630584716797
Projection step: 11, Loss: 19.220983505249023
Projection step: 12, Loss: 18.19098663330078
Projection step: 13, Loss: 17.456096649169922
Projection step: 14, Loss: 17.27035140991211
Final likelihood: tensor([-16.8836, -17.8801, -16.9484, -15.6211, -17.2836, -18.1188, -12.3748,
        -18.6150, -14.1431, -15.0025, -16.0636, -15.1927, -12.0041, -18.4429,
        -17.2429, -16.3980])
Final projection likelihood: -16.1384
1 mode projection succeeded
New goal: tensor([ 9.7753e-02,  5.4256e-01,  5.8889e-01,  6.3669e-01, -7.3890e-02,
         5.4693e-01,  8.9515e-01,  8.5266e-01,  1.3407e+00,  2.6975e-01,
         2.2236e-01,  1.1601e+00,  3.8535e-02,  1.0961e-03, -1.9383e+00],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0052]], device='cuda:1')
Original likelihood: -18.627290725708008
Adjusted likelihood: -18.627290725708008
Likelihood residual: 0.0
Original likelihood: -27.126087188720703
Adjusted likelihood: -27.126087188720703
Likelihood residual: 0.0
{'index': 27.126087188720703, 'thumb_middle': 18.627290725708008}
Current yaw: tensor([ 0.0543,  0.0024, -0.5270], device='cuda:1')
6 thumb_middle
tensor([ 0.1649,  0.5637,  0.5064,  0.7855, -0.1959,  0.6766,  0.8142,  0.9986,
         1.3655,  0.2490,  0.1873,  1.0736,  0.0543,  0.0024, -0.5270,  1.4777],
       device='cuda:1')
Solve time for step 1 9.418401534989243
Current ori: tensor([ 0.0543,  0.0024, -0.5270], device='cuda:1')
Index force: tensor([0.5911, 0.5806, 0.5991, 0.5985], device='cuda:1')
tensor([ 0.1281,  0.5703,  0.5711,  0.6535, -0.2093,  0.5566,  0.8208,  0.8449,
         1.2740,  0.2351,  0.1318,  1.1109,  0.0511,  0.0064, -0.5269,  1.3873],
       device='cuda:1')
Solve time for step 2 1.9786535959865432
Current ori: tensor([ 0.0511,  0.0064, -0.5269], device='cuda:1')
Index force: tensor([0.5754, 0.5949, 0.5948], device='cuda:1')
tensor([ 0.1125,  0.5665,  0.5783,  0.6183, -0.2140,  0.5510,  0.8380,  0.8223,
         1.2862,  0.2365,  0.1227,  1.1197,  0.0492,  0.0113, -0.5269,  1.3248],
       device='cuda:1')
Solve time for step 3 1.9334407960122917
Current ori: tensor([ 0.0492,  0.0113, -0.5269], device='cuda:1')
Index force: tensor([0.5884, 0.5900], device='cuda:1')
tensor([ 0.1206,  0.5612,  0.5878,  0.6298, -0.2050,  0.5650,  0.8420,  0.8191,
         1.2805,  0.2364,  0.1175,  1.1221,  0.0515,  0.0078, -0.5269,  1.3436],
       device='cuda:1')
Solve time for step 4 1.857513539987849
Current ori: tensor([ 0.0515,  0.0078, -0.5269], device='cuda:1')
Index force: tensor([0.5802], device='cuda:1')
Storing RECOVERY transition: reward=-0.0061 (scaled=-0.0061), steps=1
Reward stats updated: mean -0.0059 -> -0.0059, std: 0.1428
Collected 171 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.5368, Q2 Loss=1.5368, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4970
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8810, Q2 Loss=0.8810, Entropy=0.0361, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6375
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9742, Q2 Loss=0.9742, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5866
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.1493, Q2 Loss=3.1493, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6853
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8367, Q2 Loss=0.8367, Entropy=0.0002, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3372

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.2%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.8%)
Actor update: 0.11s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000003
Q1 loss: 1.475583
Q2 loss: 1.475583
Current threshold: -28.6498
Global Scale Offset: 0.5203
Reward stats: mean=-0.0059, std=0.1428, count=171
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.4756, Q2 Loss: 1.4756, Entropy: 0.0073, Mean TD Error: 2.5487, Threshold: -28.6498
Original likelihood: -24.926921844482422
Adjusted likelihood: -24.926921844482422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Current yaw: tensor([ 0.0559,  0.0128, -0.5211], device='cuda:1')
7 turn
Sampling time 3.892220959009137
tensor([ 0.0968,  0.5440,  0.5847,  0.6357, -0.1443,  0.6069,  0.8793,  0.8413,
         1.3438,  0.2553,  0.1793,  1.1612,  0.0559,  0.0128, -0.5211,  1.2896],
       device='cuda:1')
Original likelihood: -24.591123580932617
Adjusted likelihood: -24.591123580932617
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Solve time for step 1 15.029795008013025
Current ori: tensor([ 0.0559,  0.0128, -0.5211], device='cuda:1')
Middle force: tensor([0.5801, 0.5840, 1.2316, 0.6619, 0.5539, 0.5310, 0.5295, 0.6112, 0.5443,
        0.7160, 0.5233, 0.5585], device='cuda:1')
Thumb force: tensor([0.5598, 1.3612, 0.5802, 0.5482, 1.2209, 0.6003, 1.5860, 1.1994, 0.5842,
        0.5717, 0.6590, 0.5962], device='cuda:1')
Index force: tensor([0.7393, 1.0927, 0.5617, 0.5752, 0.5525, 0.6594, 0.5323, 0.6072, 0.6492,
        0.5144, 0.5372, 0.6700], device='cuda:1')
Storing NORMAL transition: reward=-0.0370 (scaled=-0.0370), steps=1
Reward stats updated: mean -0.0059 -> -0.0060, std: 0.1424
Collected 172 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.8273, Q2 Loss=1.8273, Entropy=0.0483, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5190
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.8771, Q2 Loss=1.8771, Entropy=0.0008, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4001
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8695, Q2 Loss=0.8695, Entropy=0.0008, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4253
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.8239, Q2 Loss=0.8239, Entropy=0.3030, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1521
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1920, Q2 Loss=1.1920, Entropy=0.0008, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5751

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000074
Q1 loss: 1.317960
Q2 loss: 1.317960
Current threshold: -28.6437
Global Scale Offset: 0.5171
Reward stats: mean=-0.0060, std=0.1424, count=172
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.3180, Q2 Loss: 1.3180, Entropy: 0.0708, Mean TD Error: 1.8143, Threshold: -28.6437
tensor([ 0.0690,  0.6501,  0.4802,  0.5012, -0.2605,  0.5356,  0.9223,  0.9796,
         1.3282,  0.3118,  0.2025,  1.1347,  0.0250,  0.0333, -0.4825,  0.7207],
       device='cuda:1')
Original likelihood: -33.60405731201172
Adjusted likelihood: -33.60405731201172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 34.865089416503906
Projection step: 1, Loss: 29.66204833984375
Projection step: 2, Loss: 25.359573364257812
Projection step: 3, Loss: 21.416061401367188
Projection step: 4, Loss: 18.383787155151367
Projection step: 5, Loss: 16.301902770996094
Projection step: 6, Loss: 14.041948318481445
Final likelihood: tensor([-13.2313, -13.5304, -13.9196, -13.6903, -14.7739, -14.4183, -14.2964,
        -13.5754, -14.0024, -13.2007, -14.5664, -13.9853, -14.3996, -13.9827,
        -13.9631, -15.1353])
Final projection likelihood: -14.0419
1 mode projection succeeded
New goal: tensor([ 0.0631,  0.6317,  0.4886,  0.5230, -0.1386,  0.5439,  0.8557,  0.8770,
         1.3363,  0.2185,  0.2092,  1.1751,  0.0244,  0.0269, -0.8112],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0063]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -18.402748107910156
Adjusted likelihood: -18.402748107910156
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.402748107910156}
Current yaw: tensor([ 0.0250,  0.0333, -0.4825], device='cuda:1')
8 thumb_middle
tensor([ 0.0690,  0.6501,  0.4802,  0.5012, -0.2605,  0.5356,  0.9223,  0.9796,
         1.3282,  0.3118,  0.2025,  1.1347,  0.0250,  0.0333, -0.4825,  0.7207],
       device='cuda:1')
Solve time for step 1 9.305719848984154
Current ori: tensor([ 0.0250,  0.0333, -0.4825], device='cuda:1')
Index force: tensor([0.5601, 0.5717, 0.5733, 0.5750], device='cuda:1')
tensor([ 0.0775,  0.6351,  0.4979,  0.5217, -0.2549,  0.5576,  0.8447,  0.8842,
         1.2762,  0.1937,  0.1481,  1.1562,  0.0293,  0.0284, -0.4825,  0.8168],
       device='cuda:1')
Solve time for step 2 1.9961918799963314
Current ori: tensor([ 0.0293,  0.0284, -0.4825], device='cuda:1')
Index force: tensor([0.5653, 0.5679, 0.5698], device='cuda:1')
tensor([ 0.0743,  0.6256,  0.5021,  0.5325, -0.2460,  0.5843,  0.8263,  0.8414,
         1.2906,  0.2014,  0.1358,  1.1431,  0.0322,  0.0307, -0.4825,  0.8170],
       device='cuda:1')
Solve time for step 3 2.006873086997075
Current ori: tensor([ 0.0322,  0.0307, -0.4825], device='cuda:1')
Index force: tensor([0.5621, 0.5649], device='cuda:1')
tensor([ 0.0762,  0.6280,  0.4939,  0.5455, -0.2426,  0.5784,  0.8336,  0.8552,
         1.2966,  0.2005,  0.1237,  1.1479,  0.0327,  0.0300, -0.4825,  0.8221],
       device='cuda:1')
Solve time for step 4 1.822436133021256
Current ori: tensor([ 0.0327,  0.0300, -0.4825], device='cuda:1')
Index force: tensor([0.5974], device='cuda:1')
Storing RECOVERY transition: reward=0.0097 (scaled=0.0097), steps=1
Reward stats updated: mean -0.0060 -> -0.0059, std: 0.1420
Collected 173 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.6989, Q2 Loss=0.6989, Entropy=0.3459, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5313
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8604, Q2 Loss=0.8604, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6274
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=1.0074, Q2 Loss=1.0074, Entropy=0.3459, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8857
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9037, Q2 Loss=0.9037, Entropy=0.0003, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8771
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8648, Q2 Loss=0.8648, Entropy=0.1068, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0384

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.4%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (19.7%)
Actor update: 0.11s (39.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000152
Q1 loss: 0.867044
Q2 loss: 0.867044
Current threshold: -28.6371
Global Scale Offset: 0.5154
Reward stats: mean=-0.0059, std=0.1420, count=173
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.8670, Q2 Loss: 0.8670, Entropy: 0.1598, Mean TD Error: 0.5920, Threshold: -28.6371
Original likelihood: -22.316659927368164
Adjusted likelihood: -22.316659927368164
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0276,  0.0369, -0.4926], device='cuda:1')
9 turn
Sampling time 4.054951222002273
tensor([ 0.0582,  0.6425,  0.4762,  0.5068, -0.1993,  0.6085,  0.8536,  0.8694,
         1.3653,  0.2244,  0.1833,  1.1786,  0.0276,  0.0369, -0.4926,  0.8268],
       device='cuda:1')
Original likelihood: -23.749282836914062
Adjusted likelihood: -23.749282836914062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.49348687499878
Current ori: tensor([ 0.0276,  0.0369, -0.4926], device='cuda:1')
Middle force: tensor([0.5585, 1.7143, 0.5291, 0.5222, 0.6331, 1.6297, 0.5672, 0.5215, 0.5100,
        0.7657, 0.5765, 0.6222], device='cuda:1')
Thumb force: tensor([0.7686, 0.9494, 0.5002, 0.9304, 0.8321, 0.9872, 0.7183, 0.6445, 0.5494,
        0.5808, 1.0069, 0.6141], device='cuda:1')
Index force: tensor([0.5615, 0.7000, 0.7804, 0.6036, 0.5151, 0.5073, 0.5111, 0.5338, 0.5043,
        0.5225, 0.5237, 0.6083], device='cuda:1')
Storing NORMAL transition: reward=0.0814 (scaled=0.0814), steps=1
Reward stats updated: mean -0.0059 -> -0.0054, std: 0.1417
Collected 174 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7320, Q2 Loss=0.7320, Entropy=0.0008, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3055
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=20.8645, Q2 Loss=20.8645, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4952
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1223, Q2 Loss=1.1223, Entropy=0.0009, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7878
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.7668, Q2 Loss=0.7668, Entropy=0.1658, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1551
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7294, Q2 Loss=0.7294, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6530

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.1%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.4%)
Actor update: 0.13s (42.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000022
Q1 loss: 4.843014
Q2 loss: 4.843014
Current threshold: -28.6321
Global Scale Offset: 0.5147
Reward stats: mean=-0.0054, std=0.1417, count=174
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.8430, Q2 Loss: 4.8430, Entropy: 0.0335, Mean TD Error: 1.6793, Threshold: -28.6321
tensor([ 0.0853,  0.5795,  0.5256,  0.5063, -0.1481,  0.4752,  0.7947,  1.0850,
         1.4056,  0.1923,  0.2113,  1.0582,  0.0156,  0.0500, -0.5751,  1.9164],
       device='cuda:1')
Original likelihood: -34.081932067871094
Adjusted likelihood: -34.081932067871094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.850006103515625
Projection step: 1, Loss: 29.23341941833496
Projection step: 2, Loss: 26.460399627685547
Projection step: 3, Loss: 21.295108795166016
Projection step: 4, Loss: 18.07155418395996
Projection step: 5, Loss: 14.593317031860352
Final likelihood: tensor([-17.8493, -14.2445, -17.4813, -15.3827, -12.3521, -11.1495, -24.0898,
        -12.8848, -12.1392, -14.7163, -13.0451, -11.7017, -14.6032, -15.8134,
        -15.1620, -10.8782])
Final projection likelihood: -14.5933
1 mode projection succeeded
New goal: tensor([ 0.0441,  0.6000,  0.5060,  0.5524, -0.1192,  0.4823,  0.7783,  0.9469,
         1.3521,  0.1836,  0.1934,  1.1273,  0.0195,  0.0310, -1.6503],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0064]], device='cuda:1')
Original likelihood: -16.044239044189453
Adjusted likelihood: -16.044239044189453
Likelihood residual: 0.0
{'index': 16.044239044189453, 'thumb_middle': inf}
Current yaw: tensor([ 0.0156,  0.0500, -0.5751], device='cuda:1')
10 index
tensor([ 0.0853,  0.5795,  0.5256,  0.5063, -0.1481,  0.4752,  0.7947,  1.0850,
         1.4056,  0.1923,  0.2113,  1.0582,  0.0156,  0.0500, -0.5751,  1.9164],
       device='cuda:1')
Solve time for step 1 11.67562493099831
Current ori: tensor([ 0.0156,  0.0500, -0.5751], device='cuda:1')
Middle force: tensor([0.6076, 0.6015, 0.5771, 0.5749], device='cuda:1')
Thumb force: tensor([0.5209, 0.5909, 0.5600, 0.5699], device='cuda:1')
tensor([ 0.0987,  0.5402,  0.4627,  0.5206, -0.1500,  0.4690,  0.8368,  1.0408,
         1.4192,  0.1785,  0.1868,  1.0679,  0.0090,  0.0481, -0.5792,  2.3154],
       device='cuda:1')
Solve time for step 2 2.5148542069946416
Current ori: tensor([ 0.0090,  0.0481, -0.5792], device='cuda:1')
Middle force: tensor([0.5984, 0.5752, 0.5723], device='cuda:1')
Thumb force: tensor([0.5867, 0.5588, 0.5679], device='cuda:1')
tensor([ 9.4801e-02,  5.4964e-01,  4.5275e-01,  5.2507e-01, -1.2892e-01,
         4.8573e-01,  8.3931e-01,  1.0137e+00,  1.3979e+00,  2.0290e-01,
         1.7678e-01,  1.0704e+00,  1.5171e-03,  3.5522e-02, -5.7730e-01,
         2.3132e+00], device='cuda:1')
Solve time for step 3 2.4513402490119915
Current ori: tensor([ 0.0015,  0.0355, -0.5773], device='cuda:1')
Middle force: tensor([0.5391, 0.5299], device='cuda:1')
Thumb force: tensor([0.5567, 0.5713], device='cuda:1')
tensor([ 0.0968,  0.5521,  0.4581,  0.5230, -0.1326,  0.4897,  0.8373,  1.0014,
         1.4229,  0.1640,  0.1675,  1.0625, -0.0021,  0.0383, -0.5777,  2.1208],
       device='cuda:1')
Solve time for step 4 2.3611374880129006
Current ori: tensor([-0.0021,  0.0383, -0.5777], device='cuda:1')
Middle force: tensor([0.5289], device='cuda:1')
Thumb force: tensor([0.5672], device='cuda:1')
Storing RECOVERY transition: reward=0.0067 (scaled=0.0067), steps=1
Reward stats updated: mean -0.0054 -> -0.0054, std: 0.1413
Collected 175 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6707, Q2 Loss=0.6707, Entropy=0.0002, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2139
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0278, Q2 Loss=1.0278, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1404
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7116, Q2 Loss=0.7116, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3731
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=3.0812, Q2 Loss=3.0812, Entropy=0.2052, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7515
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7359, Q2 Loss=0.7359, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5329

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.4%)
Q1 update: 0.07s (20.7%)
Q2 update: 0.06s (19.4%)
Actor update: 0.14s (41.6%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000031
Q1 loss: 1.245429
Q2 loss: 1.245429
Current threshold: -28.6290
Global Scale Offset: 0.5146
Reward stats: mean=-0.0054, std=0.1413, count=175
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2454, Q2 Loss: 1.2454, Entropy: 0.0411, Mean TD Error: 1.4024, Threshold: -28.6290
Original likelihood: -25.401798248291016
Adjusted likelihood: -25.401798248291016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9979)
Current yaw: tensor([-4.7670e-04,  4.4339e-02, -5.8096e-01], device='cuda:1')
11 turn
Sampling time 3.7079380310024135
tensor([ 4.0971e-02,  6.1012e-01,  4.9198e-01,  5.4449e-01, -1.4327e-01,
         4.8342e-01,  8.3715e-01,  1.0112e+00,  1.4124e+00,  1.9979e-01,
         1.6634e-01,  1.0807e+00, -4.7670e-04,  4.4339e-02, -5.8096e-01,
         2.0314e+00], device='cuda:1')
Original likelihood: -26.463241577148438
Adjusted likelihood: -26.463241577148438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9728)
Solve time for step 1 15.4796772809932
Current ori: tensor([-4.7670e-04,  4.4339e-02, -5.8096e-01], device='cuda:1')
Middle force: tensor([0.5697, 1.6538, 0.5358, 0.5374, 0.6635, 1.5922, 0.5592, 0.5480, 0.5588,
        0.6801, 0.5401, 0.5575], device='cuda:1')
Thumb force: tensor([0.7811, 1.0530, 0.4961, 0.9012, 0.8610, 1.0554, 0.7675, 1.1813, 0.6468,
        0.8242, 0.5477, 1.2052], device='cuda:1')
Index force: tensor([0.5170, 0.7366, 0.7928, 0.6009, 0.5021, 0.5437, 0.5089, 0.5216, 0.5757,
        0.5427, 0.6050, 0.5020], device='cuda:1')
Storing NORMAL transition: reward=0.1254 (scaled=0.1254), steps=1
Reward stats updated: mean -0.0054 -> -0.0046, std: 0.1412
Collected 176 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=8.7921, Q2 Loss=8.7921, Entropy=0.0001, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.7766
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7767, Q2 Loss=0.7767, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1739
SAC Update 3/5: Actor Loss=-0.0035, Q1 Loss=1.1067, Q2 Loss=1.1067, Entropy=0.0083, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9332
SAC Update 4/5: Actor Loss=-0.0052, Q1 Loss=1.4180, Q2 Loss=1.4180, Entropy=0.0090, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0995
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=20.6487, Q2 Loss=20.6487, Entropy=0.0627, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9229

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (17.9%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (36.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001757
Q1 loss: 6.548447
Q2 loss: 6.548447
Current threshold: -28.6037
Global Scale Offset: 0.5069
Reward stats: mean=-0.0046, std=0.1412, count=176
----------------------------------------------
SAC Update - Actor Loss: -0.0018, Q1 Loss: 6.5484, Q2 Loss: 6.5484, Entropy: 0.0160, Mean TD Error: 2.9812, Threshold: -28.6037
tensor([ 0.0624,  0.6239,  0.4950,  0.5408, -0.1242,  0.4563,  0.8572,  1.0871,
         1.3885,  0.2658,  0.2187,  0.9433, -0.0044,  0.0319, -0.7058,  2.1820],
       device='cuda:1')
Original likelihood: -21.44875144958496
Adjusted likelihood: -21.44875144958496
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9455065030197147
Current ori: tensor([-0.0044,  0.0319, -0.7058], device='cuda:1')
Middle force: tensor([1.6381, 0.5355, 0.5379, 0.6627, 1.5725, 0.5573, 0.5473, 0.5592, 0.6759,
        0.5396, 0.5559], device='cuda:1')
Thumb force: tensor([1.0418, 0.5009, 0.8952, 0.8552, 1.0484, 0.7659, 1.1748, 0.6433, 0.8227,
        0.5468, 1.2002], device='cuda:1')
Index force: tensor([0.7278, 0.7938, 0.5993, 0.5021, 0.5459, 0.5089, 0.5211, 0.5746, 0.5418,
        0.6037, 0.5019], device='cuda:1')
Storing NORMAL transition: reward=0.1551 (scaled=0.1551), steps=1
Reward stats updated: mean -0.0046 -> -0.0037, std: 0.1413
Collected 177 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8615, Q2 Loss=0.8615, Entropy=0.0008, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4588
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.8617, Q2 Loss=0.8617, Entropy=0.2945, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3945
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0282, Q2 Loss=1.0282, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1352
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6861, Q2 Loss=0.6861, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2843
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2286, Q2 Loss=1.2286, Entropy=0.0041, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0799

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.6%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.07s (20.4%)
Actor update: 0.14s (41.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000065
Q1 loss: 0.933218
Q2 loss: 0.933218
Current threshold: -28.5735
Global Scale Offset: 0.4964
Reward stats: mean=-0.0037, std=0.1413, count=177
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.9332, Q2 Loss: 0.9332, Entropy: 0.0599, Mean TD Error: 0.6705, Threshold: -28.5735
tensor([ 9.3117e-02,  6.1005e-01,  5.2565e-01,  5.7747e-01, -9.3276e-02,
         4.2685e-01,  8.9907e-01,  1.1761e+00,  1.4975e+00,  7.8219e-02,
         1.6943e-01,  8.9111e-01,  1.0704e-03,  1.4186e-02, -8.5998e-01,
         2.3984e+00], device='cuda:1')
Original likelihood: -19.757556915283203
Adjusted likelihood: -19.757556915283203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 3.0551902239967603
Current ori: tensor([ 0.0011,  0.0142, -0.8600], device='cuda:1')
Middle force: tensor([0.5342, 0.5374, 0.6637, 1.5580, 0.5570, 0.5469, 0.5609, 0.6759, 0.5398,
        0.5555], device='cuda:1')
Thumb force: tensor([0.5009, 0.8897, 0.8486, 1.0405, 0.7599, 1.1654, 0.6372, 0.8144, 0.5452,
        1.1899], device='cuda:1')
Index force: tensor([0.7873, 0.5986, 0.5020, 0.5467, 0.5090, 0.5210, 0.5734, 0.5415, 0.6024,
        0.5019], device='cuda:1')
Storing NORMAL transition: reward=0.1026 (scaled=0.1026), steps=1
Reward stats updated: mean -0.0037 -> -0.0031, std: 0.1412
Collected 178 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1731, Q2 Loss=1.1731, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3870
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5930, Q2 Loss=0.5930, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5698
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=1.1056, Q2 Loss=1.1056, Entropy=0.2105, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9547
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9760, Q2 Loss=0.9760, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2997
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.2140, Q2 Loss=1.2140, Entropy=0.2113, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5731

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.0%)
Q1 update: 0.07s (20.5%)
Q2 update: 0.07s (19.9%)
Actor update: 0.14s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000063
Q1 loss: 1.012323
Q2 loss: 1.012323
Current threshold: -28.5540
Global Scale Offset: 0.4906
Reward stats: mean=-0.0031, std=0.1412, count=178
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0123, Q2 Loss: 1.0123, Entropy: 0.0844, Mean TD Error: 0.7569, Threshold: -28.5540
tensor([ 0.0595,  0.5791,  0.4741,  0.6703,  0.0242,  0.4732,  0.9429,  1.2093,
         1.5000,  0.1305,  0.0258,  0.8738, -0.0051, -0.0617, -0.9763,  2.4030],
       device='cuda:1')
Original likelihood: -25.154752731323242
Adjusted likelihood: -25.154752731323242
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9991)
Solve time for step 4 2.6474202609970234
Current ori: tensor([-0.0051, -0.0617, -0.9763], device='cuda:1')
Middle force: tensor([0.5426, 0.6716, 1.5471, 0.5620, 0.5460, 0.6152, 0.7001, 0.5545, 0.5603],
       device='cuda:1')
Thumb force: tensor([0.8651, 0.8334, 1.0319, 0.7444, 1.1622, 0.5989, 0.7812, 0.5359, 1.1648],
       device='cuda:1')
Index force: tensor([0.5885, 0.5021, 0.5474, 0.5087, 0.5201, 0.5553, 0.5389, 0.5977, 0.5019],
       device='cuda:1')
Storing NORMAL transition: reward=0.0142 (scaled=0.0142), steps=1
Reward stats updated: mean -0.0031 -> -0.0030, std: 0.1408
Collected 179 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.8476, Q2 Loss=2.8476, Entropy=0.0007, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7535
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1211, Q2 Loss=1.1211, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8313
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.6494, Q2 Loss=0.6494, Entropy=0.3428, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9420
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=1.0366, Q2 Loss=1.0366, Entropy=0.3465, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7418
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0498, Q2 Loss=1.0498, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4508

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.7%)
Actor update: 0.12s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000308
Q1 loss: 1.340912
Q2 loss: 1.340912
Current threshold: -28.5307
Global Scale Offset: 0.4874
Reward stats: mean=-0.0030, std=0.1408, count=179
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.3409, Q2 Loss: 1.3409, Entropy: 0.1380, Mean TD Error: 1.7439, Threshold: -28.5307
tensor([ 0.0472,  0.5708,  0.4885,  0.6422,  0.0114,  0.4830,  0.9299,  1.2101,
         1.5000,  0.1035,  0.0606,  0.8172, -0.0165, -0.0550, -0.9899,  2.3235],
       device='cuda:1')
Original likelihood: -23.123165130615234
Adjusted likelihood: -23.123165130615234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.679660216002958
Current ori: tensor([-0.0165, -0.0550, -0.9899], device='cuda:1')
Middle force: tensor([0.6674, 1.5326, 0.5644, 0.5447, 0.6297, 0.7165, 0.5582, 0.5631],
       device='cuda:1')
Thumb force: tensor([0.8252, 1.0243, 0.7361, 1.1579, 0.5932, 0.7682, 0.5341, 1.1517],
       device='cuda:1')
Index force: tensor([0.5020, 0.5461, 0.5083, 0.5195, 0.5490, 0.5340, 0.5932, 0.5019],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0385 (scaled=-0.0385), steps=1
Reward stats updated: mean -0.0030 -> -0.0032, std: 0.1404
Collected 180 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6068, Q2 Loss=0.6068, Entropy=0.0036, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1420
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2454, Q2 Loss=1.2454, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6485
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=1.0234, Q2 Loss=1.0234, Entropy=0.3463, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9619
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8320, Q2 Loss=0.8320, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6249
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.5436, Q2 Loss=1.5436, Entropy=0.0831, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6340

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.4%)
Actor update: 0.11s (39.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000154
Q1 loss: 1.050231
Q2 loss: 1.050231
Current threshold: -28.5047
Global Scale Offset: 0.4855
Reward stats: mean=-0.0032, std=0.1404, count=180
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0502, Q2 Loss: 1.0502, Entropy: 0.0866, Mean TD Error: 1.0023, Threshold: -28.5047
tensor([ 0.0045,  0.6239,  0.4637,  0.5829,  0.0708,  0.5918,  0.8211,  1.2792,
         1.4185,  0.2962,  0.0813,  0.7093, -0.0396, -0.1271, -1.0042,  4.0474],
       device='cuda:1')
Original likelihood: -32.11382293701172
Adjusted likelihood: -32.11382293701172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0004)
State is out of distribution
Projection step: 0, Loss: 32.19045639038086
Projection step: 1, Loss: 29.435382843017578
Projection step: 2, Loss: 30.227582931518555
Projection step: 3, Loss: 30.726818084716797
Projection step: 4, Loss: 28.532175064086914
Projection step: 5, Loss: 28.450607299804688
Projection step: 6, Loss: 29.075847625732422
Projection step: 7, Loss: 26.472370147705078
Projection step: 8, Loss: 26.979446411132812
Projection step: 9, Loss: 31.319561004638672
Projection step: 10, Loss: 25.484729766845703
Projection step: 11, Loss: 24.677440643310547
Projection step: 12, Loss: 25.5552978515625
Projection step: 13, Loss: 24.609716415405273
Projection step: 14, Loss: 24.88430404663086
Final likelihood: tensor([-34.5996, -16.4104, -20.9159, -32.3956, -20.5844, -20.9113, -15.8203,
        -23.2511, -20.6195, -16.4562, -30.8269, -21.4006, -26.1177, -20.6337,
        -25.9416, -16.9528])
Final projection likelihood: -22.7399
1 mode projection succeeded
New goal: tensor([ 0.0617,  0.5255,  0.5758,  0.6669,  0.0030,  0.6169,  0.8948,  1.0910,
         1.4477,  0.1841,  0.1332,  0.7112, -0.0308, -0.1133,  0.1019],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0066]], device='cuda:1') tensor([[0.0067]], device='cuda:1')
Original likelihood: -32.374446868896484
Adjusted likelihood: -32.374446868896484
Likelihood residual: 0.0
Original likelihood: -33.778194427490234
Adjusted likelihood: -33.778194427490234
Likelihood residual: 0.0
{'index': 33.778194427490234, 'thumb_middle': 32.374446868896484}
Current yaw: tensor([-0.0396, -0.1271, -1.0042], device='cuda:1')
12 thumb_middle
tensor([ 0.0045,  0.6239,  0.4637,  0.5829,  0.0708,  0.5918,  0.8211,  1.2792,
         1.4185,  0.2962,  0.0813,  0.7093, -0.0396, -0.1271, -1.0042,  4.0474],
       device='cuda:1')
Solve time for step 1 9.703498260001652
Current ori: tensor([-0.0396, -0.1271, -1.0042], device='cuda:1')
Index force: tensor([0.5486, 0.5720, 0.5710, 0.5712], device='cuda:1')
tensor([ 0.0172,  0.5992,  0.5762,  0.6781, -0.0630,  0.6119,  0.8445,  1.1195,
         1.3750,  0.1882,  0.0065,  0.6742, -0.0666, -0.2244, -1.0145,  5.0542],
       device='cuda:1')
Solve time for step 2 2.109375631000148
Current ori: tensor([-0.0666, -0.2244, -1.0145], device='cuda:1')
Index force: tensor([0.5643, 0.5664, 0.5666], device='cuda:1')
tensor([-0.0130,  0.6314,  0.6430,  0.7027, -0.0676,  0.6555,  0.8708,  1.0942,
         1.3616,  0.1932, -0.0368,  0.6532, -0.0773, -0.2633, -1.0390,  4.8057],
       device='cuda:1')
Solve time for step 3 1.9091549319855403
Current ori: tensor([-0.0773, -0.2633, -1.0390], device='cuda:1')
Index force: tensor([0.5007, 0.5021], device='cuda:1')
tensor([-0.0269,  0.6586,  0.6598,  0.6986, -0.0500,  0.6868,  0.8857,  1.0929,
         1.3587,  0.1720, -0.0756,  0.6424, -0.0814, -0.2938, -1.0751,  3.9967],
       device='cuda:1')
Solve time for step 4 1.9943158609967213
Current ori: tensor([-0.0814, -0.2938, -1.0751], device='cuda:1')
Index force: tensor([0.5022], device='cuda:1')
Storing RECOVERY transition: reward=-0.0827 (scaled=-0.0165), steps=5
Reward stats updated: mean -0.0032 -> -0.0033, std: 0.1400
Collected 181 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=8.5749, Q2 Loss=8.5749, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.8350
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9560, Q2 Loss=0.9560, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6878
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.3881, Q2 Loss=2.3881, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7261
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=3.1442, Q2 Loss=3.1442, Entropy=0.1275, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.8500
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8463, Q2 Loss=0.8463, Entropy=0.0007, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2187

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.06s (19.6%)
Actor update: 0.12s (39.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000015
Q1 loss: 3.181909
Q2 loss: 3.181909
Current threshold: -28.4855
Global Scale Offset: 0.4845
Reward stats: mean=-0.0033, std=0.1400, count=181
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.1819, Q2 Loss: 3.1819, Entropy: 0.0257, Mean TD Error: 4.0635, Threshold: -28.4855
Original likelihood: -51.4101676940918
Adjusted likelihood: -51.4101676940918
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 55.280277252197266
Projection step: 1, Loss: 59.61635208129883
Projection step: 2, Loss: 48.5628662109375
Projection step: 3, Loss: 48.2025032043457
Projection step: 4, Loss: 47.485591888427734
Projection step: 5, Loss: 55.62147521972656
Projection step: 6, Loss: 58.975486755371094
Projection step: 7, Loss: 57.64527130126953
Projection step: 8, Loss: 50.646270751953125
Projection step: 9, Loss: 47.200016021728516
Projection step: 10, Loss: 41.9879035949707
Projection step: 11, Loss: 51.72069549560547
Projection step: 12, Loss: 48.562255859375
Projection step: 13, Loss: 46.108280181884766
Projection step: 14, Loss: 39.795738220214844
Final likelihood: tensor([ -31.1387,  -32.1332,  -32.9321,  -44.5051,  -33.9415,  -27.9608,
        -107.3057,  -32.6648,  -70.7622,  -31.9261,  -29.5918,  -63.4216,
         -32.6875,  -28.1161,  -62.6456,  -29.9754])
Final projection likelihood: -43.2318
1 mode projection failed, trying anyway
New goal: tensor([-0.0124,  0.6100,  0.6871,  0.6601,  0.0253,  0.8043,  0.9193,  1.1184,
         1.3615,  0.1850, -0.0073,  0.6890, -0.0427, -0.2376,  0.2001],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0069]], device='cuda:1') tensor([[0.0107]], device='cuda:1')
Original likelihood: -59.04759979248047
Adjusted likelihood: -59.04759979248047
Likelihood residual: 0.0
Original likelihood: -37.789466857910156
Adjusted likelihood: -37.789466857910156
Likelihood residual: 0.0
{'index': 37.789466857910156, 'thumb_middle': 59.04759979248047}
Current yaw: tensor([-0.0451, -0.2450, -1.1185], device='cuda:1')
13 index
tensor([-0.0441,  0.6950,  0.6778,  0.7002,  0.0376,  0.8076,  0.9282,  1.0813,
         1.3737,  0.1691, -0.0055,  0.6753, -0.0451, -0.2450, -1.1185,  3.8615],
       device='cuda:1')
Solve time for step 1 11.791578328993637
Current ori: tensor([-0.0451, -0.2450, -1.1185], device='cuda:1')
Middle force: tensor([0.5483, 0.5622, 0.6190, 0.5227], device='cuda:1')
Thumb force: tensor([0.6026, 0.5462, 0.5432, 0.5647], device='cuda:1')
tensor([-0.0760,  0.6807,  0.6702,  0.6521,  0.0302,  0.8679,  0.9442,  1.1023,
         1.3592,  0.1929, -0.0331,  0.7472, -0.0170, -0.2633, -1.1675,  4.4096],
       device='cuda:1')
Solve time for step 2 2.4982997409824748
Current ori: tensor([-0.0170, -0.2633, -1.1675], device='cuda:1')
Middle force: tensor([0.5373, 0.5711, 0.5849], device='cuda:1')
Thumb force: tensor([0.5540, 0.5259, 0.5878], device='cuda:1')
tensor([-7.1736e-02,  7.0654e-01,  6.8468e-01,  6.4605e-01,  1.2628e-02,
         9.2930e-01,  9.4374e-01,  1.0871e+00,  1.3661e+00,  1.9073e-01,
        -3.9492e-02,  7.3684e-01,  4.0310e-03, -2.8291e-01, -1.2547e+00,
         4.9660e+00], device='cuda:1')
Solve time for step 3 2.4410668019845616
Current ori: tensor([ 0.0040, -0.2829, -1.2547], device='cuda:1')
Middle force: tensor([0.5663, 0.5833], device='cuda:1')
Thumb force: tensor([0.5253, 0.5853], device='cuda:1')
tensor([-0.0287,  0.7391,  0.6894,  0.6401,  0.0183,  0.9856,  0.9290,  1.0579,
         1.3585,  0.1880, -0.0790,  0.7860,  0.0458, -0.3318, -1.3609,  5.0579],
       device='cuda:1')
Solve time for step 4 2.3666428880242165
Current ori: tensor([ 0.0458, -0.3318, -1.3609], device='cuda:1')
Middle force: tensor([0.5834], device='cuda:1')
Thumb force: tensor([0.5823], device='cuda:1')
Storing RECOVERY transition: reward=-0.4225 (scaled=-0.0845), steps=5
Reward stats updated: mean -0.0033 -> -0.0038, std: 0.1398
Collected 182 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7565, Q2 Loss=0.7565, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7575
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8298, Q2 Loss=0.8298, Entropy=0.2232, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3588
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.8865, Q2 Loss=1.8865, Entropy=0.0016, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6124
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8697, Q2 Loss=0.8697, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1641
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.9440, Q2 Loss=0.9440, Entropy=0.3398, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2096

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (15.0%)
Q1 update: 0.07s (20.8%)
Q2 update: 0.06s (19.0%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000189
Q1 loss: 1.057292
Q2 loss: 1.057292
Current threshold: -28.4702
Global Scale Offset: 0.4842
Reward stats: mean=-0.0038, std=0.1398, count=182
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0573, Q2 Loss: 1.0573, Entropy: 0.1129, Mean TD Error: 0.6205, Threshold: -28.4702
Original likelihood: -369.59747314453125
Adjusted likelihood: -369.59747314453125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 11
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0140, -0.0381], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0140, -0.0381], device='cuda:1')
1 turn
Sampling time 3.760178213007748
tensor([ 1.2616e-01,  5.8587e-01,  5.8303e-01,  5.9536e-01, -1.1234e-01,
         5.4787e-01,  8.9665e-01,  8.4294e-01,  1.2391e+00,  2.1642e-01,
         2.7852e-01,  1.2159e+00, -1.2181e-04,  1.3951e-02, -3.8083e-02,
         4.4559e-01], device='cuda:1')
Original likelihood: -19.25017547607422
Adjusted likelihood: -19.25017547607422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.622830206004437
Current ori: tensor([-0.0001,  0.0140, -0.0381], device='cuda:1')
Middle force: tensor([0.5352, 0.5266, 1.5226, 0.5937, 0.5813, 0.5672, 0.5375, 0.5288, 0.5297,
        1.9915, 0.7531, 0.5433], device='cuda:1')
Thumb force: tensor([0.6932, 0.8724, 1.8891, 0.7615, 1.0801, 0.5772, 0.6108, 0.8285, 2.0701,
        0.5517, 0.5840, 0.5743], device='cuda:1')
Index force: tensor([0.5626, 0.8822, 0.5592, 0.5600, 0.6133, 0.5774, 0.6527, 0.9631, 0.6486,
        0.6935, 0.5195, 0.6560], device='cuda:1')
Storing NORMAL transition: reward=0.0155 (scaled=0.0155), steps=1
Reward stats updated: mean -0.0038 -> -0.0036, std: 0.1394
Collected 183 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.7912, Q2 Loss=1.7912, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6632
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6842, Q2 Loss=0.6842, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3390
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1921, Q2 Loss=1.1921, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9150
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.1919, Q2 Loss=1.1919, Entropy=0.3252, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2798
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8717, Q2 Loss=0.8717, Entropy=0.0549, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4302

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.8%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (17.9%)
Actor update: 0.08s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000092
Q1 loss: 1.146228
Q2 loss: 1.146228
Current threshold: -28.4516
Global Scale Offset: 0.4840
Reward stats: mean=-0.0036, std=0.1394, count=183
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.1462, Q2 Loss: 1.1462, Entropy: 0.0760, Mean TD Error: 1.7255, Threshold: -28.4516
tensor([ 0.0552,  0.6050,  0.5337,  0.4786, -0.0462,  0.5378,  0.8937,  0.8225,
         1.2309,  0.3440,  0.2448,  1.0165, -0.0190, -0.0146, -0.0539,  1.0079],
       device='cuda:1')
Original likelihood: -10.730209350585938
Adjusted likelihood: -10.730209350585938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9024625699967146
Current ori: tensor([-0.0190, -0.0146, -0.0539], device='cuda:1')
Middle force: tensor([0.5514, 1.5219, 0.6039, 0.5788, 0.5664, 0.5537, 0.5706, 0.5387, 1.9631,
        0.7608, 0.5565], device='cuda:1')
Thumb force: tensor([0.8033, 1.8675, 0.7388, 1.0681, 0.5719, 0.5875, 0.7314, 2.0369, 0.5515,
        0.5746, 0.5553], device='cuda:1')
Index force: tensor([0.8162, 0.5585, 0.5614, 0.6159, 0.5792, 0.6417, 0.9049, 0.6336, 0.7023,
        0.5197, 0.6544], device='cuda:1')
Storing NORMAL transition: reward=0.0750 (scaled=0.0750), steps=1
Reward stats updated: mean -0.0036 -> -0.0032, std: 0.1391
Collected 184 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0954, Q2 Loss=1.0954, Entropy=0.0328, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6459
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=8.4395, Q2 Loss=8.4395, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.8788
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6933, Q2 Loss=0.6933, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5593
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=1.1545, Q2 Loss=1.1545, Entropy=0.3472, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4527
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7262, Q2 Loss=0.7262, Entropy=0.0014, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3927

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.1%)
Actor update: 0.09s (37.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000144
Q1 loss: 2.421776
Q2 loss: 2.421776
Current threshold: -28.4335
Global Scale Offset: 0.4841
Reward stats: mean=-0.0032, std=0.1391, count=184
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.4218, Q2 Loss: 2.4218, Entropy: 0.0763, Mean TD Error: 1.7859, Threshold: -28.4335
tensor([ 0.2122,  0.7197,  0.4890,  0.5905,  0.0253,  0.6774,  0.8393,  0.7815,
         1.2854,  0.3247,  0.1248,  0.9318, -0.0533, -0.0847, -0.1400,  0.7345],
       device='cuda:1')
Original likelihood: -30.16111946105957
Adjusted likelihood: -30.16111946105957
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0543)
State is out of distribution
Projection step: 0, Loss: 23.419261932373047
Projection step: 1, Loss: 23.543682098388672
Projection step: 2, Loss: 31.149934768676758
Projection step: 3, Loss: 30.490161895751953
Projection step: 4, Loss: 31.604354858398438
Projection step: 5, Loss: 30.341217041015625
Projection step: 6, Loss: 29.942256927490234
Projection step: 7, Loss: 29.320560455322266
Projection step: 8, Loss: 27.241046905517578
Projection step: 9, Loss: 26.352500915527344
Projection step: 10, Loss: 25.219409942626953
Projection step: 11, Loss: 24.58005142211914
Projection step: 12, Loss: 23.300968170166016
Projection step: 13, Loss: 22.226346969604492
Projection step: 14, Loss: 21.81957244873047
Final likelihood: tensor([-21.3787, -21.3328, -20.4945, -20.7934, -21.5681, -21.0235, -21.7915,
        -20.7076, -21.6388, -21.0271, -20.0922, -21.0626, -21.0944, -20.9096,
        -21.3881, -21.0629])
Final projection likelihood: -21.0854
1 mode projection succeeded
New goal: tensor([ 0.1483,  0.6307,  0.3640,  0.8726,  0.0196,  0.6387,  0.9037,  0.6451,
         1.2892,  0.2156,  0.1854,  0.8879, -0.0370, -0.0699, -1.4388],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -26.744117736816406
Adjusted likelihood: -26.744117736816406
Likelihood residual: 0.0
Original likelihood: -34.023014068603516
Adjusted likelihood: -34.023014068603516
Likelihood residual: 0.0
{'index': 34.023014068603516, 'thumb_middle': 26.744117736816406}
Current yaw: tensor([-0.0533, -0.0847, -0.1400], device='cuda:1')
2 thumb_middle
tensor([ 0.2122,  0.7197,  0.4890,  0.5905,  0.0253,  0.6774,  0.8393,  0.7815,
         1.2854,  0.3247,  0.1248,  0.9318, -0.0533, -0.0847, -0.1400,  0.7345],
       device='cuda:1')
Solve time for step 1 9.245858173002489
Current ori: tensor([-0.0533, -0.0847, -0.1400], device='cuda:1')
Index force: tensor([0.5572, 0.5945, 0.5815, 0.5928], device='cuda:1')
tensor([ 0.2004,  0.6894,  0.4132,  0.8070, -0.0626,  0.6253,  0.8540,  0.6526,
         1.2650,  0.2267,  0.1052,  0.8686, -0.0269, -0.0745, -0.1400,  0.8246],
       device='cuda:1')
Solve time for step 2 2.088697681989288
Current ori: tensor([-0.0269, -0.0745, -0.1400], device='cuda:1')
Index force: tensor([0.5866, 0.5763, 0.5883], device='cuda:1')
tensor([ 0.1716,  0.6790,  0.3749,  0.8438, -0.0894,  0.6231,  0.8635,  0.6329,
         1.2833,  0.2175,  0.1180,  0.8638, -0.0238, -0.0553, -0.1400,  0.7927],
       device='cuda:1')
Solve time for step 3 2.0177615940046962
Current ori: tensor([-0.0238, -0.0553, -0.1400], device='cuda:1')
Index force: tensor([0.5698, 0.5826], device='cuda:1')
tensor([ 0.1814,  0.6976,  0.3618,  0.8395, -0.0876,  0.6345,  0.8756,  0.6276,
         1.2816,  0.2087,  0.1080,  0.8631, -0.0274, -0.0623, -0.1400,  0.8010],
       device='cuda:1')
Solve time for step 4 1.8133874789928086
Current ori: tensor([-0.0274, -0.0623, -0.1400], device='cuda:1')
Index force: tensor([0.5934], device='cuda:1')
Storing RECOVERY transition: reward=0.0009 (scaled=0.0005), steps=2
Reward stats updated: mean -0.0032 -> -0.0032, std: 0.1388
Collected 185 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=0.8302, Q2 Loss=0.8302, Entropy=0.2952, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0314
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6934, Q2 Loss=0.6934, Entropy=0.1137, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3091
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8317, Q2 Loss=0.8317, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3518
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.4434, Q2 Loss=1.4434, Entropy=0.0956, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0398
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=1.2075, Q2 Loss=1.2075, Entropy=0.3299, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2857

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.05s (18.1%)
Actor update: 0.11s (39.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000360
Q1 loss: 1.001220
Q2 loss: 1.001220
Current threshold: -28.4059
Global Scale Offset: 0.4835
Reward stats: mean=-0.0032, std=0.1388, count=185
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.0012, Q2 Loss: 1.0012, Entropy: 0.1669, Mean TD Error: 0.8035, Threshold: -28.4059
Original likelihood: -21.869647979736328
Adjusted likelihood: -21.869647979736328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0202, -0.0563, -0.1334], device='cuda:1')
3 turn
Sampling time 3.718345658009639
tensor([ 0.1722,  0.6773,  0.3684,  0.8625, -0.0450,  0.6761,  0.9141,  0.6481,
         1.3359,  0.2195,  0.1765,  0.9068, -0.0202, -0.0563, -0.1334,  0.7925],
       device='cuda:1')
Original likelihood: -23.741880416870117
Adjusted likelihood: -23.741880416870117
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.43099664300098
Current ori: tensor([-0.0202, -0.0563, -0.1334], device='cuda:1')
Middle force: tensor([0.5164, 0.9601, 1.9970, 1.3877, 0.5598, 1.4692, 0.6149, 0.5224, 0.9694,
        0.5653, 0.6714, 0.9556], device='cuda:1')
Thumb force: tensor([1.0505, 1.7606, 1.6182, 1.3021, 0.5467, 1.1682, 1.0228, 0.7878, 0.5948,
        0.5999, 1.2219, 1.3596], device='cuda:1')
Index force: tensor([0.5681, 0.5862, 0.5621, 0.5225, 0.6389, 0.6382, 0.5876, 0.5621, 0.6219,
        0.5867, 0.6383, 0.5551], device='cuda:1')
Storing NORMAL transition: reward=0.0849 (scaled=0.0849), steps=1
Reward stats updated: mean -0.0032 -> -0.0027, std: 0.1385
Collected 186 transitions for RL
SAC Update 1/5: Actor Loss=-0.0015, Q1 Loss=1.4033, Q2 Loss=1.4033, Entropy=0.3521, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9165
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4478, Q2 Loss=1.4478, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0774
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7195, Q2 Loss=0.7195, Entropy=0.0327, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5092
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.6162, Q2 Loss=0.6162, Entropy=0.2520, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4048
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1676, Q2 Loss=1.1676, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2624

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.8%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (20.5%)
Actor update: 0.13s (42.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000340
Q1 loss: 1.070893
Q2 loss: 1.070893
Current threshold: -28.3738
Global Scale Offset: 0.4828
Reward stats: mean=-0.0027, std=0.1385, count=186
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.0709, Q2 Loss: 1.0709, Entropy: 0.1274, Mean TD Error: 0.8341, Threshold: -28.3738
tensor([ 0.2252,  0.5832,  0.4756,  1.0167,  0.0060,  0.6694,  0.9448,  0.7083,
         1.3465,  0.1697,  0.1048,  0.9571, -0.0118, -0.0950, -0.2254,  0.7608],
       device='cuda:1')
Original likelihood: -29.891582489013672
Adjusted likelihood: -29.891582489013672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0789)
State is out of distribution
Projection step: 0, Loss: 29.401607513427734
Projection step: 1, Loss: 28.46251678466797
Projection step: 2, Loss: 26.86501693725586
Projection step: 3, Loss: 26.681472778320312
Projection step: 4, Loss: 26.60956573486328
Projection step: 5, Loss: 25.77846336364746
Projection step: 6, Loss: 25.223552703857422
Projection step: 7, Loss: 24.47650909423828
Projection step: 8, Loss: 24.284494400024414
Projection step: 9, Loss: 23.594865798950195
Projection step: 10, Loss: 23.086965560913086
Projection step: 11, Loss: 22.46826934814453
Projection step: 12, Loss: 22.750627517700195
Projection step: 13, Loss: 21.84535026550293
Projection step: 14, Loss: 21.067974090576172
Final likelihood: tensor([-20.3720, -20.6429, -20.4945, -20.0868, -19.0608, -20.5864, -20.2771,
        -20.0278, -20.8858, -19.3815, -19.9369, -20.2907, -20.5257, -20.8792,
        -20.2126, -21.5016])
Final projection likelihood: -20.3226
1 mode projection succeeded
New goal: tensor([ 0.1475,  0.5190,  0.4997,  0.9913,  0.0310,  0.6595,  0.9561,  0.5476,
         1.3489,  0.1477,  0.1822,  0.8880, -0.0200, -0.0746, -0.4719],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -23.156471252441406
Adjusted likelihood: -23.156471252441406
Likelihood residual: 0.0
Original likelihood: -27.151079177856445
Adjusted likelihood: -27.151079177856445
Likelihood residual: 0.0
{'index': 27.151079177856445, 'thumb_middle': 23.156471252441406}
Current yaw: tensor([-0.0118, -0.0950, -0.2254], device='cuda:1')
4 thumb_middle
tensor([ 0.2252,  0.5832,  0.4756,  1.0167,  0.0060,  0.6694,  0.9448,  0.7083,
         1.3465,  0.1697,  0.1048,  0.9571, -0.0118, -0.0950, -0.2254,  0.7608],
       device='cuda:1')
Solve time for step 1 9.7942083789967
Current ori: tensor([-0.0118, -0.0950, -0.2254], device='cuda:1')
Index force: tensor([0.6001, 0.5902, 0.6113, 0.6126], device='cuda:1')
tensor([ 0.1833,  0.5406,  0.4974,  1.0038, -0.0719,  0.6294,  0.9091,  0.5614,
         1.3120,  0.1376,  0.0897,  0.8737, -0.0082, -0.0692, -0.2254,  0.7354],
       device='cuda:1')
Solve time for step 2 2.1436691720155068
Current ori: tensor([-0.0082, -0.0692, -0.2254], device='cuda:1')
Index force: tensor([0.5864, 0.6084, 0.6096], device='cuda:1')
tensor([ 0.1905,  0.5401,  0.5074,  1.0005, -0.0770,  0.6494,  0.9197,  0.5328,
         1.3223,  0.1316,  0.0844,  0.8540, -0.0076, -0.0734, -0.2254,  0.7425],
       device='cuda:1')
Solve time for step 3 2.0120274299988523
Current ori: tensor([-0.0076, -0.0734, -0.2254], device='cuda:1')
Index force: tensor([0.6039, 0.6068], device='cuda:1')
tensor([ 0.1784,  0.5368,  0.5003,  0.9973, -0.0891,  0.6513,  0.9171,  0.5292,
         1.3281,  0.1302,  0.0883,  0.8545, -0.0087, -0.0662, -0.2254,  0.7255],
       device='cuda:1')
Solve time for step 4 2.0182090559974313
Current ori: tensor([-0.0087, -0.0662, -0.2254], device='cuda:1')
Index force: tensor([0.6034], device='cuda:1')
Storing RECOVERY transition: reward=0.0026 (scaled=0.0026), steps=1
Reward stats updated: mean -0.0027 -> -0.0027, std: 0.1382
Collected 187 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8982, Q2 Loss=0.8982, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3451
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6968, Q2 Loss=0.6968, Entropy=0.1373, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3141
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1260, Q2 Loss=1.1260, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5316
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1546, Q2 Loss=1.1546, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4156
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2467, Q2 Loss=1.2467, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6429

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.3%)
Q1 update: 0.07s (21.8%)
Q2 update: 0.06s (19.1%)
Actor update: 0.13s (41.0%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 1.024439
Q2 loss: 1.024439
Current threshold: -28.3567
Global Scale Offset: 0.4825
Reward stats: mean=-0.0027, std=0.1382, count=187
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0244, Q2 Loss: 1.0244, Entropy: 0.0275, Mean TD Error: 0.6499, Threshold: -28.3567
Original likelihood: -25.053287506103516
Adjusted likelihood: -25.053287506103516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9990)
Current yaw: tensor([-0.0073, -0.0702, -0.2232], device='cuda:1')
5 turn
Sampling time 3.765178070985712
tensor([ 0.1789,  0.5435,  0.4953,  0.9901, -0.0304,  0.6981,  0.9586,  0.5461,
         1.3879,  0.1482,  0.1417,  0.8906, -0.0073, -0.0702, -0.2232,  0.8377],
       device='cuda:1')
Original likelihood: -25.243459701538086
Adjusted likelihood: -25.243459701538086
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9981)
Solve time for step 1 15.351097275997745
Current ori: tensor([-0.0073, -0.0702, -0.2232], device='cuda:1')
Middle force: tensor([0.9658, 0.5908, 0.6552, 1.0231, 1.1019, 0.8030, 0.6342, 0.7322, 0.5896,
        0.8497, 0.8304, 0.9388], device='cuda:1')
Thumb force: tensor([1.1419, 1.0618, 0.9596, 0.8586, 1.9174, 0.8358, 1.0049, 0.5539, 0.6040,
        0.5290, 0.5767, 1.0110], device='cuda:1')
Index force: tensor([0.8791, 0.6303, 0.5550, 0.7977, 0.5194, 0.5734, 0.6435, 0.5624, 0.5872,
        0.6155, 0.5037, 0.8146], device='cuda:1')
Storing NORMAL transition: reward=-0.0001 (scaled=-0.0001), steps=1
Reward stats updated: mean -0.0027 -> -0.0027, std: 0.1378
Collected 188 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7659, Q2 Loss=0.7659, Entropy=0.0080, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3909
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=2.8447, Q2 Loss=2.8447, Entropy=0.0011, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9026
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.6176, Q2 Loss=0.6176, Entropy=0.2530, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1059
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0014, Q2 Loss=1.0014, Entropy=0.0931, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5559
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0936, Q2 Loss=1.0936, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3407

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.9%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.06s (20.8%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000052
Q1 loss: 1.264638
Q2 loss: 1.264638
Current threshold: -28.3484
Global Scale Offset: 0.4828
Reward stats: mean=-0.0027, std=0.1378, count=188
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2646, Q2 Loss: 1.2646, Entropy: 0.0710, Mean TD Error: 1.4592, Threshold: -28.3484
tensor([ 0.1368,  0.4874,  0.5638,  0.9163, -0.0641,  0.7086,  0.8701,  0.6346,
         1.4125,  0.1336,  0.1947,  0.8225, -0.0090, -0.0423, -0.2201,  0.7039],
       device='cuda:1')
Original likelihood: -20.17584991455078
Adjusted likelihood: -20.17584991455078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.1194150490046013
Current ori: tensor([-0.0090, -0.0423, -0.2201], device='cuda:1')
Middle force: tensor([0.5900, 0.6543, 1.0121, 1.0910, 0.7978, 0.6306, 0.7301, 0.5880, 0.8433,
        0.8261, 0.9304], device='cuda:1')
Thumb force: tensor([1.0506, 0.9508, 0.8527, 1.8912, 0.8293, 0.9981, 0.5520, 0.6019, 0.5274,
        0.5754, 1.0045], device='cuda:1')
Index force: tensor([0.6236, 0.5530, 0.7929, 0.5187, 0.5715, 0.6408, 0.5610, 0.5854, 0.6135,
        0.5035, 0.8107], device='cuda:1')
Storing NORMAL transition: reward=0.0909 (scaled=0.0909), steps=1
Reward stats updated: mean -0.0027 -> -0.0022, std: 0.1376
Collected 189 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=20.7576, Q2 Loss=20.7576, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9537
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.9379, Q2 Loss=0.9379, Entropy=0.2494, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2881
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.9771, Q2 Loss=2.9771, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9321
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8885, Q2 Loss=0.8885, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4716
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.8451, Q2 Loss=0.8451, Entropy=0.1337, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0805

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.4%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.0%)
Actor update: 0.13s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000060
Q1 loss: 5.281249
Q2 loss: 5.281249
Current threshold: -28.3472
Global Scale Offset: 0.4834
Reward stats: mean=-0.0022, std=0.1376, count=189
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 5.2812, Q2 Loss: 5.2812, Entropy: 0.0766, Mean TD Error: 2.7452, Threshold: -28.3472
tensor([ 0.0598,  0.3778,  0.6425,  0.9163, -0.2364,  0.7942,  0.7566,  0.7207,
         1.4258,  0.2302,  0.2300,  0.8314,  0.0213,  0.0022, -0.3097,  0.8798],
       device='cuda:1')
Original likelihood: -34.4444465637207
Adjusted likelihood: -34.4444465637207
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 33.815895080566406
Projection step: 1, Loss: 32.79775619506836
Projection step: 2, Loss: 31.516193389892578
Projection step: 3, Loss: 29.30568504333496
Projection step: 4, Loss: 27.352031707763672
Projection step: 5, Loss: 26.423805236816406
Projection step: 6, Loss: 26.170549392700195
Projection step: 7, Loss: 24.563203811645508
Projection step: 8, Loss: 24.377710342407227
Projection step: 9, Loss: 22.77272605895996
Projection step: 10, Loss: 21.564228057861328
Projection step: 11, Loss: 21.36420440673828
Projection step: 12, Loss: 19.53667449951172
Projection step: 13, Loss: 18.463415145874023
Projection step: 14, Loss: 16.67997932434082
Final likelihood: tensor([-11.2257, -18.5606, -20.4531, -11.9713, -12.0170, -11.4675, -11.5277,
        -18.5200, -15.6972, -11.1294, -16.4178, -11.6183, -16.9633, -15.1558,
        -17.9473, -11.5153])
Final projection likelihood: -14.5117
1 mode projection succeeded
New goal: tensor([ 0.0632,  0.4521,  0.6026,  0.8700, -0.0850,  0.6207,  0.7991,  0.8817,
         1.3616,  0.1597,  0.2007,  1.0154,  0.0132,  0.0024, -0.6703],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0077]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -20.80756378173828
Adjusted likelihood: -20.80756378173828
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.80756378173828}
Current yaw: tensor([ 0.0213,  0.0022, -0.3097], device='cuda:1')
6 thumb_middle
tensor([ 0.0598,  0.3778,  0.6425,  0.9163, -0.2364,  0.7942,  0.7566,  0.7207,
         1.4258,  0.2302,  0.2300,  0.8314,  0.0213,  0.0022, -0.3097,  0.8798],
       device='cuda:1')
Solve time for step 1 9.834258146001957
Current ori: tensor([ 0.0213,  0.0022, -0.3097], device='cuda:1')
Index force: tensor([0.5775, 0.5746, 0.5067, 0.5927], device='cuda:1')
tensor([ 0.0719,  0.3740,  0.6373,  0.9532, -0.2062,  0.6638,  0.7507,  0.8084,
         1.3291,  0.1593,  0.1474,  0.9486,  0.0238, -0.0038, -0.3097,  0.8257],
       device='cuda:1')
Solve time for step 2 2.097597827989375
Current ori: tensor([ 0.0238, -0.0038, -0.3097], device='cuda:1')
Index force: tensor([0.5669, 0.5009, 0.5875], device='cuda:1')
tensor([ 0.0867,  0.3819,  0.6385,  0.9553, -0.1923,  0.6375,  0.7726,  0.8505,
         1.3482,  0.1485,  0.1026,  0.9714,  0.0228, -0.0118, -0.3097,  0.8436],
       device='cuda:1')
Solve time for step 3 1.9397959539783187
Current ori: tensor([ 0.0228, -0.0118, -0.3097], device='cuda:1')
Index force: tensor([0.5007, 0.5780], device='cuda:1')
tensor([ 0.0836,  0.3940,  0.6312,  0.9352, -0.1918,  0.6320,  0.7748,  0.8408,
         1.3318,  0.1552,  0.1152,  0.9834,  0.0170, -0.0106, -0.3097,  0.8308],
       device='cuda:1')
Solve time for step 4 1.9889797249925323
Current ori: tensor([ 0.0170, -0.0106, -0.3097], device='cuda:1')
Index force: tensor([0.5735], device='cuda:1')
Storing RECOVERY transition: reward=0.0120 (scaled=0.0060), steps=2
Reward stats updated: mean -0.0022 -> -0.0021, std: 0.1372
Collected 190 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8117, Q2 Loss=0.8117, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4081
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2167, Q2 Loss=1.2167, Entropy=0.0286, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6921
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7732, Q2 Loss=0.7732, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3993
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8636, Q2 Loss=0.8636, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2593
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6974, Q2 Loss=0.6974, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9648

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.06s (19.4%)
Actor update: 0.12s (39.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 0.872521
Q2 loss: 0.872521
Current threshold: -28.3480
Global Scale Offset: 0.4841
Reward stats: mean=-0.0021, std=0.1372, count=190
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8725, Q2 Loss: 0.8725, Entropy: 0.0057, Mean TD Error: 0.9447, Threshold: -28.3480
Original likelihood: -22.240516662597656
Adjusted likelihood: -22.240516662597656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0122, -0.0059, -0.3214], device='cuda:1')
7 turn
Sampling time 3.685629222978605
tensor([ 0.0645,  0.4216,  0.5949,  0.8983, -0.1356,  0.6607,  0.8029,  0.9043,
         1.4021,  0.1566,  0.1618,  1.0167,  0.0122, -0.0059, -0.3214,  0.9709],
       device='cuda:1')
Original likelihood: -19.423099517822266
Adjusted likelihood: -19.423099517822266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.506720589008182
Current ori: tensor([ 0.0122, -0.0059, -0.3214], device='cuda:1')
Middle force: tensor([0.8185, 0.7347, 0.7209, 0.8852, 0.9996, 0.5830, 0.8927, 0.5309, 0.5801,
        0.5033, 0.5699, 0.5930], device='cuda:1')
Thumb force: tensor([0.5340, 0.5492, 1.8245, 0.7290, 0.9610, 0.5720, 0.6088, 0.5744, 0.5164,
        0.5677, 0.5878, 0.6021], device='cuda:1')
Index force: tensor([0.8097, 0.5459, 1.0635, 0.8019, 1.0813, 0.6224, 0.5262, 0.5104, 0.6473,
        0.7600, 0.5564, 0.6710], device='cuda:1')
Storing NORMAL transition: reward=0.0675 (scaled=0.0675), steps=1
Reward stats updated: mean -0.0021 -> -0.0018, std: 0.1370
Collected 191 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1248, Q2 Loss=1.1248, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8732
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0428, Q2 Loss=1.0428, Entropy=0.0401, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8190
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6986, Q2 Loss=0.6986, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3170
SAC Update 4/5: Actor Loss=-0.0013, Q1 Loss=0.7255, Q2 Loss=0.7255, Entropy=0.0027, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6588
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6753, Q2 Loss=0.6753, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0900

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.0%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.07s (19.9%)
Actor update: 0.14s (41.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000255
Q1 loss: 0.853384
Q2 loss: 0.853384
Current threshold: -28.3454
Global Scale Offset: 0.4836
Reward stats: mean=-0.0018, std=0.1370, count=191
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.8534, Q2 Loss: 0.8534, Entropy: 0.0086, Mean TD Error: 0.7516, Threshold: -28.3454
tensor([ 5.7387e-02,  4.0471e-01,  5.9770e-01,  9.2852e-01, -1.4583e-01,
         6.5811e-01,  7.6563e-01,  1.0052e+00,  1.4277e+00,  1.5631e-01,
         1.9955e-01,  9.1944e-01,  1.8591e-02, -1.3583e-03, -3.8909e-01,
         9.7932e-01], device='cuda:1')
Original likelihood: -22.814044952392578
Adjusted likelihood: -22.814044952392578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.215004477999173
Current ori: tensor([ 0.0186, -0.0014, -0.3891], device='cuda:1')
Middle force: tensor([0.7306, 0.7124, 0.8866, 0.9901, 0.5807, 0.8899, 0.5303, 0.5797, 0.5030,
        0.5689, 0.5919], device='cuda:1')
Thumb force: tensor([0.5487, 1.8098, 0.7239, 0.9607, 0.5707, 0.6073, 0.5739, 0.5154, 0.5665,
        0.5870, 0.6007], device='cuda:1')
Index force: tensor([0.5441, 1.0609, 0.7948, 1.0746, 0.6230, 0.5255, 0.5103, 0.6481, 0.7632,
        0.5555, 0.6690], device='cuda:1')
Storing NORMAL transition: reward=-0.0096 (scaled=-0.0096), steps=1
Reward stats updated: mean -0.0018 -> -0.0018, std: 0.1366
Collected 192 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2999, Q2 Loss=1.2999, Entropy=0.0300, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8939
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8555, Q2 Loss=0.8555, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2416
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0245, Q2 Loss=1.0245, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5553
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8559, Q2 Loss=0.8559, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5193
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.8088, Q2 Loss=3.8088, Entropy=0.0842, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1231

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.2%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.07s (20.0%)
Actor update: 0.14s (41.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000010
Q1 loss: 1.568948
Q2 loss: 1.568948
Current threshold: -28.3403
Global Scale Offset: 0.4823
Reward stats: mean=-0.0018, std=0.1366, count=192
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.5689, Q2 Loss: 1.5689, Entropy: 0.0228, Mean TD Error: 2.0666, Threshold: -28.3403
tensor([-0.0875,  0.2662,  0.6835,  0.8995, -0.2018,  0.6253,  0.6966,  0.9338,
         1.4527,  0.0155,  0.3134,  0.7977,  0.0456,  0.0688, -0.3864,  0.7349],
       device='cuda:1')
Original likelihood: -24.620323181152344
Adjusted likelihood: -24.620323181152344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 3 3.04560451299767
Current ori: tensor([ 0.0456,  0.0688, -0.3864], device='cuda:1')
Middle force: tensor([0.5335, 2.6478, 0.6298, 0.5020, 0.9052, 0.6318, 0.6179, 0.5014, 0.5207,
        0.5830], device='cuda:1')
Thumb force: tensor([0.5531, 0.6368, 0.5511, 0.5033, 1.4182, 0.6126, 0.5867, 0.5752, 0.5869,
        0.5926], device='cuda:1')
Index force: tensor([0.5027, 1.4032, 0.5691, 0.7009, 0.5887, 0.6619, 0.5774, 0.7457, 0.6240,
        0.5884], device='cuda:1')
Storing NORMAL transition: reward=-0.0702 (scaled=-0.0702), steps=1
Reward stats updated: mean -0.0018 -> -0.0022, std: 0.1364
Collected 193 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=8.5357, Q2 Loss=8.5357, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=7.0193
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9346, Q2 Loss=0.9346, Entropy=0.0843, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6218
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6162, Q2 Loss=0.6162, Entropy=0.0218, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1335
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7351, Q2 Loss=0.7351, Entropy=0.0024, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5924
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2589, Q2 Loss=1.2589, Entropy=0.1052, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9317

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.0%)
Q1 update: 0.07s (21.4%)
Q2 update: 0.07s (19.1%)
Actor update: 0.15s (42.7%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000014
Q1 loss: 2.416104
Q2 loss: 2.416104
Current threshold: -28.3359
Global Scale Offset: 0.4818
Reward stats: mean=-0.0022, std=0.1364, count=193
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.4161, Q2 Loss: 2.4161, Entropy: 0.0427, Mean TD Error: 1.8598, Threshold: -28.3359
tensor([-0.2341,  0.2785,  0.6378,  0.7762, -0.2693,  0.5906,  0.7066,  1.0381,
         1.4536,  0.2144,  0.4438,  0.5785,  0.0821,  0.1016, -0.3251,  1.0127],
       device='cuda:1')
Original likelihood: -17.81720733642578
Adjusted likelihood: -17.81720733642578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.966855756996665
Current ori: tensor([ 0.0821,  0.1016, -0.3251], device='cuda:1')
Middle force: tensor([1.0491, 0.5821, 0.5257, 0.5055, 0.7691, 0.5946, 1.2900, 0.5948, 0.7103],
       device='cuda:1')
Thumb force: tensor([0.5433, 0.5875, 1.4754, 0.5642, 1.1066, 0.5856, 0.9281, 1.2870, 0.5693],
       device='cuda:1')
Index force: tensor([0.6038, 0.5322, 0.8611, 0.5897, 0.5789, 0.5983, 0.5506, 0.6097, 0.5255],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0190 (scaled=-0.0190), steps=1
Reward stats updated: mean -0.0022 -> -0.0023, std: 0.1360
Collected 194 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2416, Q2 Loss=1.2416, Entropy=0.0072, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6739
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=0.5922, Q2 Loss=0.5922, Entropy=0.3352, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2799
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6529, Q2 Loss=0.6529, Entropy=0.0893, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2449
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9018, Q2 Loss=0.9018, Entropy=0.0024, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0489
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1788, Q2 Loss=1.1788, Entropy=0.0020, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4501

------ SAC Update Summary (5 iterations) ------
Total time: 0.34s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.5%)
Q1 update: 0.07s (21.6%)
Q2 update: 0.07s (20.3%)
Actor update: 0.14s (40.9%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000196
Q1 loss: 0.913462
Q2 loss: 0.913462
Current threshold: -28.3239
Global Scale Offset: 0.4815
Reward stats: mean=-0.0023, std=0.1360, count=194
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.9135, Q2 Loss: 0.9135, Entropy: 0.0872, Mean TD Error: 0.3395, Threshold: -28.3239
tensor([-0.1084,  0.3175,  0.5898,  0.9126, -0.2092,  0.6278,  0.7216,  1.0766,
         1.4998,  0.2364,  0.3911,  0.6144,  0.0908,  0.0517, -0.2999,  1.2368],
       device='cuda:1')
Original likelihood: -23.982410430908203
Adjusted likelihood: -23.982410430908203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.825503423984628
Current ori: tensor([ 0.0908,  0.0517, -0.2999], device='cuda:1')
Middle force: tensor([0.6459, 0.5689, 0.5174, 0.8984, 0.5735, 0.5308, 0.5712, 0.5974],
       device='cuda:1')
Thumb force: tensor([0.5548, 0.5449, 0.5085, 0.9631, 0.6786, 0.5839, 0.5430, 0.5700],
       device='cuda:1')
Index force: tensor([0.5489, 0.6935, 0.6270, 0.6065, 0.5443, 0.6408, 0.6165, 0.5276],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0288 (scaled=-0.0288), steps=1
Reward stats updated: mean -0.0023 -> -0.0024, std: 0.1357
Collected 195 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=0.8830, Q2 Loss=0.8830, Entropy=0.3277, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3336
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.8853, Q2 Loss=0.8853, Entropy=0.2398, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3820
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8898, Q2 Loss=0.8898, Entropy=0.0003, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6727
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.9408, Q2 Loss=0.9408, Entropy=0.0037, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8748
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=4.4221, Q2 Loss=4.4221, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.2752

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (19.7%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001744
Q1 loss: 1.604202
Q2 loss: 1.604202
Current threshold: -28.2931
Global Scale Offset: 0.4755
Reward stats: mean=-0.0024, std=0.1357, count=195
----------------------------------------------
SAC Update - Actor Loss: -0.0017, Q1 Loss: 1.6042, Q2 Loss: 1.6042, Entropy: 0.1143, Mean TD Error: 1.7077, Threshold: -28.2931
tensor([-0.0790,  0.3316,  0.5668,  0.9539, -0.1994,  0.6075,  0.7684,  1.0722,
         1.5000,  0.1580,  0.3636,  0.5949,  0.1029,  0.0429, -0.2719,  1.3066],
       device='cuda:1')
Original likelihood: -29.504653930664062
Adjusted likelihood: -29.504653930664062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1270)
State is out of distribution
Projection step: 0, Loss: 30.104076385498047
Projection step: 1, Loss: 30.413827896118164
Projection step: 2, Loss: 28.77362823486328
Projection step: 3, Loss: 30.21269989013672
Projection step: 4, Loss: 27.627363204956055
Projection step: 5, Loss: 28.203014373779297
Projection step: 6, Loss: 28.216304779052734
Projection step: 7, Loss: 25.111305236816406
Projection step: 8, Loss: 27.14946746826172
Projection step: 9, Loss: 25.43353271484375
Projection step: 10, Loss: 26.843963623046875
Projection step: 11, Loss: 25.290279388427734
Projection step: 12, Loss: 24.595176696777344
Projection step: 13, Loss: 25.93423843383789
Projection step: 14, Loss: 25.455585479736328
Final likelihood: tensor([-23.4071, -26.4055, -24.3672, -25.9653, -26.7264, -25.4627, -26.3990,
        -26.0112, -26.3205, -24.3189, -25.9163, -25.5005, -27.0963, -25.5505,
        -24.0052, -26.6683])
Final projection likelihood: -25.6326
1 mode projection succeeded
New goal: tensor([-0.1173,  0.3502,  0.4232,  1.0904, -0.1587,  0.5618,  0.6738,  1.0987,
         1.4943,  0.1554,  0.3586,  0.9852,  0.0958,  0.0544,  1.1201],
       device='cuda:1')
tensor([[0.0073]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -26.729740142822266
Adjusted likelihood: -26.729740142822266
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 26.729740142822266}
Current yaw: tensor([ 0.1029,  0.0429, -0.2719], device='cuda:1')
8 thumb_middle
tensor([-0.0790,  0.3316,  0.5668,  0.9539, -0.1994,  0.6075,  0.7684,  1.0722,
         1.5000,  0.1580,  0.3636,  0.5949,  0.1029,  0.0429, -0.2719,  1.3066],
       device='cuda:1')
Solve time for step 1 9.234566297003767
Current ori: tensor([ 0.1029,  0.0429, -0.2719], device='cuda:1')
Index force: tensor([0.5654, 0.5924, 0.5924, 0.5918], device='cuda:1')
tensor([-0.0834,  0.3726,  0.4519,  1.0539, -0.2452,  0.5792,  0.6800,  1.0686,
         1.4203,  0.0995,  0.2675,  0.8485,  0.1655,  0.0964, -0.2719,  1.8958],
       device='cuda:1')
Solve time for step 2 2.077287463005632
Current ori: tensor([ 0.1655,  0.0964, -0.2719], device='cuda:1')
Index force: tensor([0.5872, 0.5899, 0.5890], device='cuda:1')
tensor([-0.0814,  0.3640,  0.4611,  1.0970, -0.2572,  0.5785,  0.6627,  1.0552,
         1.4606,  0.1166,  0.2581,  0.9228,  0.1959,  0.1105, -0.2152,  2.1773],
       device='cuda:1')
Solve time for step 3 2.0688737229793333
Current ori: tensor([ 0.1959,  0.1105, -0.2152], device='cuda:1')
Index force: tensor([0.5844, 0.5842], device='cuda:1')
tensor([-0.0845,  0.3662,  0.4455,  1.1178, -0.2671,  0.5727,  0.6495,  1.0878,
         1.4659,  0.1268,  0.2893,  0.9423,  0.1989,  0.1129, -0.1788,  2.1990],
       device='cuda:1')
Solve time for step 4 1.9881118699850049
Current ori: tensor([ 0.1989,  0.1129, -0.1788], device='cuda:1')
Index force: tensor([0.5754], device='cuda:1')
Storing RECOVERY transition: reward=-0.1942 (scaled=-0.0388), steps=5
Reward stats updated: mean -0.0024 -> -0.0026, std: 0.1354
Collected 196 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6887, Q2 Loss=0.6887, Entropy=0.1904, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4066
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0742, Q2 Loss=1.0742, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3412
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=3.4135, Q2 Loss=3.4135, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.7348
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0367, Q2 Loss=1.0367, Entropy=0.0013, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5745
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2744, Q2 Loss=1.2744, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7158

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.5%)
Target Q: 0.06s (17.1%)
Q1 update: 0.07s (20.9%)
Q2 update: 0.06s (18.8%)
Actor update: 0.13s (40.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000003
Q1 loss: 1.497516
Q2 loss: 1.497516
Current threshold: -28.2587
Global Scale Offset: 0.4654
Reward stats: mean=-0.0026, std=0.1354, count=196
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.4975, Q2 Loss: 1.4975, Entropy: 0.0383, Mean TD Error: 1.3546, Threshold: -28.2587
Original likelihood: -46.28710174560547
Adjusted likelihood: -46.28710174560547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 42.64273452758789
Projection step: 1, Loss: 44.82421112060547
Projection step: 2, Loss: 39.35390853881836
Projection step: 3, Loss: 38.9012451171875
Projection step: 4, Loss: 39.20053482055664
Projection step: 5, Loss: 36.875999450683594
Projection step: 6, Loss: 37.11669158935547
Projection step: 7, Loss: 37.562164306640625
Projection step: 8, Loss: 35.26968765258789
Projection step: 9, Loss: 36.81810760498047
Projection step: 10, Loss: 33.31096649169922
Projection step: 11, Loss: 33.7412109375
Projection step: 12, Loss: 32.081932067871094
Projection step: 13, Loss: 30.415925979614258
Projection step: 14, Loss: 33.38188552856445
Final likelihood: tensor([-28.7287, -30.8554, -27.3587, -48.8550, -36.7220, -30.2032, -29.9747,
        -43.2113, -31.4436, -31.5418, -34.6725, -32.4517, -26.6290, -39.6133,
        -25.9935, -33.1709])
Final projection likelihood: -33.2141
1 mode projection failed, trying anyway
New goal: tensor([-0.0892,  0.3889,  0.4991,  0.9958, -0.1453,  0.5484,  0.6748,  1.1665,
         1.5121, -0.0398,  0.3427,  0.8862,  0.2110,  0.0714,  0.2691],
       device='cuda:1')
tensor([[0.0050]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -31.946609497070312
Adjusted likelihood: -31.946609497070312
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 31.946609497070312}
Current yaw: tensor([ 0.2232,  0.0685, -0.1028], device='cuda:1')
9 thumb_middle
tensor([-0.1050,  0.4081,  0.4438,  1.1055, -0.1527,  0.6142,  0.7091,  1.1163,
         1.5000,  0.1629,  0.3697,  0.9870,  0.2232,  0.0685, -0.1028,  2.2584],
       device='cuda:1')
Solve time for step 1 9.517742291005561
Current ori: tensor([ 0.2232,  0.0685, -0.1028], device='cuda:1')
Index force: tensor([0.6111, 0.6117, 0.5003, 0.6016], device='cuda:1')
tensor([-0.0944,  0.4175,  0.5811,  1.1070, -0.2378,  0.4932,  0.6983,  1.1874,
         1.4862, -0.0142,  0.3450,  0.9570,  0.2903,  0.1017, -0.1490,  1.8921],
       device='cuda:1')
Solve time for step 2 2.083382607990643
Current ori: tensor([ 0.2903,  0.1017, -0.1490], device='cuda:1')
Index force: tensor([0.6137, 0.5002, 0.5999], device='cuda:1')
tensor([-0.0739,  0.4237,  0.6510,  1.2175, -0.2570,  0.4112,  0.7270,  1.2124,
         1.5000, -0.0321,  0.3604,  0.9646,  0.2937,  0.1074, -0.1674,  0.8609],
       device='cuda:1')
Solve time for step 3 2.0613385399919935
Current ori: tensor([ 0.2937,  0.1074, -0.1674], device='cuda:1')
Index force: tensor([0.5002, 0.5944], device='cuda:1')
tensor([-0.0752,  0.4310,  0.6858,  1.2093, -0.2562,  0.3983,  0.7555,  1.2389,
         1.5000, -0.0459,  0.4018,  1.0046,  0.2927,  0.1066, -0.1775, -1.0573],
       device='cuda:1')
Solve time for step 4 2.014556487003574
Current ori: tensor([ 0.2927,  0.1066, -0.1775], device='cuda:1')
Index force: tensor([0.5004], device='cuda:1')
Storing RECOVERY transition: reward=-0.1866 (scaled=-0.0373), steps=5
Reward stats updated: mean -0.0026 -> -0.0028, std: 0.1350
Collected 197 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0848, Q2 Loss=1.0848, Entropy=0.0012, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4022
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.6204, Q2 Loss=0.6204, Entropy=0.4009, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2185
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1712, Q2 Loss=1.1712, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4247
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1343, Q2 Loss=1.1343, Entropy=0.0417, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4488
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.7778, Q2 Loss=0.7778, Entropy=0.4258, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4277

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.8%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000079
Q1 loss: 0.957710
Q2 loss: 0.957710
Current threshold: -28.2404
Global Scale Offset: 0.4599
Reward stats: mean=-0.0028, std=0.1350, count=197
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.9577, Q2 Loss: 0.9577, Entropy: 0.1739, Mean TD Error: 0.5844, Threshold: -28.2404
Original likelihood: -77.79566955566406
Adjusted likelihood: -77.79566955566406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 81.739013671875
Projection step: 1, Loss: 79.35942077636719
Projection step: 2, Loss: 77.16824340820312
Projection step: 3, Loss: 83.57353210449219
Projection step: 4, Loss: 76.9993667602539
Projection step: 5, Loss: 77.19709777832031
Projection step: 6, Loss: 75.68441009521484
Projection step: 7, Loss: 75.15626525878906
Projection step: 8, Loss: 75.95448303222656
Projection step: 9, Loss: 73.3148422241211
Projection step: 10, Loss: 72.03683471679688
Projection step: 11, Loss: 73.6698989868164
Projection step: 12, Loss: 67.9206771850586
Projection step: 13, Loss: 75.21058654785156
Projection step: 14, Loss: 66.16862487792969
Final likelihood: tensor([-75.0602, -79.6209, -65.9412, -64.8191, -82.4511, -82.6179, -54.9250,
        -54.5674, -53.1424, -65.0936, -85.8749, -57.0622, -64.9973, -79.8238,
        -75.1312, -79.9739])
Final projection likelihood: -70.0689
1 mode projection failed, trying anyway
New goal: tensor([-0.0409,  0.3588,  0.6560,  1.1025, -0.1280,  0.4481,  0.8121,  1.2617,
         1.4556,  0.0190,  0.5693,  0.9524,  0.2610,  0.0815,  0.7151],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[0.0005]], device='cuda:1')
Original likelihood: -80.12925720214844
Adjusted likelihood: -80.12925720214844
Likelihood residual: 0.0
Original likelihood: -68.36436462402344
Adjusted likelihood: -68.36436462402344
Likelihood residual: 0.0
{'index': 68.36436462402344, 'thumb_middle': 80.12925720214844}
Current yaw: tensor([ 0.2699,  0.0784, -0.1277], device='cuda:1')
10 index
tensor([-0.0652,  0.4633,  0.6367,  1.1222, -0.1264,  0.4581,  0.7411,  1.2421,
         1.5000, -0.0434,  0.5471,  1.1449,  0.2699,  0.0784, -0.1277, -1.7418],
       device='cuda:1')
Solve time for step 1 11.653097055008402
Current ori: tensor([ 0.2699,  0.0784, -0.1277], device='cuda:1')
Middle force: tensor([0.5046, 0.5528, 0.5614, 0.5242], device='cuda:1')
Thumb force: tensor([0.5861, 0.5777, 0.5801, 0.6404], device='cuda:1')
tensor([-0.0891,  0.1699,  0.6191,  1.0699, -0.1345,  0.4645,  0.7065,  1.2589,
         1.4693,  0.0070,  0.5756,  1.0587,  0.2654,  0.0811, -0.1510, -5.4058],
       device='cuda:1')
Solve time for step 2 2.5059817990113515
Current ori: tensor([ 0.2654,  0.0811, -0.1510], device='cuda:1')
Middle force: tensor([0.5184, 0.5808, 0.5519], device='cuda:1')
Thumb force: tensor([0.5880, 0.5375, 0.5982], device='cuda:1')
tensor([-0.0925,  0.0982,  0.6304,  1.0715, -0.1426,  0.4635,  0.6980,  1.2648,
         1.4696,  0.0119,  0.5829,  1.0390,  0.2639,  0.0833, -0.1649,  4.3962],
       device='cuda:1')
Solve time for step 3 2.4208048230211716
Current ori: tensor([ 0.2639,  0.0833, -0.1649], device='cuda:1')
Middle force: tensor([0.5791, 0.5507], device='cuda:1')
Thumb force: tensor([0.5356, 0.5978], device='cuda:1')
tensor([-8.8660e-02,  8.3786e-02,  6.3081e-01,  1.0680e+00, -1.4898e-01,
         4.6147e-01,  6.9440e-01,  1.2624e+00,  1.4881e+00, -6.3018e-04,
         5.8581e-01,  1.0157e+00,  2.6161e-01,  8.5086e-02, -1.8725e-01,
         3.6787e+00], device='cuda:1')
Solve time for step 4 2.3318990929983556
Current ori: tensor([ 0.2616,  0.0851, -0.1873], device='cuda:1')
Middle force: tensor([0.5200], device='cuda:1')
Thumb force: tensor([0.6305], device='cuda:1')
Storing RECOVERY transition: reward=-0.1679 (scaled=-0.0336), steps=5
Reward stats updated: mean -0.0028 -> -0.0029, std: 0.1347
Collected 198 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6936, Q2 Loss=0.6936, Entropy=0.1745, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3883
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=1.2628, Q2 Loss=1.2628, Entropy=0.3419, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4958
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0906, Q2 Loss=1.0906, Entropy=0.0222, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2387
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=6.3515, Q2 Loss=6.3515, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.6852
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1422, Q2 Loss=1.1422, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3051

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (13.7%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.06s (21.3%)
Actor update: 0.12s (43.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000117
Q1 loss: 2.108129
Q2 loss: 2.108129
Current threshold: -28.2236
Global Scale Offset: 0.4570
Reward stats: mean=-0.0029, std=0.1347, count=198
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.1081, Q2 Loss: 2.1081, Entropy: 0.1077, Mean TD Error: 1.8226, Threshold: -28.2236
Original likelihood: -89.701416015625
Adjusted likelihood: -89.701416015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 99.17244720458984
Projection step: 1, Loss: 104.00886535644531
Projection step: 2, Loss: 102.57283782958984
Projection step: 3, Loss: 94.02732849121094
Projection step: 4, Loss: 92.36878967285156
Projection step: 5, Loss: 94.96629333496094
Projection step: 6, Loss: 98.09514617919922
Projection step: 7, Loss: 93.40521240234375
Projection step: 8, Loss: 99.81417846679688
Projection step: 9, Loss: 98.60735321044922
Projection step: 10, Loss: 89.07048034667969
Projection step: 11, Loss: 95.66914367675781
Projection step: 12, Loss: 90.23060607910156
Projection step: 13, Loss: 87.83657836914062
Projection step: 14, Loss: 93.00070190429688
Final likelihood: tensor([ -74.9545, -101.3619,  -59.5357,  -91.7990, -104.9738,  -74.4870,
         -82.8035,  -92.2061,  -78.0555,  -93.5263,  -91.4695,  -81.6211,
        -135.0189,  -85.4641,  -84.6596,  -95.6979])
Final projection likelihood: -89.2271
1 mode projection failed, trying anyway
New goal: tensor([-0.1050,  0.2816,  0.7328,  1.1183, -0.1514,  0.4727,  0.9398,  1.2976,
         1.4176,  0.1312,  0.5881,  0.9671,  0.2842,  0.0907,  0.3557],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0002]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -78.06684875488281
Adjusted likelihood: -78.06684875488281
Likelihood residual: 0.0
Original likelihood: -91.95924377441406
Adjusted likelihood: -91.95924377441406
Likelihood residual: 0.0
{'index': 91.95924377441406, 'thumb_middle': 78.06684875488281}
Current yaw: tensor([ 0.2914,  0.0840, -0.1571], device='cuda:1')
11 thumb_middle
tensor([-0.1145,  0.3082,  0.7170,  1.1333, -0.1522,  0.4562,  0.7393,  1.2627,
         1.4849,  0.0228,  0.5924,  1.0453,  0.2914,  0.0840, -0.1571,  4.5832],
       device='cuda:1')
Solve time for step 1 9.980294429988135
Current ori: tensor([ 0.2914,  0.0840, -0.1571], device='cuda:1')
Index force: tensor([0.5932, 0.6035, 0.5972, 0.5417], device='cuda:1')
tensor([-0.1256,  0.3424,  0.7667,  1.1558, -0.2291,  0.1886,  0.8512,  1.2542,
         1.4049,  0.0784,  0.5193,  0.9532,  0.3016,  0.1071, -0.2388,  5.0906],
       device='cuda:1')
Solve time for step 2 2.1504755080095492
Current ori: tensor([ 0.3016,  0.1071, -0.2388], device='cuda:1')
Index force: tensor([0.5987, 0.5942, 0.5351], device='cuda:1')
tensor([-0.1376,  0.3589,  0.8243,  1.1454, -0.2530,  0.0700,  0.8621,  1.2427,
         1.4200,  0.1065,  0.5250,  0.9493,  0.3576,  0.1485, -0.3264,  5.4171],
       device='cuda:1')
Solve time for step 3 1.959439950005617
Current ori: tensor([ 0.3576,  0.1485, -0.3264], device='cuda:1')
Index force: tensor([0.5887, 0.5328], device='cuda:1')
tensor([-0.1358,  0.4733,  0.9148,  1.2882, -0.2431, -0.0071,  0.8437,  1.2360,
         1.4326,  0.1230,  0.5406,  0.9554,  0.3957,  0.1956, -0.3547, -6.0255],
       device='cuda:1')
Solve time for step 4 1.9749694889760576
Current ori: tensor([ 0.3957,  0.1956, -0.3547], device='cuda:1')
Index force: tensor([0.5309], device='cuda:1')
Storing RECOVERY transition: reward=-0.0864 (scaled=-0.0173), steps=5
Reward stats updated: mean -0.0029 -> -0.0030, std: 0.1344
Collected 199 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7704, Q2 Loss=0.7704, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5854
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.8895, Q2 Loss=1.8895, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8774
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0161, Q2 Loss=1.0161, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3655
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.6088, Q2 Loss=0.6088, Entropy=0.3182, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0948
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9991, Q2 Loss=0.9991, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4214

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.0%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (19.9%)
Actor update: 0.13s (41.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000019
Q1 loss: 1.056764
Q2 loss: 1.056764
Current threshold: -28.2133
Global Scale Offset: 0.4555
Reward stats: mean=-0.0030, std=0.1344, count=199
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0568, Q2 Loss: 1.0568, Entropy: 0.0637, Mean TD Error: 0.8689, Threshold: -28.2133
Original likelihood: -311.74267578125
Adjusted likelihood: -311.74267578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 12
Loaded trajectory sampler
Current yaw: tensor([-0.0018,  0.0145, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0018,  0.0145, -0.0309], device='cuda:1')
1 turn
Sampling time 3.747957278013928
tensor([ 0.1165,  0.5351,  0.6098,  0.6613, -0.1096,  0.5134,  0.9178,  0.8804,
         1.2160,  0.3116,  0.2474,  1.2226, -0.0018,  0.0145, -0.0309,  0.2447],
       device='cuda:1')
Original likelihood: -17.8757381439209
Adjusted likelihood: -17.8757381439209
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.706655663991114
Current ori: tensor([-0.0018,  0.0145, -0.0309], device='cuda:1')
Middle force: tensor([0.5176, 0.5665, 0.5802, 1.7815, 0.5629, 1.2671, 0.5078, 1.0923, 0.5016,
        0.5180, 0.5346, 0.5153], device='cuda:1')
Thumb force: tensor([0.6486, 0.8137, 0.5759, 1.4160, 0.5509, 0.8193, 0.5791, 1.3235, 0.5717,
        0.5033, 0.5727, 0.7653], device='cuda:1')
Index force: tensor([0.7671, 0.5050, 0.5131, 0.5216, 0.5791, 0.6374, 0.7548, 0.6009, 0.5921,
        0.6107, 0.5787, 0.6729], device='cuda:1')
Storing NORMAL transition: reward=0.0778 (scaled=0.0778), steps=1
Reward stats updated: mean -0.0030 -> -0.0026, std: 0.1342
Collected 200 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3393, Q2 Loss=1.3393, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8047
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.6546, Q2 Loss=1.6546, Entropy=0.0011, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5870
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0921, Q2 Loss=1.0921, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3379
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2637, Q2 Loss=1.2637, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5667
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9000, Q2 Loss=0.9000, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1084

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.4%)
Target Q: 0.04s (12.6%)
Q1 update: 0.06s (22.0%)
Q2 update: 0.06s (20.0%)
Actor update: 0.13s (42.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001672
Q1 loss: 1.249952
Q2 loss: 1.249952
Current threshold: -28.1801
Global Scale Offset: 0.4440
Reward stats: mean=-0.0026, std=0.1342, count=200
----------------------------------------------
SAC Update - Actor Loss: -0.0017, Q1 Loss: 1.2500, Q2 Loss: 1.2500, Entropy: 0.0002, Mean TD Error: 0.8809, Threshold: -28.1801
tensor([ 0.1566,  0.6653,  0.5231,  0.5362, -0.1723,  0.4651,  0.9065,  0.9703,
         1.3200,  0.2061,  0.2865,  1.1321,  0.0072,  0.0492, -0.1113, -0.4801],
       device='cuda:1')
Original likelihood: -33.267311096191406
Adjusted likelihood: -33.267311096191406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 34.26347351074219
Projection step: 1, Loss: 34.006282806396484
Projection step: 2, Loss: 31.348934173583984
Projection step: 3, Loss: 29.444849014282227
Projection step: 4, Loss: 26.944658279418945
Projection step: 5, Loss: 24.44402313232422
Projection step: 6, Loss: 19.134109497070312
Projection step: 7, Loss: 18.23133087158203
Projection step: 8, Loss: 12.884835243225098
Final likelihood: tensor([-12.1489, -13.5605, -15.0350, -12.0374, -11.7813, -14.8014, -14.2164,
        -13.8803, -12.0025, -12.0619, -13.3983, -12.1471, -12.3985, -12.8355,
        -11.8646, -11.9877])
Final projection likelihood: -12.8848
1 mode projection succeeded
New goal: tensor([ 0.0775,  0.6356,  0.4854,  0.5333, -0.0996,  0.4853,  0.8195,  0.8715,
         1.2823,  0.1999,  0.2228,  1.1623,  0.0052,  0.0255, -2.4774],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -28.58967399597168
Adjusted likelihood: -28.58967399597168
Likelihood residual: 0.0
Original likelihood: -15.200094223022461
Adjusted likelihood: -15.200094223022461
Likelihood residual: 0.0
{'index': 15.200094223022461, 'thumb_middle': 28.58967399597168}
Current yaw: tensor([ 0.0072,  0.0492, -0.1113], device='cuda:1')
2 index
tensor([ 0.1566,  0.6653,  0.5231,  0.5362, -0.1723,  0.4651,  0.9065,  0.9703,
         1.3200,  0.2061,  0.2865,  1.1321,  0.0072,  0.0492, -0.1113, -0.4801],
       device='cuda:1')
Solve time for step 1 11.769965126994066
Current ori: tensor([ 0.0072,  0.0492, -0.1113], device='cuda:1')
Middle force: tensor([0.5986, 0.6027, 0.5467, 0.5854], device='cuda:1')
Thumb force: tensor([0.5617, 0.5354, 0.5828, 0.5622], device='cuda:1')
tensor([ 0.1448,  0.5815,  0.4432,  0.5157, -0.1351,  0.4931,  0.9005,  0.9520,
         1.3136,  0.2003,  0.2402,  1.1479, -0.0061,  0.0267, -0.1334, -1.5007],
       device='cuda:1')
Solve time for step 2 2.1559839329856914
Current ori: tensor([-0.0061,  0.0267, -0.1334], device='cuda:1')
Middle force: tensor([0.5998, 0.5457, 0.5833], device='cuda:1')
Thumb force: tensor([0.5344, 0.5814, 0.5609], device='cuda:1')
tensor([ 0.1375,  0.5854,  0.4419,  0.5106, -0.1406,  0.5057,  0.8969,  0.9395,
         1.3250,  0.1872,  0.2375,  1.1349, -0.0118,  0.0275, -0.1334, -2.0203],
       device='cuda:1')
Solve time for step 3 2.2502097450196743
Current ori: tensor([-0.0118,  0.0275, -0.1334], device='cuda:1')
Middle force: tensor([0.5445, 0.5808], device='cuda:1')
Thumb force: tensor([0.5789, 0.5588], device='cuda:1')
tensor([ 0.1329,  0.5881,  0.4375,  0.5130, -0.1346,  0.5170,  0.8871,  0.9299,
         1.3252,  0.1853,  0.2315,  1.1332, -0.0164,  0.0246, -0.1268, -2.3050],
       device='cuda:1')
Solve time for step 4 2.1730042590061203
Current ori: tensor([-0.0164,  0.0246, -0.1268], device='cuda:1')
Middle force: tensor([0.5625], device='cuda:1')
Thumb force: tensor([0.5906], device='cuda:1')
Storing RECOVERY transition: reward=0.0182 (scaled=0.0182), steps=1
Reward stats updated: mean -0.0026 -> -0.0025, std: 0.1338
Collected 201 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1222, Q2 Loss=1.1222, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0303
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=3.1313, Q2 Loss=3.1313, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.1217
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.9673, Q2 Loss=0.9673, Entropy=0.1669, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4920
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7162, Q2 Loss=0.7162, Entropy=0.0010, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5557
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7614, Q2 Loss=0.7614, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6044

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.7%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.06s (19.6%)
Actor update: 0.14s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000012
Q1 loss: 1.339683
Q2 loss: 1.339683
Current threshold: -28.1543
Global Scale Offset: 0.4353
Reward stats: mean=-0.0025, std=0.1338, count=201
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3397, Q2 Loss: 1.3397, Entropy: 0.0336, Mean TD Error: 1.5608, Threshold: -28.1543
Original likelihood: -14.17331314086914
Adjusted likelihood: -14.17331314086914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0216,  0.0225, -0.1278], device='cuda:1')
3 turn
Sampling time 3.715071129001444
tensor([ 0.0790,  0.6481,  0.4798,  0.5313, -0.1298,  0.5257,  0.8814,  0.9185,
         1.3259,  0.1958,  0.2191,  1.1358, -0.0216,  0.0225, -0.1278, -2.3705],
       device='cuda:1')
Original likelihood: -13.897082328796387
Adjusted likelihood: -13.897082328796387
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.642465836979682
Current ori: tensor([-0.0216,  0.0225, -0.1278], device='cuda:1')
Middle force: tensor([0.5220, 1.4968, 1.6933, 0.5061, 0.5529, 0.5089, 0.5556, 0.5346, 0.5091,
        0.6808, 0.4908, 0.5071], device='cuda:1')
Thumb force: tensor([0.5485, 1.1200, 0.7271, 0.5423, 1.0139, 1.4259, 0.6161, 0.5803, 0.8534,
        1.0005, 0.5271, 0.5563], device='cuda:1')
Index force: tensor([0.5497, 0.5442, 0.5130, 0.5796, 0.5446, 0.5415, 0.5534, 0.6165, 0.7072,
        0.6204, 0.7437, 0.5544], device='cuda:1')
Storing NORMAL transition: reward=-0.0140 (scaled=-0.0140), steps=1
Reward stats updated: mean -0.0025 -> -0.0025, std: 0.1335
Collected 202 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.9422, Q2 Loss=1.9422, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4678
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.4075, Q2 Loss=1.4075, Entropy=0.0912, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1884
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0479, Q2 Loss=1.0479, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0715
SAC Update 4/5: Actor Loss=-0.0006, Q1 Loss=1.3039, Q2 Loss=1.3039, Entropy=0.3454, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7276
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2715, Q2 Loss=1.2715, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1712

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (20.1%)
Actor update: 0.13s (43.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000129
Q1 loss: 1.394600
Q2 loss: 1.394600
Current threshold: -28.1348
Global Scale Offset: 0.4305
Reward stats: mean=-0.0025, std=0.1335, count=202
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.3946, Q2 Loss: 1.3946, Entropy: 0.0873, Mean TD Error: 0.9253, Threshold: -28.1348
tensor([ 0.0336,  0.5757,  0.5326,  0.5426, -0.1076,  0.5085,  0.9421,  0.8832,
         1.2509,  0.2896,  0.2771,  0.9549, -0.0129,  0.0050, -0.1131, -2.0997],
       device='cuda:1')
Original likelihood: -12.729652404785156
Adjusted likelihood: -12.729652404785156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.2160018310241867
Current ori: tensor([-0.0129,  0.0050, -0.1131], device='cuda:1')
Middle force: tensor([1.4528, 1.6435, 0.5092, 0.5502, 0.5094, 0.5535, 0.5410, 0.5110, 0.7036,
        0.5012, 0.5071], device='cuda:1')
Thumb force: tensor([1.0857, 0.7163, 0.5327, 0.9911, 1.3748, 0.6092, 0.5639, 0.8189, 0.9511,
        0.5230, 0.5529], device='cuda:1')
Index force: tensor([0.5405, 0.5118, 0.5680, 0.5431, 0.5397, 0.5516, 0.6105, 0.6895, 0.6086,
        0.7549, 0.5509], device='cuda:1')
Storing NORMAL transition: reward=-0.0625 (scaled=-0.0625), steps=1
Reward stats updated: mean -0.0025 -> -0.0028, std: 0.1332
Collected 203 transitions for RL
SAC Update 1/5: Actor Loss=-0.0038, Q1 Loss=0.9537, Q2 Loss=0.9537, Entropy=0.0005, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8307
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.5961, Q2 Loss=0.5961, Entropy=0.1909, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3093
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6107, Q2 Loss=0.6107, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2644
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=1.1861, Q2 Loss=1.1861, Entropy=0.2033, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7886
SAC Update 5/5: Actor Loss=-0.0019, Q1 Loss=0.9031, Q2 Loss=0.9031, Entropy=0.6044, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3499

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.5%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (20.4%)
Actor update: 0.13s (41.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001453
Q1 loss: 0.849947
Q2 loss: 0.849947
Current threshold: -28.0937
Global Scale Offset: 0.4216
Reward stats: mean=-0.0028, std=0.1332, count=203
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 0.8499, Q2 Loss: 0.8499, Entropy: 0.1998, Mean TD Error: 0.5086, Threshold: -28.0937
tensor([-0.0672,  0.4184,  0.5008,  0.4579, -0.0518,  0.5767,  0.8987,  0.8535,
         1.2862,  0.2347,  0.1796,  1.0755, -0.0206, -0.0324, -0.0516, -0.5920],
       device='cuda:1')
Original likelihood: -34.71207809448242
Adjusted likelihood: -34.71207809448242
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 26.282482147216797
Projection step: 1, Loss: 22.55708885192871
Projection step: 2, Loss: 19.03412437438965
Projection step: 3, Loss: 16.253292083740234
Projection step: 4, Loss: 13.844565391540527
Final likelihood: tensor([-13.2957, -13.1396, -13.2882, -13.5867, -15.7391, -13.3257, -13.9780,
        -14.6519, -13.3003, -13.3456, -13.4988, -13.2964, -14.2699, -13.3849,
        -12.7847, -16.6276])
Final projection likelihood: -13.8446
1 mode projection succeeded
New goal: tensor([-0.0247,  0.4651,  0.6323,  0.5018, -0.0275,  0.5815,  0.8016,  0.8662,
         1.3010,  0.2662,  0.2295,  0.9744, -0.0208, -0.0281,  0.1415],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0175]], device='cuda:1')
Original likelihood: -20.321044921875
Adjusted likelihood: -20.321044921875
Likelihood residual: 0.0
{'index': 20.321044921875, 'thumb_middle': inf}
Current yaw: tensor([-0.0206, -0.0324, -0.0516], device='cuda:1')
4 index
tensor([-0.0672,  0.4184,  0.5008,  0.4579, -0.0518,  0.5767,  0.8987,  0.8535,
         1.2862,  0.2347,  0.1796,  1.0755, -0.0206, -0.0324, -0.0516, -0.5920],
       device='cuda:1')
Solve time for step 1 11.755071561987279
Current ori: tensor([-0.0206, -0.0324, -0.0516], device='cuda:1')
Middle force: tensor([0.5221, 0.5006, 0.5470, 0.5913], device='cuda:1')
Thumb force: tensor([0.5802, 0.5168, 0.6054, 0.5201], device='cuda:1')
tensor([-0.0292,  0.4270,  0.5730,  0.4770, -0.0511,  0.6199,  0.8277,  0.8714,
         1.3086,  0.2149,  0.1840,  1.0041, -0.0403, -0.0316, -0.0942,  0.3773],
       device='cuda:1')
Solve time for step 2 2.5031271089974325
Current ori: tensor([-0.0403, -0.0316, -0.0942], device='cuda:1')
Middle force: tensor([0.5005, 0.5453, 0.5889], device='cuda:1')
Thumb force: tensor([0.5152, 0.6039, 0.5194], device='cuda:1')
tensor([-0.0328,  0.4333,  0.5893,  0.4773, -0.0399,  0.6289,  0.8215,  0.8796,
         1.2742,  0.2682,  0.1766,  1.0276, -0.0415, -0.0400, -0.1051,  1.1512],
       device='cuda:1')
Solve time for step 3 2.4587383510079235
Current ori: tensor([-0.0415, -0.0400, -0.1051], device='cuda:1')
Middle force: tensor([0.5430, 0.5868], device='cuda:1')
Thumb force: tensor([0.6008, 0.5187], device='cuda:1')
tensor([-0.0231,  0.4332,  0.5897,  0.4739, -0.0582,  0.6295,  0.8106,  0.8640,
         1.2992,  0.2404,  0.1936,  1.0010, -0.0450, -0.0261, -0.0883,  1.8721],
       device='cuda:1')
Solve time for step 4 2.3701243170071393
Current ori: tensor([-0.0450, -0.0261, -0.0883], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5447], device='cuda:1')
Storing RECOVERY transition: reward=0.0485 (scaled=0.0243), steps=2
Reward stats updated: mean -0.0028 -> -0.0027, std: 0.1329
Collected 204 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9766, Q2 Loss=0.9766, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5188
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=1.3210, Q2 Loss=1.3210, Entropy=0.3465, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7993
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2592, Q2 Loss=1.2592, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6660
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.6062, Q2 Loss=1.6062, Entropy=0.0750, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9109
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0930, Q2 Loss=1.0930, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0036

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.2%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000142
Q1 loss: 1.251183
Q2 loss: 1.251183
Current threshold: -28.0446
Global Scale Offset: 0.4152
Reward stats: mean=-0.0027, std=0.1329, count=204
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2512, Q2 Loss: 1.2512, Entropy: 0.0843, Mean TD Error: 1.7797, Threshold: -28.0446
Original likelihood: -20.51479721069336
Adjusted likelihood: -20.51479721069336
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0459, -0.0309, -0.1017], device='cuda:1')
5 turn
Sampling time 3.8122052649850957
tensor([-0.0406,  0.4829,  0.6275,  0.4975, -0.0520,  0.6308,  0.8133,  0.8676,
         1.2870,  0.2600,  0.1842,  1.0153, -0.0459, -0.0309, -0.1017,  2.1433],
       device='cuda:1')
Original likelihood: -20.459426879882812
Adjusted likelihood: -20.459426879882812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.835061705001863
Current ori: tensor([-0.0459, -0.0309, -0.1017], device='cuda:1')
Middle force: tensor([0.6569, 0.5549, 1.5663, 0.6460, 0.6365, 0.7961, 0.6435, 0.6677, 0.6557,
        0.5978, 0.6331, 0.5028], device='cuda:1')
Thumb force: tensor([0.5945, 1.0566, 0.9146, 1.1004, 0.5342, 0.5683, 0.5765, 0.5181, 0.5670,
        0.6095, 0.6005, 0.8801], device='cuda:1')
Index force: tensor([0.5765, 0.5225, 1.3702, 0.5924, 0.6069, 0.5939, 0.5897, 0.5084, 0.5537,
        0.6229, 0.5889, 0.5033], device='cuda:1')
Storing NORMAL transition: reward=-0.0379 (scaled=-0.0379), steps=1
Reward stats updated: mean -0.0027 -> -0.0029, std: 0.1326
Collected 205 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1583, Q2 Loss=1.1583, Entropy=0.0713, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5810
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0129, Q2 Loss=1.0129, Entropy=0.0008, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3379
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4877, Q2 Loss=1.4877, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4961
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9620, Q2 Loss=0.9620, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4466
SAC Update 5/5: Actor Loss=-0.0019, Q1 Loss=1.3212, Q2 Loss=1.3212, Entropy=0.2102, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8790

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.8%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.06s (20.4%)
Actor update: 0.13s (42.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000389
Q1 loss: 1.188434
Q2 loss: 1.188434
Current threshold: -28.0098
Global Scale Offset: 0.4113
Reward stats: mean=-0.0029, std=0.1326, count=205
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.1884, Q2 Loss: 1.1884, Entropy: 0.0566, Mean TD Error: 0.7481, Threshold: -28.0098
tensor([-0.1073,  0.4402,  0.6009,  0.5786, -0.1784,  0.6967,  0.7220,  0.9622,
         1.2987,  0.2914,  0.2396,  1.0340, -0.0491,  0.0201, -0.0634,  1.7242],
       device='cuda:1')
Original likelihood: -32.67705535888672
Adjusted likelihood: -32.67705535888672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 31.317310333251953
Projection step: 1, Loss: 28.43740463256836
Projection step: 2, Loss: 23.442340850830078
Projection step: 3, Loss: 19.623706817626953
Projection step: 4, Loss: 18.51051902770996
Projection step: 5, Loss: 17.950668334960938
Projection step: 6, Loss: 18.22076416015625
Projection step: 7, Loss: 15.73013973236084
Projection step: 8, Loss: 15.57402515411377
Projection step: 9, Loss: 14.940924644470215
Final likelihood: tensor([-15.9863, -16.6624, -15.6402, -18.5988, -15.0519, -15.8184, -13.1055,
        -15.0642, -15.8381, -13.2911, -12.2642, -12.8789, -16.2699, -14.6400,
        -15.3391, -12.6058])
Final projection likelihood: -14.9409
1 mode projection succeeded
New goal: tensor([-0.0414,  0.4571,  0.6091,  0.6428, -0.0905,  0.6068,  0.6139,  0.9832,
         1.2984,  0.2353,  0.1686,  0.9989, -0.0508,  0.0187, -0.0764],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -24.108129501342773
Adjusted likelihood: -24.108129501342773
Likelihood residual: 0.0
Original likelihood: -23.93890953063965
Adjusted likelihood: -23.93890953063965
Likelihood residual: 0.0
{'index': 23.93890953063965, 'thumb_middle': 24.108129501342773}
Current yaw: tensor([-0.0491,  0.0201, -0.0634], device='cuda:1')
6 index
tensor([-0.1073,  0.4402,  0.6009,  0.5786, -0.1784,  0.6967,  0.7220,  0.9622,
         1.2987,  0.2914,  0.2396,  1.0340, -0.0491,  0.0201, -0.0634,  1.7242],
       device='cuda:1')
Solve time for step 1 10.987086470995564
Current ori: tensor([-0.0491,  0.0201, -0.0634], device='cuda:1')
Middle force: tensor([0.5349, 0.5429, 0.5684, 0.5444], device='cuda:1')
Thumb force: tensor([0.5256, 0.5157, 0.6062, 0.5024], device='cuda:1')
tensor([-0.0353,  0.3899,  0.5532,  0.5950, -0.1927,  0.7251,  0.6873,  0.9909,
         1.3465,  0.2244,  0.2190,  1.0130, -0.0614,  0.0236, -0.0561, -0.5879],
       device='cuda:1')
Solve time for step 2 2.5299570539791603
Current ori: tensor([-0.0614,  0.0236, -0.0561], device='cuda:1')
Middle force: tensor([0.5427, 0.5683, 0.5436], device='cuda:1')
Thumb force: tensor([0.5144, 0.6005, 0.5023], device='cuda:1')
tensor([-0.0288,  0.4019,  0.5553,  0.6053, -0.1816,  0.7427,  0.6702,  0.9838,
         1.3479,  0.2196,  0.2060,  1.0019, -0.0707,  0.0158, -0.0670, -1.7732],
       device='cuda:1')
Solve time for step 3 2.4234247540007345
Current ori: tensor([-0.0707,  0.0158, -0.0670], device='cuda:1')
Middle force: tensor([0.5639, 0.5422], device='cuda:1')
Thumb force: tensor([0.5950, 0.5019], device='cuda:1')
tensor([-0.0259,  0.4063,  0.5560,  0.6063, -0.1770,  0.7391,  0.6755,  0.9983,
         1.3490,  0.2122,  0.1922,  1.0194, -0.0674,  0.0109, -0.0788, -2.6097],
       device='cuda:1')
Solve time for step 4 2.371445962024154
Current ori: tensor([-0.0674,  0.0109, -0.0788], device='cuda:1')
Middle force: tensor([0.5402], device='cuda:1')
Thumb force: tensor([0.5222], device='cuda:1')
Storing RECOVERY transition: reward=-0.0108 (scaled=-0.0108), steps=1
Reward stats updated: mean -0.0029 -> -0.0029, std: 0.1323
Collected 206 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.9632, Q2 Loss=1.9632, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4432
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1936, Q2 Loss=1.1936, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7341
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9182, Q2 Loss=0.9182, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3009
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6230, Q2 Loss=0.6230, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1271
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.3945, Q2 Loss=1.3945, Entropy=0.1057, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1992

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.6%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.2%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000011
Q1 loss: 1.218504
Q2 loss: 1.218504
Current threshold: -27.9783
Global Scale Offset: 0.4079
Reward stats: mean=-0.0029, std=0.1323, count=206
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2185, Q2 Loss: 1.2185, Entropy: 0.0212, Mean TD Error: 0.9609, Threshold: -27.9783
Original likelihood: -27.0018310546875
Adjusted likelihood: -27.0018310546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8486)
Current yaw: tensor([-0.0730,  0.0086, -0.0548], device='cuda:1')
7 turn
Sampling time 3.7017426090023946
tensor([-0.0449,  0.4519,  0.5910,  0.6299, -0.1868,  0.7489,  0.6856,  1.0071,
         1.3408,  0.2242,  0.1930,  1.0183, -0.0730,  0.0086, -0.0548, -2.8251],
       device='cuda:1')
Original likelihood: -25.412221908569336
Adjusted likelihood: -25.412221908569336
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9966)
Solve time for step 1 14.663357679994078
Current ori: tensor([-0.0730,  0.0086, -0.0548], device='cuda:1')
Middle force: tensor([0.6064, 0.5612, 1.4670, 0.6136, 0.6885, 0.7737, 0.6287, 0.5329, 0.5927,
        0.6036, 0.6468, 0.5459], device='cuda:1')
Thumb force: tensor([0.5777, 1.0506, 0.9529, 1.1385, 0.5395, 0.5715, 0.5794, 0.5512, 0.5769,
        0.6118, 0.5904, 1.1305], device='cuda:1')
Index force: tensor([0.5875, 0.5213, 1.3159, 0.5977, 0.5932, 0.5984, 0.5915, 0.5004, 0.5253,
        0.6215, 0.5698, 0.5391], device='cuda:1')
Storing NORMAL transition: reward=-0.0144 (scaled=-0.0144), steps=1
Reward stats updated: mean -0.0029 -> -0.0030, std: 0.1320
Collected 207 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8299, Q2 Loss=0.8299, Entropy=0.0007, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2427
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7767, Q2 Loss=0.7767, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8447
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1963, Q2 Loss=1.1963, Entropy=0.0778, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4771
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=8.8645, Q2 Loss=8.8645, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=7.2518
SAC Update 5/5: Actor Loss=-0.0107, Q1 Loss=0.9513, Q2 Loss=0.9513, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7479

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002142
Q1 loss: 2.523740
Q2 loss: 2.523740
Current threshold: -27.9493
Global Scale Offset: 0.4027
Reward stats: mean=-0.0030, std=0.1320, count=207
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 2.5237, Q2 Loss: 2.5237, Entropy: 0.0157, Mean TD Error: 2.1129, Threshold: -27.9493
tensor([-0.0532,  0.4942,  0.5574,  0.6344, -0.1770,  0.6854,  0.8030,  0.9350,
         1.3368,  0.2190,  0.1320,  1.1921, -0.1074,  0.0101, -0.0461, -3.0622],
       device='cuda:1')
Original likelihood: -30.944738388061523
Adjusted likelihood: -30.944738388061523
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0007)
State is out of distribution
Projection step: 0, Loss: 31.086503982543945
Projection step: 1, Loss: 28.997861862182617
Projection step: 2, Loss: 28.64992904663086
Projection step: 3, Loss: 25.467819213867188
Projection step: 4, Loss: 24.677852630615234
Projection step: 5, Loss: 23.06559181213379
Projection step: 6, Loss: 22.53501319885254
Projection step: 7, Loss: 21.29482650756836
Projection step: 8, Loss: 21.160884857177734
Projection step: 9, Loss: 20.810993194580078
Projection step: 10, Loss: 19.050621032714844
Projection step: 11, Loss: 18.55129623413086
Projection step: 12, Loss: 17.970970153808594
Projection step: 13, Loss: 17.05459976196289
Projection step: 14, Loss: 17.332836151123047
Final likelihood: tensor([-15.8781, -16.3152, -16.2518, -16.2243, -16.0544, -15.7168, -15.9815,
        -20.9435, -20.8909, -17.3026, -16.7227, -16.8082, -16.7609, -15.7133,
        -15.9894, -16.6028])
Final projection likelihood: -16.8848
1 mode projection succeeded
New goal: tensor([ 0.0210,  0.4572,  0.6000,  0.6463, -0.0664,  0.6023,  0.6913,  0.9426,
         1.3282,  0.2821,  0.1543,  0.9450, -0.0961,  0.0086, -0.0173],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0035]], device='cuda:1') tensor([[0.0018]], device='cuda:1')
Original likelihood: -21.67849349975586
Adjusted likelihood: -21.67849349975586
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.67849349975586}
Current yaw: tensor([-0.1074,  0.0101, -0.0461], device='cuda:1')
8 thumb_middle
tensor([-0.0532,  0.4942,  0.5574,  0.6344, -0.1770,  0.6854,  0.8030,  0.9350,
         1.3368,  0.2190,  0.1320,  1.1921, -0.1074,  0.0101, -0.0461, -3.0622],
       device='cuda:1')
Solve time for step 1 9.28676942299353
Current ori: tensor([-0.1074,  0.0101, -0.0461], device='cuda:1')
Index force: tensor([0.5977, 0.6122, 0.6151, 0.6163], device='cuda:1')
tensor([-5.3023e-02,  5.1300e-01,  6.4004e-01,  6.7088e-01, -1.5176e-01,
         6.0871e-01,  6.9887e-01,  9.2582e-01,  1.3015e+00,  2.5411e-01,
         8.2285e-02,  9.7316e-01, -2.7976e-01,  3.7701e-03, -4.9248e-02,
        -3.9684e+00], device='cuda:1')
Solve time for step 2 1.9938827140140347
Current ori: tensor([-0.2798,  0.0038, -0.0492], device='cuda:1')
Index force: tensor([0.6053, 0.6117, 0.6102], device='cuda:1')
tensor([-0.0792,  0.5881,  0.6656,  0.6721, -0.1310,  0.6324,  0.6970,  0.9347,
         1.3203,  0.2651,  0.0776,  0.9372, -0.6884,  0.0087, -0.0492, -4.9440],
       device='cuda:1')
Solve time for step 3 1.9230816799972672
Current ori: tensor([-0.6884,  0.0087, -0.0492], device='cuda:1')
Index force: tensor([0.5002, 0.5581], device='cuda:1')
tensor([-0.2410,  0.7610,  0.7569,  0.7138, -0.1070,  0.6978,  0.7000,  0.9220,
         1.3383,  0.2710,  0.0784,  0.9242, -1.4546,  0.0138, -0.0492, -4.4969],
       device='cuda:1')
Solve time for step 4 1.8626392659789417
Current ori: tensor([-1.4546,  0.0138, -0.0492], device='cuda:1')
Index force: tensor([0.5492], device='cuda:1')
Storing RECOVERY transition: reward=-1.5415 (scaled=-1.5415), steps=1
Reward stats updated: mean -0.0030 -> -0.0104, std: 0.1693
Collected 208 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.8554, Q2 Loss=0.8554, Entropy=0.2585, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0985
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4790, Q2 Loss=1.4790, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1547
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6103, Q2 Loss=0.6103, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8134
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.3099, Q2 Loss=1.3099, Entropy=0.1384, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8317
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8400, Q2 Loss=0.8400, Entropy=0.0063, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4239

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (18.1%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000154
Q1 loss: 1.018912
Q2 loss: 1.018912
Current threshold: -27.8983
Global Scale Offset: 0.3889
Reward stats: mean=-0.0104, std=0.1693, count=208
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0189, Q2 Loss: 1.0189, Entropy: 0.0807, Mean TD Error: 0.6644, Threshold: -27.8983
Original likelihood: -1257.567138671875
Adjusted likelihood: -1257.567138671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 13
Loaded trajectory sampler
Current yaw: tensor([ 0.0004,  0.0142, -0.0465], device='cuda:1')
Current yaw: tensor([ 0.0004,  0.0142, -0.0465], device='cuda:1')
1 turn
Sampling time 3.766262924997136
tensor([ 1.8858e-01,  6.4259e-01,  5.6457e-01,  6.0117e-01, -1.1013e-01,
         5.2422e-01,  9.0347e-01,  9.2873e-01,  1.2568e+00,  2.7025e-01,
         2.1341e-01,  1.2039e+00,  4.3526e-04,  1.4234e-02, -4.6489e-02,
         2.3119e-03], device='cuda:1')
Original likelihood: -26.382339477539062
Adjusted likelihood: -26.382339477539062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9513)
Solve time for step 1 14.847639922983944
Current ori: tensor([ 0.0004,  0.0142, -0.0465], device='cuda:1')
Middle force: tensor([0.5837, 0.5716, 1.1870, 0.5647, 1.1155, 0.6436, 0.5330, 0.5095, 0.5136,
        0.6187, 0.5248, 0.4940], device='cuda:1')
Thumb force: tensor([0.8562, 0.8917, 0.7617, 1.0469, 1.0478, 0.6594, 0.5279, 0.9627, 0.5458,
        0.5860, 0.6313, 0.6113], device='cuda:1')
Index force: tensor([0.6014, 0.6064, 0.5621, 0.5715, 0.8077, 0.5223, 1.0339, 0.9172, 0.5808,
        0.5748, 0.6344, 0.7136], device='cuda:1')
Storing NORMAL transition: reward=0.0358 (scaled=0.0358), steps=1
Reward stats updated: mean -0.0104 -> -0.0101, std: 0.1689
Collected 209 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1276, Q2 Loss=1.1276, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6340
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6739, Q2 Loss=0.6739, Entropy=0.0224, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.5565
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.2878, Q2 Loss=1.2878, Entropy=0.1404, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3993
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7232, Q2 Loss=0.7232, Entropy=0.1038, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4628
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2099, Q2 Loss=1.2099, Entropy=0.0021, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6297

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.1%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (37.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000020
Q1 loss: 1.004473
Q2 loss: 1.004473
Current threshold: -27.8664
Global Scale Offset: 0.3811
Reward stats: mean=-0.0101, std=0.1689, count=209
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0045, Q2 Loss: 1.0045, Entropy: 0.0537, Mean TD Error: 3.1365, Threshold: -27.8664
tensor([ 0.1612,  0.6141,  0.5597,  0.6265, -0.0826,  0.4973,  0.8226,  0.9181,
         1.2897,  0.2696,  0.2139,  1.1925, -0.0031,  0.0251, -0.0828,  0.2928],
       device='cuda:1')
Original likelihood: -21.921443939208984
Adjusted likelihood: -21.921443939208984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.8319091309967916
Current ori: tensor([-0.0031,  0.0251, -0.0828], device='cuda:1')
Middle force: tensor([0.5703, 1.1706, 0.5619, 1.1008, 0.6394, 0.5313, 0.5090, 0.5130, 0.6126,
        0.5242, 0.5006], device='cuda:1')
Thumb force: tensor([0.8797, 0.7562, 1.0361, 1.0322, 0.6536, 0.5264, 0.9476, 0.5414, 0.5838,
        0.6256, 0.6109], device='cuda:1')
Index force: tensor([0.6009, 0.5598, 0.5684, 0.8037, 0.5217, 1.0262, 0.9114, 0.5819, 0.5731,
        0.6320, 0.7164], device='cuda:1')
Storing NORMAL transition: reward=0.0990 (scaled=0.0990), steps=1
Reward stats updated: mean -0.0101 -> -0.0096, std: 0.1687
Collected 210 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7365, Q2 Loss=0.7365, Entropy=0.0006, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2926
SAC Update 2/5: Actor Loss=-0.0022, Q1 Loss=1.0890, Q2 Loss=1.0890, Entropy=0.5993, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4613
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6469, Q2 Loss=0.6469, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4654
SAC Update 4/5: Actor Loss=-0.0025, Q1 Loss=0.6609, Q2 Loss=0.6609, Entropy=0.0153, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3417
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.8718, Q2 Loss=1.8718, Entropy=0.0036, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7418

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000939
Q1 loss: 1.001030
Q2 loss: 1.001030
Current threshold: -27.8314
Global Scale Offset: 0.3760
Reward stats: mean=-0.0096, std=0.1687, count=210
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 1.0010, Q2 Loss: 1.0010, Entropy: 0.1238, Mean TD Error: 1.2606, Threshold: -27.8314
tensor([ 0.1451,  0.6091,  0.5067,  0.5519, -0.0997,  0.4716,  0.8140,  0.9951,
         1.3421,  0.2175,  0.2288,  1.1168, -0.0025,  0.0363, -0.1828,  0.0031],
       device='cuda:1')
Original likelihood: -25.492679595947266
Adjusted likelihood: -25.492679595947266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9956)
Solve time for step 3 2.6887844479933847
Current ori: tensor([-0.0025,  0.0363, -0.1828], device='cuda:1')
Middle force: tensor([0.5016, 1.4513, 0.6388, 0.5003, 0.5580, 0.5069, 0.5394, 0.5566, 0.5514,
        0.5919], device='cuda:1')
Thumb force: tensor([1.3301, 0.6881, 0.5393, 1.0764, 1.1836, 0.5616, 0.8742, 0.5002, 0.6053,
        0.6207], device='cuda:1')
Index force: tensor([0.7177, 0.7405, 0.5521, 0.6756, 0.6411, 0.6021, 0.5754, 0.6858, 0.6417,
        0.6066], device='cuda:1')
Storing NORMAL transition: reward=0.0637 (scaled=0.0637), steps=1
Reward stats updated: mean -0.0096 -> -0.0093, std: 0.1684
Collected 211 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8751, Q2 Loss=0.8751, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2756
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1181, Q2 Loss=1.1181, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5497
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7931, Q2 Loss=0.7931, Entropy=0.0142, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6250
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1701, Q2 Loss=1.1701, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7725
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9994, Q2 Loss=0.9994, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2150

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.991167
Q2 loss: 0.991167
Current threshold: -27.8077
Global Scale Offset: 0.3728
Reward stats: mean=-0.0093, std=0.1684, count=211
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9912, Q2 Loss: 0.9912, Entropy: 0.0031, Mean TD Error: 0.4876, Threshold: -27.8077
tensor([ 0.1539,  0.5851,  0.6180,  0.5830, -0.0582,  0.4404,  0.9096,  0.9613,
         1.2828,  0.2808,  0.2100,  1.1430,  0.0018,  0.0078, -0.2449,  0.2404],
       device='cuda:1')
Original likelihood: -17.707645416259766
Adjusted likelihood: -17.707645416259766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.6663118039723486
Current ori: tensor([ 0.0018,  0.0078, -0.2449], device='cuda:1')
Middle force: tensor([0.5006, 0.6132, 0.5005, 0.5547, 0.8006, 1.1821, 0.5449, 0.5637, 0.5768],
       device='cuda:1')
Thumb force: tensor([0.6155, 0.6430, 0.5097, 0.6439, 0.8225, 1.3302, 0.5934, 0.6099, 0.5672],
       device='cuda:1')
Index force: tensor([1.0158, 0.5370, 0.7277, 0.5442, 0.5435, 0.9866, 0.5298, 0.6003, 0.6188],
       device='cuda:1')
Storing NORMAL transition: reward=0.0810 (scaled=0.0810), steps=1
Reward stats updated: mean -0.0093 -> -0.0088, std: 0.1681
Collected 212 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0815, Q2 Loss=1.0815, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1844
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8197, Q2 Loss=0.8197, Entropy=0.0006, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5813
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1467, Q2 Loss=1.1467, Entropy=0.0008, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7459
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.4706, Q2 Loss=3.4706, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0045
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.4597, Q2 Loss=2.4597, Entropy=0.0067, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8837

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.06s (20.5%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.795630
Q2 loss: 1.795630
Current threshold: -27.7936
Global Scale Offset: 0.3709
Reward stats: mean=-0.0088, std=0.1681, count=212
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.7956, Q2 Loss: 1.7956, Entropy: 0.0018, Mean TD Error: 2.4800, Threshold: -27.7936
tensor([ 0.1585,  0.6122,  0.5866,  0.5819, -0.0649,  0.4366,  0.9441,  0.9464,
         1.3150,  0.2444,  0.2025,  1.0937, -0.0048,  0.0047, -0.3258,  0.3169],
       device='cuda:1')
Original likelihood: -19.23311424255371
Adjusted likelihood: -19.23311424255371
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.506704288010951
Current ori: tensor([-0.0048,  0.0047, -0.3258], device='cuda:1')
Middle force: tensor([0.6105, 0.5007, 0.5536, 0.7981, 1.1798, 0.5447, 0.5638, 0.5762],
       device='cuda:1')
Thumb force: tensor([0.6367, 0.5093, 0.6405, 0.8152, 1.3117, 0.5899, 0.6050, 0.5645],
       device='cuda:1')
Index force: tensor([0.5354, 0.7306, 0.5434, 0.5421, 0.9804, 0.5288, 0.5989, 0.6170],
       device='cuda:1')
Storing NORMAL transition: reward=0.0002 (scaled=0.0002), steps=1
Reward stats updated: mean -0.0088 -> -0.0088, std: 0.1677
Collected 213 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7014, Q2 Loss=0.7014, Entropy=0.0116, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2773
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0447, Q2 Loss=1.0447, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3439
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1042, Q2 Loss=1.1042, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4229
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2034, Q2 Loss=1.2034, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5168
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=4.4352, Q2 Loss=4.4352, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3705

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.05s (19.9%)
Actor update: 0.10s (42.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.697805
Q2 loss: 1.697805
Current threshold: -27.7852
Global Scale Offset: 0.3698
Reward stats: mean=-0.0088, std=0.1677, count=213
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.6978, Q2 Loss: 1.6978, Entropy: 0.0023, Mean TD Error: 1.5863, Threshold: -27.7852
tensor([ 0.1552,  0.5366,  0.6260,  0.5538, -0.0726,  0.4527,  0.9400,  0.8934,
         1.2928,  0.2393,  0.1518,  1.0369, -0.0110,  0.0095, -0.3264,  0.0977],
       device='cuda:1')
Original likelihood: -20.132726669311523
Adjusted likelihood: -20.132726669311523
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 2.454983784002252
Current ori: tensor([-0.0110,  0.0095, -0.3264], device='cuda:1')
Middle force: tensor([0.5009, 0.5539, 0.7969, 1.1794, 0.5448, 0.5633, 0.5766],
       device='cuda:1')
Thumb force: tensor([0.5096, 0.6321, 0.8062, 1.2922, 0.5860, 0.6003, 0.5598],
       device='cuda:1')
Index force: tensor([0.7230, 0.5440, 0.5410, 0.9749, 0.5281, 0.5987, 0.6177],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0090 (scaled=-0.0090), steps=1
Reward stats updated: mean -0.0088 -> -0.0088, std: 0.1673
Collected 214 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7333, Q2 Loss=0.7333, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3572
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9163, Q2 Loss=0.9163, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1301
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7182, Q2 Loss=0.7182, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2952
SAC Update 4/5: Actor Loss=-0.0017, Q1 Loss=1.0598, Q2 Loss=1.0598, Entropy=0.2395, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4397
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2071, Q2 Loss=1.2071, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7275

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.06s (19.4%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (40.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000337
Q1 loss: 0.926951
Q2 loss: 0.926951
Current threshold: -27.7739
Global Scale Offset: 0.3687
Reward stats: mean=-0.0088, std=0.1673, count=214
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.9270, Q2 Loss: 0.9270, Entropy: 0.0479, Mean TD Error: 0.3899, Threshold: -27.7739
tensor([ 0.1707,  0.6009,  0.6089,  0.5978, -0.0283,  0.4753,  0.9701,  0.8293,
         1.2738,  0.1956,  0.1703,  0.8807, -0.0179, -0.0192, -0.3183,  0.0968],
       device='cuda:1')
Original likelihood: -34.58259582519531
Adjusted likelihood: -34.58259582519531
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 27.08484649658203
Projection step: 1, Loss: 22.60081672668457
Projection step: 2, Loss: 19.507354736328125
Projection step: 3, Loss: 19.867626190185547
Projection step: 4, Loss: 16.3539981842041
Projection step: 5, Loss: 13.483892440795898
Final likelihood: tensor([-13.9618, -11.4531, -11.7729, -13.3426, -17.4134, -14.3114, -14.8816,
        -11.3937, -11.0335, -15.9844, -12.5130, -11.5583, -12.5125, -17.6002,
        -14.8034, -11.2064])
Final projection likelihood: -13.4839
1 mode projection succeeded
New goal: tensor([ 0.1056,  0.5616,  0.5708,  0.7074, -0.0157,  0.5087,  0.8270,  0.8812,
         1.3018,  0.2749,  0.1404,  1.0088, -0.0177, -0.0147, -0.5719],
       device='cuda:1')
tensor([[0.0149]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -22.71375846862793
Adjusted likelihood: -22.71375846862793
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.71375846862793}
Current yaw: tensor([-0.0179, -0.0192, -0.3183], device='cuda:1')
2 thumb_middle
tensor([ 0.1707,  0.6009,  0.6089,  0.5978, -0.0283,  0.4753,  0.9701,  0.8293,
         1.2738,  0.1956,  0.1703,  0.8807, -0.0179, -0.0192, -0.3183,  0.0968],
       device='cuda:1')
Solve time for step 1 9.23529584001517
Current ori: tensor([-0.0179, -0.0192, -0.3183], device='cuda:1')
Index force: tensor([0.5273, 0.5026, 0.5038, 0.5883], device='cuda:1')
tensor([ 0.1700,  0.6264,  0.5309,  0.6809, -0.1062,  0.4846,  0.8358,  0.8520,
         1.2816,  0.2575,  0.1060,  0.9781, -0.0168, -0.0183, -0.3183,  0.1136],
       device='cuda:1')
Solve time for step 2 1.9632076650159433
Current ori: tensor([-0.0168, -0.0183, -0.3183], device='cuda:1')
Index force: tensor([0.5931, 0.5773, 0.5919], device='cuda:1')
tensor([ 0.1635,  0.5880,  0.5613,  0.7108, -0.1093,  0.4958,  0.8103,  0.8654,
         1.2976,  0.2671,  0.0929,  0.9939, -0.0061, -0.0120, -0.3183,  0.1201],
       device='cuda:1')
Solve time for step 3 1.9176170080027077
Current ori: tensor([-0.0061, -0.0120, -0.3183], device='cuda:1')
Index force: tensor([0.5703, 0.5850], device='cuda:1')
tensor([ 0.1697,  0.5893,  0.5661,  0.7114, -0.1265,  0.5251,  0.8125,  0.8772,
         1.2977,  0.2774,  0.0889,  0.9845, -0.0060, -0.0157, -0.3183,  0.1292],
       device='cuda:1')
Solve time for step 4 1.8697351159935351
Current ori: tensor([-0.0060, -0.0157, -0.3183], device='cuda:1')
Index force: tensor([0.5740], device='cuda:1')
Storing RECOVERY transition: reward=-0.0027 (scaled=-0.0004), steps=6
Reward stats updated: mean -0.0088 -> -0.0088, std: 0.1669
Collected 215 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0122, Q2 Loss=1.0122, Entropy=0.0007, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6464
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=26.1113, Q2 Loss=26.1113, Entropy=0.0007, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.2019
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9912, Q2 Loss=0.9912, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0994
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6976, Q2 Loss=0.6976, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2850
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1079, Q2 Loss=1.1079, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5510

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 5.984030
Q2 loss: 5.984030
Current threshold: -27.7600
Global Scale Offset: 0.3676
Reward stats: mean=-0.0088, std=0.1669, count=215
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.9840, Q2 Loss: 5.9840, Entropy: 0.0003, Mean TD Error: 2.3567, Threshold: -27.7600
Original likelihood: -19.03201675415039
Adjusted likelihood: -19.03201675415039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0038, -0.0023, -0.3143], device='cuda:1')
3 turn
Sampling time 4.007943758013425
tensor([ 0.1474,  0.5734,  0.5671,  0.7052, -0.0818,  0.5665,  0.8455,  0.8773,
         1.3736,  0.2822,  0.1403,  1.0234, -0.0038, -0.0023, -0.3143,  0.1011],
       device='cuda:1')
Original likelihood: -18.076995849609375
Adjusted likelihood: -18.076995849609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.912608799000736
Current ori: tensor([-0.0038, -0.0023, -0.3143], device='cuda:1')
Middle force: tensor([1.7088, 0.4969, 0.5113, 0.5320, 0.5395, 0.5025, 1.1106, 0.5821, 0.5839,
        0.6041, 0.5624, 0.4925], device='cuda:1')
Thumb force: tensor([1.8318, 0.5460, 0.8121, 1.2323, 1.0041, 0.6063, 1.4315, 0.6059, 0.9253,
        0.8848, 0.5834, 0.6441], device='cuda:1')
Index force: tensor([0.5696, 0.9027, 0.5988, 0.7263, 0.5461, 0.6423, 0.5532, 0.6003, 0.8626,
        0.5805, 0.5145, 0.8286], device='cuda:1')
Storing NORMAL transition: reward=0.0989 (scaled=0.0989), steps=1
Reward stats updated: mean -0.0088 -> -0.0083, std: 0.1667
Collected 216 transitions for RL
SAC Update 1/5: Actor Loss=-0.0132, Q1 Loss=0.8824, Q2 Loss=0.8824, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8480
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.7215, Q2 Loss=1.7215, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6752
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8917, Q2 Loss=0.8917, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.6438
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2254, Q2 Loss=1.2254, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2704
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.3286, Q2 Loss=1.3286, Entropy=0.1284, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8283

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.9%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (19.8%)
Actor update: 0.13s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002646
Q1 loss: 1.209914
Q2 loss: 1.209914
Current threshold: -27.7109
Global Scale Offset: 0.3523
Reward stats: mean=-0.0083, std=0.1667, count=216
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 1.2099, Q2 Loss: 1.2099, Entropy: 0.0257, Mean TD Error: 1.8531, Threshold: -27.7109
tensor([ 0.1472,  0.6207,  0.5554,  0.6032, -0.0647,  0.5911,  0.7691,  0.9904,
         1.2405,  0.4586,  0.2663,  0.9232, -0.0213, -0.0116, -0.4139,  0.2810],
       device='cuda:1')
Original likelihood: -20.105234146118164
Adjusted likelihood: -20.105234146118164
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.2071216180047486
Current ori: tensor([-0.0213, -0.0116, -0.4139], device='cuda:1')
Middle force: tensor([0.5012, 0.5105, 0.5289, 0.5390, 0.5022, 1.1038, 0.5806, 0.5823, 0.6011,
        0.5617, 0.5006], device='cuda:1')
Thumb force: tensor([0.5400, 0.8069, 1.2327, 0.9950, 0.6018, 1.4197, 0.5996, 0.9154, 0.8792,
        0.5792, 0.6457], device='cuda:1')
Index force: tensor([0.8926, 0.5970, 0.7204, 0.5446, 0.6396, 0.5527, 0.6018, 0.8601, 0.5796,
        0.5142, 0.8367], device='cuda:1')
Storing NORMAL transition: reward=0.0314 (scaled=0.0314), steps=1
Reward stats updated: mean -0.0083 -> -0.0081, std: 0.1663
Collected 217 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6878, Q2 Loss=0.6878, Entropy=0.0561, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4897
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9128, Q2 Loss=0.9128, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3405
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7725, Q2 Loss=0.7725, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2713
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.9937, Q2 Loss=0.9937, Entropy=0.2538, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2842
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9322, Q2 Loss=0.9322, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7110

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000051
Q1 loss: 0.859812
Q2 loss: 0.859812
Current threshold: -27.6789
Global Scale Offset: 0.3437
Reward stats: mean=-0.0081, std=0.1663, count=217
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.8598, Q2 Loss: 0.8598, Entropy: 0.0620, Mean TD Error: 0.4193, Threshold: -27.6789
tensor([ 0.1560,  0.5916,  0.5836,  0.6423, -0.0717,  0.5985,  0.7659,  1.0223,
         1.3153,  0.3659,  0.1939,  0.9604, -0.0115, -0.0141, -0.4450,  0.3330],
       device='cuda:1')
Original likelihood: -18.862934112548828
Adjusted likelihood: -18.862934112548828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.67092532501556
Current ori: tensor([-0.0115, -0.0141, -0.4450], device='cuda:1')
Middle force: tensor([0.5101, 0.5297, 0.5398, 0.5020, 1.0951, 0.5792, 0.5836, 0.5992, 0.5606,
        0.5006], device='cuda:1')
Thumb force: tensor([0.8013, 1.2136, 0.9803, 0.6002, 1.4082, 0.5968, 0.9043, 0.8732, 0.5768,
        0.6440], device='cuda:1')
Index force: tensor([0.5915, 0.7148, 0.5431, 0.6379, 0.5521, 0.5998, 0.8526, 0.5779, 0.5137,
        0.8345], device='cuda:1')
Storing NORMAL transition: reward=-0.0059 (scaled=-0.0059), steps=1
Reward stats updated: mean -0.0081 -> -0.0081, std: 0.1659
Collected 218 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.0739, Q2 Loss=1.0739, Entropy=0.1863, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6248
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9733, Q2 Loss=0.9733, Entropy=0.0366, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3333
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9859, Q2 Loss=0.9859, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4351
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.2925, Q2 Loss=1.2925, Entropy=0.1314, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9961
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6125, Q2 Loss=0.6125, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0282

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000033
Q1 loss: 0.987590
Q2 loss: 0.987590
Current threshold: -27.6565
Global Scale Offset: 0.3391
Reward stats: mean=-0.0081, std=0.1659, count=218
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9876, Q2 Loss: 0.9876, Entropy: 0.0709, Mean TD Error: 0.4835, Threshold: -27.6565
tensor([ 0.2479,  0.6153,  0.6535,  0.6463, -0.2067,  0.6557,  0.8094,  0.9649,
         1.3367,  0.3550,  0.0741,  0.9972, -0.0088, -0.0706, -0.4450,  0.4727],
       device='cuda:1')
Original likelihood: -38.86049270629883
Adjusted likelihood: -38.86049270629883
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 39.75042724609375
Projection step: 1, Loss: 36.85743713378906
Projection step: 2, Loss: 32.54130554199219
Projection step: 3, Loss: 30.06292724609375
Projection step: 4, Loss: 25.86026382446289
Projection step: 5, Loss: 27.706012725830078
Projection step: 6, Loss: 24.934520721435547
Projection step: 7, Loss: 24.405174255371094
Projection step: 8, Loss: 23.603097915649414
Projection step: 9, Loss: 21.725444793701172
Projection step: 10, Loss: 22.832809448242188
Projection step: 11, Loss: 20.222383499145508
Projection step: 12, Loss: 20.575725555419922
Projection step: 13, Loss: 18.508174896240234
Projection step: 14, Loss: 19.044574737548828
Final likelihood: tensor([-16.5420, -16.5307, -16.8420, -16.6100, -17.0152, -23.6247, -16.9381,
        -16.3673, -20.2546, -16.7339, -16.6077, -16.5668, -16.3571, -16.6764,
        -23.3643, -16.4815])
Final projection likelihood: -17.7195
1 mode projection succeeded
New goal: tensor([ 0.1775,  0.5329,  0.6293,  0.6758, -0.0835,  0.6572,  0.9310,  0.8516,
         1.4055,  0.2670,  0.1151,  0.8674, -0.0154, -0.0577, -2.8318],
       device='cuda:1')
tensor([[0.0035]], device='cuda:1') tensor([[0.0155]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -29.80571746826172
Adjusted likelihood: -29.80571746826172
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 29.80571746826172}
Current yaw: tensor([-0.0088, -0.0706, -0.4450], device='cuda:1')
4 thumb_middle
tensor([ 0.2479,  0.6153,  0.6535,  0.6463, -0.2067,  0.6557,  0.8094,  0.9649,
         1.3367,  0.3550,  0.0741,  0.9972, -0.0088, -0.0706, -0.4450,  0.4727],
       device='cuda:1')
Solve time for step 1 9.556234297982883
Current ori: tensor([-0.0088, -0.0706, -0.4450], device='cuda:1')
Index force: tensor([0.5665, 0.5974, 0.5813, 0.5970], device='cuda:1')
tensor([ 0.2173,  0.5829,  0.6499,  0.6672, -0.1996,  0.6455,  0.8635,  0.8463,
         1.3644,  0.2723,  0.0342,  0.8734, -0.0030, -0.0494, -0.4450,  0.4386],
       device='cuda:1')
Solve time for step 2 2.0691353130096104
Current ori: tensor([-0.0030, -0.0494, -0.4450], device='cuda:1')
Index force: tensor([0.5904, 0.5762, 0.5919], device='cuda:1')
tensor([ 0.2145,  0.5779,  0.6531,  0.6674, -0.2095,  0.6513,  0.8838,  0.8334,
         1.3833,  0.2590,  0.0318,  0.8520, -0.0021, -0.0474, -0.4450,  0.4353],
       device='cuda:1')
Solve time for step 3 1.8902270600083284
Current ori: tensor([-0.0021, -0.0474, -0.4450], device='cuda:1')
Index force: tensor([0.5689, 0.5851], device='cuda:1')
tensor([ 0.2172,  0.5862,  0.6371,  0.6834, -0.2151,  0.6627,  0.8877,  0.8309,
         1.3909,  0.2613,  0.0226,  0.8490, -0.0024, -0.0491, -0.4450,  0.4425],
       device='cuda:1')
Solve time for step 4 1.93521383497864
Current ori: tensor([-0.0024, -0.0491, -0.4450], device='cuda:1')
Index force: tensor([0.5736], device='cuda:1')
Storing RECOVERY transition: reward=0.0134 (scaled=0.0045), steps=3
Reward stats updated: mean -0.0081 -> -0.0080, std: 0.1656
Collected 219 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7608, Q2 Loss=0.7608, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5568
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4662, Q2 Loss=1.4662, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1423
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0217, Q2 Loss=1.0217, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4688
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0867, Q2 Loss=1.0867, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8654
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8135, Q2 Loss=0.8135, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3233

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.06s (19.4%)
Actor update: 0.12s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.029793
Q2 loss: 1.029793
Current threshold: -27.6425
Global Scale Offset: 0.3365
Reward stats: mean=-0.0080, std=0.1656, count=219
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0298, Q2 Loss: 1.0298, Entropy: 0.0000, Mean TD Error: 0.6713, Threshold: -27.6425
Original likelihood: -28.191377639770508
Adjusted likelihood: -28.191377639770508
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2519)
State is out of distribution
Projection step: 0, Loss: 28.753597259521484
Projection step: 1, Loss: 26.405864715576172
Projection step: 2, Loss: 26.369346618652344
Projection step: 3, Loss: 24.861045837402344
Projection step: 4, Loss: 24.099958419799805
Projection step: 5, Loss: 28.1543025970459
Projection step: 6, Loss: 24.58895492553711
Projection step: 7, Loss: 24.795406341552734
Projection step: 8, Loss: 24.8111629486084
Projection step: 9, Loss: 21.662982940673828
Projection step: 10, Loss: 22.442489624023438
Projection step: 11, Loss: 21.268890380859375
Projection step: 12, Loss: 22.442508697509766
Projection step: 13, Loss: 19.915834426879883
Projection step: 14, Loss: 18.944561004638672
Final likelihood: tensor([-21.6010, -15.8635, -16.1910, -20.5347, -22.5137, -20.2121, -17.5450,
        -18.4449, -21.5381, -23.1035, -16.4781, -18.4100, -17.6047, -16.7767,
        -17.8137, -19.4217])
Final projection likelihood: -19.0033
1 mode projection succeeded
New goal: tensor([ 0.1541,  0.5227,  0.5659,  0.8057, -0.0342,  0.6559,  0.8690,  0.7949,
         1.4895,  0.1660,  0.1451,  0.9913, -0.0052, -0.0338, -2.9246],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -28.49083137512207
Adjusted likelihood: -28.49083137512207
Likelihood residual: 0.0
Original likelihood: -29.675037384033203
Adjusted likelihood: -29.675037384033203
Likelihood residual: 0.0
{'index': 29.675037384033203, 'thumb_middle': 28.49083137512207}
Current yaw: tensor([-5.0697e-05, -4.7895e-02, -4.5506e-01], device='cuda:1')
5 thumb_middle
tensor([ 2.1560e-01,  5.7616e-01,  6.4866e-01,  6.8351e-01, -1.5128e-01,
         7.0593e-01,  9.3179e-01,  8.3631e-01,  1.4444e+00,  2.6875e-01,
         9.7276e-02,  8.7055e-01, -5.0697e-05, -4.7895e-02, -4.5506e-01,
         4.5873e-01], device='cuda:1')
Solve time for step 1 9.248905220010784
Current ori: tensor([-5.0697e-05, -4.7895e-02, -4.5506e-01], device='cuda:1')
Index force: tensor([0.5145, 0.5026, 0.6379, 0.4999], device='cuda:1')
tensor([ 0.2161,  0.5966,  0.5823,  0.7618, -0.1542,  0.6447,  0.8388,  0.7567,
         1.3967,  0.1743,  0.0095,  0.9154,  0.0021, -0.0470, -0.4550,  0.4720],
       device='cuda:1')
Solve time for step 2 2.0073799979873
Current ori: tensor([ 0.0021, -0.0470, -0.4550], device='cuda:1')
Index force: tensor([0.5024, 0.6308, 0.5000], device='cuda:1')
tensor([ 0.2155,  0.5907,  0.5839,  0.7728, -0.1634,  0.6583,  0.8280,  0.7691,
         1.4091,  0.1340,  0.0135,  0.9122,  0.0044, -0.0460, -0.4550,  0.4758],
       device='cuda:1')
Solve time for step 3 1.9093087520159315
Current ori: tensor([ 0.0044, -0.0460, -0.4550], device='cuda:1')
Index force: tensor([0.6179, 0.5000], device='cuda:1')
tensor([ 0.1806,  0.5357,  0.6031,  0.8066, -0.1758,  0.6411,  0.8003,  0.7799,
         1.4268,  0.1397,  0.0131,  0.9439,  0.0178, -0.0223, -0.4550,  0.4465],
       device='cuda:1')
Solve time for step 4 1.8369183930044528
Current ori: tensor([ 0.0178, -0.0223, -0.4550], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0224 (scaled=0.0075), steps=3
Reward stats updated: mean -0.0080 -> -0.0079, std: 0.1652
Collected 220 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7129, Q2 Loss=0.7129, Entropy=0.0042, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4054
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9034, Q2 Loss=0.9034, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0450
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7484, Q2 Loss=0.7484, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5467
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8300, Q2 Loss=0.8300, Entropy=0.0004, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4424
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8118, Q2 Loss=0.8118, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3540

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.801291
Q2 loss: 0.801291
Current threshold: -27.6342
Global Scale Offset: 0.3349
Reward stats: mean=-0.0079, std=0.1652, count=220
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8013, Q2 Loss: 0.8013, Entropy: 0.0009, Mean TD Error: 0.5587, Threshold: -27.6342
Original likelihood: -27.461429595947266
Adjusted likelihood: -27.461429595947266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5836)
Current yaw: tensor([ 0.0196, -0.0281, -0.4626], device='cuda:1')
6 turn
Sampling time 3.971361354982946
tensor([ 0.1859,  0.5392,  0.6029,  0.8082, -0.1140,  0.6799,  0.8742,  0.7794,
         1.4921,  0.1560,  0.0659,  0.9627,  0.0196, -0.0281, -0.4626,  0.3883],
       device='cuda:1')
Original likelihood: -27.466594696044922
Adjusted likelihood: -27.466594696044922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5811)
State is out of distribution
Projection step: 0, Loss: 26.320301055908203
Projection step: 1, Loss: 25.936626434326172
Projection step: 2, Loss: 23.136701583862305
Projection step: 3, Loss: 23.38517189025879
Projection step: 4, Loss: 21.40572166442871
Projection step: 5, Loss: 22.273590087890625
Projection step: 6, Loss: 21.103565216064453
Projection step: 7, Loss: 20.627939224243164
Projection step: 8, Loss: 20.439653396606445
Projection step: 9, Loss: 19.905078887939453
Projection step: 10, Loss: 19.585487365722656
Projection step: 11, Loss: 19.775482177734375
Projection step: 12, Loss: 19.42586898803711
Projection step: 13, Loss: 18.584888458251953
Projection step: 14, Loss: 18.212997436523438
Final likelihood: tensor([-18.1762, -17.3084, -20.6794, -16.9296, -19.5311, -16.9838, -15.8128,
        -17.2769, -18.2338, -15.2811, -16.6156, -14.4403, -18.1993, -18.2450,
        -16.6963, -17.7733])
Final projection likelihood: -17.3864
1 mode projection succeeded
New goal: tensor([ 0.1279,  0.4999,  0.6228,  0.7209, -0.0576,  0.5998,  0.9133,  0.7822,
         1.4219,  0.1944,  0.1602,  1.1054,  0.0096, -0.0198, -2.1307],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0032]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -20.164302825927734
Adjusted likelihood: -20.164302825927734
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.164302825927734}
Current yaw: tensor([ 0.0196, -0.0281, -0.4626], device='cuda:1')
7 thumb_middle
tensor([ 0.1859,  0.5392,  0.6029,  0.8082, -0.1140,  0.6799,  0.8742,  0.7794,
         1.4921,  0.1560,  0.0659,  0.9627,  0.0196, -0.0281, -0.4626,  0.3883],
       device='cuda:1')
Solve time for step 1 9.128612317988882
Current ori: tensor([ 0.0196, -0.0281, -0.4626], device='cuda:1')
Index force: tensor([0.5629, 0.5734, 0.5837, 0.5844], device='cuda:1')
tensor([ 0.1808,  0.5257,  0.6400,  0.7581, -0.1676,  0.5944,  0.8648,  0.7462,
         1.3550,  0.1629,  0.0416,  1.0263,  0.0173, -0.0255, -0.4626,  0.3752],
       device='cuda:1')
Solve time for step 2 1.9764551130065229
Current ori: tensor([ 0.0173, -0.0255, -0.4626], device='cuda:1')
Index force: tensor([0.5673, 0.5789, 0.5790], device='cuda:1')
tensor([ 0.1537,  0.5035,  0.6451,  0.7514, -0.1921,  0.6079,  0.8393,  0.7620,
         1.3627,  0.1621,  0.0442,  1.0464,  0.0204, -0.0097, -0.4626,  0.3411],
       device='cuda:1')
Solve time for step 3 2.0239274839987047
Current ori: tensor([ 0.0204, -0.0097, -0.4626], device='cuda:1')
Index force: tensor([0.5730, 0.5739], device='cuda:1')
tensor([ 0.1536,  0.5032,  0.6444,  0.7535, -0.1952,  0.5974,  0.8700,  0.7521,
         1.3703,  0.1541,  0.0354,  1.0457,  0.0207, -0.0096, -0.4626,  0.3416],
       device='cuda:1')
Solve time for step 4 1.8539470539835747
Current ori: tensor([ 0.0207, -0.0096, -0.4626], device='cuda:1')
Index force: tensor([0.5686], device='cuda:1')
Storing RECOVERY transition: reward=-0.0215 (scaled=-0.0215), steps=0
Reward stats updated: mean -0.0079 -> -0.0080, std: 0.1648
Collected 221 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.6665, Q2 Loss=0.6665, Entropy=0.3400, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2234
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0428, Q2 Loss=1.0428, Entropy=0.0006, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2637
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.7227, Q2 Loss=0.7227, Entropy=0.2411, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3467
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.9033, Q2 Loss=0.9033, Entropy=0.3645, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3304
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6813, Q2 Loss=0.6813, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2372

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.0%)
Actor update: 0.12s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000107
Q1 loss: 0.803344
Q2 loss: 0.803344
Current threshold: -27.6265
Global Scale Offset: 0.3342
Reward stats: mean=-0.0080, std=0.1648, count=221
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.8033, Q2 Loss: 0.8033, Entropy: 0.1892, Mean TD Error: 0.2803, Threshold: -27.6265
Original likelihood: -26.113555908203125
Adjusted likelihood: -26.113555908203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9680)
Current yaw: tensor([ 0.0229,  0.0091, -0.4405], device='cuda:1')
8 turn
Sampling time 3.8247835469956044
tensor([ 0.1197,  0.4872,  0.6348,  0.7479, -0.1515,  0.6407,  0.8876,  0.7462,
         1.4335,  0.1765,  0.1056,  1.0933,  0.0229,  0.0091, -0.4405,  0.2643],
       device='cuda:1')
Original likelihood: -23.841312408447266
Adjusted likelihood: -23.841312408447266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.535427566006547
Current ori: tensor([ 0.0229,  0.0091, -0.4405], device='cuda:1')
Middle force: tensor([1.4389, 0.9040, 0.9165, 1.5288, 1.4216, 0.6565, 0.5155, 0.7751, 0.5004,
        0.4917, 0.5085, 0.5690], device='cuda:1')
Thumb force: tensor([0.5704, 0.5184, 0.5864, 0.6581, 1.0315, 1.2137, 0.9088, 0.5801, 0.6262,
        0.5327, 0.6540, 0.5740], device='cuda:1')
Index force: tensor([0.8077, 0.7233, 0.7483, 0.5245, 0.9727, 0.8158, 0.5916, 0.5147, 0.5778,
        0.7046, 0.6843, 0.6516], device='cuda:1')
Storing NORMAL transition: reward=-0.0658 (scaled=-0.0658), steps=1
Reward stats updated: mean -0.0080 -> -0.0083, std: 0.1645
Collected 222 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9671, Q2 Loss=0.9671, Entropy=0.0297, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3202
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.8079, Q2 Loss=1.8079, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8449
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8935, Q2 Loss=0.8935, Entropy=0.0641, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3846
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2731, Q2 Loss=1.2731, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7444
SAC Update 5/5: Actor Loss=-0.0035, Q1 Loss=0.7835, Q2 Loss=0.7835, Entropy=0.0660, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5737

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.1%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.07s (20.5%)
Actor update: 0.13s (42.1%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000714
Q1 loss: 1.145000
Q2 loss: 1.145000
Current threshold: -27.6139
Global Scale Offset: 0.3333
Reward stats: mean=-0.0083, std=0.1645, count=222
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 1.1450, Q2 Loss: 1.1450, Entropy: 0.0320, Mean TD Error: 2.1736, Threshold: -27.6139
tensor([ 0.0942,  0.5142,  0.5879,  0.7189, -0.1606,  0.6873,  0.8105,  0.7428,
         1.4079,  0.2510,  0.1275,  1.0776,  0.0131,  0.0210, -0.3747,  0.1381],
       device='cuda:1')
Original likelihood: -22.467044830322266
Adjusted likelihood: -22.467044830322266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.149680406000698
Current ori: tensor([ 0.0131,  0.0210, -0.3747], device='cuda:1')
Middle force: tensor([0.9020, 0.9109, 1.5138, 1.4088, 0.6413, 0.5174, 0.7678, 0.5005, 0.4995,
        0.5071, 0.5678], device='cuda:1')
Thumb force: tensor([0.5162, 0.5846, 0.6540, 1.0240, 1.2168, 0.8945, 0.5794, 0.6227, 0.5302,
        0.6565, 0.5732], device='cuda:1')
Index force: tensor([0.7212, 0.7453, 0.5236, 0.9643, 0.8127, 0.5848, 0.5140, 0.5800, 0.7258,
        0.6849, 0.6474], device='cuda:1')
Storing NORMAL transition: reward=-0.0311 (scaled=-0.0311), steps=1
Reward stats updated: mean -0.0083 -> -0.0084, std: 0.1641
Collected 223 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1740, Q2 Loss=1.1740, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7058
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7757, Q2 Loss=0.7757, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2880
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.8346, Q2 Loss=1.8346, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8506
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8089, Q2 Loss=0.8089, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3730
SAC Update 5/5: Actor Loss=-0.0022, Q1 Loss=1.1228, Q2 Loss=1.1228, Entropy=0.2791, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4115

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (18.5%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000442
Q1 loss: 1.143180
Q2 loss: 1.143180
Current threshold: -27.5865
Global Scale Offset: 0.3305
Reward stats: mean=-0.0084, std=0.1641, count=223
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.1432, Q2 Loss: 1.1432, Entropy: 0.0558, Mean TD Error: 1.3258, Threshold: -27.5865
tensor([ 0.0835,  0.5755,  0.4878,  0.6654, -0.2047,  0.8192,  0.8158,  0.6885,
         1.3551,  0.2177,  0.2131,  0.9948,  0.0174, -0.0037, -0.3433, -1.7137],
       device='cuda:1')
Original likelihood: -31.59319496154785
Adjusted likelihood: -31.59319496154785
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.340118408203125
Projection step: 1, Loss: 30.373756408691406
Projection step: 2, Loss: 27.54241371154785
Projection step: 3, Loss: 25.82332992553711
Projection step: 4, Loss: 23.545570373535156
Projection step: 5, Loss: 22.768709182739258
Projection step: 6, Loss: 21.340532302856445
Projection step: 7, Loss: 21.418060302734375
Projection step: 8, Loss: 19.109355926513672
Projection step: 9, Loss: 17.69871711730957
Projection step: 10, Loss: 18.08812713623047
Projection step: 11, Loss: 16.21448516845703
Projection step: 12, Loss: 15.475622177124023
Projection step: 13, Loss: 15.529794692993164
Projection step: 14, Loss: 14.431227684020996
Final likelihood: tensor([-13.0073, -13.1268, -15.2499, -14.4518, -16.9982, -13.9571, -13.0570,
        -17.7400, -11.5478, -18.0279, -12.7340, -13.8544, -13.6263, -13.4658,
        -14.0778, -15.9776])
Final projection likelihood: -14.4312
1 mode projection succeeded
New goal: tensor([ 0.0877,  0.5622,  0.5644,  0.6052, -0.0860,  0.6062,  0.8786,  0.7360,
         1.3443,  0.2559,  0.2244,  1.1806,  0.0123,  0.0109, -1.5679],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0045]], device='cuda:1')
Original likelihood: -33.258697509765625
Adjusted likelihood: -33.258697509765625
Likelihood residual: 0.0
{'index': 33.258697509765625, 'thumb_middle': inf}
Current yaw: tensor([ 0.0174, -0.0037, -0.3433], device='cuda:1')
9 index
tensor([ 0.0835,  0.5755,  0.4878,  0.6654, -0.2047,  0.8192,  0.8158,  0.6885,
         1.3551,  0.2177,  0.2131,  0.9948,  0.0174, -0.0037, -0.3433, -1.7137],
       device='cuda:1')
Solve time for step 1 10.786937580996891
Current ori: tensor([ 0.0174, -0.0037, -0.3433], device='cuda:1')
Middle force: tensor([0.5496, 0.6143, 0.5967, 0.5740], device='cuda:1')
Thumb force: tensor([0.5568, 0.5248, 0.5945, 0.5201], device='cuda:1')
tensor([ 0.1408,  0.5177,  0.5068,  0.5979, -0.2014,  0.7835,  0.8798,  0.7018,
         1.3475,  0.2284,  0.1810,  1.0610,  0.0339, -0.0129, -0.3691, -2.7407],
       device='cuda:1')
Solve time for step 2 2.3203560469846707
Current ori: tensor([ 0.0339, -0.0129, -0.3691], device='cuda:1')
Middle force: tensor([0.6131, 0.5924, 0.5718], device='cuda:1')
Thumb force: tensor([0.5220, 0.5929, 0.5192], device='cuda:1')
tensor([ 0.1386,  0.5216,  0.5218,  0.5877, -0.2103,  0.7626,  0.9052,  0.7155,
         1.3514,  0.2221,  0.1813,  1.0856,  0.0448, -0.0086, -0.3711, -3.1838],
       device='cuda:1')
Solve time for step 3 2.2416914379864465
Current ori: tensor([ 0.0448, -0.0086, -0.3711], device='cuda:1')
Middle force: tensor([0.5888, 0.5697], device='cuda:1')
Thumb force: tensor([0.5893, 0.5183], device='cuda:1')
tensor([ 0.1360,  0.5249,  0.5221,  0.5892, -0.2110,  0.7561,  0.9139,  0.7209,
         1.3513,  0.2197,  0.1813,  1.0988,  0.0512, -0.0079, -0.3734, -3.2378],
       device='cuda:1')
Solve time for step 4 2.1517979039927013
Current ori: tensor([ 0.0512, -0.0079, -0.3734], device='cuda:1')
Middle force: tensor([0.5650], device='cuda:1')
Thumb force: tensor([0.5175], device='cuda:1')
Storing RECOVERY transition: reward=0.0335 (scaled=0.0168), steps=2
Reward stats updated: mean -0.0084 -> -0.0083, std: 0.1638
Collected 224 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6982, Q2 Loss=0.6982, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3439
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=2.4927, Q2 Loss=2.4927, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0168
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6217, Q2 Loss=0.6217, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1411
SAC Update 4/5: Actor Loss=-0.0058, Q1 Loss=0.8714, Q2 Loss=0.8714, Entropy=0.0238, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6244
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1566, Q2 Loss=1.1566, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1763

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.6%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.3%)
Actor update: 0.10s (42.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001161
Q1 loss: 1.168130
Q2 loss: 1.168130
Current threshold: -27.5501
Global Scale Offset: 0.3253
Reward stats: mean=-0.0083, std=0.1638, count=224
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 1.1681, Q2 Loss: 1.1681, Entropy: 0.0048, Mean TD Error: 1.4605, Threshold: -27.5501
Original likelihood: -34.88904571533203
Adjusted likelihood: -34.88904571533203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 33.99022674560547
Projection step: 1, Loss: 31.587392807006836
Projection step: 2, Loss: 29.99631118774414
Projection step: 3, Loss: 26.261798858642578
Projection step: 4, Loss: 24.285175323486328
Projection step: 5, Loss: 25.250812530517578
Projection step: 6, Loss: 24.520837783813477
Projection step: 7, Loss: 21.10138702392578
Projection step: 8, Loss: 21.662158966064453
Projection step: 9, Loss: 20.215171813964844
Projection step: 10, Loss: 18.893890380859375
Projection step: 11, Loss: 19.120635986328125
Projection step: 12, Loss: 18.689224243164062
Projection step: 13, Loss: 18.048870086669922
Projection step: 14, Loss: 17.5937442779541
Final likelihood: tensor([-18.1686, -19.4197, -17.3677, -16.5989, -15.7183, -13.2595, -19.5001,
        -13.3370, -13.8418, -19.6647, -18.5267, -18.0681, -15.8658, -11.9452,
        -17.9743, -16.3850])
Final projection likelihood: -16.6026
1 mode projection succeeded
New goal: tensor([ 9.0390e-02,  5.5597e-01,  5.7654e-01,  6.0036e-01, -7.5820e-02,
         5.7694e-01,  8.8863e-01,  7.8228e-01,  1.3472e+00,  2.3606e-01,
         2.2593e-01,  1.1911e+00,  3.6650e-02,  1.3708e-04, -1.5875e+00],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -36.776397705078125
Adjusted likelihood: -36.776397705078125
Likelihood residual: 0.0
{'index': 36.776397705078125, 'thumb_middle': inf}
Current yaw: tensor([ 0.0518, -0.0033, -0.3789], device='cuda:1')
10 index
tensor([ 0.0883,  0.5687,  0.5583,  0.6024, -0.2201,  0.7698,  0.9051,  0.7100,
         1.3521,  0.2241,  0.1927,  1.0864,  0.0518, -0.0033, -0.3789, -3.2001],
       device='cuda:1')
Solve time for step 1 10.449804857984418
Current ori: tensor([ 0.0518, -0.0033, -0.3789], device='cuda:1')
Middle force: tensor([0.5063, 0.5105, 0.5325, 0.5487], device='cuda:1')
Thumb force: tensor([0.5036, 0.5204, 0.5203, 0.5376], device='cuda:1')
tensor([ 0.1431,  0.5022,  0.5341,  0.5801, -0.2334,  0.7492,  0.9375,  0.7762,
         1.3687,  0.2048,  0.1700,  1.1537,  0.0818, -0.0049, -0.4224, -2.4709],
       device='cuda:1')
Solve time for step 2 2.255915615998674
Current ori: tensor([ 0.0818, -0.0049, -0.4224], device='cuda:1')
Middle force: tensor([0.5097, 0.5306, 0.5464], device='cuda:1')
Thumb force: tensor([0.5195, 0.5191, 0.5358], device='cuda:1')
tensor([ 0.1411,  0.5110,  0.5316,  0.5852, -0.2197,  0.7633,  0.9329,  0.7554,
         1.3435,  0.2394,  0.1758,  1.1587,  0.0855, -0.0106, -0.4354, -1.6369],
       device='cuda:1')
Solve time for step 3 2.2052935850224458
Current ori: tensor([ 0.0855, -0.0106, -0.4354], device='cuda:1')
Middle force: tensor([0.5236, 0.5461], device='cuda:1')
Thumb force: tensor([0.5559, 0.5427], device='cuda:1')
tensor([ 0.1385,  0.5163,  0.5363,  0.5858, -0.2109,  0.7782,  0.9189,  0.7347,
         1.3548,  0.2260,  0.1737,  1.1345,  0.0797, -0.0133, -0.4503, -0.8684],
       device='cuda:1')
Solve time for step 4 2.1512257370050065
Current ori: tensor([ 0.0797, -0.0133, -0.4503], device='cuda:1')
Middle force: tensor([0.5439], device='cuda:1')
Thumb force: tensor([0.5396], device='cuda:1')
Storing RECOVERY transition: reward=0.1113 (scaled=0.0557), steps=2
Reward stats updated: mean -0.0083 -> -0.0080, std: 0.1635
Collected 225 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7220, Q2 Loss=0.7220, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5475
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9641, Q2 Loss=0.9641, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3712
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7024, Q2 Loss=0.7024, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4555
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2037, Q2 Loss=1.2037, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5365
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0464, Q2 Loss=1.0464, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5662

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (18.4%)
Actor update: 0.09s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.927729
Q2 loss: 0.927729
Current threshold: -27.5194
Global Scale Offset: 0.3191
Reward stats: mean=-0.0080, std=0.1635, count=225
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9277, Q2 Loss: 0.9277, Entropy: 0.0000, Mean TD Error: 0.4954, Threshold: -27.5194
Original likelihood: -44.589908599853516
Adjusted likelihood: -44.589908599853516
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 44.97602844238281
Projection step: 1, Loss: 41.714054107666016
Projection step: 2, Loss: 39.12095642089844
Projection step: 3, Loss: 36.800838470458984
Projection step: 4, Loss: 35.45124053955078
Projection step: 5, Loss: 33.352317810058594
Projection step: 6, Loss: 31.783796310424805
Projection step: 7, Loss: 32.027374267578125
Projection step: 8, Loss: 29.386722564697266
Projection step: 9, Loss: 28.914813995361328
Projection step: 10, Loss: 28.161067962646484
Projection step: 11, Loss: 27.549774169921875
Projection step: 12, Loss: 27.351055145263672
Projection step: 13, Loss: 25.830154418945312
Projection step: 14, Loss: 24.863948822021484
Final likelihood: tensor([-23.6547, -27.2216, -23.9761, -23.2125, -22.9773, -22.0594, -25.2297,
        -31.6889, -26.2826, -23.0271, -23.9308, -26.6773, -23.9235, -22.2769,
        -22.7414, -23.5413])
Final projection likelihood: -24.5263
1 mode projection succeeded
New goal: tensor([ 0.1121,  0.5659,  0.5926,  0.5924, -0.0882,  0.5896,  0.9021,  0.8489,
         1.3520,  0.1451,  0.2105,  1.2394,  0.0734, -0.0100,  0.0772],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -33.72380828857422
Adjusted likelihood: -33.72380828857422
Likelihood residual: 0.0
Original likelihood: -44.93659210205078
Adjusted likelihood: -44.93659210205078
Likelihood residual: 0.0
{'index': 44.93659210205078, 'thumb_middle': 33.72380828857422}
Current yaw: tensor([ 0.0924, -0.0057, -0.4628], device='cuda:1')
11 thumb_middle
tensor([ 0.0894,  0.5572,  0.5709,  0.6006, -0.2267,  0.7941,  0.9146,  0.7310,
         1.3712,  0.2313,  0.1626,  1.1607,  0.0924, -0.0057, -0.4628, -0.7731],
       device='cuda:1')
Solve time for step 1 9.226183386985213
Current ori: tensor([ 0.0924, -0.0057, -0.4628], device='cuda:1')
Index force: tensor([0.5788, 0.5454, 0.5805, 0.5983], device='cuda:1')
tensor([ 0.0894,  0.5483,  0.5929,  0.5839, -0.2088,  0.6228,  0.8435,  0.7906,
         1.2906,  0.1163,  0.1202,  1.2105,  0.1024, -0.0018, -0.4628, -0.7087],
       device='cuda:1')
Solve time for step 2 2.023889889009297
Current ori: tensor([ 0.1024, -0.0018, -0.4628], device='cuda:1')
Index force: tensor([0.5416, 0.5765, 0.5932], device='cuda:1')
tensor([ 0.1028,  0.5573,  0.6078,  0.5616, -0.1882,  0.6003,  0.8610,  0.8063,
         1.2906,  0.1212,  0.1134,  1.1958,  0.1162,  0.0014, -0.4628, -0.4583],
       device='cuda:1')
Solve time for step 3 1.9072235749918036
Current ori: tensor([ 0.1162,  0.0014, -0.4628], device='cuda:1')
Index force: tensor([0.5713, 0.5881], device='cuda:1')
tensor([ 1.0546e-01,  5.6491e-01,  5.9499e-01,  5.8466e-01, -2.0433e-01,
         6.1294e-01,  8.6156e-01,  8.1329e-01,  1.3101e+00,  1.0508e-01,
         1.1022e-01,  1.2083e+00,  1.2537e-01,  9.5188e-06, -4.6283e-01,
        -4.1605e-01], device='cuda:1')
Solve time for step 4 1.9212995449779555
Current ori: tensor([ 1.2537e-01,  9.5188e-06, -4.6283e-01], device='cuda:1')
Index force: tensor([0.5786], device='cuda:1')
Storing RECOVERY transition: reward=0.1106 (scaled=0.0553), steps=2
Reward stats updated: mean -0.0080 -> -0.0077, std: 0.1631
Collected 226 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8832, Q2 Loss=0.8832, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1605
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9559, Q2 Loss=0.9559, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2453
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2879, Q2 Loss=1.2879, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2162
SAC Update 4/5: Actor Loss=-0.0011, Q1 Loss=1.1169, Q2 Loss=1.1169, Entropy=0.2760, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4875
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0285, Q2 Loss=1.0285, Entropy=0.0005, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3757

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000219
Q1 loss: 1.054466
Q2 loss: 1.054466
Current threshold: -27.4969
Global Scale Offset: 0.3153
Reward stats: mean=-0.0077, std=0.1631, count=226
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0545, Q2 Loss: 1.0545, Entropy: 0.0553, Mean TD Error: 0.4970, Threshold: -27.4969
Original likelihood: -41.391109466552734
Adjusted likelihood: -41.391109466552734
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 40.433837890625
Projection step: 1, Loss: 39.914451599121094
Projection step: 2, Loss: 37.7468376159668
Projection step: 3, Loss: 37.61867141723633
Projection step: 4, Loss: 37.17567825317383
Projection step: 5, Loss: 36.10220718383789
Projection step: 6, Loss: 37.36908721923828
Projection step: 7, Loss: 33.30821228027344
Projection step: 8, Loss: 29.403318405151367
Projection step: 9, Loss: 33.12266159057617
Projection step: 10, Loss: 34.47364044189453
Projection step: 11, Loss: 31.524066925048828
Projection step: 12, Loss: 29.30194854736328
Projection step: 13, Loss: 30.54808235168457
Projection step: 14, Loss: 31.612445831298828
Final likelihood: tensor([-37.5455, -18.2767, -37.3943, -35.1623, -18.9554, -18.6029, -38.5231,
        -17.6631, -32.2043, -36.7165, -18.1510, -19.2743, -30.6227, -36.9944,
        -19.2016, -36.2132])
Final projection likelihood: -28.2188
1 mode projection failed, trying anyway
New goal: tensor([ 0.0713,  0.5560,  0.5790,  0.5890, -0.0625,  0.4999,  0.9306,  0.9468,
         1.3668,  0.1167,  0.2118,  1.2641,  0.1165, -0.0124,  0.1006],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -28.242076873779297
Adjusted likelihood: -28.242076873779297
Likelihood residual: 0.0
Original likelihood: -35.87605667114258
Adjusted likelihood: -35.87605667114258
Likelihood residual: 0.0
{'index': 35.87605667114258, 'thumb_middle': 28.242076873779297}
Current yaw: tensor([ 0.1287, -0.0043, -0.4701], device='cuda:1')
12 thumb_middle
tensor([ 0.0931,  0.5703,  0.5833,  0.5641, -0.1257,  0.6505,  0.9213,  0.8587,
         1.3733,  0.1416,  0.1813,  1.2553,  0.1287, -0.0043, -0.4701, -0.4890],
       device='cuda:1')
Solve time for step 1 9.268918228015536
Current ori: tensor([ 0.1287, -0.0043, -0.4701], device='cuda:1')
Index force: tensor([0.5966, 0.6028, 0.6071, 0.6144], device='cuda:1')
tensor([ 0.0923,  0.5458,  0.6114,  0.5921, -0.1674,  0.5219,  0.8728,  0.8881,
         1.3150,  0.0861,  0.1307,  1.2345,  0.1492,  0.0149, -0.4701, -0.1212],
       device='cuda:1')
Solve time for step 2 1.977702934993431
Current ori: tensor([ 0.1492,  0.0149, -0.4701], device='cuda:1')
Index force: tensor([0.5994, 0.6039, 0.6112], device='cuda:1')
tensor([ 0.0958,  0.5513,  0.6009,  0.6057, -0.1790,  0.5133,  0.8694,  0.9014,
         1.3325,  0.0859,  0.1298,  1.2398,  0.1482,  0.0173, -0.4701, -0.1038],
       device='cuda:1')
Solve time for step 3 1.911675966985058
Current ori: tensor([ 0.1482,  0.0173, -0.4701], device='cuda:1')
Index force: tensor([0.5929, 0.5869], device='cuda:1')
tensor([ 0.0876,  0.5551,  0.5908,  0.5963, -0.1881,  0.5041,  0.8614,  0.8968,
         1.3415,  0.0905,  0.1350,  1.2414,  0.1467,  0.0213, -0.4701, -0.0841],
       device='cuda:1')
Solve time for step 4 1.8706444109848235
Current ori: tensor([ 0.1467,  0.0213, -0.4701], device='cuda:1')
Index force: tensor([0.5764], device='cuda:1')
Storing RECOVERY transition: reward=0.0903 (scaled=0.0452), steps=2
Reward stats updated: mean -0.0077 -> -0.0075, std: 0.1628
Collected 227 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2031, Q2 Loss=1.2031, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5047
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8809, Q2 Loss=0.8809, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9432
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0481, Q2 Loss=1.0481, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7346
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1426, Q2 Loss=1.1426, Entropy=0.0006, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4338
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6779, Q2 Loss=0.6779, Entropy=0.0309, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4283

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 0.990530
Q2 loss: 0.990530
Current threshold: -27.4786
Global Scale Offset: 0.3128
Reward stats: mean=-0.0075, std=0.1628, count=227
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9905, Q2 Loss: 0.9905, Entropy: 0.0063, Mean TD Error: 0.6089, Threshold: -27.4786
Original likelihood: -20.37494468688965
Adjusted likelihood: -20.37494468688965
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.1710,  0.0158, -0.4619], device='cuda:1')
13 turn
Sampling time 3.7269854650076013
tensor([ 0.0885,  0.5474,  0.5899,  0.5664, -0.0867,  0.5603,  0.9245,  0.9329,
         1.4140,  0.1211,  0.2041,  1.2842,  0.1710,  0.0158, -0.4619, -0.3737],
       device='cuda:1')
Original likelihood: -24.61499786376953
Adjusted likelihood: -24.61499786376953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 14.331355445989175
Current ori: tensor([ 0.1710,  0.0158, -0.4619], device='cuda:1')
Middle force: tensor([0.4986, 0.7103, 1.3219, 0.5387, 1.1564, 0.6266, 0.5189, 0.5665, 0.6736,
        1.2913, 1.1815, 1.5764], device='cuda:1')
Thumb force: tensor([1.0952, 0.8483, 1.1725, 0.5057, 1.1639, 0.9147, 0.7002, 0.5985, 0.5269,
        1.7284, 1.1734, 1.2863], device='cuda:1')
Index force: tensor([0.6945, 0.8580, 1.2563, 0.5768, 0.7220, 0.6930, 0.6967, 0.5946, 0.5653,
        0.5629, 0.7044, 0.8227], device='cuda:1')
Storing NORMAL transition: reward=0.0086 (scaled=0.0086), steps=1
Reward stats updated: mean -0.0075 -> -0.0074, std: 0.1625
Collected 228 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9957, Q2 Loss=0.9957, Entropy=0.0035, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6119
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0657, Q2 Loss=1.0657, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5150
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.5729, Q2 Loss=2.5729, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0787
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8639, Q2 Loss=0.8639, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2702
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0196, Q2 Loss=1.0196, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0388

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.303539
Q2 loss: 1.303539
Current threshold: -27.4679
Global Scale Offset: 0.3114
Reward stats: mean=-0.0074, std=0.1625, count=228
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3035, Q2 Loss: 1.3035, Entropy: 0.0007, Mean TD Error: 1.7029, Threshold: -27.4679
tensor([ 0.0094,  0.5052,  0.5505,  0.8852, -0.0692,  0.5256,  1.0250,  0.8329,
         1.3802,  0.2280,  0.3210,  1.1835,  0.2158,  0.0302, -0.4888, -0.8724],
       device='cuda:1')
Original likelihood: -38.36865997314453
Adjusted likelihood: -38.36865997314453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.80385208129883
Projection step: 1, Loss: 37.625667572021484
Projection step: 2, Loss: 37.41950225830078
Projection step: 3, Loss: 35.04909133911133
Projection step: 4, Loss: 33.37705993652344
Projection step: 5, Loss: 34.38439178466797
Projection step: 6, Loss: 35.439178466796875
Projection step: 7, Loss: 34.683284759521484
Projection step: 8, Loss: 32.532867431640625
Projection step: 9, Loss: 33.778358459472656
Projection step: 10, Loss: 32.29494094848633
Projection step: 11, Loss: 32.126930236816406
Projection step: 12, Loss: 30.670734405517578
Projection step: 13, Loss: 31.093860626220703
Projection step: 14, Loss: 30.529664993286133
Final likelihood: tensor([-32.4681, -28.9696, -38.7749, -41.2962, -29.5641, -34.5264, -29.4821,
        -29.2198, -25.1532, -37.7002, -28.3427, -33.7299, -28.5053, -32.9295,
        -27.3167, -27.7892])
Final projection likelihood: -31.6105
1 mode projection failed, trying anyway
New goal: tensor([ 0.0392,  0.4564,  0.5773,  0.8385, -0.0675,  0.4478,  0.9434,  1.0377,
         1.3701,  0.2245,  0.3351,  1.0301,  0.2047,  0.0360,  0.3521],
       device='cuda:1')
tensor([[0.0032]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0021]], device='cuda:1')
Original likelihood: -36.6385612487793
Adjusted likelihood: -36.6385612487793
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 36.6385612487793}
Current yaw: tensor([ 0.2158,  0.0302, -0.4888], device='cuda:1')
14 thumb_middle
tensor([ 0.0094,  0.5052,  0.5505,  0.8852, -0.0692,  0.5256,  1.0250,  0.8329,
         1.3802,  0.2280,  0.3210,  1.1835,  0.2158,  0.0302, -0.4888, -0.8724],
       device='cuda:1')
Solve time for step 1 9.15229620898026
Current ori: tensor([ 0.2158,  0.0302, -0.4888], device='cuda:1')
Index force: tensor([0.5654, 0.6018, 0.5114, 0.5134], device='cuda:1')
tensor([-2.3208e-04,  4.7468e-01,  6.1792e-01,  1.0328e+00, -1.7163e-01,
         4.4782e-01,  9.0147e-01,  9.4883e-01,  1.3538e+00,  2.1352e-01,
         2.9607e-01,  1.0654e+00,  2.5267e-01,  3.5337e-02, -4.9488e-01,
        -1.1245e+00], device='cuda:1')
Solve time for step 2 2.014140507002594
Current ori: tensor([ 0.2527,  0.0353, -0.4949], device='cuda:1')
Index force: tensor([0.5996, 0.5089, 0.5103], device='cuda:1')
tensor([-0.0039,  0.4689,  0.6186,  1.0931, -0.1817,  0.4376,  0.8998,  0.9915,
         1.3760,  0.2203,  0.3059,  1.0471,  0.2536,  0.0363, -0.5087, -1.2432],
       device='cuda:1')
Solve time for step 3 1.9101320180052426
Current ori: tensor([ 0.2536,  0.0363, -0.5087], device='cuda:1')
Index force: tensor([0.5081, 0.5080], device='cuda:1')
tensor([-0.0101,  0.4663,  0.6311,  1.0477, -0.1867,  0.4323,  0.9127,  1.0117,
         1.3814,  0.2215,  0.3103,  1.0456,  0.2553,  0.0412, -0.5378, -1.2857],
       device='cuda:1')
Solve time for step 4 1.8273376949946396
Current ori: tensor([ 0.2553,  0.0412, -0.5378], device='cuda:1')
Index force: tensor([0.5074], device='cuda:1')
Storing RECOVERY transition: reward=0.0272 (scaled=0.0272), steps=1
Reward stats updated: mean -0.0074 -> -0.0072, std: 0.1621
Collected 229 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6617, Q2 Loss=0.6617, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2899
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6482, Q2 Loss=0.6482, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4337
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=14.1823, Q2 Loss=14.1823, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9122
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7917, Q2 Loss=0.7917, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6231
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.8422, Q2 Loss=0.8422, Entropy=0.2731, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3765

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000020
Q1 loss: 3.425224
Q2 loss: 3.425224
Current threshold: -27.4612
Global Scale Offset: 0.3106
Reward stats: mean=-0.0072, std=0.1621, count=229
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.4252, Q2 Loss: 3.4252, Entropy: 0.0546, Mean TD Error: 1.3271, Threshold: -27.4612
Original likelihood: -59.47108459472656
Adjusted likelihood: -59.47108459472656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 62.47158432006836
Projection step: 1, Loss: 58.56946563720703
Projection step: 2, Loss: 56.267601013183594
Projection step: 3, Loss: 55.72386932373047
Projection step: 4, Loss: 58.623130798339844
Projection step: 5, Loss: 53.35578155517578
Projection step: 6, Loss: 56.799686431884766
Projection step: 7, Loss: 54.104103088378906
Projection step: 8, Loss: 52.84471893310547
Projection step: 9, Loss: 53.9340934753418
Projection step: 10, Loss: 54.141685485839844
Projection step: 11, Loss: 51.88513946533203
Projection step: 12, Loss: 52.730892181396484
Projection step: 13, Loss: 46.28691482543945
Projection step: 14, Loss: 45.90217590332031
Final likelihood: tensor([-39.2013, -60.9688, -47.9939, -57.4310, -43.0145, -41.7031, -39.9668,
        -39.4403, -43.2401, -48.6797, -55.6161, -59.8965, -53.5181, -49.5310,
        -48.4778, -39.3224])
Final projection likelihood: -48.0001
1 mode projection failed, trying anyway
New goal: tensor([-0.0050,  0.3715,  0.6571,  0.9479, -0.0767,  0.4571,  0.9579,  1.1166,
         1.3973,  0.1709,  0.4130,  0.8615,  0.2445,  0.0449, -0.0267],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0004]], device='cuda:1')
Original likelihood: -53.39006805419922
Adjusted likelihood: -53.39006805419922
Likelihood residual: 0.0
Original likelihood: -57.17030334472656
Adjusted likelihood: -57.17030334472656
Likelihood residual: 0.0
{'index': 57.17030334472656, 'thumb_middle': 53.39006805419922}
Current yaw: tensor([ 0.2573,  0.0451, -0.5414], device='cuda:1')
15 thumb_middle
tensor([-0.0337,  0.4682,  0.6505,  0.9751, -0.0848,  0.5083,  0.9878,  1.0537,
         1.4434,  0.2484,  0.3833,  1.0951,  0.2573,  0.0451, -0.5414, -1.3968],
       device='cuda:1')
Solve time for step 1 9.469054226006847
Current ori: tensor([ 0.2573,  0.0451, -0.5414], device='cuda:1')
Index force: tensor([0.6166, 0.5188, 0.5935, 0.5785], device='cuda:1')
tensor([-0.0376,  0.4548,  0.5666,  1.2839, -0.2217,  0.2967,  0.9317,  1.0899,
         1.3677,  0.1541,  0.4189,  0.9680,  0.2745,  0.0858, -0.5947, -1.3470],
       device='cuda:1')
Solve time for step 2 2.078123019018676
Current ori: tensor([ 0.2745,  0.0858, -0.5947], device='cuda:1')
Index force: tensor([0.5178, 0.5899, 0.5752], device='cuda:1')
tensor([-0.0480,  0.4635,  0.6681,  1.1135, -0.2441,  0.2867,  0.9382,  1.0995,
         1.3834,  0.1379,  0.4285,  0.9638,  0.2860,  0.1015, -0.6174, -1.1683],
       device='cuda:1')
Solve time for step 3 1.9356362349935807
Current ori: tensor([ 0.2860,  0.1015, -0.6174], device='cuda:1')
Index force: tensor([0.5863, 0.5714], device='cuda:1')
tensor([-0.0351,  0.4695,  0.7849,  1.1149, -0.2478,  0.3142,  0.9220,  1.1085,
         1.3760,  0.1224,  0.4707,  0.9877,  0.2855,  0.1011, -0.6170, -0.9950],
       device='cuda:1')
Solve time for step 4 1.8648177099821623
Current ori: tensor([ 0.2855,  0.1011, -0.6170], device='cuda:1')
Index force: tensor([0.5670], device='cuda:1')
Storing RECOVERY transition: reward=0.0200 (scaled=0.0200), steps=1
Reward stats updated: mean -0.0072 -> -0.0071, std: 0.1618
Collected 230 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0302, Q2 Loss=1.0302, Entropy=0.0704, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3801
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6616, Q2 Loss=0.6616, Entropy=0.0006, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2272
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0205, Q2 Loss=1.0205, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7157
SAC Update 4/5: Actor Loss=-0.0026, Q1 Loss=1.1243, Q2 Loss=1.1243, Entropy=0.1330, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4665
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=26.8794, Q2 Loss=26.8794, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.5029

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.5%)
Actor update: 0.11s (40.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000525
Q1 loss: 6.143199
Q2 loss: 6.143199
Current threshold: -27.4471
Global Scale Offset: 0.3095
Reward stats: mean=-0.0071, std=0.1618, count=230
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 6.1432, Q2 Loss: 6.1432, Entropy: 0.0408, Mean TD Error: 2.4585, Threshold: -27.4471
Original likelihood: -85.83091735839844
Adjusted likelihood: -85.83091735839844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 83.34260559082031
Projection step: 1, Loss: 83.6375732421875
Projection step: 2, Loss: 85.39973449707031
Projection step: 3, Loss: 80.97459411621094
Projection step: 4, Loss: 79.19393920898438
Projection step: 5, Loss: 77.83895111083984
Projection step: 6, Loss: 82.61972045898438
Projection step: 7, Loss: 81.11206817626953
Projection step: 8, Loss: 79.62545776367188
Projection step: 9, Loss: 83.33265686035156
Projection step: 10, Loss: 80.26593017578125
Projection step: 11, Loss: 75.90672302246094
Projection step: 12, Loss: 77.1065444946289
Projection step: 13, Loss: 78.69393920898438
Projection step: 14, Loss: 77.7596206665039
Final likelihood: tensor([-75.7455, -78.8500, -67.8393, -66.7611, -96.6914, -82.8311, -77.7240,
        -83.0397, -76.9321, -75.3177, -89.3818, -78.5310, -82.2012, -70.5383,
        -62.2356, -87.6694])
Final projection likelihood: -78.2681
1 mode projection failed, trying anyway
New goal: tensor([ 0.0290,  0.3883,  0.7801,  0.9998, -0.1482,  0.4154,  1.0602,  1.1541,
         1.2805,  0.1613,  0.6564,  1.0434,  0.2674,  0.0957,  0.3160],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0005]], device='cuda:1')
Original likelihood: -82.03728485107422
Adjusted likelihood: -82.03728485107422
Likelihood residual: 0.0
Original likelihood: -75.48286437988281
Adjusted likelihood: -75.48286437988281
Likelihood residual: 0.0
{'index': 75.48286437988281, 'thumb_middle': 82.03728485107422}
Current yaw: tensor([ 0.2734,  0.0868, -0.5489], device='cuda:1')
16 index
tensor([ 0.0056,  0.4680,  0.7980,  0.9874, -0.1741,  0.3408,  0.9468,  1.0912,
         1.3552,  0.0845,  0.6083,  1.1625,  0.2734,  0.0868, -0.5489, -1.0243],
       device='cuda:1')
Solve time for step 1 11.829218656988814
Current ori: tensor([ 0.2734,  0.0868, -0.5489], device='cuda:1')
Middle force: tensor([0.5415, 0.5771, 0.5703, 0.5625], device='cuda:1')
Thumb force: tensor([0.5590, 0.5015, 0.6018, 0.5843], device='cuda:1')
tensor([-0.0317,  0.1743,  0.7164,  0.9488, -0.1556,  0.3793,  0.8623,  1.1341,
         1.4208,  0.0333,  0.5956,  1.0829,  0.2547,  0.0874, -0.6184, -2.6525],
       device='cuda:1')
Solve time for step 2 2.544652070006123
Current ori: tensor([ 0.2547,  0.0874, -0.6184], device='cuda:1')
Middle force: tensor([0.5727, 0.5673, 0.5596], device='cuda:1')
Thumb force: tensor([0.5013, 0.5970, 0.5808], device='cuda:1')
tensor([-0.0192,  0.1264,  0.7178,  0.9474, -0.1563,  0.3841,  0.8626,  1.1231,
         1.2874,  0.1611,  0.6634,  1.0235,  0.2518,  0.0877, -0.6288, -2.5983],
       device='cuda:1')
Solve time for step 3 2.3196251460176427
Current ori: tensor([ 0.2518,  0.0877, -0.6288], device='cuda:1')
Middle force: tensor([0.5650, 0.5571], device='cuda:1')
Thumb force: tensor([0.5907, 0.5779], device='cuda:1')
tensor([-0.0408,  0.0986,  0.7176,  0.9406, -0.1597,  0.3887,  0.8445,  1.1258,
         1.3067,  0.1408,  0.6489,  1.0489,  0.2534,  0.0881, -0.5972, -1.5077],
       device='cuda:1')
Solve time for step 4 2.1978250819956884
Current ori: tensor([ 0.2534,  0.0881, -0.5972], device='cuda:1')
Middle force: tensor([0.5550], device='cuda:1')
Thumb force: tensor([0.5742], device='cuda:1')
Storing RECOVERY transition: reward=0.0668 (scaled=0.0668), steps=1
Reward stats updated: mean -0.0071 -> -0.0068, std: 0.1615
Collected 231 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3052, Q2 Loss=1.3052, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8265
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=3.4572, Q2 Loss=3.4572, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3239
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.0561, Q2 Loss=2.0561, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9904
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.8000, Q2 Loss=0.8000, Entropy=0.1007, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1085
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7436, Q2 Loss=0.7436, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5636

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (14.6%)
Q1 update: 0.07s (20.3%)
Q2 update: 0.07s (20.3%)
Actor update: 0.14s (41.9%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000010
Q1 loss: 1.672410
Q2 loss: 1.672410
Current threshold: -27.4285
Global Scale Offset: 0.3081
Reward stats: mean=-0.0068, std=0.1615, count=231
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.6724, Q2 Loss: 1.6724, Entropy: 0.0202, Mean TD Error: 3.1626, Threshold: -27.4285
Original likelihood: -81.71420288085938
Adjusted likelihood: -81.71420288085938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 81.33804321289062
Projection step: 1, Loss: 79.66816711425781
Projection step: 2, Loss: 74.37360382080078
Projection step: 3, Loss: 69.85491943359375
Projection step: 4, Loss: 73.48240661621094
Projection step: 5, Loss: 70.196044921875
Projection step: 6, Loss: 75.35185241699219
Projection step: 7, Loss: 69.4671630859375
Projection step: 8, Loss: 72.17980194091797
Projection step: 9, Loss: 66.17850494384766
Projection step: 10, Loss: 71.59458923339844
Projection step: 11, Loss: 66.73897552490234
Projection step: 12, Loss: 67.67111206054688
Projection step: 13, Loss: 65.8465576171875
Projection step: 14, Loss: 63.47261047363281
Final likelihood: tensor([-74.5278, -65.5353, -57.9673, -75.5230, -74.8400, -86.0384, -79.4408,
        -58.4013, -49.5618, -54.4423, -64.6459, -60.6786, -78.0155, -66.7610,
        -75.6368, -67.7927])
Final projection likelihood: -68.1130
1 mode projection failed, trying anyway
New goal: tensor([-0.0817,  0.2430,  0.8303,  0.9238, -0.1592,  0.3999,  0.9238,  1.2149,
         1.2610,  0.2490,  0.6689,  0.8486,  0.2560,  0.0871,  0.1484],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -68.23387145996094
Adjusted likelihood: -68.23387145996094
Likelihood residual: 0.0
Original likelihood: -65.91329193115234
Adjusted likelihood: -65.91329193115234
Likelihood residual: 0.0
{'index': 65.91329193115234, 'thumb_middle': 68.23387145996094}
Current yaw: tensor([ 0.2647,  0.0834, -0.5992], device='cuda:1')
17 index
tensor([-0.1104,  0.3161,  0.7330,  0.9480, -0.1597,  0.3897,  0.8939,  1.1744,
         1.3077,  0.1400,  0.6453,  1.0602,  0.2647,  0.0834, -0.5992, -0.4994],
       device='cuda:1')
Solve time for step 1 11.799478724016808
Current ori: tensor([ 0.2647,  0.0834, -0.5992], device='cuda:1')
Middle force: tensor([0.5325, 0.5540, 0.5116, 0.5398], device='cuda:1')
Thumb force: tensor([0.5776, 0.5062, 0.5369, 0.5351], device='cuda:1')
tensor([-0.0529,  0.0791,  0.7491,  0.8834, -0.1557,  0.4005,  0.8722,  1.2162,
         1.2516,  0.2045,  0.6976,  0.9585,  0.2530,  0.0854, -0.6772, -1.6425],
       device='cuda:1')
Solve time for step 2 2.3284305520064663
Current ori: tensor([ 0.2530,  0.0854, -0.6772], device='cuda:1')
Middle force: tensor([0.5526, 0.5104, 0.5376], device='cuda:1')
Thumb force: tensor([0.5052, 0.5351, 0.5333], device='cuda:1')
tensor([-0.0329,  0.1081,  0.7503,  0.8777, -0.1562,  0.3964,  0.8843,  1.1791,
         1.2556,  0.2059,  0.7037,  0.9333,  0.2508,  0.0861, -0.7089, -1.0645],
       device='cuda:1')
Solve time for step 3 2.458204429014586
Current ori: tensor([ 0.2508,  0.0861, -0.7089], device='cuda:1')
Middle force: tensor([0.5090, 0.5353], device='cuda:1')
Thumb force: tensor([0.5333, 0.5312], device='cuda:1')
tensor([-0.0153,  0.1167,  0.7528,  0.8699, -0.1461,  0.4042,  0.8750,  1.1815,
         1.2439,  0.2135,  0.7050,  0.9357,  0.2499,  0.0840, -0.7032,  0.1142],
       device='cuda:1')
Solve time for step 4 2.375127956009237
Current ori: tensor([ 0.2499,  0.0840, -0.7032], device='cuda:1')
Middle force: tensor([0.5699], device='cuda:1')
Thumb force: tensor([0.5490], device='cuda:1')
Storing RECOVERY transition: reward=0.1489 (scaled=0.1489), steps=1
Reward stats updated: mean -0.0068 -> -0.0061, std: 0.1615
Collected 232 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=3.2134, Q2 Loss=3.2134, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2722
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9359, Q2 Loss=0.9359, Entropy=0.0809, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2847
SAC Update 3/5: Actor Loss=-0.0042, Q1 Loss=0.8618, Q2 Loss=0.8618, Entropy=0.2487, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5781
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7568, Q2 Loss=0.7568, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8137
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1255, Q2 Loss=1.1255, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4622

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.2%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.2%)
Actor update: 0.12s (43.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000846
Q1 loss: 1.378700
Q2 loss: 1.378700
Current threshold: -27.4003
Global Scale Offset: 0.3055
Reward stats: mean=-0.0061, std=0.1615, count=232
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 1.3787, Q2 Loss: 1.3787, Entropy: 0.0659, Mean TD Error: 1.4822, Threshold: -27.4003
Original likelihood: -59.1392936706543
Adjusted likelihood: -59.1392936706543
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 62.36650466918945
Projection step: 1, Loss: 60.305816650390625
Projection step: 2, Loss: 64.07220458984375
Projection step: 3, Loss: 62.081485748291016
Projection step: 4, Loss: 58.44076156616211
Projection step: 5, Loss: 57.76972579956055
Projection step: 6, Loss: 63.403160095214844
Projection step: 7, Loss: 59.42767333984375
Projection step: 8, Loss: 58.9637336730957
Projection step: 9, Loss: 58.895790100097656
Projection step: 10, Loss: 56.67234420776367
Projection step: 11, Loss: 58.4326286315918
Projection step: 12, Loss: 55.59354019165039
Projection step: 13, Loss: 52.248435974121094
Projection step: 14, Loss: 56.97315979003906
Final likelihood: tensor([-48.3661, -40.2159, -50.6995, -48.5645, -35.0145, -44.2628, -60.2902,
        -56.4025, -43.8614, -54.4560, -44.8117, -58.1280, -40.1004, -57.5504,
        -52.3652, -60.4401])
Final projection likelihood: -49.7206
1 mode projection failed, trying anyway
New goal: tensor([-0.0306,  0.1721,  0.8882,  0.8719, -0.1356,  0.4131,  0.9072,  1.1877,
         1.2167,  0.2625,  0.7385,  0.7114,  0.2409,  0.0837, -0.6885],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -46.84880065917969
Adjusted likelihood: -46.84880065917969
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 46.84880065917969}
Current yaw: tensor([ 0.2513,  0.0801, -0.6934], device='cuda:1')
18 thumb_middle
tensor([-0.0640,  0.2170,  0.8242,  0.9158, -0.1324,  0.4153,  0.8652,  1.1907,
         1.2408,  0.2154,  0.6993,  0.9381,  0.2513,  0.0801, -0.6934,  0.4027],
       device='cuda:1')
Solve time for step 1 9.299108885024907
Current ori: tensor([ 0.2513,  0.0801, -0.6934], device='cuda:1')
Index force: tensor([0.5644, 0.6018, 0.6033, 0.5877], device='cuda:1')
tensor([-0.0677,  0.2138,  0.8633,  0.9223, -0.2740,  0.2668,  0.8613,  1.1768,
         1.1881,  0.2293,  0.6904,  0.7552,  0.3243,  0.1094, -0.7624,  0.3192],
       device='cuda:1')
Solve time for step 2 2.1446771589980926
Current ori: tensor([ 0.3243,  0.1094, -0.7624], device='cuda:1')
Index force: tensor([0.5999, 0.5989, 0.5849], device='cuda:1')
tensor([-0.0692,  0.2087,  0.9993,  0.9272, -0.2750,  0.2601,  0.8794,  1.1750,
         1.2062,  0.2462,  0.7269,  0.7251,  0.3216,  0.1084, -0.7982,  0.4386],
       device='cuda:1')
Solve time for step 3 2.0682856460043695
Current ori: tensor([ 0.3216,  0.1084, -0.7982], device='cuda:1')
Index force: tensor([0.5855, 0.5033], device='cuda:1')
tensor([-0.0735,  0.2146,  1.0378,  0.9718, -0.2453,  0.2741,  0.9340,  1.2301,
         1.2155,  0.2493,  0.7522,  0.7172,  0.3140,  0.1003, -0.7997,  0.8938],
       device='cuda:1')
Solve time for step 4 1.9771341230079997
Current ori: tensor([ 0.3140,  0.1003, -0.7997], device='cuda:1')
Index force: tensor([0.5032], device='cuda:1')
Storing RECOVERY transition: reward=0.1493 (scaled=0.1493), steps=1
Reward stats updated: mean -0.0061 -> -0.0055, std: 0.1615
Collected 233 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8386, Q2 Loss=0.8386, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3003
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0187, Q2 Loss=1.0187, Entropy=0.0068, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.7991
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=13.6511, Q2 Loss=13.6511, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8549
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=5.8579, Q2 Loss=5.8579, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9280
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6162, Q2 Loss=0.6162, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5019

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.1%)
Q1 update: 0.07s (21.3%)
Q2 update: 0.06s (19.7%)
Actor update: 0.13s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 4.396510
Q2 loss: 4.396510
Current threshold: -27.3753
Global Scale Offset: 0.3029
Reward stats: mean=-0.0055, std=0.1615, count=233
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 4.3965, Q2 Loss: 4.3965, Entropy: 0.0014, Mean TD Error: 3.2769, Threshold: -27.3753
Original likelihood: -124.16783142089844
Adjusted likelihood: -124.16783142089844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 117.93864440917969
Projection step: 1, Loss: 111.52256774902344
Projection step: 2, Loss: 119.70979309082031
Projection step: 3, Loss: 117.96244812011719
Projection step: 4, Loss: 117.34648132324219
Projection step: 5, Loss: 116.73247528076172
Projection step: 6, Loss: 120.09185791015625
Projection step: 7, Loss: 118.56343841552734
Projection step: 8, Loss: 120.29241943359375
Projection step: 9, Loss: 112.95832824707031
Projection step: 10, Loss: 104.96723175048828
Projection step: 11, Loss: 109.73556518554688
Projection step: 12, Loss: 102.87826538085938
Projection step: 13, Loss: 104.23933410644531
Projection step: 14, Loss: 107.40264892578125
Final likelihood: tensor([-157.4698,  -92.4147,  -77.2225,  -80.1005, -121.9646, -104.8059,
        -101.4583, -127.1853, -108.9538,  -72.2423, -114.1478, -100.5331,
         -86.8472,  -91.5498,  -76.6376, -194.3246])
Final projection likelihood: -106.7411
1 mode projection failed, trying anyway
New goal: tensor([-0.0826,  0.1672,  1.0678,  0.9127, -0.1719,  0.3265,  1.1218,  1.2422,
         1.2154,  0.3151,  0.8166,  0.7698,  0.3045,  0.0942, -0.5062],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0002]], device='cuda:1') tensor([[0.0016]], device='cuda:1')
Original likelihood: -115.1097640991211
Adjusted likelihood: -115.1097640991211
Likelihood residual: 0.0
Original likelihood: -133.62799072265625
Adjusted likelihood: -133.62799072265625
Likelihood residual: 0.0
{'index': 133.62799072265625, 'thumb_middle': 115.1097640991211}
Current yaw: tensor([ 0.3110,  0.0877, -0.7617], device='cuda:1')
19 thumb_middle
tensor([-0.0606,  0.1901,  1.0629,  0.9090, -0.1684,  0.3104,  0.9185,  1.2108,
         1.2633,  0.2608,  0.8318,  0.7727,  0.3110,  0.0877, -0.7617,  1.2302],
       device='cuda:1')
Solve time for step 1 9.877305891015567
Current ori: tensor([ 0.3110,  0.0877, -0.7617], device='cuda:1')
Index force: tensor([0.6149, 0.5890, 0.5973, 0.5649], device='cuda:1')
tensor([-0.0730,  0.2164,  1.0745,  0.9214, -0.2368,  0.0140,  0.9692,  1.1603,
         1.1800,  0.2746,  0.7704,  0.7465,  0.3653,  0.1462, -0.8178,  1.5847],
       device='cuda:1')
Solve time for step 2 2.143431150005199
Current ori: tensor([ 0.3653,  0.1462, -0.8178], device='cuda:1')
Index force: tensor([0.5924, 0.5857, 0.5281], device='cuda:1')
tensor([-0.0795,  0.2421,  1.1082,  1.0580, -0.2528, -0.0468,  0.9872,  1.1375,
         1.1948,  0.2933,  0.7819,  0.7565,  0.3839,  0.1739, -0.8379,  2.0407],
       device='cuda:1')
Solve time for step 3 2.062833192991093
Current ori: tensor([ 0.3839,  0.1739, -0.8379], device='cuda:1')
Index force: tensor([0.5796, 0.5238], device='cuda:1')
tensor([-0.1371,  0.2622,  1.1391,  1.1744, -0.2290, -0.0460,  0.9945,  1.1432,
         1.2088,  0.3047,  0.8150,  0.7812,  0.3820,  0.1683, -0.8479,  2.0505],
       device='cuda:1')
Solve time for step 4 1.9879506659926847
Current ori: tensor([ 0.3820,  0.1683, -0.8479], device='cuda:1')
Index force: tensor([0.5660], device='cuda:1')
Storing RECOVERY transition: reward=0.1069 (scaled=0.1069), steps=1
Reward stats updated: mean -0.0055 -> -0.0050, std: 0.1613
Collected 234 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6968, Q2 Loss=0.6968, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2789
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8115, Q2 Loss=0.8115, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5102
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1491, Q2 Loss=1.1491, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4009
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1075, Q2 Loss=1.1075, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5753
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.3915, Q2 Loss=1.3915, Entropy=0.2212, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9060

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.0%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.12s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000032
Q1 loss: 1.031264
Q2 loss: 1.031264
Current threshold: -27.3599
Global Scale Offset: 0.3014
Reward stats: mean=-0.0050, std=0.1613, count=234
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0313, Q2 Loss: 1.0313, Entropy: 0.0442, Mean TD Error: 0.7342, Threshold: -27.3599
Original likelihood: -251.24293518066406
Adjusted likelihood: -251.24293518066406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 258.6755065917969
Projection step: 1, Loss: 260.9932861328125
Projection step: 2, Loss: 274.29742431640625
Projection step: 3, Loss: 263.16192626953125
Projection step: 4, Loss: 266.08050537109375
Projection step: 5, Loss: 264.7069396972656
Projection step: 6, Loss: 268.89312744140625
Projection step: 7, Loss: 259.23138427734375
Projection step: 8, Loss: 276.3742980957031
Projection step: 9, Loss: 260.36224365234375
Projection step: 10, Loss: 263.89837646484375
Projection step: 11, Loss: 261.3013916015625
Projection step: 12, Loss: 251.33399963378906
Projection step: 13, Loss: 265.5303039550781
Projection step: 14, Loss: 269.9681396484375
Final likelihood: tensor([-249.7723, -264.8931, -298.8083, -262.5389, -240.1482, -260.8687,
        -301.9208, -228.9261, -262.8788, -322.5678, -240.2540, -317.9045,
        -316.0520, -262.2998, -247.3795, -315.7868])
Final projection likelihood: -274.5625
1 mode projection failed, trying anyway
New goal: tensor([-0.1602,  0.3513,  1.1262,  1.0390, -0.2373, -0.0425,  1.0204,  1.1635,
         1.2367,  0.3590,  0.9217,  0.8821,  0.3828,  0.1691, -0.8350],
       device='cuda:1')
tensor([[0.0034]], device='cuda:1') tensor([[-0.0053]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -239.6223907470703
Adjusted likelihood: -239.6223907470703
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 239.6223907470703}
Current yaw: tensor([ 0.3820,  0.1694, -0.8628], device='cuda:1')
20 thumb_middle
tensor([-0.1526,  0.3494,  1.1349,  1.0063, -0.2321, -0.0420,  0.9883,  1.1506,
         1.2809,  0.3391,  0.9184,  0.8319,  0.3820,  0.1694, -0.8628,  1.8007],
       device='cuda:1')
Solve time for step 1 9.831756839004811
Current ori: tensor([ 0.3820,  0.1694, -0.8628], device='cuda:1')
Index force: tensor([0.5972, 0.6093, 0.5419, 0.5677], device='cuda:1')
tensor([-0.1882,  0.4175,  1.0704,  1.0342, -0.1674, -0.1960,  0.9210,  1.0816,
         1.2381,  0.3640,  0.8952,  0.8570,  0.4146,  0.2067, -0.8827,  1.0475],
       device='cuda:1')
Solve time for step 2 2.145385628013173
Current ori: tensor([ 0.4146,  0.2067, -0.8827], device='cuda:1')
Index force: tensor([0.6048, 0.5379, 0.5673], device='cuda:1')
tensor([-0.2525,  0.4734,  1.0021,  1.0431, -0.1703, -0.1960,  0.9119,  1.0644,
         1.2506,  0.3805,  0.8944,  0.8749,  0.4147,  0.2069, -0.8821, -0.7084],
       device='cuda:1')
Solve time for step 3 2.0812446309719235
Current ori: tensor([ 0.4147,  0.2069, -0.8821], device='cuda:1')
Index force: tensor([0.5366, 0.5617], device='cuda:1')
tensor([-0.2795,  0.4644,  1.0207,  1.0355, -0.1622, -0.1960,  0.9381,  1.0869,
         1.2496,  0.3933,  0.9058,  0.8833,  0.4147,  0.2068, -0.8821, -0.5970],
       device='cuda:1')
Solve time for step 4 2.012891023012344
Current ori: tensor([ 0.4147,  0.2068, -0.8821], device='cuda:1')
Index force: tensor([0.5258], device='cuda:1')
Storing RECOVERY transition: reward=0.0701 (scaled=0.0701), steps=1
Reward stats updated: mean -0.0050 -> -0.0047, std: 0.1610
Collected 235 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0909, Q2 Loss=1.0909, Entropy=0.0005, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2023
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9228, Q2 Loss=0.9228, Entropy=0.0893, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3166
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6474, Q2 Loss=0.6474, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4208
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9589, Q2 Loss=0.9589, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3390
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7855, Q2 Loss=0.7855, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2402

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.4%)
Q1 update: 0.07s (21.4%)
Q2 update: 0.06s (18.9%)
Actor update: 0.13s (41.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000009
Q1 loss: 0.881122
Q2 loss: 0.881122
Current threshold: -27.3480
Global Scale Offset: 0.3008
Reward stats: mean=-0.0047, std=0.1610, count=235
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8811, Q2 Loss: 0.8811, Entropy: 0.0180, Mean TD Error: 0.3038, Threshold: -27.3480
Original likelihood: -320.66754150390625
Adjusted likelihood: -320.66754150390625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 14
Loaded trajectory sampler
Current yaw: tensor([-0.0004,  0.0145, -0.0442], device='cuda:1')
Current yaw: tensor([-0.0004,  0.0145, -0.0442], device='cuda:1')
1 turn
Sampling time 3.9706541569903493
tensor([ 1.3509e-01,  6.1843e-01,  5.4356e-01,  6.0215e-01, -8.6250e-02,
         5.0129e-01,  9.1077e-01,  8.6877e-01,  1.2605e+00,  2.8317e-01,
         2.2530e-01,  1.1659e+00, -4.4170e-04,  1.4527e-02, -4.4158e-02,
         2.1041e-01], device='cuda:1')
Original likelihood: -16.055561065673828
Adjusted likelihood: -16.055561065673828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.643501943006413
Current ori: tensor([-0.0004,  0.0145, -0.0442], device='cuda:1')
Middle force: tensor([0.9676, 0.5356, 0.5081, 0.5255, 1.5408, 0.5989, 0.5551, 0.5456, 0.5304,
        1.1772, 1.4447, 0.5380], device='cuda:1')
Thumb force: tensor([1.4270, 1.5256, 2.1695, 0.5852, 1.3198, 0.6674, 0.8305, 0.9586, 1.2663,
        1.4615, 0.6521, 0.8752], device='cuda:1')
Index force: tensor([1.6393, 0.5972, 0.6288, 0.5257, 0.8825, 0.6020, 0.5693, 0.5178, 0.6610,
        0.6108, 0.5429, 0.5626], device='cuda:1')
Storing NORMAL transition: reward=0.1974 (scaled=0.1974), steps=1
Reward stats updated: mean -0.0047 -> -0.0038, std: 0.1612
Collected 236 transitions for RL
SAC Update 1/5: Actor Loss=-0.0020, Q1 Loss=1.1507, Q2 Loss=1.1507, Entropy=0.2950, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1550
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=1.4180, Q2 Loss=1.4180, Entropy=0.2253, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6202
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4260, Q2 Loss=1.4260, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6224
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8707, Q2 Loss=0.8707, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2580
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.5128, Q2 Loss=1.5128, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3779

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.2%)
Actor update: 0.13s (41.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000435
Q1 loss: 1.275630
Q2 loss: 1.275630
Current threshold: -27.3224
Global Scale Offset: 0.2997
Reward stats: mean=-0.0038, std=0.1612, count=236
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.2756, Q2 Loss: 1.2756, Entropy: 0.1041, Mean TD Error: 1.2067, Threshold: -27.3224
tensor([ 0.1414,  0.5290,  0.6510,  0.6446, -0.0602,  0.4187,  0.9396,  0.9934,
         1.3403,  0.2380,  0.2157,  1.0256,  0.0160,  0.0037, -0.2418,  0.6806],
       device='cuda:1')
Original likelihood: -14.308124542236328
Adjusted likelihood: -14.308124542236328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.1988646169775166
Current ori: tensor([ 0.0160,  0.0037, -0.2418], device='cuda:1')
Middle force: tensor([0.5335, 0.5080, 0.5268, 1.5323, 0.6003, 0.5573, 0.5485, 0.5268, 1.1668,
        1.4305, 0.5364], device='cuda:1')
Thumb force: tensor([1.5126, 2.1480, 0.5786, 1.3005, 0.6608, 0.8163, 0.9391, 1.2573, 1.4497,
        0.6499, 0.8718], device='cuda:1')
Index force: tensor([0.5931, 0.6243, 0.5248, 0.8810, 0.5998, 0.5681, 0.5173, 0.6663, 0.6092,
        0.5423, 0.5618], device='cuda:1')
Storing NORMAL transition: reward=0.1105 (scaled=0.1105), steps=1
Reward stats updated: mean -0.0038 -> -0.0033, std: 0.1610
Collected 237 transitions for RL
SAC Update 1/5: Actor Loss=-0.0034, Q1 Loss=0.7935, Q2 Loss=0.7935, Entropy=0.0710, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2089
SAC Update 2/5: Actor Loss=-0.0037, Q1 Loss=1.1704, Q2 Loss=1.1704, Entropy=0.0204, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6538
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7715, Q2 Loss=0.7715, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2098
SAC Update 4/5: Actor Loss=-0.0149, Q1 Loss=1.2184, Q2 Loss=1.2184, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8585
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9392, Q2 Loss=0.9392, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2870

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.2%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (20.7%)
Actor update: 0.13s (42.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004414
Q1 loss: 0.978615
Q2 loss: 0.978615
Current threshold: -27.2558
Global Scale Offset: 0.2892
Reward stats: mean=-0.0033, std=0.1610, count=237
----------------------------------------------
SAC Update - Actor Loss: -0.0044, Q1 Loss: 0.9786, Q2 Loss: 0.9786, Entropy: 0.0183, Mean TD Error: 0.4436, Threshold: -27.2558
tensor([ 0.1429,  0.5625,  0.6035,  0.5623, -0.0087,  0.3455,  0.9451,  1.1517,
         1.4078,  0.0940,  0.2073,  1.0075,  0.0439, -0.0106, -0.3566,  1.9222],
       device='cuda:1')
Original likelihood: -25.470508575439453
Adjusted likelihood: -25.470508575439453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9926)
Solve time for step 3 2.995468578010332
Current ori: tensor([ 0.0439, -0.0106, -0.3566], device='cuda:1')
Middle force: tensor([0.5078, 0.5285, 1.5332, 0.5968, 0.5577, 0.5489, 0.5272, 1.1582, 1.4143,
        0.5377], device='cuda:1')
Thumb force: tensor([2.1224, 0.5676, 1.2619, 0.6576, 0.8051, 0.9279, 1.2369, 1.4380, 0.6495,
        0.8588], device='cuda:1')
Index force: tensor([0.6210, 0.5256, 0.8873, 0.5998, 0.5674, 0.5169, 0.6665, 0.6072, 0.5417,
        0.5606], device='cuda:1')
Storing NORMAL transition: reward=0.0033 (scaled=0.0033), steps=1
Reward stats updated: mean -0.0033 -> -0.0033, std: 0.1607
Collected 238 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.1291, Q2 Loss=2.1291, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0576
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2415, Q2 Loss=1.2415, Entropy=0.0218, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9605
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1604, Q2 Loss=1.1604, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6012
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9892, Q2 Loss=0.9892, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8392
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.4480, Q2 Loss=3.4480, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3727

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (20.3%)
Actor update: 0.12s (44.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.793635
Q2 loss: 1.793635
Current threshold: -27.1964
Global Scale Offset: 0.2770
Reward stats: mean=-0.0033, std=0.1607, count=238
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.7936, Q2 Loss: 1.7936, Entropy: 0.0044, Mean TD Error: 3.3662, Threshold: -27.1964
tensor([ 0.1002,  0.5997,  0.6147,  0.4359,  0.1382,  0.1959,  0.9478,  1.0802,
         1.2442,  0.3748,  0.2665,  0.9446,  0.0305, -0.0027, -0.3574,  1.9090],
       device='cuda:1')
Original likelihood: -41.9794921875
Adjusted likelihood: -41.9794921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 36.28504180908203
Projection step: 1, Loss: 38.49715805053711
Projection step: 2, Loss: 28.88622283935547
Projection step: 3, Loss: 25.82175064086914
Projection step: 4, Loss: 25.180044174194336
Projection step: 5, Loss: 23.8853759765625
Projection step: 6, Loss: 21.26653480529785
Projection step: 7, Loss: 20.220394134521484
Projection step: 8, Loss: 17.86832046508789
Projection step: 9, Loss: 18.666934967041016
Projection step: 10, Loss: 18.177444458007812
Projection step: 11, Loss: 17.38372039794922
Projection step: 12, Loss: 15.391088485717773
Projection step: 13, Loss: 15.558292388916016
Projection step: 14, Loss: 13.877918243408203
Final likelihood: tensor([-11.6498, -16.7319, -15.4856,  -8.7591, -15.7804, -16.0429, -18.7417,
        -16.1126, -12.2099, -13.6475, -11.8797, -12.9964, -12.8253, -16.1416,
        -11.2012, -11.8413])
Final projection likelihood: -13.8779
1 mode projection succeeded
New goal: tensor([ 0.0850,  0.5694,  0.6106,  0.6310, -0.0236,  0.4190,  0.8395,  0.9182,
         1.2534,  0.3156,  0.1818,  1.1435,  0.0268,  0.0057,  0.0974],
       device='cuda:1')
tensor([[0.0071]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -18.32150650024414
Adjusted likelihood: -18.32150650024414
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.32150650024414}
Current yaw: tensor([ 0.0305, -0.0027, -0.3574], device='cuda:1')
2 thumb_middle
tensor([ 0.1002,  0.5997,  0.6147,  0.4359,  0.1382,  0.1959,  0.9478,  1.0802,
         1.2442,  0.3748,  0.2665,  0.9446,  0.0305, -0.0027, -0.3574,  1.9090],
       device='cuda:1')
Solve time for step 1 9.52255988001707
Current ori: tensor([ 0.0305, -0.0027, -0.3574], device='cuda:1')
Index force: tensor([0.5821, 0.6227, 0.5032, 0.6093], device='cuda:1')
tensor([ 1.0583e-01,  5.4463e-01,  6.1252e-01,  5.9541e-01, -6.8388e-02,
         3.6575e-01,  8.3685e-01,  9.3459e-01,  1.2253e+00,  3.2106e-01,
         1.5806e-01,  1.0891e+00,  5.5862e-02,  1.7547e-03, -3.5736e-01,
         1.9886e+00], device='cuda:1')
Solve time for step 2 1.999526330997469
Current ori: tensor([ 0.0559,  0.0018, -0.3574], device='cuda:1')
Index force: tensor([0.6142, 0.5012, 0.6048], device='cuda:1')
tensor([ 0.1118,  0.5030,  0.6317,  0.6801, -0.0928,  0.4212,  0.8276,  0.9085,
         1.2409,  0.3103,  0.1406,  1.1210,  0.0732,  0.0031, -0.3574,  2.0339],
       device='cuda:1')
Solve time for step 3 1.9194116290018428
Current ori: tensor([ 0.0732,  0.0031, -0.3574], device='cuda:1')
Index force: tensor([0.5010, 0.5976], device='cuda:1')
tensor([ 1.1545e-01,  5.1659e-01,  6.2502e-01,  6.6312e-01, -1.0531e-01,
         4.3307e-01,  8.2519e-01,  9.0861e-01,  1.2449e+00,  3.0671e-01,
         1.3285e-01,  1.1325e+00,  6.8490e-02,  3.5428e-04, -3.5736e-01,
         2.0332e+00], device='cuda:1')
Solve time for step 4 1.865011375019094
Current ori: tensor([ 6.8490e-02,  3.5428e-04, -3.5736e-01], device='cuda:1')
Index force: tensor([0.5842], device='cuda:1')
Storing RECOVERY transition: reward=-0.0058 (scaled=-0.0019), steps=3
Reward stats updated: mean -0.0033 -> -0.0033, std: 0.1604
Collected 239 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=1.2652, Q2 Loss=1.2652, Entropy=0.3298, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5278
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1063, Q2 Loss=1.1063, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4175
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6355, Q2 Loss=0.6355, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6400
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6510, Q2 Loss=0.6510, Entropy=0.0054, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0944
SAC Update 5/5: Actor Loss=-0.0229, Q1 Loss=1.5102, Q2 Loss=1.5102, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6849

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.3%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004779
Q1 loss: 1.033627
Q2 loss: 1.033627
Current threshold: -27.1502
Global Scale Offset: 0.2693
Reward stats: mean=-0.0033, std=0.1604, count=239
----------------------------------------------
SAC Update - Actor Loss: -0.0048, Q1 Loss: 1.0336, Q2 Loss: 1.0336, Entropy: 0.0670, Mean TD Error: 0.8729, Threshold: -27.1502
Original likelihood: -19.488079071044922
Adjusted likelihood: -19.488079071044922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0565,  0.0040, -0.3568], device='cuda:1')
3 turn
Sampling time 3.725384412013227
tensor([ 0.0894,  0.5534,  0.5837,  0.5955, -0.0485,  0.4835,  0.8634,  0.9247,
         1.2973,  0.3227,  0.1879,  1.1677,  0.0565,  0.0040, -0.3568,  2.1326],
       device='cuda:1')
Original likelihood: -17.285831451416016
Adjusted likelihood: -17.285831451416016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.404585356998723
Current ori: tensor([ 0.0565,  0.0040, -0.3568], device='cuda:1')
Middle force: tensor([0.5677, 1.6589, 0.5232, 0.5239, 0.6281, 1.6088, 0.5650, 0.5515, 0.5384,
        0.5423, 0.5532, 0.5822], device='cuda:1')
Thumb force: tensor([0.7560, 0.9574, 0.4962, 0.9134, 0.8382, 1.0570, 0.7468, 0.5238, 0.9911,
        0.8630, 0.5983, 0.5924], device='cuda:1')
Index force: tensor([0.5186, 0.7137, 0.8041, 0.5968, 0.5076, 0.5054, 0.5131, 0.5868, 0.5245,
        0.5639, 0.6500, 0.6751], device='cuda:1')
Storing NORMAL transition: reward=0.1942 (scaled=0.1942), steps=1
Reward stats updated: mean -0.0033 -> -0.0025, std: 0.1605
Collected 240 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7483, Q2 Loss=0.7483, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9126
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.4174, Q2 Loss=2.4174, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1286
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.9948, Q2 Loss=0.9948, Entropy=0.2330, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6278
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.5044, Q2 Loss=1.5044, Entropy=0.0006, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9203
SAC Update 5/5: Actor Loss=-0.0219, Q1 Loss=1.2823, Q2 Loss=1.2823, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5466

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.7%)
Actor update: 0.10s (43.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004427
Q1 loss: 1.389461
Q2 loss: 1.389461
Current threshold: -27.1153
Global Scale Offset: 0.2632
Reward stats: mean=-0.0025, std=0.1605, count=240
----------------------------------------------
SAC Update - Actor Loss: -0.0044, Q1 Loss: 1.3895, Q2 Loss: 1.3895, Entropy: 0.0467, Mean TD Error: 2.4272, Threshold: -27.1153
tensor([ 0.1785,  0.6572,  0.4945,  0.4799, -0.0552,  0.4864,  0.8375,  1.1154,
         1.3301,  0.3382,  0.2320,  1.0176,  0.0708, -0.0099, -0.5558,  3.5544],
       device='cuda:1')
Original likelihood: -28.5053768157959
Adjusted likelihood: -28.5053768157959
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0208)
State is out of distribution
Projection step: 0, Loss: 29.363008499145508
Projection step: 1, Loss: 26.766603469848633
Projection step: 2, Loss: 25.40517807006836
Projection step: 3, Loss: 24.237346649169922
Projection step: 4, Loss: 23.864978790283203
Projection step: 5, Loss: 22.746246337890625
Projection step: 6, Loss: 22.959068298339844
Projection step: 7, Loss: 22.426589965820312
Projection step: 8, Loss: 20.982410430908203
Projection step: 9, Loss: 21.396881103515625
Projection step: 10, Loss: 20.397056579589844
Projection step: 11, Loss: 19.482532501220703
Projection step: 12, Loss: 19.926239013671875
Projection step: 13, Loss: 19.715839385986328
Projection step: 14, Loss: 18.29354476928711
Final likelihood: tensor([-16.6034, -18.3284, -17.0056, -18.8663, -17.7539, -15.6454, -17.5200,
        -17.6430, -17.9550, -17.8076, -17.8709, -18.9159, -19.2049, -16.7530,
        -19.6013, -17.6555])
Final projection likelihood: -17.8206
1 mode projection succeeded
New goal: tensor([ 0.0884,  0.5692,  0.5848,  0.5872, -0.0597,  0.4667,  0.8891,  0.9447,
         1.2819,  0.3125,  0.1970,  1.1611,  0.0545, -0.0066, -1.5176],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0039]], device='cuda:1')
Original likelihood: -25.516244888305664
Adjusted likelihood: -25.516244888305664
Likelihood residual: 0.0
{'index': 25.516244888305664, 'thumb_middle': inf}
Current yaw: tensor([ 0.0708, -0.0099, -0.5558], device='cuda:1')
4 index
tensor([ 0.1785,  0.6572,  0.4945,  0.4799, -0.0552,  0.4864,  0.8375,  1.1154,
         1.3301,  0.3382,  0.2320,  1.0176,  0.0708, -0.0099, -0.5558,  3.5544],
       device='cuda:1')
Solve time for step 1 10.899950845021522
Current ori: tensor([ 0.0708, -0.0099, -0.5558], device='cuda:1')
Middle force: tensor([0.5185, 0.5329, 0.5791, 0.5028], device='cuda:1')
Thumb force: tensor([0.5023, 0.5231, 0.6037, 0.5333], device='cuda:1')
tensor([ 0.1676,  0.5249,  0.5202,  0.5449, -0.0317,  0.4656,  0.9200,  1.0272,
         1.3380,  0.3141,  0.1925,  1.0498,  0.0692, -0.0244, -0.5592,  4.6151],
       device='cuda:1')
Solve time for step 2 2.2873769070138223
Current ori: tensor([ 0.0692, -0.0244, -0.5592], device='cuda:1')
Middle force: tensor([0.5316, 0.5774, 0.5025], device='cuda:1')
Thumb force: tensor([0.5215, 0.6020, 0.5321], device='cuda:1')
tensor([ 0.1632,  0.5324,  0.5329,  0.5598, -0.0200,  0.4671,  0.9389,  1.0053,
         1.3469,  0.2941,  0.1693,  1.0660,  0.0691, -0.0322, -0.5689,  5.4578],
       device='cuda:1')
Solve time for step 3 2.2216948290006258
Current ori: tensor([ 0.0691, -0.0322, -0.5689], device='cuda:1')
Middle force: tensor([0.5744, 0.5020], device='cuda:1')
Thumb force: tensor([0.5970, 0.5308], device='cuda:1')
tensor([ 0.1634,  0.5343,  0.5425,  0.5634, -0.0304,  0.4826,  0.9387,  0.9915,
         1.3481,  0.2984,  0.1765,  1.0465,  0.0679, -0.0319, -0.6002,  5.8864],
       device='cuda:1')
Solve time for step 4 2.1585928929853253
Current ori: tensor([ 0.0679, -0.0319, -0.6002], device='cuda:1')
Middle force: tensor([0.5015], device='cuda:1')
Thumb force: tensor([0.5281], device='cuda:1')
Storing RECOVERY transition: reward=0.0297 (scaled=0.0297), steps=1
Reward stats updated: mean -0.0025 -> -0.0023, std: 0.1602
Collected 241 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6793, Q2 Loss=0.6793, Entropy=0.0506, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2706
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2736, Q2 Loss=1.2736, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4991
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6768, Q2 Loss=0.6768, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8516
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7642, Q2 Loss=0.7642, Entropy=0.0007, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4518
SAC Update 5/5: Actor Loss=-0.0068, Q1 Loss=2.6951, Q2 Loss=2.6951, Entropy=0.0044, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1945

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (21.2%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (17.5%)
Actor update: 0.08s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001360
Q1 loss: 1.217791
Q2 loss: 1.217791
Current threshold: -27.0863
Global Scale Offset: 0.2586
Reward stats: mean=-0.0023, std=0.1602, count=241
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 1.2178, Q2 Loss: 1.2178, Entropy: 0.0111, Mean TD Error: 1.4535, Threshold: -27.0863
Original likelihood: -25.2041015625
Adjusted likelihood: -25.2041015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9974)
Current yaw: tensor([ 0.0704, -0.0320, -0.5877], device='cuda:1')
5 turn
Sampling time 3.8004225059994496
tensor([ 0.1159,  0.5793,  0.5747,  0.5816, -0.0305,  0.4914,  0.9347,  0.9790,
         1.3440,  0.3019,  0.1747,  1.0602,  0.0704, -0.0320, -0.5877,  5.8717],
       device='cuda:1')
Original likelihood: -25.619110107421875
Adjusted likelihood: -25.619110107421875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9853)
Solve time for step 1 14.267257027997402
Current ori: tensor([ 0.0704, -0.0320, -0.5877], device='cuda:1')
Middle force: tensor([0.5306, 0.9619, 0.5451, 0.5390, 0.8068, 1.2256, 0.5607, 0.6093, 0.6241,
        0.5133, 0.5589, 0.4933], device='cuda:1')
Thumb force: tensor([0.9796, 1.0596, 0.5991, 0.5926, 0.5414, 0.5302, 0.5856, 0.5182, 0.5947,
        0.7745, 0.8681, 0.5230], device='cuda:1')
Index force: tensor([0.6877, 1.2818, 0.5993, 0.5660, 0.8380, 0.7415, 0.5612, 0.5271, 0.6132,
        0.5208, 0.6422, 0.6683], device='cuda:1')
Storing NORMAL transition: reward=-0.0004 (scaled=-0.0004), steps=1
Reward stats updated: mean -0.0023 -> -0.0023, std: 0.1599
Collected 242 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.2442, Q2 Loss=1.2442, Entropy=0.1195, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9075
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0133, Q2 Loss=1.0133, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3926
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6473, Q2 Loss=0.6473, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8260
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0233, Q2 Loss=1.0233, Entropy=0.0264, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3602
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7532, Q2 Loss=0.7532, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5040

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.06s (20.8%)
Actor update: 0.11s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000015
Q1 loss: 0.936265
Q2 loss: 0.936265
Current threshold: -27.0447
Global Scale Offset: 0.2529
Reward stats: mean=-0.0023, std=0.1599, count=242
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9363, Q2 Loss: 0.9363, Entropy: 0.0292, Mean TD Error: 1.5981, Threshold: -27.0447
tensor([ 0.1096,  0.5511,  0.5921,  0.6114, -0.0838,  0.4918,  1.0009,  0.9595,
         1.3438,  0.2256,  0.1893,  0.9372,  0.0794, -0.0262, -0.5883,  5.8908],
       device='cuda:1')
Original likelihood: -27.950790405273438
Adjusted likelihood: -27.950790405273438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0855)
State is out of distribution
Projection step: 0, Loss: 27.320280075073242
Projection step: 1, Loss: 25.736915588378906
Projection step: 2, Loss: 24.589231491088867
Projection step: 3, Loss: 23.59195899963379
Projection step: 4, Loss: 22.459205627441406
Projection step: 5, Loss: 22.509056091308594
Projection step: 6, Loss: 22.188669204711914
Projection step: 7, Loss: 21.245441436767578
Projection step: 8, Loss: 21.247844696044922
Projection step: 9, Loss: 21.27355194091797
Projection step: 10, Loss: 22.960214614868164
Projection step: 11, Loss: 20.70999526977539
Projection step: 12, Loss: 20.94852066040039
Projection step: 13, Loss: 20.899513244628906
Projection step: 14, Loss: 20.35503387451172
Final likelihood: tensor([-22.3516, -19.3770, -20.2947, -18.5048, -19.8457, -19.6431, -18.5508,
        -20.1856, -18.7952, -18.5875, -22.2202, -17.6974, -21.6084, -19.9838,
        -19.4486, -19.0338])
Final projection likelihood: -19.7580
1 mode projection succeeded
New goal: tensor([ 0.0813,  0.5315,  0.6216,  0.6040, -0.0511,  0.4907,  0.9219,  0.9136,
         1.3024,  0.2185,  0.2040,  1.2010,  0.0658, -0.0194, -1.0064],
       device='cuda:1')
tensor([[0.0097]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -24.83251190185547
Adjusted likelihood: -24.83251190185547
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 24.83251190185547}
Current yaw: tensor([ 0.0794, -0.0262, -0.5883], device='cuda:1')
6 thumb_middle
tensor([ 0.1096,  0.5511,  0.5921,  0.6114, -0.0838,  0.4918,  1.0009,  0.9595,
         1.3438,  0.2256,  0.1893,  0.9372,  0.0794, -0.0262, -0.5883,  5.8908],
       device='cuda:1')
Solve time for step 1 9.827211175987031
Current ori: tensor([ 0.0794, -0.0262, -0.5883], device='cuda:1')
Index force: tensor([0.5903, 0.5741, 0.5913, 0.6042], device='cuda:1')
tensor([ 0.1067,  0.5367,  0.6149,  0.5964, -0.1409,  0.4874,  0.8954,  0.8926,
         1.2590,  0.1924,  0.1319,  1.1189,  0.0820, -0.0234, -0.5883,  5.9206],
       device='cuda:1')
Solve time for step 2 2.127660983009264
Current ori: tensor([ 0.0820, -0.0234, -0.5883], device='cuda:1')
Index force: tensor([0.5703, 0.5886, 0.6026], device='cuda:1')
tensor([ 0.0987,  0.5316,  0.6206,  0.5845, -0.1492,  0.5086,  0.8845,  0.8845,
         1.2564,  0.1904,  0.1177,  1.1591,  0.0814, -0.0203, -0.5883,  5.8990],
       device='cuda:1')
Solve time for step 3 1.9679553649912123
Current ori: tensor([ 0.0814, -0.0203, -0.5883], device='cuda:1')
Index force: tensor([0.5846, 0.6000], device='cuda:1')
tensor([ 0.0915,  0.5172,  0.6290,  0.5923, -0.1531,  0.5158,  0.8807,  0.8776,
         1.2593,  0.1915,  0.1170,  1.1676,  0.0853, -0.0161, -0.5883,  5.8994],
       device='cuda:1')
Solve time for step 4 1.7026123690011445
Current ori: tensor([ 0.0853, -0.0161, -0.5883], device='cuda:1')
Index force: tensor([0.5794], device='cuda:1')
Storing RECOVERY transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean -0.0023 -> -0.0023, std: 0.1595
Collected 243 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7315, Q2 Loss=0.7315, Entropy=0.0005, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1572
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1530, Q2 Loss=1.1530, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4405
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6847, Q2 Loss=0.6847, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5315
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1270, Q2 Loss=1.1270, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7338
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2454, Q2 Loss=1.2454, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8067

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.11s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.988308
Q2 loss: 0.988308
Current threshold: -27.0199
Global Scale Offset: 0.2495
Reward stats: mean=-0.0023, std=0.1595, count=243
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9883, Q2 Loss: 0.9883, Entropy: 0.0001, Mean TD Error: 0.5339, Threshold: -27.0199
Original likelihood: -25.42196273803711
Adjusted likelihood: -25.42196273803711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9926)
Current yaw: tensor([ 0.0820, -0.0132, -0.5900], device='cuda:1')
7 turn
Sampling time 4.00518005999038
tensor([ 0.0793,  0.5315,  0.6014,  0.5848, -0.0929,  0.5576,  0.9230,  0.9057,
         1.3210,  0.2103,  0.1788,  1.2077,  0.0820, -0.0132, -0.5900,  5.8493],
       device='cuda:1')
Original likelihood: -24.94951629638672
Adjusted likelihood: -24.94951629638672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9992)
Solve time for step 1 14.447496609005611
Current ori: tensor([ 0.0820, -0.0132, -0.5900], device='cuda:1')
Middle force: tensor([0.5286, 0.9275, 0.5444, 0.5294, 0.8663, 1.3205, 0.5787, 0.5742, 0.6316,
        0.6112, 0.6210, 0.5394], device='cuda:1')
Thumb force: tensor([1.1944, 0.9598, 0.6027, 0.5862, 0.5470, 0.5266, 0.5935, 0.5502, 0.5638,
        0.5981, 0.5681, 0.7770], device='cuda:1')
Index force: tensor([0.6895, 1.1625, 0.5969, 0.5414, 0.8797, 0.7893, 0.5568, 0.5486, 0.5552,
        0.5962, 0.5848, 0.5129], device='cuda:1')
Storing NORMAL transition: reward=0.0305 (scaled=0.0305), steps=1
Reward stats updated: mean -0.0023 -> -0.0022, std: 0.1592
Collected 244 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6397, Q2 Loss=0.6397, Entropy=0.0416, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0462
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6763, Q2 Loss=0.6763, Entropy=0.0032, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2663
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0076, Q2 Loss=1.0076, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3664
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0055, Q2 Loss=1.0055, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3872
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8929, Q2 Loss=0.8929, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2762

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.844410
Q2 loss: 0.844410
Current threshold: -27.0052
Global Scale Offset: 0.2476
Reward stats: mean=-0.0022, std=0.1592, count=244
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8444, Q2 Loss: 0.8444, Entropy: 0.0090, Mean TD Error: 0.6685, Threshold: -27.0052
tensor([ 0.2195,  0.5954,  0.5634,  0.5505, -0.1712,  0.5151,  0.8969,  0.9425,
         1.4687,  0.0493,  0.2304,  1.1171,  0.0948,  0.0408, -0.6247, -5.3459],
       device='cuda:1')
Original likelihood: -32.598670959472656
Adjusted likelihood: -32.598670959472656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.164974212646484
Projection step: 1, Loss: 33.6643180847168
Projection step: 2, Loss: 32.89280319213867
Projection step: 3, Loss: 32.853668212890625
Projection step: 4, Loss: 31.034317016601562
Projection step: 5, Loss: 31.676076889038086
Projection step: 6, Loss: 32.0306510925293
Projection step: 7, Loss: 31.11552619934082
Projection step: 8, Loss: 29.508859634399414
Projection step: 9, Loss: 30.516695022583008
Projection step: 10, Loss: 29.608888626098633
Projection step: 11, Loss: 30.441463470458984
Projection step: 12, Loss: 29.55437660217285
Projection step: 13, Loss: 28.318119049072266
Projection step: 14, Loss: 28.674816131591797
Final likelihood: tensor([-26.5377, -27.7117, -28.2266, -29.5669, -28.4103, -26.6633, -33.2022,
        -32.0108, -25.9787, -32.9037, -26.7313, -31.1198, -28.4968, -27.6919,
        -32.7828, -28.4360])
Final projection likelihood: -29.1544
1 mode projection failed, trying anyway
New goal: tensor([ 0.1361,  0.6326,  0.5571,  0.4944, -0.1359,  0.5358,  0.8879,  0.8722,
         1.4402,  0.0573,  0.2636,  1.1763,  0.0790,  0.0342,  0.1220],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0064]], device='cuda:1')
Original likelihood: -30.384559631347656
Adjusted likelihood: -30.384559631347656
Likelihood residual: 0.0
{'index': 30.384559631347656, 'thumb_middle': inf}
Current yaw: tensor([ 0.0948,  0.0408, -0.6247], device='cuda:1')
8 index
tensor([ 0.2195,  0.5954,  0.5634,  0.5505, -0.1712,  0.5151,  0.8969,  0.9425,
         1.4687,  0.0493,  0.2304,  1.1171,  0.0948,  0.0408, -0.6247, -5.3459],
       device='cuda:1')
Solve time for step 1 10.801540533982916
Current ori: tensor([ 0.0948,  0.0408, -0.6247], device='cuda:1')
Middle force: tensor([0.5207, 0.5978, 0.5387, 0.5509], device='cuda:1')
Thumb force: tensor([0.6191, 0.5461, 0.5455, 0.5506], device='cuda:1')
tensor([ 0.1982,  0.4704,  0.5398,  0.5193, -0.1690,  0.5137,  0.9091,  0.9151,
         1.4758,  0.0529,  0.2155,  1.1117,  0.0917,  0.0404, -0.6146, -5.0357],
       device='cuda:1')
Solve time for step 2 2.3030298400262836
Current ori: tensor([ 0.0917,  0.0404, -0.6146], device='cuda:1')
Middle force: tensor([0.5929, 0.5370, 0.5489], device='cuda:1')
Thumb force: tensor([0.5448, 0.5445, 0.5489], device='cuda:1')
tensor([ 0.1786,  0.4932,  0.5411,  0.5184, -0.1536,  0.5441,  0.8893,  0.8774,
         1.4700,  0.0554,  0.2068,  1.0920,  0.0778,  0.0336, -0.6104, -5.3454],
       device='cuda:1')
Solve time for step 3 2.2005931489984505
Current ori: tensor([ 0.0778,  0.0336, -0.6104], device='cuda:1')
Middle force: tensor([0.5364, 0.5472], device='cuda:1')
Thumb force: tensor([0.5412, 0.5471], device='cuda:1')
tensor([ 0.1724,  0.4993,  0.5428,  0.5118, -0.1499,  0.5479,  0.8873,  0.8715,
         1.4739,  0.0489,  0.2032,  1.0816,  0.0737,  0.0313, -0.6235, -5.9145],
       device='cuda:1')
Solve time for step 4 2.1215260830067564
Current ori: tensor([ 0.0737,  0.0313, -0.6235], device='cuda:1')
Middle force: tensor([0.5432], device='cuda:1')
Thumb force: tensor([0.5420], device='cuda:1')
Storing RECOVERY transition: reward=0.0292 (scaled=0.0292), steps=1
Reward stats updated: mean -0.0022 -> -0.0021, std: 0.1589
Collected 245 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1910, Q2 Loss=1.1910, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4928
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7906, Q2 Loss=0.7906, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1924
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6649, Q2 Loss=0.6649, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2301
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1906, Q2 Loss=1.1906, Entropy=0.0011, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1865
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1037, Q2 Loss=1.1037, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7110

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.988155
Q2 loss: 0.988155
Current threshold: -26.9965
Global Scale Offset: 0.2464
Reward stats: mean=-0.0021, std=0.1589, count=245
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9882, Q2 Loss: 0.9882, Entropy: 0.0002, Mean TD Error: 0.3626, Threshold: -26.9965
Original likelihood: -30.897226333618164
Adjusted likelihood: -30.897226333618164
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 31.046672821044922
Projection step: 1, Loss: 29.887676239013672
Projection step: 2, Loss: 29.55836296081543
Projection step: 3, Loss: 28.17456817626953
Projection step: 4, Loss: 28.90264129638672
Projection step: 5, Loss: 27.36785125732422
Projection step: 6, Loss: 27.49718475341797
Projection step: 7, Loss: 27.009517669677734
Projection step: 8, Loss: 27.495407104492188
Projection step: 9, Loss: 25.948877334594727
Projection step: 10, Loss: 25.835102081298828
Projection step: 11, Loss: 25.119869232177734
Projection step: 12, Loss: 25.36640167236328
Projection step: 13, Loss: 23.374217987060547
Projection step: 14, Loss: 23.82964515686035
Final likelihood: tensor([-23.1505, -22.5572, -22.4182, -21.2099, -20.1448, -21.7950, -20.3831,
        -22.1152, -23.8424, -20.7511, -21.2628, -21.1940, -24.5394, -22.5892,
        -23.8637, -22.9416])
Final projection likelihood: -22.1724
1 mode projection succeeded
New goal: tensor([ 0.0785,  0.6263,  0.5266,  0.5029, -0.1083,  0.5213,  0.8666,  0.8668,
         1.4165,  0.0914,  0.2356,  1.1842,  0.0650,  0.0223, -0.3573],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -27.90259552001953
Adjusted likelihood: -27.90259552001953
Likelihood residual: 0.0
Original likelihood: -28.056346893310547
Adjusted likelihood: -28.056346893310547
Likelihood residual: 0.0
{'index': 28.056346893310547, 'thumb_middle': 27.90259552001953}
Current yaw: tensor([ 0.0828,  0.0327, -0.6517], device='cuda:1')
9 thumb_middle
tensor([ 0.1276,  0.6202,  0.5701,  0.5081, -0.1600,  0.5402,  0.9021,  0.8871,
         1.4782,  0.0538,  0.1958,  1.1005,  0.0828,  0.0327, -0.6517, -6.1538],
       device='cuda:1')
Solve time for step 1 9.303579552011797
Current ori: tensor([ 0.0828,  0.0327, -0.6517], device='cuda:1')
Index force: tensor([0.5482, 0.5000, 0.5000, 0.5816], device='cuda:1')
tensor([ 0.1231,  0.6179,  0.5601,  0.5192, -0.2236,  0.5289,  0.8199,  0.8302,
         1.3629,  0.0458,  0.1698,  1.1565,  0.0854,  0.0360, -0.6517, -6.1873],
       device='cuda:1')
Solve time for step 2 2.0116510649968404
Current ori: tensor([ 0.0854,  0.0360, -0.6517], device='cuda:1')
Index force: tensor([0.5000, 0.5000, 0.5768], device='cuda:1')
tensor([ 0.1203,  0.6211,  0.5536,  0.5170, -0.2233,  0.5347,  0.8170,  0.8362,
         1.3754,  0.0312,  0.1577,  1.1669,  0.0846,  0.0370, -0.6517, -6.1930],
       device='cuda:1')
Solve time for step 3 1.950264465995133
Current ori: tensor([ 0.0846,  0.0370, -0.6517], device='cuda:1')
Index force: tensor([0.5000, 0.5712], device='cuda:1')
tensor([ 0.1176,  0.6351,  0.5374,  0.5036, -0.2271,  0.5424,  0.8171,  0.8334,
         1.3662,  0.0453,  0.1588,  1.1659,  0.0810,  0.0388, -0.6517, -6.1735],
       device='cuda:1')
Solve time for step 4 1.8602931500063278
Current ori: tensor([ 0.0810,  0.0388, -0.6517], device='cuda:1')
Index force: tensor([0.5604], device='cuda:1')
Storing RECOVERY transition: reward=0.0210 (scaled=0.0210), steps=1
Reward stats updated: mean -0.0021 -> -0.0020, std: 0.1586
Collected 246 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=0.7343, Q2 Loss=0.7343, Entropy=0.1278, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3195
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.0187, Q2 Loss=2.0187, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0998
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0934, Q2 Loss=1.0934, Entropy=0.0092, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5036
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5396, Q2 Loss=1.5396, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9835
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7074, Q2 Loss=0.7074, Entropy=0.0008, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3489

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004607
Q1 loss: 1.218678
Q2 loss: 1.218678
Current threshold: -26.9915
Global Scale Offset: 0.2457
Reward stats: mean=-0.0020, std=0.1586, count=246
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.2187, Q2 Loss: 1.2187, Entropy: 0.0276, Mean TD Error: 2.2511, Threshold: -26.9915
Original likelihood: -29.186378479003906
Adjusted likelihood: -29.186378479003906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0004)
State is out of distribution
Projection step: 0, Loss: 29.041805267333984
Projection step: 1, Loss: 27.59131622314453
Projection step: 2, Loss: 26.781715393066406
Projection step: 3, Loss: 27.029531478881836
Projection step: 4, Loss: 26.73186492919922
Projection step: 5, Loss: 26.56683349609375
Projection step: 6, Loss: 26.68939208984375
Projection step: 7, Loss: 25.938241958618164
Projection step: 8, Loss: 26.291095733642578
Projection step: 9, Loss: 25.726680755615234
Projection step: 10, Loss: 25.0172119140625
Projection step: 11, Loss: 24.496726989746094
Projection step: 12, Loss: 24.22617530822754
Projection step: 13, Loss: 24.937129974365234
Projection step: 14, Loss: 24.925365447998047
Final likelihood: tensor([-24.2341, -25.0738, -20.6828, -25.0607, -25.7988, -21.5981, -23.6692,
        -20.7591, -20.3331, -22.1178, -24.2106, -25.1025, -21.3072, -24.1871,
        -21.2178, -22.2652])
Final projection likelihood: -22.9761
1 mode projection succeeded
New goal: tensor([ 0.0662,  0.6424,  0.5144,  0.4689, -0.1200,  0.5189,  0.8211,  0.8370,
         1.3990,  0.1224,  0.2208,  1.1679,  0.0644,  0.0294, -0.2480],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0015]], device='cuda:1')
Original likelihood: -26.246315002441406
Adjusted likelihood: -26.246315002441406
Likelihood residual: 0.0
Original likelihood: -25.825469970703125
Adjusted likelihood: -25.825469970703125
Likelihood residual: 0.0
{'index': 25.825469970703125, 'thumb_middle': 26.246315002441406}
Current yaw: tensor([ 0.0810,  0.0406, -0.6436], device='cuda:1')
10 index
tensor([ 0.0928,  0.6462,  0.5122,  0.4665, -0.1550,  0.5769,  0.8524,  0.8512,
         1.4340,  0.0783,  0.2055,  1.1985,  0.0810,  0.0406, -0.6436,  6.2640],
       device='cuda:1')
Solve time for step 1 11.38204015098745
Current ori: tensor([ 0.0810,  0.0406, -0.6436], device='cuda:1')
Middle force: tensor([0.5808, 0.6136, 0.5388, 0.5274], device='cuda:1')
Thumb force: tensor([0.5657, 0.5648, 0.6364, 0.5351], device='cuda:1')
tensor([ 0.1054,  0.5015,  0.4748,  0.4739, -0.1465,  0.5885,  0.8428,  0.8362,
         1.4161,  0.1059,  0.2090,  1.1714,  0.0723,  0.0361, -0.6719, -5.0919],
       device='cuda:1')
Solve time for step 2 2.1156328700017184
Current ori: tensor([ 0.0723,  0.0361, -0.6719], device='cuda:1')
Middle force: tensor([0.6103, 0.5367, 0.5261], device='cuda:1')
Thumb force: tensor([0.5609, 0.6342, 0.5338], device='cuda:1')
tensor([ 0.1099,  0.5260,  0.4776,  0.4782, -0.1425,  0.6107,  0.8252,  0.8053,
         1.4219,  0.0994,  0.2067,  1.1445,  0.0617,  0.0348, -0.6828, -4.7362],
       device='cuda:1')
Solve time for step 3 2.3668800799932797
Current ori: tensor([ 0.0617,  0.0348, -0.6828], device='cuda:1')
Middle force: tensor([0.5339, 0.5248], device='cuda:1')
Thumb force: tensor([0.6305, 0.5323], device='cuda:1')
tensor([ 0.1104,  0.5247,  0.4757,  0.4721, -0.1528,  0.6111,  0.8157,  0.8008,
         1.4243,  0.1032,  0.2207,  1.1394,  0.0627,  0.0433, -0.6587, -4.9346],
       device='cuda:1')
Solve time for step 4 2.2827417819935363
Current ori: tensor([ 0.0627,  0.0433, -0.6587], device='cuda:1')
Middle force: tensor([0.5422], device='cuda:1')
Thumb force: tensor([0.5590], device='cuda:1')
Storing RECOVERY transition: reward=0.0702 (scaled=0.0702), steps=1
Reward stats updated: mean -0.0020 -> -0.0017, std: 0.1584
Collected 247 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7484, Q2 Loss=0.7484, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5532
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7419, Q2 Loss=0.7419, Entropy=0.0092, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3930
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8369, Q2 Loss=0.8369, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9071
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9517, Q2 Loss=0.9517, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4364
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.6053, Q2 Loss=3.6053, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5044

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.5%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.05s (16.7%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000001
Q1 loss: 1.376833
Q2 loss: 1.376833
Current threshold: -26.9884
Global Scale Offset: 0.2453
Reward stats: mean=-0.0017, std=0.1584, count=247
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3768, Q2 Loss: 1.3768, Entropy: 0.0019, Mean TD Error: 2.3588, Threshold: -26.9884
Original likelihood: -25.35596466064453
Adjusted likelihood: -25.35596466064453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9942)
Current yaw: tensor([ 0.0671,  0.0448, -0.6918], device='cuda:1')
11 turn
Sampling time 3.7360509900026955
tensor([ 0.0656,  0.6288,  0.5106,  0.4704, -0.1633,  0.5979,  0.8318,  0.8232,
         1.4277,  0.1096,  0.2102,  1.1556,  0.0671,  0.0448, -0.6918, -5.0745],
       device='cuda:1')
Original likelihood: -26.78980255126953
Adjusted likelihood: -26.78980255126953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6206)
Solve time for step 1 14.438503348996164
Current ori: tensor([ 0.0671,  0.0448, -0.6918], device='cuda:1')
Middle force: tensor([1.3437, 0.5055, 0.4985, 0.5559, 0.5630, 0.5794, 1.0360, 0.6023, 0.5325,
        0.9880, 0.5791, 0.5540], device='cuda:1')
Thumb force: tensor([1.9113, 1.7408, 1.2763, 0.5134, 1.0097, 0.7830, 1.3400, 0.5832, 0.7655,
        0.6436, 0.5641, 0.5534], device='cuda:1')
Index force: tensor([0.5751, 0.8563, 0.7301, 0.5988, 0.5638, 0.5327, 0.5577, 0.5870, 0.5736,
        0.5360, 0.6028, 0.5521], device='cuda:1')
Storing NORMAL transition: reward=-0.1579 (scaled=-0.1579), steps=1
Reward stats updated: mean -0.0017 -> -0.0023, std: 0.1583
Collected 248 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9132, Q2 Loss=0.9132, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9035
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.4220, Q2 Loss=4.4220, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6873
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8280, Q2 Loss=0.8280, Entropy=0.0081, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3520
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.5628, Q2 Loss=1.5628, Entropy=0.3321, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6556
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8779, Q2 Loss=0.8779, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5287

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.9%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (19.9%)
Actor update: 0.13s (41.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000029
Q1 loss: 1.720762
Q2 loss: 1.720762
Current threshold: -26.9857
Global Scale Offset: 0.2451
Reward stats: mean=-0.0023, std=0.1583, count=248
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.7208, Q2 Loss: 1.7208, Entropy: 0.0680, Mean TD Error: 2.6254, Threshold: -26.9857
tensor([ 0.0879,  0.6459,  0.5067,  0.4778, -0.1428,  0.7313,  0.5928,  0.9177,
         1.4014,  0.1329,  0.2002,  1.2263,  0.0598,  0.0448, -0.5318, -4.9555],
       device='cuda:1')
Original likelihood: -26.50386619567871
Adjusted likelihood: -26.50386619567871
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7719)
Solve time for step 2 3.110204034979688
Current ori: tensor([ 0.0598,  0.0448, -0.5318], device='cuda:1')
Middle force: tensor([0.5045, 0.5003, 0.5522, 0.5608, 0.5740, 1.0177, 0.5985, 0.5298, 0.9790,
        0.5750, 0.5506], device='cuda:1')
Thumb force: tensor([1.7083, 1.2451, 0.5134, 0.9906, 0.7785, 1.3099, 0.5789, 0.7585, 0.6391,
        0.5621, 0.5505], device='cuda:1')
Index force: tensor([0.8589, 0.7245, 0.5956, 0.5619, 0.5304, 0.5558, 0.5852, 0.5716, 0.5344,
        0.5999, 0.5514], device='cuda:1')
Storing NORMAL transition: reward=0.0118 (scaled=0.0118), steps=1
Reward stats updated: mean -0.0023 -> -0.0022, std: 0.1580
Collected 249 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7138, Q2 Loss=0.7138, Entropy=0.2685, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3031
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7529, Q2 Loss=0.7529, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2825
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.8638, Q2 Loss=1.8638, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0593
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0355, Q2 Loss=1.0355, Entropy=0.0009, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2256
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8293, Q2 Loss=0.8293, Entropy=0.0007, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4959

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.5%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000005
Q1 loss: 1.039066
Q2 loss: 1.039066
Current threshold: -26.9826
Global Scale Offset: 0.2450
Reward stats: mean=-0.0022, std=0.1580, count=249
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0391, Q2 Loss: 1.0391, Entropy: 0.0540, Mean TD Error: 1.2733, Threshold: -26.9826
tensor([ 0.2399,  0.6827,  0.5363,  0.6413, -0.0130,  0.7090,  0.5265,  0.7395,
         1.4541,  0.0592,  0.1157,  1.3903,  0.0984,  0.0407, -0.5480, -6.1717],
       device='cuda:1')
Original likelihood: -39.529850006103516
Adjusted likelihood: -39.529850006103516
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 33.35502624511719
Projection step: 1, Loss: 35.245994567871094
Projection step: 2, Loss: 35.785884857177734
Projection step: 3, Loss: 32.604644775390625
Projection step: 4, Loss: 30.187458038330078
Projection step: 5, Loss: 27.75733184814453
Projection step: 6, Loss: 27.128341674804688
Projection step: 7, Loss: 28.48068618774414
Projection step: 8, Loss: 30.608333587646484
Projection step: 9, Loss: 28.015644073486328
Projection step: 10, Loss: 26.828466415405273
Projection step: 11, Loss: 26.76605224609375
Projection step: 12, Loss: 27.026058197021484
Projection step: 13, Loss: 27.224193572998047
Projection step: 14, Loss: 25.67820167541504
Final likelihood: tensor([-29.1180, -24.8442, -27.2898, -28.8847, -29.0755, -29.8055, -25.8428,
        -25.4345, -25.4997, -29.1564, -26.3897, -28.7381, -28.6135, -29.9578,
        -21.5918, -29.0906])
Final projection likelihood: -27.4583
1 mode projection failed, trying anyway
New goal: tensor([ 0.2028,  0.6804,  0.6852,  0.5076, -0.0545,  0.5575,  0.5753,  0.8737,
         1.3836, -0.0148,  0.2121,  1.0971,  0.0843,  0.0389,  0.4930],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -30.12166404724121
Adjusted likelihood: -30.12166404724121
Likelihood residual: 0.0
Original likelihood: -35.365196228027344
Adjusted likelihood: -35.365196228027344
Likelihood residual: 0.0
{'index': 35.365196228027344, 'thumb_middle': 30.12166404724121}
Current yaw: tensor([ 0.0984,  0.0407, -0.5480], device='cuda:1')
12 thumb_middle
tensor([ 0.2399,  0.6827,  0.5363,  0.6413, -0.0130,  0.7090,  0.5265,  0.7395,
         1.4541,  0.0592,  0.1157,  1.3903,  0.0984,  0.0407, -0.5480, -6.1717],
       device='cuda:1')
Solve time for step 1 9.346184085006826
Current ori: tensor([ 0.0984,  0.0407, -0.5480], device='cuda:1')
Index force: tensor([0.6037, 0.5845, 0.5884, 0.5977], device='cuda:1')
tensor([ 0.2495,  0.6444,  0.6577,  0.5061, -0.1214,  0.6054,  0.5493,  0.8206,
         1.3833, -0.0158,  0.1832,  1.1791,  0.1706,  0.0879, -0.5346,  5.7435],
       device='cuda:1')
Solve time for step 2 1.956908146996284
Current ori: tensor([ 0.1706,  0.0879, -0.5346], device='cuda:1')
Index force: tensor([0.5813, 0.5854, 0.5954], device='cuda:1')
tensor([ 2.4190e-01,  7.0857e-01,  6.9345e-01,  4.8839e-01, -1.8174e-01,
         5.7109e-01,  5.3813e-01,  8.4518e-01,  1.4295e+00, -5.9442e-03,
         2.1984e-01,  1.1486e+00,  1.8509e-01,  1.0431e-01, -5.0217e-01,
         5.9715e+00], device='cuda:1')
Solve time for step 3 1.8073166029935237
Current ori: tensor([ 0.1851,  0.1043, -0.5022], device='cuda:1')
Index force: tensor([0.5824, 0.5909], device='cuda:1')
tensor([ 0.2267,  0.7662,  0.6790,  0.4836, -0.2124,  0.5208,  0.5301,  0.8469,
         1.4607,  0.0103,  0.2415,  1.1499,  0.2120,  0.1098, -0.4790,  5.6295],
       device='cuda:1')
Solve time for step 4 1.71891446900554
Current ori: tensor([ 0.2120,  0.1098, -0.4790], device='cuda:1')
Index force: tensor([0.5828], device='cuda:1')
Storing RECOVERY transition: reward=-0.0888 (scaled=-0.0444), steps=2
Reward stats updated: mean -0.0022 -> -0.0024, std: 0.1577
Collected 250 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2393, Q2 Loss=1.2393, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4536
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2271, Q2 Loss=1.2271, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5162
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.7955, Q2 Loss=0.7955, Entropy=0.1366, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0483
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=13.9459, Q2 Loss=13.9459, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0315
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0874, Q2 Loss=1.0874, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5467

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (21.3%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.04s (17.2%)
Actor update: 0.08s (36.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000016
Q1 loss: 3.659035
Q2 loss: 3.659035
Current threshold: -26.9798
Global Scale Offset: 0.2450
Reward stats: mean=-0.0024, std=0.1577, count=250
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.6590, Q2 Loss: 3.6590, Entropy: 0.0273, Mean TD Error: 1.7193, Threshold: -26.9798
Original likelihood: -34.05078887939453
Adjusted likelihood: -34.05078887939453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 40.54492950439453
Projection step: 1, Loss: 39.38642501831055
Projection step: 2, Loss: 37.899169921875
Projection step: 3, Loss: 38.516319274902344
Projection step: 4, Loss: 35.4825439453125
Projection step: 5, Loss: 35.00477600097656
Projection step: 6, Loss: 34.52513122558594
Projection step: 7, Loss: 34.444210052490234
Projection step: 8, Loss: 32.09529495239258
Projection step: 9, Loss: 31.50754165649414
Projection step: 10, Loss: 33.046634674072266
Projection step: 11, Loss: 33.26994323730469
Projection step: 12, Loss: 30.15604591369629
Projection step: 13, Loss: 27.67821502685547
Projection step: 14, Loss: 27.811479568481445
Final likelihood: tensor([-22.1779, -36.2540, -24.2926, -29.7745, -27.8746, -31.3237, -26.8470,
        -24.2955, -23.2982, -29.2208, -27.7769, -30.0014, -26.4438, -31.1205,
        -28.5413, -29.8969])
Final projection likelihood: -28.0712
1 mode projection failed, trying anyway
New goal: tensor([ 0.2240,  0.7213,  0.6051,  0.4577, -0.1328,  0.4996,  0.4509,  0.8674,
         1.3689,  0.0669,  0.3505,  0.9930,  0.1947,  0.0939, -0.0887],
       device='cuda:1')
tensor([[0.0038]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0016]], device='cuda:1')
Original likelihood: -45.51763153076172
Adjusted likelihood: -45.51763153076172
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 45.51763153076172}
Current yaw: tensor([ 0.2056,  0.0921, -0.4847], device='cuda:1')
13 thumb_middle
tensor([ 0.2813,  0.7996,  0.6796,  0.4749, -0.1397,  0.5414,  0.5587,  0.8574,
         1.5000,  0.0640,  0.3398,  1.1888,  0.2056,  0.0921, -0.4847,  5.5735],
       device='cuda:1')
Solve time for step 1 8.57067270798143
Current ori: tensor([ 0.2056,  0.0921, -0.4847], device='cuda:1')
Index force: tensor([0.5948, 0.5719, 0.5878, 0.5989], device='cuda:1')
tensor([ 0.2602,  0.8352,  0.6477,  0.4639, -0.2463,  0.4017,  0.4817,  0.8824,
         1.3899,  0.0461,  0.3970,  1.0768,  0.3482,  0.1432, -0.5338,  5.2170],
       device='cuda:1')
Solve time for step 2 1.8792168160143774
Current ori: tensor([ 0.3482,  0.1432, -0.5338], device='cuda:1')
Index force: tensor([0.5705, 0.5703, 0.5766], device='cuda:1')
tensor([ 0.1973,  0.9112,  0.6527,  0.4614, -0.2932,  0.3202,  0.4669,  0.8851,
         1.4067,  0.0787,  0.4192,  1.0512,  0.3503,  0.1489, -0.5300,  5.6726],
       device='cuda:1')
Solve time for step 3 1.878708893986186
Current ori: tensor([ 0.3503,  0.1489, -0.5300], device='cuda:1')
Index force: tensor([0.5240, 0.5723], device='cuda:1')
tensor([ 0.1413,  0.9718,  0.6387,  0.4763, -0.2945,  0.3156,  0.4639,  0.8811,
         1.4352,  0.1029,  0.4375,  1.0643,  0.3480,  0.1454, -0.5156,  5.6913],
       device='cuda:1')
Solve time for step 4 1.8724316539883148
Current ori: tensor([ 0.3480,  0.1454, -0.5156], device='cuda:1')
Index force: tensor([0.5619], device='cuda:1')
Storing RECOVERY transition: reward=-0.0990 (scaled=-0.0495), steps=2
Reward stats updated: mean -0.0024 -> -0.0026, std: 0.1574
Collected 251 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8261, Q2 Loss=0.8261, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2577
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8490, Q2 Loss=0.8490, Entropy=0.0096, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4012
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4634, Q2 Loss=1.4634, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6731
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9948, Q2 Loss=0.9948, Entropy=0.0017, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2941
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.0133, Q2 Loss=1.0133, Entropy=0.2683, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5099

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (19.5%)
Q2 update: 0.06s (19.7%)
Actor update: 0.13s (43.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000052
Q1 loss: 1.029324
Q2 loss: 1.029324
Current threshold: -26.9766
Global Scale Offset: 0.2451
Reward stats: mean=-0.0026, std=0.1574, count=251
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0293, Q2 Loss: 1.0293, Entropy: 0.0559, Mean TD Error: 0.8272, Threshold: -26.9766
Original likelihood: -249.11907958984375
Adjusted likelihood: -249.11907958984375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 257.31378173828125
Projection step: 1, Loss: 252.4173126220703
Projection step: 2, Loss: 238.3967742919922
Projection step: 3, Loss: 245.86328125
Projection step: 4, Loss: 244.36814880371094
Projection step: 5, Loss: 248.30880737304688
Projection step: 6, Loss: 250.25242614746094
Projection step: 7, Loss: 248.2501220703125
Projection step: 8, Loss: 249.35662841796875
Projection step: 9, Loss: 251.15203857421875
Projection step: 10, Loss: 259.45745849609375
Projection step: 11, Loss: 242.220703125
Projection step: 12, Loss: 245.76019287109375
Projection step: 13, Loss: 248.65426635742188
Projection step: 14, Loss: 246.65420532226562
Final likelihood: tensor([-242.5151, -234.9977, -242.4241, -302.7166, -238.1532, -275.9400,
        -232.1310, -229.2841, -260.7608, -289.5205, -257.7701, -234.0086,
        -277.8193, -245.9215, -253.3772, -230.7139])
Final projection likelihood: -253.0034
1 mode projection failed, trying anyway
New goal: tensor([ 0.0912,  1.0328,  0.6100,  0.4931, -0.1528,  0.1738,  0.5429,  0.8858,
         1.4635,  0.1522,  0.5484,  1.1942,  0.3832,  0.1883, -0.5447],
       device='cuda:1')
tensor([[0.0129]], device='cuda:1') tensor([[-0.0101]], device='cuda:1') tensor([[0.0137]], device='cuda:1')
Original likelihood: -193.01600646972656
Adjusted likelihood: -193.01600646972656
Likelihood residual: 0.0
Original likelihood: -189.46266174316406
Adjusted likelihood: -189.46266174316406
Likelihood residual: 0.0
{'index': 189.46266174316406, 'thumb_middle': 193.01600646972656}
Current yaw: tensor([ 0.3832,  0.1882, -0.5687], device='cuda:1')
14 index
tensor([ 0.0984,  1.0254,  0.6233,  0.4653, -0.1469,  0.1721,  0.5145,  0.8774,
         1.5000,  0.1521,  0.5452,  1.1541,  0.3832,  0.1882, -0.5687,  4.7341],
       device='cuda:1')
Solve time for step 1 10.850990780978464
Current ori: tensor([ 0.3832,  0.1882, -0.5687], device='cuda:1')
Middle force: tensor([0.7162, 0.5493, 0.5601, 0.5463], device='cuda:1')
Thumb force: tensor([0.6383, 0.5084, 0.5480, 0.5668], device='cuda:1')
tensor([ 0.3224,  1.2488,  0.6481,  0.4986,  0.1573,  0.0331,  0.5523,  0.8855,
         1.5000,  0.2289,  0.5862,  1.1855,  0.3884,  0.2261, -0.6029,  4.8262],
       device='cuda:1')
Solve time for step 2 2.301895156997489
Current ori: tensor([ 0.3884,  0.2261, -0.6029], device='cuda:1')
Middle force: tensor([0.5500, 0.5585, 0.5458], device='cuda:1')
Thumb force: tensor([0.5085, 0.5487, 0.5668], device='cuda:1')
tensor([ 0.2054,  1.2008,  0.6695,  0.5033,  0.4436, -0.0378,  0.5435,  0.8869,
         1.5000,  0.2239,  0.5781,  1.1986,  0.3796,  0.2328, -0.6589, -5.7411],
       device='cuda:1')
Solve time for step 3 2.2008273969986476
Current ori: tensor([ 0.3796,  0.2328, -0.6589], device='cuda:1')
Middle force: tensor([0.5093, 0.5511], device='cuda:1')
Thumb force: tensor([0.5268, 0.5246], device='cuda:1')
tensor([ 0.0660,  1.1491,  0.6822,  0.5124,  0.4700, -0.1123,  0.5342,  0.8881,
         1.5000,  0.2557,  0.5853,  1.1991,  0.3820,  0.2310, -0.6386, -5.5725],
       device='cuda:1')
Solve time for step 4 2.2423366000002716
Current ori: tensor([ 0.3820,  0.2310, -0.6386], device='cuda:1')
Middle force: tensor([0.5495], device='cuda:1')
Thumb force: tensor([0.5234], device='cuda:1')
Storing RECOVERY transition: reward=-0.0564 (scaled=-0.0282), steps=2
Reward stats updated: mean -0.0026 -> -0.0027, std: 0.1571
Collected 252 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7270, Q2 Loss=0.7270, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2463
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0742, Q2 Loss=1.0742, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8857
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6950, Q2 Loss=0.6950, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2968
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8256, Q2 Loss=0.8256, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5861
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7607, Q2 Loss=0.7607, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2259

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (40.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.816515
Q2 loss: 0.816515
Current threshold: -26.9717
Global Scale Offset: 0.2452
Reward stats: mean=-0.0027, std=0.1571, count=252
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.8165, Q2 Loss: 0.8165, Entropy: 0.0000, Mean TD Error: 0.6482, Threshold: -26.9717
Original likelihood: -279.3726806640625
Adjusted likelihood: -279.3726806640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 266.868896484375
Projection step: 1, Loss: 266.9601135253906
Projection step: 2, Loss: 270.173095703125
Projection step: 3, Loss: 282.9267272949219
Projection step: 4, Loss: 268.4803466796875
Projection step: 5, Loss: 280.2483825683594
Projection step: 6, Loss: 271.89697265625
Projection step: 7, Loss: 265.38360595703125
Projection step: 8, Loss: 276.5489501953125
Projection step: 9, Loss: 283.7995910644531
Projection step: 10, Loss: 289.03106689453125
Projection step: 11, Loss: 281.91094970703125
Projection step: 12, Loss: 282.68182373046875
Projection step: 13, Loss: 285.1673583984375
Projection step: 14, Loss: 267.479248046875
Final likelihood: tensor([-271.3754, -260.0706, -267.3695, -285.5754, -291.4667, -273.4756,
        -262.2301, -277.0336, -297.7355, -253.8620, -300.4324, -274.0783,
        -318.2400, -290.4630, -269.1113, -260.5684])
Final projection likelihood: -278.3180
1 mode projection failed, trying anyway
New goal: tensor([-0.2667,  1.0080,  0.6768,  0.5441,  0.4650, -0.1230,  0.5691,  0.9038,
         1.4629,  0.2830,  0.5917,  1.3196,  0.3825,  0.2311, -0.5163],
       device='cuda:1')
tensor([[0.0038]], device='cuda:1') tensor([[-0.0028]], device='cuda:1') tensor([[0.0090]], device='cuda:1')
Original likelihood: -260.414306640625
Adjusted likelihood: -260.414306640625
Likelihood residual: 0.0
Original likelihood: -256.396484375
Adjusted likelihood: -256.396484375
Likelihood residual: 0.0
{'index': 256.396484375, 'thumb_middle': 260.414306640625}
Current yaw: tensor([ 0.3824,  0.2306, -0.6350], device='cuda:1')
15 index
tensor([-0.2615,  1.0061,  0.6946,  0.5136,  0.4700, -0.1222,  0.5386,  0.8827,
         1.5000,  0.2731,  0.5858,  1.2655,  0.3824,  0.2306, -0.6350,  5.7979],
       device='cuda:1')
Solve time for step 1 11.263854890014045
Current ori: tensor([ 0.3824,  0.2306, -0.6350], device='cuda:1')
Middle force: tensor([0.5749, 0.6101, 0.5223, 0.5963], device='cuda:1')
Thumb force: tensor([0.5315, 0.5303, 0.5988, 0.5811], device='cuda:1')
tensor([-0.1076,  1.1294,  0.7155,  0.5457,  0.4700, -0.1382,  0.5826,  0.8994,
         1.5000,  0.3093,  0.5811,  1.2439,  0.3831,  0.2301, -0.6286,  5.7204],
       device='cuda:1')
Solve time for step 2 2.297807136987103
Current ori: tensor([ 0.3831,  0.2301, -0.6286], device='cuda:1')
Middle force: tensor([0.5424, 0.5517, 0.5900], device='cuda:1')
Thumb force: tensor([0.5098, 0.5739, 0.5815], device='cuda:1')
tensor([-0.1411,  1.1461,  0.7207,  0.5517,  0.4700, -0.1515,  0.6768,  0.9015,
         1.5000,  0.3105,  0.5826,  1.2288,  0.3837,  0.2297, -0.6232, -6.1223],
       device='cuda:1')
Solve time for step 3 2.253435740014538
Current ori: tensor([ 0.3837,  0.2297, -0.6232], device='cuda:1')
Middle force: tensor([0.5522, 0.5627], device='cuda:1')
Thumb force: tensor([0.6012, 0.5279], device='cuda:1')
tensor([-0.1671,  1.1596,  0.7284,  0.5525,  0.4700, -0.1573,  0.6718,  0.9091,
         1.5000,  0.3149,  0.5907,  1.2167,  0.3840,  0.2294, -0.6208, -6.1764],
       device='cuda:1')
Solve time for step 4 2.052955491002649
Current ori: tensor([ 0.3840,  0.2294, -0.6208], device='cuda:1')
Middle force: tensor([0.5575], device='cuda:1')
Thumb force: tensor([0.5251], device='cuda:1')
Storing RECOVERY transition: reward=-0.0889 (scaled=-0.0444), steps=2
Reward stats updated: mean -0.0027 -> -0.0029, std: 0.1569
Collected 253 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.7044, Q2 Loss=0.7044, Entropy=0.3460, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1740
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9514, Q2 Loss=0.9514, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3146
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2776, Q2 Loss=1.2776, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6870
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2739, Q2 Loss=1.2739, Entropy=0.0313, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4661
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.0825, Q2 Loss=2.0825, Entropy=0.0006, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1444

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.04s (17.5%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000150
Q1 loss: 1.257970
Q2 loss: 1.257970
Current threshold: -26.9601
Global Scale Offset: 0.2453
Reward stats: mean=-0.0029, std=0.1569, count=253
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.2580, Q2 Loss: 1.2580, Entropy: 0.0758, Mean TD Error: 1.3572, Threshold: -26.9601
Original likelihood: -293.1352233886719
Adjusted likelihood: -293.1352233886719
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 293.7279052734375
Projection step: 1, Loss: 284.318359375
Projection step: 2, Loss: 287.4848327636719
Projection step: 3, Loss: 290.305419921875
Projection step: 4, Loss: 294.266845703125
Projection step: 5, Loss: 290.6636962890625
Projection step: 6, Loss: 285.64019775390625
Projection step: 7, Loss: 301.331787109375
Projection step: 8, Loss: 293.5984191894531
Projection step: 9, Loss: 285.08428955078125
Projection step: 10, Loss: 287.2045593261719
Projection step: 11, Loss: 285.9232177734375
Projection step: 12, Loss: 298.9981384277344
Projection step: 13, Loss: 283.552001953125
Projection step: 14, Loss: 299.7425231933594
Final likelihood: tensor([-316.2450, -273.4137, -294.4532, -283.5568, -295.6849, -274.1257,
        -299.2099, -284.4723, -294.2235, -253.7969, -262.7967, -301.1418,
        -277.3316, -303.7670, -290.8528, -298.9542])
Final projection likelihood: -287.7516
1 mode projection failed, trying anyway
New goal: tensor([-0.2588,  1.1258,  0.7102,  0.5789,  0.4659, -0.1725,  0.6233,  0.9296,
         1.4650,  0.3339,  0.6029,  1.2768,  0.3875,  0.2338, -0.4712],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[-0.0018]], device='cuda:1') tensor([[0.0119]], device='cuda:1')
Original likelihood: -275.32476806640625
Adjusted likelihood: -275.32476806640625
Likelihood residual: 0.0
{'index': 275.32476806640625, 'thumb_middle': inf}
Current yaw: tensor([ 0.3872,  0.2336, -0.5987], device='cuda:1')
16 index
tensor([-0.2541,  1.1240,  0.7288,  0.5532,  0.4700, -0.1707,  0.5957,  0.9055,
         1.5000,  0.3213,  0.5984,  1.2236,  0.3872,  0.2336, -0.5987,  5.9343],
       device='cuda:1')
Solve time for step 1 11.58502314297948
Current ori: tensor([ 0.3872,  0.2336, -0.5987], device='cuda:1')
Middle force: tensor([0.5889, 0.5390, 0.5298, 0.5150], device='cuda:1')
Thumb force: tensor([0.5007, 0.6039, 0.5514, 0.5409], device='cuda:1')
tensor([-0.1943,  1.1783,  0.7351,  0.5863,  0.4550, -0.1739,  0.6623,  0.9215,
         1.4999,  0.3159,  0.5980,  1.2128,  0.3865,  0.2303, -0.6015,  6.0401],
       device='cuda:1')
Solve time for step 2 2.308519405021798
Current ori: tensor([ 0.3865,  0.2303, -0.6015], device='cuda:1')
Middle force: tensor([0.5375, 0.5286, 0.5143], device='cuda:1')
Thumb force: tensor([0.6011, 0.5499, 0.5393], device='cuda:1')
tensor([-0.1928,  1.1801,  0.7333,  0.5854,  0.4700, -0.1844,  0.5824,  0.9275,
         1.4999,  0.3150,  0.5956,  1.2145,  0.3858,  0.2291, -0.6071, -6.2824],
       device='cuda:1')
Solve time for step 3 2.2454729710007086
Current ori: tensor([ 0.3858,  0.2291, -0.6071], device='cuda:1')
Middle force: tensor([0.5272, 0.5134], device='cuda:1')
Thumb force: tensor([0.5476, 0.5376], device='cuda:1')
tensor([-0.1886,  1.1952,  0.7295,  0.5884,  0.4493, -0.1867,  0.5993,  0.9298,
         1.4924,  0.3264,  0.5882,  1.2315,  0.3868,  0.2286, -0.5991,  6.1688],
       device='cuda:1')
Solve time for step 4 2.151807677000761
Current ori: tensor([ 0.3868,  0.2286, -0.5991], device='cuda:1')
Middle force: tensor([0.5126], device='cuda:1')
Thumb force: tensor([0.5363], device='cuda:1')
Storing RECOVERY transition: reward=-0.0976 (scaled=-0.0488), steps=2
Reward stats updated: mean -0.0029 -> -0.0030, std: 0.1566
Collected 254 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1574, Q2 Loss=1.1574, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5920
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0721, Q2 Loss=1.0721, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3599
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=13.9559, Q2 Loss=13.9559, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0649
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1025, Q2 Loss=1.1025, Entropy=0.0643, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1327
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=0.8021, Q2 Loss=0.8021, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9887

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.2%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004610
Q1 loss: 3.617984
Q2 loss: 3.617984
Current threshold: -26.9529
Global Scale Offset: 0.2454
Reward stats: mean=-0.0030, std=0.1566, count=254
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 3.6180, Q2 Loss: 3.6180, Entropy: 0.0129, Mean TD Error: 2.2276, Threshold: -26.9529
Original likelihood: -286.8193664550781
Adjusted likelihood: -286.8193664550781
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 294.3515319824219
Projection step: 1, Loss: 292.490966796875
Projection step: 2, Loss: 275.56390380859375
Projection step: 3, Loss: 282.00140380859375
Projection step: 4, Loss: 296.8321533203125
Projection step: 5, Loss: 290.871337890625
Projection step: 6, Loss: 288.26348876953125
Projection step: 7, Loss: 296.11688232421875
Projection step: 8, Loss: 292.1669006347656
Projection step: 9, Loss: 291.84033203125
Projection step: 10, Loss: 298.86419677734375
Projection step: 11, Loss: 288.91619873046875
Projection step: 12, Loss: 287.2785949707031
Projection step: 13, Loss: 292.4781494140625
Projection step: 14, Loss: 289.8614501953125
Final likelihood: tensor([-320.8410, -260.8104, -331.5014, -305.6375, -239.1075, -262.9486,
        -309.7974, -309.9824, -263.7170, -320.5038, -300.9649, -312.9655,
        -335.1897, -316.6473, -298.5443, -298.9321])
Final projection likelihood: -299.2557
1 mode projection failed, trying anyway
New goal: tensor([-0.2215,  1.1881,  0.6924,  0.6095,  0.4605, -0.1975,  0.6390,  0.9539,
         1.4658,  0.3386,  0.5921,  1.2902,  0.3887,  0.2321, -0.4618],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[-0.0009]], device='cuda:1') tensor([[0.0136]], device='cuda:1')
Original likelihood: -315.2691955566406
Adjusted likelihood: -315.2691955566406
Likelihood residual: 0.0
{'index': 315.2691955566406, 'thumb_middle': inf}
Current yaw: tensor([ 0.3884,  0.2319, -0.5880], device='cuda:1')
17 index
tensor([-0.2167,  1.1865,  0.7119,  0.5834,  0.4647, -0.1959,  0.6124,  0.9297,
         1.5000,  0.3254,  0.5878,  1.2379,  0.3884,  0.2319, -0.5880,  6.0331],
       device='cuda:1')
Solve time for step 1 10.763956355978735
Current ori: tensor([ 0.3884,  0.2319, -0.5880], device='cuda:1')
Middle force: tensor([0.5894, 0.5574, 0.5855, 0.5896], device='cuda:1')
Thumb force: tensor([0.5493, 0.6283, 0.5829, 0.5091], device='cuda:1')
tensor([-0.2065,  1.1849,  0.7126,  0.6103,  0.4447, -0.1960,  0.6439,  0.9490,
         1.4910,  0.3259,  0.5916,  1.2384,  0.3883,  0.2292, -0.5871,  6.1210],
       device='cuda:1')
Solve time for step 2 2.313693785981741
Current ori: tensor([ 0.3883,  0.2292, -0.5871], device='cuda:1')
Middle force: tensor([0.5556, 0.5837, 0.5880], device='cuda:1')
Thumb force: tensor([0.6253, 0.5804, 0.5085], device='cuda:1')
tensor([-0.2066,  1.1869,  0.7100,  0.6158,  0.4400, -0.1960,  0.7028,  0.9553,
         1.4936,  0.3229,  0.5887,  1.2432,  0.3885,  0.2291, -0.5848,  6.1718],
       device='cuda:1')
Solve time for step 3 2.2548425600107294
Current ori: tensor([ 0.3885,  0.2291, -0.5848], device='cuda:1')
Middle force: tensor([0.5816, 0.5859], device='cuda:1')
Thumb force: tensor([0.5772, 0.5077], device='cuda:1')
tensor([-0.2047,  1.1906,  0.7092,  0.6228,  0.4324, -0.1960,  0.7443,  0.9534,
         1.4956,  0.3196,  0.5808,  1.2564,  0.3883,  0.2280, -0.5819,  6.1038],
       device='cuda:1')
Solve time for step 4 2.17957483700593
Current ori: tensor([ 0.3883,  0.2280, -0.5819], device='cuda:1')
Middle force: tensor([0.5825], device='cuda:1')
Thumb force: tensor([0.5069], device='cuda:1')
Storing RECOVERY transition: reward=-0.1163 (scaled=-0.0581), steps=2
Reward stats updated: mean -0.0030 -> -0.0033, std: 0.1563
Collected 255 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=0.8829, Q2 Loss=0.8829, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6933
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9924, Q2 Loss=0.9924, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3726
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6312, Q2 Loss=0.6312, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1886
SAC Update 4/5: Actor Loss=-0.0035, Q1 Loss=0.9042, Q2 Loss=0.9042, Entropy=0.0694, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3417
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7415, Q2 Loss=0.7415, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4528

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.1%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.05s (18.4%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005299
Q1 loss: 0.830432
Q2 loss: 0.830432
Current threshold: -26.9379
Global Scale Offset: 0.2446
Reward stats: mean=-0.0033, std=0.1563, count=255
----------------------------------------------
SAC Update - Actor Loss: -0.0053, Q1 Loss: 0.8304, Q2 Loss: 0.8304, Entropy: 0.0139, Mean TD Error: 0.6098, Threshold: -26.9379
Original likelihood: -294.2819519042969
Adjusted likelihood: -294.2819519042969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 299.6212158203125
Projection step: 1, Loss: 297.9169616699219
Projection step: 2, Loss: 292.99884033203125
Projection step: 3, Loss: 299.0143127441406
Projection step: 4, Loss: 291.9920959472656
Projection step: 5, Loss: 290.9482421875
Projection step: 6, Loss: 305.9715270996094
Projection step: 7, Loss: 299.5624084472656
Projection step: 8, Loss: 301.28265380859375
Projection step: 9, Loss: 306.02978515625
Projection step: 10, Loss: 296.5558776855469
Projection step: 11, Loss: 293.97784423828125
Projection step: 12, Loss: 292.3305969238281
Projection step: 13, Loss: 290.5223388671875
Projection step: 14, Loss: 288.73321533203125
Final likelihood: tensor([-263.1005, -291.9498, -311.2903, -316.1906, -289.5336, -303.0865,
        -272.3539, -344.8077, -285.7615, -312.3650, -322.2270, -310.6464,
        -314.8383, -282.6995, -312.2312, -297.4795])
Final projection likelihood: -301.9101
1 mode projection failed, trying anyway
New goal: tensor([-0.2218,  1.1829,  0.7017,  0.6410,  0.4139, -0.1964,  0.7535,  0.9811,
         1.4668,  0.3360,  0.5927,  1.3037,  0.3914,  0.2332, -0.4472],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[-0.0010]], device='cuda:1') tensor([[0.0139]], device='cuda:1')
Original likelihood: -342.317138671875
Adjusted likelihood: -342.317138671875
Likelihood residual: 0.0
{'index': 342.317138671875, 'thumb_middle': inf}
Current yaw: tensor([ 0.3910,  0.2331, -0.5671], device='cuda:1')
18 index
tensor([-0.2168,  1.1811,  0.7211,  0.6157,  0.4181, -0.1944,  0.7282,  0.9561,
         1.5000,  0.3225,  0.5884,  1.2534,  0.3910,  0.2331, -0.5671,  6.0696],
       device='cuda:1')
Solve time for step 1 11.06963080598507
Current ori: tensor([ 0.3910,  0.2331, -0.5671], device='cuda:1')
Middle force: tensor([0.5678, 0.5800, 0.5320, 0.5715], device='cuda:1')
Thumb force: tensor([0.5565, 0.5271, 0.5621, 0.5607], device='cuda:1')
tensor([-0.2035,  1.1798,  0.7186,  0.6379,  0.3595, -0.1824,  0.9481,  1.1126,
         1.4959,  0.3142,  0.5932,  1.2449,  0.3906,  0.2274, -0.5668,  6.0743],
       device='cuda:1')
Solve time for step 2 2.427651064004749
Current ori: tensor([ 0.3906,  0.2274, -0.5668], device='cuda:1')
Middle force: tensor([0.5765, 0.5305, 0.5692], device='cuda:1')
Thumb force: tensor([0.5259, 0.5603, 0.5581], device='cuda:1')
tensor([-0.2032,  1.1836,  0.7052,  0.6434,  0.3626, -0.1851,  0.9383,  1.1329,
         1.4985,  0.3114,  0.5958,  1.2347,  0.3904,  0.2269, -0.5683,  6.0551],
       device='cuda:1')
Solve time for step 3 2.217985764989862
Current ori: tensor([ 0.3904,  0.2269, -0.5683], device='cuda:1')
Middle force: tensor([0.5293, 0.5680], device='cuda:1')
Thumb force: tensor([0.5586, 0.5560], device='cuda:1')
tensor([-0.2031,  1.1836,  0.7039,  0.6468,  0.3371, -0.1783,  0.8939,  1.1229,
         1.4982,  0.3114,  0.5966,  1.2339,  0.3902,  0.2271, -0.5684,  6.1376],
       device='cuda:1')
Solve time for step 4 2.157066871004645
Current ori: tensor([ 0.3902,  0.2271, -0.5684], device='cuda:1')
Middle force: tensor([0.5648], device='cuda:1')
Thumb force: tensor([0.5520], device='cuda:1')
Storing RECOVERY transition: reward=-0.1193 (scaled=-0.0596), steps=2
Reward stats updated: mean -0.0033 -> -0.0035, std: 0.1560
Collected 256 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0827, Q2 Loss=1.0827, Entropy=0.0338, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6744
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9319, Q2 Loss=0.9319, Entropy=0.0002, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3706
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4632, Q2 Loss=1.4632, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9488
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=0.8830, Q2 Loss=0.8830, Entropy=0.6841, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6258
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8487, Q2 Loss=0.8487, Entropy=0.0043, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7550

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (39.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000197
Q1 loss: 1.041911
Q2 loss: 1.041911
Current threshold: -26.9115
Global Scale Offset: 0.2433
Reward stats: mean=-0.0035, std=0.1560, count=256
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0419, Q2 Loss: 1.0419, Entropy: 0.1445, Mean TD Error: 0.6749, Threshold: -26.9115
Original likelihood: -291.0513610839844
Adjusted likelihood: -291.0513610839844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 293.60968017578125
Projection step: 1, Loss: 289.4070129394531
Projection step: 2, Loss: 300.07879638671875
Projection step: 3, Loss: 298.1716003417969
Projection step: 4, Loss: 297.8757629394531
Projection step: 5, Loss: 295.0294189453125
Projection step: 6, Loss: 282.834228515625
Projection step: 7, Loss: 298.9752502441406
Projection step: 8, Loss: 282.7947998046875
Projection step: 9, Loss: 276.26788330078125
Projection step: 10, Loss: 279.35540771484375
Projection step: 11, Loss: 310.60595703125
Projection step: 12, Loss: 285.02984619140625
Projection step: 13, Loss: 286.9031982421875
Projection step: 14, Loss: 299.43560791015625
Final likelihood: tensor([-286.1622, -305.9555, -299.6489, -301.7114, -284.3191, -318.7398,
        -293.1489, -310.9421, -281.0250, -321.9736, -280.0838, -319.0081,
        -287.0686, -301.7711, -344.9167, -282.6263])
Final projection likelihood: -301.1938
1 mode projection failed, trying anyway
New goal: tensor([-0.2806,  1.1016,  0.6867,  0.6755,  0.3505, -0.1763,  0.8542,  1.0241,
         1.4653,  0.3274,  0.6051,  1.2860,  0.3920,  0.2304, -0.4417],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[-0.0015]], device='cuda:1') tensor([[0.0105]], device='cuda:1')
Original likelihood: -292.47796630859375
Adjusted likelihood: -292.47796630859375
Likelihood residual: 0.0
{'index': 292.47796630859375, 'thumb_middle': inf}
Current yaw: tensor([ 0.3916,  0.2303, -0.5628], device='cuda:1')
19 index
tensor([-0.2755,  1.1005,  0.7074,  0.6462,  0.3559, -0.1737,  0.8293,  0.9992,
         1.5000,  0.3138,  0.5996,  1.2337,  0.3916,  0.2303, -0.5628,  6.1104],
       device='cuda:1')
Solve time for step 1 10.899575797986472
Current ori: tensor([ 0.3916,  0.2303, -0.5628], device='cuda:1')
Middle force: tensor([0.5845, 0.5766, 0.5803, 0.5101], device='cuda:1')
Thumb force: tensor([0.5592, 0.6059, 0.5380, 0.6924], device='cuda:1')
tensor([-0.1706,  1.1929,  0.7301,  0.6875,  0.3814, -0.1788,  0.8173,  0.9942,
         1.5000,  0.3100,  0.5974,  1.2231,  0.3888,  0.2269, -0.5814,  6.0858],
       device='cuda:1')
Solve time for step 2 2.2967468819988426
Current ori: tensor([ 0.3888,  0.2269, -0.5814], device='cuda:1')
Middle force: tensor([0.5737, 0.5772, 0.5092], device='cuda:1')
Thumb force: tensor([0.6016, 0.5359, 0.6887], device='cuda:1')
tensor([-0.1725,  1.1954,  0.7320,  0.6788,  0.3509, -0.1726,  0.8253,  1.0194,
         1.4999,  0.3113,  0.5983,  1.2254,  0.3895,  0.2274, -0.5750,  6.0970],
       device='cuda:1')
Solve time for step 3 2.3298041279776953
Current ori: tensor([ 0.3895,  0.2274, -0.5750], device='cuda:1')
Middle force: tensor([0.5726, 0.5079], device='cuda:1')
Thumb force: tensor([0.5340, 0.6844], device='cuda:1')
tensor([-0.1708,  1.2005,  0.7235,  0.6972,  0.3473, -0.1717,  0.8401,  1.0084,
         1.4999,  0.3093,  0.5960,  1.2318,  0.3902,  0.2264, -0.5703,  6.1136],
       device='cuda:1')
Solve time for step 4 2.21958112201537
Current ori: tensor([ 0.3902,  0.2264, -0.5703], device='cuda:1')
Middle force: tensor([0.5066], device='cuda:1')
Thumb force: tensor([0.6794], device='cuda:1')
Storing RECOVERY transition: reward=-0.1097 (scaled=-0.0549), steps=2
Reward stats updated: mean -0.0035 -> -0.0037, std: 0.1558
Collected 257 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8543, Q2 Loss=0.8543, Entropy=0.0006, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4386
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2487, Q2 Loss=1.2487, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4829
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8317, Q2 Loss=0.8317, Entropy=0.0009, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2816
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0779, Q2 Loss=1.0779, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9710
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2468, Q2 Loss=1.2468, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5452

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.3%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.1%)
Actor update: 0.10s (42.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.051875
Q2 loss: 1.051875
Current threshold: -26.8900
Global Scale Offset: 0.2425
Reward stats: mean=-0.0037, std=0.1558, count=257
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0519, Q2 Loss: 1.0519, Entropy: 0.0003, Mean TD Error: 1.5439, Threshold: -26.8900
Original likelihood: -292.4822998046875
Adjusted likelihood: -292.4822998046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 275.16912841796875
Projection step: 1, Loss: 285.166015625
Projection step: 2, Loss: 274.9250183105469
Projection step: 3, Loss: 293.939208984375
Projection step: 4, Loss: 295.67669677734375
Projection step: 5, Loss: 292.52587890625
Projection step: 6, Loss: 288.439208984375
Projection step: 7, Loss: 292.05279541015625
Projection step: 8, Loss: 298.82440185546875
Projection step: 9, Loss: 282.86773681640625
Projection step: 10, Loss: 295.5516357421875
Projection step: 11, Loss: 284.7303771972656
Projection step: 12, Loss: 299.69110107421875
Projection step: 13, Loss: 296.0191650390625
Projection step: 14, Loss: 294.68109130859375
Final likelihood: tensor([-274.6476, -308.2148, -263.1974, -297.7908, -272.8387, -260.9492,
        -306.0681, -279.5914, -316.0254, -268.6911, -279.6143, -321.4529,
        -272.2690, -281.1873, -320.2066, -293.8835])
Final projection likelihood: -288.5393
1 mode projection failed, trying anyway
New goal: tensor([-0.1843,  1.1981,  0.7092,  0.7102,  0.3832, -0.1762,  0.8688,  1.0434,
         1.4659,  0.3278,  0.6066,  1.2767,  0.3903,  0.2305, -0.4513],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[-0.0014]], device='cuda:1') tensor([[0.0149]], device='cuda:1')
Original likelihood: -304.1173400878906
Adjusted likelihood: -304.1173400878906
Likelihood residual: 0.0
{'index': 304.1173400878906, 'thumb_middle': inf}
Current yaw: tensor([ 0.3901,  0.2303, -0.5735], device='cuda:1')
20 index
tensor([-0.1789,  1.1958,  0.7293,  0.6834,  0.3877, -0.1751,  0.8419,  1.0187,
         1.5000,  0.3162,  0.6019,  1.2249,  0.3901,  0.2303, -0.5735,  6.1038],
       device='cuda:1')
Solve time for step 1 10.974383202992612
Current ori: tensor([ 0.3901,  0.2303, -0.5735], device='cuda:1')
Middle force: tensor([0.5709, 0.5951, 0.5911, 0.5261], device='cuda:1')
Thumb force: tensor([0.5732, 0.5925, 0.5497, 0.6603], device='cuda:1')
tensor([-0.1734,  1.1979,  0.7195,  0.7053,  0.3894, -0.1757,  0.8849,  1.0366,
         1.4945,  0.3172,  0.6077,  1.2160,  0.3894,  0.2293, -0.5780,  6.1049],
       device='cuda:1')
Solve time for step 2 2.40373580501182
Current ori: tensor([ 0.3894,  0.2293, -0.5780], device='cuda:1')
Middle force: tensor([0.6057, 0.5271, 0.5979], device='cuda:1')
Thumb force: tensor([0.5488, 0.5287, 0.5918], device='cuda:1')
tensor([-0.1736,  1.2033,  0.7114,  0.7069,  0.3912, -0.1758,  0.8858,  1.0586,
         1.4999,  0.3120,  0.6016,  1.2211,  0.3891,  0.2288, -0.5798,  6.1142],
       device='cuda:1')
Solve time for step 3 2.2247896770131774
Current ori: tensor([ 0.3891,  0.2288, -0.5798], device='cuda:1')
Middle force: tensor([0.5259, 0.5956], device='cuda:1')
Thumb force: tensor([0.5274, 0.5884], device='cuda:1')
tensor([-0.1717,  1.2031,  0.7123,  0.7116,  0.3864, -0.1763,  0.8763,  1.0436,
         1.4960,  0.3144,  0.6019,  1.2230,  0.3892,  0.2280, -0.5791,  6.1123],
       device='cuda:1')
Solve time for step 4 2.1723333219997585
Current ori: tensor([ 0.3892,  0.2280, -0.5791], device='cuda:1')
Middle force: tensor([0.5716], device='cuda:1')
Thumb force: tensor([0.5049], device='cuda:1')
Storing RECOVERY transition: reward=-0.1136 (scaled=-0.0568), steps=2
Reward stats updated: mean -0.0037 -> -0.0039, std: 0.1555
Collected 258 transitions for RL
SAC Update 1/5: Actor Loss=-0.0133, Q1 Loss=1.1099, Q2 Loss=1.1099, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8094
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0644, Q2 Loss=1.0644, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3542
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.7531, Q2 Loss=0.7531, Entropy=0.3406, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9462
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3004, Q2 Loss=1.3004, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1704
SAC Update 5/5: Actor Loss=-0.0128, Q1 Loss=1.5196, Q2 Loss=1.5196, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0786

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005391
Q1 loss: 1.149471
Q2 loss: 1.149471
Current threshold: -26.8608
Global Scale Offset: 0.2399
Reward stats: mean=-0.0039, std=0.1555, count=258
----------------------------------------------
SAC Update - Actor Loss: -0.0054, Q1 Loss: 1.1495, Q2 Loss: 1.1495, Entropy: 0.0681, Mean TD Error: 2.4718, Threshold: -26.8608
Original likelihood: -289.0163269042969
Adjusted likelihood: -289.0163269042969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 297.4510498046875
Projection step: 1, Loss: 288.8184814453125
Projection step: 2, Loss: 294.4179992675781
Projection step: 3, Loss: 296.6588134765625
Projection step: 4, Loss: 286.4567565917969
Projection step: 5, Loss: 286.07159423828125
Projection step: 6, Loss: 294.1218566894531
Projection step: 7, Loss: 302.9201965332031
Projection step: 8, Loss: 292.052490234375
Projection step: 9, Loss: 291.6353759765625
Projection step: 10, Loss: 290.43841552734375
Projection step: 11, Loss: 290.0226745605469
Projection step: 12, Loss: 288.9365539550781
Projection step: 13, Loss: 291.8583984375
Projection step: 14, Loss: 278.37939453125
Final likelihood: tensor([-324.0778, -247.5735, -306.5848, -283.0523, -315.3884, -302.0705,
        -288.4991, -283.2995, -300.1061, -297.5237, -336.1313, -269.7845,
        -287.6676, -332.4298, -274.0904, -266.5302])
Final projection likelihood: -294.6756
1 mode projection failed, trying anyway
New goal: tensor([-0.2313,  1.1360,  0.6879,  0.7392,  0.3809, -0.1780,  0.9143,  1.0683,
         1.4665,  0.3268,  0.6102,  1.2745,  0.3910,  0.2315, -0.4525],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 15
Loaded trajectory sampler
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
1 turn
Sampling time 3.727584025997203
tensor([ 0.1363,  0.5748,  0.6160,  0.5807, -0.1191,  0.4981,  0.9644,  0.8939,
         1.2625,  0.2633,  0.2112,  1.2053, -0.0020,  0.0145, -0.0306,  0.2450],
       device='cuda:1')
Original likelihood: -19.640695571899414
Adjusted likelihood: -19.640695571899414
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.146702199999709
Current ori: tensor([-0.0020,  0.0145, -0.0306], device='cuda:1')
Middle force: tensor([0.5430, 0.5253, 1.5047, 0.5973, 0.5874, 0.5593, 0.5395, 0.5267, 0.5277,
        0.5940, 1.0899, 0.6246], device='cuda:1')
Thumb force: tensor([0.6661, 0.8859, 1.8551, 0.7355, 1.0643, 0.5854, 0.6093, 0.8445, 2.0501,
        0.5911, 0.5676, 0.5903], device='cuda:1')
Index force: tensor([0.5514, 0.8609, 0.5657, 0.5573, 0.6182, 0.5823, 0.6544, 0.9590, 0.6436,
        0.6188, 0.5550, 0.5808], device='cuda:1')
Storing NORMAL transition: reward=0.0102 (scaled=0.0102), steps=1
Reward stats updated: mean -0.0039 -> -0.0038, std: 0.1552
Collected 259 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7231, Q2 Loss=0.7231, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4386
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7078, Q2 Loss=0.7078, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3984
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=0.9128, Q2 Loss=0.9128, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4331
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9426, Q2 Loss=0.9426, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2465
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=26.8045, Q2 Loss=26.8045, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.9277

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (18.0%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001924
Q1 loss: 6.018156
Q2 loss: 6.018156
Current threshold: -26.8086
Global Scale Offset: 0.2322
Reward stats: mean=-0.0038, std=0.1552, count=259
----------------------------------------------
SAC Update - Actor Loss: -0.0019, Q1 Loss: 6.0182, Q2 Loss: 6.0182, Entropy: 0.0000, Mean TD Error: 2.2888, Threshold: -26.8086
tensor([ 0.0682,  0.6255,  0.5162,  0.4971, -0.1468,  0.4806,  1.0542,  0.8176,
         1.3338,  0.2801,  0.1719,  0.9191, -0.0152,  0.0116, -0.0410,  0.7375],
       device='cuda:1')
Original likelihood: -21.194658279418945
Adjusted likelihood: -21.194658279418945
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.924975649017142
Current ori: tensor([-0.0152,  0.0116, -0.0410], device='cuda:1')
Middle force: tensor([0.5426, 1.5175, 0.6031, 0.5886, 0.5588, 0.5465, 0.5422, 0.5309, 0.6143,
        1.0823, 0.6231], device='cuda:1')
Thumb force: tensor([0.8296, 1.8185, 0.7155, 1.0494, 0.5810, 0.5899, 0.7956, 2.0249, 0.5656,
        0.5656, 0.5875], device='cuda:1')
Index force: tensor([0.8083, 0.5669, 0.5560, 0.6142, 0.5830, 0.6522, 0.9218, 0.6300, 0.6222,
        0.5536, 0.5787], device='cuda:1')
Storing NORMAL transition: reward=-0.0309 (scaled=-0.0309), steps=1
Reward stats updated: mean -0.0038 -> -0.0039, std: 0.1549
Collected 260 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=13.9892, Q2 Loss=13.9892, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0283
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6597, Q2 Loss=0.6597, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6695
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.6440, Q2 Loss=1.6440, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1124
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5425, Q2 Loss=1.5425, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2807
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0448, Q2 Loss=1.0448, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3559

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.4%)
Q1 update: 0.06s (21.3%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 3.776054
Q2 loss: 3.776054
Current threshold: -26.7776
Global Scale Offset: 0.2277
Reward stats: mean=-0.0039, std=0.1549, count=260
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 3.7761, Q2 Loss: 3.7761, Entropy: 0.0000, Mean TD Error: 2.4894, Threshold: -26.7776
tensor([ 0.0722,  0.6584,  0.4690,  0.4952, -0.1429,  0.5157,  1.0049,  0.8221,
         1.3882,  0.2684,  0.1780,  0.9396, -0.0223,  0.0103, -0.0103,  0.6885],
       device='cuda:1')
Original likelihood: -15.865978240966797
Adjusted likelihood: -15.865978240966797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.8641800559998956
Current ori: tensor([-0.0223,  0.0103, -0.0103], device='cuda:1')
Middle force: tensor([1.5008, 0.6040, 0.5898, 0.5568, 0.5427, 0.5424, 0.5290, 0.6173, 1.0750,
        0.6199], device='cuda:1')
Thumb force: tensor([1.7965, 0.7035, 1.0344, 0.5800, 0.5877, 0.7943, 2.0056, 0.5618, 0.5636,
        0.5860], device='cuda:1')
Index force: tensor([0.5645, 0.5541, 0.6094, 0.5830, 0.6526, 0.9047, 0.6260, 0.6166, 0.5519,
        0.5770], device='cuda:1')
Storing NORMAL transition: reward=0.1495 (scaled=0.1495), steps=1
Reward stats updated: mean -0.0039 -> -0.0033, std: 0.1549
Collected 261 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0019, Q2 Loss=1.0019, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2700
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.2457, Q2 Loss=1.2457, Entropy=0.1219, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6546
SAC Update 3/5: Actor Loss=-0.0020, Q1 Loss=1.2662, Q2 Loss=1.2662, Entropy=0.2016, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5657
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.9535, Q2 Loss=0.9535, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1019
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3400, Q2 Loss=1.3400, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6864

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.4%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000406
Q1 loss: 1.161468
Q2 loss: 1.161468
Current threshold: -26.7483
Global Scale Offset: 0.2247
Reward stats: mean=-0.0033, std=0.1549, count=261
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.1615, Q2 Loss: 1.1615, Entropy: 0.0647, Mean TD Error: 0.6557, Threshold: -26.7483
tensor([ 9.2035e-02,  6.3386e-01,  5.0278e-01,  5.5664e-01, -1.2871e-01,
         4.7644e-01,  1.0238e+00,  9.4301e-01,  1.4247e+00,  2.1951e-01,
         1.9868e-01,  8.3899e-01, -1.2612e-02, -9.4406e-04, -1.5946e-01,
         8.7136e-01], device='cuda:1')
Original likelihood: -18.655620574951172
Adjusted likelihood: -18.655620574951172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.8091012760123704
Current ori: tensor([-0.0126, -0.0009, -0.1595], device='cuda:1')
Middle force: tensor([0.6022, 0.5906, 0.5552, 0.5417, 0.5493, 0.5287, 0.6217, 1.0671, 0.6176],
       device='cuda:1')
Thumb force: tensor([0.6941, 1.0210, 0.5790, 0.5816, 0.7736, 1.9822, 0.5560, 0.5616, 0.5839],
       device='cuda:1')
Index force: tensor([0.5501, 0.6049, 0.5814, 0.6519, 0.8846, 0.6209, 0.6130, 0.5505, 0.5750],
       device='cuda:1')
Storing NORMAL transition: reward=0.0728 (scaled=0.0728), steps=1
Reward stats updated: mean -0.0033 -> -0.0031, std: 0.1547
Collected 262 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0795, Q2 Loss=1.0795, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8625
SAC Update 2/5: Actor Loss=-0.0067, Q1 Loss=1.1648, Q2 Loss=1.1648, Entropy=0.0048, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5313
SAC Update 3/5: Actor Loss=-0.0116, Q1 Loss=1.1243, Q2 Loss=1.1243, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2285
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=4.9801, Q2 Loss=4.9801, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9668
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8424, Q2 Loss=0.8424, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5838

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003661
Q1 loss: 1.838226
Q2 loss: 1.838226
Current threshold: -26.6793
Global Scale Offset: 0.2156
Reward stats: mean=-0.0031, std=0.1547, count=262
----------------------------------------------
SAC Update - Actor Loss: -0.0037, Q1 Loss: 1.8382, Q2 Loss: 1.8382, Entropy: 0.0010, Mean TD Error: 1.6346, Threshold: -26.6793
tensor([ 0.0857,  0.6089,  0.5088,  0.5873, -0.0675,  0.4077,  1.1786,  0.9320,
         1.5000,  0.0848,  0.0889,  0.7784,  0.0090, -0.0409, -0.2348,  2.0134],
       device='cuda:1')
Original likelihood: -28.828458786010742
Adjusted likelihood: -28.828458786010742
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0001)
State is out of distribution
Projection step: 0, Loss: 25.864215850830078
Projection step: 1, Loss: 25.310924530029297
Projection step: 2, Loss: 25.847721099853516
Projection step: 3, Loss: 23.079748153686523
Projection step: 4, Loss: 21.22635269165039
Projection step: 5, Loss: 20.53523826599121
Projection step: 6, Loss: 19.140830993652344
Projection step: 7, Loss: 18.555376052856445
Projection step: 8, Loss: 17.571311950683594
Projection step: 9, Loss: 15.962004661560059
Projection step: 10, Loss: 15.663492202758789
Projection step: 11, Loss: 14.807689666748047
Final likelihood: tensor([-12.5783, -14.8239, -12.6982, -16.1489, -16.2666, -16.1482, -13.0739,
        -12.7765, -16.1801, -15.0990, -12.4755, -16.1651, -15.6147, -14.8731,
        -15.1883, -16.8128])
Final projection likelihood: -14.8077
1 mode projection succeeded
New goal: tensor([ 0.0612,  0.5202,  0.6015,  0.6303, -0.0295,  0.5080,  0.8823,  0.9061,
         1.3997,  0.1020,  0.1767,  0.9721,  0.0046, -0.0292, -0.5330],
       device='cuda:1')
tensor([[0.0070]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -22.24860954284668
Adjusted likelihood: -22.24860954284668
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.24860954284668}
Current yaw: tensor([ 0.0090, -0.0409, -0.2348], device='cuda:1')
2 thumb_middle
tensor([ 0.0857,  0.6089,  0.5088,  0.5873, -0.0675,  0.4077,  1.1786,  0.9320,
         1.5000,  0.0848,  0.0889,  0.7784,  0.0090, -0.0409, -0.2348,  2.0134],
       device='cuda:1')
Solve time for step 1 9.176631523005199
Current ori: tensor([ 0.0090, -0.0409, -0.2348], device='cuda:1')
Index force: tensor([0.5713, 0.5826, 0.5964, 0.6041], device='cuda:1')
tensor([ 0.0776,  0.5640,  0.5613,  0.5916, -0.1151,  0.4687,  0.9216,  0.8920,
         1.3799,  0.0806,  0.0857,  0.8975,  0.0193, -0.0345, -0.2335,  2.0301],
       device='cuda:1')
Solve time for step 2 1.9856436760164797
Current ori: tensor([ 0.0193, -0.0345, -0.2335], device='cuda:1')
Index force: tensor([0.5777, 0.5932, 0.6008], device='cuda:1')
tensor([ 0.0588,  0.5454,  0.5737,  0.5823, -0.1252,  0.4985,  0.8702,  0.8824,
         1.3808,  0.0789,  0.0917,  0.9263,  0.0216, -0.0242, -0.2335,  2.0048],
       device='cuda:1')
Solve time for step 3 1.918655775982188
Current ori: tensor([ 0.0216, -0.0242, -0.2335], device='cuda:1')
Index force: tensor([0.5888, 0.5976], device='cuda:1')
tensor([ 0.0522,  0.5414,  0.5740,  0.5806, -0.1342,  0.5085,  0.8604,  0.8846,
         1.3821,  0.0795,  0.0892,  0.9374,  0.0221, -0.0206, -0.2335,  1.9956],
       device='cuda:1')
Solve time for step 4 1.8856911140028387
Current ori: tensor([ 0.0221, -0.0206, -0.2335], device='cuda:1')
Index force: tensor([0.5860], device='cuda:1')
Storing RECOVERY transition: reward=-0.0041 (scaled=-0.0010), steps=4
Reward stats updated: mean -0.0031 -> -0.0030, std: 0.1544
Collected 263 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=4.9874, Q2 Loss=4.9874, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.9781
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.5249, Q2 Loss=1.5249, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1365
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.9824, Q2 Loss=0.9824, Entropy=0.3350, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6582
SAC Update 4/5: Actor Loss=-0.0169, Q1 Loss=1.2797, Q2 Loss=1.2797, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9192
SAC Update 5/5: Actor Loss=-0.0025, Q1 Loss=1.2823, Q2 Loss=1.2823, Entropy=0.1409, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5655

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003973
Q1 loss: 2.011363
Q2 loss: 2.011363
Current threshold: -26.6150
Global Scale Offset: 0.2075
Reward stats: mean=-0.0030, std=0.1544, count=263
----------------------------------------------
SAC Update - Actor Loss: -0.0040, Q1 Loss: 2.0114, Q2 Loss: 2.0114, Entropy: 0.0952, Mean TD Error: 2.6515, Threshold: -26.6150
Original likelihood: -19.781835556030273
Adjusted likelihood: -19.781835556030273
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0250, -0.0260, -0.2299], device='cuda:1')
3 turn
Sampling time 3.6997091869998258
tensor([ 0.0592,  0.5435,  0.5746,  0.5852, -0.0658,  0.5623,  0.8978,  0.9042,
         1.4394,  0.1032,  0.1465,  0.9758,  0.0250, -0.0260, -0.2299,  2.0501],
       device='cuda:1')
Original likelihood: -18.46334457397461
Adjusted likelihood: -18.46334457397461
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.364829758007545
Current ori: tensor([ 0.0250, -0.0260, -0.2299], device='cuda:1')
Middle force: tensor([0.7104, 0.5434, 0.9283, 0.5464, 0.7536, 0.8321, 0.6310, 0.6715, 0.5431,
        0.5859, 0.7939, 1.1410], device='cuda:1')
Thumb force: tensor([1.2316, 0.5438, 0.5641, 0.6038, 1.6128, 1.1713, 0.5845, 0.5584, 0.5867,
        0.5968, 0.5602, 0.5719], device='cuda:1')
Index force: tensor([0.5815, 0.7064, 0.5257, 0.5952, 0.5384, 0.5780, 0.5564, 0.5642, 0.5718,
        0.6237, 0.6089, 0.5684], device='cuda:1')
Storing NORMAL transition: reward=0.0325 (scaled=0.0325), steps=1
Reward stats updated: mean -0.0030 -> -0.0029, std: 0.1541
Collected 264 transitions for RL
SAC Update 1/5: Actor Loss=-0.0163, Q1 Loss=1.2578, Q2 Loss=1.2578, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9084
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7681, Q2 Loss=0.7681, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5247
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3632, Q2 Loss=1.3632, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0956
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2224, Q2 Loss=1.2224, Entropy=0.0469, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0507
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9903, Q2 Loss=0.9903, Entropy=0.0110, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3772

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.8%)
Actor update: 0.12s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003267
Q1 loss: 1.120346
Q2 loss: 1.120346
Current threshold: -26.5623
Global Scale Offset: 0.2024
Reward stats: mean=-0.0029, std=0.1541, count=264
----------------------------------------------
SAC Update - Actor Loss: -0.0033, Q1 Loss: 1.1203, Q2 Loss: 1.1203, Entropy: 0.0116, Mean TD Error: 0.7913, Threshold: -26.5623
tensor([ 0.0641,  0.5557,  0.6010,  0.5138, -0.0772,  0.4915,  0.8513,  0.8172,
         1.5000,  0.0603,  0.2585,  0.8493,  0.0391,  0.0293, -0.2636,  2.3317],
       device='cuda:1')
Original likelihood: -22.835601806640625
Adjusted likelihood: -22.835601806640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9095010529854335
Current ori: tensor([ 0.0391,  0.0293, -0.2636], device='cuda:1')
Middle force: tensor([0.5319, 0.8981, 0.5421, 0.7422, 0.8036, 0.6034, 0.6594, 0.5261, 0.5451,
        0.7644, 1.1140], device='cuda:1')
Thumb force: tensor([0.5459, 0.5650, 0.6052, 1.6051, 1.1774, 0.5913, 0.5581, 0.5913, 0.6199,
        0.5654, 0.5730], device='cuda:1')
Index force: tensor([0.7128, 0.5272, 0.5938, 0.5361, 0.5782, 0.5633, 0.5639, 0.5951, 0.6644,
        0.6129, 0.5711], device='cuda:1')
Storing NORMAL transition: reward=0.0534 (scaled=0.0534), steps=1
Reward stats updated: mean -0.0029 -> -0.0027, std: 0.1539
Collected 265 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=13.5339, Q2 Loss=13.5339, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0263
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9703, Q2 Loss=0.9703, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3784
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9771, Q2 Loss=0.9771, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0544
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.3967, Q2 Loss=1.3967, Entropy=0.0010, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1323
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8023, Q2 Loss=0.8023, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2903

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.6%)
Actor update: 0.10s (43.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 3.536055
Q2 loss: 3.536055
Current threshold: -26.5308
Global Scale Offset: 0.1994
Reward stats: mean=-0.0027, std=0.1539, count=265
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.5361, Q2 Loss: 3.5361, Entropy: 0.0002, Mean TD Error: 3.3764, Threshold: -26.5308
tensor([ 0.0596,  0.5844,  0.5681,  0.4921, -0.0782,  0.4992,  0.8248,  0.8564,
         1.5000,  0.0717,  0.2879,  0.7658,  0.0310,  0.0290, -0.3166,  2.4298],
       device='cuda:1')
Original likelihood: -19.64196014404297
Adjusted likelihood: -19.64196014404297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7394844900118187
Current ori: tensor([ 0.0310,  0.0290, -0.3166], device='cuda:1')
Middle force: tensor([0.8902, 0.5394, 0.7354, 0.7912, 0.5915, 0.6533, 0.5197, 0.5351, 0.7537,
        1.0982], device='cuda:1')
Thumb force: tensor([0.5607, 0.6043, 1.5915, 1.1707, 0.5952, 0.5561, 0.5950, 0.6255, 0.5660,
        0.5724], device='cuda:1')
Index force: tensor([0.5258, 0.5928, 0.5344, 0.5766, 0.5632, 0.5626, 0.6029, 0.6757, 0.6116,
        0.5706], device='cuda:1')
Storing NORMAL transition: reward=0.0907 (scaled=0.0907), steps=1
Reward stats updated: mean -0.0027 -> -0.0023, std: 0.1537
Collected 266 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.4893, Q2 Loss=2.4893, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3836
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7703, Q2 Loss=0.7703, Entropy=0.0224, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4470
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9694, Q2 Loss=0.9694, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2766
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5762, Q2 Loss=1.5762, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1792
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=0.8890, Q2 Loss=0.8890, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4045

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004607
Q1 loss: 1.338815
Q2 loss: 1.338815
Current threshold: -26.5120
Global Scale Offset: 0.1976
Reward stats: mean=-0.0023, std=0.1537, count=266
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.3388, Q2 Loss: 1.3388, Entropy: 0.0045, Mean TD Error: 2.3382, Threshold: -26.5120
tensor([ 0.0574,  0.5910,  0.5541,  0.4970, -0.0795,  0.4806,  0.8282,  0.9081,
         1.5000,  0.0889,  0.3270,  0.6719,  0.0304,  0.0281, -0.4077,  2.5430],
       device='cuda:1')
Original likelihood: -20.947898864746094
Adjusted likelihood: -20.947898864746094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.629380578000564
Current ori: tensor([ 0.0304,  0.0281, -0.4077], device='cuda:1')
Middle force: tensor([0.5375, 0.7299, 0.7822, 0.5852, 0.6484, 0.5168, 0.5313, 0.7469, 1.0872],
       device='cuda:1')
Thumb force: tensor([0.5999, 1.5778, 1.1626, 0.5967, 0.5542, 0.5973, 0.6258, 0.5659, 0.5709],
       device='cuda:1')
Index force: tensor([0.5897, 0.5330, 0.5749, 0.5618, 0.5613, 0.6044, 0.6777, 0.6091, 0.5693],
       device='cuda:1')
Storing NORMAL transition: reward=0.0827 (scaled=0.0827), steps=1
Reward stats updated: mean -0.0023 -> -0.0020, std: 0.1535
Collected 267 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7342, Q2 Loss=0.7342, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4922
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=25.4851, Q2 Loss=25.4851, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=10.0512
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=1.0328, Q2 Loss=1.0328, Entropy=0.3456, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5851
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2852, Q2 Loss=1.2852, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2904
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1665, Q2 Loss=1.1665, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5029

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000065
Q1 loss: 5.940772
Q2 loss: 5.940772
Current threshold: -26.4983
Global Scale Offset: 0.1966
Reward stats: mean=-0.0020, std=0.1535, count=267
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 5.9408, Q2 Loss: 5.9408, Entropy: 0.0691, Mean TD Error: 2.7844, Threshold: -26.4983
tensor([ 0.1091,  0.5633,  0.6546,  0.4668,  0.0354,  0.5028,  0.8988,  0.9570,
         1.5000,  0.1122,  0.2642,  0.5041,  0.0353, -0.0529, -0.4956,  2.8314],
       device='cuda:1')
Original likelihood: -26.358421325683594
Adjusted likelihood: -26.358421325683594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6009)
Solve time for step 5 2.5081700090086088
Current ori: tensor([ 0.0353, -0.0529, -0.4956], device='cuda:1')
Middle force: tensor([0.7184, 0.7886, 0.5956, 0.6469, 0.5239, 0.5564, 0.7611, 1.0829],
       device='cuda:1')
Thumb force: tensor([1.5666, 1.1454, 0.5862, 0.5515, 0.5806, 0.5936, 0.5587, 0.5682],
       device='cuda:1')
Index force: tensor([0.5307, 0.5727, 0.5575, 0.5600, 0.5888, 0.6409, 0.6047, 0.5665],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0208 (scaled=-0.0208), steps=1
Reward stats updated: mean -0.0020 -> -0.0021, std: 0.1532
Collected 268 transitions for RL
SAC Update 1/5: Actor Loss=-0.0012, Q1 Loss=1.4336, Q2 Loss=1.4336, Entropy=0.3042, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5083
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.8694, Q2 Loss=4.8694, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.0248
SAC Update 3/5: Actor Loss=-0.0208, Q1 Loss=1.2214, Q2 Loss=1.2214, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3176
SAC Update 4/5: Actor Loss=-0.0140, Q1 Loss=1.2506, Q2 Loss=1.2506, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2115
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2397, Q2 Loss=1.2397, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1021

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (41.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007203
Q1 loss: 2.002944
Q2 loss: 2.002944
Current threshold: -26.4309
Global Scale Offset: 0.1876
Reward stats: mean=-0.0021, std=0.1532, count=268
----------------------------------------------
SAC Update - Actor Loss: -0.0072, Q1 Loss: 2.0029, Q2 Loss: 2.0029, Entropy: 0.0608, Mean TD Error: 2.6329, Threshold: -26.4309
tensor([ 0.1288,  0.5341,  0.6435,  0.5176,  0.0055,  0.5750,  0.9138,  1.0103,
         1.4192,  0.2269,  0.3434,  0.4825,  0.0478, -0.0798, -0.4826,  2.0505],
       device='cuda:1')
Original likelihood: -32.07067108154297
Adjusted likelihood: -32.07067108154297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.59380340576172
Projection step: 1, Loss: 30.67424964904785
Projection step: 2, Loss: 31.568265914916992
Projection step: 3, Loss: 28.487014770507812
Projection step: 4, Loss: 25.983932495117188
Projection step: 5, Loss: 26.54592514038086
Projection step: 6, Loss: 25.88587760925293
Projection step: 7, Loss: 26.160301208496094
Projection step: 8, Loss: 25.25574493408203
Projection step: 9, Loss: 22.5118408203125
Projection step: 10, Loss: 23.187198638916016
Projection step: 11, Loss: 24.004003524780273
Projection step: 12, Loss: 23.752914428710938
Projection step: 13, Loss: 24.978923797607422
Projection step: 14, Loss: 20.75534439086914
Final likelihood: tensor([-18.3264, -26.8598, -29.2384, -29.0758, -18.5241, -19.1661, -19.6879,
        -22.4362, -18.5548, -23.6273, -34.0916, -21.5945, -28.5909, -18.9850,
        -20.5827, -20.6368])
Final projection likelihood: -23.1236
1 mode projection succeeded
New goal: tensor([ 0.0749,  0.4513,  0.7129,  0.5962,  0.0144,  0.5484,  0.8220,  0.8659,
         1.4904,  0.0172,  0.2948,  0.8339,  0.0394, -0.0611, -0.4558],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0048]], device='cuda:1')
Original likelihood: -30.414539337158203
Adjusted likelihood: -30.414539337158203
Likelihood residual: 0.0
{'index': 30.414539337158203, 'thumb_middle': inf}
Current yaw: tensor([ 0.0478, -0.0798, -0.4826], device='cuda:1')
4 index
tensor([ 0.1288,  0.5341,  0.6435,  0.5176,  0.0055,  0.5750,  0.9138,  1.0103,
         1.4192,  0.2269,  0.3434,  0.4825,  0.0478, -0.0798, -0.4826,  2.0505],
       device='cuda:1')
Solve time for step 1 11.573780034988886
Current ori: tensor([ 0.0478, -0.0798, -0.4826], device='cuda:1')
Middle force: tensor([0.5751, 0.5850, 0.5205, 0.5436], device='cuda:1')
Thumb force: tensor([0.5205, 0.5442, 0.5094, 0.5771], device='cuda:1')
tensor([ 0.1299,  0.4232,  0.6416,  0.5488, -0.0048,  0.5956,  0.9719,  1.0096,
         1.5000,  0.0263,  0.2271,  0.6638,  0.1029, -0.1220, -0.5040,  2.0472],
       device='cuda:1')
Solve time for step 2 2.3297615420015063
Current ori: tensor([ 0.1029, -0.1220, -0.5040], device='cuda:1')
Middle force: tensor([0.5595, 0.5216, 0.5295], device='cuda:1')
Thumb force: tensor([0.6390, 0.5169, 0.5277], device='cuda:1')
tensor([ 1.1444e-01,  4.2016e-01,  6.5542e-01,  5.6081e-01,  5.0539e-04,
         6.7546e-01,  9.7763e-01,  9.7001e-01,  1.5000e+00,  7.4567e-02,
         2.4802e-01,  6.4155e-01,  2.3456e-01, -2.1512e-01, -5.3517e-01,
         2.5295e+00], device='cuda:1')
Solve time for step 3 2.23173559299903
Current ori: tensor([ 0.2346, -0.2151, -0.5352], device='cuda:1')
Middle force: tensor([0.5254, 0.5560], device='cuda:1')
Thumb force: tensor([0.5260, 0.5469], device='cuda:1')
tensor([ 0.1049,  0.4344,  0.6812,  0.5728, -0.0233,  0.7536,  1.0263,  0.9875,
         1.5000,  0.0677,  0.2927,  0.7239,  0.2903, -0.1996, -0.6760,  4.1327],
       device='cuda:1')
Solve time for step 4 2.164701635017991
Current ori: tensor([ 0.2903, -0.1996, -0.6760], device='cuda:1')
Middle force: tensor([0.5403], device='cuda:1')
Thumb force: tensor([0.6573], device='cuda:1')
Storing RECOVERY transition: reward=-0.0758 (scaled=-0.0152), steps=5
Reward stats updated: mean -0.0021 -> -0.0021, std: 0.1529
Collected 269 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.0507, Q2 Loss=2.0507, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3017
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7053, Q2 Loss=0.7053, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1832
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6862, Q2 Loss=0.6862, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3683
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9925, Q2 Loss=0.9925, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3624
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.1457, Q2 Loss=1.1457, Entropy=0.2529, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7717

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.9%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.1%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000190
Q1 loss: 1.116071
Q2 loss: 1.116071
Current threshold: -26.3545
Global Scale Offset: 0.1769
Reward stats: mean=-0.0021, std=0.1529, count=269
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.1161, Q2 Loss: 1.1161, Entropy: 0.0506, Mean TD Error: 1.3975, Threshold: -26.3545
Original likelihood: -65.17245483398438
Adjusted likelihood: -65.17245483398438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 65.39971923828125
Projection step: 1, Loss: 68.2881851196289
Projection step: 2, Loss: 69.19271850585938
Projection step: 3, Loss: 63.012054443359375
Projection step: 4, Loss: 63.67595291137695
Projection step: 5, Loss: 65.71651458740234
Projection step: 6, Loss: 65.09275817871094
Projection step: 7, Loss: 61.94951629638672
Projection step: 8, Loss: 60.01515579223633
Projection step: 9, Loss: 58.820556640625
Projection step: 10, Loss: 64.61651611328125
Projection step: 11, Loss: 61.096649169921875
Projection step: 12, Loss: 60.98305130004883
Projection step: 13, Loss: 59.878719329833984
Projection step: 14, Loss: 62.107723236083984
Final likelihood: tensor([-61.0911, -60.9461, -62.3446, -66.4538, -55.9263, -53.1958, -55.6880,
        -54.5518, -58.0546, -54.8137, -60.6481, -57.0493, -61.5609, -57.7900,
        -55.2915, -57.0298])
Final projection likelihood: -58.2772
1 mode projection failed, trying anyway
New goal: tensor([ 0.1448,  0.5014,  0.9167,  0.7356,  0.0022,  0.7494,  1.0122,  1.0910,
         1.5144, -0.0656,  0.3121,  0.7739,  0.2986, -0.1774, -1.4671],
       device='cuda:1')
tensor([[0.0036]], device='cuda:1') tensor([[0.0117]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -73.00277709960938
Adjusted likelihood: -73.00277709960938
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 73.00277709960938}
Current yaw: tensor([ 0.3052, -0.1862, -0.6957], device='cuda:1')
5 thumb_middle
tensor([ 0.1468,  0.5457,  0.9034,  0.6947, -0.0519,  0.8191,  1.0449,  0.9784,
         1.5000,  0.0850,  0.3375,  0.7589,  0.3052, -0.1862, -0.6957,  4.7076],
       device='cuda:1')
Solve time for step 1 8.415399688994512
Current ori: tensor([ 0.3052, -0.1862, -0.6957], device='cuda:1')
Index force: tensor([0.6040, 0.6021, 0.6137, 0.5930], device='cuda:1')
tensor([ 5.5515e-02,  6.2738e-01,  9.2632e-01,  7.2682e-01,  9.3417e-03,
         7.9926e-01,  9.8739e-01,  1.0335e+00,  1.3705e+00, -2.7498e-03,
         2.4651e-01,  7.6503e-01,  3.5503e-01, -2.6217e-01, -6.7369e-01,
         5.2849e+00], device='cuda:1')
Solve time for step 2 1.9801781919959467
Current ori: tensor([ 0.3550, -0.2622, -0.6737], device='cuda:1')
Index force: tensor([0.5996, 0.6112, 0.5904], device='cuda:1')
tensor([ 2.1749e-02,  6.4318e-01,  9.3439e-01,  7.3677e-01,  4.9221e-02,
         8.5511e-01,  1.0193e+00,  1.0636e+00,  1.3144e+00, -3.6618e-03,
         1.8516e-01,  7.6427e-01,  3.6148e-01, -2.9576e-01, -5.3587e-01,
         4.5822e+00], device='cuda:1')
Solve time for step 3 1.876212384988321
Current ori: tensor([ 0.3615, -0.2958, -0.5359], device='cuda:1')
Index force: tensor([0.5799, 0.5911], device='cuda:1')
tensor([-0.0306,  0.6637,  0.9393,  0.7400,  0.0697,  0.8780,  1.0402,  1.0738,
         1.2881, -0.0075,  0.1288,  0.7622,  0.3672, -0.3123, -0.4914,  4.7787],
       device='cuda:1')
Solve time for step 4 1.8397961640148424
Current ori: tensor([ 0.3672, -0.3123, -0.4914], device='cuda:1')
Index force: tensor([0.5609], device='cuda:1')
Storing RECOVERY transition: reward=-0.1500 (scaled=-0.0300), steps=5
Reward stats updated: mean -0.0021 -> -0.0023, std: 0.1526
Collected 270 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0002, Q2 Loss=1.0002, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6592
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.7430, Q2 Loss=0.7430, Entropy=0.3464, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3107
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.8285, Q2 Loss=0.8285, Entropy=0.3169, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2922
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=13.0993, Q2 Loss=13.0993, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1535
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9852, Q2 Loss=0.9852, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8468

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.0%)
Actor update: 0.11s (41.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000094
Q1 loss: 3.331253
Q2 loss: 3.331253
Current threshold: -26.3003
Global Scale Offset: 0.1707
Reward stats: mean=-0.0023, std=0.1526, count=270
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 3.3313, Q2 Loss: 3.3313, Entropy: 0.1327, Mean TD Error: 1.4525, Threshold: -26.3003
Original likelihood: -114.29742431640625
Adjusted likelihood: -114.29742431640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 128.0323486328125
Projection step: 1, Loss: 125.22195434570312
Projection step: 2, Loss: 130.53842163085938
Projection step: 3, Loss: 133.47686767578125
Projection step: 4, Loss: 122.17036437988281
Projection step: 5, Loss: 131.09982299804688
Projection step: 6, Loss: 117.92613220214844
Projection step: 7, Loss: 121.94454956054688
Projection step: 8, Loss: 124.29475402832031
Projection step: 9, Loss: 124.48081970214844
Projection step: 10, Loss: 152.20489501953125
Projection step: 11, Loss: 130.9195098876953
Projection step: 12, Loss: 118.70320129394531
Projection step: 13, Loss: 126.23531341552734
Projection step: 14, Loss: 122.82801818847656
Final likelihood: tensor([-130.6095,  -92.2594, -187.4954, -205.1408, -205.3263,  -87.3429,
        -125.2619, -100.2486, -154.7472,  -93.6239, -145.9396,  -88.2551,
         -94.4402, -134.6943,  -95.9707, -113.6687])
Final projection likelihood: -128.4390
1 mode projection failed, trying anyway
New goal: tensor([-0.0217,  0.5832,  0.8771,  0.7059,  0.0736,  0.8511,  1.1216,  1.2879,
         1.3679, -0.0147,  0.1722,  0.7909,  0.3528, -0.2542, -1.2678],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -189.989013671875
Adjusted likelihood: -189.989013671875
Likelihood residual: 0.0
{'index': 189.989013671875, 'thumb_middle': inf}
Current yaw: tensor([ 0.3550, -0.2537, -0.7536], device='cuda:1')
6 index
tensor([-0.0783,  0.6217,  0.9480,  0.7450,  0.0883,  0.9157,  1.1192,  1.1306,
         1.4031, -0.0445,  0.2142,  0.7758,  0.3550, -0.2537, -0.7536,  5.3519],
       device='cuda:1')
Solve time for step 1 10.858300935011357
Current ori: tensor([ 0.3550, -0.2537, -0.7536], device='cuda:1')
Middle force: tensor([0.5917, 0.6135, 0.5557, 0.6150], device='cuda:1')
Thumb force: tensor([0.5710, 0.6522, 0.5308, 0.5586], device='cuda:1')
tensor([ 0.2132,  0.6672,  0.9531,  0.7351,  0.1145,  0.9749,  1.0598,  1.1122,
         1.3919, -0.0062,  0.2084,  0.7825,  0.3552, -0.2602, -0.7327,  5.2119],
       device='cuda:1')
Solve time for step 2 2.274081646988634
Current ori: tensor([ 0.3552, -0.2602, -0.7327], device='cuda:1')
Middle force: tensor([0.5787, 0.5559, 0.5310], device='cuda:1')
Thumb force: tensor([0.6444, 0.6546, 0.5377], device='cuda:1')
tensor([ 0.1918,  0.6998,  0.9615,  0.7342,  0.1255,  1.0027,  1.0254,  1.1064,
         1.3944, -0.0154,  0.2097,  0.7846,  0.3552, -0.2588, -0.7439,  5.0497],
       device='cuda:1')
Solve time for step 3 2.2128530790214427
Current ori: tensor([ 0.3552, -0.2588, -0.7439], device='cuda:1')
Middle force: tensor([0.5203, 0.6022], device='cuda:1')
Thumb force: tensor([0.5020, 0.5225], device='cuda:1')
tensor([ 0.1990,  0.7084,  0.9654,  0.7325,  0.1279,  1.0161,  1.0158,  1.0907,
         1.3950, -0.0194,  0.2015,  0.7853,  0.3552, -0.2598, -0.7388,  5.1431],
       device='cuda:1')
Solve time for step 4 1.945711761014536
Current ori: tensor([ 0.3552, -0.2598, -0.7388], device='cuda:1')
Middle force: tensor([0.5967], device='cuda:1')
Thumb force: tensor([0.5208], device='cuda:1')
Storing RECOVERY transition: reward=-0.1518 (scaled=-0.0304), steps=5
Reward stats updated: mean -0.0023 -> -0.0024, std: 0.1524
Collected 271 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.7547, Q2 Loss=1.7547, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2687
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.4265, Q2 Loss=1.4265, Entropy=0.0016, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9645
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1944, Q2 Loss=1.1944, Entropy=0.0016, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7228
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=1.1480, Q2 Loss=1.1480, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3799
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9988, Q2 Loss=0.9988, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4341

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.6%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (17.5%)
Actor update: 0.08s (37.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004605
Q1 loss: 1.304475
Q2 loss: 1.304475
Current threshold: -26.2664
Global Scale Offset: 0.1672
Reward stats: mean=-0.0024, std=0.1524, count=271
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.3045, Q2 Loss: 1.3045, Entropy: 0.0006, Mean TD Error: 1.7540, Threshold: -26.2664
Original likelihood: -135.11431884765625
Adjusted likelihood: -135.11431884765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 156.5226593017578
Projection step: 1, Loss: 128.8660125732422
Projection step: 2, Loss: 135.23699951171875
Projection step: 3, Loss: 132.07839965820312
Projection step: 4, Loss: 147.6396942138672
Projection step: 5, Loss: 151.83058166503906
Projection step: 6, Loss: 147.40728759765625
Projection step: 7, Loss: 146.04098510742188
Projection step: 8, Loss: 138.02774047851562
Projection step: 9, Loss: 128.03768920898438
Projection step: 10, Loss: 122.50267028808594
Projection step: 11, Loss: 113.56169128417969
Projection step: 12, Loss: 109.43340301513672
Projection step: 13, Loss: 126.25023651123047
Projection step: 14, Loss: 131.173828125
Final likelihood: tensor([-100.8986, -106.6321, -138.8036, -135.3180, -108.9577, -122.5372,
        -114.7951, -127.2837, -168.0037, -122.4959, -164.4991, -110.6865,
        -123.4577,  -98.4509, -133.9579,  -87.5305])
Final projection likelihood: -122.7693
1 mode projection failed, trying anyway
New goal: tensor([ 0.0908,  0.6709,  0.8587,  0.7098,  0.0830,  0.9195,  1.0482,  1.2825,
         1.3570, -0.0173,  0.1768,  0.8415,  0.3533, -0.2567, -1.1946],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0018]], device='cuda:1') tensor([[0.0045]], device='cuda:1')
Original likelihood: -238.84060668945312
Adjusted likelihood: -238.84060668945312
Likelihood residual: 0.0
{'index': 238.84060668945312, 'thumb_middle': inf}
Current yaw: tensor([ 0.3547, -0.2563, -0.7750], device='cuda:1')
7 index
tensor([ 0.0482,  0.7178,  0.9631,  0.7316,  0.0970,  0.9848,  1.0380,  1.1397,
         1.3983, -0.0393,  0.2080,  0.7847,  0.3547, -0.2563, -0.7750,  5.2738],
       device='cuda:1')
Solve time for step 1 10.758639162988402
Current ori: tensor([ 0.3547, -0.2563, -0.7750], device='cuda:1')
Middle force: tensor([0.5175, 0.5734, 0.6003, 0.5209], device='cuda:1')
Thumb force: tensor([0.5747, 0.5334, 0.5680, 0.5193], device='cuda:1')
tensor([ 0.2851,  0.6884,  0.9524,  0.7420,  0.1387,  1.0356,  0.9896,  1.1064,
         1.3856,  0.0056,  0.1914,  0.8268,  0.3554, -0.2658, -0.7552,  5.1759],
       device='cuda:1')
Solve time for step 2 2.2951078280166257
Current ori: tensor([ 0.3554, -0.2658, -0.7552], device='cuda:1')
Middle force: tensor([0.5723, 0.5988, 0.5197], device='cuda:1')
Thumb force: tensor([0.5313, 0.5670, 0.5183], device='cuda:1')
tensor([ 2.2824e-01,  7.4761e-01,  9.5658e-01,  7.3658e-01,  1.5697e-01,
         1.0639e+00,  9.6548e-01,  1.0788e+00,  1.3841e+00,  3.0971e-03,
         1.7700e-01,  8.3414e-01,  3.5532e-01, -2.6823e-01, -7.6722e-01,
         5.1212e+00], device='cuda:1')
Solve time for step 3 2.2143352320126723
Current ori: tensor([ 0.3553, -0.2682, -0.7672], device='cuda:1')
Middle force: tensor([0.5984, 0.5186], device='cuda:1')
Thumb force: tensor([0.5646, 0.5173], device='cuda:1')
tensor([ 0.2430,  0.7221,  0.9517,  0.7392,  0.1704,  1.0809,  0.9623,  1.0316,
         1.3821,  0.0105,  0.1759,  0.8322,  0.3554, -0.2696, -0.7657,  5.1711],
       device='cuda:1')
Solve time for step 4 2.151251865987433
Current ori: tensor([ 0.3554, -0.2696, -0.7657], device='cuda:1')
Middle force: tensor([0.5175], device='cuda:1')
Thumb force: tensor([0.5157], device='cuda:1')
Storing RECOVERY transition: reward=-0.1569 (scaled=-0.0314), steps=5
Reward stats updated: mean -0.0024 -> -0.0025, std: 0.1521
Collected 272 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8975, Q2 Loss=0.8975, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2423
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0817, Q2 Loss=1.0817, Entropy=0.0023, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2695
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2113, Q2 Loss=1.2113, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5540
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3197, Q2 Loss=1.3197, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5016
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6737, Q2 Loss=0.6737, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1383

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (39.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.036770
Q2 loss: 1.036770
Current threshold: -26.2461
Global Scale Offset: 0.1651
Reward stats: mean=-0.0025, std=0.1521, count=272
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0368, Q2 Loss: 1.0368, Entropy: 0.0005, Mean TD Error: 0.5411, Threshold: -26.2461
Original likelihood: -152.1432647705078
Adjusted likelihood: -152.1432647705078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 150.80043029785156
Projection step: 1, Loss: 163.88916015625
Projection step: 2, Loss: 159.3275146484375
Projection step: 3, Loss: 162.6649169921875
Projection step: 4, Loss: 153.83811950683594
Projection step: 5, Loss: 158.389892578125
Projection step: 6, Loss: 149.7477264404297
Projection step: 7, Loss: 144.35140991210938
Projection step: 8, Loss: 156.62269592285156
Projection step: 9, Loss: 160.28964233398438
Projection step: 10, Loss: 155.22325134277344
Projection step: 11, Loss: 151.289794921875
Projection step: 12, Loss: 153.879638671875
Projection step: 13, Loss: 147.99334716796875
Projection step: 14, Loss: 158.94720458984375
Final likelihood: tensor([ -90.2706, -212.9955, -177.5417, -153.4492, -180.2303, -170.0426,
        -103.5697, -209.5179, -169.6479, -130.7570, -146.1800, -177.3102,
        -106.5059, -166.7670, -211.1784, -161.9385])
Final projection likelihood: -160.4939
1 mode projection failed, trying anyway
New goal: tensor([ 0.1484,  0.7498,  0.8627,  0.7420,  0.1144,  0.9870,  0.9627,  1.2579,
         1.3415, -0.0081,  0.1671,  0.8999,  0.3543, -0.2625, -1.0349],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0046]], device='cuda:1')
Original likelihood: -210.78790283203125
Adjusted likelihood: -210.78790283203125
Likelihood residual: 0.0
{'index': 210.78790283203125, 'thumb_middle': inf}
Current yaw: tensor([ 0.3546, -0.2617, -0.8015], device='cuda:1')
8 index
tensor([ 0.1097,  0.7808,  0.9467,  0.7365,  0.1277,  1.0441,  0.9642,  1.1403,
         1.3956, -0.0473,  0.1753,  0.8359,  0.3546, -0.2617, -0.8015,  5.2454],
       device='cuda:1')
Solve time for step 1 10.824582875997294
Current ori: tensor([ 0.3546, -0.2617, -0.8015], device='cuda:1')
Middle force: tensor([0.5542, 0.5099, 0.5686, 0.5083], device='cuda:1')
Thumb force: tensor([0.5243, 0.6100, 0.6547, 0.5395], device='cuda:1')
tensor([ 0.1945,  0.7554,  0.9545,  0.7621,  0.1536,  1.0885,  0.9148,  1.1262,
         1.3840, -0.0084,  0.1707,  0.8826,  0.3549, -0.2685, -0.7946,  5.2072],
       device='cuda:1')
Solve time for step 2 2.4142338300007395
Current ori: tensor([ 0.3549, -0.2685, -0.7946], device='cuda:1')
Middle force: tensor([0.5998, 0.5385, 0.6162], device='cuda:1')
Thumb force: tensor([0.5180, 0.6306, 0.6110], device='cuda:1')
tensor([ 2.1661e-01,  7.9637e-01,  9.6263e-01,  7.6649e-01,  1.6338e-01,
         1.1026e+00,  9.0243e-01,  1.1155e+00,  1.3807e+00, -2.5146e-03,
         1.5712e-01,  8.9318e-01,  3.5496e-01, -2.7213e-01, -7.9638e-01,
         5.1750e+00], device='cuda:1')
Solve time for step 3 2.19808724601171
Current ori: tensor([ 0.3550, -0.2721, -0.7964], device='cuda:1')
Middle force: tensor([0.5351, 0.6142], device='cuda:1')
Thumb force: tensor([0.6292, 0.6097], device='cuda:1')
tensor([ 0.2302,  0.8501,  0.9639,  0.7711,  0.1721,  1.1089,  0.9121,  1.0958,
         1.3666,  0.0438,  0.1533,  0.8964,  0.3573, -0.2806, -0.8168,  5.2054],
       device='cuda:1')
Solve time for step 4 2.1304625640041195
Current ori: tensor([ 0.3573, -0.2806, -0.8168], device='cuda:1')
Middle force: tensor([0.6117], device='cuda:1')
Thumb force: tensor([0.6059], device='cuda:1')
Storing RECOVERY transition: reward=-0.1863 (scaled=-0.0373), steps=5
Reward stats updated: mean -0.0025 -> -0.0026, std: 0.1518
Collected 273 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0820, Q2 Loss=1.0820, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3715
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3024, Q2 Loss=1.3024, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8103
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9564, Q2 Loss=0.9564, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2868
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=1.2673, Q2 Loss=1.2673, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3141
SAC Update 5/5: Actor Loss=-0.0012, Q1 Loss=1.0034, Q2 Loss=1.0034, Entropy=0.1404, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4229

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.04s (18.1%)
Actor update: 0.10s (43.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004851
Q1 loss: 1.122298
Q2 loss: 1.122298
Current threshold: -26.2321
Global Scale Offset: 0.1638
Reward stats: mean=-0.0026, std=0.1518, count=273
----------------------------------------------
SAC Update - Actor Loss: -0.0049, Q1 Loss: 1.1223, Q2 Loss: 1.1223, Entropy: 0.0281, Mean TD Error: 0.4411, Threshold: -26.2321
Original likelihood: -178.42648315429688
Adjusted likelihood: -178.42648315429688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 174.3057403564453
Projection step: 1, Loss: 176.083984375
Projection step: 2, Loss: 186.20913696289062
Projection step: 3, Loss: 179.73394775390625
Projection step: 4, Loss: 178.67919921875
Projection step: 5, Loss: 177.3176727294922
Projection step: 6, Loss: 178.80972290039062
Projection step: 7, Loss: 174.1403350830078
Projection step: 8, Loss: 183.30667114257812
Projection step: 9, Loss: 186.95590209960938
Projection step: 10, Loss: 190.9375457763672
Projection step: 11, Loss: 173.92112731933594
Projection step: 12, Loss: 178.640869140625
Projection step: 13, Loss: 168.8397216796875
Projection step: 14, Loss: 174.38314819335938
Final likelihood: tensor([-196.9253, -258.7006, -140.1961, -234.6204, -136.7937, -235.3324,
        -183.7244, -153.1037, -140.8081, -172.8848, -178.5536, -197.2531,
        -188.8329, -180.5326, -153.8374, -193.4773])
Final projection likelihood: -184.0985
1 mode projection failed, trying anyway
New goal: tensor([ 0.1546,  0.7884,  0.9137,  0.7832,  0.1166,  1.0230,  0.9202,  1.2786,
         1.3231,  0.0244,  0.1894,  0.9460,  0.3560, -0.2715, -1.0497],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0054]], device='cuda:1')
Original likelihood: -240.93223571777344
Adjusted likelihood: -240.93223571777344
Likelihood residual: 0.0
{'index': 240.93223571777344, 'thumb_middle': inf}
Current yaw: tensor([ 0.3556, -0.2703, -0.9082], device='cuda:1')
9 index
tensor([ 0.1173,  0.8104,  0.9665,  0.7720,  0.1270,  1.0635,  0.9258,  1.1893,
         1.3745, -0.0114,  0.1881,  0.8933,  0.3556, -0.2703, -0.9082,  5.3116],
       device='cuda:1')
Solve time for step 1 11.023213389999
Current ori: tensor([ 0.3556, -0.2703, -0.9082], device='cuda:1')
Middle force: tensor([0.5562, 0.5742, 0.5704, 0.5375], device='cuda:1')
Thumb force: tensor([0.6416, 0.5454, 0.5712, 0.6072], device='cuda:1')
tensor([ 0.3009,  0.7433,  1.0027,  0.8054,  0.1582,  1.1051,  0.8909,  1.1572,
         1.3601,  0.0396,  0.1831,  0.9317,  0.3571, -0.2783, -0.8897,  5.2946],
       device='cuda:1')
Solve time for step 2 2.3566245590045583
Current ori: tensor([ 0.3571, -0.2783, -0.8897], device='cuda:1')
Middle force: tensor([0.5005, 0.5337, 0.6199], device='cuda:1')
Thumb force: tensor([0.5091, 0.6598, 0.5831], device='cuda:1')
tensor([ 0.3224,  0.8167,  1.0175,  0.8194,  0.1653,  1.1194,  0.8739,  1.1624,
         1.3580,  0.0436,  0.1680,  0.9437,  0.3580, -0.2819, -0.8998,  5.2811],
       device='cuda:1')
Solve time for step 3 2.197533245984232
Current ori: tensor([ 0.3580, -0.2819, -0.8998], device='cuda:1')
Middle force: tensor([0.5316, 0.6183], device='cuda:1')
Thumb force: tensor([0.6547, 0.5822], device='cuda:1')
tensor([ 0.3210,  0.8364,  1.0220,  0.8161,  0.1804,  1.1292,  0.8797,  1.1265,
         1.3464,  0.0918,  0.1804,  0.9396,  0.3591, -0.2870, -0.8701,  5.2448],
       device='cuda:1')
Solve time for step 4 2.1180471870175097
Current ori: tensor([ 0.3591, -0.2870, -0.8701], device='cuda:1')
Middle force: tensor([0.6158], device='cuda:1')
Thumb force: tensor([0.5793], device='cuda:1')
Storing RECOVERY transition: reward=-0.2143 (scaled=-0.0429), steps=5
Reward stats updated: mean -0.0026 -> -0.0027, std: 0.1516
Collected 274 transitions for RL
SAC Update 1/5: Actor Loss=-0.0008, Q1 Loss=0.6913, Q2 Loss=0.6913, Entropy=0.3425, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1790
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=13.1070, Q2 Loss=13.1070, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2105
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3145, Q2 Loss=1.3145, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1910
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.2368, Q2 Loss=1.2368, Entropy=0.3222, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4014
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7862, Q2 Loss=0.7862, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4698

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (19.2%)
Actor update: 0.12s (39.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000237
Q1 loss: 3.427138
Q2 loss: 3.427138
Current threshold: -26.2071
Global Scale Offset: 0.1628
Reward stats: mean=-0.0027, std=0.1516, count=274
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 3.4271, Q2 Loss: 3.4271, Entropy: 0.1329, Mean TD Error: 2.2904, Threshold: -26.2071
Original likelihood: -182.8345489501953
Adjusted likelihood: -182.8345489501953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 198.63497924804688
Projection step: 1, Loss: 194.88909912109375
Projection step: 2, Loss: 226.21160888671875
Projection step: 3, Loss: 203.9365692138672
Projection step: 4, Loss: 195.76914978027344
Projection step: 5, Loss: 188.0611114501953
Projection step: 6, Loss: 177.69781494140625
Projection step: 7, Loss: 176.24765014648438
Projection step: 8, Loss: 181.96633911132812
Projection step: 9, Loss: 220.00604248046875
Projection step: 10, Loss: 191.03538513183594
Projection step: 11, Loss: 186.16954040527344
Projection step: 12, Loss: 195.66921997070312
Projection step: 13, Loss: 177.08050537109375
Projection step: 14, Loss: 182.60580444335938
Final likelihood: tensor([-205.0722, -295.1642, -181.0832, -165.5196, -249.0542, -212.2317,
        -138.1613, -180.1854, -200.6750, -225.0944, -197.8056, -195.2431,
        -172.9154, -161.2565, -218.5107, -194.6674])
Final projection likelihood: -199.5400
1 mode projection failed, trying anyway
New goal: tensor([ 0.2044,  0.8311,  0.9899,  0.8375,  0.1268,  1.0519,  0.8741,  1.2983,
         1.3109,  0.0475,  0.2151,  0.9913,  0.3567, -0.2750, -1.0380],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0048]], device='cuda:1')
Original likelihood: -220.61968994140625
Adjusted likelihood: -220.61968994140625
Likelihood residual: 0.0
{'index': 220.61968994140625, 'thumb_middle': inf}
Current yaw: tensor([ 0.3565, -0.2740, -0.9739], device='cuda:1')
10 index
tensor([ 0.1720,  0.8510,  1.0279,  0.8204,  0.1347,  1.0814,  0.8897,  1.2304,
         1.3621,  0.0317,  0.2108,  0.9381,  0.3565, -0.2740, -0.9739,  5.3648],
       device='cuda:1')
Solve time for step 1 11.499911375984084
Current ori: tensor([ 0.3565, -0.2740, -0.9739], device='cuda:1')
Middle force: tensor([0.5613, 0.6311, 0.5728, 0.6030], device='cuda:1')
Thumb force: tensor([0.6013, 0.5371, 0.5951, 0.6131], device='cuda:1')
tensor([ 0.3504,  0.8090,  1.0807,  0.8605,  0.1627,  1.1178,  0.8559,  1.2078,
         1.3491,  0.0783,  0.2072,  0.9820,  0.3576, -0.2813, -0.9499,  5.3562],
       device='cuda:1')
Solve time for step 2 2.2945935700263362
Current ori: tensor([ 0.3576, -0.2813, -0.9499], device='cuda:1')
Middle force: tensor([0.6254, 0.5714, 0.5999], device='cuda:1')
Thumb force: tensor([0.5346, 0.5902, 0.6138], device='cuda:1')
tensor([ 0.3109,  0.8422,  1.0858,  0.8656,  0.1727,  1.1354,  0.8368,  1.1989,
         1.3528,  0.0602,  0.1872,  0.9857,  0.3577, -0.2826, -0.9639,  5.3466],
       device='cuda:1')
Solve time for step 3 2.2148279109969735
Current ori: tensor([ 0.3577, -0.2826, -0.9639], device='cuda:1')
Middle force: tensor([0.5692, 0.5977], device='cuda:1')
Thumb force: tensor([0.5860, 0.6129], device='cuda:1')
tensor([ 0.2944,  0.8628,  1.0846,  0.8610,  0.1746,  1.1410,  0.8278,  1.1980,
         1.3539,  0.0572,  0.1991,  0.9877,  0.3573, -0.2800, -0.9717,  5.3490],
       device='cuda:1')
Solve time for step 4 2.1362134579976555
Current ori: tensor([ 0.3573, -0.2800, -0.9717], device='cuda:1')
Middle force: tensor([0.5754], device='cuda:1')
Thumb force: tensor([0.6028], device='cuda:1')
Storing RECOVERY transition: reward=-0.2194 (scaled=-0.0439), steps=5
Reward stats updated: mean -0.0027 -> -0.0029, std: 0.1513
Collected 275 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2567, Q2 Loss=1.2567, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6302
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1098, Q2 Loss=1.1098, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5256
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0674, Q2 Loss=1.0674, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4558
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.8345, Q2 Loss=0.8345, Entropy=0.3345, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3066
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2940, Q2 Loss=1.2940, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3769

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (20.1%)
Actor update: 0.12s (41.5%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000099
Q1 loss: 1.112482
Q2 loss: 1.112482
Current threshold: -26.1874
Global Scale Offset: 0.1623
Reward stats: mean=-0.0029, std=0.1513, count=275
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.1125, Q2 Loss: 1.1125, Entropy: 0.0669, Mean TD Error: 0.8590, Threshold: -26.1874
Original likelihood: -240.2044677734375
Adjusted likelihood: -240.2044677734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 229.4647216796875
Projection step: 1, Loss: 227.27383422851562
Projection step: 2, Loss: 230.330322265625
Projection step: 3, Loss: 218.10418701171875
Projection step: 4, Loss: 225.3395233154297
Projection step: 5, Loss: 230.5945587158203
Projection step: 6, Loss: 214.55165100097656
Projection step: 7, Loss: 231.72972106933594
Projection step: 8, Loss: 241.68093872070312
Projection step: 9, Loss: 241.66659545898438
Projection step: 10, Loss: 216.6541748046875
Projection step: 11, Loss: 254.27468872070312
Projection step: 12, Loss: 239.4017333984375
Projection step: 13, Loss: 238.06466674804688
Projection step: 14, Loss: 216.2046356201172
Final likelihood: tensor([-168.5973, -224.5979, -277.9357, -241.8718, -288.6970, -206.5160,
        -217.3244, -211.5468, -269.8344, -230.9874, -185.8003, -152.0842,
        -234.3899, -183.4726, -240.9805, -210.7630])
Final projection likelihood: -221.5874
1 mode projection failed, trying anyway
New goal: tensor([ 0.3332,  0.9579,  1.0683,  0.8752,  0.1600,  1.1286,  0.8036,  1.2401,
         1.3039,  0.0783,  0.2231,  1.0296,  0.3570, -0.2830, -0.9807],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -201.75738525390625
Adjusted likelihood: -201.75738525390625
Likelihood residual: 0.0
Original likelihood: -235.0538330078125
Adjusted likelihood: -235.0538330078125
Likelihood residual: 0.0
{'index': 235.0538330078125, 'thumb_middle': 201.75738525390625}
Current yaw: tensor([ 0.3567, -0.2818, -0.9752], device='cuda:1')
11 thumb_middle
tensor([ 0.3111,  0.9696,  1.0644,  0.8529,  0.1649,  1.1403,  0.8265,  1.2090,
         1.3483,  0.0726,  0.2148,  0.9880,  0.3567, -0.2818, -0.9752,  5.3729],
       device='cuda:1')
Solve time for step 1 9.588778502016794
Current ori: tensor([ 0.3567, -0.2818, -0.9752], device='cuda:1')
Index force: tensor([0.5726, 0.5810, 0.5746, 0.5836], device='cuda:1')
tensor([ 0.3157,  1.0059,  1.0600,  0.8557,  0.1621,  1.1113,  0.7157,  1.1608,
         1.2661,  0.1264,  0.1306,  1.0418,  0.3720, -0.3284, -0.8710,  5.2253],
       device='cuda:1')
Solve time for step 2 1.9813242600066587
Current ori: tensor([ 0.3720, -0.3284, -0.8710], device='cuda:1')
Index force: tensor([0.5859, 0.5895, 0.5990], device='cuda:1')
tensor([ 0.3051,  1.0203,  1.0894,  0.8710,  0.1587,  1.1238,  0.7085,  1.1553,
         1.2303,  0.1221,  0.0658,  1.0387,  0.3792, -0.3477, -0.8236,  5.1078],
       device='cuda:1')
Solve time for step 3 1.94329814001685
Current ori: tensor([ 0.3792, -0.3477, -0.8236], device='cuda:1')
Index force: tensor([0.5878, 0.5978], device='cuda:1')
tensor([ 0.2948,  1.0662,  1.0512,  0.8354,  0.1616,  1.1543,  0.7268,  1.1681,
         1.2441,  0.1147,  0.0352,  1.0257,  0.3786, -0.3459, -0.8282,  5.1396],
       device='cuda:1')
Solve time for step 4 1.8066776210034732
Current ori: tensor([ 0.3786, -0.3459, -0.8282], device='cuda:1')
Index force: tensor([0.5680], device='cuda:1')
Storing RECOVERY transition: reward=-0.2312 (scaled=-0.0462), steps=5
Reward stats updated: mean -0.0029 -> -0.0030, std: 0.1511
Collected 276 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.5807, Q2 Loss=1.5807, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2642
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.7379, Q2 Loss=0.7379, Entropy=0.3414, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3558
SAC Update 3/5: Actor Loss=-0.0014, Q1 Loss=1.6431, Q2 Loss=1.6431, Entropy=0.2823, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2604
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.4709, Q2 Loss=1.4709, Entropy=0.0025, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9583
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6875, Q2 Loss=1.6875, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2700

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.6%)
Q1 update: 0.05s (20.9%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (38.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000445
Q1 loss: 1.424007
Q2 loss: 1.424007
Current threshold: -26.1577
Global Scale Offset: 0.1618
Reward stats: mean=-0.0030, std=0.1511, count=276
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.4240, Q2 Loss: 1.4240, Entropy: 0.1252, Mean TD Error: 3.4217, Threshold: -26.1577
Original likelihood: -288.65106201171875
Adjusted likelihood: -288.65106201171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 308.0028076171875
Projection step: 1, Loss: 293.9517822265625
Projection step: 2, Loss: 284.74853515625
Projection step: 3, Loss: 309.10125732421875
Projection step: 4, Loss: 285.1239013671875
Projection step: 5, Loss: 287.2755126953125
Projection step: 6, Loss: 312.19061279296875
Projection step: 7, Loss: 287.5858459472656
Projection step: 8, Loss: 294.72613525390625
Projection step: 9, Loss: 300.6240234375
Projection step: 10, Loss: 288.84857177734375
Projection step: 11, Loss: 291.3056640625
Projection step: 12, Loss: 281.4569091796875
Projection step: 13, Loss: 286.2584533691406
Projection step: 14, Loss: 291.20452880859375
Final likelihood: tensor([-302.3352, -230.7684, -273.9160, -320.2683, -278.9731, -294.1987,
        -316.8178, -298.3208, -325.1904, -323.3431, -337.4200, -258.1958,
        -275.1112, -313.2891, -327.0974, -217.9841])
Final projection likelihood: -293.3268
1 mode projection failed, trying anyway
New goal: tensor([ 0.2491,  1.0518,  1.0661,  0.8511,  0.1674,  1.1985,  0.7770,  1.2330,
         1.2950,  0.0559,  0.0722,  1.0201,  0.3660, -0.3121, -0.9341],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0069]], device='cuda:1')
Original likelihood: -207.62454223632812
Adjusted likelihood: -207.62454223632812
Likelihood residual: 0.0
Original likelihood: -317.2302551269531
Adjusted likelihood: -317.2302551269531
Likelihood residual: 0.0
{'index': 317.2302551269531, 'thumb_middle': 207.62454223632812}
Current yaw: tensor([ 0.3657, -0.3109, -0.9471], device='cuda:1')
12 thumb_middle
tensor([ 0.2348,  1.0557,  1.0476,  0.8439,  0.1669,  1.1976,  0.7909,  1.2192,
         1.3220,  0.0501,  0.0718,  1.0033,  0.3657, -0.3109, -0.9471,  5.3118],
       device='cuda:1')
Solve time for step 1 9.895959043991752
Current ori: tensor([ 0.3657, -0.3109, -0.9471], device='cuda:1')
Index force: tensor([0.5896, 0.5816, 0.5970, 0.5986], device='cuda:1')
tensor([ 0.1943,  1.1206,  1.0722,  0.8531,  0.1707,  1.1712,  0.6894,  1.1549,
         1.2451,  0.0806, -0.0710,  1.0129,  0.3799, -0.3498, -0.8216,  5.1710],
       device='cuda:1')
Solve time for step 2 2.1321474599826615
Current ori: tensor([ 0.3799, -0.3498, -0.8216], device='cuda:1')
Index force: tensor([0.5796, 0.5936, 0.5948], device='cuda:1')
tensor([ 0.1421,  1.1126,  1.1004,  0.9695,  0.1645,  1.1862,  0.6764,  1.1515,
         1.2501,  0.0600, -0.0545,  1.0176,  0.3785, -0.3457, -0.8299,  5.1099],
       device='cuda:1')
Solve time for step 3 2.266140694002388
Current ori: tensor([ 0.3785, -0.3457, -0.8299], device='cuda:1')
Index force: tensor([0.5778, 0.5963], device='cuda:1')
tensor([ 0.1062,  1.1250,  1.1233,  0.9322,  0.1561,  1.1979,  0.6776,  1.1508,
         1.1781,  0.0841, -0.1203,  1.0157,  0.3879, -0.3697, -0.7818,  5.0886],
       device='cuda:1')
Solve time for step 4 2.0005010869936086
Current ori: tensor([ 0.3879, -0.3697, -0.7818], device='cuda:1')
Index force: tensor([0.5868], device='cuda:1')
Storing RECOVERY transition: reward=-0.2377 (scaled=-0.0475), steps=5
Reward stats updated: mean -0.0030 -> -0.0032, std: 0.1508
Collected 277 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9810, Q2 Loss=0.9810, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1763
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8266, Q2 Loss=0.8266, Entropy=0.1187, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0968
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6964, Q2 Loss=0.6964, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2338
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2894, Q2 Loss=1.2894, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1446
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.9566, Q2 Loss=1.9566, Entropy=0.0021, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3505

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.3%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.05s (17.3%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000013
Q1 loss: 1.149989
Q2 loss: 1.149989
Current threshold: -26.1338
Global Scale Offset: 0.1615
Reward stats: mean=-0.0032, std=0.1508, count=277
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.1500, Q2 Loss: 1.1500, Entropy: 0.0242, Mean TD Error: 1.6004, Threshold: -26.1338
Original likelihood: -350.30438232421875
Adjusted likelihood: -350.30438232421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 16
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.7328722509846557
tensor([ 0.1429,  0.6288,  0.5114,  0.6531, -0.0971,  0.5233,  0.8939,  0.8871,
         1.2214,  0.2449,  0.2849,  1.1977, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -21.75077247619629
Adjusted likelihood: -21.75077247619629
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.722392021009
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([0.5341, 0.5698, 1.2449, 0.5691, 1.2201, 0.6580, 0.5404, 0.5236, 0.5118,
        0.9046, 0.7080, 0.4865], device='cuda:1')
Thumb force: tensor([0.9000, 0.8759, 0.8163, 1.0479, 0.9748, 0.6519, 0.5202, 0.8915, 0.5402,
        0.5315, 0.5422, 0.5492], device='cuda:1')
Index force: tensor([0.6205, 0.6220, 0.5461, 0.5723, 0.8248, 0.5274, 1.0228, 1.0055, 0.5568,
        0.6119, 0.5875, 0.7197], device='cuda:1')
Storing NORMAL transition: reward=-0.0308 (scaled=-0.0308), steps=1
Reward stats updated: mean -0.0032 -> -0.0033, std: 0.1505
Collected 278 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3806, Q2 Loss=1.3806, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6614
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.4266, Q2 Loss=1.4266, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2503
SAC Update 3/5: Actor Loss=-0.0030, Q1 Loss=0.7764, Q2 Loss=0.7764, Entropy=0.0991, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4034
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2381, Q2 Loss=1.2381, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1002
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2512, Q2 Loss=1.2512, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8282

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.1%)
Q1 update: 0.07s (21.1%)
Q2 update: 0.06s (20.1%)
Actor update: 0.13s (40.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000600
Q1 loss: 1.214566
Q2 loss: 1.214566
Current threshold: -26.1070
Global Scale Offset: 0.1609
Reward stats: mean=-0.0033, std=0.1505, count=278
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 1.2146, Q2 Loss: 1.2146, Entropy: 0.0198, Mean TD Error: 1.4487, Threshold: -26.1070
tensor([ 1.3246e-01,  6.8269e-01,  4.2774e-01,  6.4722e-01, -8.6304e-02,
         5.6795e-01,  7.7099e-01,  9.0659e-01,  1.3452e+00,  9.9384e-02,
         2.0578e-01,  1.2832e+00, -1.2809e-02,  1.6680e-02, -3.4291e-04,
         2.0653e-01], device='cuda:1')
Original likelihood: -22.09322738647461
Adjusted likelihood: -22.09322738647461
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.186543638992589
Current ori: tensor([-0.0128,  0.0167, -0.0003], device='cuda:1')
Middle force: tensor([0.5688, 1.2308, 0.5657, 1.1980, 0.6537, 0.5398, 0.5190, 0.5113, 0.8899,
        0.7040, 0.5022], device='cuda:1')
Thumb force: tensor([0.8645, 0.8124, 1.0400, 0.9758, 0.6458, 0.5190, 0.8959, 0.5381, 0.5324,
        0.5407, 0.5465], device='cuda:1')
Index force: tensor([0.6168, 0.5446, 0.5699, 0.8156, 0.5266, 1.0122, 1.0032, 0.5552, 0.6078,
        0.5848, 0.7215], device='cuda:1')
Storing NORMAL transition: reward=0.0400 (scaled=0.0400), steps=1
Reward stats updated: mean -0.0033 -> -0.0031, std: 0.1503
Collected 279 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2164, Q2 Loss=1.2164, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8153
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0987, Q2 Loss=1.0987, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3425
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1812, Q2 Loss=1.1812, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5230
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2088, Q2 Loss=1.2088, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9862
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1025, Q2 Loss=1.1025, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9059

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.0%)
Q1 update: 0.07s (20.4%)
Q2 update: 0.06s (19.8%)
Actor update: 0.13s (41.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.161536
Q2 loss: 1.161536
Current threshold: -26.0848
Global Scale Offset: 0.1603
Reward stats: mean=-0.0031, std=0.1503, count=279
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.1615, Q2 Loss: 1.1615, Entropy: 0.0000, Mean TD Error: 0.7146, Threshold: -26.0848
tensor([ 0.3099,  0.7535,  0.4920,  0.5388, -0.1874,  0.5472,  0.7888,  0.9256,
         1.4350,  0.1889,  0.1402,  1.1444, -0.0604,  0.0744, -0.0490, -2.4162],
       device='cuda:1')
Original likelihood: -35.480804443359375
Adjusted likelihood: -35.480804443359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 36.887325286865234
Projection step: 1, Loss: 36.01776123046875
Projection step: 2, Loss: 30.89710235595703
Projection step: 3, Loss: 32.21949005126953
Projection step: 4, Loss: 29.870004653930664
Projection step: 5, Loss: 30.53742218017578
Projection step: 6, Loss: 29.258604049682617
Projection step: 7, Loss: 27.274919509887695
Projection step: 8, Loss: 27.684131622314453
Projection step: 9, Loss: 28.558303833007812
Projection step: 10, Loss: 28.388763427734375
Projection step: 11, Loss: 25.972003936767578
Projection step: 12, Loss: 25.60429573059082
Projection step: 13, Loss: 25.99530029296875
Projection step: 14, Loss: 24.304954528808594
Final likelihood: tensor([-22.0502, -22.4213, -22.1652, -27.3815, -24.1024, -22.6447, -24.5318,
        -24.9849, -23.8253, -22.2971, -23.1247, -24.4864, -23.4508, -22.3339,
        -25.1665, -22.1230])
Final projection likelihood: -23.5681
1 mode projection succeeded
New goal: tensor([ 0.2290,  0.7090,  0.4997,  0.6082, -0.1083,  0.4977,  0.6633,  0.9959,
         1.3846,  0.1033,  0.1757,  1.0042, -0.0641,  0.0544,  2.1797],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0126]], device='cuda:1')
Original likelihood: -28.663246154785156
Adjusted likelihood: -28.663246154785156
Likelihood residual: 0.0
{'index': 28.663246154785156, 'thumb_middle': inf}
Current yaw: tensor([-0.0604,  0.0744, -0.0490], device='cuda:1')
2 index
tensor([ 0.3099,  0.7535,  0.4920,  0.5388, -0.1874,  0.5472,  0.7888,  0.9256,
         1.4350,  0.1889,  0.1402,  1.1444, -0.0604,  0.0744, -0.0490, -2.4162],
       device='cuda:1')
Solve time for step 1 11.065272022999125
Current ori: tensor([-0.0604,  0.0744, -0.0490], device='cuda:1')
Middle force: tensor([0.5560, 0.6017, 0.6006, 0.5516], device='cuda:1')
Thumb force: tensor([0.6008, 0.5592, 0.5987, 0.5509], device='cuda:1')
tensor([ 0.2888,  0.7099,  0.4863,  0.5858, -0.1909,  0.5892,  0.7055,  0.9661,
         1.4605,  0.1581,  0.1479,  1.0882, -0.0741,  0.0799, -0.0773, -4.1718],
       device='cuda:1')
Solve time for step 2 2.520647914003348
Current ori: tensor([-0.0741,  0.0799, -0.0773], device='cuda:1')
Middle force: tensor([0.5981, 0.5397, 0.5247], device='cuda:1')
Thumb force: tensor([0.5329, 0.5382, 0.5592], device='cuda:1')
tensor([ 0.2818,  0.7109,  0.4889,  0.5955, -0.1895,  0.5987,  0.6896,  0.9726,
         1.4654,  0.1484,  0.1425,  1.0909, -0.0756,  0.0791, -0.0722, -5.6179],
       device='cuda:1')
Solve time for step 3 2.4247872740088496
Current ori: tensor([-0.0756,  0.0791, -0.0722], device='cuda:1')
Middle force: tensor([0.5003, 0.5394], device='cuda:1')
Thumb force: tensor([0.6024, 0.5513], device='cuda:1')
tensor([ 0.2822,  0.7130,  0.4857,  0.5978, -0.1766,  0.6176,  0.6761,  0.9612,
         1.4477,  0.1740,  0.1398,  1.0856, -0.0831,  0.0710, -0.0737, -6.2453],
       device='cuda:1')
Solve time for step 4 2.3574299379833974
Current ori: tensor([-0.0831,  0.0710, -0.0737], device='cuda:1')
Middle force: tensor([0.5920], device='cuda:1')
Thumb force: tensor([0.5454], device='cuda:1')
Storing RECOVERY transition: reward=0.0247 (scaled=0.0124), steps=2
Reward stats updated: mean -0.0031 -> -0.0031, std: 0.1500
Collected 280 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6672, Q2 Loss=0.6672, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1567
SAC Update 2/5: Actor Loss=-0.0230, Q1 Loss=3.1780, Q2 Loss=3.1780, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6944
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.1327, Q2 Loss=1.1327, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8371
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3708, Q2 Loss=1.3708, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5404
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0849, Q2 Loss=1.0849, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4790

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.0%)
Q1 update: 0.06s (20.7%)
Q2 update: 0.06s (20.9%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007133
Q1 loss: 1.486708
Q2 loss: 1.486708
Current threshold: -26.0716
Global Scale Offset: 0.1600
Reward stats: mean=-0.0031, std=0.1500, count=280
----------------------------------------------
SAC Update - Actor Loss: -0.0071, Q1 Loss: 1.4867, Q2 Loss: 1.4867, Entropy: 0.0000, Mean TD Error: 1.7415, Threshold: -26.0716
Original likelihood: -30.914165496826172
Adjusted likelihood: -30.914165496826172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 33.69919204711914
Projection step: 1, Loss: 32.93003845214844
Projection step: 2, Loss: 32.48991012573242
Projection step: 3, Loss: 32.594425201416016
Projection step: 4, Loss: 29.393692016601562
Projection step: 5, Loss: 29.383251190185547
Projection step: 6, Loss: 28.66489028930664
Projection step: 7, Loss: 28.81013298034668
Projection step: 8, Loss: 26.220048904418945
Projection step: 9, Loss: 27.35540008544922
Projection step: 10, Loss: 25.96701431274414
Projection step: 11, Loss: 25.730663299560547
Projection step: 12, Loss: 25.02654457092285
Projection step: 13, Loss: 24.616615295410156
Projection step: 14, Loss: 24.699350357055664
Final likelihood: tensor([-23.0512, -23.3667, -22.9331, -22.6888, -27.4036, -22.4823, -25.6700,
        -22.8146, -22.9604, -22.9947, -22.5693, -23.1477, -23.6579, -23.6953,
        -21.8113, -22.5995])
Final projection likelihood: -23.3654
1 mode projection succeeded
New goal: tensor([ 0.1347,  0.6999,  0.4445,  0.5976, -0.1102,  0.4946,  0.6594,  0.9367,
         1.3984,  0.0776,  0.1526,  1.0880, -0.0839,  0.0648,  1.8551],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -29.278121948242188
Adjusted likelihood: -29.278121948242188
Likelihood residual: 0.0
Original likelihood: -27.728824615478516
Adjusted likelihood: -27.728824615478516
Likelihood residual: 0.0
{'index': 27.728824615478516, 'thumb_middle': 29.278121948242188}
Current yaw: tensor([-0.0857,  0.0859, -0.0799], device='cuda:1')
3 index
tensor([ 0.1763,  0.7522,  0.5114,  0.6124, -0.1978,  0.6130,  0.6707,  0.9669,
         1.4730,  0.1485,  0.1366,  1.0934, -0.0857,  0.0859, -0.0799,  6.1885],
       device='cuda:1')
Solve time for step 1 11.008325745002367
Current ori: tensor([-0.0857,  0.0859, -0.0799], device='cuda:1')
Middle force: tensor([0.5167, 0.5909, 0.5360, 0.5071], device='cuda:1')
Thumb force: tensor([0.6493, 0.5427, 0.5133, 0.5144], device='cuda:1')
tensor([ 0.2104,  0.6605,  0.4178,  0.5810, -0.1940,  0.6065,  0.6920,  0.9472,
         1.4848,  0.1263,  0.1291,  1.0849, -0.0885,  0.0837, -0.0978, -5.3848],
       device='cuda:1')
Solve time for step 2 2.504334290017141
Current ori: tensor([-0.0885,  0.0837, -0.0978], device='cuda:1')
Middle force: tensor([0.5928, 0.5349, 0.5066], device='cuda:1')
Thumb force: tensor([0.5379, 0.5127, 0.5136], device='cuda:1')
tensor([ 0.1958,  0.6556,  0.4088,  0.5759, -0.1943,  0.5978,  0.7023,  0.9520,
         1.4961,  0.1046,  0.1141,  1.1068, -0.0866,  0.0837, -0.1108, -4.5936],
       device='cuda:1')
Solve time for step 3 2.377045172994258
Current ori: tensor([-0.0866,  0.0837, -0.1108], device='cuda:1')
Middle force: tensor([0.5547, 0.5004], device='cuda:1')
Thumb force: tensor([0.5796, 0.5095], device='cuda:1')
tensor([ 0.1903,  0.6556,  0.4054,  0.5725, -0.1964,  0.6427,  0.7295,  0.9616,
         1.5000,  0.0518,  0.0787,  1.1340, -0.1810,  0.1080, -0.1380, -4.3367],
       device='cuda:1')
Solve time for step 4 2.398797005007509
Current ori: tensor([-0.1810,  0.1080, -0.1380], device='cuda:1')
Middle force: tensor([0.5003], device='cuda:1')
Thumb force: tensor([0.5077], device='cuda:1')
Storing RECOVERY transition: reward=-0.1243 (scaled=-0.0621), steps=2
Reward stats updated: mean -0.0031 -> -0.0033, std: 0.1498
Collected 281 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.5586, Q2 Loss=1.5586, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4328
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2197, Q2 Loss=1.2197, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5777
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2621, Q2 Loss=1.2621, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7924
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7242, Q2 Loss=0.7242, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2362
SAC Update 5/5: Actor Loss=-0.0207, Q1 Loss=1.3795, Q2 Loss=1.3795, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7626

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.4%)
Q1 update: 0.07s (20.5%)
Q2 update: 0.06s (19.1%)
Actor update: 0.14s (42.0%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004132
Q1 loss: 1.228812
Q2 loss: 1.228812
Current threshold: -26.0615
Global Scale Offset: 0.1594
Reward stats: mean=-0.0033, std=0.1498, count=281
----------------------------------------------
SAC Update - Actor Loss: -0.0041, Q1 Loss: 1.2288, Q2 Loss: 1.2288, Entropy: 0.0000, Mean TD Error: 0.9603, Threshold: -26.0615
Original likelihood: -306.5387268066406
Adjusted likelihood: -306.5387268066406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 17
Loaded trajectory sampler
Current yaw: tensor([-0.0014,  0.0144, -0.0310], device='cuda:1')
Current yaw: tensor([-0.0014,  0.0144, -0.0310], device='cuda:1')
1 turn
Sampling time 3.7068775910011027
tensor([ 0.0669,  0.5519,  0.5819,  0.5763, -0.1420,  0.5714,  0.8940,  0.8607,
         1.2451,  0.2682,  0.2576,  1.1736, -0.0014,  0.0144, -0.0310,  0.2416],
       device='cuda:1')
Original likelihood: -16.954299926757812
Adjusted likelihood: -16.954299926757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.666447985015111
Current ori: tensor([-0.0014,  0.0144, -0.0310], device='cuda:1')
Middle force: tensor([0.6728, 0.9808, 0.5385, 0.5643, 0.5236, 0.5431, 1.0394, 0.7664, 0.7907,
        0.5517, 0.5429, 0.7513], device='cuda:1')
Thumb force: tensor([0.8488, 1.1535, 0.5436, 0.9209, 1.0823, 0.6018, 0.5835, 1.4472, 0.7708,
        0.5351, 0.6103, 0.5521], device='cuda:1')
Index force: tensor([0.8446, 0.8915, 0.6985, 0.6394, 0.5830, 0.6681, 0.5694, 0.6091, 0.5618,
        0.5643, 0.6748, 0.5177], device='cuda:1')
Storing NORMAL transition: reward=0.0449 (scaled=0.0449), steps=1
Reward stats updated: mean -0.0033 -> -0.0031, std: 0.1496
Collected 282 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1205, Q2 Loss=1.1205, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2984
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2412, Q2 Loss=1.2412, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3807
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7974, Q2 Loss=0.7974, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9111
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8975, Q2 Loss=0.8975, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3179
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6869, Q2 Loss=1.6869, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3362

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (19.6%)
Actor update: 0.12s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.148697
Q2 loss: 1.148697
Current threshold: -26.0484
Global Scale Offset: 0.1581
Reward stats: mean=-0.0031, std=0.1496, count=282
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.1487, Q2 Loss: 1.1487, Entropy: 0.0000, Mean TD Error: 1.8489, Threshold: -26.0484
tensor([ 0.0548,  0.5703,  0.5921,  0.4850, -0.1137,  0.4249,  0.8829,  0.8861,
         1.3433,  0.2537,  0.1542,  1.1610, -0.0133,  0.0203, -0.0763,  0.2301],
       device='cuda:1')
Original likelihood: -17.20086097717285
Adjusted likelihood: -17.20086097717285
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.190965457004495
Current ori: tensor([-0.0133,  0.0203, -0.0763], device='cuda:1')
Middle force: tensor([0.9660, 0.5364, 0.5659, 0.5235, 0.5346, 1.0279, 0.7583, 0.7863, 0.5512,
        0.5368, 0.7453], device='cuda:1')
Thumb force: tensor([1.1435, 0.5414, 0.9092, 1.0746, 0.6089, 0.5830, 1.4400, 0.7666, 0.5335,
        0.6100, 0.5503], device='cuda:1')
Index force: tensor([0.8809, 0.7029, 0.6381, 0.5810, 0.6762, 0.5695, 0.6065, 0.5618, 0.5642,
        0.6852, 0.5181], device='cuda:1')
Storing NORMAL transition: reward=0.0978 (scaled=0.0978), steps=1
Reward stats updated: mean -0.0031 -> -0.0028, std: 0.1494
Collected 283 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7811, Q2 Loss=0.7811, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4790
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1268, Q2 Loss=1.1268, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3842
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.0693, Q2 Loss=2.0693, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4156
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=25.2932, Q2 Loss=25.2932, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=10.3183
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=2.8919, Q2 Loss=2.8919, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6306

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.4%)
Target Q: 0.05s (14.4%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.07s (20.7%)
Actor update: 0.13s (42.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 6.432458
Q2 loss: 6.432458
Current threshold: -26.0407
Global Scale Offset: 0.1573
Reward stats: mean=-0.0028, std=0.1494, count=283
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 6.4325, Q2 Loss: 6.4325, Entropy: 0.0000, Mean TD Error: 4.4455, Threshold: -26.0407
tensor([ 0.0589,  0.5673,  0.5888,  0.5070, -0.0864,  0.4302,  0.9407,  0.9406,
         1.3568,  0.2395,  0.1671,  1.1001, -0.0110,  0.0182, -0.1740,  0.3388],
       device='cuda:1')
Original likelihood: -12.436826705932617
Adjusted likelihood: -12.436826705932617
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.9814849450194743
Current ori: tensor([-0.0110,  0.0182, -0.1740], device='cuda:1')
Middle force: tensor([0.5374, 0.5688, 0.5238, 0.5374, 1.0215, 0.7555, 0.7862, 0.5522, 0.5341,
        0.7462], device='cuda:1')
Thumb force: tensor([0.5407, 0.8977, 1.0639, 0.5981, 0.5815, 1.4259, 0.7601, 0.5318, 0.6081,
        0.5478], device='cuda:1')
Index force: tensor([0.6933, 0.6340, 0.5797, 0.6744, 0.5684, 0.6048, 0.5608, 0.5631, 0.6892,
        0.5178], device='cuda:1')
Storing NORMAL transition: reward=-0.0077 (scaled=-0.0077), steps=1
Reward stats updated: mean -0.0028 -> -0.0028, std: 0.1492
Collected 284 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3188, Q2 Loss=1.3188, Entropy=0.0000, Time=0.09sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5823
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6783, Q2 Loss=0.6783, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0524
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.8506, Q2 Loss=0.8506, Entropy=0.2378, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0645
SAC Update 4/5: Actor Loss=-0.0018, Q1 Loss=1.2136, Q2 Loss=1.2136, Entropy=0.2206, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4141
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2838, Q2 Loss=1.2838, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5573

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.9%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.06s (20.1%)
Actor update: 0.14s (42.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000406
Q1 loss: 1.069036
Q2 loss: 1.069036
Current threshold: -26.0274
Global Scale Offset: 0.1567
Reward stats: mean=-0.0028, std=0.1492, count=284
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.0690, Q2 Loss: 1.0690, Entropy: 0.0917, Mean TD Error: 0.3341, Threshold: -26.0274
tensor([ 0.1116,  0.5802,  0.5859,  0.5146, -0.1467,  0.3371,  0.9305,  0.9639,
         1.3375,  0.1882,  0.2550,  1.1437, -0.0167,  0.0659, -0.1718,  0.4517],
       device='cuda:1')
Original likelihood: -31.751636505126953
Adjusted likelihood: -31.751636505126953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 29.80971908569336
Projection step: 1, Loss: 27.57400131225586
Projection step: 2, Loss: 25.408798217773438
Projection step: 3, Loss: 24.34719467163086
Projection step: 4, Loss: 22.632091522216797
Projection step: 5, Loss: 20.835655212402344
Projection step: 6, Loss: 20.011062622070312
Projection step: 7, Loss: 18.537837982177734
Projection step: 8, Loss: 20.27918243408203
Projection step: 9, Loss: 17.851375579833984
Projection step: 10, Loss: 16.9898738861084
Projection step: 11, Loss: 17.056766510009766
Projection step: 12, Loss: 17.59969139099121
Projection step: 13, Loss: 16.693527221679688
Projection step: 14, Loss: 16.70156478881836
Final likelihood: tensor([-15.1387, -14.1488, -15.2428, -13.1799, -16.2914, -16.0970, -14.5423,
        -15.8530, -16.5805, -15.9682, -25.0220, -16.6590, -14.1273, -15.2441,
        -15.7562, -25.6594])
Final projection likelihood: -16.5944
1 mode projection succeeded
New goal: tensor([ 0.0557,  0.6016,  0.4851,  0.6352, -0.0872,  0.4433,  0.7835,  0.8398,
         1.3114,  0.1498,  0.1724,  1.1141, -0.0298,  0.0384, -1.4947],
       device='cuda:1')
tensor([[0.0052]], device='cuda:1') tensor([[0.0052]], device='cuda:1') tensor([[0.0037]], device='cuda:1')
Original likelihood: -20.16668701171875
Adjusted likelihood: -20.16668701171875
Likelihood residual: 0.0
Original likelihood: -19.376419067382812
Adjusted likelihood: -19.376419067382812
Likelihood residual: 0.0
{'index': 19.376419067382812, 'thumb_middle': 20.16668701171875}
Current yaw: tensor([-0.0167,  0.0659, -0.1718], device='cuda:1')
2 index
tensor([ 0.1116,  0.5802,  0.5859,  0.5146, -0.1467,  0.3371,  0.9305,  0.9639,
         1.3375,  0.1882,  0.2550,  1.1437, -0.0167,  0.0659, -0.1718,  0.4517],
       device='cuda:1')
Solve time for step 1 10.426317303004907
Current ori: tensor([-0.0167,  0.0659, -0.1718], device='cuda:1')
Middle force: tensor([0.5920, 0.5752, 0.5761, 0.5406], device='cuda:1')
Thumb force: tensor([0.5352, 0.5392, 0.5965, 0.6280], device='cuda:1')
tensor([ 0.1190,  0.5383,  0.4580,  0.5768, -0.0769,  0.4349,  0.8753,  0.9197,
         1.3708,  0.1629,  0.2176,  1.0967, -0.0490,  0.0405, -0.2138,  0.6772],
       device='cuda:1')
Solve time for step 2 2.2926451039966196
Current ori: tensor([-0.0490,  0.0405, -0.2138], device='cuda:1')
Middle force: tensor([0.5739, 0.5733, 0.5392], device='cuda:1')
Thumb force: tensor([0.5363, 0.5950, 0.6259], device='cuda:1')
tensor([ 0.1094,  0.5473,  0.4404,  0.5995, -0.0516,  0.4776,  0.8512,  0.8928,
         1.3701,  0.1542,  0.1907,  1.0875, -0.0648,  0.0247, -0.2257,  1.0357],
       device='cuda:1')
Solve time for step 3 2.0840815420087893
Current ori: tensor([-0.0648,  0.0247, -0.2257], device='cuda:1')
Middle force: tensor([0.5709, 0.5380], device='cuda:1')
Thumb force: tensor([0.5897, 0.6232], device='cuda:1')
tensor([ 0.1089,  0.5530,  0.4362,  0.6015, -0.0620,  0.4716,  0.8505,  0.8941,
         1.3744,  0.1601,  0.1885,  1.1094, -0.0670,  0.0328, -0.2475,  1.4862],
       device='cuda:1')
Solve time for step 4 2.1392143290140666
Current ori: tensor([-0.0670,  0.0328, -0.2475], device='cuda:1')
Middle force: tensor([0.5107], device='cuda:1')
Thumb force: tensor([0.5853], device='cuda:1')
Storing RECOVERY transition: reward=0.0698 (scaled=0.0233), steps=3
Reward stats updated: mean -0.0028 -> -0.0027, std: 0.1489
Collected 285 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2488, Q2 Loss=1.2488, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4126
SAC Update 2/5: Actor Loss=-0.0122, Q1 Loss=0.7921, Q2 Loss=0.7921, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6762
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7986, Q2 Loss=0.7986, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1093
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.2471, Q2 Loss=2.2471, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5019
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1583, Q2 Loss=1.1583, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1488

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (17.8%)
Actor update: 0.10s (40.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002431
Q1 loss: 1.248997
Q2 loss: 1.248997
Current threshold: -25.9777
Global Scale Offset: 0.1529
Reward stats: mean=-0.0027, std=0.1489, count=285
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 1.2490, Q2 Loss: 1.2490, Entropy: 0.0000, Mean TD Error: 1.3698, Threshold: -25.9777
Original likelihood: -14.765477180480957
Adjusted likelihood: -14.765477180480957
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0722,  0.0341, -0.2457], device='cuda:1')
3 turn
Sampling time 3.9477305290056393
tensor([ 0.0638,  0.6129,  0.4694,  0.6219, -0.0634,  0.4829,  0.8394,  0.8823,
         1.3771,  0.1624,  0.1755,  1.1303, -0.0722,  0.0341, -0.2457,  1.5641],
       device='cuda:1')
Original likelihood: -14.234710693359375
Adjusted likelihood: -14.234710693359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.269310192001285
Current ori: tensor([-0.0722,  0.0341, -0.2457], device='cuda:1')
Middle force: tensor([0.7653, 0.5528, 0.6168, 0.5823, 0.8103, 0.5704, 0.5518, 0.5655, 0.9072,
        0.5131, 0.5624, 0.5783], device='cuda:1')
Thumb force: tensor([0.7810, 1.0949, 0.6762, 1.2214, 0.6025, 0.7294, 0.6267, 0.6769, 0.7014,
        0.6542, 0.6127, 0.5759], device='cuda:1')
Index force: tensor([1.1183, 0.5482, 0.9039, 0.8486, 0.6674, 0.6059, 0.6153, 0.5400, 0.6030,
        0.5740, 0.5658, 0.5534], device='cuda:1')
Storing NORMAL transition: reward=0.0977 (scaled=0.0977), steps=1
Reward stats updated: mean -0.0027 -> -0.0024, std: 0.1488
Collected 286 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3411, Q2 Loss=1.3411, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8944
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8107, Q2 Loss=0.8107, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5163
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.9650, Q2 Loss=2.9650, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7036
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=1.0733, Q2 Loss=1.0733, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4860
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=1.2017, Q2 Loss=1.2017, Entropy=0.2158, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5627

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.1%)
Actor update: 0.12s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006587
Q1 loss: 1.478353
Q2 loss: 1.478353
Current threshold: -25.9341
Global Scale Offset: 0.1494
Reward stats: mean=-0.0024, std=0.1488, count=286
----------------------------------------------
SAC Update - Actor Loss: -0.0066, Q1 Loss: 1.4784, Q2 Loss: 1.4784, Entropy: 0.0432, Mean TD Error: 1.6326, Threshold: -25.9341
tensor([ 0.1336,  0.5752,  0.5721,  0.6406, -0.0328,  0.5033,  0.8291,  0.9028,
         1.3294,  0.2408,  0.1826,  1.0845, -0.0863,  0.0174, -0.3464,  1.6937],
       device='cuda:1')
Original likelihood: -18.18703269958496
Adjusted likelihood: -18.18703269958496
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9412720919935964
Current ori: tensor([-0.0863,  0.0174, -0.3464], device='cuda:1')
Middle force: tensor([0.5554, 0.6112, 0.5454, 0.8043, 0.5628, 0.9079, 0.5974, 0.5413, 0.5688,
        0.5047, 0.6072], device='cuda:1')
Thumb force: tensor([1.0591, 0.6530, 1.2144, 0.6118, 0.7559, 0.5656, 0.6072, 0.8892, 0.8845,
        1.2411, 0.6091], device='cuda:1')
Index force: tensor([0.5357, 0.8867, 0.8755, 0.6514, 0.5953, 0.5166, 0.6007, 0.5736, 0.5549,
        0.5332, 0.6018], device='cuda:1')
Storing NORMAL transition: reward=0.0026 (scaled=0.0026), steps=1
Reward stats updated: mean -0.0024 -> -0.0023, std: 0.1485
Collected 287 transitions for RL
SAC Update 1/5: Actor Loss=-0.0021, Q1 Loss=1.1477, Q2 Loss=1.1477, Entropy=0.0629, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7711
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0396, Q2 Loss=1.0396, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7187
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8581, Q2 Loss=0.8581, Entropy=0.0069, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5455
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9409, Q2 Loss=0.9409, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1630
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=4.2348, Q2 Loss=4.2348, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.0640

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.6%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (41.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000416
Q1 loss: 1.644196
Q2 loss: 1.644196
Current threshold: -25.8730
Global Scale Offset: 0.1447
Reward stats: mean=-0.0023, std=0.1485, count=287
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.6442, Q2 Loss: 1.6442, Entropy: 0.0140, Mean TD Error: 1.8525, Threshold: -25.8730
tensor([ 0.1358,  0.5370,  0.5682,  0.7531, -0.0987,  0.4711,  0.9815,  0.9088,
         1.3524,  0.1390,  0.2113,  1.0572, -0.0696,  0.0106, -0.3458,  1.8099],
       device='cuda:1')
Original likelihood: -22.475048065185547
Adjusted likelihood: -22.475048065185547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7505841410020366
Current ori: tensor([-0.0696,  0.0106, -0.3458], device='cuda:1')
Middle force: tensor([0.5900, 0.5459, 0.8077, 0.5633, 0.9098, 0.5956, 0.5397, 0.5680, 0.5043,
        0.6074], device='cuda:1')
Thumb force: tensor([0.6632, 1.1833, 0.6003, 0.7444, 0.5598, 0.6029, 0.8798, 0.8695, 1.2208,
        0.6029], device='cuda:1')
Index force: tensor([0.8764, 0.8575, 0.6472, 0.5912, 0.5157, 0.5953, 0.5704, 0.5528, 0.5315,
        0.5973], device='cuda:1')
Storing NORMAL transition: reward=0.0184 (scaled=0.0184), steps=1
Reward stats updated: mean -0.0023 -> -0.0023, std: 0.1483
Collected 288 transitions for RL
SAC Update 1/5: Actor Loss=-0.0026, Q1 Loss=0.9908, Q2 Loss=0.9908, Entropy=0.1314, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1863
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8983, Q2 Loss=0.8983, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5435
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.7011, Q2 Loss=1.7011, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3698
SAC Update 4/5: Actor Loss=-0.0019, Q1 Loss=1.2415, Q2 Loss=1.2415, Entropy=0.1309, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7069
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2441, Q2 Loss=1.2441, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2790

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (22.6%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (17.7%)
Actor update: 0.08s (36.6%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000900
Q1 loss: 1.215174
Q2 loss: 1.215174
Current threshold: -25.8150
Global Scale Offset: 0.1413
Reward stats: mean=-0.0023, std=0.1483, count=288
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 1.2152, Q2 Loss: 1.2152, Entropy: 0.0525, Mean TD Error: 2.4171, Threshold: -25.8150
tensor([ 0.1053,  0.4400,  0.6992,  0.7342, -0.0345,  0.5997,  0.9141,  1.0355,
         1.2957,  0.2417,  0.2061,  0.8494, -0.1035, -0.0484, -0.3746,  2.8633],
       device='cuda:1')
Original likelihood: -25.792509078979492
Adjusted likelihood: -25.792509078979492
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5210)
State is out of distribution
Projection step: 0, Loss: 27.006532669067383
Projection step: 1, Loss: 24.16558265686035
Projection step: 2, Loss: 23.00506019592285
Projection step: 3, Loss: 23.266490936279297
Projection step: 4, Loss: 23.78128433227539
Projection step: 5, Loss: 23.139202117919922
Projection step: 6, Loss: 22.15945053100586
Projection step: 7, Loss: 22.283435821533203
Projection step: 8, Loss: 23.795740127563477
Projection step: 9, Loss: 21.034406661987305
Projection step: 10, Loss: 22.268661499023438
Projection step: 11, Loss: 20.833919525146484
Projection step: 12, Loss: 21.055278778076172
Projection step: 13, Loss: 21.726043701171875
Projection step: 14, Loss: 22.226032257080078
Final likelihood: tensor([-17.9747, -23.8284, -25.3418, -17.9975, -17.8665, -17.8867, -26.1415,
        -20.1364, -18.6441, -20.9307, -21.8427, -25.9928, -17.8873, -23.1142,
        -18.2026, -24.1164])
Final projection likelihood: -21.1190
1 mode projection succeeded
New goal: tensor([ 0.0899,  0.4134,  0.6619,  0.8038, -0.0133,  0.6178,  0.7058,  0.9331,
         1.3123,  0.2495,  0.1479,  0.7701, -0.0935, -0.0312,  0.0295],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -31.465179443359375
Adjusted likelihood: -31.465179443359375
Likelihood residual: 0.0
Original likelihood: -33.756710052490234
Adjusted likelihood: -33.756710052490234
Likelihood residual: 0.0
{'index': 33.756710052490234, 'thumb_middle': 31.465179443359375}
Current yaw: tensor([-0.1035, -0.0484, -0.3746], device='cuda:1')
4 thumb_middle
tensor([ 0.1053,  0.4400,  0.6992,  0.7342, -0.0345,  0.5997,  0.9141,  1.0355,
         1.2957,  0.2417,  0.2061,  0.8494, -0.1035, -0.0484, -0.3746,  2.8633],
       device='cuda:1')
Solve time for step 1 9.283728858019458
Current ori: tensor([-0.1035, -0.0484, -0.3746], device='cuda:1')
Index force: tensor([0.5438, 0.5753, 0.6076, 0.6013], device='cuda:1')
tensor([ 0.0914,  0.4734,  0.6710,  0.7755, -0.0892,  0.6130,  0.7330,  0.9425,
         1.2893,  0.2392,  0.1211,  0.7782, -0.2530, -0.1163, -0.3709,  5.9251],
       device='cuda:1')
Solve time for step 2 2.1376032490225043
Current ori: tensor([-0.2530, -0.1163, -0.3709], device='cuda:1')
Index force: tensor([0.5701, 0.6038, 0.5974], device='cuda:1')
tensor([ 0.0617,  0.5329,  0.7273,  0.8215, -0.0550,  0.6766,  0.7293,  0.9389,
         1.2849,  0.2368,  0.0803,  0.7502, -0.6096, -0.2654, -0.3675, -4.3277],
       device='cuda:1')
Solve time for step 3 2.0612411110196263
Current ori: tensor([-0.6096, -0.2654, -0.3675], device='cuda:1')
Index force: tensor([0.5928, 0.5917], device='cuda:1')
tensor([-0.1201,  0.7549,  0.8309,  0.8634, -0.0393,  0.7502,  0.7267,  0.9128,
         1.2868,  0.2346,  0.0697,  0.7493, -1.2958, -0.4595, -0.3676, -2.7651],
       device='cuda:1')
Solve time for step 4 1.9994943249912467
Current ori: tensor([-1.2958, -0.4595, -0.3676], device='cuda:1')
Index force: tensor([0.5777], device='cuda:1')
Storing RECOVERY transition: reward=-1.6007 (scaled=-0.5336), steps=3
Reward stats updated: mean -0.0023 -> -0.0041, std: 0.1512
Collected 289 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.8038, Q2 Loss=0.8038, Entropy=0.1279, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6816
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=12.6065, Q2 Loss=12.6065, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1770
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.2522, Q2 Loss=1.2522, Entropy=0.3466, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.4141
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2000, Q2 Loss=1.2000, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4421
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2536, Q2 Loss=1.2536, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8187

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.9%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (19.2%)
Actor update: 0.12s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000042
Q1 loss: 3.423231
Q2 loss: 3.423231
Current threshold: -25.7738
Global Scale Offset: 0.1392
Reward stats: mean=-0.0041, std=0.1512, count=289
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.4232, Q2 Loss: 3.4232, Entropy: 0.0949, Mean TD Error: 1.9067, Threshold: -25.7738
Original likelihood: -1239.2490234375
Adjusted likelihood: -1239.2490234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 18
Loaded trajectory sampler
Current yaw: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
Current yaw: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
1 turn
Sampling time 3.7072544010006823
tensor([ 1.1832e-01,  6.1885e-01,  5.6104e-01,  5.3361e-01, -1.1103e-01,
         5.2208e-01,  9.0883e-01,  9.0264e-01,  1.1881e+00,  3.1096e-01,
         2.8266e-01,  1.2156e+00, -2.3689e-04,  1.4497e-02, -4.4017e-02,
         2.1902e-01], device='cuda:1')
Original likelihood: -16.702871322631836
Adjusted likelihood: -16.702871322631836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.669314238999505
Current ori: tensor([-0.0002,  0.0145, -0.0440], device='cuda:1')
Middle force: tensor([0.7174, 0.7473, 0.5427, 0.8792, 0.5443, 0.5762, 0.4919, 0.4994, 0.5931,
        0.5595, 0.5739, 0.5985], device='cuda:1')
Thumb force: tensor([0.6133, 0.6747, 0.7518, 1.2942, 1.1982, 1.4184, 0.6239, 0.5656, 0.6063,
        1.0585, 0.6426, 0.6074], device='cuda:1')
Index force: tensor([0.6746, 0.6172, 0.5501, 0.6017, 1.0403, 0.7486, 0.8341, 0.6574, 0.5976,
        0.6052, 0.8184, 0.6000], device='cuda:1')
Storing NORMAL transition: reward=0.0937 (scaled=0.0937), steps=1
Reward stats updated: mean -0.0041 -> -0.0038, std: 0.1511
Collected 290 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=0.8598, Q2 Loss=0.8598, Entropy=0.3441, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9410
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9623, Q2 Loss=0.9623, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8111
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8306, Q2 Loss=0.8306, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0711
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2490, Q2 Loss=1.2490, Entropy=0.0937, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3258
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=2.3290, Q2 Loss=2.3290, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4610

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.2%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.2%)
Actor update: 0.13s (41.5%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000128
Q1 loss: 1.246127
Q2 loss: 1.246127
Current threshold: -25.7431
Global Scale Offset: 0.1380
Reward stats: mean=-0.0038, std=0.1511, count=290
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2461, Q2 Loss: 1.2461, Entropy: 0.0876, Mean TD Error: 1.5220, Threshold: -25.7431
tensor([ 0.0408,  0.6308,  0.4898,  0.4823, -0.1618,  0.4828,  0.9173,  0.8024,
         1.3929,  0.1952,  0.3026,  0.8945, -0.0073,  0.0563, -0.1413,  0.2336],
       device='cuda:1')
Original likelihood: -30.087257385253906
Adjusted likelihood: -30.087257385253906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 29.500473022460938
Projection step: 1, Loss: 25.767290115356445
Projection step: 2, Loss: 22.027118682861328
Projection step: 3, Loss: 19.037784576416016
Projection step: 4, Loss: 18.03094482421875
Projection step: 5, Loss: 18.9416561126709
Projection step: 6, Loss: 17.459075927734375
Projection step: 7, Loss: 16.99685287475586
Projection step: 8, Loss: 15.701753616333008
Projection step: 9, Loss: 15.534673690795898
Projection step: 10, Loss: 14.474481582641602
Final likelihood: tensor([-12.1137, -12.3882, -15.6486, -15.1072, -15.5907, -15.5348, -10.3687,
        -16.0200, -15.4176, -11.7541, -15.4553, -15.0387, -15.3933, -15.0701,
        -15.4825, -15.2080])
Final projection likelihood: -14.4745
1 mode projection succeeded
New goal: tensor([ 0.0400,  0.6120,  0.4432,  0.6091, -0.1064,  0.4786,  0.8646,  0.8197,
         1.3366,  0.1081,  0.2445,  1.0684, -0.0220,  0.0334, -1.0467],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -21.650279998779297
Adjusted likelihood: -21.650279998779297
Likelihood residual: 0.0
Original likelihood: -15.532758712768555
Adjusted likelihood: -15.532758712768555
Likelihood residual: 0.0
{'index': 15.532758712768555, 'thumb_middle': 21.650279998779297}
Current yaw: tensor([-0.0073,  0.0563, -0.1413], device='cuda:1')
2 index
tensor([ 0.0408,  0.6308,  0.4898,  0.4823, -0.1618,  0.4828,  0.9173,  0.8024,
         1.3929,  0.1952,  0.3026,  0.8945, -0.0073,  0.0563, -0.1413,  0.2336],
       device='cuda:1')
Solve time for step 1 10.730757965007797
Current ori: tensor([-0.0073,  0.0563, -0.1413], device='cuda:1')
Middle force: tensor([0.5790, 0.5189, 0.5057, 0.5475], device='cuda:1')
Thumb force: tensor([0.5951, 0.5436, 0.5861, 0.6037], device='cuda:1')
tensor([ 0.0817,  0.5556,  0.4079,  0.5593, -0.1421,  0.4933,  0.9075,  0.8391,
         1.4440,  0.1052,  0.2223,  0.9632, -0.0090,  0.0417, -0.1654,  1.4610],
       device='cuda:1')
Solve time for step 2 2.1785939629771747
Current ori: tensor([-0.0090,  0.0417, -0.1654], device='cuda:1')
Middle force: tensor([0.5184, 0.5054, 0.5457], device='cuda:1')
Thumb force: tensor([0.5409, 0.5841, 0.6022], device='cuda:1')
tensor([ 0.0831,  0.5659,  0.4024,  0.5757, -0.1446,  0.4951,  0.9051,  0.8504,
         1.4279,  0.1438,  0.2128,  0.9822, -0.0116,  0.0422, -0.1819,  2.0752],
       device='cuda:1')
Solve time for step 3 2.206816899997648
Current ori: tensor([-0.0116,  0.0422, -0.1819], device='cuda:1')
Middle force: tensor([0.5052, 0.5439], device='cuda:1')
Thumb force: tensor([0.5795, 0.6011], device='cuda:1')
tensor([ 0.0809,  0.5673,  0.4000,  0.5818, -0.1371,  0.4994,  0.9053,  0.8483,
         1.4297,  0.1403,  0.1887,  1.0106, -0.0137,  0.0376, -0.1908,  2.2334],
       device='cuda:1')
Solve time for step 4 2.1743938959843945
Current ori: tensor([-0.0137,  0.0376, -0.1908], device='cuda:1')
Middle force: tensor([0.5061], device='cuda:1')
Thumb force: tensor([0.5534], device='cuda:1')
Storing RECOVERY transition: reward=0.0212 (scaled=0.0212), steps=1
Reward stats updated: mean -0.0038 -> -0.0037, std: 0.1508
Collected 291 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9113, Q2 Loss=0.9113, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4506
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7499, Q2 Loss=0.7499, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3248
SAC Update 3/5: Actor Loss=-0.0034, Q1 Loss=1.6106, Q2 Loss=1.6106, Entropy=0.0753, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2675
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1112, Q2 Loss=1.1112, Entropy=0.0112, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3215
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7881, Q2 Loss=0.7881, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0653

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.3%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000673
Q1 loss: 1.034222
Q2 loss: 1.034222
Current threshold: -25.7114
Global Scale Offset: 0.1369
Reward stats: mean=-0.0037, std=0.1508, count=291
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 1.0342, Q2 Loss: 1.0342, Entropy: 0.0173, Mean TD Error: 1.4860, Threshold: -25.7114
Original likelihood: -15.314925193786621
Adjusted likelihood: -15.314925193786621
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0152,  0.0352, -0.1605], device='cuda:1')
3 turn
Sampling time 3.9426923550199717
tensor([ 0.0337,  0.6201,  0.4390,  0.6080, -0.1328,  0.5126,  0.8946,  0.8331,
         1.4202,  0.1509,  0.1840,  1.0270, -0.0152,  0.0352, -0.1605,  2.2028],
       device='cuda:1')
Original likelihood: -14.956328392028809
Adjusted likelihood: -14.956328392028809
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.404439495992847
Current ori: tensor([-0.0152,  0.0352, -0.1605], device='cuda:1')
Middle force: tensor([0.5289, 0.5011, 1.2475, 1.3045, 0.6119, 0.5483, 0.5687, 0.5821, 0.5438,
        0.7437, 0.5635, 0.5149], device='cuda:1')
Thumb force: tensor([0.7973, 0.5119, 1.1418, 1.0247, 0.6149, 0.8327, 0.9174, 1.4497, 1.8412,
        0.5246, 1.2411, 0.7166], device='cuda:1')
Index force: tensor([0.5137, 0.6973, 0.6224, 0.5326, 0.8800, 0.5403, 0.5274, 0.6116, 0.5083,
        0.5427, 0.5464, 0.5143], device='cuda:1')
Storing NORMAL transition: reward=0.0365 (scaled=0.0365), steps=1
Reward stats updated: mean -0.0037 -> -0.0035, std: 0.1506
Collected 292 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7474, Q2 Loss=0.7474, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3441
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7677, Q2 Loss=0.7677, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0970
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=1.0486, Q2 Loss=1.0486, Entropy=0.3249, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4872
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7722, Q2 Loss=0.7722, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5914
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2792, Q2 Loss=1.2792, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6074

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.7%)
Actor update: 0.11s (40.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000106
Q1 loss: 0.923031
Q2 loss: 0.923031
Current threshold: -25.6827
Global Scale Offset: 0.1359
Reward stats: mean=-0.0035, std=0.1506, count=292
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.9230, Q2 Loss: 0.9230, Entropy: 0.0650, Mean TD Error: 0.6254, Threshold: -25.6827
tensor([-2.5609e-02,  5.6107e-01,  5.0578e-01,  5.1872e-01, -7.9831e-02,
         5.2392e-01,  8.5016e-01,  1.0011e+00,  1.5000e+00, -1.0500e-01,
         1.8277e-01,  1.0160e+00,  3.2815e-03, -2.3350e-03, -1.9565e-01,
         2.9840e+00], device='cuda:1')
Original likelihood: -18.296310424804688
Adjusted likelihood: -18.296310424804688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.081762643996626
Current ori: tensor([ 0.0033, -0.0023, -0.1956], device='cuda:1')
Middle force: tensor([0.5011, 1.2388, 1.3106, 0.6911, 0.5532, 0.5707, 0.5820, 0.5455, 0.7434,
        0.5668, 0.5197], device='cuda:1')
Thumb force: tensor([0.5111, 1.1295, 1.0097, 0.5481, 0.8178, 0.9023, 1.4322, 1.8101, 0.5236,
        1.2211, 0.6906], device='cuda:1')
Index force: tensor([0.6901, 0.6245, 0.5295, 0.9005, 0.5370, 0.5270, 0.6091, 0.5087, 0.5416,
        0.5452, 0.5132], device='cuda:1')
Storing NORMAL transition: reward=0.0333 (scaled=0.0333), steps=1
Reward stats updated: mean -0.0035 -> -0.0034, std: 0.1504
Collected 293 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7678, Q2 Loss=0.7678, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3870
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0338, Q2 Loss=1.0338, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1788
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3097, Q2 Loss=1.3097, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6071
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1764, Q2 Loss=1.1764, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2996
SAC Update 5/5: Actor Loss=-0.0129, Q1 Loss=1.0814, Q2 Loss=1.0814, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4760

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.06s (19.3%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (40.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002575
Q1 loss: 1.073825
Q2 loss: 1.073825
Current threshold: -25.6640
Global Scale Offset: 0.1354
Reward stats: mean=-0.0034, std=0.1504, count=293
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 1.0738, Q2 Loss: 1.0738, Entropy: 0.0000, Mean TD Error: 1.3897, Threshold: -25.6640
tensor([ 0.0913,  0.5882,  0.5569,  0.5680, -0.1730,  0.4877,  0.9185,  1.0473,
         1.3059,  0.2714,  0.2446,  1.0574,  0.0210,  0.0132, -0.2296,  4.0128],
       device='cuda:1')
Original likelihood: -21.590858459472656
Adjusted likelihood: -21.590858459472656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.829085831006523
Current ori: tensor([ 0.0210,  0.0132, -0.2296], device='cuda:1')
Middle force: tensor([1.2259, 1.3103, 0.6524, 0.5459, 0.5674, 0.5814, 0.5456, 0.7417, 0.5642,
        0.5172], device='cuda:1')
Thumb force: tensor([1.1117, 0.9979, 0.5669, 0.8189, 0.8999, 1.4173, 1.7926, 0.5229, 1.2144,
        0.6957], device='cuda:1')
Index force: tensor([0.6165, 0.5273, 0.8877, 0.5396, 0.5265, 0.6069, 0.5085, 0.5405, 0.5442,
        0.5134], device='cuda:1')
Storing NORMAL transition: reward=0.0726 (scaled=0.0726), steps=1
Reward stats updated: mean -0.0034 -> -0.0032, std: 0.1502
Collected 294 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7704, Q2 Loss=0.7704, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3512
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4628, Q2 Loss=1.4628, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7372
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2645, Q2 Loss=1.2645, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6004
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8393, Q2 Loss=0.8393, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1291
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7413, Q2 Loss=0.7413, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1202

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.4%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (41.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.015650
Q2 loss: 1.015650
Current threshold: -25.6529
Global Scale Offset: 0.1351
Reward stats: mean=-0.0032, std=0.1502, count=294
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.0156, Q2 Loss: 1.0156, Entropy: 0.0000, Mean TD Error: 1.7876, Threshold: -25.6529
tensor([ 0.1715,  0.6421,  0.5073,  0.6599, -0.1924,  0.4646,  0.9338,  1.0581,
         1.3838,  0.2064,  0.2462,  1.0060,  0.0191,  0.0408, -0.3043,  5.1025],
       device='cuda:1')
Original likelihood: -32.154052734375
Adjusted likelihood: -32.154052734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.907814025878906
Projection step: 1, Loss: 29.885433197021484
Projection step: 2, Loss: 27.735408782958984
Projection step: 3, Loss: 24.988977432250977
Projection step: 4, Loss: 25.809383392333984
Projection step: 5, Loss: 21.131343841552734
Projection step: 6, Loss: 18.646053314208984
Projection step: 7, Loss: 16.79815673828125
Projection step: 8, Loss: 13.474756240844727
Final likelihood: tensor([-12.6063, -14.8216, -11.5095, -11.0764, -13.1115, -15.7372, -15.0902,
        -11.1142, -12.2361, -11.4304, -14.3712, -13.2755, -13.8621, -12.5617,
        -14.0095, -18.7825])
Final projection likelihood: -13.4748
1 mode projection succeeded
New goal: tensor([ 0.0960,  0.6093,  0.4977,  0.5760, -0.1079,  0.4867,  0.8772,  0.9363,
         1.3546,  0.2087,  0.2259,  1.0876,  0.0225,  0.0223, -2.1757],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -25.720478057861328
Adjusted likelihood: -25.720478057861328
Likelihood residual: 0.0
Original likelihood: -20.908832550048828
Adjusted likelihood: -20.908832550048828
Likelihood residual: 0.0
{'index': 20.908832550048828, 'thumb_middle': 25.720478057861328}
Current yaw: tensor([ 0.0191,  0.0408, -0.3043], device='cuda:1')
4 index
tensor([ 0.1715,  0.6421,  0.5073,  0.6599, -0.1924,  0.4646,  0.9338,  1.0581,
         1.3838,  0.2064,  0.2462,  1.0060,  0.0191,  0.0408, -0.3043,  5.1025],
       device='cuda:1')
Solve time for step 1 10.75433540699305
Current ori: tensor([ 0.0191,  0.0408, -0.3043], device='cuda:1')
Middle force: tensor([0.5378, 0.6000, 0.5100, 0.5027], device='cuda:1')
Thumb force: tensor([0.5027, 0.5847, 0.5672, 0.5016], device='cuda:1')
tensor([ 0.1608,  0.5701,  0.4606,  0.5724, -0.1555,  0.4848,  0.9489,  1.0171,
         1.3640,  0.2167,  0.2098,  1.0303,  0.0098,  0.0171, -0.3075,  4.0323],
       device='cuda:1')
Solve time for step 2 2.319784380000783
Current ori: tensor([ 0.0098,  0.0171, -0.3075], device='cuda:1')
Middle force: tensor([0.6018, 0.5091, 0.5023], device='cuda:1')
Thumb force: tensor([0.5771, 0.5646, 0.5013], device='cuda:1')
tensor([ 1.4988e-01,  5.7369e-01,  4.5882e-01,  5.6521e-01, -1.4958e-01,
         4.9504e-01,  9.4537e-01,  9.9429e-01,  1.4002e+00,  1.6233e-01,
         1.8014e-01,  1.0240e+00,  1.9986e-04,  1.5037e-02, -3.2766e-01,
         3.4623e+00], device='cuda:1')
Solve time for step 3 2.2151226380083244
Current ori: tensor([ 1.9986e-04,  1.5037e-02, -3.2766e-01], device='cuda:1')
Middle force: tensor([0.5079, 0.5019], device='cuda:1')
Thumb force: tensor([0.5597, 0.5010], device='cuda:1')
tensor([ 1.4695e-01,  5.7710e-01,  4.5782e-01,  5.6129e-01, -1.6167e-01,
         4.9297e-01,  9.3825e-01,  9.9821e-01,  1.3975e+00,  1.7944e-01,
         1.8515e-01,  1.0305e+00, -1.0306e-04,  2.3213e-02, -3.2744e-01,
         3.0777e+00], device='cuda:1')
Solve time for step 4 2.1825534180097748
Current ori: tensor([-1.0306e-04,  2.3213e-02, -3.2744e-01], device='cuda:1')
Middle force: tensor([0.5014], device='cuda:1')
Thumb force: tensor([0.5008], device='cuda:1')
Storing RECOVERY transition: reward=0.0109 (scaled=0.0036), steps=3
Reward stats updated: mean -0.0032 -> -0.0031, std: 0.1499
Collected 295 transitions for RL
SAC Update 1/5: Actor Loss=-0.0046, Q1 Loss=0.8820, Q2 Loss=0.8820, Entropy=0.0280, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5268
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=1.0971, Q2 Loss=1.0971, Entropy=0.0559, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5988
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=0.8813, Q2 Loss=0.8813, Entropy=0.0755, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1360
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7704, Q2 Loss=0.7704, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5175
SAC Update 5/5: Actor Loss=-0.0042, Q1 Loss=0.8079, Q2 Loss=0.8079, Entropy=0.0214, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4596

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (16.8%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (19.1%)
Actor update: 0.12s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002389
Q1 loss: 0.887747
Q2 loss: 0.887747
Current threshold: -25.6086
Global Scale Offset: 0.1334
Reward stats: mean=-0.0031, std=0.1499, count=295
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 0.8877, Q2 Loss: 0.8877, Entropy: 0.0362, Mean TD Error: 0.4477, Threshold: -25.6086
Original likelihood: -22.754131317138672
Adjusted likelihood: -22.754131317138672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0020,  0.0253, -0.3134], device='cuda:1')
5 turn
Sampling time 3.8007408500125166
tensor([ 9.4807e-02,  6.3192e-01,  4.9671e-01,  5.7546e-01, -1.6730e-01,
         4.9271e-01,  9.4055e-01,  9.9721e-01,  1.3874e+00,  1.9546e-01,
         1.9120e-01,  1.0400e+00,  2.0264e-03,  2.5323e-02, -3.1342e-01,
         2.9837e+00], device='cuda:1')
Original likelihood: -22.223892211914062
Adjusted likelihood: -22.223892211914062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.114640404004604
Current ori: tensor([ 0.0020,  0.0253, -0.3134], device='cuda:1')
Middle force: tensor([0.5275, 0.4995, 1.3095, 1.3389, 0.6040, 0.5416, 0.5208, 0.5575, 0.5674,
        0.5295, 0.5098, 0.5461], device='cuda:1')
Thumb force: tensor([0.8030, 0.5424, 1.1983, 1.0687, 0.6927, 0.8628, 0.5513, 1.2132, 0.6795,
        0.6149, 0.5728, 0.6224], device='cuda:1')
Index force: tensor([0.5037, 0.6616, 0.5889, 0.5319, 0.8925, 0.5332, 0.5751, 0.4952, 0.5133,
        0.6736, 0.6529, 0.6839], device='cuda:1')
Storing NORMAL transition: reward=0.0075 (scaled=0.0075), steps=1
Reward stats updated: mean -0.0031 -> -0.0031, std: 0.1497
Collected 296 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3109, Q2 Loss=1.3109, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2028
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.6435, Q2 Loss=1.6435, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3246
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=0.7675, Q2 Loss=0.7675, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3049
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9678, Q2 Loss=0.9678, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4511
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3251, Q2 Loss=1.3251, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5921

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002520
Q1 loss: 1.202943
Q2 loss: 1.202943
Current threshold: -25.5531
Global Scale Offset: 0.1300
Reward stats: mean=-0.0031, std=0.1497, count=296
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 1.2029, Q2 Loss: 1.2029, Entropy: 0.0000, Mean TD Error: 1.3751, Threshold: -25.5531
tensor([ 8.6333e-02,  6.2083e-01,  5.2863e-01,  5.2744e-01, -1.7790e-01,
         5.0567e-01,  9.1283e-01,  1.0285e+00,  1.5000e+00, -5.5370e-03,
         1.2793e-01,  1.0308e+00,  7.1696e-04,  2.9673e-02, -3.2115e-01,
         2.9684e+00], device='cuda:1')
Original likelihood: -27.0546932220459
Adjusted likelihood: -27.0546932220459
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0001)
State is out of distribution
Projection step: 0, Loss: 26.91412925720215
Projection step: 1, Loss: 23.665496826171875
Projection step: 2, Loss: 19.079120635986328
Projection step: 3, Loss: 15.428293228149414
Projection step: 4, Loss: 12.58601188659668
Final likelihood: tensor([-11.0239, -11.3124, -13.1304, -11.3368, -11.3517, -13.0849, -13.8485,
        -14.2519, -13.2810, -12.0540, -12.0360, -12.1134, -13.6191, -11.5524,
        -13.2682, -14.1116])
Final projection likelihood: -12.5860
1 mode projection succeeded
New goal: tensor([ 6.2727e-02,  6.2051e-01,  4.8763e-01,  5.4167e-01, -1.2385e-01,
         5.0494e-01,  8.8240e-01,  9.1247e-01,  1.4535e+00,  2.4796e-02,
         1.4772e-01,  1.1643e+00, -2.3755e-04,  2.0178e-02, -7.0180e-01],
       device='cuda:1')
tensor([[0.0049]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -24.907482147216797
Adjusted likelihood: -24.907482147216797
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 24.907482147216797}
Current yaw: tensor([ 0.0007,  0.0297, -0.3211], device='cuda:1')
6 thumb_middle
tensor([ 8.6333e-02,  6.2083e-01,  5.2863e-01,  5.2744e-01, -1.7790e-01,
         5.0567e-01,  9.1283e-01,  1.0285e+00,  1.5000e+00, -5.5370e-03,
         1.2793e-01,  1.0308e+00,  7.1696e-04,  2.9673e-02, -3.2115e-01,
         2.9684e+00], device='cuda:1')
Solve time for step 1 9.369003974017687
Current ori: tensor([ 0.0007,  0.0297, -0.3211], device='cuda:1')
Index force: tensor([0.5876, 0.5829, 0.5958, 0.5869], device='cuda:1')
tensor([ 8.0708e-02,  6.2851e-01,  5.0924e-01,  5.3244e-01, -2.2963e-01,
         4.8480e-01,  8.5520e-01,  9.1225e-01,  1.4066e+00, -2.2824e-03,
         9.7222e-02,  1.1052e+00, -5.0341e-04,  3.3403e-02, -3.2114e-01,
         2.9430e+00], device='cuda:1')
Solve time for step 2 2.1086733439879026
Current ori: tensor([-0.0005,  0.0334, -0.3211], device='cuda:1')
Index force: tensor([0.5776, 0.5918, 0.5830], device='cuda:1')
tensor([ 0.0794,  0.6474,  0.4889,  0.5186, -0.2321,  0.5032,  0.8518,  0.9009,
         1.4197, -0.0314,  0.0809,  1.1310, -0.0055,  0.0332, -0.3211,  2.9348],
       device='cuda:1')
Solve time for step 3 1.923850551014766
Current ori: tensor([-0.0055,  0.0332, -0.3211], device='cuda:1')
Index force: tensor([0.5868, 0.5792], device='cuda:1')
tensor([ 0.0661,  0.6415,  0.4819,  0.5232, -0.2380,  0.5036,  0.8598,  0.8836,
         1.4294, -0.0106,  0.0653,  1.1303, -0.0035,  0.0410, -0.3211,  2.9173],
       device='cuda:1')
Solve time for step 4 1.8409904769796412
Current ori: tensor([-0.0035,  0.0410, -0.3211], device='cuda:1')
Index force: tensor([0.5689], device='cuda:1')
Storing RECOVERY transition: reward=-0.0097 (scaled=-0.0097), steps=1
Reward stats updated: mean -0.0031 -> -0.0031, std: 0.1494
Collected 297 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0669, Q2 Loss=1.0669, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3909
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7324, Q2 Loss=0.7324, Entropy=0.0004, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1984
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9446, Q2 Loss=0.9446, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1634
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1540, Q2 Loss=1.1540, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3284
SAC Update 5/5: Actor Loss=-0.0036, Q1 Loss=1.1818, Q2 Loss=1.1818, Entropy=0.0093, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7872

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.5%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (42.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000725
Q1 loss: 1.015945
Q2 loss: 1.015945
Current threshold: -25.5034
Global Scale Offset: 0.1268
Reward stats: mean=-0.0031, std=0.1494, count=297
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 1.0159, Q2 Loss: 1.0159, Entropy: 0.0019, Mean TD Error: 1.3736, Threshold: -25.5034
Original likelihood: -30.36016082763672
Adjusted likelihood: -30.36016082763672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 28.628116607666016
Projection step: 1, Loss: 25.374706268310547
Projection step: 2, Loss: 22.738656997680664
Projection step: 3, Loss: 20.081737518310547
Projection step: 4, Loss: 17.563770294189453
Projection step: 5, Loss: 15.049196243286133
Projection step: 6, Loss: 13.25008773803711
Final likelihood: tensor([-13.5523, -13.2719, -12.7064, -13.4634, -13.3450, -13.2260, -13.0637,
        -13.0739, -13.6444, -13.4686, -12.8631, -13.5781, -13.0421, -13.5153,
        -12.9461, -13.2412])
Final projection likelihood: -13.2501
1 mode projection succeeded
New goal: tensor([ 5.5438e-02,  6.1143e-01,  4.9131e-01,  5.4504e-01, -1.1979e-01,
         5.2703e-01,  8.5608e-01,  8.2095e-01,  1.3963e+00,  5.1277e-02,
         1.4847e-01,  1.2027e+00, -1.3254e-03,  2.5283e-02, -7.6573e-01],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -19.630695343017578
Adjusted likelihood: -19.630695343017578
Likelihood residual: 0.0
Original likelihood: -17.164958953857422
Adjusted likelihood: -17.164958953857422
Likelihood residual: 0.0
{'index': 17.164958953857422, 'thumb_middle': 19.630695343017578}
Current yaw: tensor([ 0.0017,  0.0413, -0.3122], device='cuda:1')
7 index
tensor([ 6.5204e-02,  6.2909e-01,  4.8369e-01,  5.5147e-01, -1.8500e-01,
         5.4898e-01,  8.7738e-01,  9.1292e-01,  1.4899e+00,  2.4244e-02,
         1.1666e-01,  1.1642e+00,  1.7463e-03,  4.1271e-02, -3.1220e-01,
         2.9428e+00], device='cuda:1')
Solve time for step 1 11.692229245003546
Current ori: tensor([ 0.0017,  0.0413, -0.3122], device='cuda:1')
Middle force: tensor([0.5679, 0.5710, 0.5126, 0.5147], device='cuda:1')
Thumb force: tensor([0.5783, 0.5825, 0.6489, 0.5996], device='cuda:1')
tensor([ 1.0442e-01,  5.5605e-01,  4.3769e-01,  5.2598e-01, -1.6245e-01,
         5.4819e-01,  9.0849e-01,  8.8428e-01,  1.4674e+00,  4.4067e-02,
         9.4521e-02,  1.1844e+00, -4.2006e-04,  2.5116e-02, -3.2344e-01,
         3.9922e+00], device='cuda:1')
Solve time for step 2 2.456724792980822
Current ori: tensor([-0.0004,  0.0251, -0.3234], device='cuda:1')
Middle force: tensor([0.5668, 0.5116, 0.5140], device='cuda:1')
Thumb force: tensor([0.5807, 0.6458, 0.5974], device='cuda:1')
tensor([ 1.0396e-01,  5.6151e-01,  4.4544e-01,  5.1588e-01, -1.6021e-01,
         5.5611e-01,  9.1100e-01,  8.6516e-01,  1.4497e+00,  7.3510e-02,
         9.8710e-02,  1.1786e+00, -4.3482e-03,  2.2951e-02, -3.1827e-01,
         4.6480e+00], device='cuda:1')
Solve time for step 3 2.2719506610010285
Current ori: tensor([-0.0043,  0.0230, -0.3183], device='cuda:1')
Middle force: tensor([0.5000, 0.5227], device='cuda:1')
Thumb force: tensor([0.5371, 0.5203], device='cuda:1')
tensor([ 0.1035,  0.5634,  0.4480,  0.5166, -0.1633,  0.5729,  0.8957,  0.8426,
         1.4869,  0.0133,  0.0948,  1.1465, -0.0152,  0.0260, -0.3252,  5.1308],
       device='cuda:1')
Solve time for step 4 2.28736490700976
Current ori: tensor([-0.0152,  0.0260, -0.3252], device='cuda:1')
Middle force: tensor([0.5209], device='cuda:1')
Thumb force: tensor([0.5175], device='cuda:1')
Storing RECOVERY transition: reward=0.0168 (scaled=0.0168), steps=1
Reward stats updated: mean -0.0031 -> -0.0031, std: 0.1492
Collected 298 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=2.4873, Q2 Loss=2.4873, Entropy=0.2703, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.8081
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0394, Q2 Loss=1.0394, Entropy=0.0011, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1937
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9980, Q2 Loss=0.9980, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0994
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.0297, Q2 Loss=2.0297, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4231
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9128, Q2 Loss=0.9128, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3618

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000035
Q1 loss: 1.493468
Q2 loss: 1.493468
Current threshold: -25.4640
Global Scale Offset: 0.1244
Reward stats: mean=-0.0031, std=0.1492, count=298
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.4935, Q2 Loss: 1.4935, Entropy: 0.0543, Mean TD Error: 1.9772, Threshold: -25.4640
Original likelihood: -20.53378677368164
Adjusted likelihood: -20.53378677368164
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0150,  0.0323, -0.3384], device='cuda:1')
8 turn
Sampling time 3.8950315789843444
tensor([ 0.0480,  0.6237,  0.4833,  0.5385, -0.1739,  0.5650,  0.8995,  0.8511,
         1.4608,  0.0819,  0.0997,  1.1546, -0.0150,  0.0323, -0.3384,  5.2534],
       device='cuda:1')
Original likelihood: -20.259483337402344
Adjusted likelihood: -20.259483337402344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.10153466401971
Current ori: tensor([-0.0150,  0.0323, -0.3384], device='cuda:1')
Middle force: tensor([0.5725, 1.5644, 0.5372, 0.5213, 0.6648, 1.5578, 0.5643, 0.5568, 0.5805,
        1.0888, 0.5279, 0.5935], device='cuda:1')
Thumb force: tensor([0.7231, 0.9140, 0.5024, 0.8450, 0.8220, 0.9877, 0.6450, 0.9861, 0.5505,
        0.7532, 0.6016, 1.1063], device='cuda:1')
Index force: tensor([0.5399, 0.6833, 0.7683, 0.5896, 0.5004, 0.5003, 0.5656, 0.5758, 0.5874,
        0.5485, 0.5628, 0.5795], device='cuda:1')
Storing NORMAL transition: reward=0.0438 (scaled=0.0438), steps=1
Reward stats updated: mean -0.0031 -> -0.0029, std: 0.1489
Collected 299 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9510, Q2 Loss=0.9510, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1040
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=12.8871, Q2 Loss=12.8871, Entropy=0.0001, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2520
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8604, Q2 Loss=0.8604, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3173
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.9313, Q2 Loss=2.9313, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6953
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1651, Q2 Loss=1.1651, Entropy=0.2378, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0280

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.8%)
Q1 update: 0.07s (20.4%)
Q2 update: 0.07s (20.3%)
Actor update: 0.14s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000009
Q1 loss: 3.758979
Q2 loss: 3.758979
Current threshold: -25.4409
Global Scale Offset: 0.1230
Reward stats: mean=-0.0029, std=0.1489, count=299
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.7590, Q2 Loss: 3.7590, Entropy: 0.0476, Mean TD Error: 2.6793, Threshold: -25.4409
tensor([ 0.0637,  0.6622,  0.3930,  0.6353, -0.2364,  0.5986,  0.8742,  1.0410,
         1.5000,  0.1112,  0.0405,  1.0824, -0.0152,  0.0237, -0.3819,  5.3286],
       device='cuda:1')
Original likelihood: -28.905027389526367
Adjusted likelihood: -28.905027389526367
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 29.308979034423828
Projection step: 1, Loss: 26.029380798339844
Projection step: 2, Loss: 24.35320281982422
Projection step: 3, Loss: 22.29189682006836
Projection step: 4, Loss: 20.303869247436523
Projection step: 5, Loss: 19.635665893554688
Projection step: 6, Loss: 17.525707244873047
Projection step: 7, Loss: 18.142473220825195
Projection step: 8, Loss: 17.27143096923828
Projection step: 9, Loss: 15.72276782989502
Projection step: 10, Loss: 16.76163101196289
Projection step: 11, Loss: 15.519164085388184
Projection step: 12, Loss: 14.531997680664062
Final likelihood: tensor([-15.3602, -11.6971, -15.1020, -11.8803, -14.8422, -12.9176, -16.8445,
        -15.6634, -17.7452, -12.1401, -11.5651, -15.5635, -12.1529, -15.1460,
        -16.0141, -17.8777])
Final projection likelihood: -14.5320
1 mode projection succeeded
New goal: tensor([ 0.0762,  0.6171,  0.4769,  0.5646, -0.0951,  0.5559,  0.8030,  0.8442,
         1.4230,  0.1755,  0.1597,  1.1123, -0.0219,  0.0225, -2.1141],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0041]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -19.683155059814453
Adjusted likelihood: -19.683155059814453
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 19.683155059814453}
Current yaw: tensor([-0.0152,  0.0237, -0.3819], device='cuda:1')
9 thumb_middle
tensor([ 0.0637,  0.6622,  0.3930,  0.6353, -0.2364,  0.5986,  0.8742,  1.0410,
         1.5000,  0.1112,  0.0405,  1.0824, -0.0152,  0.0237, -0.3819,  5.3286],
       device='cuda:1')
Solve time for step 1 9.806278392992681
Current ori: tensor([-0.0152,  0.0237, -0.3819], device='cuda:1')
Index force: tensor([0.5607, 0.5003, 0.6019, 0.6024], device='cuda:1')
tensor([ 0.0589,  0.6367,  0.4519,  0.5829, -0.2231,  0.5623,  0.7917,  0.8666,
         1.3781,  0.1260,  0.0602,  1.0763, -0.0143,  0.0264, -0.3819,  5.3168],
       device='cuda:1')
Solve time for step 2 2.1293603729864117
Current ori: tensor([-0.0143,  0.0264, -0.3819], device='cuda:1')
Index force: tensor([0.5002, 0.5975, 0.5978], device='cuda:1')
tensor([ 0.0565,  0.6425,  0.4552,  0.5562, -0.2180,  0.5760,  0.7866,  0.8378,
         1.3726,  0.1371,  0.0612,  1.0811, -0.0177,  0.0273, -0.3819,  5.3052],
       device='cuda:1')
Solve time for step 3 2.0130693730025087
Current ori: tensor([-0.0177,  0.0273, -0.3819], device='cuda:1')
Index force: tensor([0.5924, 0.5938], device='cuda:1')
tensor([ 0.0549,  0.6339,  0.4695,  0.5503, -0.2151,  0.5818,  0.7835,  0.8274,
         1.3718,  0.1379,  0.0607,  1.0797, -0.0164,  0.0283, -0.3819,  5.3040],
       device='cuda:1')
Solve time for step 4 1.988222540996503
Current ori: tensor([-0.0164,  0.0283, -0.3819], device='cuda:1')
Index force: tensor([0.5761], device='cuda:1')
Storing RECOVERY transition: reward=0.0014 (scaled=0.0014), steps=1
Reward stats updated: mean -0.0029 -> -0.0029, std: 0.1487
Collected 300 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7230, Q2 Loss=0.7230, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1615
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3923, Q2 Loss=1.3923, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2885
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=5.4957, Q2 Loss=5.4957, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.4208
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3585, Q2 Loss=1.3585, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5201
SAC Update 5/5: Actor Loss=-0.0163, Q1 Loss=1.2018, Q2 Loss=1.2018, Entropy=0.2291, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0545

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.4%)
Target Q: 0.04s (12.8%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.9%)
Actor update: 0.13s (43.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003264
Q1 loss: 2.034270
Q2 loss: 2.034270
Current threshold: -25.4171
Global Scale Offset: 0.1212
Reward stats: mean=-0.0029, std=0.1487, count=300
----------------------------------------------
SAC Update - Actor Loss: -0.0033, Q1 Loss: 2.0343, Q2 Loss: 2.0343, Entropy: 0.0458, Mean TD Error: 2.8891, Threshold: -25.4171
Original likelihood: -23.454608917236328
Adjusted likelihood: -23.454608917236328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0141,  0.0265, -0.3834], device='cuda:1')
10 turn
Sampling time 3.8990652350184973
tensor([ 0.0575,  0.6303,  0.4688,  0.5663, -0.1519,  0.6179,  0.8088,  0.8340,
         1.4354,  0.1656,  0.1020,  1.1026, -0.0141,  0.0265, -0.3834,  5.3191],
       device='cuda:1')
Original likelihood: -22.92038345336914
Adjusted likelihood: -22.92038345336914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.3463389200042
Current ori: tensor([-0.0141,  0.0265, -0.3834], device='cuda:1')
Middle force: tensor([0.5274, 0.7300, 0.5678, 0.5009, 0.7375, 1.0328, 0.5844, 0.5220, 0.6245,
        0.6309, 0.5067, 0.5323], device='cuda:1')
Thumb force: tensor([0.8758, 0.6607, 1.5906, 2.4115, 0.8728, 1.8523, 0.6041, 0.8388, 0.5477,
        0.6024, 1.4577, 0.5492], device='cuda:1')
Index force: tensor([0.5154, 0.9061, 0.6196, 0.5977, 0.6140, 0.6049, 0.5884, 0.4962, 0.4998,
        0.5928, 0.6473, 0.6816], device='cuda:1')
Storing NORMAL transition: reward=0.1108 (scaled=0.1108), steps=1
Reward stats updated: mean -0.0029 -> -0.0025, std: 0.1486
Collected 301 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9232, Q2 Loss=0.9232, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1771
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8726, Q2 Loss=0.8726, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2905
SAC Update 3/5: Actor Loss=-0.0055, Q1 Loss=0.9835, Q2 Loss=0.9835, Entropy=0.0645, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5887
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2389, Q2 Loss=1.2389, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6146
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9080, Q2 Loss=0.9080, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3418

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.5%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (41.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001092
Q1 loss: 0.985251
Q2 loss: 0.985251
Current threshold: -25.3548
Global Scale Offset: 0.1167
Reward stats: mean=-0.0025, std=0.1486, count=301
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 0.9853, Q2 Loss: 0.9853, Entropy: 0.0129, Mean TD Error: 0.4025, Threshold: -25.3548
tensor([ 0.0379,  0.6487,  0.3970,  0.6185, -0.1679,  0.6095,  0.7731,  0.9233,
         1.4161,  0.2360,  0.1714,  0.9882, -0.0132,  0.0379, -0.4952,  5.4304],
       device='cuda:1')
Original likelihood: -23.123743057250977
Adjusted likelihood: -23.123743057250977
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.0864165459934156
Current ori: tensor([-0.0132,  0.0379, -0.4952], device='cuda:1')
Middle force: tensor([0.7287, 0.5675, 0.5009, 0.7356, 1.0274, 0.5848, 0.5214, 0.6240, 0.6290,
        0.5065, 0.5327], device='cuda:1')
Thumb force: tensor([0.6522, 1.5720, 2.3854, 0.8671, 1.8343, 0.5998, 0.8384, 0.5469, 0.6014,
        1.4449, 0.5457], device='cuda:1')
Index force: tensor([0.9031, 0.6206, 0.5962, 0.6139, 0.6037, 0.5872, 0.5009, 0.5000, 0.5910,
        0.6469, 0.6811], device='cuda:1')
Storing NORMAL transition: reward=0.1274 (scaled=0.1274), steps=1
Reward stats updated: mean -0.0025 -> -0.0021, std: 0.1485
Collected 302 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3116, Q2 Loss=1.3116, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0058
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1365, Q2 Loss=1.1365, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2416
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=0.9505, Q2 Loss=0.9505, Entropy=0.1355, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4588
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0477, Q2 Loss=1.0477, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3463
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8433, Q2 Loss=0.8433, Entropy=0.1556, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8467

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.3%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (39.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000193
Q1 loss: 1.057922
Q2 loss: 1.057922
Current threshold: -25.3061
Global Scale Offset: 0.1136
Reward stats: mean=-0.0021, std=0.1485, count=302
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.0579, Q2 Loss: 1.0579, Entropy: 0.0582, Mean TD Error: 0.7798, Threshold: -25.3061
tensor([ 0.1349,  0.6333,  0.4124,  0.6340, -0.1519,  0.5824,  0.8483,  0.8785,
         1.4665,  0.1671,  0.1651,  0.8864, -0.0268,  0.0268, -0.6232, -6.0745],
       device='cuda:1')
Original likelihood: -23.72374725341797
Adjusted likelihood: -23.72374725341797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7292299330001697
Current ori: tensor([-0.0268,  0.0268, -0.6232], device='cuda:1')
Middle force: tensor([0.5660, 0.5007, 0.7304, 1.0199, 0.5789, 0.5196, 0.6179, 0.6084, 0.5039,
        0.5256], device='cuda:1')
Thumb force: tensor([1.5531, 2.3699, 0.8628, 1.8182, 0.6039, 0.8508, 0.5500, 0.6252, 1.4541,
        0.5582], device='cuda:1')
Index force: tensor([0.6138, 0.6005, 0.6138, 0.6018, 0.5851, 0.5008, 0.5000, 0.5838, 0.6757,
        0.6733], device='cuda:1')
Storing NORMAL transition: reward=-0.0107 (scaled=-0.0107), steps=1
Reward stats updated: mean -0.0021 -> -0.0021, std: 0.1483
Collected 303 transitions for RL
SAC Update 1/5: Actor Loss=-0.0159, Q1 Loss=1.1621, Q2 Loss=1.1621, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3649
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6804, Q2 Loss=0.6804, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4642
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7528, Q2 Loss=0.7528, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2510
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=1.3583, Q2 Loss=1.3583, Entropy=0.0022, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6730
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8194, Q2 Loss=0.8194, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5248

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004687
Q1 loss: 0.954614
Q2 loss: 0.954614
Current threshold: -25.2620
Global Scale Offset: 0.1112
Reward stats: mean=-0.0021, std=0.1483, count=303
----------------------------------------------
SAC Update - Actor Loss: -0.0047, Q1 Loss: 0.9546, Q2 Loss: 0.9546, Entropy: 0.0004, Mean TD Error: 0.6556, Threshold: -25.2620
tensor([ 0.1282,  0.6821,  0.4179,  0.6576, -0.1414,  0.5063,  0.8677,  0.9106,
         1.3706,  0.3314,  0.1684,  0.9852, -0.0284,  0.0247, -0.6124, -5.9683],
       device='cuda:1')
Original likelihood: -22.384632110595703
Adjusted likelihood: -22.384632110595703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.6432678079872858
Current ori: tensor([-0.0284,  0.0247, -0.6124], device='cuda:1')
Middle force: tensor([0.5007, 0.7268, 1.0134, 0.5740, 0.5191, 0.6139, 0.5949, 0.5028, 0.5214],
       device='cuda:1')
Thumb force: tensor([2.3488, 0.8579, 1.8005, 0.6086, 0.8510, 0.5504, 0.6414, 1.4525, 0.5696],
       device='cuda:1')
Index force: tensor([0.6022, 0.6153, 0.6030, 0.5838, 0.5008, 0.5000, 0.5795, 0.6935, 0.6654],
       device='cuda:1')
Storing NORMAL transition: reward=0.0453 (scaled=0.0453), steps=1
Reward stats updated: mean -0.0021 -> -0.0019, std: 0.1481
Collected 304 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.7516, Q2 Loss=2.7516, Entropy=0.0807, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6583
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7856, Q2 Loss=0.7856, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3780
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7657, Q2 Loss=0.7657, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4084
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1482, Q2 Loss=1.1482, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9301
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.5731, Q2 Loss=1.5731, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.6361

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (19.4%)
Actor update: 0.12s (40.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000008
Q1 loss: 1.404839
Q2 loss: 1.404839
Current threshold: -25.2197
Global Scale Offset: 0.1090
Reward stats: mean=-0.0019, std=0.1481, count=304
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.4048, Q2 Loss: 1.4048, Entropy: 0.0161, Mean TD Error: 1.8022, Threshold: -25.2197
tensor([ 0.1077,  0.6230,  0.4876,  0.6413, -0.1454,  0.5203,  0.8531,  0.9277,
         1.3490,  0.4513,  0.1980,  0.9621, -0.0187,  0.0388, -0.6590, -5.9430],
       device='cuda:1')
Original likelihood: -23.435565948486328
Adjusted likelihood: -23.435565948486328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.48206863400992
Current ori: tensor([-0.0187,  0.0388, -0.6590], device='cuda:1')
Middle force: tensor([0.7194, 1.0034, 0.5701, 0.5178, 0.6091, 0.5888, 0.5022, 0.5197],
       device='cuda:1')
Thumb force: tensor([0.8497, 1.7856, 0.6110, 0.8602, 0.5511, 0.6513, 1.4560, 0.5757],
       device='cuda:1')
Index force: tensor([0.6111, 0.6007, 0.5802, 0.5007, 0.5000, 0.5738, 0.7022, 0.6560],
       device='cuda:1')
Storing NORMAL transition: reward=0.0156 (scaled=0.0156), steps=1
Reward stats updated: mean -0.0019 -> -0.0019, std: 0.1478
Collected 305 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0075, Q2 Loss=1.0075, Entropy=0.0003, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7466
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3500, Q2 Loss=1.3500, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3703
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=1.3922, Q2 Loss=1.3922, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7000
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3258, Q2 Loss=1.3258, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6305
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1349, Q2 Loss=1.1349, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1456

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.3%)
Q1 update: 0.06s (19.5%)
Q2 update: 0.06s (19.8%)
Actor update: 0.13s (42.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004605
Q1 loss: 1.242070
Q2 loss: 1.242070
Current threshold: -25.1947
Global Scale Offset: 0.1077
Reward stats: mean=-0.0019, std=0.1478, count=305
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.2421, Q2 Loss: 1.2421, Entropy: 0.0001, Mean TD Error: 0.7186, Threshold: -25.1947
tensor([ 0.1641,  0.6043,  0.4882,  0.7480, -0.1469,  0.3525,  0.9743,  1.0605,
         1.5000,  0.3736,  0.0192,  0.9629, -0.0249,  0.0666, -0.6819,  5.7987],
       device='cuda:1')
Original likelihood: -30.945030212402344
Adjusted likelihood: -30.945030212402344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 30.792739868164062
Projection step: 1, Loss: 29.280445098876953
Projection step: 2, Loss: 28.096946716308594
Projection step: 3, Loss: 26.544845581054688
Projection step: 4, Loss: 25.70397186279297
Projection step: 5, Loss: 26.08248519897461
Projection step: 6, Loss: 22.804529190063477
Projection step: 7, Loss: 23.025341033935547
Projection step: 8, Loss: 21.43344497680664
Projection step: 9, Loss: 21.028892517089844
Projection step: 10, Loss: 20.674816131591797
Projection step: 11, Loss: 21.277921676635742
Projection step: 12, Loss: 20.29960823059082
Projection step: 13, Loss: 19.48116683959961
Projection step: 14, Loss: 19.017993927001953
Final likelihood: tensor([-18.3863, -25.2022, -18.7791, -15.0118, -18.0789, -18.9247, -17.4695,
        -21.6192, -19.4778, -16.6372, -17.3746, -20.2606, -21.1543, -17.9430,
        -19.1962, -18.8796])
Final projection likelihood: -19.0247
1 mode projection succeeded
New goal: tensor([ 0.0830,  0.6170,  0.4728,  0.6112, -0.1044,  0.4425,  0.8288,  0.9368,
         1.4519,  0.3335,  0.0834,  1.1036, -0.0357,  0.0399, -2.3596],
       device='cuda:1')
tensor([[0.0064]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0038]], device='cuda:1')
Original likelihood: -23.876136779785156
Adjusted likelihood: -23.876136779785156
Likelihood residual: 0.0
Original likelihood: -20.235273361206055
Adjusted likelihood: -20.235273361206055
Likelihood residual: 0.0
{'index': 20.235273361206055, 'thumb_middle': 23.876136779785156}
Current yaw: tensor([-0.0249,  0.0666, -0.6819], device='cuda:1')
11 index
tensor([ 0.1641,  0.6043,  0.4882,  0.7480, -0.1469,  0.3525,  0.9743,  1.0605,
         1.5000,  0.3736,  0.0192,  0.9629, -0.0249,  0.0666, -0.6819,  5.7987],
       device='cuda:1')
Solve time for step 1 10.502732357010245
Current ori: tensor([-0.0249,  0.0666, -0.6819], device='cuda:1')
Middle force: tensor([0.5265, 0.5019, 0.5578, 0.5610], device='cuda:1')
Thumb force: tensor([0.5279, 0.5332, 0.5942, 0.5966], device='cuda:1')
tensor([ 0.1309,  0.5549,  0.4269,  0.6179, -0.1148,  0.4159,  0.9265,  1.0352,
         1.5000,  0.3458,  0.0108,  0.9734, -0.0654,  0.0569, -0.7021,  5.5944],
       device='cuda:1')
Solve time for step 2 2.3220597119943704
Current ori: tensor([-0.0654,  0.0569, -0.7021], device='cuda:1')
Middle force: tensor([0.5017, 0.5563, 0.5594], device='cuda:1')
Thumb force: tensor([0.5303, 0.5921, 0.5942], device='cuda:1')
tensor([ 0.1174,  0.5670,  0.4228,  0.5931, -0.0988,  0.4297,  0.9194,  1.0358,
         1.4976,  0.3686, -0.0138,  1.0197, -0.0736,  0.0487, -0.7139,  5.7131],
       device='cuda:1')
Solve time for step 3 2.259299313998781
Current ori: tensor([-0.0736,  0.0487, -0.7139], device='cuda:1')
Middle force: tensor([0.5365, 0.5240], device='cuda:1')
Thumb force: tensor([0.5084, 0.6046], device='cuda:1')
tensor([ 0.1156,  0.5737,  0.4253,  0.5856, -0.0820,  0.4587,  0.9040,  1.0100,
         1.4951,  0.3634, -0.0367,  1.0331, -0.0836,  0.0377, -0.6915,  5.9969],
       device='cuda:1')
Solve time for step 4 2.1826682520040777
Current ori: tensor([-0.0836,  0.0377, -0.6915], device='cuda:1')
Middle force: tensor([0.5221], device='cuda:1')
Thumb force: tensor([0.5967], device='cuda:1')
Storing RECOVERY transition: reward=-0.0011 (scaled=-0.0002), steps=5
Reward stats updated: mean -0.0019 -> -0.0019, std: 0.1476
Collected 306 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3155, Q2 Loss=1.3155, Entropy=0.0004, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8846
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9850, Q2 Loss=0.9850, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3353
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9081, Q2 Loss=0.9081, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5886
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.7361, Q2 Loss=0.7361, Entropy=0.3466, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3513
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2560, Q2 Loss=1.2560, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3969

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.7%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000012
Q1 loss: 1.040134
Q2 loss: 1.040134
Current threshold: -25.1795
Global Scale Offset: 0.1070
Reward stats: mean=-0.0019, std=0.1476, count=306
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0401, Q2 Loss: 1.0401, Entropy: 0.0694, Mean TD Error: 0.7113, Threshold: -25.1795
Original likelihood: -18.003948211669922
Adjusted likelihood: -18.003948211669922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0854,  0.0302, -0.6877], device='cuda:1')
12 turn
Sampling time 3.944149386981735
tensor([ 0.0706,  0.6251,  0.4569,  0.6044, -0.0714,  0.4670,  0.9036,  1.0048,
         1.4956,  0.3714, -0.0623,  1.0563, -0.0854,  0.0302, -0.6877,  6.1500],
       device='cuda:1')
Original likelihood: -19.146669387817383
Adjusted likelihood: -19.146669387817383
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.293217689002631
Current ori: tensor([-0.0854,  0.0302, -0.6877], device='cuda:1')
Middle force: tensor([1.0364, 0.6166, 0.6825, 0.6747, 0.9139, 0.5013, 0.5483, 1.3756, 1.3495,
        0.5720, 0.9549, 0.5634], device='cuda:1')
Thumb force: tensor([0.7301, 1.1356, 0.5567, 1.3065, 0.5630, 0.5077, 0.5718, 1.4682, 0.5771,
        0.5708, 0.8206, 0.6060], device='cuda:1')
Index force: tensor([1.1545, 0.5028, 0.8803, 0.8215, 0.7125, 0.6352, 0.5453, 0.5035, 0.9111,
        0.5669, 0.5487, 0.6183], device='cuda:1')
Storing NORMAL transition: reward=-0.0270 (scaled=-0.0270), steps=1
Reward stats updated: mean -0.0019 -> -0.0020, std: 0.1474
Collected 307 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6978, Q2 Loss=0.6978, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1648
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9246, Q2 Loss=0.9246, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1659
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=1.2889, Q2 Loss=1.2889, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8444
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2277, Q2 Loss=1.2277, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3912
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.1178, Q2 Loss=1.1178, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4131

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.1%)
Q1 update: 0.06s (18.6%)
Q2 update: 0.05s (18.5%)
Actor update: 0.11s (38.4%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004605
Q1 loss: 1.051348
Q2 loss: 1.051348
Current threshold: -25.1703
Global Scale Offset: 0.1065
Reward stats: mean=-0.0020, std=0.1474, count=307
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.0513, Q2 Loss: 1.0513, Entropy: 0.0000, Mean TD Error: 0.3959, Threshold: -25.1703
tensor([ 0.0732,  0.5671,  0.5222,  0.6521, -0.0613,  0.4641,  0.9200,  1.0146,
         1.5000,  0.3166, -0.1284,  1.1718, -0.0689,  0.0152, -0.6575, -6.2798],
       device='cuda:1')
Original likelihood: -17.338130950927734
Adjusted likelihood: -17.338130950927734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9431610649917275
Current ori: tensor([-0.0689,  0.0152, -0.6575], device='cuda:1')
Middle force: tensor([0.6289, 0.7055, 0.6828, 0.9177, 0.5015, 0.5535, 1.3680, 1.3456, 0.5745,
        0.9465, 0.5630], device='cuda:1')
Thumb force: tensor([1.1174, 0.5441, 1.2864, 0.5574, 0.5069, 0.5672, 1.4555, 0.5731, 0.5672,
        0.8170, 0.6041], device='cuda:1')
Index force: tensor([0.5025, 0.8832, 0.8128, 0.7133, 0.6317, 0.5426, 0.5034, 0.9062, 0.5657,
        0.5485, 0.6168], device='cuda:1')
Storing NORMAL transition: reward=0.0058 (scaled=0.0058), steps=1
Reward stats updated: mean -0.0020 -> -0.0019, std: 0.1471
Collected 308 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.0870, Q2 Loss=1.0870, Entropy=0.1342, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2915
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8854, Q2 Loss=0.8854, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9738
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=13.0317, Q2 Loss=13.0317, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2799
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8931, Q2 Loss=0.8931, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5160
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=1.0446, Q2 Loss=1.0446, Entropy=0.3459, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4920

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.06s (20.2%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000090
Q1 loss: 3.388365
Q2 loss: 3.388365
Current threshold: -25.1625
Global Scale Offset: 0.1063
Reward stats: mean=-0.0019, std=0.1471, count=308
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 3.3884, Q2 Loss: 3.3884, Entropy: 0.0960, Mean TD Error: 1.5106, Threshold: -25.1625
tensor([ 9.5061e-03,  5.2184e-01,  5.4809e-01,  6.1103e-01,  4.1193e-03,
         3.5030e-01,  9.0806e-01,  1.0835e+00,  1.5000e+00,  3.2691e-01,
        -9.1818e-02,  1.0020e+00, -5.8381e-02,  3.1696e-02, -6.6281e-01,
        -6.1148e+00], device='cuda:1')
Original likelihood: -22.59528160095215
Adjusted likelihood: -22.59528160095215
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.730368635006016
Current ori: tensor([-0.0584,  0.0317, -0.6628], device='cuda:1')
Middle force: tensor([0.7236, 0.7019, 0.9566, 0.5020, 0.5659, 1.3345, 1.3429, 0.5861, 0.9328,
        0.5627], device='cuda:1')
Thumb force: tensor([0.5294, 1.2536, 0.5394, 0.5061, 0.5565, 1.4538, 0.5644, 0.5569, 0.8149,
        0.6014], device='cuda:1')
Index force: tensor([0.9022, 0.8059, 0.7230, 0.6271, 0.5398, 0.5039, 0.9188, 0.5648, 0.5496,
        0.6158], device='cuda:1')
Storing NORMAL transition: reward=-0.0205 (scaled=-0.0205), steps=1
Reward stats updated: mean -0.0019 -> -0.0020, std: 0.1469
Collected 309 transitions for RL
SAC Update 1/5: Actor Loss=-0.0155, Q1 Loss=2.2248, Q2 Loss=2.2248, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5560
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0229, Q2 Loss=1.0229, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6093
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8942, Q2 Loss=0.8942, Entropy=0.0626, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8900
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=2.6583, Q2 Loss=2.6583, Entropy=0.0002, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6953
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7768, Q2 Loss=0.7768, Entropy=0.0001, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3034

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.0%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (19.5%)
Actor update: 0.13s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005117
Q1 loss: 1.515411
Q2 loss: 1.515411
Current threshold: -25.0983
Global Scale Offset: 0.1023
Reward stats: mean=-0.0020, std=0.1469, count=309
----------------------------------------------
SAC Update - Actor Loss: -0.0051, Q1 Loss: 1.5154, Q2 Loss: 1.5154, Entropy: 0.0126, Mean TD Error: 2.8108, Threshold: -25.0983
tensor([ 0.0553,  0.4618,  0.4609,  0.6863, -0.0405,  0.1803,  0.9337,  1.1994,
         1.5000,  0.3251, -0.1277,  0.9403, -0.1454,  0.0795, -0.6628, -1.0477],
       device='cuda:1')
Original likelihood: -26.435359954833984
Adjusted likelihood: -26.435359954833984
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 26.178468704223633
Projection step: 1, Loss: 24.70010757446289
Projection step: 2, Loss: 26.73970603942871
Projection step: 3, Loss: 26.41192054748535
Projection step: 4, Loss: 22.458969116210938
Projection step: 5, Loss: 23.579322814941406
Projection step: 6, Loss: 25.64380645751953
Projection step: 7, Loss: 21.929386138916016
Projection step: 8, Loss: 21.12734603881836
Projection step: 9, Loss: 22.503353118896484
Projection step: 10, Loss: 23.580862045288086
Projection step: 11, Loss: 22.34996223449707
Projection step: 12, Loss: 21.379859924316406
Projection step: 13, Loss: 23.55776596069336
Projection step: 14, Loss: 23.258037567138672
Final likelihood: tensor([-26.2860, -20.3642, -16.7329, -21.7134, -34.0350, -20.1485, -21.1178,
        -34.0315, -18.0054, -20.5655, -20.6164, -21.9412, -33.2939, -20.1282,
        -21.5846, -20.9457])
Final projection likelihood: -23.2194
1 mode projection succeeded
New goal: tensor([ 0.0758,  0.5338,  0.5683,  0.6379, -0.0506,  0.2569,  0.9421,  1.1559,
         1.5320,  0.3752,  0.0404,  0.9872, -0.1369,  0.0713, -1.0317],
       device='cuda:1')
tensor([[0.0151]], device='cuda:1') tensor([[0.0196]], device='cuda:1') tensor([[0.0153]], device='cuda:1')
Original likelihood: -31.320781707763672
Adjusted likelihood: -31.320781707763672
Likelihood residual: 0.0
Original likelihood: -31.328269958496094
Adjusted likelihood: -31.328269958496094
Likelihood residual: 0.0
{'index': 31.328269958496094, 'thumb_middle': 31.320781707763672}
Current yaw: tensor([-0.1454,  0.0795, -0.6628], device='cuda:1')
13 thumb_middle
tensor([ 0.0553,  0.4618,  0.4609,  0.6863, -0.0405,  0.1803,  0.9337,  1.1994,
         1.5000,  0.3251, -0.1277,  0.9403, -0.1454,  0.0795, -0.6628, -1.0477],
       device='cuda:1')
Solve time for step 1 9.000391921028495
Current ori: tensor([-0.1454,  0.0795, -0.6628], device='cuda:1')
Index force: tensor([0.5519, 0.6006, 0.5863, 0.5881], device='cuda:1')
tensor([ 0.0068,  0.5804,  0.5851,  0.6866, -0.0818,  0.3305,  0.9282,  1.1341,
         1.4612,  0.3359, -0.0815,  0.9378, -0.3636,  0.1967, -0.6628, -5.8057],
       device='cuda:1')
Solve time for step 2 2.0238112669903785
Current ori: tensor([-0.3636,  0.1967, -0.6628], device='cuda:1')
Index force: tensor([0.5895, 0.5812, 0.5764], device='cuda:1')
tensor([-0.0774,  0.6659,  0.6234,  0.6453, -0.1037,  0.3621,  0.9389,  1.1127,
         1.4817,  0.3481, -0.0388,  0.9646, -0.8453,  0.4247, -0.6628,  5.0753],
       device='cuda:1')
Solve time for step 3 1.8523566340154503
Current ori: tensor([-0.8453,  0.4247, -0.6628], device='cuda:1')
Index force: tensor([0.5697, 0.5784], device='cuda:1')
tensor([-0.2985,  0.8305,  0.8527,  0.8382, -0.1396,  0.4627,  0.9348,  1.0733,
         1.4880,  0.3524, -0.0260,  0.9557, -1.5888,  0.5879, -0.6627,  2.7872],
       device='cuda:1')
Solve time for step 4 1.7886083939811215
Current ori: tensor([-1.5888,  0.5879, -0.6627], device='cuda:1')
Index force: tensor([0.5688], device='cuda:1')
Storing RECOVERY transition: reward=-1.5366 (scaled=-0.5122), steps=3
Reward stats updated: mean -0.0020 -> -0.0036, std: 0.1495
Collected 310 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.2385, Q2 Loss=1.2385, Entropy=0.1109, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4257
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1420, Q2 Loss=1.1420, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9276
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9714, Q2 Loss=0.9714, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1837
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5040, Q2 Loss=1.5040, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3014
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3771, Q2 Loss=1.3771, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4700

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000009
Q1 loss: 1.246607
Q2 loss: 1.246607
Current threshold: -25.0427
Global Scale Offset: 0.0991
Reward stats: mean=-0.0036, std=0.1495, count=310
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2466, Q2 Loss: 1.2466, Entropy: 0.0222, Mean TD Error: 1.6617, Threshold: -25.0427
Original likelihood: -1284.92724609375
Adjusted likelihood: -1284.92724609375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 19
Loaded trajectory sampler
Current yaw: tensor([-0.0028,  0.0148, -0.0444], device='cuda:1')
Current yaw: tensor([-0.0028,  0.0148, -0.0444], device='cuda:1')
1 turn
Sampling time 3.8683211730094627
tensor([ 0.1726,  0.6367,  0.5524,  0.6096, -0.1056,  0.5271,  0.8650,  0.9752,
         1.1977,  0.3156,  0.2665,  1.2025, -0.0028,  0.0148, -0.0444,  0.1443],
       device='cuda:1')
Original likelihood: -22.296218872070312
Adjusted likelihood: -22.296218872070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.049546887021279
Current ori: tensor([-0.0028,  0.0148, -0.0444], device='cuda:1')
Middle force: tensor([0.5097, 1.1405, 0.5626, 0.4972, 0.5626, 0.5211, 0.5406, 0.8605, 0.5505,
        0.4854, 0.5220, 0.4809], device='cuda:1')
Thumb force: tensor([0.7630, 1.9257, 0.5703, 1.0112, 0.4696, 0.5704, 0.5720, 0.5701, 0.5685,
        0.7128, 0.6324, 0.9858], device='cuda:1')
Index force: tensor([0.5278, 1.0662, 0.5017, 0.6581, 0.6429, 0.5919, 0.5119, 0.5979, 0.6166,
        0.6345, 0.5927, 0.8566], device='cuda:1')
Storing NORMAL transition: reward=0.0218 (scaled=0.0218), steps=1
Reward stats updated: mean -0.0036 -> -0.0036, std: 0.1492
Collected 311 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0690, Q2 Loss=1.0690, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0991
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0043, Q2 Loss=1.0043, Entropy=0.0007, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6864
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=0.9768, Q2 Loss=0.9768, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4156
SAC Update 4/5: Actor Loss=-0.0025, Q1 Loss=0.7467, Q2 Loss=0.7467, Entropy=0.1414, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0549
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7242, Q2 Loss=0.7242, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1898

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.7%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.005106
Q1 loss: 0.904211
Q2 loss: 0.904211
Current threshold: -25.0028
Global Scale Offset: 0.0971
Reward stats: mean=-0.0036, std=0.1492, count=311
----------------------------------------------
SAC Update - Actor Loss: -0.0051, Q1 Loss: 0.9042, Q2 Loss: 0.9042, Entropy: 0.0284, Mean TD Error: 0.6891, Threshold: -25.0028
tensor([ 0.2016,  0.5961,  0.5930,  0.6845, -0.1532,  0.5752,  0.8326,  0.9703,
         1.1741,  0.4374,  0.2684,  1.2126, -0.0339,  0.0230, -0.0677,  0.5205],
       device='cuda:1')
Original likelihood: -29.28662872314453
Adjusted likelihood: -29.28662872314453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 28.539703369140625
Projection step: 1, Loss: 27.334148406982422
Projection step: 2, Loss: 24.083974838256836
Projection step: 3, Loss: 22.88540267944336
Projection step: 4, Loss: 22.784326553344727
Projection step: 5, Loss: 21.996915817260742
Projection step: 6, Loss: 21.695547103881836
Projection step: 7, Loss: 19.763376235961914
Projection step: 8, Loss: 17.802207946777344
Projection step: 9, Loss: 17.085838317871094
Projection step: 10, Loss: 15.2312650680542
Projection step: 11, Loss: 13.294139862060547
Final likelihood: tensor([-12.0914, -11.9704, -11.2814, -15.2015, -12.2451, -15.1953, -17.2455,
        -11.7160, -16.0080, -11.6204, -12.8087, -14.1876, -12.9192, -11.3740,
        -15.6511, -11.1907])
Final projection likelihood: -13.2941
1 mode projection succeeded
New goal: tensor([ 0.1159,  0.5392,  0.5818,  0.7051, -0.0535,  0.5401,  0.7658,  0.9210,
         1.3068,  0.3453,  0.2054,  1.0349, -0.0389,  0.0162, -2.8429],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -22.865428924560547
Adjusted likelihood: -22.865428924560547
Likelihood residual: 0.0
{'index': 22.865428924560547, 'thumb_middle': inf}
Current yaw: tensor([-0.0339,  0.0230, -0.0677], device='cuda:1')
2 index
tensor([ 0.2016,  0.5961,  0.5930,  0.6845, -0.1532,  0.5752,  0.8326,  0.9703,
         1.1741,  0.4374,  0.2684,  1.2126, -0.0339,  0.0230, -0.0677,  0.5205],
       device='cuda:1')
Solve time for step 1 10.804506293003215
Current ori: tensor([-0.0339,  0.0230, -0.0677], device='cuda:1')
Middle force: tensor([0.5364, 0.5316, 0.5470, 0.5868], device='cuda:1')
Thumb force: tensor([0.5516, 0.6024, 0.5930, 0.5760], device='cuda:1')
tensor([ 0.1788,  0.4971,  0.5313,  0.6735, -0.1614,  0.6083,  0.7957,  0.9218,
         1.2605,  0.3569,  0.2329,  1.1373, -0.0663,  0.0349, -0.0941,  1.3607],
       device='cuda:1')
Solve time for step 2 2.3169610730255954
Current ori: tensor([-0.0663,  0.0349, -0.0941], device='cuda:1')
Middle force: tensor([0.5307, 0.5458, 0.5847], device='cuda:1')
Thumb force: tensor([0.5970, 0.5908, 0.5743], device='cuda:1')
tensor([ 0.1640,  0.4948,  0.5334,  0.6741, -0.1725,  0.6152,  0.7887,  0.9238,
         1.2953,  0.3177,  0.2228,  1.1215, -0.0758,  0.0421, -0.0741,  1.8730],
       device='cuda:1')
Solve time for step 3 2.2062518919992726
Current ori: tensor([-0.0758,  0.0421, -0.0741], device='cuda:1')
Middle force: tensor([0.5454, 0.5828], device='cuda:1')
Thumb force: tensor([0.5850, 0.5724], device='cuda:1')
tensor([ 0.1617,  0.4972,  0.5340,  0.6750, -0.1668,  0.6217,  0.7865,  0.9157,
         1.2996,  0.3142,  0.2179,  1.1052, -0.0820,  0.0391, -0.0935,  2.0430],
       device='cuda:1')
Solve time for step 4 2.1292754700116348
Current ori: tensor([-0.0820,  0.0391, -0.0935], device='cuda:1')
Middle force: tensor([0.5822], device='cuda:1')
Thumb force: tensor([0.5672], device='cuda:1')
Storing RECOVERY transition: reward=0.0311 (scaled=0.0311), steps=1
Reward stats updated: mean -0.0036 -> -0.0035, std: 0.1490
Collected 312 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=0.7000, Q2 Loss=0.7000, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1968
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7406, Q2 Loss=0.7406, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7652
SAC Update 3/5: Actor Loss=-0.0053, Q1 Loss=1.1843, Q2 Loss=1.1843, Entropy=0.0024, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3756
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1065, Q2 Loss=1.1065, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6344
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=1.1398, Q2 Loss=1.1398, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2456

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.4%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.007949
Q1 loss: 0.974245
Q2 loss: 0.974245
Current threshold: -24.9496
Global Scale Offset: 0.0949
Reward stats: mean=-0.0035, std=0.1490, count=312
----------------------------------------------
SAC Update - Actor Loss: -0.0079, Q1 Loss: 0.9742, Q2 Loss: 0.9742, Entropy: 0.0005, Mean TD Error: 0.6435, Threshold: -24.9496
Original likelihood: -24.03847885131836
Adjusted likelihood: -24.03847885131836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9981)
Current yaw: tensor([-0.0838,  0.0314, -0.1057], device='cuda:1')
3 turn
Sampling time 3.696851193992188
tensor([ 0.1092,  0.5387,  0.5657,  0.6960, -0.1557,  0.6230,  0.7905,  0.9209,
         1.3003,  0.3087,  0.2007,  1.1146, -0.0838,  0.0314, -0.1057,  2.1451],
       device='cuda:1')
Original likelihood: -23.534170150756836
Adjusted likelihood: -23.534170150756836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.144896443001926
Current ori: tensor([-0.0838,  0.0314, -0.1057], device='cuda:1')
Middle force: tensor([0.5564, 0.5319, 1.1550, 0.5285, 0.5601, 0.7993, 0.6147, 0.5261, 0.8075,
        0.5513, 0.5802, 0.5883], device='cuda:1')
Thumb force: tensor([0.5799, 1.0910, 1.0788, 1.1552, 0.4974, 0.5659, 0.5611, 0.5846, 0.8668,
        0.5244, 1.0447, 0.5071], device='cuda:1')
Index force: tensor([0.5835, 0.5113, 1.3146, 0.5752, 0.7306, 0.6497, 0.5874, 0.5485, 0.5389,
        0.5835, 0.5538, 0.5870], device='cuda:1')
Storing NORMAL transition: reward=0.0299 (scaled=0.0299), steps=1
Reward stats updated: mean -0.0035 -> -0.0033, std: 0.1488
Collected 313 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2659, Q2 Loss=1.2659, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6085
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7220, Q2 Loss=0.7220, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2401
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.1738, Q2 Loss=1.1738, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7645
SAC Update 4/5: Actor Loss=-0.0159, Q1 Loss=1.6187, Q2 Loss=1.6187, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3403
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2682, Q2 Loss=1.2682, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2526

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (19.6%)
Actor update: 0.10s (42.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.005269
Q1 loss: 1.209718
Q2 loss: 1.209718
Current threshold: -24.8539
Global Scale Offset: 0.0897
Reward stats: mean=-0.0033, std=0.1488, count=313
----------------------------------------------
SAC Update - Actor Loss: -0.0053, Q1 Loss: 1.2097, Q2 Loss: 1.2097, Entropy: 0.0000, Mean TD Error: 2.4412, Threshold: -24.8539
tensor([ 0.1066,  0.5011,  0.6133,  0.6956, -0.1550,  0.6306,  0.7451,  1.0013,
         1.3289,  0.2646,  0.1783,  1.1248, -0.0789,  0.0308, -0.1352,  2.2725],
       device='cuda:1')
Original likelihood: -23.54791259765625
Adjusted likelihood: -23.54791259765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.887116742989747
Current ori: tensor([-0.0789,  0.0308, -0.1352], device='cuda:1')
Middle force: tensor([0.5305, 1.1356, 0.5269, 0.5578, 0.7964, 0.6111, 0.5237, 0.8037, 0.5493,
        0.5758, 0.5858], device='cuda:1')
Thumb force: tensor([1.0681, 1.0657, 1.1302, 0.5004, 0.5611, 0.5583, 0.5825, 0.8580, 0.5227,
        1.0270, 0.5063], device='cuda:1')
Index force: tensor([0.5104, 1.2852, 0.5742, 0.7211, 0.6433, 0.5843, 0.5451, 0.5385, 0.5803,
        0.5516, 0.5837], device='cuda:1')
Storing NORMAL transition: reward=-0.0881 (scaled=-0.0881), steps=1
Reward stats updated: mean -0.0033 -> -0.0036, std: 0.1486
Collected 314 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7786, Q2 Loss=0.7786, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5566
SAC Update 2/5: Actor Loss=-0.0113, Q1 Loss=1.0089, Q2 Loss=1.0089, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1379
SAC Update 3/5: Actor Loss=-0.0229, Q1 Loss=2.9646, Q2 Loss=2.9646, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7137
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7854, Q2 Loss=0.7854, Entropy=0.0002, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7195
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0424, Q2 Loss=1.0424, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3573

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (39.8%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.006830
Q1 loss: 1.315994
Q2 loss: 1.315994
Current threshold: -24.7662
Global Scale Offset: 0.0848
Reward stats: mean=-0.0036, std=0.1486, count=314
----------------------------------------------
SAC Update - Actor Loss: -0.0068, Q1 Loss: 1.3160, Q2 Loss: 1.3160, Entropy: 0.0000, Mean TD Error: 1.4970, Threshold: -24.7662
tensor([ 0.0594,  0.3866,  0.5846,  0.7223, -0.1254,  0.6257,  0.8018,  0.8602,
         1.3604,  0.2092,  0.1399,  1.1382, -0.1026,  0.0221, -0.0493,  3.7831],
       device='cuda:1')
Original likelihood: -24.819095611572266
Adjusted likelihood: -24.819095611572266
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4275)
State is out of distribution
Projection step: 0, Loss: 24.45465850830078
Projection step: 1, Loss: 22.56991195678711
Projection step: 2, Loss: 23.400390625
Projection step: 3, Loss: 23.33460235595703
Projection step: 4, Loss: 22.77701187133789
Projection step: 5, Loss: 20.514102935791016
Projection step: 6, Loss: 20.382728576660156
Projection step: 7, Loss: 19.341869354248047
Projection step: 8, Loss: 19.14797592163086
Projection step: 9, Loss: 17.940860748291016
Projection step: 10, Loss: 18.359601974487305
Projection step: 11, Loss: 18.66297721862793
Projection step: 12, Loss: 18.99010467529297
Projection step: 13, Loss: 16.525020599365234
Projection step: 14, Loss: 17.667531967163086
Final likelihood: tensor([-18.9039, -15.4138, -15.4267, -19.8349, -20.0332, -15.1977, -15.1687,
        -18.2168, -15.2470, -14.9247, -14.8304, -15.5068, -15.4559, -15.3229,
        -16.4287, -15.5204])
Final projection likelihood: -16.3395
1 mode projection succeeded
New goal: tensor([ 0.0652,  0.4548,  0.6358,  0.6805, -0.0502,  0.5844,  0.7020,  0.8772,
         1.3475,  0.2464,  0.1606,  0.9855, -0.0919,  0.0124,  0.0342],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0115]], device='cuda:1')
Original likelihood: -25.37970733642578
Adjusted likelihood: -25.37970733642578
Likelihood residual: 0.0
{'index': 25.37970733642578, 'thumb_middle': inf}
Current yaw: tensor([-0.1026,  0.0221, -0.0493], device='cuda:1')
4 index
tensor([ 0.0594,  0.3866,  0.5846,  0.7223, -0.1254,  0.6257,  0.8018,  0.8602,
         1.3604,  0.2092,  0.1399,  1.1382, -0.1026,  0.0221, -0.0493,  3.7831],
       device='cuda:1')
Solve time for step 1 10.616403090010863
Current ori: tensor([-0.1026,  0.0221, -0.0493], device='cuda:1')
Middle force: tensor([0.5626, 0.5041, 0.5391, 0.5374], device='cuda:1')
Thumb force: tensor([0.5441, 0.5620, 0.5425, 0.5643], device='cuda:1')
tensor([ 0.0817,  0.4047,  0.5903,  0.6684, -0.1337,  0.6545,  0.7545,  0.8859,
         1.3569,  0.2278,  0.1635,  1.0824, -0.1166,  0.0267, -0.0611,  4.3000],
       device='cuda:1')
Solve time for step 2 2.279108461982105
Current ori: tensor([-0.1166,  0.0267, -0.0611], device='cuda:1')
Middle force: tensor([0.5037, 0.5381, 0.5363], device='cuda:1')
Thumb force: tensor([0.5612, 0.5411, 0.5623], device='cuda:1')
tensor([ 0.0818,  0.4204,  0.5948,  0.6580, -0.1350,  0.6659,  0.7357,  0.8879,
         1.3590,  0.2341,  0.1719,  1.0621, -0.1251,  0.0299, -0.0926,  4.2805],
       device='cuda:1')
Solve time for step 3 2.1509466849965975
Current ori: tensor([-0.1251,  0.0299, -0.0926], device='cuda:1')
Middle force: tensor([0.5906, 0.6126], device='cuda:1')
Thumb force: tensor([0.5648, 0.5822], device='cuda:1')
tensor([ 0.0792,  0.4262,  0.5955,  0.6537, -0.1416,  0.6645,  0.7338,  0.8840,
         1.3619,  0.2398,  0.1818,  1.0538, -0.1300,  0.0370, -0.1180,  3.8742],
       device='cuda:1')
Solve time for step 4 2.046560604998376
Current ori: tensor([-0.1300,  0.0370, -0.1180], device='cuda:1')
Middle force: tensor([0.5585], device='cuda:1')
Thumb force: tensor([0.5970], device='cuda:1')
Storing RECOVERY transition: reward=0.0728 (scaled=0.0364), steps=2
Reward stats updated: mean -0.0036 -> -0.0035, std: 0.1484
Collected 315 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.8689, Q2 Loss=0.8689, Entropy=0.6548, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5993
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2038, Q2 Loss=1.2038, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4349
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1656, Q2 Loss=1.1656, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2163
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3347, Q2 Loss=1.3347, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4825
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.5365, Q2 Loss=1.5365, Entropy=0.0004, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.2686

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.6%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000094
Q1 loss: 1.221890
Q2 loss: 1.221890
Current threshold: -24.7089
Global Scale Offset: 0.0819
Reward stats: mean=-0.0035, std=0.1484, count=315
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.2219, Q2 Loss: 1.2219, Entropy: 0.1310, Mean TD Error: 0.8003, Threshold: -24.7089
Original likelihood: -30.317373275756836
Adjusted likelihood: -30.317373275756836
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.701171875
Projection step: 1, Loss: 28.254552841186523
Projection step: 2, Loss: 27.8260498046875
Projection step: 3, Loss: 28.871021270751953
Projection step: 4, Loss: 28.17235565185547
Projection step: 5, Loss: 29.137910842895508
Projection step: 6, Loss: 27.92321014404297
Projection step: 7, Loss: 28.533308029174805
Projection step: 8, Loss: 28.48272705078125
Projection step: 9, Loss: 27.684667587280273
Projection step: 10, Loss: 27.560489654541016
Projection step: 11, Loss: 26.736011505126953
Projection step: 12, Loss: 26.932056427001953
Projection step: 13, Loss: 26.106016159057617
Projection step: 14, Loss: 25.65070152282715
Final likelihood: tensor([-27.2227, -25.4746, -27.0647, -28.0013, -25.0482, -24.7837, -27.4036,
        -25.4998, -23.4937, -28.5740, -25.8125, -23.0272, -25.2109, -26.2041,
        -24.1882, -22.8439])
Final projection likelihood: -25.6158
1 mode projection failed, trying anyway
New goal: tensor([ 0.0388,  0.4905,  0.5737,  0.6735, -0.0739,  0.5944,  0.6787,  0.8289,
         1.3555,  0.2032,  0.1827,  0.9692, -0.1202,  0.0264,  0.2222],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1')
Original likelihood: -27.722684860229492
Adjusted likelihood: -27.722684860229492
Likelihood residual: 0.0
Original likelihood: -25.90050506591797
Adjusted likelihood: -25.90050506591797
Likelihood residual: 0.0
{'index': 25.90050506591797, 'thumb_middle': 27.722684860229492}
Current yaw: tensor([-0.1301,  0.0393, -0.1309], device='cuda:1')
5 index
tensor([ 0.0381,  0.4782,  0.6282,  0.6730, -0.1437,  0.6610,  0.7348,  0.8880,
         1.3623,  0.2414,  0.1799,  1.0674, -0.1301,  0.0393, -0.1309,  3.7321],
       device='cuda:1')
Solve time for step 1 10.353264067001874
Current ori: tensor([-0.1301,  0.0393, -0.1309], device='cuda:1')
Middle force: tensor([0.5019, 0.5323, 0.5871, 0.5060], device='cuda:1')
Thumb force: tensor([0.5001, 0.5617, 0.5695, 0.5729], device='cuda:1')
tensor([ 0.0506,  0.4509,  0.5514,  0.6511, -0.1579,  0.7109,  0.7401,  0.8643,
         1.4188,  0.1858,  0.1839,  1.0046, -0.1964,  0.0598, -0.1530,  3.3327],
       device='cuda:1')
Solve time for step 2 2.3520093680126593
Current ori: tensor([-0.1964,  0.0598, -0.1530], device='cuda:1')
Middle force: tensor([0.5317, 0.5837, 0.5055], device='cuda:1')
Thumb force: tensor([0.5581, 0.5671, 0.5704], device='cuda:1')
tensor([ 0.0348,  0.4796,  0.5567,  0.6563, -0.1381,  0.7441,  0.7571,  0.8556,
         1.4540,  0.2353,  0.1813,  1.0224, -0.4873,  0.1390, -0.1545,  2.0267],
       device='cuda:1')
Solve time for step 3 2.1492022360034753
Current ori: tensor([-0.4873,  0.1390, -0.1545], device='cuda:1')
Middle force: tensor([0.5664, 0.5047], device='cuda:1')
Thumb force: tensor([0.5604, 0.5681], device='cuda:1')
tensor([-0.0559,  0.6418,  0.5900,  0.6498, -0.1337,  0.8781,  0.7682,  0.8284,
         1.5000,  0.2325,  0.1945,  1.0003, -1.1130,  0.2703, -0.1545,  1.2884],
       device='cuda:1')
Solve time for step 4 2.0596142249996774
Current ori: tensor([-1.1130,  0.2703, -0.1545], device='cuda:1')
Middle force: tensor([0.5089], device='cuda:1')
Thumb force: tensor([0.5096], device='cuda:1')
Storing RECOVERY transition: reward=-1.3587 (scaled=-0.6794), steps=2
Reward stats updated: mean -0.0035 -> -0.0056, std: 0.1530
Collected 316 transitions for RL
SAC Update 1/5: Actor Loss=-0.0128, Q1 Loss=1.1542, Q2 Loss=1.1542, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8213
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=2.1434, Q2 Loss=2.1434, Entropy=0.3194, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=3.4051
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1217, Q2 Loss=1.1217, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7184
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=0.8030, Q2 Loss=0.8030, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2026
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9398, Q2 Loss=0.9398, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3175

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (18.2%)
Actor update: 0.09s (37.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007193
Q1 loss: 1.232408
Q2 loss: 1.232408
Current threshold: -24.6762
Global Scale Offset: 0.0802
Reward stats: mean=-0.0056, std=0.1530, count=316
----------------------------------------------
SAC Update - Actor Loss: -0.0072, Q1 Loss: 1.2324, Q2 Loss: 1.2324, Entropy: 0.0639, Mean TD Error: 1.0930, Threshold: -24.6762
Original likelihood: -1200.59375
Adjusted likelihood: -1200.59375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 20
Loaded trajectory sampler
Current yaw: tensor([-0.0022,  0.0148, -0.0408], device='cuda:1')
Current yaw: tensor([-0.0022,  0.0148, -0.0408], device='cuda:1')
1 turn
Sampling time 3.933154488011496
tensor([ 0.1451,  0.6109,  0.5896,  0.5518, -0.1194,  0.5008,  0.9354,  0.9378,
         1.2469,  0.2849,  0.2597,  1.1247, -0.0022,  0.0148, -0.0408, -0.0200],
       device='cuda:1')
Original likelihood: -17.741565704345703
Adjusted likelihood: -17.741565704345703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.024506148009095
Current ori: tensor([-0.0022,  0.0148, -0.0408], device='cuda:1')
Middle force: tensor([0.7582, 1.6823, 0.6399, 0.5537, 0.7872, 0.5771, 0.5694, 0.5699, 0.4994,
        0.5813, 0.5291, 0.4847], device='cuda:1')
Thumb force: tensor([0.6024, 1.8098, 1.8978, 1.5549, 1.1646, 0.7311, 0.5130, 0.5229, 0.6009,
        1.2990, 0.5989, 0.6326], device='cuda:1')
Index force: tensor([0.7230, 1.3833, 0.6116, 0.5083, 1.3624, 0.6016, 0.5034, 0.6077, 0.6696,
        0.6155, 0.5696, 0.8818], device='cuda:1')
Storing NORMAL transition: reward=0.0180 (scaled=0.0180), steps=1
Reward stats updated: mean -0.0056 -> -0.0056, std: 0.1527
Collected 317 transitions for RL
SAC Update 1/5: Actor Loss=-0.0228, Q1 Loss=0.7376, Q2 Loss=0.7376, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2636
SAC Update 2/5: Actor Loss=-0.0230, Q1 Loss=1.2068, Q2 Loss=1.2068, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9795
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.9417, Q2 Loss=0.9417, Entropy=0.3362, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6099
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=7.0651, Q2 Loss=7.0651, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.7776
SAC Update 5/5: Actor Loss=-0.0014, Q1 Loss=0.8634, Q2 Loss=0.8634, Entropy=0.2764, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1346

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.4%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009548
Q1 loss: 2.162942
Q2 loss: 2.162942
Current threshold: -24.6392
Global Scale Offset: 0.0786
Reward stats: mean=-0.0056, std=0.1527, count=317
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 2.1629, Q2 Loss: 2.1629, Entropy: 0.1225, Mean TD Error: 1.7530, Threshold: -24.6392
tensor([ 0.1138,  0.6480,  0.5767,  0.3772, -0.0641,  0.4102,  0.8955,  1.1704,
         1.1793,  0.2184,  0.3348,  1.1653, -0.0111,  0.0130, -0.0589, -0.4075],
       device='cuda:1')
Original likelihood: -24.653606414794922
Adjusted likelihood: -24.653606414794922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4789)
State is out of distribution
Projection step: 0, Loss: 24.454010009765625
Projection step: 1, Loss: 19.487998962402344
Projection step: 2, Loss: 17.463275909423828
Projection step: 3, Loss: 15.635662078857422
Projection step: 4, Loss: 14.090057373046875
Final likelihood: tensor([-12.5758, -12.4937, -12.4803, -15.3864, -13.7274, -14.4028, -10.5560,
        -20.9915, -14.7371, -13.8341, -16.4559, -10.0319, -12.1408, -15.9467,
        -13.8302, -15.8503])
Final projection likelihood: -14.0901
1 mode projection succeeded
New goal: tensor([ 0.0967,  0.6356,  0.5266,  0.4849, -0.0789,  0.4157,  0.7702,  1.0957,
         1.2345,  0.3384,  0.2383,  1.0873, -0.0099,  0.0132, -1.1194],
       device='cuda:1')
tensor([[0.0065]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -20.861225128173828
Adjusted likelihood: -20.861225128173828
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.861225128173828}
Current yaw: tensor([-0.0111,  0.0130, -0.0589], device='cuda:1')
2 thumb_middle
tensor([ 0.1138,  0.6480,  0.5767,  0.3772, -0.0641,  0.4102,  0.8955,  1.1704,
         1.1793,  0.2184,  0.3348,  1.1653, -0.0111,  0.0130, -0.0589, -0.4075],
       device='cuda:1')
Solve time for step 1 9.016368288983358
Current ori: tensor([-0.0111,  0.0130, -0.0589], device='cuda:1')
Index force: tensor([0.5812, 0.5680, 0.5951, 0.5936], device='cuda:1')
tensor([ 0.1081,  0.6546,  0.5366,  0.4433, -0.1354,  0.3926,  0.7787,  1.1025,
         1.1781,  0.3089,  0.2183,  1.0916, -0.0084,  0.0165, -0.0589, -0.4098],
       device='cuda:1')
Solve time for step 2 1.9996697469905484
Current ori: tensor([-0.0084,  0.0165, -0.0589], device='cuda:1')
Index force: tensor([0.5616, 0.5898, 0.5874], device='cuda:1')
tensor([ 0.0961,  0.6435,  0.5321,  0.4697, -0.1558,  0.4110,  0.7733,  1.0972,
         1.2187,  0.3089,  0.1795,  1.0939, -0.0041,  0.0233, -0.0589, -0.4128],
       device='cuda:1')
Solve time for step 3 1.9145318109949585
Current ori: tensor([-0.0041,  0.0233, -0.0589], device='cuda:1')
Index force: tensor([0.5837, 0.5821], device='cuda:1')
tensor([ 0.0966,  0.6499,  0.5221,  0.4711, -0.1438,  0.4062,  0.7694,  1.0976,
         1.2281,  0.3174,  0.1718,  1.0753, -0.0054,  0.0230, -0.0589, -0.4140],
       device='cuda:1')
Solve time for step 4 1.9772646889905445
Current ori: tensor([-0.0054,  0.0230, -0.0589], device='cuda:1')
Index force: tensor([0.5665], device='cuda:1')
Storing RECOVERY transition: reward=-0.0179 (scaled=-0.0179), steps=1
Reward stats updated: mean -0.0056 -> -0.0056, std: 0.1525
Collected 318 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2368, Q2 Loss=1.2368, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4127
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1869, Q2 Loss=1.1869, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2394
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=3.3680, Q2 Loss=3.3680, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7223
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=1.0377, Q2 Loss=1.0377, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1760
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2359, Q2 Loss=1.2359, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4540

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (18.2%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (43.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004605
Q1 loss: 1.613042
Q2 loss: 1.613042
Current threshold: -24.6075
Global Scale Offset: 0.0775
Reward stats: mean=-0.0056, std=0.1525, count=318
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.6130, Q2 Loss: 1.6130, Entropy: 0.0000, Mean TD Error: 1.4009, Threshold: -24.6075
Original likelihood: -22.961566925048828
Adjusted likelihood: -22.961566925048828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0008,  0.0343, -0.0418], device='cuda:1')
3 turn
Sampling time 3.6916771729884204
tensor([ 7.4600e-02,  6.3555e-01,  5.1767e-01,  4.8179e-01, -1.0350e-01,
         4.6748e-01,  7.8858e-01,  1.0886e+00,  1.2928e+00,  3.4829e-01,
         2.2960e-01,  1.1102e+00, -8.4599e-04,  3.4322e-02, -4.1783e-02,
        -4.2374e-01], device='cuda:1')
Original likelihood: -23.66997528076172
Adjusted likelihood: -23.66997528076172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 1 14.415767230006168
Current ori: tensor([-0.0008,  0.0343, -0.0418], device='cuda:1')
Middle force: tensor([0.5346, 0.4981, 1.2746, 1.3040, 0.5823, 0.5379, 0.5125, 0.5463, 0.5618,
        0.5644, 0.5292, 0.5014], device='cuda:1')
Thumb force: tensor([0.7581, 0.5473, 1.1771, 1.0784, 0.6787, 0.8481, 0.5312, 1.2252, 0.6245,
        0.9032, 0.6094, 1.0130], device='cuda:1')
Index force: tensor([0.5092, 0.6642, 0.5856, 0.5344, 0.9123, 0.5494, 0.5839, 0.4964, 0.5064,
        0.6132, 0.6989, 0.6570], device='cuda:1')
Storing NORMAL transition: reward=0.0089 (scaled=0.0089), steps=1
Reward stats updated: mean -0.0056 -> -0.0055, std: 0.1522
Collected 319 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.9644, Q2 Loss=1.9644, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.3188
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0166, Q2 Loss=1.0166, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4219
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0765, Q2 Loss=1.0765, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5017
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.3555, Q2 Loss=1.3555, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6882
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2300, Q2 Loss=1.2300, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1380

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 1.328615
Q2 loss: 1.328615
Current threshold: -24.5887
Global Scale Offset: 0.0769
Reward stats: mean=-0.0055, std=0.1522, count=319
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.3286, Q2 Loss: 1.3286, Entropy: 0.0000, Mean TD Error: 2.6137, Threshold: -24.5887
tensor([ 0.0709,  0.6171,  0.5349,  0.4953, -0.1129,  0.4615,  0.8132,  1.0481,
         1.4469,  0.1297,  0.0958,  1.1944,  0.0030,  0.0383, -0.0510, -0.4591],
       device='cuda:1')
Original likelihood: -28.434755325317383
Adjusted likelihood: -28.434755325317383
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 27.158912658691406
Projection step: 1, Loss: 22.64208984375
Projection step: 2, Loss: 20.92531394958496
Projection step: 3, Loss: 17.61016082763672
Projection step: 4, Loss: 16.034255981445312
Projection step: 5, Loss: 15.291592597961426
Projection step: 6, Loss: 12.122498512268066
Final likelihood: tensor([-10.4261, -10.8857, -12.0552, -10.8765, -10.4970, -12.0870, -16.3691,
        -13.0353, -16.2978, -10.5933, -12.7895, -12.9877, -10.7161, -11.1880,
        -10.1876, -12.9680])
Final projection likelihood: -12.1225
1 mode projection succeeded
New goal: tensor([ 4.1657e-02,  6.0744e-01,  4.8619e-01,  5.8474e-01, -1.0045e-01,
         4.6215e-01,  8.3256e-01,  9.4707e-01,  1.3803e+00,  1.2941e-01,
         1.4546e-01,  1.1698e+00,  1.1755e-03,  2.2314e-02, -1.7497e+00],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -21.901302337646484
Adjusted likelihood: -21.901302337646484
Likelihood residual: 0.0
Original likelihood: -23.65677261352539
Adjusted likelihood: -23.65677261352539
Likelihood residual: 0.0
{'index': 23.65677261352539, 'thumb_middle': 21.901302337646484}
Current yaw: tensor([ 0.0030,  0.0383, -0.0510], device='cuda:1')
4 thumb_middle
tensor([ 0.0709,  0.6171,  0.5349,  0.4953, -0.1129,  0.4615,  0.8132,  1.0481,
         1.4469,  0.1297,  0.0958,  1.1944,  0.0030,  0.0383, -0.0510, -0.4591],
       device='cuda:1')
Solve time for step 1 9.198165507987142
Current ori: tensor([ 0.0030,  0.0383, -0.0510], device='cuda:1')
Index force: tensor([0.5746, 0.5724, 0.5882, 0.5926], device='cuda:1')
tensor([ 0.0666,  0.6296,  0.4903,  0.5380, -0.1899,  0.4306,  0.7836,  0.9398,
         1.3718,  0.1118,  0.0762,  1.1515,  0.0038,  0.0412, -0.0510, -0.4566],
       device='cuda:1')
Solve time for step 2 2.03385693099699
Current ori: tensor([ 0.0038,  0.0412, -0.0510], device='cuda:1')
Index force: tensor([0.5683, 0.5854, 0.5902], device='cuda:1')
tensor([ 0.0814,  0.6335,  0.4833,  0.5699, -0.2015,  0.4726,  0.8039,  0.9272,
         1.3604,  0.1094,  0.0745,  1.1515,  0.0050,  0.0334, -0.0510, -0.4278],
       device='cuda:1')
Solve time for step 3 1.8592960790265352
Current ori: tensor([ 0.0050,  0.0334, -0.0510], device='cuda:1')
Index force: tensor([0.5806, 0.5866], device='cuda:1')
tensor([ 0.0900,  0.6359,  0.4876,  0.5719, -0.1945,  0.4642,  0.8242,  0.9355,
         1.3705,  0.1032,  0.0617,  1.1305,  0.0043,  0.0286, -0.0510, -0.4172],
       device='cuda:1')
Solve time for step 4 1.8560602030192968
Current ori: tensor([ 0.0043,  0.0286, -0.0510], device='cuda:1')
Index force: tensor([0.5770], device='cuda:1')
Storing RECOVERY transition: reward=-0.0138 (scaled=-0.0138), steps=1
Reward stats updated: mean -0.0055 -> -0.0056, std: 0.1520
Collected 320 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1334, Q2 Loss=1.1334, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4738
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8728, Q2 Loss=0.8728, Entropy=0.3366, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5044
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1772, Q2 Loss=1.1772, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7749
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6874, Q2 Loss=0.6874, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1007
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=0.8460, Q2 Loss=0.8460, Entropy=0.3347, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3466

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.2%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.05s (19.9%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000115
Q1 loss: 0.943341
Q2 loss: 0.943341
Current threshold: -24.5796
Global Scale Offset: 0.0766
Reward stats: mean=-0.0056, std=0.1520, count=320
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.9433, Q2 Loss: 0.9433, Entropy: 0.1343, Mean TD Error: 0.4401, Threshold: -24.5796
Original likelihood: -28.599163055419922
Adjusted likelihood: -28.599163055419922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 27.857402801513672
Projection step: 1, Loss: 24.42864418029785
Projection step: 2, Loss: 19.98519515991211
Projection step: 3, Loss: 17.746490478515625
Projection step: 4, Loss: 16.346878051757812
Projection step: 5, Loss: 13.263761520385742
Final likelihood: tensor([-13.0482, -11.6491, -15.8010, -12.5487, -12.6844, -16.7788, -11.3171,
        -13.2003, -10.9789, -12.8287, -13.2102, -12.9289, -13.1266, -11.5721,
        -14.8673, -15.6800])
Final projection likelihood: -13.2638
1 mode projection succeeded
New goal: tensor([ 0.0446,  0.6077,  0.4853,  0.5954, -0.1154,  0.4797,  0.8553,  0.8890,
         1.3718,  0.1279,  0.1474,  1.1915,  0.0116,  0.0270, -1.0209],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -20.38182830810547
Adjusted likelihood: -20.38182830810547
Likelihood residual: 0.0
Original likelihood: -19.147281646728516
Adjusted likelihood: -19.147281646728516
Likelihood residual: 0.0
{'index': 19.147281646728516, 'thumb_middle': 20.38182830810547}
Current yaw: tensor([ 0.0109,  0.0433, -0.0376], device='cuda:1')
5 index
tensor([ 0.0619,  0.6149,  0.4852,  0.5798, -0.1454,  0.5024,  0.8375,  0.9550,
         1.4448,  0.1378,  0.1182,  1.1713,  0.0109,  0.0433, -0.0376, -0.4260],
       device='cuda:1')
Solve time for step 1 10.639216349984054
Current ori: tensor([ 0.0109,  0.0433, -0.0376], device='cuda:1')
Middle force: tensor([0.6122, 0.5177, 0.5124, 0.5031], device='cuda:1')
Thumb force: tensor([0.5491, 0.5578, 0.6092, 0.5823], device='cuda:1')
tensor([ 0.0996,  0.5495,  0.4328,  0.5709, -0.1288,  0.4943,  0.8741,  0.9271,
         1.4333,  0.1471,  0.1049,  1.1795,  0.0095,  0.0321, -0.0552,  0.2528],
       device='cuda:1')
Solve time for step 2 2.3611301150231156
Current ori: tensor([ 0.0095,  0.0321, -0.0552], device='cuda:1')
Middle force: tensor([0.5166, 0.5115, 0.5028], device='cuda:1')
Thumb force: tensor([0.5552, 0.6068, 0.5799], device='cuda:1')
tensor([ 0.0982,  0.5540,  0.4361,  0.5698, -0.1328,  0.4978,  0.8732,  0.9112,
         1.4397,  0.1402,  0.1079,  1.1683,  0.0062,  0.0351, -0.0524,  0.6414],
       device='cuda:1')
Solve time for step 3 2.230586787016364
Current ori: tensor([ 0.0062,  0.0351, -0.0524], device='cuda:1')
Middle force: tensor([0.5171, 0.5458], device='cuda:1')
Thumb force: tensor([0.5832, 0.5511], device='cuda:1')
tensor([ 0.0990,  0.5599,  0.4329,  0.5730, -0.1281,  0.4909,  0.8853,  0.9153,
         1.4310,  0.1560,  0.0993,  1.1833,  0.0073,  0.0315, -0.0704,  0.8146],
       device='cuda:1')
Solve time for step 4 2.172252831980586
Current ori: tensor([ 0.0073,  0.0315, -0.0704], device='cuda:1')
Middle force: tensor([0.5543], device='cuda:1')
Thumb force: tensor([0.5626], device='cuda:1')
Storing RECOVERY transition: reward=0.0043 (scaled=0.0043), steps=1
Reward stats updated: mean -0.0056 -> -0.0055, std: 0.1518
Collected 321 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2142, Q2 Loss=1.2142, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8199
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1913, Q2 Loss=1.1913, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2320
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2658, Q2 Loss=1.2658, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1787
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7706, Q2 Loss=0.7706, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2601
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3090, Q2 Loss=1.3090, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6521

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 1.150188
Q2 loss: 1.150188
Current threshold: -24.5784
Global Scale Offset: 0.0764
Reward stats: mean=-0.0055, std=0.1518, count=321
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.1502, Q2 Loss: 1.1502, Entropy: 0.0000, Mean TD Error: 1.4285, Threshold: -24.5784
Original likelihood: -22.27356719970703
Adjusted likelihood: -22.27356719970703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0055,  0.0334, -0.0550], device='cuda:1')
6 turn
Sampling time 3.940828456019517
tensor([ 0.0489,  0.6152,  0.4674,  0.5918, -0.1327,  0.5011,  0.8781,  0.9041,
         1.4330,  0.1530,  0.1003,  1.1827,  0.0055,  0.0334, -0.0550,  0.8111],
       device='cuda:1')
Original likelihood: -21.212223052978516
Adjusted likelihood: -21.212223052978516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.304350672988221
Current ori: tensor([ 0.0055,  0.0334, -0.0550], device='cuda:1')
Middle force: tensor([2.4007, 1.0164, 0.6058, 0.5019, 0.5679, 0.9984, 0.5871, 0.5786, 0.5315,
        0.5112, 0.5684, 0.5029], device='cuda:1')
Thumb force: tensor([2.5781, 2.4404, 0.8799, 0.5553, 0.5795, 0.5703, 0.5512, 0.6262, 0.5584,
        0.5658, 0.6104, 0.8117], device='cuda:1')
Index force: tensor([1.0866, 1.1721, 0.6029, 0.9799, 0.5426, 0.5503, 0.5610, 0.6183, 0.5599,
        0.5869, 0.6163, 0.6153], device='cuda:1')
Storing NORMAL transition: reward=0.1996 (scaled=0.1996), steps=1
Reward stats updated: mean -0.0055 -> -0.0049, std: 0.1520
Collected 322 transitions for RL
SAC Update 1/5: Actor Loss=-0.0173, Q1 Loss=1.3159, Q2 Loss=1.3159, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8541
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1219, Q2 Loss=1.1219, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7150
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0845, Q2 Loss=1.0845, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2647
SAC Update 4/5: Actor Loss=-0.0041, Q1 Loss=0.8113, Q2 Loss=0.8113, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4515
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6867, Q2 Loss=1.6867, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.2318

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (42.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004275
Q1 loss: 1.204070
Q2 loss: 1.204070
Current threshold: -24.5777
Global Scale Offset: 0.0762
Reward stats: mean=-0.0049, std=0.1520, count=322
----------------------------------------------
SAC Update - Actor Loss: -0.0043, Q1 Loss: 1.2041, Q2 Loss: 1.2041, Entropy: 0.0000, Mean TD Error: 1.7034, Threshold: -24.5777
tensor([ 0.0665,  0.6144,  0.4912,  0.5810, -0.1041,  0.4559,  0.9509,  0.9477,
         1.3881,  0.2392,  0.1649,  1.0206,  0.0021,  0.0130, -0.2537,  1.1502],
       device='cuda:1')
Original likelihood: -10.671833038330078
Adjusted likelihood: -10.671833038330078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.897177009988809
Current ori: tensor([ 0.0021,  0.0130, -0.2537], device='cuda:1')
Middle force: tensor([1.0170, 0.6048, 0.5018, 0.5679, 0.9891, 0.5894, 0.5801, 0.5319, 0.5108,
        0.5728, 0.5030], device='cuda:1')
Thumb force: tensor([2.3965, 0.8729, 0.5517, 0.5751, 0.5656, 0.5476, 0.6183, 0.5535, 0.5634,
        0.6007, 0.8033], device='cuda:1')
Index force: tensor([1.1563, 0.6016, 0.9812, 0.5416, 0.5488, 0.5598, 0.6181, 0.5597, 0.5853,
        0.6139, 0.6114], device='cuda:1')
Storing NORMAL transition: reward=-0.0827 (scaled=-0.0827), steps=1
Reward stats updated: mean -0.0049 -> -0.0051, std: 0.1518
Collected 323 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8701, Q2 Loss=0.8701, Entropy=0.2722, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.2984
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.5151, Q2 Loss=1.5151, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2530
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1833, Q2 Loss=1.1833, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3423
SAC Update 4/5: Actor Loss=-0.0009, Q1 Loss=0.8712, Q2 Loss=0.8712, Entropy=0.3402, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7148
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2713, Q2 Loss=1.2713, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0201

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (20.5%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000179
Q1 loss: 1.142212
Q2 loss: 1.142212
Current threshold: -24.5735
Global Scale Offset: 0.0762
Reward stats: mean=-0.0051, std=0.1518, count=323
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.1422, Q2 Loss: 1.1422, Entropy: 0.1225, Mean TD Error: 1.1257, Threshold: -24.5735
tensor([ 0.0439,  0.6163,  0.5037,  0.5112, -0.2412,  0.4586,  0.9031,  0.9144,
         1.4657,  0.0221,  0.2149,  0.9761, -0.0032,  0.0271, -0.1717,  1.0042],
       device='cuda:1')
Original likelihood: -31.49294090270996
Adjusted likelihood: -31.49294090270996
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.513572692871094
Projection step: 1, Loss: 27.26283073425293
Projection step: 2, Loss: 24.479427337646484
Projection step: 3, Loss: 20.63052749633789
Projection step: 4, Loss: 16.448381423950195
Projection step: 5, Loss: 13.131248474121094
Final likelihood: tensor([-12.6509, -12.6602, -13.0616, -13.2437, -13.0864, -13.1329, -13.6166,
        -13.4582, -12.7983, -13.4212, -12.4201, -13.1755, -13.2395, -13.9930,
        -13.3341, -12.8078])
Final projection likelihood: -13.1312
1 mode projection succeeded
New goal: tensor([ 0.0230,  0.6189,  0.4600,  0.5209, -0.1354,  0.4895,  0.9029,  0.9023,
         1.4260,  0.0227,  0.1999,  1.0610, -0.0054,  0.0223, -0.5784],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0125]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -19.40904998779297
Adjusted likelihood: -19.40904998779297
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 19.40904998779297}
Current yaw: tensor([-0.0032,  0.0271, -0.1717], device='cuda:1')
7 thumb_middle
tensor([ 0.0439,  0.6163,  0.5037,  0.5112, -0.2412,  0.4586,  0.9031,  0.9144,
         1.4657,  0.0221,  0.2149,  0.9761, -0.0032,  0.0271, -0.1717,  1.0042],
       device='cuda:1')
Solve time for step 1 9.223968278995017
Current ori: tensor([-0.0032,  0.0271, -0.1717], device='cuda:1')
Index force: tensor([0.5841, 0.5803, 0.6046, 0.6062], device='cuda:1')
tensor([ 0.0225,  0.6363,  0.4575,  0.4907, -0.2406,  0.4744,  0.8849,  0.8898,
         1.4046, -0.0075,  0.1484,  1.0238, -0.0089,  0.0386, -0.1717,  0.9626],
       device='cuda:1')
Solve time for step 2 1.9652015699830372
Current ori: tensor([-0.0089,  0.0386, -0.1717], device='cuda:1')
Index force: tensor([0.5762, 0.6015, 0.6027], device='cuda:1')
tensor([ 0.0139,  0.6355,  0.4527,  0.4839, -0.2416,  0.4835,  0.8816,  0.8887,
         1.4125, -0.0034,  0.1368,  1.0352, -0.0090,  0.0436, -0.1717,  0.9483],
       device='cuda:1')
Solve time for step 3 2.017974201007746
Current ori: tensor([-0.0090,  0.0436, -0.1717], device='cuda:1')
Index force: tensor([0.5961, 0.5986], device='cuda:1')
tensor([ 0.0191,  0.6332,  0.4544,  0.5039, -0.2388,  0.4873,  0.8828,  0.8852,
         1.4118, -0.0064,  0.1337,  1.0382, -0.0071,  0.0403, -0.1716,  0.9636],
       device='cuda:1')
Solve time for step 4 1.8254452510154806
Current ori: tensor([-0.0071,  0.0403, -0.1716], device='cuda:1')
Index force: tensor([0.5797], device='cuda:1')
Storing RECOVERY transition: reward=-0.0015 (scaled=-0.0008), steps=2
Reward stats updated: mean -0.0051 -> -0.0051, std: 0.1516
Collected 324 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=1.3027, Q2 Loss=1.3027, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0682
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1521, Q2 Loss=1.1521, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.9266
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3842, Q2 Loss=1.3842, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8377
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.2911, Q2 Loss=1.2911, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5616
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2924, Q2 Loss=1.2924, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5931

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.9%)
Target Q: 0.04s (14.6%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (43.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004605
Q1 loss: 1.284509
Q2 loss: 1.284509
Current threshold: -24.5667
Global Scale Offset: 0.0761
Reward stats: mean=-0.0051, std=0.1516, count=324
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.2845, Q2 Loss: 1.2845, Entropy: 0.0000, Mean TD Error: 1.1974, Threshold: -24.5667
Original likelihood: -24.585784912109375
Adjusted likelihood: -24.585784912109375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4714)
Current yaw: tensor([-0.0043,  0.0431, -0.1716], device='cuda:1')
8 turn
Sampling time 3.7147149509983137
tensor([ 0.0120,  0.6287,  0.4500,  0.5178, -0.1840,  0.5258,  0.9063,  0.9001,
         1.4803,  0.0280,  0.1789,  1.0612, -0.0043,  0.0431, -0.1716,  0.9672],
       device='cuda:1')
Original likelihood: -25.640172958374023
Adjusted likelihood: -25.640172958374023
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 25.53868865966797
Projection step: 1, Loss: 22.815921783447266
Projection step: 2, Loss: 19.988147735595703
Projection step: 3, Loss: 18.1402587890625
Projection step: 4, Loss: 16.177501678466797
Projection step: 5, Loss: 16.15593910217285
Projection step: 6, Loss: 15.149304389953613
Projection step: 7, Loss: 14.686454772949219
Final likelihood: tensor([-13.3967, -12.0242, -12.3604, -16.7767, -17.5956, -11.2926, -12.3456,
        -17.7311, -17.0221, -14.0853, -16.9058, -12.7471, -13.8267, -12.3352,
        -17.6485, -16.8898])
Final projection likelihood: -14.6865
1 mode projection succeeded
New goal: tensor([ 0.0403,  0.6148,  0.4608,  0.5731, -0.1176,  0.4932,  0.8559,  0.8563,
         1.3764,  0.0512,  0.1701,  1.1528, -0.0132,  0.0286, -0.4182],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -18.321531295776367
Adjusted likelihood: -18.321531295776367
Likelihood residual: 0.0
Original likelihood: -17.371963500976562
Adjusted likelihood: -17.371963500976562
Likelihood residual: 0.0
{'index': 17.371963500976562, 'thumb_middle': 18.321531295776367}
Current yaw: tensor([-0.0043,  0.0431, -0.1716], device='cuda:1')
9 index
tensor([ 0.0120,  0.6287,  0.4500,  0.5178, -0.1840,  0.5258,  0.9063,  0.9001,
         1.4803,  0.0280,  0.1789,  1.0612, -0.0043,  0.0431, -0.1716,  0.9672],
       device='cuda:1')
Solve time for step 1 10.758978136989754
Current ori: tensor([-0.0043,  0.0431, -0.1716], device='cuda:1')
Middle force: tensor([0.5317, 0.5239, 0.5913, 0.5196], device='cuda:1')
Thumb force: tensor([0.5941, 0.5116, 0.5801, 0.6630], device='cuda:1')
tensor([ 0.0809,  0.5593,  0.4079,  0.5402, -0.1798,  0.5384,  0.9112,  0.8993,
         1.5000, -0.0189,  0.1510,  1.0633, -0.0139,  0.0357, -0.1815,  1.6111],
       device='cuda:1')
Solve time for step 2 2.4829334630048834
Current ori: tensor([-0.0139,  0.0357, -0.1815], device='cuda:1')
Middle force: tensor([0.5233, 0.5895, 0.5190], device='cuda:1')
Thumb force: tensor([0.5106, 0.5780, 0.6598], device='cuda:1')
tensor([ 0.0813,  0.5637,  0.4139,  0.5449, -0.1821,  0.5304,  0.9212,  0.9101,
         1.4431,  0.1018,  0.1486,  1.0965, -0.0126,  0.0356, -0.1967,  1.8844],
       device='cuda:1')
Solve time for step 3 2.4129257410240825
Current ori: tensor([-0.0126,  0.0356, -0.1967], device='cuda:1')
Middle force: tensor([0.5859, 0.5180], device='cuda:1')
Thumb force: tensor([0.5735, 0.6569], device='cuda:1')
tensor([ 0.0823,  0.5672,  0.4125,  0.5471, -0.1700,  0.5427,  0.9170,  0.9009,
         1.4542,  0.0757,  0.1230,  1.1115, -0.0177,  0.0280, -0.2026,  1.8898],
       device='cuda:1')
Solve time for step 4 2.1175820979988202
Current ori: tensor([-0.0177,  0.0280, -0.2026], device='cuda:1')
Middle force: tensor([0.5185], device='cuda:1')
Thumb force: tensor([0.5203], device='cuda:1')
Storing RECOVERY transition: reward=0.0274 (scaled=0.0274), steps=0
Reward stats updated: mean -0.0051 -> -0.0050, std: 0.1513
Collected 325 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7628, Q2 Loss=0.7628, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2538
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=0.8498, Q2 Loss=0.8498, Entropy=0.2594, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1058
SAC Update 3/5: Actor Loss=-0.0186, Q1 Loss=1.2850, Q2 Loss=1.2850, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5810
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7218, Q2 Loss=0.7218, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7774
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=1.1972, Q2 Loss=1.1972, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0192

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.3%)
Actor update: 0.10s (38.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008627
Q1 loss: 0.963310
Q2 loss: 0.963310
Current threshold: -24.5527
Global Scale Offset: 0.0760
Reward stats: mean=-0.0050, std=0.1513, count=325
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 0.9633, Q2 Loss: 0.9633, Entropy: 0.0519, Mean TD Error: 1.7474, Threshold: -24.5527
Original likelihood: -18.26702880859375
Adjusted likelihood: -18.26702880859375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0227,  0.0334, -0.1988], device='cuda:1')
10 turn
Sampling time 3.7236737589992117
tensor([ 0.0302,  0.6247,  0.4507,  0.5659, -0.1770,  0.5533,  0.9048,  0.8881,
         1.4634,  0.0741,  0.1197,  1.1069, -0.0227,  0.0334, -0.1988,  1.8608],
       device='cuda:1')
Original likelihood: -17.44583511352539
Adjusted likelihood: -17.44583511352539
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.243833827000344
Current ori: tensor([-0.0227,  0.0334, -0.1988], device='cuda:1')
Middle force: tensor([0.5670, 0.6749, 1.3274, 1.3686, 1.9489, 0.5670, 0.5601, 0.5436, 0.9813,
        0.8049, 0.6824, 0.5693], device='cuda:1')
Thumb force: tensor([0.6099, 1.2878, 0.5540, 1.1946, 1.1418, 0.6184, 1.1323, 0.8509, 1.2782,
        1.3507, 0.5460, 0.9503], device='cuda:1')
Index force: tensor([0.6368, 1.0026, 0.8006, 0.7669, 0.7138, 0.5502, 0.5522, 0.5753, 0.5246,
        0.9863, 0.6628, 0.6532], device='cuda:1')
Storing NORMAL transition: reward=-0.0026 (scaled=-0.0026), steps=1
Reward stats updated: mean -0.0050 -> -0.0050, std: 0.1511
Collected 326 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7743, Q2 Loss=0.7743, Entropy=0.0020, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3079
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.5915, Q2 Loss=1.5915, Entropy=0.0190, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.2568
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0819, Q2 Loss=1.0819, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5378
SAC Update 4/5: Actor Loss=-0.0097, Q1 Loss=1.1748, Q2 Loss=1.1748, Entropy=0.0132, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5488
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9526, Q2 Loss=0.9526, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1238

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.3%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001945
Q1 loss: 1.115032
Q2 loss: 1.115032
Current threshold: -24.5293
Global Scale Offset: 0.0754
Reward stats: mean=-0.0050, std=0.1511, count=326
----------------------------------------------
SAC Update - Actor Loss: -0.0019, Q1 Loss: 1.1150, Q2 Loss: 1.1150, Entropy: 0.0068, Mean TD Error: 1.7550, Threshold: -24.5293
tensor([ 0.1671,  0.6372,  0.5431,  0.5756, -0.2724,  0.6322,  0.8677,  0.8112,
         1.5000,  0.0914,  0.1163,  0.9585, -0.0538,  0.0780, -0.2032, -0.5538],
       device='cuda:1')
Original likelihood: -35.02021026611328
Adjusted likelihood: -35.02021026611328
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 32.378841400146484
Projection step: 1, Loss: 31.141284942626953
Projection step: 2, Loss: 30.45821189880371
Projection step: 3, Loss: 31.424766540527344
Projection step: 4, Loss: 29.354938507080078
Projection step: 5, Loss: 28.617557525634766
Projection step: 6, Loss: 28.344064712524414
Projection step: 7, Loss: 28.18448257446289
Projection step: 8, Loss: 29.01303482055664
Projection step: 9, Loss: 29.516582489013672
Projection step: 10, Loss: 28.934226989746094
Projection step: 11, Loss: 29.374313354492188
Projection step: 12, Loss: 28.341899871826172
Projection step: 13, Loss: 32.73756408691406
Projection step: 14, Loss: 27.40896987915039
Final likelihood: tensor([-25.5397, -22.3582, -31.0705, -27.3370, -23.5106, -25.7389, -22.4974,
        -23.6321, -24.0326, -25.9061, -25.1916, -26.3989, -22.2487, -26.0701,
        -23.0054, -27.1072])
Final projection likelihood: -25.1028
1 mode projection failed, trying anyway
New goal: tensor([ 0.0961,  0.6042,  0.4701,  0.6717, -0.1740,  0.6048,  0.8045,  0.7903,
         1.4612,  0.0649,  0.1595,  1.1303, -0.0569,  0.0551,  1.1387],
       device='cuda:1')
tensor([[0.0071]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0035]], device='cuda:1')
Original likelihood: -30.513078689575195
Adjusted likelihood: -30.513078689575195
Likelihood residual: 0.0
Original likelihood: -26.726795196533203
Adjusted likelihood: -26.726795196533203
Likelihood residual: 0.0
{'index': 26.726795196533203, 'thumb_middle': 30.513078689575195}
Current yaw: tensor([-0.0538,  0.0780, -0.2032], device='cuda:1')
11 index
tensor([ 0.1671,  0.6372,  0.5431,  0.5756, -0.2724,  0.6322,  0.8677,  0.8112,
         1.5000,  0.0914,  0.1163,  0.9585, -0.0538,  0.0780, -0.2032, -0.5538],
       device='cuda:1')
Solve time for step 1 10.492952998989495
Current ori: tensor([-0.0538,  0.0780, -0.2032], device='cuda:1')
Middle force: tensor([0.5959, 0.5600, 0.5138, 0.5925], device='cuda:1')
Thumb force: tensor([0.5579, 0.5639, 0.5476, 0.5261], device='cuda:1')
tensor([ 0.1526,  0.5569,  0.4414,  0.6281, -0.2357,  0.6419,  0.8713,  0.8343,
         1.5000,  0.0794,  0.0984,  1.0326, -0.0602,  0.0502, -0.2299, -1.6665],
       device='cuda:1')
Solve time for step 2 2.235556973988423
Current ori: tensor([-0.0602,  0.0502, -0.2299], device='cuda:1')
Middle force: tensor([0.5590, 0.5132, 0.5898], device='cuda:1')
Thumb force: tensor([0.5607, 0.5460, 0.5251], device='cuda:1')
tensor([ 0.1374,  0.5595,  0.4294,  0.6414, -0.2293,  0.6552,  0.8587,  0.8275,
         1.5000,  0.0725,  0.0879,  1.0431, -0.0633,  0.0458, -0.2128, -2.3516],
       device='cuda:1')
Solve time for step 3 2.1283678409818094
Current ori: tensor([-0.0633,  0.0458, -0.2128], device='cuda:1')
Middle force: tensor([0.5677, 0.5517], device='cuda:1')
Thumb force: tensor([0.5447, 0.6393], device='cuda:1')
tensor([ 0.1329,  0.5613,  0.4259,  0.6444, -0.2375,  0.6501,  0.8611,  0.8360,
         1.5000,  0.0757,  0.0900,  1.0580, -0.0600,  0.0502, -0.1929, -3.0299],
       device='cuda:1')
Solve time for step 4 2.111568779015215
Current ori: tensor([-0.0600,  0.0502, -0.1929], device='cuda:1')
Middle force: tensor([0.5821], device='cuda:1')
Thumb force: tensor([0.5229], device='cuda:1')
Storing RECOVERY transition: reward=-0.0245 (scaled=-0.0245), steps=1
Reward stats updated: mean -0.0050 -> -0.0051, std: 0.1509
Collected 327 transitions for RL
SAC Update 1/5: Actor Loss=-0.0048, Q1 Loss=0.8411, Q2 Loss=0.8411, Entropy=0.0003, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5735
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0845, Q2 Loss=1.0845, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3905
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2869, Q2 Loss=1.2869, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2263
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7532, Q2 Loss=0.7532, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3235
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.9067, Q2 Loss=0.9067, Entropy=0.2989, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2327

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (37.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001027
Q1 loss: 0.974468
Q2 loss: 0.974468
Current threshold: -24.5012
Global Scale Offset: 0.0744
Reward stats: mean=-0.0051, std=0.1509, count=327
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 0.9745, Q2 Loss: 0.9745, Entropy: 0.0599, Mean TD Error: 0.3493, Threshold: -24.5012
Original likelihood: -29.056577682495117
Adjusted likelihood: -29.056577682495117
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 27.947437286376953
Projection step: 1, Loss: 27.37322235107422
Projection step: 2, Loss: 26.749370574951172
Projection step: 3, Loss: 25.812328338623047
Projection step: 4, Loss: 24.687664031982422
Projection step: 5, Loss: 23.383556365966797
Projection step: 6, Loss: 23.087392807006836
Projection step: 7, Loss: 21.893569946289062
Projection step: 8, Loss: 21.720462799072266
Projection step: 9, Loss: 21.742576599121094
Projection step: 10, Loss: 21.197057723999023
Projection step: 11, Loss: 20.301681518554688
Projection step: 12, Loss: 19.73281478881836
Projection step: 13, Loss: 18.82257652282715
Projection step: 14, Loss: 18.281391143798828
Final likelihood: tensor([-17.4078, -18.1325, -18.0051, -18.1221, -17.0763, -18.0226, -16.7906,
        -17.1025, -18.6834, -17.5078, -17.8937, -17.4952, -18.1243, -17.0737,
        -16.7491, -18.5881])
Final projection likelihood: -17.6734
1 mode projection succeeded
New goal: tensor([ 0.0812,  0.5804,  0.3729,  0.9132, -0.1155,  0.5828,  0.8059,  0.7523,
         1.4475,  0.0144,  0.1655,  1.0875, -0.0615,  0.0337, -0.6109],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -19.8851375579834
Adjusted likelihood: -19.8851375579834
Likelihood residual: 0.0
Original likelihood: -27.160945892333984
Adjusted likelihood: -27.160945892333984
Likelihood residual: 0.0
{'index': 27.160945892333984, 'thumb_middle': 19.8851375579834}
Current yaw: tensor([-0.0666,  0.0481, -0.1763], device='cuda:1')
12 thumb_middle
tensor([ 0.0828,  0.6125,  0.4604,  0.6672, -0.2400,  0.6603,  0.8620,  0.8335,
         1.5000,  0.0738,  0.0853,  1.0589, -0.0666,  0.0481, -0.1763, -3.1372],
       device='cuda:1')
Solve time for step 1 9.519238684006268
Current ori: tensor([-0.0666,  0.0481, -0.1763], device='cuda:1')
Index force: tensor([0.5825, 0.5699, 0.5995, 0.6062], device='cuda:1')
tensor([ 8.1715e-02,  6.1125e-01,  3.7769e-01,  8.2739e-01, -2.4234e-01,
         6.0294e-01,  8.0171e-01,  7.6095e-01,  1.4208e+00,  2.8826e-03,
         9.7865e-02,  1.0666e+00, -4.8845e-02,  5.5848e-02, -1.7630e-01,
        -3.2163e+00], device='cuda:1')
Solve time for step 2 2.024189201008994
Current ori: tensor([-0.0488,  0.0558, -0.1763], device='cuda:1')
Index force: tensor([0.5649, 0.5949, 0.6073], device='cuda:1')
tensor([ 0.0945,  0.6076,  0.3736,  0.8702, -0.2408,  0.6108,  0.8091,  0.7427,
         1.4242, -0.0139,  0.0998,  1.0691, -0.0436,  0.0492, -0.1763, -3.1942],
       device='cuda:1')
Solve time for step 3 2.0284020749968477
Current ori: tensor([-0.0436,  0.0492, -0.1763], device='cuda:1')
Index force: tensor([0.5903, 0.5000], device='cuda:1')
tensor([ 0.1038,  0.5884,  0.3802,  0.9307, -0.2416,  0.6133,  0.8113,  0.7416,
         1.4302, -0.0167,  0.0935,  1.0629, -0.0333,  0.0429, -0.1763, -3.1601],
       device='cuda:1')
Solve time for step 4 1.7808971169870347
Current ori: tensor([-0.0333,  0.0429, -0.1763], device='cuda:1')
Index force: tensor([0.5818], device='cuda:1')
Storing RECOVERY transition: reward=-0.0163 (scaled=-0.0163), steps=1
Reward stats updated: mean -0.0051 -> -0.0051, std: 0.1506
Collected 328 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2268, Q2 Loss=1.2268, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4600
SAC Update 2/5: Actor Loss=-0.0011, Q1 Loss=0.7523, Q2 Loss=0.7523, Entropy=0.3134, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2236
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=12.3491, Q2 Loss=12.3491, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1571
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=3.3978, Q2 Loss=3.3978, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.7815
SAC Update 5/5: Actor Loss=-0.0186, Q1 Loss=1.2864, Q2 Loss=1.2864, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5843

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003945
Q1 loss: 3.802486
Q2 loss: 3.802486
Current threshold: -24.4797
Global Scale Offset: 0.0738
Reward stats: mean=-0.0051, std=0.1506, count=328
----------------------------------------------
SAC Update - Actor Loss: -0.0039, Q1 Loss: 3.8025, Q2 Loss: 3.8025, Entropy: 0.0627, Mean TD Error: 2.4413, Threshold: -24.4797
Original likelihood: -23.47793197631836
Adjusted likelihood: -23.47793197631836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Current yaw: tensor([-0.0439,  0.0380, -0.1814], device='cuda:1')
13 turn
Sampling time 4.115837646997534
tensor([ 0.1098,  0.6200,  0.3632,  0.8872, -0.1807,  0.6570,  0.8257,  0.7258,
         1.4868,  0.0149,  0.1336,  1.0827, -0.0439,  0.0380, -0.1814, -3.1668],
       device='cuda:1')
Original likelihood: -23.83516502380371
Adjusted likelihood: -23.83516502380371
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9934)
Solve time for step 1 13.946032662992366
Current ori: tensor([-0.0439,  0.0380, -0.1814], device='cuda:1')
Middle force: tensor([0.5019, 0.9435, 1.0909, 0.6364, 0.5982, 0.6009, 0.6989, 0.5412, 0.6006,
        0.7417, 0.5402, 0.5837], device='cuda:1')
Thumb force: tensor([0.5278, 0.7366, 0.5628, 0.5797, 0.5056, 0.6142, 0.6006, 0.5498, 0.5815,
        0.6658, 0.6610, 0.5734], device='cuda:1')
Index force: tensor([0.8300, 0.5555, 0.6007, 0.5733, 0.6537, 0.5973, 0.5687, 0.5694, 0.5835,
        0.5644, 0.6057, 0.5778], device='cuda:1')
Storing NORMAL transition: reward=0.0073 (scaled=0.0073), steps=1
Reward stats updated: mean -0.0051 -> -0.0051, std: 0.1504
Collected 329 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.4045, Q2 Loss=1.4045, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5599
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7673, Q2 Loss=0.7673, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8960
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.8592, Q2 Loss=2.8592, Entropy=0.0321, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6171
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=0.6918, Q2 Loss=0.6918, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0876
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7693, Q2 Loss=0.7693, Entropy=0.0217, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2947

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.6%)
Q1 update: 0.04s (17.9%)
Q2 update: 0.04s (17.8%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004608
Q1 loss: 1.298427
Q2 loss: 1.298427
Current threshold: -24.4652
Global Scale Offset: 0.0734
Reward stats: mean=-0.0051, std=0.1504, count=329
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.2984, Q2 Loss: 1.2984, Entropy: 0.0108, Mean TD Error: 1.4911, Threshold: -24.4652
tensor([ 0.1177,  0.6484,  0.3825,  0.7816, -0.2760,  0.6965,  0.8593,  0.8051,
         1.4850,  0.0510,  0.1739,  1.0151, -0.0501,  0.0556, -0.1910, -3.4443],
       device='cuda:1')
Original likelihood: -35.4304313659668
Adjusted likelihood: -35.4304313659668
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 36.5458984375
Projection step: 1, Loss: 34.37975311279297
Projection step: 2, Loss: 32.24644470214844
Projection step: 3, Loss: 29.591651916503906
Projection step: 4, Loss: 28.387765884399414
Projection step: 5, Loss: 27.57315444946289
Projection step: 6, Loss: 25.111675262451172
Projection step: 7, Loss: 25.04979705810547
Projection step: 8, Loss: 23.99658966064453
Projection step: 9, Loss: 23.25434112548828
Projection step: 10, Loss: 22.956592559814453
Projection step: 11, Loss: 21.97673225402832
Projection step: 12, Loss: 20.886127471923828
Projection step: 13, Loss: 20.201221466064453
Projection step: 14, Loss: 19.421924591064453
Final likelihood: tensor([-18.3180, -16.0376, -19.1293, -18.4039, -18.6816, -18.9446, -17.9431,
        -18.5019, -18.6219, -19.0575, -18.3847, -18.7631, -18.2268, -19.0948,
        -18.7922, -18.7905])
Final projection likelihood: -18.4807
1 mode projection succeeded
New goal: tensor([ 0.0846,  0.5950,  0.3647,  0.8736, -0.1303,  0.6260,  0.7873,  0.7311,
         1.4475, -0.0069,  0.1716,  1.1050, -0.0561,  0.0354,  3.0934],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -25.110950469970703
Adjusted likelihood: -25.110950469970703
Likelihood residual: 0.0
{'index': 25.110950469970703, 'thumb_middle': inf}
Current yaw: tensor([-0.0501,  0.0556, -0.1910], device='cuda:1')
14 index
tensor([ 0.1177,  0.6484,  0.3825,  0.7816, -0.2760,  0.6965,  0.8593,  0.8051,
         1.4850,  0.0510,  0.1739,  1.0151, -0.0501,  0.0556, -0.1910, -3.4443],
       device='cuda:1')
Solve time for step 1 11.76196388999233
Current ori: tensor([-0.0501,  0.0556, -0.1910], device='cuda:1')
Middle force: tensor([0.5603, 0.6167, 0.5705, 0.5397], device='cuda:1')
Thumb force: tensor([0.6060, 0.5680, 0.6304, 0.5002], device='cuda:1')
tensor([ 0.1252,  0.5535,  0.3228,  0.8282, -0.2506,  0.7145,  0.8622,  0.7810,
         1.4960,  0.0063,  0.1357,  1.0297, -0.0596,  0.0363, -0.1959, -3.0556],
       device='cuda:1')
Solve time for step 2 2.2166332970082294
Current ori: tensor([-0.0596,  0.0363, -0.1959], device='cuda:1')
Middle force: tensor([0.6113, 0.5685, 0.5382], device='cuda:1')
Thumb force: tensor([0.5651, 0.6279, 0.5001], device='cuda:1')
tensor([ 1.2277e-01,  5.5580e-01,  3.2318e-01,  8.3978e-01, -2.4081e-01,
         7.1788e-01,  8.6631e-01,  7.8009e-01,  1.4909e+00,  2.6633e-03,
         1.1569e-01,  1.0579e+00, -5.9193e-02,  2.7742e-02, -1.9080e-01,
        -3.1881e+00], device='cuda:1')
Solve time for step 3 2.150464066013228
Current ori: tensor([-0.0592,  0.0277, -0.1908], device='cuda:1')
Middle force: tensor([0.5805, 0.5784], device='cuda:1')
Thumb force: tensor([0.5921, 0.5341], device='cuda:1')
tensor([ 1.2274e-01,  5.5918e-01,  3.2081e-01,  8.4277e-01, -2.3918e-01,
         7.2292e-01,  8.6272e-01,  7.7229e-01,  1.4909e+00,  2.2868e-03,
         1.1529e-01,  1.0532e+00, -6.1884e-02,  2.6978e-02, -1.8851e-01,
        -3.6082e+00], device='cuda:1')
Solve time for step 4 2.0782835689897183
Current ori: tensor([-0.0619,  0.0270, -0.1885], device='cuda:1')
Middle force: tensor([0.5026], device='cuda:1')
Thumb force: tensor([0.5139], device='cuda:1')
Storing RECOVERY transition: reward=-0.0108 (scaled=-0.0108), steps=1
Reward stats updated: mean -0.0051 -> -0.0051, std: 0.1502
Collected 330 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=1.5696, Q2 Loss=1.5696, Entropy=0.0339, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0195
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7741, Q2 Loss=0.7741, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2766
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9043, Q2 Loss=0.9043, Entropy=0.0005, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3460
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1595, Q2 Loss=1.1595, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5239
SAC Update 5/5: Actor Loss=-0.0119, Q1 Loss=1.1028, Q2 Loss=1.1028, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7181

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.3%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.8%)
Actor update: 0.09s (38.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.006982
Q1 loss: 1.102045
Q2 loss: 1.102045
Current threshold: -24.4562
Global Scale Offset: 0.0732
Reward stats: mean=-0.0051, std=0.1502, count=330
----------------------------------------------
SAC Update - Actor Loss: -0.0070, Q1 Loss: 1.1020, Q2 Loss: 1.1020, Entropy: 0.0069, Mean TD Error: 0.7768, Threshold: -24.4562
Original likelihood: -28.365280151367188
Adjusted likelihood: -28.365280151367188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 29.00872039794922
Projection step: 1, Loss: 27.611644744873047
Projection step: 2, Loss: 26.73224449157715
Projection step: 3, Loss: 25.04969024658203
Projection step: 4, Loss: 24.129287719726562
Projection step: 5, Loss: 23.50944709777832
Projection step: 6, Loss: 22.351621627807617
Projection step: 7, Loss: 21.731922149658203
Projection step: 8, Loss: 20.752605438232422
Projection step: 9, Loss: 19.962451934814453
Projection step: 10, Loss: 19.368791580200195
Projection step: 11, Loss: 18.660755157470703
Projection step: 12, Loss: 17.56218719482422
Projection step: 13, Loss: 17.41080665588379
Projection step: 14, Loss: 16.56939697265625
Final likelihood: tensor([-15.7114, -16.2832, -15.6932, -15.4560, -16.3879, -15.4920, -16.7009,
        -17.1446, -16.2976, -15.8891, -15.4121, -15.6869, -15.6523, -15.4458,
        -16.1996, -15.5107])
Final projection likelihood: -15.9352
1 mode projection succeeded
New goal: tensor([ 0.0947,  0.5593,  0.3818,  0.9664, -0.1047,  0.6110,  0.8137,  0.7173,
         1.4635,  0.0123,  0.1870,  1.0364, -0.0602,  0.0254, -1.5046],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -20.618511199951172
Adjusted likelihood: -20.618511199951172
Likelihood residual: 0.0
Original likelihood: -28.512752532958984
Adjusted likelihood: -28.512752532958984
Likelihood residual: 0.0
{'index': 28.512752532958984, 'thumb_middle': 20.618511199951172}
Current yaw: tensor([-0.0657,  0.0326, -0.1799], device='cuda:1')
15 thumb_middle
tensor([ 0.0709,  0.6052,  0.3529,  0.8666, -0.2503,  0.7273,  0.8611,  0.7724,
         1.4931,  0.0117,  0.1095,  1.0639, -0.0657,  0.0326, -0.1799, -3.7184],
       device='cuda:1')
Solve time for step 1 9.40543842499028
Current ori: tensor([-0.0657,  0.0326, -0.1799], device='cuda:1')
Index force: tensor([0.5710, 0.5978, 0.6023, 0.5963], device='cuda:1')
tensor([ 0.0731,  0.5728,  0.3722,  0.9251, -0.2309,  0.6315,  0.8033,  0.7124,
         1.4166, -0.0231,  0.1044,  1.0221, -0.0495,  0.0468, -0.1799, -3.8337],
       device='cuda:1')
Solve time for step 2 1.9976807810016908
Current ori: tensor([-0.0495,  0.0468, -0.1799], device='cuda:1')
Index force: tensor([0.5933, 0.5993, 0.5930], device='cuda:1')
tensor([ 0.0803,  0.5670,  0.3755,  0.9494, -0.2255,  0.6315,  0.7987,  0.7020,
         1.4291, -0.0272,  0.1032,  1.0150, -0.0449,  0.0435, -0.1799, -3.8167],
       device='cuda:1')
Solve time for step 3 1.9222378370177466
Current ori: tensor([-0.0449,  0.0435, -0.1799], device='cuda:1')
Index force: tensor([0.5921, 0.5869], device='cuda:1')
tensor([ 0.0892,  0.5778,  0.3693,  0.9482, -0.2213,  0.6315,  0.7985,  0.7010,
         1.4277, -0.0252,  0.1019,  1.0117, -0.0477,  0.0378, -0.1799, -3.8051],
       device='cuda:1')
Solve time for step 4 1.8061526019882876
Current ori: tensor([-0.0477,  0.0378, -0.1799], device='cuda:1')
Index force: tensor([0.5792], device='cuda:1')
Storing RECOVERY transition: reward=-0.0009 (scaled=-0.0009), steps=1
Reward stats updated: mean -0.0051 -> -0.0051, std: 0.1500
Collected 331 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=23.2330, Q2 Loss=23.2330, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=10.2659
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4103, Q2 Loss=1.4103, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7236
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0289, Q2 Loss=1.0289, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0521
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3862, Q2 Loss=1.3862, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6131
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7002, Q2 Loss=0.7002, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1302

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 5.551703
Q2 loss: 5.551703
Current threshold: -24.4509
Global Scale Offset: 0.0731
Reward stats: mean=-0.0051, std=0.1500, count=331
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 5.5517, Q2 Loss: 5.5517, Entropy: 0.0000, Mean TD Error: 2.5570, Threshold: -24.4509
Original likelihood: -21.21478271484375
Adjusted likelihood: -21.21478271484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0461,  0.0275, -0.1874], device='cuda:1')
16 turn
Sampling time 3.887727362976875
tensor([ 9.7579e-02,  5.6839e-01,  3.8412e-01,  9.6255e-01, -1.6026e-01,
         6.6838e-01,  8.1443e-01,  7.1445e-01,  1.4933e+00, -1.2695e-03,
         1.3321e-01,  1.0298e+00, -4.6130e-02,  2.7493e-02, -1.8745e-01,
        -3.5819e+00], device='cuda:1')
Original likelihood: -20.092708587646484
Adjusted likelihood: -20.092708587646484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.095611686003394
Current ori: tensor([-0.0461,  0.0275, -0.1874], device='cuda:1')
Middle force: tensor([1.5612, 0.5168, 0.6951, 0.8284, 0.4937, 0.8590, 0.7553, 0.5773, 0.5008,
        0.6264, 0.5771, 0.6014], device='cuda:1')
Thumb force: tensor([1.1959, 0.6005, 1.9213, 0.5727, 0.5394, 0.6207, 1.1405, 0.9335, 0.5870,
        0.5719, 0.6825, 1.1112], device='cuda:1')
Index force: tensor([0.5041, 0.8563, 0.7755, 0.5415, 0.6088, 0.6804, 1.0063, 0.5572, 0.7640,
        0.5859, 0.7017, 0.8166], device='cuda:1')
Storing NORMAL transition: reward=-0.1125 (scaled=-0.1125), steps=1
Reward stats updated: mean -0.0051 -> -0.0054, std: 0.1499
Collected 332 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0351, Q2 Loss=1.0351, Entropy=0.0029, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4768
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1266, Q2 Loss=1.1266, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3017
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9731, Q2 Loss=0.9731, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4390
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0979, Q2 Loss=1.0979, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4042
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7913, Q2 Loss=0.7913, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6333

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.004804
Q2 loss: 1.004804
Current threshold: -24.4477
Global Scale Offset: 0.0730
Reward stats: mean=-0.0054, std=0.1499, count=332
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0048, Q2 Loss: 1.0048, Entropy: 0.0006, Mean TD Error: 0.6510, Threshold: -24.4477
tensor([ 0.0730,  0.5092,  0.4732,  0.9039, -0.1452,  0.7502,  0.6801,  0.7258,
         1.4047,  0.1463,  0.1371,  1.1235, -0.0432,  0.0253, -0.0742, -3.2303],
       device='cuda:1')
Original likelihood: -19.479503631591797
Adjusted likelihood: -19.479503631591797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9346567890024744
Current ori: tensor([-0.0432,  0.0253, -0.0742], device='cuda:1')
Middle force: tensor([0.5187, 0.6955, 0.8224, 0.5002, 0.8556, 0.7524, 0.5769, 0.5011, 0.6236,
        0.5758, 0.6016], device='cuda:1')
Thumb force: tensor([0.5931, 1.8906, 0.5700, 0.5384, 0.6170, 1.1258, 0.9234, 0.5809, 0.5702,
        0.6776, 1.0994], device='cuda:1')
Index force: tensor([0.8399, 0.7748, 0.5402, 0.6191, 0.6769, 1.0024, 0.5557, 0.7642, 0.5840,
        0.7004, 0.8121], device='cuda:1')
Storing NORMAL transition: reward=-0.0231 (scaled=-0.0231), steps=1
Reward stats updated: mean -0.0054 -> -0.0055, std: 0.1496
Collected 333 transitions for RL
SAC Update 1/5: Actor Loss=-0.0171, Q1 Loss=1.2639, Q2 Loss=1.2639, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4028
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8096, Q2 Loss=0.8096, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0481
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0537, Q2 Loss=1.0537, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4531
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7487, Q2 Loss=0.7487, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7857
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7808, Q2 Loss=0.7808, Entropy=0.0128, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3263

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.2%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (42.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003411
Q1 loss: 0.931350
Q2 loss: 0.931350
Current threshold: -24.4112
Global Scale Offset: 0.0712
Reward stats: mean=-0.0055, std=0.1496, count=333
----------------------------------------------
SAC Update - Actor Loss: -0.0034, Q1 Loss: 0.9314, Q2 Loss: 0.9314, Entropy: 0.0026, Mean TD Error: 0.6032, Threshold: -24.4112
tensor([ 0.1259,  0.5324,  0.5594,  0.7685, -0.1150,  0.8490,  0.5443,  0.7004,
         1.3931,  0.1730,  0.1014,  1.1375, -0.0613,  0.0118, -0.0521, -3.5514],
       device='cuda:1')
Original likelihood: -23.029211044311523
Adjusted likelihood: -23.029211044311523
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7433886459912173
Current ori: tensor([-0.0613,  0.0118, -0.0521], device='cuda:1')
Middle force: tensor([1.3193, 0.5116, 0.7777, 0.5525, 0.5023, 0.5072, 0.5003, 0.5136, 0.5065,
        0.6009], device='cuda:1')
Thumb force: tensor([0.9340, 0.5376, 0.9074, 0.5509, 0.6023, 0.5436, 0.6413, 0.5467, 0.7554,
        0.5463], device='cuda:1')
Index force: tensor([0.5102, 0.7331, 1.1431, 0.5557, 0.6433, 0.5303, 0.5910, 0.5025, 0.5506,
        0.5535], device='cuda:1')
Storing NORMAL transition: reward=-0.0086 (scaled=-0.0086), steps=1
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1494
Collected 334 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0445, Q2 Loss=1.0445, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8775
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.8841, Q2 Loss=0.8841, Entropy=0.2824, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3061
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9900, Q2 Loss=0.9900, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4534
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1741, Q2 Loss=1.1741, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4119
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9520, Q2 Loss=0.9520, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8064

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000076
Q1 loss: 1.008923
Q2 loss: 1.008923
Current threshold: -24.3870
Global Scale Offset: 0.0702
Reward stats: mean=-0.0055, std=0.1494, count=334
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.0089, Q2 Loss: 1.0089, Entropy: 0.0565, Mean TD Error: 0.7711, Threshold: -24.3870
tensor([-0.0136,  0.5184,  0.3909,  0.8860, -0.1267,  0.7757,  0.5856,  0.7232,
         1.3833,  0.0621,  0.1725,  1.1169, -0.0393,  0.0340, -0.0425, -3.0538],
       device='cuda:1')
Original likelihood: -22.902740478515625
Adjusted likelihood: -22.902740478515625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 2.637469503999455
Current ori: tensor([-0.0393,  0.0340, -0.0425], device='cuda:1')
Middle force: tensor([0.5103, 0.8543, 0.5528, 0.5069, 0.5107, 0.5010, 0.5157, 0.5071, 0.6026],
       device='cuda:1')
Thumb force: tensor([0.5364, 0.8050, 0.5464, 0.5627, 0.5299, 0.6090, 0.5401, 0.7359, 0.5439],
       device='cuda:1')
Index force: tensor([0.7263, 1.1456, 0.5549, 0.6045, 0.5283, 0.5752, 0.5023, 0.5499, 0.5514],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0040 (scaled=-0.0040), steps=1
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1492
Collected 335 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=0.6907, Q2 Loss=0.6907, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0118
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1635, Q2 Loss=1.1635, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4240
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9894, Q2 Loss=0.9894, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4958
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7886, Q2 Loss=0.7886, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3432
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=1.0100, Q2 Loss=1.0100, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4476

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (41.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006616
Q1 loss: 0.928446
Q2 loss: 0.928446
Current threshold: -24.3720
Global Scale Offset: 0.0696
Reward stats: mean=-0.0055, std=0.1492, count=335
----------------------------------------------
SAC Update - Actor Loss: -0.0066, Q1 Loss: 0.9284, Q2 Loss: 0.9284, Entropy: 0.0000, Mean TD Error: 0.3445, Threshold: -24.3720
tensor([-0.0388,  0.5680,  0.2960,  0.8885, -0.1829,  0.7012,  0.5681,  0.7623,
         1.2999,  0.1345,  0.2424,  1.2085, -0.0536,  0.0725, -0.0425, -3.4130],
       device='cuda:1')
Original likelihood: -29.905105590820312
Adjusted likelihood: -29.905105590820312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 29.340808868408203
Projection step: 1, Loss: 28.976165771484375
Projection step: 2, Loss: 28.371536254882812
Projection step: 3, Loss: 26.793487548828125
Projection step: 4, Loss: 26.905715942382812
Projection step: 5, Loss: 26.528244018554688
Projection step: 6, Loss: 25.288623809814453
Projection step: 7, Loss: 24.702194213867188
Projection step: 8, Loss: 24.07219696044922
Projection step: 9, Loss: 22.927669525146484
Projection step: 10, Loss: 22.009441375732422
Projection step: 11, Loss: 21.634838104248047
Projection step: 12, Loss: 21.16735076904297
Projection step: 13, Loss: 20.545597076416016
Projection step: 14, Loss: 20.239456176757812
Final likelihood: tensor([-16.7512, -19.6637, -18.8722, -19.5450, -19.3032, -18.7324, -19.3272,
        -21.4318, -21.7288, -21.1384, -19.7651, -21.1880, -20.4203, -20.5414,
        -17.3640, -20.1146])
Final projection likelihood: -19.7430
1 mode projection succeeded
New goal: tensor([ 0.0255,  0.5545,  0.3583,  0.9240, -0.1042,  0.6061,  0.6356,  0.8561,
         1.3779,  0.0495,  0.1342,  1.1897, -0.0565,  0.0513, -0.1538],
       device='cuda:1')
tensor([[0.0125]], device='cuda:1') tensor([[0.0051]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -21.173974990844727
Adjusted likelihood: -21.173974990844727
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.173974990844727}
Current yaw: tensor([-0.0536,  0.0725, -0.0425], device='cuda:1')
17 thumb_middle
tensor([-0.0388,  0.5680,  0.2960,  0.8885, -0.1829,  0.7012,  0.5681,  0.7623,
         1.2999,  0.1345,  0.2424,  1.2085, -0.0536,  0.0725, -0.0425, -3.4130],
       device='cuda:1')
Solve time for step 1 9.002966336003738
Current ori: tensor([-0.0536,  0.0725, -0.0425], device='cuda:1')
Index force: tensor([0.5263, 0.5003, 0.6151, 0.5002], device='cuda:1')
tensor([-0.0428,  0.5674,  0.2858,  0.9015, -0.2061,  0.6279,  0.5913,  0.8170,
         1.3785,  0.0692,  0.1373,  1.1913, -0.0446,  0.1127, -0.0474, -3.7683],
       device='cuda:1')
Solve time for step 2 1.9016460189886857
Current ori: tensor([-0.0446,  0.1127, -0.0474], device='cuda:1')
Index force: tensor([0.5002, 0.6131, 0.5000], device='cuda:1')
tensor([-0.0401,  0.5658,  0.2927,  0.8972, -0.2135,  0.6214,  0.5935,  0.8207,
         1.4215,  0.0618,  0.1238,  1.1879, -0.0413,  0.1175, -0.0408, -3.8494],
       device='cuda:1')
Solve time for step 3 1.8409933609946165
Current ori: tensor([-0.0413,  0.1175, -0.0408], device='cuda:1')
Index force: tensor([0.6089, 0.5000], device='cuda:1')
tensor([-0.0248,  0.5517,  0.3117,  0.9284, -0.2124,  0.6226,  0.5993,  0.8212,
         1.4252,  0.0593,  0.1232,  1.1950, -0.0316,  0.1138, -0.0310, -3.9225],
       device='cuda:1')
Solve time for step 4 1.8565560540009756
Current ori: tensor([-0.0316,  0.1138, -0.0310], device='cuda:1')
Index force: tensor([0.5955], device='cuda:1')
Storing RECOVERY transition: reward=-0.0580 (scaled=-0.0145), steps=4
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1490
Collected 336 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=3.3760, Q2 Loss=3.3760, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.8575
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8035, Q2 Loss=0.8035, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5463
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7345, Q2 Loss=0.7345, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1695
SAC Update 4/5: Actor Loss=-0.0150, Q1 Loss=1.2327, Q2 Loss=1.2327, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7965
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=1.2263, Q2 Loss=1.2263, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2433

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.007598
Q1 loss: 1.474617
Q2 loss: 1.474617
Current threshold: -24.3630
Global Scale Offset: 0.0692
Reward stats: mean=-0.0055, std=0.1490, count=336
----------------------------------------------
SAC Update - Actor Loss: -0.0076, Q1 Loss: 1.4746, Q2 Loss: 1.4746, Entropy: 0.0000, Mean TD Error: 1.5226, Threshold: -24.3630
Original likelihood: -35.88880920410156
Adjusted likelihood: -35.88880920410156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 31.78856658935547
Projection step: 1, Loss: 34.901512145996094
Projection step: 2, Loss: 34.00358200073242
Projection step: 3, Loss: 34.91503143310547
Projection step: 4, Loss: 33.49118423461914
Projection step: 5, Loss: 31.49738311767578
Projection step: 6, Loss: 31.361358642578125
Projection step: 7, Loss: 29.370159149169922
Projection step: 8, Loss: 29.065643310546875
Projection step: 9, Loss: 27.60397720336914
Projection step: 10, Loss: 27.757110595703125
Projection step: 11, Loss: 26.837688446044922
Projection step: 12, Loss: 25.613706588745117
Projection step: 13, Loss: 25.4569149017334
Projection step: 14, Loss: 24.363380432128906
Final likelihood: tensor([-25.3351, -25.2431, -24.7799, -25.1491, -23.7787, -21.6858, -21.4633,
        -22.0317, -25.2563, -24.4819, -25.5752, -24.3577, -27.5900, -24.8388,
        -25.5886, -24.4628])
Final projection likelihood: -24.4761
1 mode projection failed, trying anyway
New goal: tensor([-0.0086,  0.5520,  0.3517,  0.9076, -0.1163,  0.6515,  0.5439,  0.8182,
         1.3919,  0.0845,  0.1260,  1.1740, -0.0513,  0.0638, -0.2380],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -24.614059448242188
Adjusted likelihood: -24.614059448242188
Likelihood residual: 0.0
Original likelihood: -24.455650329589844
Adjusted likelihood: -24.455650329589844
Likelihood residual: 0.0
{'index': 24.455650329589844, 'thumb_middle': 24.614059448242188}
Current yaw: tensor([-0.0382,  0.0916,  0.0148], device='cuda:1')
18 index
tensor([-0.0088,  0.5255,  0.3421,  0.9682, -0.1755,  0.6656,  0.5751,  0.7889,
         1.4785,  0.0918,  0.1564,  1.2126, -0.0382,  0.0916,  0.0148, -3.8982],
       device='cuda:1')
Solve time for step 1 10.580475559021579
Current ori: tensor([-0.0382,  0.0916,  0.0148], device='cuda:1')
Middle force: tensor([0.5502, 0.5505, 0.6087, 0.5733], device='cuda:1')
Thumb force: tensor([0.5716, 0.5240, 0.5324, 0.6020], device='cuda:1')
tensor([ 0.0329,  0.4859,  0.2995,  0.8901, -0.1621,  0.6871,  0.5476,  0.8008,
         1.4702,  0.0981,  0.1473,  1.1912, -0.0487,  0.0827, -0.0213, -4.1320],
       device='cuda:1')
Solve time for step 2 2.2221216509933583
Current ori: tensor([-0.0487,  0.0827, -0.0213], device='cuda:1')
Middle force: tensor([0.5498, 0.6061, 0.5715], device='cuda:1')
Thumb force: tensor([0.5212, 0.5310, 0.6014], device='cuda:1')
tensor([ 0.0341,  0.4985,  0.3009,  0.8796, -0.1559,  0.6976,  0.5374,  0.7972,
         1.4709,  0.0923,  0.1395,  1.1945, -0.0515,  0.0788, -0.0181, -4.7676],
       device='cuda:1')
Solve time for step 3 2.1238040440075565
Current ori: tensor([-0.0515,  0.0788, -0.0181], device='cuda:1')
Middle force: tensor([0.5004, 0.5004], device='cuda:1')
Thumb force: tensor([0.5191, 0.5464], device='cuda:1')
tensor([ 0.0322,  0.4997,  0.3042,  0.8764, -0.1448,  0.7056,  0.5355,  0.7933,
         1.4572,  0.1063,  0.1306,  1.2057, -0.0535,  0.0712, -0.0149, -5.4068],
       device='cuda:1')
Solve time for step 4 2.123342858016258
Current ori: tensor([-0.0535,  0.0712, -0.0149], device='cuda:1')
Middle force: tensor([0.5198], device='cuda:1')
Thumb force: tensor([0.5764], device='cuda:1')
Storing RECOVERY transition: reward=-0.0305 (scaled=-0.0076), steps=4
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1487
Collected 337 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.3646, Q2 Loss=1.3646, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3171
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.3113, Q2 Loss=2.3113, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5438
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9285, Q2 Loss=0.9285, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3197
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8223, Q2 Loss=0.8223, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9207
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7304, Q2 Loss=0.7304, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3783

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (20.7%)
Q2 update: 0.06s (20.3%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 1.231412
Q2 loss: 1.231412
Current threshold: -24.3577
Global Scale Offset: 0.0690
Reward stats: mean=-0.0055, std=0.1487, count=337
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2314, Q2 Loss: 1.2314, Entropy: 0.0000, Mean TD Error: 1.6959, Threshold: -24.3577
Original likelihood: -32.39176940917969
Adjusted likelihood: -32.39176940917969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 30.005027770996094
Projection step: 1, Loss: 26.4791259765625
Projection step: 2, Loss: 25.793983459472656
Projection step: 3, Loss: 24.81292724609375
Projection step: 4, Loss: 24.09042739868164
Projection step: 5, Loss: 23.290966033935547
Projection step: 6, Loss: 23.22224235534668
Projection step: 7, Loss: 21.994853973388672
Projection step: 8, Loss: 21.138259887695312
Projection step: 9, Loss: 20.27112579345703
Projection step: 10, Loss: 19.923980712890625
Projection step: 11, Loss: 18.919723510742188
Projection step: 12, Loss: 18.46862030029297
Projection step: 13, Loss: 17.891094207763672
Projection step: 14, Loss: 17.316251754760742
Final likelihood: tensor([-16.6641, -16.1435, -15.7806, -18.2911, -16.7243, -15.9263, -16.6560,
        -16.4455, -16.5052, -16.0745, -12.1057, -16.3437, -19.4228, -18.0543,
        -16.8104, -17.0511])
Final projection likelihood: -16.5625
1 mode projection succeeded
New goal: tensor([ 0.0480,  0.5590,  0.3428,  0.9975, -0.0731,  0.6211,  0.5954,  0.8574,
         1.4039,  0.0832,  0.1299,  1.0958, -0.0537,  0.0435, -0.4743],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -17.52094268798828
Adjusted likelihood: -17.52094268798828
Likelihood residual: 0.0
Original likelihood: -21.368980407714844
Adjusted likelihood: -21.368980407714844
Likelihood residual: 0.0
{'index': 21.368980407714844, 'thumb_middle': 17.52094268798828}
Current yaw: tensor([-0.0503,  0.0671, -0.0109], device='cuda:1')
19 thumb_middle
tensor([-1.1796e-04,  5.5183e-01,  3.4757e-01,  8.9867e-01, -1.3952e-01,
         7.0341e-01,  5.3768e-01,  8.0590e-01,  1.4544e+00,  1.0451e-01,
         1.2156e-01,  1.2238e+00, -5.0322e-02,  6.7057e-02, -1.0942e-02,
        -5.5003e+00], device='cuda:1')
Solve time for step 1 9.143434476980474
Current ori: tensor([-0.0503,  0.0671, -0.0109], device='cuda:1')
Index force: tensor([0.5912, 0.5785, 0.5934, 0.6073], device='cuda:1')
tensor([ 0.0212,  0.5601,  0.3271,  0.9530, -0.1802,  0.6190,  0.5563,  0.8287,
         1.3984,  0.0734,  0.0773,  1.1043, -0.0398,  0.0826, -0.0110, -5.7557],
       device='cuda:1')
Solve time for step 2 1.9422773260157555
Current ori: tensor([-0.0398,  0.0826, -0.0110], device='cuda:1')
Index force: tensor([0.5751, 0.5901, 0.6032], device='cuda:1')
tensor([ 0.0373,  0.5642,  0.3253,  0.9739, -0.1861,  0.6090,  0.5633,  0.8304,
         1.4162,  0.0710,  0.0751,  1.0892, -0.0392,  0.0734, -0.0110, -5.7603],
       device='cuda:1')
Solve time for step 3 1.9018650670186616
Current ori: tensor([-0.0392,  0.0734, -0.0110], device='cuda:1')
Index force: tensor([0.5856, 0.5992], device='cuda:1')
tensor([ 0.0434,  0.5669,  0.3278,  0.9723, -0.1893,  0.6136,  0.5627,  0.8282,
         1.4232,  0.0742,  0.0708,  1.0814, -0.0405,  0.0696, -0.0110, -5.7495],
       device='cuda:1')
Solve time for step 4 1.8079698250221554
Current ori: tensor([-0.0405,  0.0696, -0.0110], device='cuda:1')
Index force: tensor([0.5910], device='cuda:1')
Storing RECOVERY transition: reward=-0.0132 (scaled=-0.0033), steps=4
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1485
Collected 338 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=0.7655, Q2 Loss=0.7655, Entropy=0.0008, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2816
SAC Update 2/5: Actor Loss=-0.0020, Q1 Loss=0.7631, Q2 Loss=0.7631, Entropy=0.1980, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2247
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9888, Q2 Loss=0.9888, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4421
SAC Update 4/5: Actor Loss=-0.0190, Q1 Loss=1.3578, Q2 Loss=1.3578, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6435
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=0.8521, Q2 Loss=0.8521, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5921

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.3%)
Actor update: 0.10s (42.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010542
Q1 loss: 0.945453
Q2 loss: 0.945453
Current threshold: -24.2970
Global Scale Offset: 0.0672
Reward stats: mean=-0.0055, std=0.1485, count=338
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 0.9455, Q2 Loss: 0.9455, Entropy: 0.0398, Mean TD Error: 0.4368, Threshold: -24.2970
Original likelihood: -26.459869384765625
Adjusted likelihood: -26.459869384765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 25.616947174072266
Projection step: 1, Loss: 23.65555191040039
Projection step: 2, Loss: 22.8563232421875
Projection step: 3, Loss: 21.005355834960938
Projection step: 4, Loss: 20.46216583251953
Projection step: 5, Loss: 20.83307647705078
Projection step: 6, Loss: 18.57223892211914
Projection step: 7, Loss: 17.695030212402344
Projection step: 8, Loss: 17.011539459228516
Projection step: 9, Loss: 16.21298599243164
Projection step: 10, Loss: 15.290422439575195
Projection step: 11, Loss: 14.480091094970703
Final likelihood: tensor([-14.6951, -14.4525, -14.9376, -14.0616, -13.7710, -14.3078, -16.2896,
        -14.2366, -13.5036, -15.9955, -14.2723, -14.4670, -14.1267, -14.1896,
        -14.5168, -13.8580])
Final projection likelihood: -14.4801
1 mode projection succeeded
New goal: tensor([ 0.0645,  0.5851,  0.3042,  1.0225, -0.0711,  0.6180,  0.6266,  0.8457,
         1.4209,  0.1013,  0.1189,  1.0720, -0.0476,  0.0369, -0.9469],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -18.802989959716797
Adjusted likelihood: -18.802989959716797
Likelihood residual: 0.0
Original likelihood: -22.35947608947754
Adjusted likelihood: -22.35947608947754
Likelihood residual: 0.0
{'index': 22.35947608947754, 'thumb_middle': 18.802989959716797}
Current yaw: tensor([-0.0414,  0.0573, -0.0270], device='cuda:1')
20 thumb_middle
tensor([ 0.0562,  0.5650,  0.3335,  0.9906, -0.1255,  0.6584,  0.5895,  0.8439,
         1.4852,  0.1083,  0.1040,  1.0960, -0.0414,  0.0573, -0.0270, -5.5752],
       device='cuda:1')
Solve time for step 1 8.78334113501478
Current ori: tensor([-0.0414,  0.0573, -0.0270], device='cuda:1')
Index force: tensor([0.5825, 0.6045, 0.5982, 0.6110], device='cuda:1')
tensor([ 0.0517,  0.5746,  0.3085,  1.0025, -0.1881,  0.5974,  0.5855,  0.8235,
         1.4206,  0.0903,  0.0680,  1.0608, -0.0412,  0.0615, -0.0269, -5.6310],
       device='cuda:1')
Solve time for step 2 1.8747675720078405
Current ori: tensor([-0.0412,  0.0615, -0.0269], device='cuda:1')
Index force: tensor([0.6000, 0.5947, 0.6077], device='cuda:1')
tensor([ 0.0619,  0.5934,  0.2952,  0.9942, -0.1862,  0.6078,  0.5901,  0.8249,
         1.4223,  0.0861,  0.0570,  1.0517, -0.0466,  0.0552, -0.0269, -5.6263],
       device='cuda:1')
Solve time for step 3 1.862914362020092
Current ori: tensor([-0.0466,  0.0552, -0.0269], device='cuda:1')
Index force: tensor([0.5878, 0.6026], device='cuda:1')
tensor([ 0.0759,  0.6026,  0.2930,  0.9991, -0.1783,  0.6163,  0.6013,  0.8244,
         1.4187,  0.0804,  0.0489,  1.0517, -0.0487,  0.0464, -0.0269, -5.6053],
       device='cuda:1')
Solve time for step 4 1.8550242600031197
Current ori: tensor([-0.0487,  0.0464, -0.0269], device='cuda:1')
Index force: tensor([0.5560], device='cuda:1')
Storing RECOVERY transition: reward=-0.0096 (scaled=-0.0024), steps=4
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1483
Collected 339 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3172, Q2 Loss=1.3172, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0703
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7044, Q2 Loss=0.7044, Entropy=0.0089, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0474
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7839, Q2 Loss=0.7839, Entropy=0.1039, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5350
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0178, Q2 Loss=1.0178, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4161
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=2.8540, Q2 Loss=2.8540, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6962

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (20.1%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004607
Q1 loss: 1.335471
Q2 loss: 1.335471
Current threshold: -24.2428
Global Scale Offset: 0.0653
Reward stats: mean=-0.0055, std=0.1483, count=339
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.3355, Q2 Loss: 1.3355, Entropy: 0.0226, Mean TD Error: 1.5530, Threshold: -24.2428
Original likelihood: -22.974090576171875
Adjusted likelihood: -22.974090576171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Marked last transition as done (final step)
{}

Trial 21
Loaded trajectory sampler
Current yaw: tensor([-0.0022,  0.0149, -0.0419], device='cuda:1')
Current yaw: tensor([-0.0022,  0.0149, -0.0419], device='cuda:1')
1 turn
Sampling time 3.7554847089922987
tensor([ 0.1334,  0.6374,  0.5534,  0.5278, -0.1404,  0.5665,  0.8728,  0.9523,
         1.2236,  0.2599,  0.2638,  1.2306, -0.0022,  0.0149, -0.0419, -0.0953],
       device='cuda:1')
Original likelihood: -21.377300262451172
Adjusted likelihood: -21.377300262451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.268157999991672
Current ori: tensor([-0.0022,  0.0149, -0.0419], device='cuda:1')
Middle force: tensor([0.5883, 0.5754, 1.1564, 0.5676, 1.1325, 0.6397, 0.5380, 0.5405, 0.5149,
        0.8356, 0.7123, 0.6108], device='cuda:1')
Thumb force: tensor([0.8822, 0.8710, 0.7832, 1.0722, 0.9964, 0.6543, 0.5262, 0.8817, 0.5430,
        0.5395, 0.7336, 0.6147], device='cuda:1')
Index force: tensor([0.6000, 0.6021, 0.5606, 0.5749, 0.8134, 0.5275, 1.0326, 0.9386, 0.5988,
        0.5926, 0.7742, 0.6183], device='cuda:1')
Storing NORMAL transition: reward=-0.0029 (scaled=-0.0029), steps=1
Reward stats updated: mean -0.0055 -> -0.0055, std: 0.1481
Collected 340 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8176, Q2 Loss=0.8176, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7621
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8748, Q2 Loss=0.8748, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4731
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.3320, Q2 Loss=1.3320, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6200
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.9284, Q2 Loss=1.9284, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.4556
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8001, Q2 Loss=0.8001, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8256

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (38.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 1.150577
Q2 loss: 1.150577
Current threshold: -24.2107
Global Scale Offset: 0.0643
Reward stats: mean=-0.0055, std=0.1481, count=340
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.1506, Q2 Loss: 1.1506, Entropy: 0.0000, Mean TD Error: 2.0273, Threshold: -24.2107
tensor([ 0.0794,  0.5964,  0.5948,  0.4488, -0.2464,  0.6104,  0.6985,  0.9578,
         1.2650,  0.3097,  0.2548,  1.0860,  0.0025,  0.0456, -0.0408, -0.1849],
       device='cuda:1')
Original likelihood: -37.389015197753906
Adjusted likelihood: -37.389015197753906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.45874786376953
Projection step: 1, Loss: 34.623626708984375
Projection step: 2, Loss: 29.747482299804688
Projection step: 3, Loss: 27.9845027923584
Projection step: 4, Loss: 23.307693481445312
Projection step: 5, Loss: 21.93510627746582
Projection step: 6, Loss: 20.130159378051758
Projection step: 7, Loss: 17.636363983154297
Projection step: 8, Loss: 15.839178085327148
Projection step: 9, Loss: 14.281582832336426
Final likelihood: tensor([-14.1603, -14.0450, -14.1873, -14.3804, -14.5188, -14.0473, -14.4221,
        -13.8627, -14.6112, -14.2457, -14.0771, -14.1664, -14.7771, -14.3467,
        -14.0048, -14.6524])
Final projection likelihood: -14.2816
1 mode projection succeeded
New goal: tensor([ 0.0623,  0.5456,  0.5970,  0.5453, -0.1109,  0.6053,  0.7732,  0.7882,
         1.3035,  0.2234,  0.1954,  1.2234, -0.0074,  0.0302, -0.9880],
       device='cuda:1')
tensor([[0.0066]], device='cuda:1') tensor([[0.0095]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -28.508358001708984
Adjusted likelihood: -28.508358001708984
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 28.508358001708984}
Current yaw: tensor([ 0.0025,  0.0456, -0.0408], device='cuda:1')
2 thumb_middle
tensor([ 0.0794,  0.5964,  0.5948,  0.4488, -0.2464,  0.6104,  0.6985,  0.9578,
         1.2650,  0.3097,  0.2548,  1.0860,  0.0025,  0.0456, -0.0408, -0.1849],
       device='cuda:1')
Solve time for step 1 8.839008390001254
Current ori: tensor([ 0.0025,  0.0456, -0.0408], device='cuda:1')
Index force: tensor([0.6194, 0.5041, 0.5918, 0.6010], device='cuda:1')
tensor([ 0.0830,  0.5354,  0.6031,  0.6021, -0.2366,  0.5982,  0.7440,  0.8136,
         1.2730,  0.2278,  0.1592,  1.1744,  0.0266,  0.0485, -0.0408, -0.1405],
       device='cuda:1')
Solve time for step 2 1.9658968389849178
Current ori: tensor([ 0.0266,  0.0485, -0.0408], device='cuda:1')
Index force: tensor([0.5040, 0.5903, 0.5991], device='cuda:1')
tensor([ 0.0772,  0.5401,  0.5979,  0.5877, -0.2376,  0.6066,  0.7572,  0.7847,
         1.2960,  0.2139,  0.1394,  1.1896,  0.0247,  0.0513, -0.0408, -0.1553],
       device='cuda:1')
Solve time for step 3 1.8759440670255572
Current ori: tensor([ 0.0247,  0.0513, -0.0408], device='cuda:1')
Index force: tensor([0.5849, 0.5951], device='cuda:1')
tensor([ 0.0820,  0.5648,  0.5913,  0.5447, -0.2303,  0.6131,  0.7608,  0.7786,
         1.2926,  0.2116,  0.1249,  1.1996,  0.0157,  0.0471, -0.0408, -0.1593],
       device='cuda:1')
Solve time for step 4 1.809036129998276
Current ori: tensor([ 0.0157,  0.0471, -0.0408], device='cuda:1')
Index force: tensor([0.5868], device='cuda:1')
Storing RECOVERY transition: reward=0.0033 (scaled=0.0033), steps=1
Reward stats updated: mean -0.0055 -> -0.0054, std: 0.1479
Collected 341 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.0044, Q2 Loss=2.0044, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.5015
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1525, Q2 Loss=1.1525, Entropy=0.0018, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8948
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4053, Q2 Loss=1.4053, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4910
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.3401, Q2 Loss=1.3401, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7812
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0312, Q2 Loss=1.0312, Entropy=0.0006, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3373

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.2%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.3%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.386707
Q2 loss: 1.386707
Current threshold: -24.1916
Global Scale Offset: 0.0636
Reward stats: mean=-0.0054, std=0.1479, count=341
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.3867, Q2 Loss: 1.3867, Entropy: 0.0005, Mean TD Error: 1.6012, Threshold: -24.1916
Original likelihood: -28.833271026611328
Adjusted likelihood: -28.833271026611328
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 28.49207878112793
Projection step: 1, Loss: 26.05596923828125
Projection step: 2, Loss: 21.167036056518555
Projection step: 3, Loss: 21.012210845947266
Projection step: 4, Loss: 17.7886905670166
Projection step: 5, Loss: 16.264251708984375
Projection step: 6, Loss: 14.975608825683594
Final likelihood: tensor([-13.6011, -22.7369, -13.6439, -13.5972, -13.4493, -13.2134, -12.9126,
        -13.5930, -18.5104, -15.0347, -18.5392, -14.9809, -14.4660, -14.4762,
        -14.1113, -12.7436])
Final projection likelihood: -14.9756
1 mode projection succeeded
New goal: tensor([ 0.0743,  0.5810,  0.5682,  0.5599, -0.1335,  0.6181,  0.8064,  0.7610,
         1.3287,  0.2460,  0.1950,  1.2278,  0.0166,  0.0278, -0.8832],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -26.07831573486328
Adjusted likelihood: -26.07831573486328
Likelihood residual: 0.0
Original likelihood: -21.938674926757812
Adjusted likelihood: -21.938674926757812
Likelihood residual: 0.0
{'index': 21.938674926757812, 'thumb_middle': 26.07831573486328}
Current yaw: tensor([ 0.0136,  0.0448, -0.0442], device='cuda:1')
3 index
tensor([ 0.0823,  0.5741,  0.5834,  0.5362, -0.1736,  0.6469,  0.7804,  0.7911,
         1.3641,  0.2369,  0.1637,  1.2180,  0.0136,  0.0448, -0.0442, -0.1100],
       device='cuda:1')
Solve time for step 1 10.66489710798487
Current ori: tensor([ 0.0136,  0.0448, -0.0442], device='cuda:1')
Middle force: tensor([0.5128, 0.5425, 0.6017, 0.5693], device='cuda:1')
Thumb force: tensor([0.5533, 0.5339, 0.5571, 0.5666], device='cuda:1')
tensor([ 0.1235,  0.5171,  0.5202,  0.5311, -0.1810,  0.6279,  0.8097,  0.7773,
         1.3647,  0.2417,  0.1761,  1.2013,  0.0152,  0.0486, -0.0640, -0.5329],
       device='cuda:1')
Solve time for step 2 2.30054731699056
Current ori: tensor([ 0.0152,  0.0486, -0.0640], device='cuda:1')
Middle force: tensor([0.5415, 0.5995, 0.5676], device='cuda:1')
Thumb force: tensor([0.5316, 0.5552, 0.5649], device='cuda:1')
tensor([ 0.1220,  0.5256,  0.5190,  0.5339, -0.1713,  0.6344,  0.8099,  0.7689,
         1.3571,  0.2478,  0.1679,  1.2076,  0.0131,  0.0423, -0.0656, -0.6327],
       device='cuda:1')
Solve time for step 3 2.168953982007224
Current ori: tensor([ 0.0131,  0.0423, -0.0656], device='cuda:1')
Middle force: tensor([0.5089, 0.5376], device='cuda:1')
Thumb force: tensor([0.5653, 0.5370], device='cuda:1')
tensor([ 0.1194,  0.5300,  0.5147,  0.5373, -0.1657,  0.6298,  0.8206,  0.7733,
         1.3437,  0.2676,  0.1594,  1.2224,  0.0139,  0.0368, -0.0811, -0.5349],
       device='cuda:1')
Solve time for step 4 2.1229008219961543
Current ori: tensor([ 0.0139,  0.0368, -0.0811], device='cuda:1')
Middle force: tensor([0.5397], device='cuda:1')
Thumb force: tensor([0.6203], device='cuda:1')
Storing RECOVERY transition: reward=0.0475 (scaled=0.0475), steps=1
Reward stats updated: mean -0.0054 -> -0.0053, std: 0.1477
Collected 342 transitions for RL
SAC Update 1/5: Actor Loss=-0.0027, Q1 Loss=1.3547, Q2 Loss=1.3547, Entropy=0.1189, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1843
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3737, Q2 Loss=1.3737, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6070
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8582, Q2 Loss=0.8582, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0950
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0843, Q2 Loss=1.0843, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4751
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2101, Q2 Loss=1.2101, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0699

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.3%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000532
Q1 loss: 1.176198
Q2 loss: 1.176198
Current threshold: -24.1640
Global Scale Offset: 0.0631
Reward stats: mean=-0.0053, std=0.1477, count=342
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.1762, Q2 Loss: 1.1762, Entropy: 0.0238, Mean TD Error: 0.8862, Threshold: -24.1640
Original likelihood: -26.813812255859375
Adjusted likelihood: -26.813812255859375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 23.79478645324707
Projection step: 1, Loss: 21.402347564697266
Projection step: 2, Loss: 18.649553298950195
Projection step: 3, Loss: 16.25253677368164
Projection step: 4, Loss: 15.462596893310547
Projection step: 5, Loss: 13.505772590637207
Final likelihood: tensor([-13.0709, -12.5649, -12.7624, -12.5972, -13.0633, -12.7634, -14.1676,
        -12.8213, -16.4897, -12.6018, -12.5117, -13.5623, -13.1839, -13.2431,
        -13.8872, -16.8017])
Final projection likelihood: -13.5058
1 mode projection succeeded
New goal: tensor([ 0.0682,  0.5870,  0.5418,  0.5774, -0.1311,  0.6029,  0.8338,  0.7609,
         1.3192,  0.2492,  0.1829,  1.2402,  0.0144,  0.0263, -0.9033],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -22.590473175048828
Adjusted likelihood: -22.590473175048828
Likelihood residual: 0.0
Original likelihood: -18.376346588134766
Adjusted likelihood: -18.376346588134766
Likelihood residual: 0.0
{'index': 18.376346588134766, 'thumb_middle': 22.590473175048828}
Current yaw: tensor([ 0.0118,  0.0390, -0.0881], device='cuda:1')
4 index
tensor([ 0.0706,  0.5858,  0.5494,  0.5513, -0.1680,  0.6312,  0.8176,  0.7682,
         1.3571,  0.2548,  0.1465,  1.2316,  0.0118,  0.0390, -0.0881, -0.5084],
       device='cuda:1')
Solve time for step 1 10.722798761009471
Current ori: tensor([ 0.0118,  0.0390, -0.0881], device='cuda:1')
Middle force: tensor([0.5976, 0.5067, 0.5345, 0.5953], device='cuda:1')
Thumb force: tensor([0.5936, 0.5959, 0.6273, 0.5066], device='cuda:1')
tensor([ 0.1186,  0.5266,  0.4928,  0.5486, -0.1656,  0.6191,  0.8392,  0.7642,
         1.3457,  0.2716,  0.1533,  1.2220,  0.0122,  0.0358, -0.1136, -0.1986],
       device='cuda:1')
Solve time for step 2 2.2287854079913814
Current ori: tensor([ 0.0122,  0.0358, -0.1136], device='cuda:1')
Middle force: tensor([0.5063, 0.5333, 0.5931], device='cuda:1')
Thumb force: tensor([0.5933, 0.6247, 0.5061], device='cuda:1')
tensor([ 0.1143,  0.5353,  0.4903,  0.5519, -0.1605,  0.6213,  0.8414,  0.7619,
         1.3553,  0.2531,  0.1367,  1.2361,  0.0124,  0.0320, -0.1103,  0.0243],
       device='cuda:1')
Solve time for step 3 2.23966912200558
Current ori: tensor([ 0.0124,  0.0320, -0.1103], device='cuda:1')
Middle force: tensor([0.5317, 0.5909], device='cuda:1')
Thumb force: tensor([0.6195, 0.5055], device='cuda:1')
tensor([ 0.1148,  0.5371,  0.4919,  0.5521, -0.1668,  0.6157,  0.8424,  0.7695,
         1.3600,  0.2539,  0.1406,  1.2276,  0.0120,  0.0355, -0.1282,  0.1865],
       device='cuda:1')
Solve time for step 4 2.142647799977567
Current ori: tensor([ 0.0120,  0.0355, -0.1282], device='cuda:1')
Middle force: tensor([0.5708], device='cuda:1')
Thumb force: tensor([0.5724], device='cuda:1')
Storing RECOVERY transition: reward=0.1025 (scaled=0.1025), steps=1
Reward stats updated: mean -0.0053 -> -0.0050, std: 0.1476
Collected 343 transitions for RL
SAC Update 1/5: Actor Loss=-0.0012, Q1 Loss=0.9371, Q2 Loss=0.9371, Entropy=0.0516, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5670
SAC Update 2/5: Actor Loss=-0.0132, Q1 Loss=1.1643, Q2 Loss=1.1643, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7616
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2254, Q2 Loss=1.2254, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5735
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7011, Q2 Loss=0.7011, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0706
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0528, Q2 Loss=1.0528, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7095

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002891
Q1 loss: 1.016158
Q2 loss: 1.016158
Current threshold: -24.1409
Global Scale Offset: 0.0627
Reward stats: mean=-0.0050, std=0.1476, count=343
----------------------------------------------
SAC Update - Actor Loss: -0.0029, Q1 Loss: 1.0162, Q2 Loss: 1.0162, Entropy: 0.0103, Mean TD Error: 0.7364, Threshold: -24.1409
Original likelihood: -22.344093322753906
Adjusted likelihood: -22.344093322753906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0092,  0.0369, -0.1431], device='cuda:1')
5 turn
Sampling time 3.7971883580030408
tensor([ 0.0647,  0.5913,  0.5279,  0.5683, -0.1654,  0.6214,  0.8340,  0.7583,
         1.3679,  0.2515,  0.1320,  1.2290,  0.0092,  0.0369, -0.1431,  0.2130],
       device='cuda:1')
Original likelihood: -22.05699920654297
Adjusted likelihood: -22.05699920654297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.328133730014088
Current ori: tensor([ 0.0092,  0.0369, -0.1431], device='cuda:1')
Middle force: tensor([0.5221, 0.7132, 0.5597, 0.5114, 0.8113, 1.1002, 0.5897, 0.5640, 0.5211,
        0.6011, 0.6335, 0.5230], device='cuda:1')
Thumb force: tensor([0.9296, 0.6647, 1.6358, 2.5522, 0.9187, 1.8034, 0.6104, 0.7263, 0.5453,
        1.6046, 0.5780, 0.6048], device='cuda:1')
Index force: tensor([0.5238, 0.8977, 0.6080, 0.5949, 0.6010, 0.6007, 0.5942, 0.5289, 0.4968,
        0.7904, 0.5534, 0.7696], device='cuda:1')
Storing NORMAL transition: reward=0.1128 (scaled=0.1128), steps=1
Reward stats updated: mean -0.0050 -> -0.0046, std: 0.1475
Collected 344 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9298, Q2 Loss=0.9298, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9397
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7401, Q2 Loss=0.7401, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1629
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1857, Q2 Loss=1.1857, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7859
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1205, Q2 Loss=1.1205, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9369
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7888, Q2 Loss=0.7888, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6351

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.952988
Q2 loss: 0.952988
Current threshold: -24.1273
Global Scale Offset: 0.0625
Reward stats: mean=-0.0046, std=0.1475, count=344
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.9530, Q2 Loss: 0.9530, Entropy: 0.0000, Mean TD Error: 0.6921, Threshold: -24.1273
tensor([ 0.0304,  0.5700,  0.5397,  0.5325, -0.1170,  0.5792,  0.9377,  0.7583,
         1.2913,  0.3545,  0.1346,  1.1976,  0.0170, -0.0031, -0.2549,  0.7971],
       device='cuda:1')
Original likelihood: -17.393043518066406
Adjusted likelihood: -17.393043518066406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.9470577479805797
Current ori: tensor([ 0.0170, -0.0031, -0.2549], device='cuda:1')
Middle force: tensor([0.7420, 0.5589, 0.5196, 0.8134, 1.0934, 0.6144, 0.5728, 0.5279, 0.6657,
        0.6342, 0.5574], device='cuda:1')
Thumb force: tensor([0.6291, 1.6215, 2.5056, 0.9108, 1.7902, 0.5870, 0.7056, 0.5377, 1.5437,
        0.5761, 0.5548], device='cuda:1')
Index force: tensor([0.8949, 0.6068, 0.5773, 0.5991, 0.5992, 0.5913, 0.5285, 0.5008, 0.7449,
        0.5520, 0.7425], device='cuda:1')
Storing NORMAL transition: reward=-0.0216 (scaled=-0.0216), steps=1
Reward stats updated: mean -0.0046 -> -0.0047, std: 0.1473
Collected 345 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0894, Q2 Loss=1.0894, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5027
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7492, Q2 Loss=0.7492, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1496
SAC Update 3/5: Actor Loss=-0.0160, Q1 Loss=1.2383, Q2 Loss=1.2383, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6957
SAC Update 4/5: Actor Loss=-0.0200, Q1 Loss=1.3570, Q2 Loss=1.3570, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6488
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.3038, Q2 Loss=1.3038, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6137

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.1%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007189
Q1 loss: 1.147542
Q2 loss: 1.147542
Current threshold: -24.1192
Global Scale Offset: 0.0623
Reward stats: mean=-0.0047, std=0.1473, count=345
----------------------------------------------
SAC Update - Actor Loss: -0.0072, Q1 Loss: 1.1475, Q2 Loss: 1.1475, Entropy: 0.0000, Mean TD Error: 0.5221, Threshold: -24.1192
tensor([ 0.0066,  0.5617,  0.5447,  0.4870, -0.0826,  0.6751,  0.7704,  0.9148,
         1.2066,  0.3189,  0.1509,  1.1454,  0.0128, -0.0293, -0.2341,  0.6395],
       device='cuda:1')
Original likelihood: -26.125219345092773
Adjusted likelihood: -26.125219345092773
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 25.473560333251953
Projection step: 1, Loss: 21.623279571533203
Projection step: 2, Loss: 18.58924102783203
Projection step: 3, Loss: 16.602954864501953
Projection step: 4, Loss: 16.687868118286133
Projection step: 5, Loss: 15.136711120605469
Projection step: 6, Loss: 14.219182968139648
Final likelihood: tensor([-16.6816, -14.2062, -12.4189, -12.8271, -13.7559, -17.7396, -12.8612,
        -13.6565, -13.5664, -14.0351, -12.9314, -12.9582, -18.8829, -13.5383,
        -14.0447, -13.4030])
Final projection likelihood: -14.2192
1 mode projection succeeded
New goal: tensor([ 0.0190,  0.5476,  0.5855,  0.5499, -0.0530,  0.5579,  0.8385,  0.8682,
         1.2805,  0.2772,  0.1746,  1.1321,  0.0097, -0.0235, -0.8275],
       device='cuda:1')
tensor([[0.0083]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -21.0361385345459
Adjusted likelihood: -21.0361385345459
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.0361385345459}
Current yaw: tensor([ 0.0128, -0.0293, -0.2341], device='cuda:1')
6 thumb_middle
tensor([ 0.0066,  0.5617,  0.5447,  0.4870, -0.0826,  0.6751,  0.7704,  0.9148,
         1.2066,  0.3189,  0.1509,  1.1454,  0.0128, -0.0293, -0.2341,  0.6395],
       device='cuda:1')
Solve time for step 1 8.961005078017479
Current ori: tensor([ 0.0128, -0.0293, -0.2341], device='cuda:1')
Index force: tensor([0.5883, 0.5860, 0.5931, 0.5925], device='cuda:1')
tensor([ 0.0045,  0.5320,  0.5605,  0.5340, -0.1262,  0.5763,  0.7904,  0.8506,
         1.2324,  0.2767,  0.0959,  1.0979,  0.0207, -0.0256, -0.2341,  0.6259],
       device='cuda:1')
Solve time for step 2 2.064830508985324
Current ori: tensor([ 0.0207, -0.0256, -0.2341], device='cuda:1')
Index force: tensor([0.5796, 0.5880, 0.5866], device='cuda:1')
tensor([-0.0032,  0.5205,  0.5651,  0.5425, -0.1441,  0.5701,  0.8138,  0.8543,
         1.2452,  0.2689,  0.0865,  1.1140,  0.0252, -0.0219, -0.2341,  0.6313],
       device='cuda:1')
Solve time for step 3 1.9776503100001719
Current ori: tensor([ 0.0252, -0.0219, -0.2341], device='cuda:1')
Index force: tensor([0.5804, 0.5800], device='cuda:1')
tensor([ 0.0044,  0.5352,  0.5522,  0.5405, -0.1375,  0.5831,  0.8036,  0.8554,
         1.2435,  0.2528,  0.0897,  1.1054,  0.0216, -0.0258, -0.2341,  0.6365],
       device='cuda:1')
Solve time for step 4 1.7759896909992676
Current ori: tensor([ 0.0216, -0.0258, -0.2341], device='cuda:1')
Index force: tensor([0.5732], device='cuda:1')
Storing RECOVERY transition: reward=0.0014 (scaled=0.0007), steps=2
Reward stats updated: mean -0.0047 -> -0.0047, std: 0.1471
Collected 346 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7613, Q2 Loss=0.7613, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2258
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8424, Q2 Loss=0.8424, Entropy=0.0042, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.3354
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=1.6714, Q2 Loss=1.6714, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.3824
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7715, Q2 Loss=0.7715, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7003
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.2568, Q2 Loss=1.2568, Entropy=0.0410, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3059

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004608
Q1 loss: 1.060707
Q2 loss: 1.060707
Current threshold: -24.1143
Global Scale Offset: 0.0622
Reward stats: mean=-0.0047, std=0.1471, count=346
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.0607, Q2 Loss: 1.0607, Entropy: 0.0090, Mean TD Error: 1.1900, Threshold: -24.1143
Original likelihood: -21.56586456298828
Adjusted likelihood: -21.56586456298828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0257, -0.0253, -0.2358], device='cuda:1')
7 turn
Sampling time 3.8275104950007517
tensor([-0.0088,  0.5291,  0.5419,  0.5522, -0.0903,  0.6302,  0.8548,  0.8661,
         1.2996,  0.2957,  0.1518,  1.1236,  0.0257, -0.0253, -0.2358,  0.5922],
       device='cuda:1')
Original likelihood: -21.832422256469727
Adjusted likelihood: -21.832422256469727
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.162851680011954
Current ori: tensor([ 0.0257, -0.0253, -0.2358], device='cuda:1')
Middle force: tensor([1.1294, 1.2699, 1.4787, 0.5754, 1.0303, 0.6497, 0.5770, 0.7422, 0.7322,
        0.5155, 0.6858, 0.6433], device='cuda:1')
Thumb force: tensor([0.7696, 0.6125, 0.6596, 0.5012, 0.5823, 0.5061, 0.8907, 0.7748, 0.7059,
        0.7899, 0.5572, 0.6070], device='cuda:1')
Index force: tensor([0.5929, 1.0958, 0.9445, 0.5728, 0.5696, 0.6256, 0.6099, 0.5361, 0.5341,
        0.5629, 0.5464, 0.5927], device='cuda:1')
Storing NORMAL transition: reward=0.1562 (scaled=0.1562), steps=1
Reward stats updated: mean -0.0047 -> -0.0042, std: 0.1471
Collected 347 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2766, Q2 Loss=1.2766, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4702
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.7951, Q2 Loss=0.7951, Entropy=0.1014, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3197
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0461, Q2 Loss=1.0461, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7247
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3045, Q2 Loss=1.3045, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6210
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=1.3497, Q2 Loss=1.3497, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7865

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (20.3%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004616
Q1 loss: 1.154403
Q2 loss: 1.154403
Current threshold: -24.1103
Global Scale Offset: 0.0622
Reward stats: mean=-0.0042, std=0.1471, count=347
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.1544, Q2 Loss: 1.1544, Entropy: 0.0203, Mean TD Error: 0.5844, Threshold: -24.1103
tensor([ 0.0278,  0.5074,  0.6147,  0.5419, -0.0568,  0.5116,  0.8263,  0.9375,
         1.2595,  0.3949,  0.3820,  0.9984,  0.1209,  0.0254, -0.4120,  1.4565],
       device='cuda:1')
Original likelihood: -42.20669937133789
Adjusted likelihood: -42.20669937133789
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 37.73131561279297
Projection step: 1, Loss: 35.9340705871582
Projection step: 2, Loss: 33.69291687011719
Projection step: 3, Loss: 33.31010437011719
Projection step: 4, Loss: 28.55611801147461
Projection step: 5, Loss: 36.27421188354492
Projection step: 6, Loss: 34.814659118652344
Projection step: 7, Loss: 34.92170715332031
Projection step: 8, Loss: 27.892864227294922
Projection step: 9, Loss: 35.99797058105469
Projection step: 10, Loss: 32.070899963378906
Projection step: 11, Loss: 34.45661163330078
Projection step: 12, Loss: 33.35809326171875
Projection step: 13, Loss: 28.991737365722656
Projection step: 14, Loss: 31.79505729675293
Final likelihood: tensor([-37.5514, -16.1730, -37.2465, -37.9454, -33.1967, -14.1996, -40.8479,
        -26.7185, -39.8079, -14.4951, -34.8575, -33.5217, -14.4069, -34.9911,
        -16.3262, -15.0626])
Final projection likelihood: -27.9593
1 mode projection failed, trying anyway
New goal: tensor([ 0.0455,  0.5416,  0.5641,  0.6299, -0.0647,  0.4453,  0.9045,  0.9334,
         1.2531,  0.3569,  0.3288,  1.1538,  0.1127,  0.0191, -0.5558],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -35.21099853515625
Adjusted likelihood: -35.21099853515625
Likelihood residual: 0.0
Original likelihood: -22.96529769897461
Adjusted likelihood: -22.96529769897461
Likelihood residual: 0.0
{'index': 22.96529769897461, 'thumb_middle': 35.21099853515625}
Current yaw: tensor([ 0.1209,  0.0254, -0.4120], device='cuda:1')
8 index
tensor([ 0.0278,  0.5074,  0.6147,  0.5419, -0.0568,  0.5116,  0.8263,  0.9375,
         1.2595,  0.3949,  0.3820,  0.9984,  0.1209,  0.0254, -0.4120,  1.4565],
       device='cuda:1')
Solve time for step 1 10.515049829002237
Current ori: tensor([ 0.1209,  0.0254, -0.4120], device='cuda:1')
Middle force: tensor([0.5740, 0.5563, 0.5682, 0.5537], device='cuda:1')
Thumb force: tensor([0.5844, 0.5550, 0.5051, 0.6557], device='cuda:1')
tensor([ 0.0727,  0.4174,  0.5369,  0.6080, -0.0207,  0.5132,  0.8968,  0.9224,
         1.3183,  0.3849,  0.3356,  1.0598,  0.2530,  0.0285, -0.4111, -1.1747],
       device='cuda:1')
Solve time for step 2 2.2454428570054006
Current ori: tensor([ 0.2530,  0.0285, -0.4111], device='cuda:1')
Middle force: tensor([0.5528, 0.5634, 0.5511], device='cuda:1')
Thumb force: tensor([0.5537, 0.5053, 0.6584], device='cuda:1')
tensor([ 0.0512,  0.3017,  0.5422,  0.6362,  0.0129,  0.5735,  0.9182,  1.0017,
         1.3773,  0.3813,  0.3618,  1.0888,  0.2686,  0.0247, -0.4112, -1.4560],
       device='cuda:1')
Solve time for step 3 2.2665397959935945
Current ori: tensor([ 0.2686,  0.0247, -0.4112], device='cuda:1')
Middle force: tensor([0.5599, 0.5460], device='cuda:1')
Thumb force: tensor([0.5047, 0.6614], device='cuda:1')
tensor([ 0.0533,  0.2502,  0.5919,  0.6494,  0.0311,  0.6319,  0.9415,  1.0086,
         1.4353,  0.3537,  0.3580,  1.0947,  0.2786,  0.0107, -0.4235, -0.5278],
       device='cuda:1')
Solve time for step 4 2.0976767020183615
Current ori: tensor([ 0.2786,  0.0107, -0.4235], device='cuda:1')
Middle force: tensor([0.5359], device='cuda:1')
Thumb force: tensor([0.6680], device='cuda:1')
Storing RECOVERY transition: reward=-0.0609 (scaled=-0.0609), steps=1
Reward stats updated: mean -0.0042 -> -0.0044, std: 0.1469
Collected 348 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7057, Q2 Loss=0.7057, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5839
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8292, Q2 Loss=0.8292, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4397
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=5.4332, Q2 Loss=5.4332, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=6.4875
SAC Update 4/5: Actor Loss=-0.0150, Q1 Loss=0.8743, Q2 Loss=0.8743, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1429
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=1.2260, Q2 Loss=1.2260, Entropy=0.0030, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.5260

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (18.9%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007600
Q1 loss: 1.813668
Q2 loss: 1.813668
Current threshold: -24.0879
Global Scale Offset: 0.0615
Reward stats: mean=-0.0044, std=0.1469, count=348
----------------------------------------------
SAC Update - Actor Loss: -0.0076, Q1 Loss: 1.8137, Q2 Loss: 1.8137, Entropy: 0.0006, Mean TD Error: 2.0360, Threshold: -24.0879
Original likelihood: -47.298072814941406
Adjusted likelihood: -47.298072814941406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 48.49311828613281
Projection step: 1, Loss: 47.26627731323242
Projection step: 2, Loss: 45.30547332763672
Projection step: 3, Loss: 44.63353729248047
Projection step: 4, Loss: 43.60377883911133
Projection step: 5, Loss: 42.14661407470703
Projection step: 6, Loss: 40.1313362121582
Projection step: 7, Loss: 42.18608093261719
Projection step: 8, Loss: 38.531089782714844
Projection step: 9, Loss: 37.99863052368164
Projection step: 10, Loss: 37.48588562011719
Projection step: 11, Loss: 37.349334716796875
Projection step: 12, Loss: 37.80187225341797
Projection step: 13, Loss: 37.307289123535156
Projection step: 14, Loss: 36.40389633178711
Final likelihood: tensor([-30.1523, -37.8786, -35.5570, -31.9470, -37.1167, -39.4685, -35.2537,
        -38.0032, -37.0966, -32.4435, -31.5788, -37.9338, -32.9097, -38.6234,
        -35.5394, -34.7644])
Final projection likelihood: -35.3917
1 mode projection failed, trying anyway
New goal: tensor([1.1365e-01, 4.2069e-01, 7.3698e-01, 7.8234e-01, 9.4302e-04, 5.0858e-01,
        9.0374e-01, 1.1018e+00, 1.3369e+00, 2.6685e-01, 3.8436e-01, 9.3159e-01,
        2.3144e-01, 2.8425e-04, 3.5968e-01], device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -42.51476287841797
Adjusted likelihood: -42.51476287841797
Likelihood residual: 0.0
Original likelihood: -65.54144287109375
Adjusted likelihood: -65.54144287109375
Likelihood residual: 0.0
{'index': 65.54144287109375, 'thumb_middle': 42.51476287841797}
Current yaw: tensor([ 0.2467, -0.0012, -0.4077], device='cuda:1')
9 thumb_middle
tensor([ 1.1863e-01,  4.3651e-01,  6.0504e-01,  6.4383e-01,  2.4533e-02,
         6.4593e-01,  9.5007e-01,  9.6399e-01,  1.4098e+00,  3.8005e-01,
         3.4545e-01,  1.0520e+00,  2.4666e-01, -1.2018e-03, -4.0768e-01,
        -7.9233e-01], device='cuda:1')
Solve time for step 1 9.233206503995461
Current ori: tensor([ 0.2467, -0.0012, -0.4077], device='cuda:1')
Index force: tensor([0.5924, 0.5523, 0.5752, 0.5884], device='cuda:1')
tensor([ 0.1359,  0.4541,  0.8202,  0.9149, -0.0638,  0.5157,  0.8627,  1.0371,
         1.3356,  0.2820,  0.3470,  0.9479,  0.2444, -0.0062, -0.4304, -0.5900],
       device='cuda:1')
Solve time for step 2 1.9428738999995403
Current ori: tensor([ 0.2444, -0.0062, -0.4304], device='cuda:1')
Index force: tensor([0.5504, 0.5724, 0.5850], device='cuda:1')
tensor([ 1.2958e-01,  4.3974e-01,  8.3975e-01,  8.6824e-01, -8.0290e-02,
         5.3480e-01,  8.4707e-01,  1.0515e+00,  1.3419e+00,  2.7666e-01,
         3.3926e-01,  9.4341e-01,  2.4668e-01, -4.4066e-04, -4.5501e-01,
        -6.7714e-01], device='cuda:1')
Solve time for step 3 2.0032530720054638
Current ori: tensor([ 2.4668e-01, -4.4066e-04, -4.5501e-01], device='cuda:1')
Index force: tensor([0.5670, 0.5792], device='cuda:1')
tensor([ 0.1085,  0.4440,  0.8443,  0.8388, -0.0993,  0.5203,  0.8392,  1.0564,
         1.3463,  0.2613,  0.3517,  0.9283,  0.2472,  0.0044, -0.4723, -0.7633],
       device='cuda:1')
Solve time for step 4 1.8051595150027424
Current ori: tensor([ 0.2472,  0.0044, -0.4723], device='cuda:1')
Index force: tensor([0.5705], device='cuda:1')
Storing RECOVERY transition: reward=-0.0021 (scaled=-0.0021), steps=1
Reward stats updated: mean -0.0044 -> -0.0044, std: 0.1467
Collected 349 transitions for RL
SAC Update 1/5: Actor Loss=-0.0158, Q1 Loss=1.1969, Q2 Loss=1.1969, Entropy=0.2002, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5494
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9522, Q2 Loss=0.9522, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.9248
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9511, Q2 Loss=0.9511, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8276
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1404, Q2 Loss=1.1404, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5323
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.6981, Q2 Loss=1.6981, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7288

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003162
Q1 loss: 1.187739
Q2 loss: 1.187739
Current threshold: -24.0494
Global Scale Offset: 0.0603
Reward stats: mean=-0.0044, std=0.1467, count=349
----------------------------------------------
SAC Update - Actor Loss: -0.0032, Q1 Loss: 1.1877, Q2 Loss: 1.1877, Entropy: 0.0400, Mean TD Error: 1.1126, Threshold: -24.0494
Original likelihood: -47.13861846923828
Adjusted likelihood: -47.13861846923828
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 45.95513916015625
Projection step: 1, Loss: 45.255409240722656
Projection step: 2, Loss: 43.56870651245117
Projection step: 3, Loss: 42.31827926635742
Projection step: 4, Loss: 42.726036071777344
Projection step: 5, Loss: 42.511207580566406
Projection step: 6, Loss: 44.02091979980469
Projection step: 7, Loss: 41.29999923706055
Projection step: 8, Loss: 41.37640380859375
Projection step: 9, Loss: 40.68260955810547
Projection step: 10, Loss: 39.16465759277344
Projection step: 11, Loss: 40.00065612792969
Projection step: 12, Loss: 38.91023635864258
Projection step: 13, Loss: 37.901206970214844
Projection step: 14, Loss: 37.01165771484375
Final likelihood: tensor([-34.1000, -32.0003, -34.9964, -38.7026, -34.8821, -33.5691, -46.5485,
        -32.6241, -41.4145, -38.0393, -40.6252, -32.8239, -41.2418, -35.2117,
        -33.4263, -35.3135])
Final projection likelihood: -36.5950
1 mode projection failed, trying anyway
New goal: tensor([ 0.0985,  0.3533,  0.7427,  0.8768, -0.0088,  0.4840,  0.9263,  1.1699,
         1.3490,  0.2149,  0.4545,  0.8122,  0.2348,  0.0121,  0.4935],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0021]], device='cuda:1')
Original likelihood: -53.140220642089844
Adjusted likelihood: -53.140220642089844
Likelihood residual: 0.0
Original likelihood: -46.378265380859375
Adjusted likelihood: -46.378265380859375
Likelihood residual: 0.0
{'index': 46.378265380859375, 'thumb_middle': 53.140220642089844}
Current yaw: tensor([ 0.2488,  0.0100, -0.4847], device='cuda:1')
10 index
tensor([ 0.0886,  0.4397,  0.8317,  0.8455, -0.0063,  0.5742,  0.9203,  1.1008,
         1.3918,  0.2861,  0.4355,  0.9914,  0.2488,  0.0100, -0.4847, -0.7845],
       device='cuda:1')
Solve time for step 1 10.686067911010468
Current ori: tensor([ 0.2488,  0.0100, -0.4847], device='cuda:1')
Middle force: tensor([0.5208, 0.5098, 0.5569, 0.5068], device='cuda:1')
Thumb force: tensor([0.5347, 0.5785, 0.5488, 0.5690], device='cuda:1')
tensor([ 0.0620,  0.1399,  0.7663,  0.8661, -0.0216,  0.6224,  0.9332,  1.1094,
         1.4298,  0.2967,  0.4617,  0.9518,  0.2982,  0.0118, -0.4847, -0.0378],
       device='cuda:1')
Solve time for step 2 2.286209787998814
Current ori: tensor([ 0.2982,  0.0118, -0.4847], device='cuda:1')
Middle force: tensor([0.5068, 0.5714, 0.5804], device='cuda:1')
Thumb force: tensor([0.5685, 0.5220, 0.5394], device='cuda:1')
tensor([ 0.0099,  0.0401,  0.8073,  0.8910, -0.0366,  0.6244,  0.9460,  1.1711,
         1.4379,  0.3388,  0.4551,  0.9625,  0.3205,  0.0132, -0.4852,  0.1699],
       device='cuda:1')
Solve time for step 3 2.0918284019862767
Current ori: tensor([ 0.3205,  0.0132, -0.4852], device='cuda:1')
Middle force: tensor([0.5360, 0.5111], device='cuda:1')
Thumb force: tensor([0.6025, 0.5330], device='cuda:1')
tensor([ 0.0112,  0.0399,  0.8519,  0.9246, -0.0220,  0.6193,  0.9692,  1.1766,
         1.4526,  0.3558,  0.4304,  0.9723,  0.3206,  0.0148, -0.4897,  0.1485],
       device='cuda:1')
Solve time for step 4 2.095203111995943
Current ori: tensor([ 0.3206,  0.0148, -0.4897], device='cuda:1')
Middle force: tensor([0.5109], device='cuda:1')
Thumb force: tensor([0.5307], device='cuda:1')
Storing RECOVERY transition: reward=-0.0215 (scaled=-0.0215), steps=1
Reward stats updated: mean -0.0044 -> -0.0044, std: 0.1465
Collected 350 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9889, Q2 Loss=0.9889, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4455
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9290, Q2 Loss=0.9290, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8353
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4136, Q2 Loss=1.4136, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6047
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=23.9262, Q2 Loss=23.9262, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=10.5118
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8551, Q2 Loss=0.8551, Entropy=0.0009, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.3634

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.2%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (44.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 5.622547
Q2 loss: 5.622547
Current threshold: -24.0266
Global Scale Offset: 0.0596
Reward stats: mean=-0.0044, std=0.1465, count=350
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.6225, Q2 Loss: 5.6225, Entropy: 0.0002, Mean TD Error: 3.1521, Threshold: -24.0266
Original likelihood: -65.74837493896484
Adjusted likelihood: -65.74837493896484
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 66.45359802246094
Projection step: 1, Loss: 69.05421447753906
Projection step: 2, Loss: 63.84970474243164
Projection step: 3, Loss: 66.39635467529297
Projection step: 4, Loss: 66.42031860351562
Projection step: 5, Loss: 63.19349670410156
Projection step: 6, Loss: 59.94105529785156
Projection step: 7, Loss: 65.23363494873047
Projection step: 8, Loss: 58.50596618652344
Projection step: 9, Loss: 60.8972053527832
Projection step: 10, Loss: 58.5386962890625
Projection step: 11, Loss: 58.97244644165039
Projection step: 12, Loss: 57.05622100830078
Projection step: 13, Loss: 55.352455139160156
Projection step: 14, Loss: 57.19817352294922
Final likelihood: tensor([-50.6364, -52.4428, -53.6321, -50.3204, -54.4678, -62.0220, -71.6879,
        -69.0737, -53.2606, -53.8349, -59.0893, -48.0100, -54.0530, -66.8352,
        -52.2899, -47.9405])
Final projection likelihood: -56.2248
1 mode projection failed, trying anyway
New goal: tensor([ 0.0646,  0.2116,  0.8843,  0.9722, -0.0280,  0.5158,  0.9323,  1.2013,
         1.3862,  0.2140,  0.4056,  0.8201,  0.2758,  0.0100,  0.5114],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -61.9140625
Adjusted likelihood: -61.9140625
Likelihood residual: 0.0
Original likelihood: -88.31509399414062
Adjusted likelihood: -88.31509399414062
Likelihood residual: 0.0
{'index': 88.31509399414062, 'thumb_middle': 61.9140625}
Current yaw: tensor([ 0.2881,  0.0041, -0.4963], device='cuda:1')
11 thumb_middle
tensor([ 0.0211,  0.2299,  0.9633,  0.9932, -0.0247,  0.6127,  0.9620,  1.1815,
         1.4550,  0.3790,  0.3984,  0.9994,  0.2881,  0.0041, -0.4963,  0.4480],
       device='cuda:1')
Solve time for step 1 8.856834995996905
Current ori: tensor([ 0.2881,  0.0041, -0.4963], device='cuda:1')
Index force: tensor([0.5927, 0.5836, 0.6175, 0.5335], device='cuda:1')
tensor([ 0.1086,  0.2689,  0.9702,  1.0164, -0.1004,  0.4413,  0.9142,  1.1759,
         1.3685,  0.2114,  0.3936,  0.9112,  0.2781, -0.0134, -0.4298,  0.4196],
       device='cuda:1')
Solve time for step 2 1.9248461370007135
Current ori: tensor([ 0.2781, -0.0134, -0.4298], device='cuda:1')
Index force: tensor([0.5558, 0.5893, 0.5990], device='cuda:1')
tensor([ 0.1073,  0.2771,  0.9512,  1.0303, -0.1075,  0.4831,  0.8974,  1.1673,
         1.3654,  0.1870,  0.3981,  0.8909,  0.2765, -0.0139, -0.4328,  0.4075],
       device='cuda:1')
Solve time for step 3 1.866841862007277
Current ori: tensor([ 0.2765, -0.0139, -0.4328], device='cuda:1')
Index force: tensor([0.5839, 0.5941], device='cuda:1')
tensor([ 0.0906,  0.2795,  0.9748,  0.9864, -0.1062,  0.4664,  0.8983,  1.1572,
         1.3540,  0.1704,  0.4132,  0.8964,  0.2790, -0.0217, -0.3982,  0.4074],
       device='cuda:1')
Solve time for step 4 1.8514797629904933
Current ori: tensor([ 0.2790, -0.0217, -0.3982], device='cuda:1')
Index force: tensor([0.5640], device='cuda:1')
Storing RECOVERY transition: reward=-0.1387 (scaled=-0.1387), steps=1
Reward stats updated: mean -0.0044 -> -0.0048, std: 0.1465
Collected 351 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.2203, Q2 Loss=1.2203, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6054
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7862, Q2 Loss=0.7862, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3313
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7805, Q2 Loss=0.7805, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7964
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.4818, Q2 Loss=1.4818, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4074
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7913, Q2 Loss=0.7913, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4534

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (39.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.012007
Q2 loss: 1.012007
Current threshold: -24.0132
Global Scale Offset: 0.0592
Reward stats: mean=-0.0048, std=0.1465, count=351
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.0120, Q2 Loss: 1.0120, Entropy: 0.0000, Mean TD Error: 0.9188, Threshold: -24.0132
Original likelihood: -59.333274841308594
Adjusted likelihood: -59.333274841308594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 58.7367057800293
Projection step: 1, Loss: 62.59415054321289
Projection step: 2, Loss: 58.77838897705078
Projection step: 3, Loss: 60.797603607177734
Projection step: 4, Loss: 54.825836181640625
Projection step: 5, Loss: 56.029273986816406
Projection step: 6, Loss: 56.01258850097656
Projection step: 7, Loss: 53.933494567871094
Projection step: 8, Loss: 53.69719314575195
Projection step: 9, Loss: 53.26593017578125
Projection step: 10, Loss: 51.6846923828125
Projection step: 11, Loss: 51.17237854003906
Projection step: 12, Loss: 51.29011917114258
Projection step: 13, Loss: 50.08096694946289
Projection step: 14, Loss: 50.495216369628906
Final likelihood: tensor([-46.8165, -45.4052, -51.7543, -45.8728, -60.7422, -47.2270, -44.4591,
        -46.9398, -51.6615, -47.1784, -47.4930, -44.1026, -45.1854, -70.9265,
        -57.8211, -76.2708])
Final projection likelihood: -51.8660
1 mode projection failed, trying anyway
New goal: tensor([ 0.1176,  0.2741,  0.8605,  1.0307, -0.0056,  0.5077,  0.9534,  1.2491,
         1.3607,  0.1198,  0.4554,  0.8759,  0.2691, -0.0219,  0.5787],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -53.10118865966797
Adjusted likelihood: -53.10118865966797
Likelihood residual: 0.0
Original likelihood: -69.80268859863281
Adjusted likelihood: -69.80268859863281
Likelihood residual: 0.0
{'index': 69.80268859863281, 'thumb_middle': 53.10118865966797}
Current yaw: tensor([ 0.2823, -0.0278, -0.3388], device='cuda:1')
12 thumb_middle
tensor([ 0.0798,  0.2749,  0.9287,  1.0917, -0.0250,  0.5646,  1.0003,  1.2304,
         1.3693,  0.1599,  0.4989,  1.0187,  0.2823, -0.0278, -0.3388,  0.3565],
       device='cuda:1')
Solve time for step 1 8.91976971499389
Current ori: tensor([ 0.2823, -0.0278, -0.3388], device='cuda:1')
Index force: tensor([0.5888, 0.5951, 0.5755, 0.5289], device='cuda:1')
tensor([ 0.0944,  0.2751,  0.9512,  1.0675, -0.0763,  0.4842,  0.9010,  1.1927,
         1.3269,  0.1007,  0.4475,  0.9144,  0.2821, -0.0307, -0.3168,  0.3487],
       device='cuda:1')
Solve time for step 2 2.078291693003848
Current ori: tensor([ 0.2821, -0.0307, -0.3168], device='cuda:1')
Index force: tensor([0.5810, 0.5067, 0.5231], device='cuda:1')
tensor([ 0.1034,  0.3098,  0.9081,  1.1586, -0.0903,  0.4897,  0.9082,  1.1956,
         1.3580,  0.1191,  0.4279,  0.8927,  0.2834, -0.0567, -0.2283,  0.3150],
       device='cuda:1')
Solve time for step 3 1.8973894430091605
Current ori: tensor([ 0.2834, -0.0567, -0.2283], device='cuda:1')
Index force: tensor([0.5060, 0.5204], device='cuda:1')
tensor([ 0.0719,  0.3169,  0.9691,  1.0815, -0.0618,  0.5316,  0.8962,  1.2002,
         1.3804,  0.1281,  0.4095,  0.8643,  0.2895, -0.0872, -0.2062,  0.5027],
       device='cuda:1')
Solve time for step 4 2.0343778189853765
Current ori: tensor([ 0.2895, -0.0872, -0.2062], device='cuda:1')
Index force: tensor([0.5178], device='cuda:1')
Storing RECOVERY transition: reward=-0.2819 (scaled=-0.2819), steps=1
Reward stats updated: mean -0.0048 -> -0.0056, std: 0.1470
Collected 352 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8177, Q2 Loss=0.8177, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7485
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8723, Q2 Loss=0.8723, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3249
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8829, Q2 Loss=0.8829, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2975
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=0.8497, Q2 Loss=0.8497, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2671
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1333, Q2 Loss=1.1333, Entropy=0.0131, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8797

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.06s (20.5%)
Actor update: 0.12s (42.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004606
Q1 loss: 0.911166
Q2 loss: 0.911166
Current threshold: -24.0051
Global Scale Offset: 0.0590
Reward stats: mean=-0.0056, std=0.1470, count=352
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 0.9112, Q2 Loss: 0.9112, Entropy: 0.0026, Mean TD Error: 0.9035, Threshold: -24.0051
Original likelihood: -50.51308059692383
Adjusted likelihood: -50.51308059692383
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 56.469764709472656
Projection step: 1, Loss: 52.63872146606445
Projection step: 2, Loss: 52.36259460449219
Projection step: 3, Loss: 52.01544189453125
Projection step: 4, Loss: 51.688194274902344
Projection step: 5, Loss: 51.475128173828125
Projection step: 6, Loss: 51.03575897216797
Projection step: 7, Loss: 48.69658660888672
Projection step: 8, Loss: 50.47917938232422
Projection step: 9, Loss: 51.52962875366211
Projection step: 10, Loss: 46.903255462646484
Projection step: 11, Loss: 49.35472106933594
Projection step: 12, Loss: 45.721221923828125
Projection step: 13, Loss: 48.863258361816406
Projection step: 14, Loss: 48.42771530151367
Final likelihood: tensor([-46.6616, -51.3869, -35.9727, -40.0253, -61.3590, -42.4894, -48.4880,
        -44.6433, -42.5423, -43.5527, -61.5514, -43.9306, -45.0450, -40.6927,
        -45.4073, -47.9784])
Final projection likelihood: -46.3579
1 mode projection failed, trying anyway
New goal: tensor([ 0.0684,  0.2901,  0.8892,  1.1479,  0.0543,  0.5895,  0.9574,  1.2634,
         1.4208,  0.1345,  0.3945,  0.7726,  0.2878, -0.1138, -1.8937],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0052]], device='cuda:1') tensor([[0.0016]], device='cuda:1')
Original likelihood: -51.73002624511719
Adjusted likelihood: -51.73002624511719
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 51.73002624511719}
Current yaw: tensor([ 0.2997, -0.1201, -0.1946], device='cuda:1')
13 thumb_middle
tensor([ 0.0749,  0.3471,  1.0047,  1.1413,  0.0270,  0.6242,  1.0419,  1.2829,
         1.4420,  0.1680,  0.4654,  0.8890,  0.2997, -0.1201, -0.1946,  0.9360],
       device='cuda:1')
Solve time for step 1 9.337712076987373
Current ori: tensor([ 0.2997, -0.1201, -0.1946], device='cuda:1')
Index force: tensor([0.5925, 0.5745, 0.5703, 0.5907], device='cuda:1')
tensor([ 0.0346,  0.3954,  0.9368,  1.1583,  0.0180,  0.6102,  0.9426,  1.2467,
         1.4078,  0.1372,  0.3636,  0.7882,  0.3385, -0.2189, -0.2027,  0.9976],
       device='cuda:1')
Solve time for step 2 1.9499675989791285
Current ori: tensor([ 0.3385, -0.2189, -0.2027], device='cuda:1')
Index force: tensor([0.5715, 0.5671, 0.5860], device='cuda:1')
tensor([ 0.0278,  0.4606,  0.9374,  1.1796,  0.0633,  0.6690,  0.9942,  1.2745,
         1.3334,  0.1694,  0.3403,  0.7613,  0.3555, -0.2662, -0.0529,  1.9350],
       device='cuda:1')
Solve time for step 3 1.914767648006091
Current ori: tensor([ 0.3555, -0.2662, -0.0529], device='cuda:1')
Index force: tensor([0.5634, 0.5808], device='cuda:1')
tensor([ 0.0144,  0.4962,  0.9243,  1.1612,  0.1336,  0.7157,  1.0322,  1.2707,
         1.2438,  0.2101,  0.3696,  0.7628,  0.3652, -0.3066,  0.1365,  3.7692],
       device='cuda:1')
Solve time for step 4 1.8546572779887356
Current ori: tensor([ 0.3652, -0.3066,  0.1365], device='cuda:1')
Index force: tensor([0.5761], device='cuda:1')
Storing RECOVERY transition: reward=-0.4201 (scaled=-0.4201), steps=1
Reward stats updated: mean -0.0056 -> -0.0068, std: 0.1485
Collected 353 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0153, Q2 Loss=1.0153, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4611
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9944, Q2 Loss=0.9944, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8507
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.9273, Q2 Loss=0.9273, Entropy=0.3035, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5913
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0617, Q2 Loss=1.0617, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4007
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2322, Q2 Loss=1.2322, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3578

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000021
Q1 loss: 1.046183
Q2 loss: 1.046183
Current threshold: -23.9995
Global Scale Offset: 0.0589
Reward stats: mean=-0.0068, std=0.1485, count=353
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0462, Q2 Loss: 1.0462, Entropy: 0.0607, Mean TD Error: 0.7323, Threshold: -23.9995
Original likelihood: -148.6727294921875
Adjusted likelihood: -148.6727294921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 133.22952270507812
Projection step: 1, Loss: 134.24998474121094
Projection step: 2, Loss: 130.02587890625
Projection step: 3, Loss: 125.76982116699219
Projection step: 4, Loss: 136.42825317382812
Projection step: 5, Loss: 131.80026245117188
Projection step: 6, Loss: 137.55947875976562
Projection step: 7, Loss: 134.20407104492188
Projection step: 8, Loss: 119.3623275756836
Projection step: 9, Loss: 135.55239868164062
Projection step: 10, Loss: 124.96613311767578
Projection step: 11, Loss: 137.67196655273438
Projection step: 12, Loss: 138.06068420410156
Projection step: 13, Loss: 136.0937957763672
Projection step: 14, Loss: 135.52615356445312
Final likelihood: tensor([-117.8604, -121.9550, -148.5768, -144.8653, -141.8911, -142.2204,
        -179.6746,  -90.1811, -141.2473, -175.8399,  -92.1024, -128.4309,
        -143.0210, -115.3173, -115.0321, -181.5368])
Final projection likelihood: -136.2345
1 mode projection failed, trying anyway
New goal: tensor([ 0.0756,  0.5374,  0.8580,  1.0976,  0.1813,  0.7955,  1.0583,  1.3912,
         1.2397,  0.1807,  0.4523,  0.7876,  0.3528, -0.2621, -0.2068],
       device='cuda:1')
tensor([[0.0035]], device='cuda:1') tensor([[0.0040]], device='cuda:1') tensor([[0.0044]], device='cuda:1')
Original likelihood: -145.43603515625
Adjusted likelihood: -145.43603515625
Likelihood residual: 0.0
Original likelihood: -215.38453674316406
Adjusted likelihood: -215.38453674316406
Likelihood residual: 0.0
{'index': 215.38453674316406, 'thumb_middle': 145.43603515625}
Current yaw: tensor([ 0.3550, -0.2620, -0.1056], device='cuda:1')
14 thumb_middle
tensor([ 0.0282,  0.5451,  0.9502,  1.1586,  0.2149,  0.8445,  1.0786,  1.2613,
         1.2584,  0.1656,  0.5334,  0.7557,  0.3550, -0.2620, -0.1056,  5.7651],
       device='cuda:1')
Solve time for step 1 9.234315715002595
Current ori: tensor([ 0.3550, -0.2620, -0.1056], device='cuda:1')
Index force: tensor([0.5987, 0.5999, 0.5981, 0.5951], device='cuda:1')
tensor([-0.0218,  0.5450,  0.8884,  1.1144,  0.1460,  0.7731,  1.0075,  1.3306,
         1.1561,  0.2183,  0.3927,  0.7862,  0.3757, -0.3380,  0.0991,  4.6644],
       device='cuda:1')
Solve time for step 2 1.9299836859863717
Current ori: tensor([ 0.3757, -0.3380,  0.0991], device='cuda:1')
Index force: tensor([0.5938, 0.5927, 0.5897], device='cuda:1')
tensor([-0.0604,  0.5593,  0.8837,  1.1061,  0.1304,  0.7880,  1.0302,  1.3600,
         1.1459,  0.2244,  0.3448,  0.7844,  0.3804, -0.3495,  0.1445,  3.3784],
       device='cuda:1')
Solve time for step 3 1.8727491530007683
Current ori: tensor([ 0.3804, -0.3495,  0.1445], device='cuda:1')
Index force: tensor([0.5890, 0.5929], device='cuda:1')
tensor([-0.0830,  0.5986,  0.8727,  1.1029,  0.1039,  0.8064,  1.0480,  1.3726,
         1.1478,  0.2177,  0.3424,  0.7887,  0.3801, -0.3488,  0.1420,  4.0967],
       device='cuda:1')
Solve time for step 4 1.841653010022128
Current ori: tensor([ 0.3801, -0.3488,  0.1420], device='cuda:1')
Index force: tensor([0.5715], device='cuda:1')
Storing RECOVERY transition: reward=-0.5350 (scaled=-0.5350), steps=1
Reward stats updated: mean -0.0068 -> -0.0082, std: 0.1509
Collected 354 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=1.1436, Q2 Loss=1.1436, Entropy=0.2802, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0167
SAC Update 2/5: Actor Loss=-0.0230, Q1 Loss=0.8228, Q2 Loss=0.8228, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2806
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9363, Q2 Loss=0.9363, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0457
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0368, Q2 Loss=1.0368, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4219
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8188, Q2 Loss=0.8188, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7607

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004662
Q1 loss: 0.951674
Q2 loss: 0.951674
Current threshold: -23.9920
Global Scale Offset: 0.0588
Reward stats: mean=-0.0082, std=0.1509, count=354
----------------------------------------------
SAC Update - Actor Loss: -0.0047, Q1 Loss: 0.9517, Q2 Loss: 0.9517, Entropy: 0.0560, Mean TD Error: 1.3051, Threshold: -23.9920
Original likelihood: -237.739990234375
Adjusted likelihood: -237.739990234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 257.3895263671875
Projection step: 1, Loss: 272.941650390625
Projection step: 2, Loss: 235.78305053710938
Projection step: 3, Loss: 254.4341278076172
Projection step: 4, Loss: 253.76431274414062
Projection step: 5, Loss: 247.43307495117188
Projection step: 6, Loss: 246.8016357421875
Projection step: 7, Loss: 249.40386962890625
Projection step: 8, Loss: 253.89389038085938
Projection step: 9, Loss: 246.22215270996094
Projection step: 10, Loss: 248.16790771484375
Projection step: 11, Loss: 265.9898376464844
Projection step: 12, Loss: 275.7373962402344
Projection step: 13, Loss: 263.06402587890625
Projection step: 14, Loss: 257.4798583984375
Final likelihood: tensor([-219.6464, -252.9270, -284.9881, -259.1054, -213.6869, -219.0477,
        -314.6087, -243.9542, -234.7776, -272.4652, -254.2992, -296.4698,
        -273.7733, -317.8293, -296.9081, -293.0389])
Final projection likelihood: -265.4704
1 mode projection failed, trying anyway
New goal: tensor([-0.0558,  0.6690,  0.9322,  1.1157,  0.1005,  0.8727,  1.1024,  1.4101,
         1.1857,  0.1687,  0.3974,  0.7916,  0.3657, -0.3129,  0.1017],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0069]], device='cuda:1') tensor([[0.0045]], device='cuda:1')
Original likelihood: -252.04644775390625
Adjusted likelihood: -252.04644775390625
Likelihood residual: 0.0
Original likelihood: -270.14801025390625
Adjusted likelihood: -270.14801025390625
Likelihood residual: 0.0
{'index': 270.14801025390625, 'thumb_middle': 252.04644775390625}
Current yaw: tensor([ 0.3658, -0.3111,  0.0061], device='cuda:1')
15 thumb_middle
tensor([-0.0750,  0.6698,  0.9177,  1.1137,  0.1032,  0.8742,  1.1112,  1.3899,
         1.2095,  0.1569,  0.4037,  0.7791,  0.3658, -0.3111,  0.0061,  4.8337],
       device='cuda:1')
Solve time for step 1 9.171203900012188
Current ori: tensor([ 0.3658, -0.3111,  0.0061], device='cuda:1')
Index force: tensor([0.5877, 0.5869, 0.5852, 0.5983], device='cuda:1')
tensor([-0.1273,  0.6903,  0.9237,  1.1134,  0.0459,  0.8395,  1.0644,  1.3902,
         1.1412,  0.2047,  0.2987,  0.7957,  0.3832, -0.3559,  0.1759,  4.0938],
       device='cuda:1')
Solve time for step 2 1.964553183002863
Current ori: tensor([ 0.3832, -0.3559,  0.1759], device='cuda:1')
Index force: tensor([0.5839, 0.5818, 0.5944], device='cuda:1')
tensor([-0.1552,  0.7032,  0.9242,  1.1079,  0.0204,  0.8464,  1.0770,  1.3964,
         1.1351,  0.2113,  0.2931,  0.7995,  0.3843, -0.3593,  0.1954,  3.8188],
       device='cuda:1')
Solve time for step 3 1.88104673899943
Current ori: tensor([ 0.3843, -0.3593,  0.1954], device='cuda:1')
Index force: tensor([0.5389, 0.5604], device='cuda:1')
tensor([-0.1578,  0.7110,  0.9303,  1.1047,  0.0154,  0.8512,  1.0922,  1.3852,
         1.1492,  0.1579,  0.2714,  0.8091,  0.3821, -0.3535,  0.1780,  4.2653],
       device='cuda:1')
Solve time for step 4 1.8139432140160352
Current ori: tensor([ 0.3821, -0.3535,  0.1780], device='cuda:1')
Index force: tensor([0.5709], device='cuda:1')
Storing RECOVERY transition: reward=-0.5644 (scaled=-0.5644), steps=1
Reward stats updated: mean -0.0082 -> -0.0098, std: 0.1535
Collected 355 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.7173, Q2 Loss=1.7173, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.1861
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7814, Q2 Loss=0.7814, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4032
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.1904, Q2 Loss=1.1904, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2715
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.3225, Q2 Loss=1.3225, Entropy=0.0002, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0822
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.2316, Q2 Loss=1.2316, Entropy=0.1924, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0194

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000028
Q1 loss: 1.248659
Q2 loss: 1.248659
Current threshold: -23.9871
Global Scale Offset: 0.0588
Reward stats: mean=-0.0098, std=0.1535, count=355
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.2487, Q2 Loss: 1.2487, Entropy: 0.0385, Mean TD Error: 2.5925, Threshold: -23.9871
Original likelihood: -271.4390563964844
Adjusted likelihood: -271.4390563964844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 281.66741943359375
Projection step: 1, Loss: 264.8883056640625
Projection step: 2, Loss: 275.35693359375
Projection step: 3, Loss: 279.86444091796875
Projection step: 4, Loss: 262.6944885253906
Projection step: 5, Loss: 271.0213623046875
Projection step: 6, Loss: 280.2716064453125
Projection step: 7, Loss: 253.58154296875
Projection step: 8, Loss: 275.3980712890625
Projection step: 9, Loss: 259.9259033203125
Projection step: 10, Loss: 256.16552734375
Projection step: 11, Loss: 268.4964599609375
Projection step: 12, Loss: 267.0557861328125
Projection step: 13, Loss: 281.96490478515625
Projection step: 14, Loss: 277.499267578125
Final likelihood: tensor([-346.5813, -258.4915, -258.5466, -260.6759, -224.8391, -251.7784,
        -286.9397, -207.2658, -232.0590, -324.3516, -237.7332, -282.6500,
        -272.8188, -294.1945, -289.0623, -274.2431])
Final projection likelihood: -268.8894
1 mode projection failed, trying anyway
New goal: tensor([-0.1297,  0.7829,  0.9694,  1.1176,  0.0201,  0.9322,  1.1434,  1.4148,
         1.1758,  0.1295,  0.3649,  0.8083,  0.3688, -0.3221,  0.1185],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0051]], device='cuda:1') tensor([[0.0046]], device='cuda:1')
Original likelihood: -157.3837432861328
Adjusted likelihood: -157.3837432861328
Likelihood residual: 0.0
Original likelihood: -266.0261535644531
Adjusted likelihood: -266.0261535644531
Likelihood residual: 0.0
{'index': 266.0261535644531, 'thumb_middle': 157.3837432861328}
Current yaw: tensor([ 0.3691, -0.3205,  0.0354], device='cuda:1')
16 thumb_middle
tensor([-0.1440,  0.7857,  0.9569,  1.1134,  0.0201,  0.9319,  1.1507,  1.4002,
         1.1974,  0.1207,  0.3701,  0.8002,  0.3691, -0.3205,  0.0354,  4.4358],
       device='cuda:1')
Solve time for step 1 9.219429429998854
Current ori: tensor([ 0.3691, -0.3205,  0.0354], device='cuda:1')
Index force: tensor([0.5827, 0.5533, 0.5626, 0.5534], device='cuda:1')
tensor([-0.1920,  0.7943,  0.9769,  1.1074, -0.0452,  0.8678,  1.0920,  1.3746,
         1.0896,  0.1771,  0.2892,  0.8186,  0.3890, -0.3714,  0.2018,  4.0133],
       device='cuda:1')
Solve time for step 2 1.9764559550094418
Current ori: tensor([ 0.3890, -0.3714,  0.2018], device='cuda:1')
Index force: tensor([0.5508, 0.5589, 0.5494], device='cuda:1')
tensor([-0.2158,  0.8293,  0.9638,  1.1189, -0.0716,  0.8944,  1.1006,  1.4007,
         1.0993,  0.1407,  0.2695,  0.8238,  0.3876, -0.3681,  0.1879,  4.0466],
       device='cuda:1')
Solve time for step 3 1.984526925982209
Current ori: tensor([ 0.3876, -0.3681,  0.1879], device='cuda:1')
Index force: tensor([0.5929, 0.5913], device='cuda:1')
tensor([-0.2406,  0.8372,  0.9574,  1.1101, -0.0987,  0.8919,  1.1130,  1.4042,
         1.1020,  0.1305,  0.2730,  0.8184,  0.3869, -0.3663,  0.1811,  4.2049],
       device='cuda:1')
Solve time for step 4 1.8075765140238218
Current ori: tensor([ 0.3869, -0.3663,  0.1811], device='cuda:1')
Index force: tensor([0.5934], device='cuda:1')
Storing RECOVERY transition: reward=-0.5681 (scaled=-0.5681), steps=1
Reward stats updated: mean -0.0098 -> -0.0114, std: 0.1561
Collected 356 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.4484, Q2 Loss=1.4484, Entropy=0.2006, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0681
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7599, Q2 Loss=0.7599, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.0850
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=1.2941, Q2 Loss=1.2941, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.9933
SAC Update 4/5: Actor Loss=-0.0156, Q1 Loss=1.1956, Q2 Loss=1.1956, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4813
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.5725, Q2 Loss=1.5725, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0828

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (13.9%)
Q1 update: 0.06s (21.3%)
Q2 update: 0.06s (20.1%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007757
Q1 loss: 1.254093
Q2 loss: 1.254093
Current threshold: -23.9802
Global Scale Offset: 0.0588
Reward stats: mean=-0.0114, std=0.1561, count=356
----------------------------------------------
SAC Update - Actor Loss: -0.0078, Q1 Loss: 1.2541, Q2 Loss: 1.2541, Entropy: 0.0401, Mean TD Error: 2.5421, Threshold: -23.9802
Original likelihood: -280.1983642578125
Adjusted likelihood: -280.1983642578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 272.47430419921875
Projection step: 1, Loss: 287.068359375
Projection step: 2, Loss: 286.780517578125
Projection step: 3, Loss: 300.0965881347656
Projection step: 4, Loss: 291.77703857421875
Projection step: 5, Loss: 280.79266357421875
Projection step: 6, Loss: 310.8447265625
Projection step: 7, Loss: 300.0436096191406
Projection step: 8, Loss: 295.2024841308594
Projection step: 9, Loss: 285.6230163574219
Projection step: 10, Loss: 294.7047119140625
Projection step: 11, Loss: 288.1705322265625
Projection step: 12, Loss: 303.7569580078125
Projection step: 13, Loss: 304.78759765625
Projection step: 14, Loss: 270.69573974609375
Final likelihood: tensor([-352.0504, -292.0742, -230.7298, -290.7412, -267.9257, -288.6328,
        -311.9030, -258.2678, -283.8344, -275.2773, -246.9818, -295.7314,
        -316.6767, -283.5629, -275.1730, -301.4463])
Final projection likelihood: -285.6880
1 mode projection failed, trying anyway
New goal: tensor([-0.2260,  0.9086,  1.0238,  1.1290, -0.0946,  0.9817,  1.1658,  1.4220,
         1.1530,  0.0929,  0.3534,  0.8165,  0.3726, -0.3312,  0.1048],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0052]], device='cuda:1') tensor([[0.0049]], device='cuda:1')
Original likelihood: -223.01431274414062
Adjusted likelihood: -223.01431274414062
Likelihood residual: 0.0
Original likelihood: -243.90216064453125
Adjusted likelihood: -243.90216064453125
Likelihood residual: 0.0
{'index': 243.90216064453125, 'thumb_middle': 223.01431274414062}
Current yaw: tensor([ 0.3727, -0.3298,  0.0343], device='cuda:1')
17 thumb_middle
tensor([-0.2368,  0.9102,  1.0124,  1.1246, -0.0957,  0.9811,  1.1748,  1.4109,
         1.1727,  0.0847,  0.3584,  0.8113,  0.3727, -0.3298,  0.0343,  4.2967],
       device='cuda:1')
Solve time for step 1 9.323638950008899
Current ori: tensor([ 0.3727, -0.3298,  0.0343], device='cuda:1')
Index force: tensor([0.6032, 0.5724, 0.5661, 0.5925], device='cuda:1')
tensor([-0.2923,  0.9577,  1.0495,  1.1394, -0.1755,  0.8868,  1.1036,  1.4268,
         1.1251,  0.1054,  0.2362,  0.8327,  0.3842, -0.3614,  0.1397,  4.1440],
       device='cuda:1')
Solve time for step 2 1.9489033140125684
Current ori: tensor([ 0.3842, -0.3614,  0.1397], device='cuda:1')
Index force: tensor([0.5706, 0.5623, 0.5887], device='cuda:1')
tensor([-0.3030,  1.0179,  1.0220,  1.0770, -0.1878,  0.9020,  1.1090,  1.4201,
         1.1230,  0.1137,  0.2331,  0.8185,  0.3850, -0.3628,  0.1353,  4.1674],
       device='cuda:1')
Solve time for step 3 1.8717521199723706
Current ori: tensor([ 0.3850, -0.3628,  0.1353], device='cuda:1')
Index force: tensor([0.5818, 0.5707], device='cuda:1')
tensor([-0.3103,  1.0498,  1.0145,  1.0505, -0.1989,  0.9309,  1.0984,  1.4104,
         1.0935,  0.1287,  0.2473,  0.8193,  0.3882, -0.3711,  0.1512,  4.1683],
       device='cuda:1')
Solve time for step 4 1.8531021950184368
Current ori: tensor([ 0.3882, -0.3711,  0.1512], device='cuda:1')
Index force: tensor([0.5777], device='cuda:1')
Storing RECOVERY transition: reward=-0.6427 (scaled=-0.6427), steps=1
Reward stats updated: mean -0.0114 -> -0.0132, std: 0.1594
Collected 357 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=1.0184, Q2 Loss=1.0184, Entropy=0.0590, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3584
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8393, Q2 Loss=0.8393, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.1029
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7583, Q2 Loss=0.7583, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3563
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8929, Q2 Loss=0.8929, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.8457
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7586, Q2 Loss=0.7586, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4182

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (18.7%)
Q2 update: 0.05s (18.9%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001455
Q1 loss: 0.853491
Q2 loss: 0.853491
Current threshold: -23.9462
Global Scale Offset: 0.0582
Reward stats: mean=-0.0132, std=0.1594, count=357
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 0.8535, Q2 Loss: 0.8535, Entropy: 0.0118, Mean TD Error: 1.6163, Threshold: -23.9462
Original likelihood: -311.12445068359375
Adjusted likelihood: -311.12445068359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 22
Loaded trajectory sampler
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
1 turn
Sampling time 3.84400593402097
tensor([ 1.2021e-01,  6.3065e-01,  5.0436e-01,  6.1625e-01, -1.0511e-01,
         5.1590e-01,  9.3987e-01,  8.4962e-01,  1.2304e+00,  3.0232e-01,
         2.3992e-01,  1.1856e+00,  5.8629e-04,  1.4505e-02, -4.4825e-02,
         4.1213e-02], device='cuda:1')
Original likelihood: -14.149606704711914
Adjusted likelihood: -14.149606704711914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.1013521309942
Current ori: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:1')
Middle force: tensor([1.3022, 0.5025, 0.5124, 0.5353, 0.5272, 1.2480, 0.8862, 0.4957, 0.5420,
        0.6231, 0.7518, 0.6216], device='cuda:1')
Thumb force: tensor([1.1291, 0.5082, 1.1664, 0.5448, 1.5103, 0.9035, 0.8650, 0.8468, 0.8948,
        0.5537, 0.5675, 0.5568], device='cuda:1')
Index force: tensor([0.5023, 0.6985, 0.5402, 0.6677, 0.8511, 1.1078, 0.6259, 0.6857, 0.5609,
        0.5650, 0.5320, 0.6388], device='cuda:1')
Storing NORMAL transition: reward=0.1560 (scaled=0.1560), steps=1
Reward stats updated: mean -0.0132 -> -0.0127, std: 0.1595
Collected 358 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=1.5893, Q2 Loss=1.5893, Entropy=0.0002, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.5943
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9931, Q2 Loss=0.9931, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.1188
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=1.1431, Q2 Loss=1.1431, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.8492
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2372, Q2 Loss=1.2372, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1382
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.1335, Q2 Loss=1.1335, Entropy=0.0001, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4265

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.9%)
Actor update: 0.10s (40.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009210
Q1 loss: 1.219243
Q2 loss: 1.219243
Current threshold: -23.9261
Global Scale Offset: 0.0578
Reward stats: mean=-0.0127, std=0.1595, count=358
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.2192, Q2 Loss: 1.2192, Entropy: 0.0001, Mean TD Error: 1.4254, Threshold: -23.9261
tensor([ 0.1035,  0.6681,  0.4652,  0.5472, -0.1073,  0.2915,  1.1123,  1.0003,
         1.3176,  0.3782,  0.2561,  0.9680, -0.0083,  0.0389, -0.2027,  0.1782],
       device='cuda:1')
Original likelihood: -29.840744018554688
Adjusted likelihood: -29.840744018554688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 30.552207946777344
Projection step: 1, Loss: 26.250324249267578
Projection step: 2, Loss: 22.53948402404785
Projection step: 3, Loss: 19.14089584350586
Projection step: 4, Loss: 17.127336502075195
Projection step: 5, Loss: 16.503231048583984
Projection step: 6, Loss: 14.380109786987305
Final likelihood: tensor([-11.9163, -14.2485, -14.8394, -18.3825, -14.5231, -11.9853, -17.4506,
        -12.9246, -18.5160, -11.3990, -19.1074, -15.3524, -15.6256, -11.5591,
        -10.4832, -11.7686])
Final projection likelihood: -14.3801
1 mode projection succeeded
New goal: tensor([ 0.0621,  0.6355,  0.4664,  0.5585, -0.0989,  0.3827,  0.9078,  0.9431,
         1.2878,  0.3165,  0.1676,  1.1241, -0.0148,  0.0269, -1.2310],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -23.407634735107422
Adjusted likelihood: -23.407634735107422
Likelihood residual: 0.0
Original likelihood: -20.088573455810547
Adjusted likelihood: -20.088573455810547
Likelihood residual: 0.0
{'index': 20.088573455810547, 'thumb_middle': 23.407634735107422}
Current yaw: tensor([-0.0083,  0.0389, -0.2027], device='cuda:1')
2 index
tensor([ 0.1035,  0.6681,  0.4652,  0.5472, -0.1073,  0.2915,  1.1123,  1.0003,
         1.3176,  0.3782,  0.2561,  0.9680, -0.0083,  0.0389, -0.2027,  0.1782],
       device='cuda:1')
Solve time for step 1 10.994487820949871
Current ori: tensor([-0.0083,  0.0389, -0.2027], device='cuda:1')
Middle force: tensor([0.5475, 0.5270, 0.5589, 0.5579], device='cuda:1')
Thumb force: tensor([0.6142, 0.6402, 0.5483, 0.5360], device='cuda:1')
tensor([ 0.1225,  0.5839,  0.4129,  0.5328, -0.0647,  0.3577,  1.0421,  1.0376,
         1.3478,  0.3159,  0.1724,  1.0189, -0.0198,  0.0133, -0.1961,  1.4469],
       device='cuda:1')
Solve time for step 2 2.369660236989148
Current ori: tensor([-0.0198,  0.0133, -0.1961], device='cuda:1')
Middle force: tensor([0.5247, 0.5565, 0.5560], device='cuda:1')
Thumb force: tensor([0.6374, 0.5473, 0.5356], device='cuda:1')
tensor([ 0.1257,  0.5910,  0.4188,  0.5332, -0.0550,  0.3691,  1.0314,  1.0481,
         1.3462,  0.3126,  0.1582,  1.0331, -0.0203,  0.0069, -0.1939,  2.2355],
       device='cuda:1')
Solve time for step 3 2.2991660239640623
Current ori: tensor([-0.0203,  0.0069, -0.1939], device='cuda:1')
Middle force: tensor([0.5084, 0.5413], device='cuda:1')
Thumb force: tensor([0.5783, 0.6128], device='cuda:1')
tensor([ 0.1246,  0.5929,  0.4182,  0.5344, -0.0470,  0.3970,  1.0104,  1.0234,
         1.3539,  0.3172,  0.1478,  1.0072, -0.0364,  0.0044, -0.2190,  2.6838],
       device='cuda:1')
Solve time for step 4 2.173505519051105
Current ori: tensor([-0.0364,  0.0044, -0.2190], device='cuda:1')
Middle force: tensor([0.5402], device='cuda:1')
Thumb force: tensor([0.6044], device='cuda:1')
Storing RECOVERY transition: reward=0.0276 (scaled=0.0276), steps=1
Reward stats updated: mean -0.0127 -> -0.0126, std: 0.1593
Collected 359 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3741, Q2 Loss=1.3741, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7259
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.1683, Q2 Loss=1.1683, Entropy=0.0849, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6480
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2752, Q2 Loss=1.2752, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0280
SAC Update 4/5: Actor Loss=-0.0236, Q1 Loss=1.5436, Q2 Loss=1.5436, Entropy=0.3430, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9139
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.8899, Q2 Loss=0.8899, Entropy=0.0006, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7173

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.8%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (18.6%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004721
Q1 loss: 1.250200
Q2 loss: 1.250200
Current threshold: -23.9106
Global Scale Offset: 0.0576
Reward stats: mean=-0.0126, std=0.1593, count=359
----------------------------------------------
SAC Update - Actor Loss: -0.0047, Q1 Loss: 1.2502, Q2 Loss: 1.2502, Entropy: 0.0857, Mean TD Error: 1.0066, Threshold: -23.9106
Original likelihood: -10.542924880981445
Adjusted likelihood: -10.542924880981445
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0441,  0.0038, -0.2311], device='cuda:1')
3 turn
Sampling time 3.7426223510410637
tensor([ 0.0752,  0.6496,  0.4566,  0.5518, -0.0441,  0.4106,  1.0004,  1.0081,
         1.3822,  0.2811,  0.1212,  1.0062, -0.0441,  0.0038, -0.2311,  2.7446],
       device='cuda:1')
Original likelihood: -10.46638011932373
Adjusted likelihood: -10.46638011932373
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.348286774998996
Current ori: tensor([-0.0441,  0.0038, -0.2311], device='cuda:1')
Middle force: tensor([0.9783, 0.6021, 0.7314, 0.6703, 0.9486, 0.5635, 1.0190, 1.8070, 0.5209,
        0.5586, 0.5445, 0.5213], device='cuda:1')
Thumb force: tensor([0.7127, 1.0127, 0.5264, 1.1884, 0.5382, 0.7288, 0.6002, 0.9545, 0.5576,
        1.1859, 1.0383, 0.8086], device='cuda:1')
Index force: tensor([1.1089, 0.5265, 0.9264, 0.8115, 0.7060, 0.6130, 0.5170, 1.1871, 0.6155,
        0.5837, 0.5270, 0.5360], device='cuda:1')
Storing NORMAL transition: reward=0.0937 (scaled=0.0937), steps=1
Reward stats updated: mean -0.0126 -> -0.0123, std: 0.1591
Collected 360 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8994, Q2 Loss=0.8994, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1396
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7262, Q2 Loss=0.7262, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6233
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2422, Q2 Loss=1.2422, Entropy=0.0345, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8973
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.3163, Q2 Loss=1.3163, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9608
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8950, Q2 Loss=0.8950, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7557

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (40.9%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000002
Q1 loss: 1.015826
Q2 loss: 1.015826
Current threshold: -23.8979
Global Scale Offset: 0.0575
Reward stats: mean=-0.0123, std=0.1591, count=360
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0158, Q2 Loss: 1.0158, Entropy: 0.0069, Mean TD Error: 1.6753, Threshold: -23.8979
tensor([ 0.1402,  0.5768,  0.4347,  0.4486, -0.0771,  0.3787,  1.0953,  1.0692,
         1.4572,  0.2475,  0.0296,  1.0351, -0.0523,  0.0119, -0.3263,  2.4328],
       device='cuda:1')
Original likelihood: -21.56464385986328
Adjusted likelihood: -21.56464385986328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.0208305299747735
Current ori: tensor([-0.0523,  0.0119, -0.3263], device='cuda:1')
Middle force: tensor([0.6178, 0.7671, 0.6775, 0.9788, 0.5834, 1.0351, 0.6815, 0.5003, 0.5627,
        0.6587, 0.5798], device='cuda:1')
Thumb force: tensor([1.0050, 0.5315, 1.2269, 0.5386, 0.7373, 0.5863, 0.5621, 0.5137, 0.5592,
        1.4864, 1.0775], device='cuda:1')
Index force: tensor([0.5266, 0.9104, 0.8074, 0.6955, 0.6127, 0.5041, 0.5446, 0.5671, 0.5954,
        0.6086, 0.6088], device='cuda:1')
Storing NORMAL transition: reward=0.1083 (scaled=0.1083), steps=1
Reward stats updated: mean -0.0123 -> -0.0119, std: 0.1590
Collected 361 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8997, Q2 Loss=0.8997, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3640
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.2287, Q2 Loss=1.2287, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3006
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.3500, Q2 Loss=1.3500, Entropy=0.0001, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.4274
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.6603, Q2 Loss=1.6603, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.5082
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=3.9154, Q2 Loss=3.9154, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.6577

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (17.8%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (41.8%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.810807
Q2 loss: 1.810807
Current threshold: -23.8903
Global Scale Offset: 0.0575
Reward stats: mean=-0.0119, std=0.1590, count=361
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.8108, Q2 Loss: 1.8108, Entropy: 0.0000, Mean TD Error: 2.4516, Threshold: -23.8903
tensor([ 0.0903,  0.6146,  0.5235,  0.5397, -0.0537,  0.3989,  1.0741,  1.1012,
         1.4756,  0.2245,  0.0468,  0.9395, -0.0650,  0.0042, -0.4379,  2.2349],
       device='cuda:1')
Original likelihood: -15.984514236450195
Adjusted likelihood: -15.984514236450195
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7267405120073818
Current ori: tensor([-0.0650,  0.0042, -0.4379], device='cuda:1')
Middle force: tensor([0.7711, 0.6831, 0.9868, 0.5857, 1.0309, 0.6803, 0.5003, 0.5644, 0.6603,
        0.5788], device='cuda:1')
Thumb force: tensor([0.5275, 1.2147, 0.5352, 0.7313, 0.5837, 0.5605, 0.5134, 0.5569, 1.4704,
        1.0701], device='cuda:1')
Index force: tensor([0.9121, 0.7942, 0.6909, 0.6102, 0.5040, 0.5433, 0.5655, 0.5920, 0.6065,
        0.6071], device='cuda:1')
Storing NORMAL transition: reward=0.0189 (scaled=0.0189), steps=1
Reward stats updated: mean -0.0119 -> -0.0119, std: 0.1588
Collected 362 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.9722, Q2 Loss=0.9722, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0884
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7949, Q2 Loss=0.7949, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3624
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=0.8103, Q2 Loss=0.8103, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6419
SAC Update 4/5: Actor Loss=-0.0169, Q1 Loss=1.3146, Q2 Loss=1.3146, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8357
SAC Update 5/5: Actor Loss=-0.0038, Q1 Loss=0.7356, Q2 Loss=0.7356, Entropy=0.0541, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3901

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (40.8%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008752
Q1 loss: 0.925514
Q2 loss: 0.925514
Current threshold: -23.8807
Global Scale Offset: 0.0574
Reward stats: mean=-0.0119, std=0.1588, count=362
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 0.9255, Q2 Loss: 0.9255, Entropy: 0.0108, Mean TD Error: 0.8637, Threshold: -23.8807
tensor([ 0.0945,  0.5264,  0.5903,  0.6771, -0.0847,  0.3304,  1.1091,  1.1812,
         1.4911,  0.2057,  0.0636,  0.9751, -0.0343,  0.0244, -0.4531,  2.1228],
       device='cuda:1')
Original likelihood: -23.142139434814453
Adjusted likelihood: -23.142139434814453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 4 2.538457872986328
Current ori: tensor([-0.0343,  0.0244, -0.4531], device='cuda:1')
Middle force: tensor([0.6720, 0.9740, 0.5809, 1.0223, 0.6719, 0.5003, 0.5580, 0.6572, 0.5772],
       device='cuda:1')
Thumb force: tensor([1.2086, 0.5365, 0.7319, 0.5829, 0.5619, 0.5132, 0.5602, 1.4603, 1.0635],
       device='cuda:1')
Index force: tensor([0.7948, 0.6876, 0.6095, 0.5040, 0.5428, 0.5648, 0.5919, 0.6043, 0.6058],
       device='cuda:1')
Storing NORMAL transition: reward=0.0188 (scaled=0.0188), steps=1
Reward stats updated: mean -0.0119 -> -0.0118, std: 0.1586
Collected 363 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1747, Q2 Loss=1.1747, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7839
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9003, Q2 Loss=0.9003, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4134
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7073, Q2 Loss=0.7073, Entropy=0.0015, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1586
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1424, Q2 Loss=1.1424, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.4334
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2297, Q2 Loss=1.2297, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4581

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.030867
Q2 loss: 1.030867
Current threshold: -23.8593
Global Scale Offset: 0.0571
Reward stats: mean=-0.0118, std=0.1586, count=363
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0309, Q2 Loss: 1.0309, Entropy: 0.0003, Mean TD Error: 0.6495, Threshold: -23.8593
tensor([ 0.0802,  0.5102,  0.5586,  0.7625, -0.0599,  0.3508,  1.0854,  1.2833,
         1.5000,  0.1673,  0.0451,  0.9898, -0.0221,  0.0075, -0.4699,  2.2683],
       device='cuda:1')
Original likelihood: -20.931655883789062
Adjusted likelihood: -20.931655883789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 2.5116905759787187
Current ori: tensor([-0.0221,  0.0075, -0.4699], device='cuda:1')
Middle force: tensor([0.9501, 0.5686, 0.9927, 1.7136, 0.5304, 0.5676, 0.5385, 0.5227],
       device='cuda:1')
Thumb force: tensor([0.5277, 0.7013, 0.5833, 0.9263, 0.5417, 1.1331, 1.0205, 0.7779],
       device='cuda:1')
Index force: tensor([0.6760, 0.5963, 0.5152, 1.1315, 0.5935, 0.5665, 0.5230, 0.5293],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0357 (scaled=-0.0357), steps=1
Reward stats updated: mean -0.0118 -> -0.0118, std: 0.1584
Collected 364 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=10.6037, Q2 Loss=10.6037, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9531
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0513, Q2 Loss=1.0513, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3046
SAC Update 3/5: Actor Loss=-0.0230, Q1 Loss=0.9109, Q2 Loss=0.9109, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5906
SAC Update 4/5: Actor Loss=-0.0230, Q1 Loss=1.5822, Q2 Loss=1.5822, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2257
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.9276, Q2 Loss=1.9276, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.0470

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (16.4%)
Q1 update: 0.05s (18.4%)
Q2 update: 0.05s (17.0%)
Actor update: 0.11s (37.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009210
Q1 loss: 3.215156
Q2 loss: 3.215156
Current threshold: -23.8466
Global Scale Offset: 0.0570
Reward stats: mean=-0.0118, std=0.1584, count=364
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 3.2152, Q2 Loss: 3.2152, Entropy: 0.0000, Mean TD Error: 1.8242, Threshold: -23.8466
tensor([ 0.0434,  0.3427,  0.6091,  0.8737, -0.1338,  0.3692,  1.2349,  1.2979,
         1.4613,  0.2132,  0.0833,  1.0260, -0.0076,  0.0181, -0.4339,  2.7977],
       device='cuda:1')
Original likelihood: -29.56675910949707
Adjusted likelihood: -29.56675910949707
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 28.516843795776367
Projection step: 1, Loss: 23.539939880371094
Projection step: 2, Loss: 21.596641540527344
Projection step: 3, Loss: 20.142120361328125
Projection step: 4, Loss: 22.375347137451172
Projection step: 5, Loss: 20.985729217529297
Projection step: 6, Loss: 19.420642852783203
Projection step: 7, Loss: 17.06219482421875
Projection step: 8, Loss: 16.262664794921875
Projection step: 9, Loss: 15.402490615844727
Projection step: 10, Loss: 14.893935203552246
Final likelihood: tensor([-15.9709, -15.2548, -15.2060, -15.1863, -16.3009, -10.6715, -14.4051,
        -14.6482, -11.7465, -14.9416, -15.1472, -21.6648, -14.6220, -13.5074,
        -12.9032, -16.1266])
Final projection likelihood: -14.8939
1 mode projection succeeded
New goal: tensor([ 0.0779,  0.4771,  0.5566,  0.7695, -0.0789,  0.4764,  0.9328,  1.0247,
         1.3669,  0.2155,  0.1827,  0.9041, -0.0025,  0.0109, -0.6522],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0071]], device='cuda:1')
Original likelihood: -25.608551025390625
Adjusted likelihood: -25.608551025390625
Likelihood residual: 0.0
{'index': 25.608551025390625, 'thumb_middle': inf}
Current yaw: tensor([-0.0076,  0.0181, -0.4339], device='cuda:1')
4 index
tensor([ 0.0434,  0.3427,  0.6091,  0.8737, -0.1338,  0.3692,  1.2349,  1.2979,
         1.4613,  0.2132,  0.0833,  1.0260, -0.0076,  0.0181, -0.4339,  2.7977],
       device='cuda:1')
Solve time for step 1 10.506849969970062
Current ori: tensor([-0.0076,  0.0181, -0.4339], device='cuda:1')
Middle force: tensor([0.5615, 0.5280, 0.5986, 0.5307], device='cuda:1')
Thumb force: tensor([0.5579, 0.5472, 0.5653, 0.5110], device='cuda:1')
tensor([ 0.1020,  0.4127,  0.5220,  0.7632, -0.1234,  0.4326,  1.1622,  1.2341,
         1.4466,  0.2572,  0.1050,  0.9306, -0.0502,  0.0156, -0.4195,  2.8713],
       device='cuda:1')
Solve time for step 2 2.4353393770288676
Current ori: tensor([-0.0502,  0.0156, -0.4195], device='cuda:1')
Middle force: tensor([0.5266, 0.5959, 0.5293], device='cuda:1')
Thumb force: tensor([0.5450, 0.5634, 0.5104], device='cuda:1')
tensor([ 0.1065,  0.4413,  0.5132,  0.7449, -0.1122,  0.4661,  1.1313,  1.2099,
         1.4531,  0.2441,  0.0987,  0.8963, -0.0683,  0.0097, -0.4134,  2.7115],
       device='cuda:1')
Solve time for step 3 2.1299918020376936
Current ori: tensor([-0.0683,  0.0097, -0.4134], device='cuda:1')
Middle force: tensor([0.5134, 0.5639], device='cuda:1')
Thumb force: tensor([0.6648, 0.5347], device='cuda:1')
tensor([ 1.0897e-01,  4.5123e-01,  5.1302e-01,  7.4139e-01, -9.1769e-02,
         4.9413e-01,  1.1226e+00,  1.1923e+00,  1.4479e+00,  2.5144e-01,
         8.0995e-02,  8.9614e-01, -8.3959e-02,  1.6584e-03, -3.9917e-01,
         2.4285e+00], device='cuda:1')
Solve time for step 4 2.0593583390000276
Current ori: tensor([-0.0840,  0.0017, -0.3992], device='cuda:1')
Middle force: tensor([0.5679], device='cuda:1')
Thumb force: tensor([0.5894], device='cuda:1')
Storing RECOVERY transition: reward=-0.0328 (scaled=-0.0066), steps=5
Reward stats updated: mean -0.0118 -> -0.0118, std: 0.1582
Collected 365 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.8394, Q2 Loss=0.8394, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1430
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4585, Q2 Loss=1.4585, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7412
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=19.9690, Q2 Loss=19.9690, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=9.6899
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7858, Q2 Loss=0.7858, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3866
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9713, Q2 Loss=0.9713, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8024

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.5%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (20.2%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 4.804792
Q2 loss: 4.804792
Current threshold: -23.8391
Global Scale Offset: 0.0569
Reward stats: mean=-0.0118, std=0.1582, count=365
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 4.8048, Q2 Loss: 4.8048, Entropy: 0.0000, Mean TD Error: 2.3526, Threshold: -23.8391
Original likelihood: -24.440710067749023
Adjusted likelihood: -24.440710067749023
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0023)
State is out of distribution
Projection step: 0, Loss: 21.581575393676758
Projection step: 1, Loss: 21.222198486328125
Projection step: 2, Loss: 21.55867576599121
Projection step: 3, Loss: 19.769805908203125
Projection step: 4, Loss: 21.151901245117188
Projection step: 5, Loss: 19.776315689086914
Projection step: 6, Loss: 19.74212074279785
Projection step: 7, Loss: 20.381393432617188
Projection step: 8, Loss: 17.517559051513672
Projection step: 9, Loss: 18.66927146911621
Projection step: 10, Loss: 16.75364112854004
Projection step: 11, Loss: 16.56985092163086
Projection step: 12, Loss: 16.922657012939453
Projection step: 13, Loss: 15.953314781188965
Projection step: 14, Loss: 15.206486701965332
Final likelihood: tensor([-14.5872, -15.0646, -14.6103, -14.4374, -16.8760, -15.8822, -16.7016,
        -16.6476, -14.4504, -15.0615, -15.5987, -16.2552, -15.1665, -16.2013,
        -14.1629, -15.0118])
Final projection likelihood: -15.4197
1 mode projection succeeded
New goal: tensor([ 5.9400e-02,  4.9400e-01,  5.5423e-01,  7.0383e-01, -4.8780e-02,
         5.5459e-01,  7.9566e-01,  9.7154e-01,  1.4003e+00,  2.2772e-01,
         1.4897e-01,  8.4883e-01, -9.0345e-02,  2.3262e-04, -1.5637e-01],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -22.230274200439453
Adjusted likelihood: -22.230274200439453
Likelihood residual: 0.0
Original likelihood: -29.980003356933594
Adjusted likelihood: -29.980003356933594
Likelihood residual: 0.0
{'index': 29.980003356933594, 'thumb_middle': 22.230274200439453}
Current yaw: tensor([-0.1009, -0.0072, -0.4153], device='cuda:1')
5 thumb_middle
tensor([ 0.0655,  0.5076,  0.5455,  0.7608, -0.0686,  0.5215,  1.1155,  1.1675,
         1.4489,  0.2628,  0.0635,  0.8783, -0.1009, -0.0072, -0.4153,  2.8709],
       device='cuda:1')
Solve time for step 1 9.118221366021316
Current ori: tensor([-0.1009, -0.0072, -0.4153], device='cuda:1')
Index force: tensor([0.5830, 0.5906, 0.5892, 0.5526], device='cuda:1')
tensor([ 0.0514,  0.5121,  0.5523,  0.7201, -0.1517,  0.5259,  0.8308,  0.9951,
         1.3657,  0.2173,  0.0732,  0.8363, -0.1183,  0.0051, -0.4107,  2.6092],
       device='cuda:1')
Solve time for step 2 1.9594624650198966
Current ori: tensor([-0.1183,  0.0051, -0.4107], device='cuda:1')
Index force: tensor([0.5839, 0.5839, 0.5498], device='cuda:1')
tensor([ 0.0310,  0.5228,  0.5614,  0.7197, -0.1610,  0.5528,  0.7892,  0.9681,
         1.3774,  0.2156,  0.0786,  0.8264, -0.1513,  0.0190, -0.4107,  2.3098],
       device='cuda:1')
Solve time for step 3 1.8564393279957585
Current ori: tensor([-0.1513,  0.0190, -0.4107], device='cuda:1')
Index force: tensor([0.5785, 0.5462], device='cuda:1')
tensor([ 0.0166,  0.5700,  0.5966,  0.7311, -0.1566,  0.5704,  0.7794,  0.9553,
         1.3794,  0.2083,  0.0768,  0.8276, -0.3715,  0.0360, -0.4107, -0.9986],
       device='cuda:1')
Solve time for step 4 1.8751898090122268
Current ori: tensor([-0.3715,  0.0360, -0.4107], device='cuda:1')
Index force: tensor([0.5508], device='cuda:1')
Storing RECOVERY transition: reward=-0.6379 (scaled=-0.1276), steps=5
Reward stats updated: mean -0.0118 -> -0.0121, std: 0.1581
Collected 366 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7938, Q2 Loss=0.7938, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3476
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4665, Q2 Loss=1.4665, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2722
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1600, Q2 Loss=1.1600, Entropy=0.0275, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7148
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9775, Q2 Loss=0.9775, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1070
SAC Update 5/5: Actor Loss=-0.0133, Q1 Loss=1.1312, Q2 Loss=1.1312, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4753

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (17.9%)
Actor update: 0.11s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002661
Q1 loss: 1.105775
Q2 loss: 1.105775
Current threshold: -23.8345
Global Scale Offset: 0.0568
Reward stats: mean=-0.0121, std=0.1581, count=366
----------------------------------------------
SAC Update - Actor Loss: -0.0027, Q1 Loss: 1.1058, Q2 Loss: 1.1058, Entropy: 0.0055, Mean TD Error: 0.7834, Threshold: -23.8345
Original likelihood: -618.2109985351562
Adjusted likelihood: -618.2109985351562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 23
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0285], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0285], device='cuda:1')
1 turn
Sampling time 3.877762109041214
tensor([ 0.1256,  0.6316,  0.5428,  0.5491, -0.1114,  0.5081,  0.9272,  0.9210,
         1.2231,  0.2728,  0.2581,  1.1961, -0.0019,  0.0146, -0.0285,  0.2672],
       device='cuda:1')
Original likelihood: -18.53878402709961
Adjusted likelihood: -18.53878402709961
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.591069245012477
Current ori: tensor([-0.0019,  0.0146, -0.0285], device='cuda:1')
Middle force: tensor([0.7907, 0.5097, 0.5485, 0.8911, 0.9352, 0.9325, 0.8696, 0.7806, 0.5902,
        1.0274, 0.5749, 0.5419], device='cuda:1')
Thumb force: tensor([0.8001, 3.3694, 1.3559, 0.5941, 0.6958, 0.9024, 0.8442, 0.7432, 0.5298,
        0.7340, 0.9771, 0.6083], device='cuda:1')
Index force: tensor([0.7343, 0.5286, 0.5452, 0.8138, 0.5580, 0.5593, 0.5613, 0.5423, 0.5765,
        0.5350, 0.5839, 0.7253], device='cuda:1')
Storing NORMAL transition: reward=0.0011 (scaled=0.0011), steps=1
Reward stats updated: mean -0.0121 -> -0.0121, std: 0.1579
Collected 367 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1073, Q2 Loss=1.1073, Entropy=0.0000, Time=0.07sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.9719
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.3613, Q2 Loss=1.3613, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7743
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7556, Q2 Loss=0.7556, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5180
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.1122, Q2 Loss=1.1122, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.5443
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.0878, Q2 Loss=1.0878, Entropy=0.3189, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4388

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (20.8%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000043
Q1 loss: 1.084870
Q2 loss: 1.084870
Current threshold: -23.8311
Global Scale Offset: 0.0568
Reward stats: mean=-0.0121, std=0.1579, count=367
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0849, Q2 Loss: 1.0849, Entropy: 0.0638, Mean TD Error: 1.0495, Threshold: -23.8311
tensor([ 0.1971,  0.6037,  0.6087,  0.6425, -0.3031,  0.4640,  1.0507,  0.9717,
         1.2387,  0.3229,  0.1668,  1.1092,  0.0121, -0.0223, -0.0300,  0.3968],
       device='cuda:1')
Original likelihood: -49.71904754638672
Adjusted likelihood: -49.71904754638672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 50.720149993896484
Projection step: 1, Loss: 46.60677719116211
Projection step: 2, Loss: 43.734039306640625
Projection step: 3, Loss: 39.66712951660156
Projection step: 4, Loss: 37.12672424316406
Projection step: 5, Loss: 33.59560012817383
Projection step: 6, Loss: 28.89274787902832
Projection step: 7, Loss: 26.245567321777344
Projection step: 8, Loss: 22.788555145263672
Projection step: 9, Loss: 22.26771354675293
Projection step: 10, Loss: 19.58266830444336
Projection step: 11, Loss: 18.918418884277344
Projection step: 12, Loss: 17.438274383544922
Projection step: 13, Loss: 16.90365982055664
Projection step: 14, Loss: 15.448719024658203
Final likelihood: tensor([-13.5306, -11.5286, -16.2189, -15.3991, -15.6952, -13.7974, -11.3957,
        -15.6025, -16.2064, -15.4474, -12.2031, -13.9580, -15.0301, -15.1529,
        -15.3355, -15.4048])
Final projection likelihood: -14.4942
1 mode projection succeeded
New goal: tensor([ 0.1087,  0.5253,  0.5871,  0.6850, -0.0671,  0.5448,  0.9081,  0.8963,
         1.3543,  0.3438,  0.1604,  1.0802,  0.0059, -0.0065, -1.7547],
       device='cuda:1')
tensor([[0.0066]], device='cuda:1') tensor([[0.0159]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -21.650983810424805
Adjusted likelihood: -21.650983810424805
Likelihood residual: 0.0
Original likelihood: -26.255308151245117
Adjusted likelihood: -26.255308151245117
Likelihood residual: 0.0
{'index': 26.255308151245117, 'thumb_middle': 21.650983810424805}
Current yaw: tensor([ 0.0121, -0.0223, -0.0300], device='cuda:1')
2 thumb_middle
tensor([ 0.1971,  0.6037,  0.6087,  0.6425, -0.3031,  0.4640,  1.0507,  0.9717,
         1.2387,  0.3229,  0.1668,  1.1092,  0.0121, -0.0223, -0.0300,  0.3968],
       device='cuda:1')
Solve time for step 1 9.392480031994637
Current ori: tensor([ 0.0121, -0.0223, -0.0300], device='cuda:1')
Index force: tensor([0.5961, 0.5878, 0.5751, 0.6083], device='cuda:1')
tensor([ 0.1533,  0.5731,  0.5915,  0.6657, -0.2187,  0.4917,  0.9016,  0.8879,
         1.2976,  0.3245,  0.0849,  1.0484,  0.0191,  0.0040, -0.0300,  0.3487],
       device='cuda:1')
Solve time for step 2 2.067434853001032
Current ori: tensor([ 0.0191,  0.0040, -0.0300], device='cuda:1')
Index force: tensor([0.5812, 0.5704, 0.6029], device='cuda:1')
tensor([ 0.1443,  0.5720,  0.5854,  0.6619, -0.2091,  0.5124,  0.8724,  0.8734,
         1.3230,  0.3307,  0.0673,  1.0397,  0.0190,  0.0089, -0.0300,  0.3323],
       device='cuda:1')
Solve time for step 3 1.9165361219784245
Current ori: tensor([ 0.0190,  0.0089, -0.0300], device='cuda:1')
Index force: tensor([0.5638, 0.5965], device='cuda:1')
tensor([ 0.1558,  0.5877,  0.5813,  0.6516, -0.1999,  0.5258,  0.8749,  0.8700,
         1.3233,  0.3273,  0.0594,  1.0321,  0.0148,  0.0016, -0.0300,  0.3459],
       device='cuda:1')
Solve time for step 4 1.8405032429727726
Current ori: tensor([ 0.0148,  0.0016, -0.0300], device='cuda:1')
Index force: tensor([0.5853], device='cuda:1')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0016), steps=1
Reward stats updated: mean -0.0121 -> -0.0121, std: 0.1577
Collected 368 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1679, Q2 Loss=1.1679, Entropy=0.0000, Time=0.08sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=4.9459
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7734, Q2 Loss=0.7734, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7559
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=1.5208, Q2 Loss=1.5208, Entropy=0.0004, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9964
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9200, Q2 Loss=0.9200, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4553
SAC Update 5/5: Actor Loss=-0.0043, Q1 Loss=0.8384, Q2 Loss=0.8384, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3876

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (19.5%)
Q2 update: 0.06s (19.5%)
Actor update: 0.12s (40.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002742
Q1 loss: 1.044103
Q2 loss: 1.044103
Current threshold: -23.8037
Global Scale Offset: 0.0562
Reward stats: mean=-0.0121, std=0.1577, count=368
----------------------------------------------
SAC Update - Actor Loss: -0.0027, Q1 Loss: 1.0441, Q2 Loss: 1.0441, Entropy: 0.0001, Mean TD Error: 1.7082, Threshold: -23.8037
Original likelihood: -22.306806564331055
Adjusted likelihood: -22.306806564331055
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0193,  0.0074, -0.0314], device='cuda:1')
3 turn
Sampling time 3.7152447450207546
tensor([ 0.1428,  0.5734,  0.5818,  0.6626, -0.1439,  0.5655,  0.9070,  0.8898,
         1.3839,  0.3424,  0.1161,  1.0696,  0.0193,  0.0074, -0.0314,  0.3692],
       device='cuda:1')
Original likelihood: -20.353816986083984
Adjusted likelihood: -20.353816986083984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.252377884986345
Current ori: tensor([ 0.0193,  0.0074, -0.0314], device='cuda:1')
Middle force: tensor([0.8562, 0.5220, 0.5002, 0.6523, 0.6004, 0.5098, 0.5229, 0.5023, 0.8063,
        0.5384, 0.5778, 0.5614], device='cuda:1')
Thumb force: tensor([0.9992, 0.5884, 0.5780, 0.8205, 0.5259, 0.6821, 0.9397, 1.6935, 0.6193,
        0.5671, 0.5676, 0.5158], device='cuda:1')
Index force: tensor([0.5363, 0.5768, 0.7021, 0.6833, 0.6028, 0.6270, 0.5559, 0.5470, 0.6912,
        0.6755, 0.5337, 0.6440], device='cuda:1')
Storing NORMAL transition: reward=0.1347 (scaled=0.1347), steps=1
Reward stats updated: mean -0.0121 -> -0.0117, std: 0.1576
Collected 369 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7504, Q2 Loss=0.7504, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1388
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4658, Q2 Loss=1.4658, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2419
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2277, Q2 Loss=1.2277, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5897
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.1197, Q2 Loss=1.1197, Entropy=0.1798, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.3569
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7265, Q2 Loss=0.7265, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.2082

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.7%)
Actor update: 0.08s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000025
Q1 loss: 1.058021
Q2 loss: 1.058021
Current threshold: -23.7727
Global Scale Offset: 0.0555
Reward stats: mean=-0.0117, std=0.1576, count=369
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0580, Q2 Loss: 1.0580, Entropy: 0.0360, Mean TD Error: 0.7071, Threshold: -23.7727
tensor([ 0.1365,  0.5769,  0.5605,  0.6821, -0.1562,  0.5207,  0.9387,  0.9846,
         1.4903,  0.2102,  0.0879,  0.9886,  0.0202,  0.0108, -0.1664,  0.5069],
       device='cuda:1')
Original likelihood: -25.53002166748047
Adjusted likelihood: -25.53002166748047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 22.671493530273438
Projection step: 1, Loss: 20.48383140563965
Projection step: 2, Loss: 19.816497802734375
Projection step: 3, Loss: 17.44495391845703
Projection step: 4, Loss: 18.306034088134766
Projection step: 5, Loss: 16.054058074951172
Projection step: 6, Loss: 16.552846908569336
Projection step: 7, Loss: 15.221580505371094
Projection step: 8, Loss: 15.926741600036621
Projection step: 9, Loss: 14.835589408874512
Final likelihood: tensor([-15.5488, -13.6516, -14.9789, -11.5032, -13.4915, -17.4696, -15.9216,
        -13.1026, -14.5785, -15.2412, -15.2813, -15.0267, -15.5502, -14.1496,
        -16.8880, -14.9862])
Final projection likelihood: -14.8356
1 mode projection succeeded
New goal: tensor([ 0.1032,  0.5394,  0.5671,  0.6447, -0.0827,  0.5257,  0.9030,  0.9299,
         1.4395,  0.2919,  0.1673,  1.0808,  0.0152,  0.0102, -2.4734],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -17.677072525024414
Adjusted likelihood: -17.677072525024414
Likelihood residual: 0.0
Original likelihood: -21.0205020904541
Adjusted likelihood: -21.0205020904541
Likelihood residual: 0.0
{'index': 21.0205020904541, 'thumb_middle': 17.677072525024414}
Current yaw: tensor([ 0.0202,  0.0108, -0.1664], device='cuda:1')
4 thumb_middle
tensor([ 0.1365,  0.5769,  0.5605,  0.6821, -0.1562,  0.5207,  0.9387,  0.9846,
         1.4903,  0.2102,  0.0879,  0.9886,  0.0202,  0.0108, -0.1664,  0.5069],
       device='cuda:1')
Solve time for step 1 8.937137414002791
Current ori: tensor([ 0.0202,  0.0108, -0.1664], device='cuda:1')
Index force: tensor([0.5752, 0.5865, 0.5022, 0.5844], device='cuda:1')
tensor([ 0.1229,  0.5655,  0.5641,  0.6780, -0.2071,  0.4924,  0.8515,  0.8897,
         1.3846,  0.2308,  0.0503,  1.0205,  0.0219,  0.0202, -0.1664,  0.4751],
       device='cuda:1')
Solve time for step 2 2.126171103969682
Current ori: tensor([ 0.0219,  0.0202, -0.1664], device='cuda:1')
Index force: tensor([0.5008, 0.5968, 0.5003], device='cuda:1')
tensor([ 0.1252,  0.5692,  0.5679,  0.6638, -0.2133,  0.5052,  0.8488,  0.8872,
         1.3856,  0.2519,  0.0440,  1.0230,  0.0199,  0.0187, -0.1664,  0.4720],
       device='cuda:1')
Solve time for step 3 1.8763356139534153
Current ori: tensor([ 0.0199,  0.0187, -0.1664], device='cuda:1')
Index force: tensor([0.5661, 0.5976], device='cuda:1')
tensor([ 0.1150,  0.5582,  0.5802,  0.6499, -0.2214,  0.5072,  0.8509,  0.8876,
         1.3881,  0.2618,  0.0428,  1.0256,  0.0213,  0.0242, -0.1664,  0.4572],
       device='cuda:1')
Solve time for step 4 1.8365299399592914
Current ori: tensor([ 0.0213,  0.0242, -0.1664], device='cuda:1')
Index force: tensor([0.5763], device='cuda:1')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0056), steps=1
Reward stats updated: mean -0.0117 -> -0.0116, std: 0.1574
Collected 370 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=1.5214, Q2 Loss=1.5214, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.5561
SAC Update 2/5: Actor Loss=-0.0230, Q1 Loss=0.7850, Q2 Loss=0.7850, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2863
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.9453, Q2 Loss=0.9453, Entropy=0.1029, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.5915
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0367, Q2 Loss=1.0367, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0617
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.4534, Q2 Loss=1.4534, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0314

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009221
Q1 loss: 1.148370
Q2 loss: 1.148370
Current threshold: -23.7527
Global Scale Offset: 0.0551
Reward stats: mean=-0.0116, std=0.1574, count=370
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.1484, Q2 Loss: 1.1484, Entropy: 0.0206, Mean TD Error: 1.9054, Threshold: -23.7527
Original likelihood: -26.226200103759766
Adjusted likelihood: -26.226200103759766
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 25.888357162475586
Projection step: 1, Loss: 22.917285919189453
Projection step: 2, Loss: 21.20185089111328
Projection step: 3, Loss: 19.12279510498047
Projection step: 4, Loss: 18.68460464477539
Projection step: 5, Loss: 18.070234298706055
Projection step: 6, Loss: 15.765459060668945
Projection step: 7, Loss: 15.739758491516113
Projection step: 8, Loss: 14.685227394104004
Final likelihood: tensor([-14.0135, -14.2134, -10.3636, -15.0085, -15.9954, -17.8908, -10.9578,
        -17.2101, -13.7547, -15.8291, -13.3141, -14.2479, -14.1225, -14.0051,
        -16.7430, -17.2943])
Final projection likelihood: -14.6852
1 mode projection succeeded
New goal: tensor([ 0.0754,  0.5644,  0.5508,  0.6228, -0.0895,  0.5267,  0.8646,  0.8305,
         1.3990,  0.3226,  0.1942,  1.1240,  0.0216,  0.0219, -1.9837],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -19.046630859375
Adjusted likelihood: -19.046630859375
Likelihood residual: 0.0
Original likelihood: -18.885190963745117
Adjusted likelihood: -18.885190963745117
Likelihood residual: 0.0
{'index': 18.885190963745117, 'thumb_middle': 19.046630859375}
Current yaw: tensor([ 0.0260,  0.0343, -0.1625], device='cuda:1')
5 index
tensor([ 0.0943,  0.5429,  0.5802,  0.6512, -0.1696,  0.5433,  0.8753,  0.9140,
         1.4469,  0.2838,  0.0986,  1.0781,  0.0260,  0.0343, -0.1625,  0.4593],
       device='cuda:1')
Solve time for step 1 10.686721827019937
Current ori: tensor([ 0.0260,  0.0343, -0.1625], device='cuda:1')
Middle force: tensor([0.5563, 0.5395, 0.5939, 0.5670], device='cuda:1')
Thumb force: tensor([0.6034, 0.5708, 0.5855, 0.6297], device='cuda:1')
tensor([ 0.1241,  0.5102,  0.5062,  0.6077, -0.1584,  0.5400,  0.9007,  0.8822,
         1.4310,  0.3298,  0.0924,  1.0770,  0.0219,  0.0273, -0.1751,  0.9593],
       device='cuda:1')
Solve time for step 2 2.285391323035583
Current ori: tensor([ 0.0219,  0.0273, -0.1751], device='cuda:1')
Middle force: tensor([0.5701, 0.5008, 0.5077], device='cuda:1')
Thumb force: tensor([0.5615, 0.5004, 0.5081], device='cuda:1')
tensor([ 0.1249,  0.5213,  0.5025,  0.6062, -0.1624,  0.5638,  0.8985,  0.8550,
         1.4240,  0.3437,  0.0990,  1.0546,  0.0130,  0.0247, -0.1751,  1.1462],
       device='cuda:1')
Solve time for step 3 2.2148774929810315
Current ori: tensor([ 0.0130,  0.0247, -0.1751], device='cuda:1')
Middle force: tensor([0.5007, 0.5070], device='cuda:1')
Thumb force: tensor([0.5004, 0.5073], device='cuda:1')
tensor([ 0.1224,  0.5246,  0.4992,  0.5985, -0.1470,  0.5815,  0.8883,  0.8450,
         1.4452,  0.3003,  0.0680,  1.0552,  0.0050,  0.0151, -0.1877,  1.1537],
       device='cuda:1')
Solve time for step 4 2.080698730016593
Current ori: tensor([ 0.0050,  0.0151, -0.1877], device='cuda:1')
Middle force: tensor([0.5058], device='cuda:1')
Thumb force: tensor([0.5060], device='cuda:1')
Storing RECOVERY transition: reward=0.0229 (scaled=0.0229), steps=1
Reward stats updated: mean -0.0116 -> -0.0116, std: 0.1572
Collected 371 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.3154, Q2 Loss=1.3154, Entropy=0.2213, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4388
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8740, Q2 Loss=0.8740, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=2.1973
SAC Update 3/5: Actor Loss=-0.0018, Q1 Loss=0.9893, Q2 Loss=0.9893, Entropy=0.2287, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.7529
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.1097, Q2 Loss=1.1097, Entropy=0.0620, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7181
SAC Update 5/5: Actor Loss=-0.0230, Q1 Loss=1.1096, Q2 Loss=1.1096, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.8458

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.4%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004994
Q1 loss: 1.079601
Q2 loss: 1.079601
Current threshold: -23.7294
Global Scale Offset: 0.0549
Reward stats: mean=-0.0116, std=0.1572, count=371
----------------------------------------------
SAC Update - Actor Loss: -0.0050, Q1 Loss: 1.0796, Q2 Loss: 1.0796, Entropy: 0.1024, Mean TD Error: 1.1906, Threshold: -23.7294
Original likelihood: -20.756671905517578
Adjusted likelihood: -20.756671905517578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0071,  0.0163, -0.1890], device='cuda:1')
6 turn
Sampling time 3.9379772410029545
tensor([ 0.0765,  0.5727,  0.5413,  0.6170, -0.1558,  0.5788,  0.9004,  0.8495,
         1.4255,  0.3536,  0.0616,  1.0859,  0.0071,  0.0163, -0.1890,  1.1407],
       device='cuda:1')
Original likelihood: -20.70439910888672
Adjusted likelihood: -20.70439910888672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.4391317970003
Current ori: tensor([ 0.0071,  0.0163, -0.1890], device='cuda:1')
Middle force: tensor([1.2695, 0.5159, 0.5045, 0.5157, 0.5930, 0.6063, 1.0500, 0.8068, 0.8023,
        0.6101, 0.5219, 0.5575], device='cuda:1')
Thumb force: tensor([1.8908, 1.9162, 1.3935, 0.5844, 1.0739, 0.7775, 1.4910, 0.5840, 0.6885,
        0.6615, 0.5559, 0.7733], device='cuda:1')
Index force: tensor([0.5622, 0.8162, 0.7418, 0.6373, 0.5543, 0.5483, 0.5750, 0.5188, 0.5736,
        0.5603, 0.5010, 0.5647], device='cuda:1')
Storing NORMAL transition: reward=0.0644 (scaled=0.0644), steps=1
Reward stats updated: mean -0.0116 -> -0.0114, std: 0.1570
Collected 372 transitions for RL
SAC Update 1/5: Actor Loss=-0.0230, Q1 Loss=1.4169, Q2 Loss=1.4169, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7359
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=1.4006, Q2 Loss=1.4006, Entropy=0.3444, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6209
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4267, Q2 Loss=1.4267, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6203
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.2251, Q2 Loss=1.2251, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1324
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=1.2446, Q2 Loss=1.2446, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7305

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (42.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006427
Q1 loss: 1.342763
Q2 loss: 1.342763
Current threshold: -23.6980
Global Scale Offset: 0.0545
Reward stats: mean=-0.0114, std=0.1570, count=372
----------------------------------------------
SAC Update - Actor Loss: -0.0064, Q1 Loss: 1.3428, Q2 Loss: 1.3428, Entropy: 0.0689, Mean TD Error: 0.5680, Threshold: -23.6980
tensor([-0.0465,  0.4875,  0.4778,  0.7620, -0.1902,  0.5825,  0.8077,  0.9854,
         1.4838,  0.2850,  0.1553,  0.8837,  0.0101,  0.0415, -0.2551,  1.3464],
       device='cuda:1')
Original likelihood: -34.01264190673828
Adjusted likelihood: -34.01264190673828
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 34.73804473876953
Projection step: 1, Loss: 29.418930053710938
Projection step: 2, Loss: 29.29278564453125
Projection step: 3, Loss: 24.748729705810547
Projection step: 4, Loss: 21.980941772460938
Projection step: 5, Loss: 18.136470794677734
Projection step: 6, Loss: 17.144695281982422
Projection step: 7, Loss: 15.540019035339355
Projection step: 8, Loss: 15.719757080078125
Projection step: 9, Loss: 12.67367172241211
Final likelihood: tensor([-11.3688, -13.9682, -13.0529, -13.9933, -13.4491, -10.7810, -13.9740,
        -13.2957, -13.3601, -14.7769,  -9.7551,  -9.2464, -13.7978,  -9.4040,
        -12.8760, -15.6794])
Final projection likelihood: -12.6737
1 mode projection succeeded
New goal: tensor([ 0.0073,  0.5224,  0.5542,  0.6881, -0.1014,  0.5575,  0.6805,  0.8888,
         1.3435,  0.1903,  0.1737,  1.0226,  0.0101,  0.0226, -1.3842],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -21.790637969970703
Adjusted likelihood: -21.790637969970703
Likelihood residual: 0.0
Original likelihood: -24.960952758789062
Adjusted likelihood: -24.960952758789062
Likelihood residual: 0.0
{'index': 24.960952758789062, 'thumb_middle': 21.790637969970703}
Current yaw: tensor([ 0.0101,  0.0415, -0.2551], device='cuda:1')
7 thumb_middle
tensor([-0.0465,  0.4875,  0.4778,  0.7620, -0.1902,  0.5825,  0.8077,  0.9854,
         1.4838,  0.2850,  0.1553,  0.8837,  0.0101,  0.0415, -0.2551,  1.3464],
       device='cuda:1')
Solve time for step 1 9.330410565016791
Current ori: tensor([ 0.0101,  0.0415, -0.2551], device='cuda:1')
Index force: tensor([0.5522, 0.5938, 0.5846, 0.5873], device='cuda:1')
tensor([-0.0537,  0.4656,  0.5272,  0.7111, -0.2061,  0.5646,  0.6853,  0.9007,
         1.3498,  0.2186,  0.1446,  0.9959,  0.0132,  0.0479, -0.2550,  1.3346],
       device='cuda:1')
Solve time for step 2 2.0957332039834
Current ori: tensor([ 0.0132,  0.0479, -0.2550], device='cuda:1')
Index force: tensor([0.5868, 0.5822, 0.5983], device='cuda:1')
tensor([-0.0381,  0.4702,  0.5307,  0.7165, -0.1993,  0.5853,  0.6837,  0.8772,
         1.3614,  0.1818,  0.1262,  1.0072,  0.0123,  0.0397, -0.2550,  1.3503],
       device='cuda:1')
Solve time for step 3 1.9911683450336568
Current ori: tensor([ 0.0123,  0.0397, -0.2550], device='cuda:1')
Index force: tensor([0.5759, 0.6081], device='cuda:1')
tensor([-0.0224,  0.4718,  0.5433,  0.7117, -0.1907,  0.5994,  0.6805,  0.8608,
         1.3543,  0.1786,  0.1240,  1.0043,  0.0109,  0.0313, -0.2550,  1.3619],
       device='cuda:1')
Solve time for step 4 1.8500956690404564
Current ori: tensor([ 0.0109,  0.0313, -0.2550], device='cuda:1')
Index force: tensor([0.5989], device='cuda:1')
Storing RECOVERY transition: reward=0.0067 (scaled=0.0067), steps=1
Reward stats updated: mean -0.0114 -> -0.0113, std: 0.1568
Collected 373 transitions for RL
SAC Update 1/5: Actor Loss=-0.0125, Q1 Loss=1.0662, Q2 Loss=1.0662, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.0503
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4038, Q2 Loss=1.4038, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=5.0092
SAC Update 3/5: Actor Loss=-0.0011, Q1 Loss=1.2096, Q2 Loss=1.2096, Entropy=0.3232, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.9797
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9648, Q2 Loss=0.9648, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.4524
SAC Update 5/5: Actor Loss=-0.0196, Q1 Loss=1.3954, Q2 Loss=1.3954, Entropy=0.0000, Time=0.04sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.7757

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.2%)
Actor loss: -0.006632
Q1 loss: 1.207969
Q2 loss: 1.207969
Current threshold: -23.6163
Global Scale Offset: 0.0527
Reward stats: mean=-0.0113, std=0.1568, count=373
----------------------------------------------
SAC Update - Actor Loss: -0.0066, Q1 Loss: 1.2080, Q2 Loss: 1.2080, Entropy: 0.0647, Mean TD Error: 1.6535, Threshold: -23.6163
Original likelihood: -20.789447784423828
Adjusted likelihood: -20.789447784423828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0090,  0.0231, -0.2605], device='cuda:1')
8 turn
Sampling time 3.847077568003442
tensor([-0.0070,  0.4796,  0.5482,  0.7057, -0.1160,  0.6476,  0.7065,  0.8813,
         1.4095,  0.2041,  0.1654,  1.0332,  0.0090,  0.0231, -0.2605,  1.3744],
       device='cuda:1')
Original likelihood: -22.06386375427246
Adjusted likelihood: -22.06386375427246
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.435234634031076
Current ori: tensor([ 0.0090,  0.0231, -0.2605], device='cuda:1')
Middle force: tensor([0.5350, 0.5448, 0.5706, 0.5917, 0.5032, 0.5506, 0.9637, 0.6417, 0.5986,
        0.6280, 0.6253, 0.6027], device='cuda:1')
Thumb force: tensor([0.9155, 0.8817, 0.5455, 2.9579, 0.6266, 1.5824, 2.1043, 0.5266, 0.6096,
        0.5990, 0.5619, 0.6523], device='cuda:1')
Index force: tensor([0.5425, 0.6112, 0.5863, 0.7319, 0.6751, 0.5661, 0.6529, 0.6287, 0.5782,
        0.5841, 0.5645, 0.5299], device='cuda:1')
Storing NORMAL transition: reward=-0.0047 (scaled=-0.0047), steps=1
Reward stats updated: mean -0.0113 -> -0.0113, std: 0.1566
Collected 374 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.1831, Q2 Loss=1.1831, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.1356
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8508, Q2 Loss=0.8508, Entropy=0.0000, Time=0.06sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=1.3989
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.2650, Q2 Loss=1.2650, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.1971
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9114, Q2 Loss=0.9114, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.6218
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7543, Q2 Loss=0.7543, Entropy=0.0000, Time=0.05sActor IP Change=0.0000, Critic IP Change 1=0.0000, Critic IP Change 2=0.0000, Mean TD Error=0.2213

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.8%)
Q1 update: 0.06s (20.7%)
Q2 update: 0.06s (20.9%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.992931
Q2 loss: 0.992931
Current threshold: -23.5651
Global Scale Offset: 0.0516
Reward stats: mean=-0.0113, std=0.1566, count=374
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.9929, Q2 Loss: 0.9929, Entropy: 0.0000, Mean TD Error: 0.7150, Threshold: -23.5651
tensor([-0.0295,  0.4014,  0.6378,  0.7061, -0.1309,  0.6539,  0.6140,  1.0402,
         1.4020,  0.2454,  0.2759,  0.8670,  0.0283,  0.0326, -0.2570,  1.3294],
       device='cuda:1')
Original likelihood: -25.363590240478516
Adjusted likelihood: -25.363590240478516
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 26.313980102539062
Projection step: 1, Loss: 24.089550018310547
Projection step: 2, Loss: 21.49958038330078
Projection step: 3, Loss: 18.687231063842773
Projection step: 4, Loss: 18.912696838378906
Projection step: 5, Loss: 18.72048568725586
Projection step: 6, Loss: 16.532855987548828
Projection step: 7, Loss: 14.595351219177246
Final likelihood: tensor([-14.1785, -15.4989, -15.7601, -15.6475, -13.8488, -13.2732, -14.0831,
        -13.6093, -14.2129, -13.5812, -20.2638, -13.5329, -13.0671, -13.2813,
        -14.0279, -15.6592])
Final projection likelihood: -14.5954
1 mode projection succeeded
New goal: tensor([-0.0206,  0.4703,  0.5787,  0.7143, -0.0632,  0.6065,  0.5606,  0.9546,
         1.3339,  0.2332,  0.2407,  1.0155,  0.0241,  0.0237, -0.6515],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -22.00387954711914
Adjusted likelihood: -22.00387954711914
Likelihood residual: 0.0
Original likelihood: -24.017364501953125
Adjusted likelihood: -24.017364501953125
Likelihood residual: 0.0
{'index': 24.017364501953125, 'thumb_middle': 22.00387954711914}
Current yaw: tensor([ 0.0283,  0.0326, -0.2570], device='cuda:1')
9 thumb_middle
tensor([-0.0295,  0.4014,  0.6378,  0.7061, -0.1309,  0.6539,  0.6140,  1.0402,
         1.4020,  0.2454,  0.2759,  0.8670,  0.0283,  0.0326, -0.2570,  1.3294],
       device='cuda:1')
Solve time for step 1 9.224545961013064
Current ori: tensor([ 0.0283,  0.0326, -0.2570], device='cuda:1')
Index force: tensor([0.5886, 0.6006, 0.5032, 0.5865], device='cuda:1')
tensor([-0.0072,  0.4192,  0.6075,  0.7550, -0.1495,  0.6279,  0.5458,  0.9483,
         1.3078,  0.2129,  0.1878,  0.9566,  0.0304,  0.0227, -0.2556,  1.4178],
       device='cuda:1')
Solve time for step 2 1.9663683680118993
Current ori: tensor([ 0.0304,  0.0227, -0.2556], device='cuda:1')
Index force: tensor([0.5926, 0.5004, 0.5823], device='cuda:1')
tensor([ 0.0056,  0.4236,  0.5915,  0.7968, -0.1479,  0.6439,  0.5521,  0.9517,
         1.3102,  0.2163,  0.1641,  0.9814,  0.0342,  0.0158, -0.2556,  1.4420],
       device='cuda:1')
Solve time for step 3 1.9098899259697646
Current ori: tensor([ 0.0342,  0.0158, -0.2556], device='cuda:1')
Index force: tensor([0.5013, 0.5986], device='cuda:1')
[1;34mwandb[0m: 🚀 View run [33mallegro_screwdriver_recovery_data_sac_bernoulli_likelihood_64_orig_lower_critic_lr_lower_alpha_more_inducing_pts_2025-03-17-09-33-06[0m at: [34mhttps://wandb.ai/abhinavk99/ccai-screwdriver/runs/9cq0gcql[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250317_093306-9cq0gcql/logs[0m
