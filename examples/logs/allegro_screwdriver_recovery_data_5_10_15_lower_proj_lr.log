Importing module 'gym_38' (/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
PyTorch version 2.4.1+cu121
Device count 2
/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
No ROS install found, continuing
CCAI_PATH /home/abhinav/Documents/ccai
Not connected to PVD
Physics Engine: PhysX
Physics Device: cpu
GPU Pipeline: disabled
Using VHACD cache directory '/home/abhinav/.isaacgym/vhacd'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/base_ns.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/link_1.0.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/ft_c.stl'
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]

Trial 1
Loaded trajectory sampler
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
1 turn
Sampling time 3.8349983519874513
tensor([ 1.5538e-01,  6.1090e-01,  5.7053e-01,  6.0998e-01, -1.1557e-01,
         5.3958e-01,  8.8539e-01,  9.3525e-01,  1.2574e+00,  2.2958e-01,
         2.3280e-01,  1.2081e+00,  5.5207e-05,  1.3631e-02, -4.8130e-02,
         4.4650e-01], device='cuda:1')
Original likelihood: -107.50236511230469
Adjusted likelihood: -107.50236511230469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.998976207047235
Current ori: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:1')
Middle force: tensor([0.5791, 0.5709, 1.1438, 0.5580, 1.1024, 0.6482, 0.5358, 0.5249, 0.5829,
        0.5540, 0.5206, 0.5708], device='cuda:1')
Thumb force: tensor([0.8664, 0.8197, 0.7561, 1.0166, 0.9685, 0.6757, 0.5213, 0.5700, 0.5453,
        0.6043, 0.5627, 0.5500], device='cuda:1')
Index force: tensor([0.5978, 0.6008, 0.5560, 0.5699, 0.7921, 0.5254, 1.0088, 0.5495, 0.5799,
        0.6410, 0.5969, 0.5416], device='cuda:1')
Storing NORMAL transition: reward=0.0014 (scaled=0.0014), steps=1
Reward stats updated: mean 0.0000 -> 0.0014, std: 0.0000
Collected 1 transitions for RL
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:1')
Original likelihood: -210.39617919921875
Adjusted likelihood: -210.39617919921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 211.31607055664062
Projection step: 1, Loss: 196.03131103515625
Projection step: 2, Loss: 192.03518676757812
Projection step: 3, Loss: 183.591796875
Projection step: 4, Loss: 179.67279052734375
Projection step: 5, Loss: 160.3355255126953
Projection step: 6, Loss: 156.06019592285156
Projection step: 7, Loss: 165.8201446533203
Projection step: 8, Loss: 149.53890991210938
Projection step: 9, Loss: 137.60922241210938
Projection step: 10, Loss: 132.89990234375
Projection step: 11, Loss: 133.66024780273438
Projection step: 12, Loss: 119.21310424804688
Projection step: 13, Loss: 118.72647094726562
Projection step: 14, Loss: 118.31173706054688
Projection step: 15, Loss: 126.92958068847656
Projection step: 16, Loss: 112.43327331542969
Projection step: 17, Loss: 101.00204467773438
Final likelihood: tensor([-110.0100,  -92.5678,  -89.9983,  -86.4708, -125.4212, -104.8228,
         -87.4081,  -93.5196, -118.1119,  -94.2394,  -89.4972,  -92.0547,
        -106.0708, -113.1097, -121.1122,  -91.6183])
Final projection likelihood: -101.0021
1 mode projection succeeded
New goal: tensor([ 0.1845,  0.6270,  0.5080,  0.5661, -0.1115,  0.4922,  0.8836,  1.0846,
         1.2814,  0.3292,  0.2000,  1.0821,  0.0036,  0.0141, -2.4588],
       device='cuda:1')
tensor([[0.0068]], device='cuda:1') tensor([[0.0077]], device='cuda:1') tensor([[0.0106]], device='cuda:1')
Original likelihood: -153.4710693359375
Adjusted likelihood: -153.4710693359375
Likelihood residual: 0.0
Original likelihood: -154.0536346435547
Adjusted likelihood: -154.0536346435547
Likelihood residual: 0.0
{'index': 154.0536346435547, 'thumb_middle': 153.4710693359375}
Current yaw: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:1')
2 thumb_middle
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:1')
Solve time for step 1 8.886457342014182
Current ori: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:1')
Index force: tensor([0.5941, 0.5733, 0.5840, 0.5754], device='cuda:1')
tensor([ 0.2148,  0.7099,  0.5211,  0.5788, -0.2310,  0.4583,  0.8544,  1.0683,
         1.2658,  0.3049,  0.1281,  1.0622,  0.0124,  0.0425, -0.0510, -1.1288],
       device='cuda:1')
Solve time for step 2 3.780074655020144
Current ori: tensor([ 0.0124,  0.0425, -0.0510], device='cuda:1')
Index force: tensor([0.5654, 0.5747, 0.5792], device='cuda:1')
tensor([ 0.2255,  0.7021,  0.5391,  0.5955, -0.2393,  0.4552,  0.8324,  1.0621,
         1.2695,  0.3193,  0.1458,  1.0668,  0.0141,  0.0368, -0.0476, -1.1020],
       device='cuda:1')
Solve time for step 3 3.373672283021733
Current ori: tensor([ 0.0141,  0.0368, -0.0476], device='cuda:1')
Index force: tensor([0.5484, 0.5737], device='cuda:1')
tensor([ 0.2320,  0.7068,  0.5495,  0.5733, -0.2353,  0.4556,  0.8373,  1.0429,
         1.2692,  0.3301,  0.1435,  1.0611,  0.0115,  0.0320, -0.0475, -1.0978],
       device='cuda:1')
Solve time for step 4 3.4085821880144067
Current ori: tensor([ 0.0115,  0.0320, -0.0475], device='cuda:1')
Index force: tensor([0.5644], device='cuda:1')
Storing RECOVERY transition: reward=0.0017 (scaled=0.0017), steps=1
Reward stats updated: mean 0.0014 -> 0.0016, std: 0.0001
Collected 2 transitions for RL
Original likelihood: -195.17822265625
Adjusted likelihood: -195.17822265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 206.76324462890625
Projection step: 1, Loss: 182.00863647460938
Projection step: 2, Loss: 176.3682098388672
Projection step: 3, Loss: 174.40145874023438
Projection step: 4, Loss: 173.07852172851562
Projection step: 5, Loss: 157.50540161132812
Projection step: 6, Loss: 155.88565063476562
Projection step: 7, Loss: 152.19482421875
Projection step: 8, Loss: 138.267333984375
Projection step: 9, Loss: 134.16009521484375
Projection step: 10, Loss: 128.30213928222656
Projection step: 11, Loss: 124.15428161621094
Projection step: 12, Loss: 116.01731872558594
Projection step: 13, Loss: 109.47419738769531
Projection step: 14, Loss: 102.19357299804688
Final likelihood: tensor([ -93.4594, -120.9107,  -94.6207, -118.1016, -108.5083, -104.2822,
        -104.6886, -112.3516,  -97.7090, -116.3223,  -90.2181,  -97.8577,
         -91.9262,  -96.2113,  -94.8162,  -93.1132])
Final projection likelihood: -102.1936
1 mode projection succeeded
New goal: tensor([ 0.1689,  0.6506,  0.4922,  0.5346, -0.1140,  0.4919,  0.8535,  1.0540,
         1.3223,  0.3794,  0.1910,  1.0827,  0.0141,  0.0189, -2.6235],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0013]], device='cuda:1')
Original likelihood: -219.94827270507812
Adjusted likelihood: -219.94827270507812
Likelihood residual: 0.0
Original likelihood: -102.1633529663086
Adjusted likelihood: -102.1633529663086
Likelihood residual: 0.0
{'index': 102.1633529663086, 'thumb_middle': 219.94827270507812}
Current yaw: tensor([ 0.0120,  0.0350, -0.0524], device='cuda:1')
3 index
tensor([ 0.2153,  0.7174,  0.5139,  0.5774, -0.1724,  0.4923,  0.8701,  1.0826,
         1.3282,  0.3580,  0.1963,  1.0882,  0.0120,  0.0350, -0.0524, -1.0220],
       device='cuda:1')
Solve time for step 1 10.290960195998196
Current ori: tensor([ 0.0120,  0.0350, -0.0524], device='cuda:1')
Middle force: tensor([0.5619, 0.5881, 0.5954, 0.5461], device='cuda:1')
Thumb force: tensor([0.6005, 0.5739, 0.5227, 0.5156], device='cuda:1')
tensor([ 0.2145,  0.6155,  0.4598,  0.5277, -0.1602,  0.4978,  0.8744,  1.0742,
         1.3258,  0.3679,  0.1802,  1.0905,  0.0060,  0.0275, -0.0762, -2.4009],
       device='cuda:1')
Solve time for step 2 4.143205681990366
Current ori: tensor([ 0.0060,  0.0275, -0.0762], device='cuda:1')
Middle force: tensor([0.5799, 0.5010, 0.5446], device='cuda:1')
Thumb force: tensor([0.5660, 0.6617, 0.5596], device='cuda:1')
tensor([ 2.0750e-01,  6.1103e-01,  4.5611e-01,  5.2241e-01, -1.4912e-01,
         5.1200e-01,  8.6627e-01,  1.0614e+00,  1.3273e+00,  3.6302e-01,
         1.6659e-01,  1.0925e+00,  2.4268e-04,  2.1296e-02, -7.2419e-02,
        -3.1891e+00], device='cuda:1')
Solve time for step 3 4.050436051969882
Current ori: tensor([ 0.0002,  0.0213, -0.0724], device='cuda:1')
Middle force: tensor([0.5224, 0.5583], device='cuda:1')
Thumb force: tensor([0.5416, 0.5749], device='cuda:1')
tensor([ 2.0650e-01,  6.1072e-01,  4.5670e-01,  5.2164e-01, -1.5227e-01,
         5.1242e-01,  8.6708e-01,  1.0627e+00,  1.3263e+00,  3.6753e-01,
         1.6774e-01,  1.0926e+00, -5.0065e-04,  2.2402e-02, -7.6618e-02,
        -3.7049e+00], device='cuda:1')
Solve time for step 4 3.9289546179934405
Current ori: tensor([-0.0005,  0.0224, -0.0766], device='cuda:1')
Middle force: tensor([0.5142], device='cuda:1')
Thumb force: tensor([0.6517], device='cuda:1')
Storing RECOVERY transition: reward=0.0199 (scaled=0.0199), steps=1
Reward stats updated: mean 0.0016 -> 0.0077, std: 0.0087
Collected 3 transitions for RL
Original likelihood: -160.51536560058594
Adjusted likelihood: -160.51536560058594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 156.2862091064453
Projection step: 1, Loss: 148.3555908203125
Projection step: 2, Loss: 148.33700561523438
Projection step: 3, Loss: 131.1685333251953
Projection step: 4, Loss: 121.6378402709961
Projection step: 5, Loss: 118.82754516601562
Projection step: 6, Loss: 109.34359741210938
Projection step: 7, Loss: 95.95872497558594
Final likelihood: tensor([ -80.4834,  -87.5945,  -86.1342,  -94.4266,  -84.1419, -110.3046,
         -84.6914,  -93.2186, -109.7225, -104.1139, -138.5272,  -96.9085,
         -86.6545,  -77.8459,  -89.3472, -111.2248])
Final projection likelihood: -95.9587
1 mode projection succeeded
New goal: tensor([ 1.2156e-01,  6.4134e-01,  4.9351e-01,  5.5396e-01, -1.2548e-01,
         5.0417e-01,  8.5485e-01,  1.0206e+00,  1.3231e+00,  3.7396e-01,
         1.7828e-01,  1.1010e+00, -2.4394e-04,  2.0880e-02, -1.2672e+00],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -142.00814819335938
Adjusted likelihood: -142.00814819335938
Likelihood residual: 0.0
Original likelihood: -114.1636962890625
Adjusted likelihood: -114.1636962890625
Likelihood residual: 0.0
{'index': 114.1636962890625, 'thumb_middle': 142.00814819335938}
Current yaw: tensor([ 0.0010,  0.0295, -0.0702], device='cuda:1')
4 index
tensor([ 1.4467e-01,  6.7539e-01,  5.0113e-01,  5.3944e-01, -1.6240e-01,
         5.0771e-01,  8.6498e-01,  1.0629e+00,  1.3336e+00,  3.6018e-01,
         1.7599e-01,  1.0863e+00,  9.8022e-04,  2.9459e-02, -7.0193e-02,
        -3.8497e+00], device='cuda:1')
Solve time for step 1 10.73222398897633
Current ori: tensor([ 0.0010,  0.0295, -0.0702], device='cuda:1')
Middle force: tensor([0.5450, 0.5755, 0.5584, 0.5967], device='cuda:1')
Thumb force: tensor([0.5473, 0.5806, 0.6493, 0.6072], device='cuda:1')
tensor([ 0.1670,  0.5907,  0.4497,  0.5337, -0.1597,  0.5084,  0.8720,  1.0451,
         1.3394,  0.3540,  0.1736,  1.0723, -0.0037,  0.0286, -0.0806, -3.1618],
       device='cuda:1')
Solve time for step 2 4.210909629997332
Current ori: tensor([-0.0037,  0.0286, -0.0806], device='cuda:1')
Middle force: tensor([0.5010, 0.5049, 0.5926], device='cuda:1')
Thumb force: tensor([0.5289, 0.5866, 0.5393], device='cuda:1')
tensor([ 0.1689,  0.5917,  0.4493,  0.5343, -0.1400,  0.5145,  0.8791,  1.0464,
         1.3208,  0.3725,  0.1578,  1.0960, -0.0035,  0.0147, -0.0834, -2.8088],
       device='cuda:1')
Solve time for step 3 3.975448446988594
Current ori: tensor([-0.0035,  0.0147, -0.0834], device='cuda:1')
Middle force: tensor([0.5658, 0.5947], device='cuda:1')
Thumb force: tensor([0.5579, 0.5740], device='cuda:1')
tensor([ 0.1684,  0.5893,  0.4484,  0.5344, -0.1435,  0.5218,  0.8791,  1.0414,
         1.3181,  0.3796,  0.1630,  1.0829, -0.0074,  0.0147, -0.0877, -2.6216],
       device='cuda:1')
Solve time for step 4 4.06115740101086
Current ori: tensor([-0.0074,  0.0147, -0.0877], device='cuda:1')
Middle force: tensor([0.5870], device='cuda:1')
Thumb force: tensor([0.5644], device='cuda:1')
Storing RECOVERY transition: reward=0.0208 (scaled=0.0208), steps=1
Reward stats updated: mean 0.0077 -> 0.0110, std: 0.0094
Collected 4 transitions for RL
Original likelihood: -122.28591918945312
Adjusted likelihood: -122.28591918945312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0104,  0.0214, -0.0708], device='cuda:1')
5 turn
Sampling time 3.550443645042833
tensor([ 0.1086,  0.6546,  0.4912,  0.5527, -0.1519,  0.5261,  0.8700,  1.0290,
         1.3413,  0.3477,  0.1550,  1.0806, -0.0104,  0.0214, -0.0708, -2.6079],
       device='cuda:1')
Original likelihood: -118.57345581054688
Adjusted likelihood: -118.57345581054688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.046226675040089
Current ori: tensor([-0.0104,  0.0214, -0.0708], device='cuda:1')
Middle force: tensor([0.5174, 0.5076, 0.5050, 1.5001, 0.6837, 0.4999, 0.5536, 0.5029, 0.5311,
        1.7149, 0.5683, 0.5171], device='cuda:1')
Thumb force: tensor([1.3299, 0.8944, 1.3004, 0.6211, 0.5328, 1.0129, 1.2324, 0.5444, 0.9548,
        1.8665, 0.6741, 0.6612], device='cuda:1')
Index force: tensor([0.5572, 0.8411, 0.6909, 0.7597, 0.5550, 0.6366, 0.6216, 0.6403, 0.6008,
        0.5628, 0.6005, 0.6301], device='cuda:1')
Storing NORMAL transition: reward=-0.0039 (scaled=-0.0039), steps=1
Reward stats updated: mean 0.0110 -> 0.0080, std: 0.0103
Collected 5 transitions for RL
tensor([ 0.0331,  0.6848,  0.3888,  0.4923, -0.2097,  0.5401,  0.8279,  0.9422,
         1.3591,  0.3883,  0.2203,  1.0085, -0.0181,  0.0689, -0.0712, -2.7329],
       device='cuda:1')
Original likelihood: -227.2147979736328
Adjusted likelihood: -227.2147979736328
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 231.87152099609375
Projection step: 1, Loss: 224.75611877441406
Projection step: 2, Loss: 203.23025512695312
Projection step: 3, Loss: 193.72988891601562
Projection step: 4, Loss: 192.77468872070312
Projection step: 5, Loss: 180.490478515625
Projection step: 6, Loss: 178.836181640625
Projection step: 7, Loss: 169.35836791992188
Projection step: 8, Loss: 164.7437286376953
Projection step: 9, Loss: 151.47824096679688
Projection step: 10, Loss: 147.5507049560547
Projection step: 11, Loss: 143.94398498535156
Projection step: 12, Loss: 135.98538208007812
Projection step: 13, Loss: 134.09303283691406
Projection step: 14, Loss: 128.60906982421875
Projection step: 15, Loss: 126.24751281738281
Projection step: 16, Loss: 121.8741455078125
Projection step: 17, Loss: 119.1781997680664
Projection step: 18, Loss: 114.63807678222656
Projection step: 19, Loss: 110.96078491210938
Projection step: 20, Loss: 109.76478576660156
Projection step: 21, Loss: 107.99686431884766
Projection step: 22, Loss: 103.73051452636719
Final likelihood: tensor([-101.2021, -101.0419, -104.8037, -102.2949, -106.2366, -106.3230,
        -107.7277, -102.9852, -101.3962,  -97.3888, -103.5584, -108.1220,
        -102.6236,  -99.2783, -103.1304, -111.5753])
Final projection likelihood: -103.7305
1 mode projection succeeded
New goal: tensor([ 0.0341,  0.6520,  0.4181,  0.5740, -0.1477,  0.4972,  0.8100,  0.9316,
         1.3227,  0.2144,  0.1635,  1.1956, -0.0298,  0.0486, -0.8995],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -150.80531311035156
Adjusted likelihood: -150.80531311035156
Likelihood residual: 0.0
Original likelihood: -150.005126953125
Adjusted likelihood: -150.005126953125
Likelihood residual: 0.0
{'index': 150.005126953125, 'thumb_middle': 150.80531311035156}
Current yaw: tensor([-0.0181,  0.0689, -0.0712], device='cuda:1')
6 index
tensor([ 0.0331,  0.6848,  0.3888,  0.4923, -0.2097,  0.5401,  0.8279,  0.9422,
         1.3591,  0.3883,  0.2203,  1.0085, -0.0181,  0.0689, -0.0712, -2.7329],
       device='cuda:1')
Solve time for step 1 10.960957876988687
Current ori: tensor([-0.0181,  0.0689, -0.0712], device='cuda:1')
Middle force: tensor([0.5955, 0.6033, 0.5729, 0.5328], device='cuda:1')
Thumb force: tensor([0.6134, 0.5258, 0.5856, 0.5348], device='cuda:1')
tensor([ 0.0812,  0.5882,  0.3604,  0.5373, -0.1915,  0.5256,  0.8532,  0.9685,
         1.4145,  0.2945,  0.1168,  1.1128, -0.0098,  0.0533, -0.0934, -3.7744],
       device='cuda:1')
Solve time for step 2 4.472913902020082
Current ori: tensor([-0.0098,  0.0533, -0.0934], device='cuda:1')
Middle force: tensor([0.5984, 0.5685, 0.5305], device='cuda:1')
Thumb force: tensor([0.5241, 0.5833, 0.5338], device='cuda:1')
tensor([ 0.0838,  0.5839,  0.3648,  0.5465, -0.1913,  0.5309,  0.8517,  0.9620,
         1.4237,  0.2742,  0.1018,  1.1312, -0.0093,  0.0526, -0.0727, -4.7235],
       device='cuda:1')
Solve time for step 3 4.099514908040874
Current ori: tensor([-0.0093,  0.0526, -0.0727], device='cuda:1')
Middle force: tensor([0.5682, 0.5324], device='cuda:1')
Thumb force: tensor([0.5883, 0.5345], device='cuda:1')
tensor([ 0.0822,  0.5821,  0.3658,  0.5480, -0.1939,  0.5349,  0.8482,  0.9515,
         1.4252,  0.2734,  0.1047,  1.1272, -0.0114,  0.0550, -0.0620, -5.5160],
       device='cuda:1')
Solve time for step 4 3.9333189190365374
Current ori: tensor([-0.0114,  0.0550, -0.0620], device='cuda:1')
Middle force: tensor([0.5134], device='cuda:1')
Thumb force: tensor([0.5758], device='cuda:1')
Storing RECOVERY transition: reward=0.0076 (scaled=0.0076), steps=1
Reward stats updated: mean 0.0080 -> 0.0079, std: 0.0094
Collected 6 transitions for RL
Original likelihood: -193.1403350830078
Adjusted likelihood: -193.1403350830078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 187.1432647705078
Projection step: 1, Loss: 177.35382080078125
Projection step: 2, Loss: 169.59957885742188
Projection step: 3, Loss: 165.4662322998047
Projection step: 4, Loss: 154.0824432373047
Projection step: 5, Loss: 145.05752563476562
Projection step: 6, Loss: 141.01109313964844
Projection step: 7, Loss: 129.46835327148438
Projection step: 8, Loss: 125.81153869628906
Projection step: 9, Loss: 123.98167419433594
Projection step: 10, Loss: 120.16136169433594
Projection step: 11, Loss: 113.82260131835938
Projection step: 12, Loss: 109.51528930664062
Projection step: 13, Loss: 105.36743927001953
Projection step: 14, Loss: 102.61236572265625
Final likelihood: tensor([-110.5275,  -99.8886, -110.0113, -114.4208, -103.9710, -107.4395,
         -99.1437, -100.9009, -103.4672,  -96.2097, -100.5110,  -98.7701,
        -101.2106,  -96.6042,  -94.0114, -104.7102])
Final projection likelihood: -102.6124
1 mode projection succeeded
New goal: tensor([ 0.0400,  0.6391,  0.4336,  0.6025, -0.1483,  0.4857,  0.8522,  0.9264,
         1.3537,  0.2255,  0.1250,  1.2153, -0.0195,  0.0385, -0.7129],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -156.788818359375
Adjusted likelihood: -156.788818359375
Likelihood residual: 0.0
Original likelihood: -151.7428741455078
Adjusted likelihood: -151.7428741455078
Likelihood residual: 0.0
{'index': 151.7428741455078, 'thumb_middle': 156.788818359375}
Current yaw: tensor([-0.0122,  0.0505, -0.0766], device='cuda:1')
7 index
tensor([ 0.0319,  0.6531,  0.4097,  0.5693, -0.1877,  0.5357,  0.8497,  0.9566,
         1.4267,  0.2720,  0.0894,  1.1403, -0.0122,  0.0505, -0.0766, -5.7052],
       device='cuda:1')
Solve time for step 1 9.839901670988183
Current ori: tensor([-0.0122,  0.0505, -0.0766], device='cuda:1')
Middle force: tensor([0.5619, 0.5416, 0.5177, 0.5656], device='cuda:1')
Thumb force: tensor([0.5630, 0.6152, 0.5134, 0.5790], device='cuda:1')
tensor([ 0.0894,  0.5725,  0.3816,  0.5778, -0.1956,  0.5232,  0.8839,  0.9506,
         1.4349,  0.2671,  0.0683,  1.1650, -0.0131,  0.0504, -0.0888, -5.0701],
       device='cuda:1')
Solve time for step 2 4.132599783013575
Current ori: tensor([-0.0131,  0.0504, -0.0888], device='cuda:1')
Middle force: tensor([0.5400, 0.5157, 0.5601], device='cuda:1')
Thumb force: tensor([0.6039, 0.5120, 0.5742], device='cuda:1')
tensor([ 0.0889,  0.5745,  0.3761,  0.5725, -0.1936,  0.5226,  0.8866,  0.9488,
         1.4319,  0.2725,  0.0652,  1.1720, -0.0133,  0.0491, -0.0910, -4.8186],
       device='cuda:1')
Solve time for step 3 3.748229854973033
Current ori: tensor([-0.0133,  0.0491, -0.0910], device='cuda:1')
Middle force: tensor([0.5001, 0.5005], device='cuda:1')
Thumb force: tensor([0.5630, 0.5023], device='cuda:1')
tensor([ 0.0877,  0.5724,  0.3783,  0.5762, -0.1892,  0.5233,  0.8885,  0.9509,
         1.4324,  0.2703,  0.0525,  1.1885, -0.0132,  0.0458, -0.0952, -4.8481],
       device='cuda:1')
Solve time for step 4 3.612302916997578
Current ori: tensor([-0.0132,  0.0458, -0.0952], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5589], device='cuda:1')
Storing RECOVERY transition: reward=0.0260 (scaled=0.0260), steps=1
Reward stats updated: mean 0.0079 -> 0.0105, std: 0.0108
Collected 7 transitions for RL
Original likelihood: -158.6496124267578
Adjusted likelihood: -158.6496124267578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 155.56967163085938
Projection step: 1, Loss: 149.04196166992188
Projection step: 2, Loss: 147.6224365234375
Projection step: 3, Loss: 140.25315856933594
Projection step: 4, Loss: 138.59434509277344
Projection step: 5, Loss: 141.540283203125
Projection step: 6, Loss: 131.10122680664062
Projection step: 7, Loss: 126.03706359863281
Projection step: 8, Loss: 115.44316864013672
Projection step: 9, Loss: 123.27967834472656
Projection step: 10, Loss: 120.52073669433594
Projection step: 11, Loss: 111.25843811035156
Projection step: 12, Loss: 110.9271240234375
Projection step: 13, Loss: 107.31294250488281
Projection step: 14, Loss: 99.81135559082031
Final likelihood: tensor([-104.3913, -101.0023, -103.2462,  -90.2497, -101.4512,  -98.1792,
         -93.8316, -101.2446,  -94.6067,  -99.7243,  -96.9844,  -97.2197,
        -104.3001, -106.9237, -101.4408, -102.1860])
Final projection likelihood: -99.8113
1 mode projection succeeded
New goal: tensor([ 0.0449,  0.6344,  0.4406,  0.6212, -0.1425,  0.4852,  0.8661,  0.9149,
         1.3643,  0.2524,  0.1083,  1.2173, -0.0212,  0.0362, -0.6746],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -125.91059875488281
Adjusted likelihood: -125.91059875488281
Likelihood residual: 0.0
Original likelihood: -165.18019104003906
Adjusted likelihood: -165.18019104003906
Likelihood residual: 0.0
{'index': 165.18019104003906, 'thumb_middle': 125.91059875488281}
Current yaw: tensor([-0.0161,  0.0444, -0.0945], device='cuda:1')
8 thumb_middle
tensor([ 0.0380,  0.6392,  0.4214,  0.5966, -0.1861,  0.5284,  0.8851,  0.9443,
         1.4275,  0.2807,  0.0477,  1.1967, -0.0161,  0.0444, -0.0945, -4.8963],
       device='cuda:1')
Solve time for step 1 8.681983424001373
Current ori: tensor([-0.0161,  0.0444, -0.0945], device='cuda:1')
Index force: tensor([0.5789, 0.5717, 0.5862, 0.5761], device='cuda:1')
tensor([ 0.0476,  0.6559,  0.4088,  0.5930, -0.2207,  0.4804,  0.8487,  0.9050,
         1.3394,  0.2346,  0.0208,  1.1909, -0.0203,  0.0387, -0.0945, -4.8928],
       device='cuda:1')
Solve time for step 2 3.5574599310057238
Current ori: tensor([-0.0203,  0.0387, -0.0945], device='cuda:1')
Index force: tensor([0.5626, 0.5777, 0.5695], device='cuda:1')
tensor([ 0.0510,  0.6433,  0.4276,  0.5977, -0.2191,  0.4888,  0.8420,  0.8861,
         1.3348,  0.2198,  0.0267,  1.1917, -0.0174,  0.0371, -0.0945, -4.8842],
       device='cuda:1')
Solve time for step 3 3.476447784982156
Current ori: tensor([-0.0174,  0.0371, -0.0945], device='cuda:1')
Index force: tensor([0.5679, 0.5618], device='cuda:1')
tensor([ 0.0376,  0.6303,  0.4261,  0.6115, -0.2254,  0.4851,  0.8427,  0.8969,
         1.3337,  0.2333,  0.0349,  1.1964, -0.0130,  0.0451, -0.0945, -4.8962],
       device='cuda:1')
Solve time for step 4 3.338230277004186
Current ori: tensor([-0.0130,  0.0451, -0.0945], device='cuda:1')
Index force: tensor([0.5587], device='cuda:1')
Storing RECOVERY transition: reward=0.0315 (scaled=0.0315), steps=1
Reward stats updated: mean 0.0105 -> 0.0131, std: 0.0122
Collected 8 transitions for RL
Original likelihood: -159.21609497070312
Adjusted likelihood: -159.21609497070312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 157.48666381835938
Projection step: 1, Loss: 152.610107421875
Projection step: 2, Loss: 143.19723510742188
Projection step: 3, Loss: 138.6421661376953
Projection step: 4, Loss: 130.99786376953125
Projection step: 5, Loss: 121.49002075195312
Projection step: 6, Loss: 119.82075500488281
Projection step: 7, Loss: 114.09892272949219
Projection step: 8, Loss: 103.73320770263672
Final likelihood: tensor([-101.2111,  -97.4243, -100.3086,  -96.1274,  -97.8833, -102.4511,
        -101.8227, -101.0597,  -98.6888, -118.4112, -102.1869,  -99.5204,
        -123.4595, -107.2073, -105.9454, -106.0236])
Final projection likelihood: -103.7332
1 mode projection succeeded
New goal: tensor([ 0.0448,  0.6131,  0.4602,  0.6248, -0.1414,  0.5003,  0.8514,  0.9053,
         1.3411,  0.2332,  0.1264,  1.2267, -0.0126,  0.0351, -0.3396],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -147.47640991210938
Adjusted likelihood: -147.47640991210938
Likelihood residual: 0.0
Original likelihood: -142.5020294189453
Adjusted likelihood: -142.5020294189453
Likelihood residual: 0.0
{'index': 142.5020294189453, 'thumb_middle': 147.47640991210938}
Current yaw: tensor([-0.0096,  0.0429, -0.0997], device='cuda:1')
9 index
tensor([ 0.0413,  0.6191,  0.4397,  0.6230, -0.1649,  0.5231,  0.8665,  0.9253,
         1.3945,  0.2507,  0.0970,  1.2250, -0.0096,  0.0429, -0.0997, -4.8715],
       device='cuda:1')
Solve time for step 1 10.099264468997717
Current ori: tensor([-0.0096,  0.0429, -0.0997], device='cuda:1')
Middle force: tensor([0.5438, 0.5675, 0.5397, 0.5324], device='cuda:1')
Thumb force: tensor([0.6059, 0.6303, 0.6395, 0.6144], device='cuda:1')
tensor([ 0.0919,  0.5519,  0.4064,  0.5987, -0.1735,  0.5252,  0.8815,  0.9248,
         1.4010,  0.2590,  0.0838,  1.2185, -0.0185,  0.0432, -0.1183, -3.2514],
       device='cuda:1')
Solve time for step 2 4.212852457014378
Current ori: tensor([-0.0185,  0.0432, -0.1183], device='cuda:1')
Middle force: tensor([0.5761, 0.6046, 0.5904], device='cuda:1')
Thumb force: tensor([0.5473, 0.5975, 0.5843], device='cuda:1')
tensor([ 0.0938,  0.5506,  0.4076,  0.5988, -0.1762,  0.5301,  0.8798,  0.9214,
         1.4068,  0.2508,  0.0818,  1.2135, -0.0210,  0.0438, -0.1175, -2.4416],
       device='cuda:1')
Solve time for step 3 4.1540140570141375
Current ori: tensor([-0.0210,  0.0438, -0.1175], device='cuda:1')
Middle force: tensor([0.5373, 0.5760], device='cuda:1')
Thumb force: tensor([0.5719, 0.5478], device='cuda:1')
tensor([ 0.0939,  0.5504,  0.4074,  0.5976, -0.1797,  0.5274,  0.8806,  0.9264,
         1.4078,  0.2631,  0.0742,  1.2205, -0.0232,  0.0460, -0.1371, -1.9771],
       device='cuda:1')
Solve time for step 4 3.766290556988679
Current ori: tensor([-0.0232,  0.0460, -0.1371], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5020], device='cuda:1')
Storing RECOVERY transition: reward=0.0738 (scaled=0.0738), steps=1
Reward stats updated: mean 0.0131 -> 0.0199, std: 0.0223
Collected 9 transitions for RL
Original likelihood: -139.1297607421875
Adjusted likelihood: -139.1297607421875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0224,  0.0466, -0.1431], device='cuda:1')
10 turn
Sampling time 3.560832543997094
tensor([ 0.0406,  0.6138,  0.4489,  0.6188, -0.1806,  0.5245,  0.8823,  0.9298,
         1.4023,  0.2757,  0.0669,  1.2414, -0.0224,  0.0466, -0.1431, -1.8677],
       device='cuda:1')
Original likelihood: -135.08412170410156
Adjusted likelihood: -135.08412170410156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.167490750958677
Current ori: tensor([-0.0224,  0.0466, -0.1431], device='cuda:1')
Middle force: tensor([0.5652, 0.5566, 1.0826, 0.5879, 0.6472, 0.5749, 0.8504, 0.5898, 0.5107,
        0.5622, 0.6443, 0.6513], device='cuda:1')
Thumb force: tensor([0.6218, 0.5776, 0.5778, 0.5551, 0.9925, 0.6220, 0.5996, 0.5858, 0.5585,
        0.5670, 0.6056, 0.7955], device='cuda:1')
Index force: tensor([0.6013, 1.0914, 0.7374, 0.5586, 0.6000, 0.6294, 0.5097, 0.5943, 0.6351,
        0.5504, 0.5160, 0.5894], device='cuda:1')
Storing NORMAL transition: reward=-0.0001 (scaled=-0.0001), steps=1
Reward stats updated: mean 0.0199 -> 0.0179, std: 0.0220
Collected 10 transitions for RL
tensor([ 0.0647,  0.6837,  0.3930,  0.5542, -0.1762,  0.4976,  0.9506,  0.8880,
         1.4616,  0.3139, -0.1011,  1.2234, -0.0427,  0.0332, -0.1432, -1.8771],
       device='cuda:1')
Original likelihood: -189.44125366210938
Adjusted likelihood: -189.44125366210938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 178.07553100585938
Projection step: 1, Loss: 156.94451904296875
Projection step: 2, Loss: 165.08447265625
Projection step: 3, Loss: 167.00608825683594
Projection step: 4, Loss: 153.41400146484375
Projection step: 5, Loss: 142.15768432617188
Projection step: 6, Loss: 143.7294921875
Projection step: 7, Loss: 154.67816162109375
Projection step: 8, Loss: 138.5455780029297
Projection step: 9, Loss: 137.92764282226562
Projection step: 10, Loss: 135.31851196289062
Projection step: 11, Loss: 127.53246307373047
Projection step: 12, Loss: 131.30712890625
Projection step: 13, Loss: 126.58697509765625
Projection step: 14, Loss: 128.49835205078125
Projection step: 15, Loss: 120.61097717285156
Projection step: 16, Loss: 119.42892456054688
Projection step: 17, Loss: 121.46788024902344
Projection step: 18, Loss: 121.81094360351562
Projection step: 19, Loss: 114.3824462890625
Projection step: 20, Loss: 114.14188385009766
Projection step: 21, Loss: 113.18045043945312
Projection step: 22, Loss: 114.20875549316406
Projection step: 23, Loss: 113.42460632324219
Projection step: 24, Loss: 109.520263671875
Final likelihood: tensor([-125.1947, -112.6244, -105.3579, -103.2041, -102.6922, -110.5730,
        -109.2357, -111.1041,  -92.9870, -103.0989, -112.6936, -115.3123,
        -118.0437, -116.9431, -100.7874, -108.5672])
Final projection likelihood: -109.2762
1 mode projection succeeded
New goal: tensor([ 0.0538,  0.6729,  0.3781,  0.6339, -0.0776,  0.4609,  0.7816,  0.9387,
         1.4300,  0.2793,  0.0463,  1.1217, -0.0447,  0.0248,  0.4153],
       device='cuda:1')
tensor([[0.0055]], device='cuda:1') tensor([[0.0044]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -135.63037109375
Adjusted likelihood: -135.63037109375
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 135.63037109375}
Current yaw: tensor([-0.0427,  0.0332, -0.1432], device='cuda:1')
11 thumb_middle
tensor([ 0.0647,  0.6837,  0.3930,  0.5542, -0.1762,  0.4976,  0.9506,  0.8880,
         1.4616,  0.3139, -0.1011,  1.2234, -0.0427,  0.0332, -0.1432, -1.8771],
       device='cuda:1')
Solve time for step 1 8.8637363720336
Current ori: tensor([-0.0427,  0.0332, -0.1432], device='cuda:1')
Index force: tensor([0.5872, 0.5526, 0.5940, 0.5820], device='cuda:1')
tensor([ 0.0598,  0.6858,  0.3712,  0.5891, -0.1732,  0.4529,  0.7897,  0.9164,
         1.3985,  0.2702, -0.0413,  1.1109, -0.0402,  0.0355, -0.1432, -1.8727],
       device='cuda:1')
Solve time for step 2 3.4879668779904023
Current ori: tensor([-0.0402,  0.0355, -0.1432], device='cuda:1')
Index force: tensor([0.5482, 0.5885, 0.5784], device='cuda:1')
tensor([ 0.0592,  0.6794,  0.3721,  0.6159, -0.1638,  0.4577,  0.7694,  0.9233,
         1.3990,  0.2619, -0.0359,  1.0948, -0.0367,  0.0350, -0.1432, -1.8623],
       device='cuda:1')
Solve time for step 3 3.4167301270063035
Current ori: tensor([-0.0367,  0.0350, -0.1432], device='cuda:1')
Index force: tensor([0.5793, 0.5717], device='cuda:1')
tensor([ 0.0511,  0.6784,  0.3644,  0.6185, -0.1663,  0.4551,  0.7635,  0.9241,
         1.3983,  0.2637, -0.0296,  1.0924, -0.0360,  0.0399, -0.1432, -1.8725],
       device='cuda:1')
Solve time for step 4 3.1525354139739648
Current ori: tensor([-0.0360,  0.0399, -0.1432], device='cuda:1')
Index force: tensor([0.5641], device='cuda:1')
Storing RECOVERY transition: reward=0.0020 (scaled=0.0020), steps=1
Reward stats updated: mean 0.0179 -> 0.0164, std: 0.0214
Collected 11 transitions for RL
Original likelihood: -146.30416870117188
Adjusted likelihood: -146.30416870117188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9781)
Current yaw: tensor([-0.0330,  0.0431, -0.1453], device='cuda:1')
12 turn
Sampling time 3.590818285010755
tensor([ 0.0451,  0.6703,  0.3648,  0.6325, -0.1065,  0.5046,  0.7907,  0.9352,
         1.4625,  0.2793,  0.0187,  1.1219, -0.0330,  0.0431, -0.1453, -1.8684],
       device='cuda:1')
Original likelihood: -151.56924438476562
Adjusted likelihood: -151.56924438476562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1959)
State is out of distribution
Projection step: 0, Loss: 137.62229919433594
Projection step: 1, Loss: 151.9807586669922
Projection step: 2, Loss: 146.80226135253906
Projection step: 3, Loss: 137.54806518554688
Projection step: 4, Loss: 131.89942932128906
Projection step: 5, Loss: 136.9996337890625
Projection step: 6, Loss: 134.04818725585938
Projection step: 7, Loss: 134.58921813964844
Projection step: 8, Loss: 129.05001831054688
Projection step: 9, Loss: 129.33773803710938
Projection step: 10, Loss: 125.80422973632812
Projection step: 11, Loss: 123.17742919921875
Projection step: 12, Loss: 118.497802734375
Projection step: 13, Loss: 118.40882873535156
Projection step: 14, Loss: 119.87075805664062
Projection step: 15, Loss: 113.5071792602539
Projection step: 16, Loss: 113.4649887084961
Projection step: 17, Loss: 109.8887710571289
Projection step: 18, Loss: 107.6225357055664
Projection step: 19, Loss: 107.8021469116211
Projection step: 20, Loss: 105.21363830566406
Projection step: 21, Loss: 102.93055725097656
Final likelihood: tensor([-103.1950, -102.6916, -105.1275, -109.1766, -106.8800,  -99.5137,
        -110.5491,  -99.6121, -103.2247, -107.2643, -100.7011, -101.5380,
        -111.2234,  -97.2454, -101.8813,  -87.0654])
Final projection likelihood: -102.9306
1 mode projection succeeded
New goal: tensor([ 0.0418,  0.6519,  0.3839,  0.6713, -0.0780,  0.4835,  0.7545,  0.9655,
         1.4146,  0.2629,  0.0811,  1.1267, -0.0392,  0.0260, -0.8044],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -159.34326171875
Adjusted likelihood: -159.34326171875
Likelihood residual: 0.0
Original likelihood: -130.02059936523438
Adjusted likelihood: -130.02059936523438
Likelihood residual: 0.0
{'index': 130.02059936523438, 'thumb_middle': 159.34326171875}
Current yaw: tensor([-0.0330,  0.0431, -0.1453], device='cuda:1')
13 index
tensor([ 0.0451,  0.6703,  0.3648,  0.6325, -0.1065,  0.5046,  0.7907,  0.9352,
         1.4625,  0.2793,  0.0187,  1.1219, -0.0330,  0.0431, -0.1453, -1.8684],
       device='cuda:1')
Solve time for step 1 10.450107740005478
Current ori: tensor([-0.0330,  0.0431, -0.1453], device='cuda:1')
Middle force: tensor([0.5210, 0.5172, 0.5124, 0.5173], device='cuda:1')
Thumb force: tensor([0.5389, 0.5486, 0.6841, 0.6685], device='cuda:1')
tensor([ 0.0852,  0.5853,  0.3290,  0.6390, -0.0997,  0.5153,  0.7699,  0.9596,
         1.4586,  0.2841,  0.0151,  1.1231, -0.0337,  0.0385, -0.1532, -6.1651],
       device='cuda:1')
Solve time for step 2 4.09884366299957
Current ori: tensor([-0.0337,  0.0385, -0.1532], device='cuda:1')
Middle force: tensor([0.5600, 0.5001, 0.5512], device='cuda:1')
Thumb force: tensor([0.6139, 0.5202, 0.6272], device='cuda:1')
tensor([ 0.0850,  0.5823,  0.3285,  0.6442, -0.1149,  0.5085,  0.7648,  0.9657,
         1.4573,  0.2977,  0.0387,  1.1007, -0.0331,  0.0488, -0.1592,  3.8639],
       device='cuda:1')
Solve time for step 3 3.903651941975113
Current ori: tensor([-0.0331,  0.0488, -0.1592], device='cuda:1')
Middle force: tensor([0.5001, 0.5468], device='cuda:1')
Thumb force: tensor([0.5169, 0.6189], device='cuda:1')
tensor([ 0.0856,  0.5824,  0.3279,  0.6411, -0.1117,  0.5120,  0.7655,  0.9723,
         1.4662,  0.2838,  0.0109,  1.1293, -0.0355,  0.0452, -0.1678,  2.2481],
       device='cuda:1')
Solve time for step 4 3.9002251260099
Current ori: tensor([-0.0355,  0.0452, -0.1678], device='cuda:1')
Middle force: tensor([0.5434], device='cuda:1')
Thumb force: tensor([0.6053], device='cuda:1')
Storing RECOVERY transition: reward=0.0172 (scaled=0.0172), steps=0
Reward stats updated: mean 0.0164 -> 0.0165, std: 0.0205
Collected 12 transitions for RL
Original likelihood: -140.6265106201172
Adjusted likelihood: -140.6265106201172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0409,  0.0441, -0.1633], device='cuda:1')
14 turn
Sampling time 3.549863398016896
tensor([ 0.0355,  0.6490,  0.3691,  0.6643, -0.1089,  0.5246,  0.7579,  0.9536,
         1.4612,  0.2942,  0.0152,  1.1182, -0.0409,  0.0441, -0.1633,  1.8088],
       device='cuda:1')
Original likelihood: -143.02059936523438
Adjusted likelihood: -143.02059936523438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 14.067519237985834
Current ori: tensor([-0.0409,  0.0441, -0.1633], device='cuda:1')
Middle force: tensor([0.9720, 0.6016, 0.6125, 0.5291, 0.6119, 0.5750, 0.5681, 0.5655, 1.3612,
        0.5179, 0.5519, 0.6958], device='cuda:1')
Thumb force: tensor([0.8830, 0.5651, 0.5963, 1.2433, 0.5968, 0.5852, 0.5361, 0.6338, 0.5226,
        0.5912, 1.3236, 0.6761], device='cuda:1')
Index force: tensor([0.5848, 0.6040, 0.6153, 0.5432, 0.5838, 0.5988, 0.5294, 0.6080, 0.6298,
        0.5117, 0.5050, 0.5981], device='cuda:1')
Storing NORMAL transition: reward=-0.0878 (scaled=-0.0878), steps=1
Reward stats updated: mean 0.0165 -> 0.0085, std: 0.0341
Collected 13 transitions for RL
tensor([-0.0186,  0.5551,  0.4410,  0.6878, -0.0968,  0.5034,  0.8215,  0.8890,
         1.4493,  0.2550,  0.0343,  1.1331, -0.0206,  0.0349, -0.0733,  2.0014],
       device='cuda:1')
Original likelihood: -140.2625274658203
Adjusted likelihood: -140.2625274658203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.492925962025765
Current ori: tensor([-0.0206,  0.0349, -0.0733], device='cuda:1')
Middle force: tensor([0.6012, 0.6194, 0.5328, 0.6128, 0.5868, 0.5665, 0.5761, 1.3551, 0.5215,
        0.5564, 0.6952], device='cuda:1')
Thumb force: tensor([0.5583, 0.5866, 1.1974, 0.5909, 0.5691, 0.5341, 0.6082, 0.5205, 0.5755,
        1.2870, 0.6671], device='cuda:1')
Index force: tensor([0.6020, 0.6104, 0.5432, 0.5787, 0.5971, 0.5285, 0.6072, 0.6194, 0.5109,
        0.5046, 0.5945], device='cuda:1')
Storing NORMAL transition: reward=0.0738 (scaled=0.0738), steps=1
Reward stats updated: mean 0.0085 -> 0.0131, std: 0.0369
Collected 14 transitions for RL
tensor([ 0.0091,  0.5293,  0.4559,  0.7777, -0.0754,  0.4725,  0.8590,  0.9370,
         1.4706,  0.2107,  0.0199,  1.1189, -0.0084,  0.0200, -0.1462,  2.0602],
       device='cuda:1')
Original likelihood: -108.70538330078125
Adjusted likelihood: -108.70538330078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.196042905037757
Current ori: tensor([-0.0084,  0.0200, -0.1462], device='cuda:1')
Middle force: tensor([0.6140, 0.5319, 0.6096, 0.5872, 0.5640, 0.5765, 1.3391, 0.5218, 0.5560,
        0.6902], device='cuda:1')
Thumb force: tensor([0.5800, 1.1767, 0.5867, 0.5649, 0.5326, 0.6014, 0.5191, 0.5715, 1.2623,
        0.6617], device='cuda:1')
Index force: tensor([0.6047, 0.5414, 0.5754, 0.5930, 0.5272, 0.6032, 0.6133, 0.5101, 0.5042,
        0.5914], device='cuda:1')
Storing NORMAL transition: reward=0.0747 (scaled=0.0747), steps=1
Reward stats updated: mean 0.0131 -> 0.0172, std: 0.0388
Collected 15 transitions for RL
tensor([ 3.5449e-02,  5.0888e-01,  4.8567e-01,  8.2231e-01, -5.1989e-02,
         4.6278e-01,  8.6643e-01,  9.9586e-01,  1.4869e+00,  1.7260e-01,
         9.2446e-03,  1.0987e+00, -1.8717e-03,  4.9118e-03, -2.2050e-01,
         2.1702e+00], device='cuda:1')
Original likelihood: -107.45806884765625
Adjusted likelihood: -107.45806884765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.131584574002773
Current ori: tensor([-0.0019,  0.0049, -0.2205], device='cuda:1')
Middle force: tensor([0.5288, 0.6064, 0.5862, 0.5618, 0.5754, 1.3222, 0.5214, 0.5550, 0.6848],
       device='cuda:1')
Thumb force: tensor([1.1584, 0.5823, 0.5617, 0.5309, 0.5961, 0.5177, 0.5686, 1.2386, 0.6565],
       device='cuda:1')
Index force: tensor([0.5390, 0.5717, 0.5890, 0.5259, 0.5997, 0.6079, 0.5094, 0.5039, 0.5882],
       device='cuda:1')
Storing NORMAL transition: reward=0.0395 (scaled=0.0395), steps=1
Reward stats updated: mean 0.0172 -> 0.0186, std: 0.0380
Collected 16 transitions for RL
tensor([ 3.7658e-02,  4.8998e-01,  5.0016e-01,  8.4993e-01, -5.3719e-02,
         4.5278e-01,  8.7150e-01,  1.0120e+00,  1.4922e+00,  1.6798e-01,
         1.7712e-02,  1.0788e+00,  1.0200e-04,  5.3004e-03, -2.6003e-01,
         2.0605e+00], device='cuda:1')
Original likelihood: -103.02644348144531
Adjusted likelihood: -103.02644348144531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 5 4.773658028978389
Current ori: tensor([ 1.0200e-04,  5.3004e-03, -2.6003e-01], device='cuda:1')
Middle force: tensor([0.5999, 0.5836, 0.5596, 0.5727, 1.3038, 0.5204, 0.5533, 0.6791],
       device='cuda:1')
Thumb force: tensor([0.5790, 0.5595, 0.5293, 0.5925, 0.5166, 0.5666, 1.2172, 0.6518],
       device='cuda:1')
Index force: tensor([0.5675, 0.5858, 0.5248, 0.5969, 0.6031, 0.5089, 0.5036, 0.5854],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0722 (scaled=-0.0722), steps=1
Reward stats updated: mean 0.0186 -> 0.0133, std: 0.0426
Collected 17 transitions for RL
tensor([ 0.1560,  0.5162,  0.5455,  0.8185,  0.0448,  0.5724,  0.8440,  0.9424,
         1.4061,  0.1345,  0.0474,  1.0367, -0.0077, -0.0688, -0.1926,  3.4246],
       device='cuda:1')
Original likelihood: -160.56521606445312
Adjusted likelihood: -160.56521606445312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 149.6934356689453
Projection step: 1, Loss: 148.8132781982422
Projection step: 2, Loss: 143.49049377441406
Projection step: 3, Loss: 140.44412231445312
Projection step: 4, Loss: 138.4770050048828
Projection step: 5, Loss: 143.61083984375
Projection step: 6, Loss: 137.9241180419922
Projection step: 7, Loss: 139.01116943359375
Projection step: 8, Loss: 141.94442749023438
Projection step: 9, Loss: 140.61355590820312
Projection step: 10, Loss: 135.35801696777344
Projection step: 11, Loss: 138.23550415039062
Projection step: 12, Loss: 137.60665893554688
Projection step: 13, Loss: 135.26593017578125
Projection step: 14, Loss: 139.94772338867188
Projection step: 15, Loss: 130.88909912109375
Projection step: 16, Loss: 131.60098266601562
Projection step: 17, Loss: 127.05711364746094
Projection step: 18, Loss: 122.98887634277344
Projection step: 19, Loss: 122.36756896972656
Projection step: 20, Loss: 127.62938690185547
Projection step: 21, Loss: 120.99757385253906
Projection step: 22, Loss: 118.11027526855469
Projection step: 23, Loss: 109.36863708496094
Projection step: 24, Loss: 108.02436065673828
Final likelihood: tensor([-137.5686, -109.9504, -145.5114, -107.2237, -132.2552, -102.0621,
         -96.4191,  -95.4568, -101.4216, -103.7135, -136.8585, -152.2868,
        -109.3400, -143.5843,  -92.9098, -101.9704])
Final projection likelihood: -116.7832
1 mode projection succeeded
New goal: tensor([ 0.1186,  0.4756,  0.6097,  0.8572,  0.0317,  0.5740,  0.8631,  0.7467,
         1.3695,  0.1483,  0.1498,  0.8848, -0.0116, -0.0580, -0.7475],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0051]], device='cuda:1')
Original likelihood: -189.938720703125
Adjusted likelihood: -189.938720703125
Likelihood residual: 0.0
{'index': 189.938720703125, 'thumb_middle': inf}
Current yaw: tensor([-0.0077, -0.0688, -0.1926], device='cuda:1')
15 index
tensor([ 0.1560,  0.5162,  0.5455,  0.8185,  0.0448,  0.5724,  0.8440,  0.9424,
         1.4061,  0.1345,  0.0474,  1.0367, -0.0077, -0.0688, -0.1926,  3.4246],
       device='cuda:1')
Solve time for step 1 10.167508320009802
Current ori: tensor([-0.0077, -0.0688, -0.1926], device='cuda:1')
Middle force: tensor([0.5813, 0.5201, 0.5001, 0.5514], device='cuda:1')
Thumb force: tensor([0.5653, 0.5983, 0.6209, 0.5786], device='cuda:1')
tensor([ 0.1720,  0.4260,  0.5414,  0.8166,  0.0410,  0.5785,  0.8947,  0.8137,
         1.4016,  0.1597,  0.0732,  0.9532, -0.0302, -0.0682, -0.2186,  4.3217],
       device='cuda:1')
Solve time for step 2 4.204499613959342
Current ori: tensor([-0.0302, -0.0682, -0.2186], device='cuda:1')
Middle force: tensor([0.5375, 0.5315, 0.5560], device='cuda:1')
Thumb force: tensor([0.5827, 0.6299, 0.5852], device='cuda:1')
tensor([ 0.1697,  0.4210,  0.5469,  0.8146,  0.0380,  0.5850,  0.8975,  0.7814,
         1.4002,  0.1684,  0.0834,  0.9283, -0.0372, -0.0661, -0.2173,  4.5184],
       device='cuda:1')
Solve time for step 3 4.062381727970205
Current ori: tensor([-0.0372, -0.0661, -0.2173], device='cuda:1')
Middle force: tensor([0.5002, 0.5118], device='cuda:1')
Thumb force: tensor([0.5902, 0.5805], device='cuda:1')
tensor([ 0.1673,  0.4188,  0.5466,  0.8153,  0.0295,  0.5903,  0.8878,  0.7690,
         1.4105,  0.1543,  0.0899,  0.9131, -0.0413, -0.0597, -0.2059,  4.2418],
       device='cuda:1')
Solve time for step 4 4.081391915038694
Current ori: tensor([-0.0413, -0.0597, -0.2059], device='cuda:1')
Middle force: tensor([0.5105], device='cuda:1')
Thumb force: tensor([0.5933], device='cuda:1')
Storing RECOVERY transition: reward=0.0192 (scaled=0.0038), steps=5
Reward stats updated: mean 0.0133 -> 0.0128, std: 0.0414
Collected 18 transitions for RL
Original likelihood: -133.35096740722656
Adjusted likelihood: -133.35096740722656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0446, -0.0561, -0.2124], device='cuda:1')
16 turn
Sampling time 3.5796025909949094
tensor([ 0.1215,  0.4724,  0.5911,  0.8462,  0.0247,  0.5911,  0.8847,  0.7633,
         1.4078,  0.1696,  0.0964,  0.9037, -0.0446, -0.0561, -0.2124,  4.0859],
       device='cuda:1')
Original likelihood: -135.45138549804688
Adjusted likelihood: -135.45138549804688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.833267073030584
Current ori: tensor([-0.0446, -0.0561, -0.2124], device='cuda:1')
Middle force: tensor([1.0574, 1.1072, 0.5803, 0.5810, 0.5057, 0.5701, 1.0917, 1.0800, 0.5383,
        0.5204, 0.5037, 0.5779], device='cuda:1')
Thumb force: tensor([0.6144, 2.1119, 1.3658, 0.5169, 1.5040, 0.6148, 0.9947, 0.5599, 0.5160,
        0.6772, 0.6114, 0.5317], device='cuda:1')
Index force: tensor([0.5256, 0.5798, 0.5649, 0.6689, 0.5443, 0.6110, 0.9428, 0.5075, 0.6537,
        0.6551, 0.6576, 0.5463], device='cuda:1')
Storing NORMAL transition: reward=0.0676 (scaled=0.0676), steps=1
Reward stats updated: mean 0.0128 -> 0.0156, std: 0.0421
Collected 19 transitions for RL
tensor([ 0.0768,  0.4271,  0.6561,  0.7636,  0.0238,  0.5956,  0.8650,  0.7876,
         1.4136,  0.1746,  0.1277,  0.8241, -0.0531, -0.0551, -0.2815,  4.6732],
       device='cuda:1')
Original likelihood: -144.60556030273438
Adjusted likelihood: -144.60556030273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9984)
Solve time for step 2 5.3168852719827555
Current ori: tensor([-0.0531, -0.0551, -0.2815], device='cuda:1')
Middle force: tensor([1.1627, 0.5426, 0.6786, 0.8032, 0.5511, 0.5076, 0.5963, 0.6141, 0.7804,
        0.6024, 0.6929], device='cuda:1')
Thumb force: tensor([0.8058, 0.5021, 0.6055, 0.7797, 1.5984, 0.5626, 0.5275, 0.5641, 0.8329,
        0.6050, 0.5486], device='cuda:1')
Index force: tensor([0.9390, 0.7087, 0.5181, 0.6037, 0.6153, 0.5603, 0.5803, 0.5708, 0.5389,
        0.6042, 0.5531], device='cuda:1')
Storing NORMAL transition: reward=0.1146 (scaled=0.1146), steps=1
Reward stats updated: mean 0.0156 -> 0.0206, std: 0.0464
Collected 20 transitions for RL
tensor([ 0.0528,  0.2878,  0.6936,  1.0215, -0.0247,  0.6106,  0.7037,  0.9603,
         1.4727,  0.2795,  0.2070,  0.6070, -0.0431, -0.0154, -0.3927,  4.4382],
       device='cuda:1')
Original likelihood: -168.05404663085938
Adjusted likelihood: -168.05404663085938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 198.73410034179688
Projection step: 1, Loss: 154.366943359375
Projection step: 2, Loss: 161.3092041015625
Projection step: 3, Loss: 155.63096618652344
Projection step: 4, Loss: 158.5164794921875
Projection step: 5, Loss: 141.11270141601562
Projection step: 6, Loss: 151.3721466064453
Projection step: 7, Loss: 135.8836669921875
Projection step: 8, Loss: 142.334716796875
Projection step: 9, Loss: 141.5787353515625
Projection step: 10, Loss: 132.2745819091797
Projection step: 11, Loss: 131.5279083251953
Projection step: 12, Loss: 127.08711242675781
Projection step: 13, Loss: 124.04537963867188
Projection step: 14, Loss: 121.04712677001953
Projection step: 15, Loss: 121.05531311035156
Projection step: 16, Loss: 112.0539321899414
Projection step: 17, Loss: 117.72283935546875
Projection step: 18, Loss: 112.44401550292969
Projection step: 19, Loss: 104.23464965820312
Final likelihood: tensor([ -95.4546, -103.4985, -106.2709, -112.5554, -113.1459, -107.8003,
         -86.4866, -112.3986, -105.8202, -107.3751, -109.3941, -107.1509,
         -79.9043,  -97.8722, -106.6509, -115.9761])
Final projection likelihood: -104.2347
1 mode projection succeeded
New goal: tensor([ 0.0718,  0.4469,  0.5717,  0.8461, -0.0358,  0.5947,  0.7359,  0.9741,
         1.3991,  0.1714,  0.1993,  0.7164, -0.0416, -0.0102, -0.8212],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0020]], device='cuda:1')
Original likelihood: -179.21896362304688
Adjusted likelihood: -179.21896362304688
Likelihood residual: 0.0
Original likelihood: -141.39442443847656
Adjusted likelihood: -141.39442443847656
Likelihood residual: 0.0
{'index': 141.39442443847656, 'thumb_middle': 179.21896362304688}
Current yaw: tensor([-0.0431, -0.0154, -0.3927], device='cuda:1')
17 index
tensor([ 0.0528,  0.2878,  0.6936,  1.0215, -0.0247,  0.6106,  0.7037,  0.9603,
         1.4727,  0.2795,  0.2070,  0.6070, -0.0431, -0.0154, -0.3927,  4.4382],
       device='cuda:1')
Solve time for step 1 9.967537390009966
Current ori: tensor([-0.0431, -0.0154, -0.3927], device='cuda:1')
Middle force: tensor([0.5447, 0.5252, 0.5582, 0.5067], device='cuda:1')
Thumb force: tensor([0.5300, 0.5571, 0.5345, 0.6625], device='cuda:1')
tensor([ 0.0995,  0.3641,  0.5435,  0.8445, -0.0294,  0.5977,  0.7330,  0.9741,
         1.4974,  0.2153,  0.1635,  0.6702, -0.0358, -0.0186, -0.4016, -5.7765],
       device='cuda:1')
Solve time for step 2 3.9859106700168923
Current ori: tensor([-0.0358, -0.0186, -0.4016], device='cuda:1')
Middle force: tensor([0.5226, 0.5531, 0.5059], device='cuda:1')
Thumb force: tensor([0.5511, 0.5309, 0.6617], device='cuda:1')
tensor([ 0.1045,  0.3916,  0.5244,  0.8206, -0.0381,  0.6159,  0.7462,  0.9795,
         1.5000,  0.2036,  0.1451,  0.6847, -0.0374, -0.0264, -0.4089, -4.2283],
       device='cuda:1')
Solve time for step 3 3.8131311599863693
Current ori: tensor([-0.0374, -0.0264, -0.4089], device='cuda:1')
Middle force: tensor([0.5495, 0.5055], device='cuda:1')
Thumb force: tensor([0.5270, 0.6556], device='cuda:1')
tensor([ 0.1038,  0.3959,  0.5209,  0.8152, -0.0491,  0.6270,  0.7596,  0.9880,
         1.4979,  0.2085,  0.1281,  0.7115, -0.0361, -0.0306, -0.4198, -3.1254],
       device='cuda:1')
Solve time for step 4 3.755083876021672
Current ori: tensor([-0.0361, -0.0306, -0.4198], device='cuda:1')
Middle force: tensor([0.5067], device='cuda:1')
Thumb force: tensor([0.5002], device='cuda:1')
Storing RECOVERY transition: reward=0.0244 (scaled=0.0122), steps=2
Reward stats updated: mean 0.0206 -> 0.0202, std: 0.0453
Collected 21 transitions for RL
Original likelihood: -159.43881225585938
Adjusted likelihood: -159.43881225585938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 148.1286163330078
Projection step: 1, Loss: 146.2041473388672
Projection step: 2, Loss: 146.49452209472656
Projection step: 3, Loss: 132.38031005859375
Projection step: 4, Loss: 147.143310546875
Projection step: 5, Loss: 166.5462188720703
Projection step: 6, Loss: 132.74717712402344
Projection step: 7, Loss: 131.11785888671875
Projection step: 8, Loss: 129.29661560058594
Projection step: 9, Loss: 129.080322265625
Projection step: 10, Loss: 118.01969909667969
Projection step: 11, Loss: 119.94172668457031
Projection step: 12, Loss: 119.394287109375
Projection step: 13, Loss: 121.6030044555664
Projection step: 14, Loss: 114.88720703125
Projection step: 15, Loss: 115.94512939453125
Projection step: 16, Loss: 108.00447082519531
Projection step: 17, Loss: 109.41780090332031
Projection step: 18, Loss: 105.38438415527344
Projection step: 19, Loss: 103.71018981933594
Final likelihood: tensor([-122.4486,  -95.0380,  -88.0991, -131.8436, -119.4443,  -94.2942,
         -97.8831,  -95.5025, -132.6907,  -95.6480,  -90.2315,  -93.5700,
         -95.6660, -117.5471,  -94.7931,  -94.6634])
Final projection likelihood: -103.7102
1 mode projection succeeded
New goal: tensor([ 0.0804,  0.4652,  0.6105,  0.7713, -0.0304,  0.6433,  0.6963,  0.9702,
         1.4348,  0.2005,  0.1766,  0.7554, -0.0316, -0.0282, -0.4573],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -146.36944580078125
Adjusted likelihood: -146.36944580078125
Likelihood residual: 0.0
Original likelihood: -160.0123291015625
Adjusted likelihood: -160.0123291015625
Likelihood residual: 0.0
{'index': 160.0123291015625, 'thumb_middle': 146.36944580078125}
Current yaw: tensor([-0.0376, -0.0355, -0.4182], device='cuda:1')
18 thumb_middle
tensor([ 0.0534,  0.4487,  0.5647,  0.8427, -0.0597,  0.6517,  0.7612,  0.9802,
         1.4914,  0.2189,  0.1243,  0.7141, -0.0376, -0.0355, -0.4182, -2.8197],
       device='cuda:1')
Solve time for step 1 8.944382146990392
Current ori: tensor([-0.0376, -0.0355, -0.4182], device='cuda:1')
Index force: tensor([0.5675, 0.5872, 0.5886, 0.6014], device='cuda:1')
tensor([ 0.0652,  0.4590,  0.5963,  0.7825, -0.1066,  0.6348,  0.6844,  0.9498,
         1.4013,  0.1846,  0.0777,  0.7101, -0.0696, -0.0381, -0.4182, -3.0067],
       device='cuda:1')
Solve time for step 2 3.592901263036765
Current ori: tensor([-0.0696, -0.0381, -0.4182], device='cuda:1')
Index force: tensor([0.5001, 0.5476, 0.5950], device='cuda:1')
tensor([ 0.0534,  0.4716,  0.6263,  0.7770, -0.1188,  0.6424,  0.6763,  0.9518,
         1.3930,  0.1848,  0.0795,  0.7138, -0.1649, -0.0893, -0.4182, -2.8673],
       device='cuda:1')
Solve time for step 3 3.4996359280194156
Current ori: tensor([-0.1649, -0.0893, -0.4182], device='cuda:1')
Index force: tensor([0.5419, 0.5891], device='cuda:1')
tensor([ 0.0073,  0.5200,  0.6712,  0.8058, -0.0918,  0.6797,  0.6894,  0.9551,
         1.3582,  0.1730,  0.0205,  0.6875, -0.2677, -0.1478, -0.3332, -3.5644],
       device='cuda:1')
Solve time for step 4 3.314682256022934
Current ori: tensor([-0.2677, -0.1478, -0.3332], device='cuda:1')
Index force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=-0.3376 (scaled=-0.1688), steps=2
Reward stats updated: mean 0.0202 -> 0.0116, std: 0.0592
Collected 22 transitions for RL
Original likelihood: -1045.139404296875
Adjusted likelihood: -1045.139404296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 2
Loaded trajectory sampler
Current yaw: tensor([-0.0026,  0.0145, -0.0437], device='cuda:1')
Current yaw: tensor([-0.0026,  0.0145, -0.0437], device='cuda:1')
1 turn
Sampling time 3.808469759998843
tensor([ 0.1478,  0.6003,  0.5799,  0.6059, -0.1235,  0.5450,  0.8891,  0.9433,
         1.2298,  0.2943,  0.2471,  1.1775, -0.0026,  0.0145, -0.0437,  0.1129],
       device='cuda:1')
Original likelihood: -117.00547790527344
Adjusted likelihood: -117.00547790527344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.988337584014516
Current ori: tensor([-0.0026,  0.0145, -0.0437], device='cuda:1')
Middle force: tensor([0.6388, 0.5882, 0.6902, 0.5298, 0.6340, 1.0628, 0.5704, 0.5816, 0.4940,
        0.4963, 0.5843, 0.5019], device='cuda:1')
Thumb force: tensor([2.5028, 1.2604, 1.4226, 0.8679, 1.0459, 0.7922, 1.0236, 1.4176, 0.5521,
        0.5354, 0.5675, 0.5654], device='cuda:1')
Index force: tensor([0.6989, 0.5882, 0.5206, 1.0153, 1.0672, 0.5466, 0.5265, 0.6665, 0.7616,
        0.8190, 0.5972, 0.8400], device='cuda:1')
Storing NORMAL transition: reward=-0.0002 (scaled=-0.0002), steps=1
Reward stats updated: mean 0.0116 -> 0.0111, std: 0.0580
Collected 23 transitions for RL
tensor([ 0.1873,  0.6504,  0.5721,  0.5719, -0.1715,  0.5545,  0.8012,  0.9616,
         1.3022,  0.2346,  0.1629,  1.1015, -0.0153, -0.0175, -0.0437,  0.2515],
       device='cuda:1')
Original likelihood: -204.97976684570312
Adjusted likelihood: -204.97976684570312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 214.61795043945312
Projection step: 1, Loss: 203.6951904296875
Projection step: 2, Loss: 189.64495849609375
Projection step: 3, Loss: 179.11343383789062
Projection step: 4, Loss: 177.62269592285156
Projection step: 5, Loss: 162.07229614257812
Projection step: 6, Loss: 154.03244018554688
Projection step: 7, Loss: 149.2406463623047
Projection step: 8, Loss: 137.60345458984375
Projection step: 9, Loss: 133.3068389892578
Projection step: 10, Loss: 128.2881317138672
Projection step: 11, Loss: 123.18072509765625
Projection step: 12, Loss: 120.53726959228516
Projection step: 13, Loss: 124.62615203857422
Projection step: 14, Loss: 134.24652099609375
Projection step: 15, Loss: 116.99427795410156
Projection step: 16, Loss: 120.53471374511719
Projection step: 17, Loss: 122.6440200805664
Projection step: 18, Loss: 126.63069152832031
Projection step: 19, Loss: 118.40733337402344
Projection step: 20, Loss: 112.60704040527344
Projection step: 21, Loss: 117.21768951416016
Projection step: 22, Loss: 108.39736938476562
Projection step: 23, Loss: 108.94927978515625
Projection step: 24, Loss: 101.74818420410156
Final likelihood: tensor([ -95.0484,  -94.4552, -109.9043, -111.5579,  -91.2113,  -98.6022,
        -106.9505,  -90.5848, -105.0462, -117.8455, -101.9775, -101.8840,
        -112.2620,  -97.5679, -110.0542,  -83.0190])
Final projection likelihood: -101.7482
1 mode projection succeeded
New goal: tensor([ 0.1247,  0.5867,  0.5732,  0.5907, -0.0721,  0.5719,  0.9039,  0.8763,
         1.3269,  0.3005,  0.1803,  1.0838, -0.0112, -0.0074, -2.4394],
       device='cuda:1')
tensor([[0.0032]], device='cuda:1') tensor([[0.0124]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -156.5979766845703
Adjusted likelihood: -156.5979766845703
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 156.5979766845703}
Current yaw: tensor([-0.0153, -0.0175, -0.0437], device='cuda:1')
2 thumb_middle
tensor([ 0.1873,  0.6504,  0.5721,  0.5719, -0.1715,  0.5545,  0.8012,  0.9616,
         1.3022,  0.2346,  0.1629,  1.1015, -0.0153, -0.0175, -0.0437,  0.2515],
       device='cuda:1')
Solve time for step 1 8.89616288302932
Current ori: tensor([-0.0153, -0.0175, -0.0437], device='cuda:1')
Index force: tensor([0.5630, 0.5996, 0.5945, 0.5988], device='cuda:1')
tensor([ 0.1549,  0.6248,  0.5692,  0.5760, -0.1937,  0.5284,  0.8429,  0.8670,
         1.2829,  0.2689,  0.0970,  1.0508, -0.0104,  0.0032, -0.0437,  0.2115],
       device='cuda:1')
Solve time for step 2 3.6300144709530286
Current ori: tensor([-0.0104,  0.0032, -0.0437], device='cuda:1')
Index force: tensor([0.5876, 0.5845, 0.5891], device='cuda:1')
tensor([ 0.1676,  0.6303,  0.5740,  0.5789, -0.1919,  0.5408,  0.8583,  0.8540,
         1.2823,  0.2812,  0.0855,  1.0387, -0.0112, -0.0045, -0.0437,  0.2303],
       device='cuda:1')
Solve time for step 3 3.456459398032166
Current ori: tensor([-0.0112, -0.0045, -0.0437], device='cuda:1')
Index force: tensor([0.5712, 0.5773], device='cuda:1')
tensor([ 0.1574,  0.6194,  0.5744,  0.5852, -0.1963,  0.5330,  0.8567,  0.8481,
         1.2877,  0.2828,  0.0861,  1.0449, -0.0086,  0.0022, -0.0437,  0.2186],
       device='cuda:1')
Solve time for step 4 3.31271431298228
Current ori: tensor([-0.0086,  0.0022, -0.0437], device='cuda:1')
Index force: tensor([0.5732], device='cuda:1')
Storing RECOVERY transition: reward=-0.0013 (scaled=-0.0013), steps=1
Reward stats updated: mean 0.0111 -> 0.0106, std: 0.0568
Collected 24 transitions for RL
Original likelihood: -115.94468688964844
Adjusted likelihood: -115.94468688964844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0024,  0.0125, -0.0420], device='cuda:1')
3 turn
Sampling time 3.5605753430281766
tensor([ 0.1399,  0.5964,  0.5792,  0.6011, -0.1392,  0.5693,  0.8918,  0.8630,
         1.3452,  0.3046,  0.1604,  1.0698, -0.0024,  0.0125, -0.0420,  0.2086],
       device='cuda:1')
Original likelihood: -109.41252136230469
Adjusted likelihood: -109.41252136230469
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.975012417009566
Current ori: tensor([-0.0024,  0.0125, -0.0420], device='cuda:1')
Middle force: tensor([2.3893, 1.9254, 1.0704, 0.5045, 0.5081, 0.5207, 0.8480, 0.9785, 0.6016,
        0.5707, 0.5838, 0.5533], device='cuda:1')
Thumb force: tensor([0.9861, 2.5210, 0.9502, 0.5887, 2.3912, 0.5729, 0.5954, 0.5377, 1.1073,
        1.2230, 0.6238, 0.6291], device='cuda:1')
Index force: tensor([1.3969, 0.5323, 1.0784, 0.6285, 0.7636, 0.5205, 0.5362, 0.6193, 0.5552,
        0.5337, 0.6044, 0.6680], device='cuda:1')
Storing NORMAL transition: reward=0.1186 (scaled=0.1186), steps=1
Reward stats updated: mean 0.0106 -> 0.0149, std: 0.0596
Collected 25 transitions for RL
tensor([ 6.4482e-02,  5.2050e-01,  6.0444e-01,  6.0734e-01, -2.0693e-01,
         5.2713e-01,  8.6721e-01,  9.0302e-01,  1.5000e+00,  1.2090e-01,
         2.4025e-01,  8.4895e-01, -6.0925e-04,  6.3794e-02, -1.6556e-01,
         4.5639e-01], device='cuda:1')
Original likelihood: -259.10595703125
Adjusted likelihood: -259.10595703125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 255.25221252441406
Projection step: 1, Loss: 249.71206665039062
Projection step: 2, Loss: 238.57366943359375
Projection step: 3, Loss: 230.02395629882812
Projection step: 4, Loss: 226.118896484375
Projection step: 5, Loss: 219.78890991210938
Projection step: 6, Loss: 205.45187377929688
Projection step: 7, Loss: 198.52505493164062
Projection step: 8, Loss: 199.161376953125
Projection step: 9, Loss: 186.43983459472656
Projection step: 10, Loss: 182.55026245117188
Projection step: 11, Loss: 170.87477111816406
Projection step: 12, Loss: 166.84962463378906
Projection step: 13, Loss: 159.52056884765625
Projection step: 14, Loss: 150.89779663085938
Projection step: 15, Loss: 145.1569366455078
Projection step: 16, Loss: 140.45005798339844
Projection step: 17, Loss: 144.30575561523438
Projection step: 18, Loss: 137.74847412109375
Projection step: 19, Loss: 137.01901245117188
Projection step: 20, Loss: 132.6336669921875
Projection step: 21, Loss: 129.174560546875
Projection step: 22, Loss: 129.60580444335938
Projection step: 23, Loss: 126.85285186767578
Projection step: 24, Loss: 121.83729553222656
Final likelihood: tensor([-110.5546, -117.2838, -124.1571, -119.5216, -125.2048, -123.1349,
        -121.4503, -121.0872, -115.8720, -121.9303, -112.3739, -124.1848,
        -125.9116, -129.5033, -123.6790, -123.9290])
Final projection likelihood: -121.2361
1 mode projection succeeded
New goal: tensor([ 0.0634,  0.5443,  0.5512,  0.6442, -0.1288,  0.5278,  0.8565,  0.7823,
         1.3613,  0.1215,  0.1976,  1.1428, -0.0161,  0.0377, -0.6570],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -156.17361450195312
Adjusted likelihood: -156.17361450195312
Likelihood residual: 0.0
Original likelihood: -117.95140838623047
Adjusted likelihood: -117.95140838623047
Likelihood residual: 0.0
{'index': 117.95140838623047, 'thumb_middle': 156.17361450195312}
Current yaw: tensor([-0.0006,  0.0638, -0.1656], device='cuda:1')
4 index
tensor([ 6.4482e-02,  5.2050e-01,  6.0444e-01,  6.0734e-01, -2.0693e-01,
         5.2713e-01,  8.6721e-01,  9.0302e-01,  1.5000e+00,  1.2090e-01,
         2.4025e-01,  8.4895e-01, -6.0925e-04,  6.3794e-02, -1.6556e-01,
         4.5639e-01], device='cuda:1')
Solve time for step 1 10.279866244003642
Current ori: tensor([-0.0006,  0.0638, -0.1656], device='cuda:1')
Middle force: tensor([0.5498, 0.5465, 0.5386, 0.5687], device='cuda:1')
Thumb force: tensor([0.6101, 0.6199, 0.5941, 0.5463], device='cuda:1')
tensor([ 0.1060,  0.4848,  0.5146,  0.6138, -0.1771,  0.5224,  0.9149,  0.8640,
         1.4765,  0.1389,  0.1864,  0.9257, -0.0022,  0.0425, -0.1660,  0.2949],
       device='cuda:1')
Solve time for step 2 4.164886565995403
Current ori: tensor([-0.0022,  0.0425, -0.1660], device='cuda:1')
Middle force: tensor([0.5448, 0.5360, 0.5656], device='cuda:1')
Thumb force: tensor([0.6101, 0.5908, 0.5441], device='cuda:1')
tensor([ 0.1095,  0.4918,  0.5048,  0.6183, -0.1472,  0.5260,  0.9353,  0.8638,
         1.4598,  0.1408,  0.1365,  1.0003,  0.0017,  0.0208, -0.1584,  0.1961],
       device='cuda:1')
Solve time for step 3 4.067068963951897
Current ori: tensor([ 0.0017,  0.0208, -0.1584], device='cuda:1')
Middle force: tensor([0.5013, 0.5165], device='cuda:1')
Thumb force: tensor([0.5701, 0.5347], device='cuda:1')
tensor([ 1.1307e-01,  4.9320e-01,  5.0381e-01,  6.1932e-01, -1.3008e-01,
         5.3513e-01,  9.3814e-01,  8.5906e-01,  1.4503e+00,  1.5007e-01,
         1.1054e-01,  1.0294e+00, -6.2458e-04,  9.2910e-03, -1.6487e-01,
         1.6876e-01], device='cuda:1')
Solve time for step 4 3.9451440339908004
Current ori: tensor([-0.0006,  0.0093, -0.1649], device='cuda:1')
Middle force: tensor([0.5089], device='cuda:1')
Thumb force: tensor([0.5279], device='cuda:1')
Storing RECOVERY transition: reward=0.0102 (scaled=0.0102), steps=1
Reward stats updated: mean 0.0149 -> 0.0147, std: 0.0584
Collected 26 transitions for RL
Original likelihood: -105.30361938476562
Adjusted likelihood: -105.30361938476562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0072,  0.0076, -0.1708], device='cuda:1')
5 turn
Sampling time 3.5853399459738284
tensor([ 0.0642,  0.5536,  0.5443,  0.6403, -0.1256,  0.5466,  0.9294,  0.8430,
         1.4467,  0.1612,  0.1068,  1.0212, -0.0072,  0.0076, -0.1708,  0.1543],
       device='cuda:1')
Original likelihood: -104.4228515625
Adjusted likelihood: -104.4228515625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.047264952969272
Current ori: tensor([-0.0072,  0.0076, -0.1708], device='cuda:1')
Middle force: tensor([0.9068, 2.2407, 0.5650, 1.4198, 0.6579, 0.9769, 0.5565, 0.8096, 0.5009,
        0.6673, 0.5189, 0.5371], device='cuda:1')
Thumb force: tensor([0.6569, 1.2042, 1.6239, 0.5290, 0.5594, 0.6835, 0.5169, 0.6404, 1.2634,
        0.6669, 0.5270, 0.6278], device='cuda:1')
Index force: tensor([0.6228, 1.7107, 0.6368, 0.7275, 0.7528, 0.7326, 0.6460, 0.7819, 0.5817,
        0.7172, 0.5885, 0.7089], device='cuda:1')
Storing NORMAL transition: reward=0.0301 (scaled=0.0301), steps=1
Reward stats updated: mean 0.0147 -> 0.0153, std: 0.0574
Collected 27 transitions for RL
tensor([ 0.0666,  0.4309,  0.6172,  0.8398, -0.0870,  0.5310,  0.8246,  0.9461,
         1.5000,  0.0297,  0.1693,  0.9950,  0.0435,  0.0100, -0.2028,  0.2968],
       device='cuda:1')
Original likelihood: -149.20068359375
Adjusted likelihood: -149.20068359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6686)
Solve time for step 2 5.507388642989099
Current ori: tensor([ 0.0435,  0.0100, -0.2028], device='cuda:1')
Middle force: tensor([2.1834, 0.5610, 1.3733, 0.6458, 0.9505, 0.5492, 0.8042, 0.5006, 0.6520,
        0.5118, 0.5311], device='cuda:1')
Thumb force: tensor([1.1838, 1.6044, 0.5309, 0.5558, 0.6822, 0.5175, 0.6263, 1.2402, 0.6683,
        0.5280, 0.6260], device='cuda:1')
Index force: tensor([1.6885, 0.6305, 0.7313, 0.7587, 0.7338, 0.6464, 0.7856, 0.6079, 0.7165,
        0.6120, 0.7165], device='cuda:1')
Storing NORMAL transition: reward=0.1011 (scaled=0.1011), steps=1
Reward stats updated: mean 0.0153 -> 0.0183, std: 0.0586
Collected 28 transitions for RL
tensor([ 0.1026,  0.4954,  0.5685,  0.8101, -0.0111,  0.5957,  0.7663,  1.0311,
         1.3900,  0.1844,  0.2133,  0.8760,  0.0343, -0.0416, -0.3056,  0.3276],
       device='cuda:1')
Original likelihood: -122.58174133300781
Adjusted likelihood: -122.58174133300781
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.052663379989099
Current ori: tensor([ 0.0343, -0.0416, -0.3056], device='cuda:1')
Middle force: tensor([0.5570, 1.3482, 0.6874, 0.9816, 0.5721, 0.8400, 0.5019, 0.6829, 0.5217,
        0.5407], device='cuda:1')
Thumb force: tensor([1.5773, 0.5302, 0.5392, 0.6425, 0.5120, 0.5982, 1.1952, 0.6390, 0.5188,
        0.6025], device='cuda:1')
Index force: tensor([0.6250, 0.7259, 0.7396, 0.7264, 0.6277, 0.7719, 0.5538, 0.6998, 0.5851,
        0.6972], device='cuda:1')
Storing NORMAL transition: reward=-0.0217 (scaled=-0.0217), steps=1
Reward stats updated: mean 0.0183 -> 0.0170, std: 0.0580
Collected 29 transitions for RL
tensor([ 0.0400,  0.5132,  0.5368,  0.7134, -0.1384,  0.6719,  0.7839,  0.9298,
         1.4604,  0.0862,  0.2645,  0.8200,  0.0407, -0.0025, -0.2822,  0.3816],
       device='cuda:1')
Original likelihood: -178.07638549804688
Adjusted likelihood: -178.07638549804688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 172.3180694580078
Projection step: 1, Loss: 169.47633361816406
Projection step: 2, Loss: 154.6537322998047
Projection step: 3, Loss: 149.34405517578125
Projection step: 4, Loss: 144.53292846679688
Projection step: 5, Loss: 141.49871826171875
Projection step: 6, Loss: 135.13108825683594
Projection step: 7, Loss: 131.7455596923828
Projection step: 8, Loss: 131.81265258789062
Projection step: 9, Loss: 124.11124420166016
Projection step: 10, Loss: 118.93060302734375
Projection step: 11, Loss: 112.15469360351562
Projection step: 12, Loss: 108.52955627441406
Projection step: 13, Loss: 107.68037414550781
Projection step: 14, Loss: 106.06427001953125
Projection step: 15, Loss: 98.1197509765625
Final likelihood: tensor([ -93.7784, -105.6003,  -91.2590,  -91.6197,  -91.9468,  -89.6322,
         -85.4122,  -91.6184,  -85.6709, -114.8552,  -95.5142, -107.4592,
         -91.4819,  -99.7962, -103.8562, -130.4153])
Final projection likelihood: -98.1198
1 mode projection succeeded
New goal: tensor([ 0.0524,  0.5371,  0.5695,  0.6442, -0.0913,  0.5597,  0.8166,  0.8645,
         1.4038,  0.1078,  0.2276,  1.0079,  0.0361, -0.0016, -1.2538],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -123.30828857421875
Adjusted likelihood: -123.30828857421875
Likelihood residual: 0.0
Original likelihood: -178.02078247070312
Adjusted likelihood: -178.02078247070312
Likelihood residual: 0.0
{'index': 178.02078247070312, 'thumb_middle': 123.30828857421875}
Current yaw: tensor([ 0.0407, -0.0025, -0.2822], device='cuda:1')
6 thumb_middle
tensor([ 0.0400,  0.5132,  0.5368,  0.7134, -0.1384,  0.6719,  0.7839,  0.9298,
         1.4604,  0.0862,  0.2645,  0.8200,  0.0407, -0.0025, -0.2822,  0.3816],
       device='cuda:1')
Solve time for step 1 9.230266773956828
Current ori: tensor([ 0.0407, -0.0025, -0.2822], device='cuda:1')
Index force: tensor([0.5870, 0.5989, 0.5943, 0.5998], device='cuda:1')
tensor([ 3.6675e-02,  5.0609e-01,  5.6037e-01,  6.7835e-01, -1.7716e-01,
         5.6930e-01,  7.8725e-01,  8.5020e-01,  1.3684e+00,  7.6148e-02,
         1.6099e-01,  9.3460e-01,  4.0326e-02, -2.8838e-04, -2.8222e-01,
         4.2874e-01], device='cuda:1')
Solve time for step 2 3.5037494740099646
Current ori: tensor([ 0.0403, -0.0003, -0.2822], device='cuda:1')
Index force: tensor([0.5048, 0.5984, 0.5510], device='cuda:1')
tensor([ 3.5889e-02,  5.0932e-01,  5.6489e-01,  6.5911e-01, -1.7938e-01,
         5.6417e-01,  7.9077e-01,  8.4364e-01,  1.3635e+00,  8.0394e-02,
         1.4532e-01,  9.6415e-01,  3.7314e-02, -3.3612e-04, -2.8222e-01,
         4.1873e-01], device='cuda:1')
Solve time for step 3 3.4461587079567835
Current ori: tensor([ 0.0373, -0.0003, -0.2822], device='cuda:1')
Index force: tensor([0.5846, 0.5433], device='cuda:1')
tensor([ 0.0385,  0.5140,  0.5635,  0.6549, -0.1722,  0.5680,  0.7917,  0.8466,
         1.3569,  0.0771,  0.1386,  0.9697,  0.0355, -0.0019, -0.2822,  0.4172],
       device='cuda:1')
Solve time for step 4 3.3542565960087813
Current ori: tensor([ 0.0355, -0.0019, -0.2822], device='cuda:1')
Index force: tensor([0.5327], device='cuda:1')
Storing RECOVERY transition: reward=0.0085 (scaled=0.0028), steps=3
Reward stats updated: mean 0.0170 -> 0.0165, std: 0.0571
Collected 30 transitions for RL
Original likelihood: -135.64878845214844
Adjusted likelihood: -135.64878845214844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0366, -0.0032, -0.2905], device='cuda:1')
7 turn
Sampling time 3.7604286859859712
tensor([ 0.0354,  0.5069,  0.5672,  0.6608, -0.1020,  0.6106,  0.8349,  0.8689,
         1.4196,  0.1049,  0.1927,  1.0048,  0.0366, -0.0032, -0.2905,  0.4161],
       device='cuda:1')
Original likelihood: -129.8526153564453
Adjusted likelihood: -129.8526153564453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.29497246799292
Current ori: tensor([ 0.0366, -0.0032, -0.2905], device='cuda:1')
Middle force: tensor([1.1545, 0.9403, 0.5756, 0.5605, 0.8725, 0.9151, 0.5785, 0.7292, 0.5835,
        0.6054, 0.6722, 1.0498], device='cuda:1')
Thumb force: tensor([0.9280, 0.5469, 1.0370, 1.0231, 0.5653, 0.5763, 0.5993, 0.7314, 0.9013,
        0.5261, 0.5826, 0.5609], device='cuda:1')
Index force: tensor([0.5221, 0.9914, 0.5396, 0.5097, 0.5681, 0.5507, 0.6467, 0.5485, 0.5807,
        0.6122, 0.5461, 0.5405], device='cuda:1')
Storing NORMAL transition: reward=-0.0653 (scaled=-0.0653), steps=1
Reward stats updated: mean 0.0165 -> 0.0139, std: 0.0580
Collected 31 transitions for RL
tensor([-0.1775,  0.3719,  0.5999,  0.6587, -0.1325,  0.6331,  0.7683,  0.8848,
         1.3971,  0.1100,  0.2856,  0.9609,  0.0392,  0.0229, -0.2257, -0.0307],
       device='cuda:1')
Original likelihood: -214.4292449951172
Adjusted likelihood: -214.4292449951172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 215.61595153808594
Projection step: 1, Loss: 184.8887939453125
Projection step: 2, Loss: 178.5280303955078
Projection step: 3, Loss: 190.45989990234375
Projection step: 4, Loss: 193.54295349121094
Projection step: 5, Loss: 204.87384033203125
Projection step: 6, Loss: 185.57339477539062
Projection step: 7, Loss: 190.02987670898438
Projection step: 8, Loss: 175.8441925048828
Projection step: 9, Loss: 172.94349670410156
Projection step: 10, Loss: 168.95193481445312
Projection step: 11, Loss: 164.18605041503906
Projection step: 12, Loss: 163.60107421875
Projection step: 13, Loss: 157.33290100097656
Projection step: 14, Loss: 150.15725708007812
Projection step: 15, Loss: 150.33987426757812
Projection step: 16, Loss: 138.9136962890625
Projection step: 17, Loss: 138.57052612304688
Projection step: 18, Loss: 139.534423828125
Projection step: 19, Loss: 126.71870422363281
Projection step: 20, Loss: 130.86439514160156
Projection step: 21, Loss: 127.19234466552734
Projection step: 22, Loss: 119.16277313232422
Projection step: 23, Loss: 120.81295776367188
Projection step: 24, Loss: 118.80258178710938
Final likelihood: tensor([-135.2767, -117.2713, -114.1144, -135.4035,  -95.4558, -112.9069,
        -141.2758,  -96.7490, -106.3123, -107.9728, -115.5269, -107.4621,
        -116.0857, -134.5915, -112.6643, -114.2573])
Final projection likelihood: -116.4579
1 mode projection succeeded
New goal: tensor([-0.0498,  0.4767,  0.6773,  0.6216, -0.1262,  0.5593,  0.7340,  0.9700,
         1.2962,  0.2272,  0.1886,  1.0585,  0.0317,  0.0180, -0.9112],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -152.92311096191406
Adjusted likelihood: -152.92311096191406
Likelihood residual: 0.0
Original likelihood: -181.1654510498047
Adjusted likelihood: -181.1654510498047
Likelihood residual: 0.0
{'index': 181.1654510498047, 'thumb_middle': 152.92311096191406}
Current yaw: tensor([ 0.0392,  0.0229, -0.2257], device='cuda:1')
8 thumb_middle
tensor([-0.1775,  0.3719,  0.5999,  0.6587, -0.1325,  0.6331,  0.7683,  0.8848,
         1.3971,  0.1100,  0.2856,  0.9609,  0.0392,  0.0229, -0.2257, -0.0307],
       device='cuda:1')
Solve time for step 1 9.19452055497095
Current ori: tensor([ 0.0392,  0.0229, -0.2257], device='cuda:1')
Index force: tensor([0.5714, 0.5717, 0.5894, 0.5994], device='cuda:1')
tensor([-0.1408,  0.4242,  0.6148,  0.5937, -0.1834,  0.5655,  0.7243,  0.9338,
         1.2977,  0.1884,  0.1538,  1.0193,  0.0913, -0.0097, -0.2257,  0.6397],
       device='cuda:1')
Solve time for step 2 3.675063730974216
Current ori: tensor([ 0.0913, -0.0097, -0.2257], device='cuda:1')
Index force: tensor([0.5609, 0.5781, 0.5889], device='cuda:1')
tensor([-0.1357,  0.4900,  0.6476,  0.5843, -0.1580,  0.5833,  0.7285,  0.9530,
         1.2877,  0.2214,  0.1380,  1.0451,  0.2435, -0.0510, -0.2256,  1.3897],
       device='cuda:1')
Solve time for step 3 3.7400853959843516
Current ori: tensor([ 0.2435, -0.0510, -0.2256], device='cuda:1')
Index force: tensor([0.5752, 0.5001], device='cuda:1')
tensor([-0.0852,  0.5669,  0.8331,  0.6923, -0.1021,  0.6204,  0.7865,  0.9892,
         1.3277,  0.2320,  0.1894,  1.0793,  0.2914, -0.1904, -0.2123,  3.1141],
       device='cuda:1')
Solve time for step 4 3.580901985988021
Current ori: tensor([ 0.2914, -0.1904, -0.2123], device='cuda:1')
Index force: tensor([0.5361], device='cuda:1')
Storing RECOVERY transition: reward=-0.3363 (scaled=-0.3363), steps=1
Reward stats updated: mean 0.0139 -> 0.0029, std: 0.0835
Collected 32 transitions for RL
Original likelihood: -1052.0
Adjusted likelihood: -1052.0
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 3
Loaded trajectory sampler
Current yaw: tensor([-0.0001,  0.0139, -0.0386], device='cuda:1')
Current yaw: tensor([-0.0001,  0.0139, -0.0386], device='cuda:1')
1 turn
Sampling time 3.614451818051748
tensor([ 1.1947e-01,  6.2054e-01,  5.5254e-01,  5.4797e-01, -1.2011e-01,
         5.5881e-01,  8.7827e-01,  8.8617e-01,  1.2162e+00,  2.7885e-01,
         2.5990e-01,  1.2243e+00, -1.1371e-04,  1.3942e-02, -3.8642e-02,
         3.0525e-01], device='cuda:1')
Original likelihood: -97.27308654785156
Adjusted likelihood: -97.27308654785156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.068949855980463
Current ori: tensor([-0.0001,  0.0139, -0.0386], device='cuda:1')
Middle force: tensor([0.5505, 0.5756, 1.1820, 0.5665, 1.1496, 0.6448, 0.5331, 0.5331, 0.5139,
        0.5104, 0.5828, 0.6043], device='cuda:1')
Thumb force: tensor([0.8538, 0.8491, 0.7634, 1.0221, 0.9448, 0.6360, 0.5212, 0.8446, 0.5335,
        0.5806, 0.5919, 0.5873], device='cuda:1')
Index force: tensor([0.6030, 0.6070, 0.5504, 0.5695, 0.7944, 0.5313, 1.0071, 0.9395, 0.5909,
        0.5128, 0.5851, 0.5813], device='cuda:1')
Storing NORMAL transition: reward=0.0346 (scaled=0.0346), steps=1
Reward stats updated: mean 0.0029 -> 0.0039, std: 0.0824
Collected 33 transitions for RL
tensor([ 0.1465,  0.6732,  0.5364,  0.4780, -0.1275,  0.5210,  0.8820,  0.9828,
         1.2329,  0.2304,  0.2865,  1.2080,  0.0181,  0.0125, -0.0735, -0.5426],
       device='cuda:1')
Original likelihood: -117.57676696777344
Adjusted likelihood: -117.57676696777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.541150979988743
Current ori: tensor([ 0.0181,  0.0125, -0.0735], device='cuda:1')
Middle force: tensor([0.5673, 1.1564, 0.5589, 1.1051, 0.6287, 0.5305, 0.5223, 0.5107, 0.5069,
        0.5742, 0.5962], device='cuda:1')
Thumb force: tensor([0.8213, 0.7412, 0.9905, 0.9253, 0.6317, 0.5174, 0.8412, 0.5335, 0.5756,
        0.5902, 0.5831], device='cuda:1')
Index force: tensor([0.5944, 0.5427, 0.5612, 0.7712, 0.5275, 0.9802, 0.9295, 0.5838, 0.5106,
        0.5760, 0.5727], device='cuda:1')
Storing NORMAL transition: reward=0.0834 (scaled=0.0834), steps=1
Reward stats updated: mean 0.0039 -> 0.0062, std: 0.0823
Collected 34 transitions for RL
tensor([ 3.4751e-02,  6.4762e-01,  4.8448e-01,  3.9961e-01, -1.0769e-01,
         5.1514e-01,  8.9769e-01,  1.0052e+00,  1.2774e+00,  1.5257e-01,
         3.4129e-01,  9.9881e-01,  1.3282e-02, -3.1517e-04, -1.5662e-01,
        -9.9327e-01], device='cuda:1')
Original likelihood: -105.97479248046875
Adjusted likelihood: -105.97479248046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.049769155972172
Current ori: tensor([ 0.0133, -0.0003, -0.1566], device='cuda:1')
Middle force: tensor([0.5008, 0.5467, 0.6811, 1.6272, 0.5043, 0.6173, 0.5400, 0.6487, 0.5735,
        0.5702], device='cuda:1')
Thumb force: tensor([0.5838, 0.5845, 0.5675, 1.4664, 0.5503, 1.1841, 0.8871, 0.9035, 0.6214,
        0.5183], device='cuda:1')
Index force: tensor([1.0803, 0.5717, 0.5128, 0.5512, 0.6287, 0.6716, 0.5078, 0.5405, 0.5605,
        0.5815], device='cuda:1')
Storing NORMAL transition: reward=-0.0103 (scaled=-0.0103), steps=1
Reward stats updated: mean 0.0062 -> 0.0057, std: 0.0811
Collected 35 transitions for RL
tensor([ 0.0654,  0.6227,  0.5467,  0.4190, -0.0791,  0.5289,  0.9271,  1.0073,
         1.1691,  0.2832,  0.3836,  0.8671,  0.0180, -0.0279, -0.1474, -1.0863],
       device='cuda:1')
Original likelihood: -190.48358154296875
Adjusted likelihood: -190.48358154296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 162.81723022460938
Projection step: 1, Loss: 164.25439453125
Projection step: 2, Loss: 153.26849365234375
Projection step: 3, Loss: 142.655029296875
Projection step: 4, Loss: 139.93658447265625
Projection step: 5, Loss: 127.88371276855469
Projection step: 6, Loss: 128.9615478515625
Projection step: 7, Loss: 124.88212585449219
Projection step: 8, Loss: 117.17420959472656
Projection step: 9, Loss: 115.05879211425781
Projection step: 10, Loss: 109.33985900878906
Projection step: 11, Loss: 106.63595581054688
Projection step: 12, Loss: 102.43511962890625
Final likelihood: tensor([ -93.1788,  -95.7133,  -97.9647, -100.5220,  -94.6025, -106.4546,
         -89.9138,  -84.7827, -102.5051, -114.7971,  -91.1820, -111.9214,
        -105.7275, -108.6880,  -93.1636, -147.8450])
Final projection likelihood: -102.4351
1 mode projection succeeded
New goal: tensor([ 0.0510,  0.5754,  0.5393,  0.5202, -0.0611,  0.5123,  0.8740,  0.9322,
         1.2721,  0.2655,  0.2736,  1.0276,  0.0160, -0.0200, -0.7343],
       device='cuda:1')
tensor([[0.0048]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -117.62425231933594
Adjusted likelihood: -117.62425231933594
Likelihood residual: 0.0
Original likelihood: -179.69204711914062
Adjusted likelihood: -179.69204711914062
Likelihood residual: 0.0
{'index': 179.69204711914062, 'thumb_middle': 117.62425231933594}
Current yaw: tensor([ 0.0180, -0.0279, -0.1474], device='cuda:1')
2 thumb_middle
tensor([ 0.0654,  0.6227,  0.5467,  0.4190, -0.0791,  0.5289,  0.9271,  1.0073,
         1.1691,  0.2832,  0.3836,  0.8671,  0.0180, -0.0279, -0.1474, -1.0863],
       device='cuda:1')
Solve time for step 1 8.972125127969775
Current ori: tensor([ 0.0180, -0.0279, -0.1474], device='cuda:1')
Index force: tensor([0.5727, 0.5829, 0.5607, 0.5673], device='cuda:1')
tensor([ 0.0533,  0.6025,  0.5320,  0.4932, -0.1379,  0.4876,  0.8564,  0.9369,
         1.2164,  0.2614,  0.2019,  0.9650,  0.0292, -0.0170, -0.1476, -1.0927],
       device='cuda:1')
Solve time for step 2 3.533562251017429
Current ori: tensor([ 0.0292, -0.0170, -0.1476], device='cuda:1')
Index force: tensor([0.5705, 0.5522, 0.5571], device='cuda:1')
tensor([ 0.0529,  0.5959,  0.5400,  0.4947, -0.1469,  0.5034,  0.8463,  0.9187,
         1.2263,  0.2360,  0.1936,  0.9810,  0.0310, -0.0166, -0.1476, -1.0885],
       device='cuda:1')
Solve time for step 3 3.437946937046945
Current ori: tensor([ 0.0310, -0.0166, -0.1476], device='cuda:1')
Index force: tensor([0.5422, 0.5470], device='cuda:1')
tensor([ 0.0685,  0.5966,  0.5445,  0.5128, -0.1470,  0.5206,  0.8514,  0.9161,
         1.2252,  0.2509,  0.1782,  0.9800,  0.0334, -0.0242, -0.1476, -1.0598],
       device='cuda:1')
Solve time for step 4 3.4100386110367253
Current ori: tensor([ 0.0334, -0.0242, -0.1476], device='cuda:1')
Index force: tensor([0.5338], device='cuda:1')
Storing RECOVERY transition: reward=-0.0073 (scaled=-0.0024), steps=3
Reward stats updated: mean 0.0057 -> 0.0055, std: 0.0800
Collected 36 transitions for RL
Original likelihood: -108.09780883789062
Adjusted likelihood: -108.09780883789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0345, -0.0091, -0.1403], device='cuda:1')
3 turn
Sampling time 3.5939467959688045
tensor([ 0.0360,  0.5995,  0.5146,  0.5016, -0.0920,  0.5488,  0.8840,  0.9436,
         1.2883,  0.2655,  0.2458,  1.0413,  0.0345, -0.0091, -0.1403, -1.0409],
       device='cuda:1')
Original likelihood: -107.68862915039062
Adjusted likelihood: -107.68862915039062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.987454562040512
Current ori: tensor([ 0.0345, -0.0091, -0.1403], device='cuda:1')
Middle force: tensor([0.5160, 0.5001, 0.5057, 1.5584, 0.6071, 0.5773, 0.5507, 0.8545, 1.2099,
        0.6070, 0.5558, 1.0218], device='cuda:1')
Thumb force: tensor([1.1469, 0.8841, 1.3146, 0.6318, 0.6114, 0.8344, 0.5593, 0.5778, 0.5773,
        0.5752, 0.5497, 0.5191], device='cuda:1')
Index force: tensor([0.5829, 0.7250, 0.6079, 0.7614, 0.6146, 0.6057, 0.6281, 0.5766, 0.6281,
        0.5807, 0.6727, 0.5443], device='cuda:1')
Storing NORMAL transition: reward=-0.0228 (scaled=-0.0228), steps=1
Reward stats updated: mean 0.0055 -> 0.0047, std: 0.0791
Collected 37 transitions for RL
tensor([-0.0301,  0.6147,  0.4336,  0.5072, -0.1314,  0.5556,  0.8573,  0.8791,
         1.2847,  0.2780,  0.2080,  0.9719,  0.0222,  0.0213, -0.1171, -1.2724],
       device='cuda:1')
Original likelihood: -138.0145263671875
Adjusted likelihood: -138.0145263671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.482899262977298
Current ori: tensor([ 0.0222,  0.0213, -0.1171], device='cuda:1')
Middle force: tensor([0.5000, 0.5040, 1.5200, 0.6006, 0.5688, 0.5495, 0.8431, 1.1922, 0.6015,
        0.5493, 1.0100], device='cuda:1')
Thumb force: tensor([0.8626, 1.2910, 0.6339, 0.6080, 0.8228, 0.5556, 0.5737, 0.5725, 0.5713,
        0.5477, 0.5176], device='cuda:1')
Index force: tensor([0.7203, 0.6162, 0.7547, 0.6092, 0.6071, 0.6210, 0.5726, 0.6228, 0.5778,
        0.6720, 0.5418], device='cuda:1')
Storing NORMAL transition: reward=0.0509 (scaled=0.0509), steps=1
Reward stats updated: mean 0.0047 -> 0.0060, std: 0.0784
Collected 38 transitions for RL
tensor([ 0.0268,  0.6220,  0.4677,  0.4935, -0.1211,  0.6097,  0.9316,  0.9929,
         1.3858,  0.2633,  0.1648,  0.9154,  0.0217, -0.0417, -0.1694, -1.2317],
       device='cuda:1')
Original likelihood: -174.02371215820312
Adjusted likelihood: -174.02371215820312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 174.92996215820312
Projection step: 1, Loss: 167.91481018066406
Projection step: 2, Loss: 162.6387481689453
Projection step: 3, Loss: 183.2521514892578
Projection step: 4, Loss: 163.06686401367188
Projection step: 5, Loss: 146.2104949951172
Projection step: 6, Loss: 148.5253143310547
Projection step: 7, Loss: 142.24728393554688
Projection step: 8, Loss: 143.7411346435547
Projection step: 9, Loss: 141.31349182128906
Projection step: 10, Loss: 136.23516845703125
Projection step: 11, Loss: 139.29910278320312
Projection step: 12, Loss: 128.74984741210938
Projection step: 13, Loss: 136.656494140625
Projection step: 14, Loss: 130.66720581054688
Projection step: 15, Loss: 128.01168823242188
Projection step: 16, Loss: 125.28096771240234
Projection step: 17, Loss: 128.33380126953125
Projection step: 18, Loss: 123.13246154785156
Projection step: 19, Loss: 122.53834533691406
Projection step: 20, Loss: 126.2381362915039
Projection step: 21, Loss: 120.85768127441406
Projection step: 22, Loss: 125.31982421875
Projection step: 23, Loss: 122.66116333007812
Projection step: 24, Loss: 124.22152709960938
Final likelihood: tensor([-120.6187, -141.0875,  -95.6096, -129.3576, -127.0543, -119.7652,
        -120.4018, -143.9973, -121.9709,  -95.7920, -100.2482, -103.0270,
        -115.9373, -110.7998, -121.8946, -125.4348])
Final projection likelihood: -118.3123
1 mode projection succeeded
New goal: tensor([ 0.0384,  0.5472,  0.6047,  0.5188, -0.0518,  0.5308,  0.8427,  0.9055,
         1.3725,  0.2338,  0.2064,  1.0594,  0.0165, -0.0298, -1.0477],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -164.66195678710938
Adjusted likelihood: -164.66195678710938
Likelihood residual: 0.0
Original likelihood: -174.05392456054688
Adjusted likelihood: -174.05392456054688
Likelihood residual: 0.0
{'index': 174.05392456054688, 'thumb_middle': 164.66195678710938}
Current yaw: tensor([ 0.0217, -0.0417, -0.1694], device='cuda:1')
4 thumb_middle
tensor([ 0.0268,  0.6220,  0.4677,  0.4935, -0.1211,  0.6097,  0.9316,  0.9929,
         1.3858,  0.2633,  0.1648,  0.9154,  0.0217, -0.0417, -0.1694, -1.2317],
       device='cuda:1')
Solve time for step 1 8.685654690023512
Current ori: tensor([ 0.0217, -0.0417, -0.1694], device='cuda:1')
Index force: tensor([0.6627, 0.5004, 0.5003, 0.5004], device='cuda:1')
tensor([-0.0382,  0.5749,  0.5748,  0.5192, -0.1441,  0.5243,  0.8242,  0.8998,
         1.3248,  0.2203,  0.1093,  0.9905,  0.0676, -0.0948, -0.1692, -1.1284],
       device='cuda:1')
Solve time for step 2 3.6462254649959505
Current ori: tensor([ 0.0676, -0.0948, -0.1692], device='cuda:1')
Index force: tensor([0.5002, 0.5000, 0.5001], device='cuda:1')
tensor([-0.0510,  0.5916,  0.6072,  0.4954, -0.0724,  0.5658,  0.8540,  0.9083,
         1.3050,  0.2110,  0.0678,  0.9891,  0.1696, -0.2392, -0.1692, -1.2258],
       device='cuda:1')
Solve time for step 3 3.4992293989635073
Current ori: tensor([ 0.1696, -0.2392, -0.1692], device='cuda:1')
Index force: tensor([0.5002, 0.5651], device='cuda:1')
tensor([-0.1277,  0.7848,  0.6318,  0.4996, -0.0045,  0.6107,  0.8974,  0.9153,
         1.3150,  0.2282,  0.0938,  1.0002,  0.2645, -0.3388, -0.2635, -2.0791],
       device='cuda:1')
Solve time for step 4 3.3472749710199423
Current ori: tensor([ 0.2645, -0.3388, -0.2635], device='cuda:1')
Index force: tensor([0.5005], device='cuda:1')
Storing RECOVERY transition: reward=-0.0064 (scaled=-0.0032), steps=2
Reward stats updated: mean 0.0060 -> 0.0057, std: 0.0774
Collected 39 transitions for RL
Original likelihood: -1121.00244140625
Adjusted likelihood: -1121.00244140625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 4
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.775370165996719
tensor([ 0.1275,  0.5690,  0.6177,  0.5755, -0.1288,  0.5919,  0.8720,  0.8213,
         1.2289,  0.2801,  0.2467,  1.2126, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -115.10482025146484
Adjusted likelihood: -115.10482025146484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.206265599001199
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([1.8060, 0.5841, 0.5166, 1.0664, 0.5320, 0.5203, 0.5489, 0.5429, 0.4847,
        0.4781, 0.4833, 0.4845], device='cuda:1')
Thumb force: tensor([1.0615, 0.6734, 1.5368, 1.1630, 0.6963, 1.1033, 0.5705, 0.5674, 0.5295,
        0.6648, 0.6005, 0.6448], device='cuda:1')
Index force: tensor([0.6336, 0.5263, 0.5505, 0.5028, 0.5456, 0.5255, 0.5885, 0.6790, 0.8422,
        0.6928, 0.7972, 0.7905], device='cuda:1')
Storing NORMAL transition: reward=-0.0620 (scaled=-0.0620), steps=1
Reward stats updated: mean 0.0057 -> 0.0040, std: 0.0771
Collected 40 transitions for RL
tensor([ 0.1491,  0.5890,  0.6164,  0.5582, -0.1270,  0.5751,  0.8618,  0.9216,
         1.1515,  0.3388,  0.2836,  1.2988,  0.0296,  0.0044,  0.0305, -0.4195],
       device='cuda:1')
Original likelihood: -150.15536499023438
Adjusted likelihood: -150.15536499023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4662)
State is out of distribution
Projection step: 0, Loss: 146.74566650390625
Projection step: 1, Loss: 128.65914916992188
Projection step: 2, Loss: 130.31253051757812
Projection step: 3, Loss: 115.41798400878906
Projection step: 4, Loss: 106.00009155273438
Projection step: 5, Loss: 109.44475555419922
Projection step: 6, Loss: 109.06505584716797
Projection step: 7, Loss: 110.24032592773438
Projection step: 8, Loss: 103.62865447998047
Final likelihood: tensor([-126.6470,  -96.8200,  -81.3556, -139.7197,  -86.3903, -110.3324,
        -110.4727, -114.4245,  -92.3546,  -87.0239,  -84.5586, -117.6342,
        -108.9396, -110.8677, -104.6750,  -85.8426])
Final projection likelihood: -103.6287
1 mode projection succeeded
New goal: tensor([ 0.1129,  0.5708,  0.5962,  0.5706, -0.0904,  0.5679,  0.8815,  0.8635,
         1.2390,  0.3440,  0.2745,  1.2030,  0.0274,  0.0067,  0.0727],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -95.24552917480469
Adjusted likelihood: -95.24552917480469
Likelihood residual: 0.0
Original likelihood: -108.33378601074219
Adjusted likelihood: -108.33378601074219
Likelihood residual: 0.0
{'index': 108.33378601074219, 'thumb_middle': 95.24552917480469}
Current yaw: tensor([0.0296, 0.0044, 0.0305], device='cuda:1')
2 thumb_middle
tensor([ 0.1491,  0.5890,  0.6164,  0.5582, -0.1270,  0.5751,  0.8618,  0.9216,
         1.1515,  0.3388,  0.2836,  1.2988,  0.0296,  0.0044,  0.0305, -0.4195],
       device='cuda:1')
Solve time for step 1 8.963720671948977
Current ori: tensor([0.0296, 0.0044, 0.0305], device='cuda:1')
Index force: tensor([0.5939, 0.5983, 0.5590, 0.6079], device='cuda:1')
tensor([ 0.1271,  0.5886,  0.5950,  0.5581, -0.2061,  0.5317,  0.8313,  0.8433,
         1.1731,  0.3220,  0.1847,  1.1797,  0.0292,  0.0158,  0.0305, -0.4340],
       device='cuda:1')
Solve time for step 2 3.6109197629848495
Current ori: tensor([0.0292, 0.0158, 0.0305], device='cuda:1')
Index force: tensor([0.5897, 0.5542, 0.6014], device='cuda:1')
tensor([ 0.1219,  0.5993,  0.5828,  0.5430, -0.2136,  0.5350,  0.8348,  0.8377,
         1.1863,  0.3232,  0.1726,  1.1632,  0.0258,  0.0176,  0.0305, -0.4478],
       device='cuda:1')
Solve time for step 3 3.507232556003146
Current ori: tensor([0.0258, 0.0176, 0.0305], device='cuda:1')
Index force: tensor([0.5482, 0.5938], device='cuda:1')
tensor([ 0.1247,  0.5892,  0.5903,  0.5606, -0.2123,  0.5371,  0.8351,  0.8339,
         1.1892,  0.3216,  0.1703,  1.1595,  0.0293,  0.0171,  0.0305, -0.4383],
       device='cuda:1')
Solve time for step 4 3.3538473210064694
Current ori: tensor([0.0293, 0.0171, 0.0305], device='cuda:1')
Index force: tensor([0.5544], device='cuda:1')
Storing RECOVERY transition: reward=-0.0094 (scaled=-0.0094), steps=1
Reward stats updated: mean 0.0040 -> 0.0037, std: 0.0762
Collected 41 transitions for RL
Original likelihood: -126.35050201416016
Adjusted likelihood: -126.35050201416016
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([0.0371, 0.0265, 0.0390], device='cuda:1')
3 turn
Sampling time 3.789054356981069
tensor([ 0.1083,  0.5626,  0.5986,  0.5830, -0.1558,  0.5743,  0.8699,  0.8556,
         1.2594,  0.3436,  0.2389,  1.1944,  0.0371,  0.0265,  0.0390, -0.4330],
       device='cuda:1')
Original likelihood: -128.8792724609375
Adjusted likelihood: -128.8792724609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.940413890988566
Current ori: tensor([0.0371, 0.0265, 0.0390], device='cuda:1')
Middle force: tensor([0.5557, 0.6228, 1.6452, 0.9094, 0.5492, 0.4998, 0.6788, 0.4894, 0.5547,
        0.7982, 0.6269, 0.5454], device='cuda:1')
Thumb force: tensor([1.0505, 0.9822, 0.6760, 1.2867, 1.0195, 0.5411, 0.5598, 0.6413, 0.6120,
        0.5635, 0.6049, 0.9837], device='cuda:1')
Index force: tensor([0.6354, 0.6396, 0.6423, 0.5587, 0.7503, 0.5601, 0.5243, 0.6970, 0.6417,
        0.5783, 0.5668, 0.5657], device='cuda:1')
Storing NORMAL transition: reward=0.1018 (scaled=0.1018), steps=1
Reward stats updated: mean 0.0037 -> 0.0060, std: 0.0768
Collected 42 transitions for RL
tensor([ 0.0666,  0.6072,  0.5115,  0.5550, -0.1816,  0.5466,  0.8933,  0.8454,
         1.3073,  0.2912,  0.2963,  1.0444,  0.0275,  0.0429, -0.0638, -0.2987],
       device='cuda:1')
Original likelihood: -159.11416625976562
Adjusted likelihood: -159.11416625976562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 161.37185668945312
Projection step: 1, Loss: 147.70217895507812
Projection step: 2, Loss: 151.47882080078125
Projection step: 3, Loss: 139.77581787109375
Projection step: 4, Loss: 136.7340087890625
Projection step: 5, Loss: 130.16725158691406
Projection step: 6, Loss: 121.02288818359375
Projection step: 7, Loss: 124.16048431396484
Projection step: 8, Loss: 120.16320037841797
Projection step: 9, Loss: 115.18574523925781
Projection step: 10, Loss: 108.18841552734375
Projection step: 11, Loss: 103.1146240234375
Final likelihood: tensor([-113.8588, -104.4137, -114.4362, -113.6032,  -93.0639, -113.5007,
        -109.5487, -111.9983,  -98.8340,  -99.8105,  -91.7365,  -98.0346,
         -98.5125,  -90.0058, -102.0901,  -96.3867])
Final projection likelihood: -103.1146
1 mode projection succeeded
New goal: tensor([ 0.0650,  0.5928,  0.5430,  0.5465, -0.1229,  0.5324,  0.8834,  0.7967,
         1.3051,  0.2512,  0.2551,  1.1443,  0.0274,  0.0315, -0.4828],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -119.81407165527344
Adjusted likelihood: -119.81407165527344
Likelihood residual: 0.0
Original likelihood: -110.72967529296875
Adjusted likelihood: -110.72967529296875
Likelihood residual: 0.0
{'index': 110.72967529296875, 'thumb_middle': 119.81407165527344}
Current yaw: tensor([ 0.0275,  0.0429, -0.0638], device='cuda:1')
4 index
tensor([ 0.0666,  0.6072,  0.5115,  0.5550, -0.1816,  0.5466,  0.8933,  0.8454,
         1.3073,  0.2912,  0.2963,  1.0444,  0.0275,  0.0429, -0.0638, -0.2987],
       device='cuda:1')
Solve time for step 1 10.127340033999644
Current ori: tensor([ 0.0275,  0.0429, -0.0638], device='cuda:1')
Middle force: tensor([0.5597, 0.5445, 0.5164, 0.5064], device='cuda:1')
Thumb force: tensor([0.5448, 0.5349, 0.5698, 0.5413], device='cuda:1')
tensor([ 0.1110,  0.5336,  0.4879,  0.5309, -0.1748,  0.5376,  0.9168,  0.8417,
         1.3265,  0.2600,  0.2671,  1.0668,  0.0298,  0.0362, -0.0805,  4.0862],
       device='cuda:1')
Solve time for step 2 4.29071222001221
Current ori: tensor([ 0.0298,  0.0362, -0.0805], device='cuda:1')
Middle force: tensor([0.5411, 0.5148, 0.5050], device='cuda:1')
Thumb force: tensor([0.5300, 0.5652, 0.5379], device='cuda:1')
tensor([ 0.1201,  0.5353,  0.4931,  0.5234, -0.1587,  0.5415,  0.9279,  0.8314,
         1.3278,  0.2502,  0.2428,  1.0829,  0.0273,  0.0253, -0.0910, -5.5594],
       device='cuda:1')
Solve time for step 3 3.870796151983086
Current ori: tensor([ 0.0273,  0.0253, -0.0910], device='cuda:1')
Middle force: tensor([0.5479, 0.5745], device='cuda:1')
Thumb force: tensor([0.5273, 0.5585], device='cuda:1')
tensor([ 0.1188,  0.5334,  0.4924,  0.5270, -0.1527,  0.5433,  0.9290,  0.8348,
         1.3303,  0.2405,  0.2285,  1.1031,  0.0293,  0.0210, -0.0843, -3.9176],
       device='cuda:1')
Solve time for step 4 3.9387708969879895
Current ori: tensor([ 0.0293,  0.0210, -0.0843], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5638], device='cuda:1')
Storing RECOVERY transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean 0.0060 -> 0.0062, std: 0.0759
Collected 43 transitions for RL
Original likelihood: -124.6330337524414
Adjusted likelihood: -124.6330337524414
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0283,  0.0218, -0.0755], device='cuda:1')
5 turn
Sampling time 3.6439771620207466
tensor([ 0.0684,  0.5961,  0.5345,  0.5433, -0.1530,  0.5467,  0.9250,  0.8292,
         1.3261,  0.2486,  0.2289,  1.1061,  0.0283,  0.0218, -0.0755, -3.5771],
       device='cuda:1')
Original likelihood: -107.10409545898438
Adjusted likelihood: -107.10409545898438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.868472745001782
Current ori: tensor([ 0.0283,  0.0218, -0.0755], device='cuda:1')
Middle force: tensor([1.1226, 0.7200, 0.5580, 0.5390, 0.8376, 0.8805, 0.5326, 0.5642, 0.6181,
        0.5207, 0.5640, 0.5573], device='cuda:1')
Thumb force: tensor([0.8810, 0.6861, 1.0322, 1.0212, 0.5612, 0.5814, 0.6264, 0.5286, 0.5714,
        0.6063, 0.5993, 0.5813], device='cuda:1')
Index force: tensor([0.5245, 0.9533, 0.5484, 0.5040, 0.5461, 0.5452, 0.6754, 0.5802, 0.8132,
        0.6359, 0.5925, 0.5692], device='cuda:1')
Storing NORMAL transition: reward=-0.1086 (scaled=-0.1086), steps=1
Reward stats updated: mean 0.0062 -> 0.0036, std: 0.0769
Collected 44 transitions for RL
tensor([ 0.0065,  0.6043,  0.4512,  0.5554, -0.2354,  0.4932,  0.9344,  0.8473,
         1.3789,  0.2007,  0.2882,  1.1340,  0.0612,  0.0754,  0.0268, -3.1429],
       device='cuda:1')
Original likelihood: -229.9695587158203
Adjusted likelihood: -229.9695587158203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 215.41537475585938
Projection step: 1, Loss: 220.74925231933594
Projection step: 2, Loss: 197.75405883789062
Projection step: 3, Loss: 181.35678100585938
Projection step: 4, Loss: 176.89663696289062
Projection step: 5, Loss: 207.35658264160156
Projection step: 6, Loss: 194.56497192382812
Projection step: 7, Loss: 165.17950439453125
Projection step: 8, Loss: 186.3153533935547
Projection step: 9, Loss: 184.5575714111328
Projection step: 10, Loss: 179.48818969726562
Projection step: 11, Loss: 190.71885681152344
Projection step: 12, Loss: 196.94998168945312
Projection step: 13, Loss: 188.80828857421875
Projection step: 14, Loss: 187.19146728515625
Projection step: 15, Loss: 173.22906494140625
Projection step: 16, Loss: 195.242431640625
Projection step: 17, Loss: 170.37261962890625
Projection step: 18, Loss: 181.67079162597656
Projection step: 19, Loss: 181.8890380859375
Projection step: 20, Loss: 189.03060913085938
Projection step: 21, Loss: 204.93447875976562
Projection step: 22, Loss: 185.8013458251953
Projection step: 23, Loss: 178.41668701171875
Projection step: 24, Loss: 179.83987426757812
Final likelihood: tensor([-164.1512, -228.4607, -191.0907, -151.1165, -215.7752, -178.8127,
        -171.4518, -166.2193, -220.0830, -196.0261, -162.3903, -215.8617,
        -221.2198, -173.3795, -200.9038, -177.6097])
Final projection likelihood: -189.6595
1 mode projection failed, trying anyway
New goal: tensor([-0.0267,  0.5863,  0.3931,  0.7289, -0.1733,  0.4455,  0.8641,  0.8243,
         1.3351,  0.2587,  0.2304,  1.1834,  0.0628,  0.0695,  0.1030],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -221.41220092773438
Adjusted likelihood: -221.41220092773438
Likelihood residual: 0.0
Original likelihood: -194.47743225097656
Adjusted likelihood: -194.47743225097656
Likelihood residual: 0.0
{'index': 194.47743225097656, 'thumb_middle': 221.41220092773438}
Current yaw: tensor([0.0612, 0.0754, 0.0268], device='cuda:1')
6 index
tensor([ 0.0065,  0.6043,  0.4512,  0.5554, -0.2354,  0.4932,  0.9344,  0.8473,
         1.3789,  0.2007,  0.2882,  1.1340,  0.0612,  0.0754,  0.0268, -3.1429],
       device='cuda:1')
Solve time for step 1 10.59175426902948
Current ori: tensor([0.0612, 0.0754, 0.0268], device='cuda:1')
Middle force: tensor([0.5588, 0.5464, 0.5168, 0.5159], device='cuda:1')
Thumb force: tensor([0.6054, 0.6115, 0.6310, 0.5922], device='cuda:1')
tensor([ 0.0275,  0.5317,  0.3578,  0.6738, -0.2120,  0.5026,  0.9313,  0.8670,
         1.3484,  0.2289,  0.2733,  1.1564,  0.0607,  0.0596,  0.0162, -3.8682],
       device='cuda:1')
Solve time for step 2 4.288736393034924
Current ori: tensor([0.0607, 0.0596, 0.0162], device='cuda:1')
Middle force: tensor([0.5410, 0.5143, 0.5140], device='cuda:1')
Thumb force: tensor([0.6056, 0.6256, 0.5895], device='cuda:1')
tensor([ 0.0276,  0.5307,  0.3482,  0.6962, -0.2001,  0.5103,  0.9310,  0.8612,
         1.3508,  0.2194,  0.2555,  1.1657,  0.0572,  0.0521,  0.0133, -4.4122],
       device='cuda:1')
Solve time for step 3 4.1306513819727115
Current ori: tensor([0.0572, 0.0521, 0.0133], device='cuda:1')
Middle force: tensor([0.5224, 0.5595], device='cuda:1')
Thumb force: tensor([0.5204, 0.5543], device='cuda:1')
tensor([ 0.0206,  0.5289,  0.3414,  0.7035, -0.2116,  0.5008,  0.9361,  0.8642,
         1.3527,  0.2218,  0.2690,  1.1602,  0.0613,  0.0590,  0.0163, -5.0360],
       device='cuda:1')
Solve time for step 4 3.8942857760121115
Current ori: tensor([0.0613, 0.0590, 0.0163], device='cuda:1')
Middle force: tensor([0.5262], device='cuda:1')
Thumb force: tensor([0.5021], device='cuda:1')
Storing RECOVERY transition: reward=0.0027 (scaled=0.0027), steps=1
Reward stats updated: mean 0.0036 -> 0.0036, std: 0.0761
Collected 45 transitions for RL
Original likelihood: -222.23260498046875
Adjusted likelihood: -222.23260498046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 219.947998046875
Projection step: 1, Loss: 211.53097534179688
Projection step: 2, Loss: 212.7000274658203
Projection step: 3, Loss: 215.55908203125
Projection step: 4, Loss: 207.22650146484375
Projection step: 5, Loss: 210.91433715820312
Projection step: 6, Loss: 192.1822509765625
Projection step: 7, Loss: 202.88650512695312
Projection step: 8, Loss: 202.5208282470703
Projection step: 9, Loss: 198.17337036132812
Projection step: 10, Loss: 193.1427001953125
Projection step: 11, Loss: 199.4095001220703
Projection step: 12, Loss: 195.83444213867188
Projection step: 13, Loss: 184.7601776123047
Projection step: 14, Loss: 194.4117431640625
Projection step: 15, Loss: 190.0759735107422
Projection step: 16, Loss: 187.9148406982422
Projection step: 17, Loss: 191.98410034179688
Projection step: 18, Loss: 187.86524963378906
Projection step: 19, Loss: 180.39682006835938
Projection step: 20, Loss: 187.2852020263672
Projection step: 21, Loss: 190.6403350830078
Projection step: 22, Loss: 191.25238037109375
Projection step: 23, Loss: 176.85731506347656
Projection step: 24, Loss: 180.7176055908203
Final likelihood: tensor([-188.5582, -170.1726, -174.7910, -171.1853, -171.0860, -191.4262,
         -92.1980, -184.5591, -200.2980, -178.7444, -175.7617, -174.6742,
        -179.9693, -177.3706, -158.4262, -172.5815])
Final projection likelihood: -172.6127
1 mode projection failed, trying anyway
New goal: tensor([-0.0559,  0.5872,  0.2978,  0.8382, -0.1608,  0.4780,  0.8474,  0.7758,
         1.3374,  0.2475,  0.2064,  1.2147,  0.0595,  0.0610, -0.2124],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -177.0721893310547
Adjusted likelihood: -177.0721893310547
Likelihood residual: 0.0
Original likelihood: -168.78976440429688
Adjusted likelihood: -168.78976440429688
Likelihood residual: 0.0
{'index': 168.78976440429688, 'thumb_middle': 177.0721893310547}
Current yaw: tensor([0.0590, 0.0643, 0.0256], device='cuda:1')
7 index
tensor([-0.0219,  0.5826,  0.3771,  0.7214, -0.2178,  0.5050,  0.9266,  0.8572,
         1.3558,  0.2229,  0.2789,  1.1463,  0.0590,  0.0643,  0.0256, -5.2708],
       device='cuda:1')
Solve time for step 1 10.546063215006143
Current ori: tensor([0.0590, 0.0643, 0.0256], device='cuda:1')
Middle force: tensor([0.5351, 0.6232, 0.5742, 0.5448], device='cuda:1')
Thumb force: tensor([0.5228, 0.5810, 0.5338, 0.6271], device='cuda:1')
tensor([-0.0087,  0.5317,  0.2666,  0.7950, -0.2134,  0.5158,  0.9209,  0.8293,
         1.3876,  0.1807,  0.2582,  1.1339,  0.0490,  0.0639,  0.0220,  6.1347],
       device='cuda:1')
Solve time for step 2 4.14030901301885
Current ori: tensor([0.0490, 0.0639, 0.0220], device='cuda:1')
Middle force: tensor([0.6187, 0.5707, 0.5421], device='cuda:1')
Thumb force: tensor([0.5730, 0.5309, 0.6222], device='cuda:1')
tensor([-5.0461e-03,  5.3645e-01,  2.5567e-01,  8.0533e-01, -1.9313e-01,
         5.2238e-01,  9.2826e-01,  8.2626e-01,  1.3628e+00,  2.0321e-01,
         2.4354e-01,  1.1577e+00,  4.8029e-02,  5.0390e-02,  2.3893e-02,
         5.3116e+00], device='cuda:1')
Solve time for step 3 4.111574798007496
Current ori: tensor([0.0480, 0.0504, 0.0239], device='cuda:1')
Middle force: tensor([0.5912, 0.6009], device='cuda:1')
Thumb force: tensor([0.5979, 0.5069], device='cuda:1')
tensor([-0.0073,  0.5359,  0.2526,  0.8089, -0.1973,  0.5145,  0.9333,  0.8403,
         1.3566,  0.2116,  0.2508,  1.1631,  0.0534,  0.0518,  0.0224,  4.9850],
       device='cuda:1')
Solve time for step 4 4.216409110988025
Current ori: tensor([0.0534, 0.0518, 0.0224], device='cuda:1')
Middle force: tensor([0.5310], device='cuda:1')
Thumb force: tensor([0.5120], device='cuda:1')
Storing RECOVERY transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean 0.0036 -> 0.0038, std: 0.0753
Collected 46 transitions for RL
Original likelihood: -180.992431640625
Adjusted likelihood: -180.992431640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 187.5356903076172
Projection step: 1, Loss: 167.61962890625
Projection step: 2, Loss: 166.06150817871094
Projection step: 3, Loss: 163.114013671875
Projection step: 4, Loss: 161.93661499023438
Projection step: 5, Loss: 160.77452087402344
Projection step: 6, Loss: 161.24880981445312
Projection step: 7, Loss: 156.4842529296875
Projection step: 8, Loss: 153.17486572265625
Projection step: 9, Loss: 153.1629180908203
Projection step: 10, Loss: 148.3957061767578
Projection step: 11, Loss: 150.18923950195312
Projection step: 12, Loss: 152.31265258789062
Projection step: 13, Loss: 140.17169189453125
Projection step: 14, Loss: 143.52822875976562
Projection step: 15, Loss: 141.48358154296875
Projection step: 16, Loss: 140.907958984375
Projection step: 17, Loss: 140.50634765625
Projection step: 18, Loss: 136.82565307617188
Projection step: 19, Loss: 135.89630126953125
Projection step: 20, Loss: 128.8194580078125
Projection step: 21, Loss: 130.55796813964844
Projection step: 22, Loss: 131.8114471435547
Projection step: 23, Loss: 124.13357543945312
Projection step: 24, Loss: 124.56912231445312
Final likelihood: tensor([-119.4376, -141.1464, -120.2749, -128.6879, -126.3357, -115.9524,
        -138.2183, -124.0855, -113.1070, -109.1732, -114.1533, -110.6361,
        -124.0080, -121.5154, -120.4476, -127.6587])
Final projection likelihood: -122.1774
1 mode projection succeeded
New goal: tensor([ 0.0042,  0.5865,  0.3667,  0.7883, -0.1233,  0.4731,  0.9184,  0.7308,
         1.3072,  0.2539,  0.1923,  1.1768,  0.0386,  0.0355, -0.4106],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -144.01980590820312
Adjusted likelihood: -144.01980590820312
Likelihood residual: 0.0
Original likelihood: -139.66844177246094
Adjusted likelihood: -139.66844177246094
Likelihood residual: 0.0
{'index': 139.66844177246094, 'thumb_middle': 144.01980590820312}
Current yaw: tensor([0.0450, 0.0454, 0.0178], device='cuda:1')
8 index
tensor([-0.0479,  0.5886,  0.2893,  0.8336, -0.1856,  0.5303,  0.9227,  0.8270,
         1.3548,  0.2112,  0.2399,  1.1555,  0.0450,  0.0454,  0.0178,  4.9506],
       device='cuda:1')
Solve time for step 1 10.706145775038749
Current ori: tensor([0.0450, 0.0454, 0.0178], device='cuda:1')
Middle force: tensor([0.5653, 0.5596, 0.5176, 0.5519], device='cuda:1')
Thumb force: tensor([0.5785, 0.5477, 0.5363, 0.5033], device='cuda:1')
tensor([ 4.1662e-02,  5.3544e-01,  3.1194e-01,  7.7254e-01, -1.5598e-01,
         5.3804e-01,  9.5756e-01,  7.6179e-01,  1.3212e+00,  2.4867e-01,
         2.2572e-01,  1.1471e+00,  3.1795e-02,  2.6721e-02, -2.2296e-03,
        -5.8804e+00], device='cuda:1')
Solve time for step 2 4.210511755023617
Current ori: tensor([ 0.0318,  0.0267, -0.0022], device='cuda:1')
Middle force: tensor([0.5566, 0.5159, 0.5486], device='cuda:1')
Thumb force: tensor([0.5432, 0.5338, 0.5027], device='cuda:1')
tensor([ 0.0507,  0.5371,  0.3205,  0.7654, -0.1567,  0.5312,  0.9695,  0.7608,
         1.3462,  0.2148,  0.2043,  1.1601,  0.0329,  0.0261, -0.0147, -4.9322],
       device='cuda:1')
Solve time for step 3 4.4762196989613585
Current ori: tensor([ 0.0329,  0.0261, -0.0147], device='cuda:1')
Middle force: tensor([0.5141, 0.5445], device='cuda:1')
Thumb force: tensor([0.5278, 0.5018], device='cuda:1')
tensor([ 5.1692e-02,  5.3975e-01,  3.2161e-01,  7.6163e-01, -1.6521e-01,
         5.2605e-01,  9.6858e-01,  7.6305e-01,  1.3405e+00,  2.2596e-01,
         2.1913e-01,  1.1611e+00,  3.6807e-02,  3.2254e-02,  3.8565e-03,
        -4.5965e+00], device='cuda:1')
Solve time for step 4 4.041660193004645
Current ori: tensor([0.0368, 0.0323, 0.0039], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5910], device='cuda:1')
Storing RECOVERY transition: reward=0.0343 (scaled=0.0343), steps=1
Reward stats updated: mean 0.0038 -> 0.0044, std: 0.0746
Collected 47 transitions for RL
Original likelihood: -132.36148071289062
Adjusted likelihood: -132.36148071289062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0353,  0.0301, -0.0018], device='cuda:1')
9 turn
Sampling time 3.7373516200459562
tensor([ 4.4162e-03,  5.9024e-01,  3.5946e-01,  7.8474e-01, -1.6199e-01,
         5.2789e-01,  9.6897e-01,  7.6126e-01,  1.3330e+00,  2.3820e-01,
         2.1698e-01,  1.1625e+00,  3.5295e-02,  3.0100e-02, -1.8178e-03,
        -4.5779e+00], device='cuda:1')
Original likelihood: -131.6691131591797
Adjusted likelihood: -131.6691131591797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.997086816991214
Current ori: tensor([ 0.0353,  0.0301, -0.0018], device='cuda:1')
Middle force: tensor([0.8892, 1.1977, 1.6698, 0.6203, 0.5231, 0.5532, 0.5738, 0.8396, 0.6182,
        1.0867, 0.7391, 0.5928], device='cuda:1')
Thumb force: tensor([0.6638, 1.8170, 0.7715, 0.5891, 0.6253, 0.5861, 0.8525, 0.5762, 0.6080,
        1.5978, 0.7274, 0.5017], device='cuda:1')
Index force: tensor([0.7333, 0.8335, 1.0169, 0.6116, 0.5811, 0.6402, 0.5488, 0.5230, 0.5889,
        0.5510, 1.0662, 0.5980], device='cuda:1')
Storing NORMAL transition: reward=0.0007 (scaled=0.0007), steps=1
Reward stats updated: mean 0.0044 -> 0.0044, std: 0.0738
Collected 48 transitions for RL
tensor([ 1.5958e-02,  6.9697e-01,  2.0325e-01,  7.9814e-01, -2.2849e-01,
         5.7814e-01,  8.6119e-01,  9.5669e-01,  1.3120e+00,  3.6525e-01,
         1.9475e-01,  1.0140e+00,  2.1323e-02,  3.0485e-02, -1.8341e-03,
        -4.5174e+00], device='cuda:1')
Original likelihood: -217.24172973632812
Adjusted likelihood: -217.24172973632812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 218.88247680664062
Projection step: 1, Loss: 212.2642822265625
Projection step: 2, Loss: 201.4118194580078
Projection step: 3, Loss: 189.51071166992188
Projection step: 4, Loss: 181.72998046875
Projection step: 5, Loss: 174.02383422851562
Projection step: 6, Loss: 165.90093994140625
Projection step: 7, Loss: 160.94378662109375
Projection step: 8, Loss: 153.26773071289062
Projection step: 9, Loss: 145.07350158691406
Projection step: 10, Loss: 134.31143188476562
Projection step: 11, Loss: 128.70762634277344
Projection step: 12, Loss: 122.42758178710938
Projection step: 13, Loss: 110.26399230957031
Projection step: 14, Loss: 105.8980484008789
Projection step: 15, Loss: 107.24625396728516
Projection step: 16, Loss: 101.39826202392578
Final likelihood: tensor([-103.4950, -104.4475, -105.0159,  -77.5071, -110.8021, -107.4715,
        -108.3364, -106.7411, -100.1125, -103.4210, -108.4111,  -96.4147,
        -100.0318, -105.2007,  -93.5081,  -91.4557])
Final projection likelihood: -101.3983
1 mode projection succeeded
New goal: tensor([ 0.0386,  0.6352,  0.3640,  0.7016, -0.1200,  0.5284,  0.8396,  0.8615,
         1.3173,  0.2951,  0.1873,  1.1583,  0.0215,  0.0238,  0.2040],
       device='cuda:1')
tensor([[0.0076]], device='cuda:1') tensor([[0.0051]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -125.98019409179688
Adjusted likelihood: -125.98019409179688
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 125.98019409179688}
Current yaw: tensor([ 0.0213,  0.0305, -0.0018], device='cuda:1')
10 thumb_middle
tensor([ 1.5958e-02,  6.9697e-01,  2.0325e-01,  7.9814e-01, -2.2849e-01,
         5.7814e-01,  8.6119e-01,  9.5669e-01,  1.3120e+00,  3.6525e-01,
         1.9475e-01,  1.0140e+00,  2.1323e-02,  3.0485e-02, -1.8341e-03,
        -4.5174e+00], device='cuda:1')
Solve time for step 1 8.786691698012874
Current ori: tensor([ 0.0213,  0.0305, -0.0018], device='cuda:1')
Index force: tensor([0.5915, 0.5721, 0.5767, 0.6021], device='cuda:1')
tensor([ 1.8281e-02,  6.3788e-01,  3.3828e-01,  7.1616e-01, -2.1195e-01,
         5.1509e-01,  8.1903e-01,  8.5729e-01,  1.2814e+00,  2.8960e-01,
         1.1881e-01,  1.1089e+00,  2.4415e-02,  2.9069e-02, -1.8341e-03,
        -4.5236e+00], device='cuda:1')
Solve time for step 2 3.555252530029975
Current ori: tensor([ 0.0244,  0.0291, -0.0018], device='cuda:1')
Index force: tensor([0.5877, 0.5936, 0.5675], device='cuda:1')
tensor([ 1.6672e-02,  6.2331e-01,  3.6320e-01,  7.0638e-01, -2.1109e-01,
         5.2048e-01,  8.1451e-01,  8.4592e-01,  1.2822e+00,  2.9816e-01,
         1.0394e-01,  1.1302e+00,  2.6555e-02,  3.0023e-02, -1.8341e-03,
        -4.5232e+00], device='cuda:1')
Solve time for step 3 3.505561881000176
Current ori: tensor([ 0.0266,  0.0300, -0.0018], device='cuda:1')
Index force: tensor([0.5794, 0.5565], device='cuda:1')
tensor([ 2.2008e-02,  6.3987e-01,  3.5289e-01,  6.8953e-01, -2.0869e-01,
         5.1370e-01,  8.2528e-01,  8.4234e-01,  1.2759e+00,  2.7871e-01,
         1.1181e-01,  1.1267e+00,  2.1398e-02,  2.7011e-02, -1.8341e-03,
        -4.5299e+00], device='cuda:1')
Solve time for step 4 3.379536497988738
Current ori: tensor([ 0.0214,  0.0270, -0.0018], device='cuda:1')
Index force: tensor([0.5705], device='cuda:1')
Storing RECOVERY transition: reward=0.0091 (scaled=0.0091), steps=1
Reward stats updated: mean 0.0044 -> 0.0045, std: 0.0730
Collected 49 transitions for RL
Original likelihood: -124.67829895019531
Adjusted likelihood: -124.67829895019531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0266,  0.0341, -0.0115], device='cuda:1')
11 turn
Sampling time 3.8214504590141587
tensor([ 0.0066,  0.6255,  0.3541,  0.6995, -0.1531,  0.5320,  0.8718,  0.8799,
         1.3420,  0.2909,  0.1813,  1.1615,  0.0266,  0.0341, -0.0115, -4.4847],
       device='cuda:1')
Original likelihood: -134.049072265625
Adjusted likelihood: -134.049072265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.100405846023932
Current ori: tensor([ 0.0266,  0.0341, -0.0115], device='cuda:1')
Middle force: tensor([0.5799, 1.6180, 0.5312, 0.5315, 0.6423, 1.5665, 0.5554, 0.5542, 0.5102,
        0.6102, 0.5061, 0.6125], device='cuda:1')
Thumb force: tensor([0.8244, 0.9272, 0.5014, 0.8580, 0.8199, 0.9955, 0.5971, 0.5624, 0.6748,
        0.7927, 0.5026, 0.5548], device='cuda:1')
Index force: tensor([0.5194, 0.6730, 0.7446, 0.5868, 0.5161, 0.5099, 0.6096, 0.6224, 0.5505,
        0.5325, 0.7085, 0.5578], device='cuda:1')
Storing NORMAL transition: reward=0.0465 (scaled=0.0465), steps=1
Reward stats updated: mean 0.0045 -> 0.0053, std: 0.0726
Collected 50 transitions for RL
tensor([-0.0076,  0.6126,  0.4116,  0.6014, -0.1236,  0.4275,  0.7938,  1.1088,
         1.3583,  0.3510,  0.1557,  1.1303,  0.0198,  0.0424, -0.0585, -4.5336],
       device='cuda:1')
Original likelihood: -182.25875854492188
Adjusted likelihood: -182.25875854492188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 181.74386596679688
Projection step: 1, Loss: 167.27291870117188
Projection step: 2, Loss: 163.85975646972656
Projection step: 3, Loss: 158.53631591796875
Projection step: 4, Loss: 142.97708129882812
Projection step: 5, Loss: 149.3022003173828
Projection step: 6, Loss: 131.54571533203125
Projection step: 7, Loss: 129.0076141357422
Projection step: 8, Loss: 122.22486114501953
Projection step: 9, Loss: 114.10958099365234
Projection step: 10, Loss: 105.03924560546875
Projection step: 11, Loss: 99.94064331054688
Final likelihood: tensor([-102.5316,  -96.3864,  -96.3851,  -92.5629, -104.1553,  -91.9513,
        -112.0136,  -93.7563, -103.8045,  -96.3022,  -90.1589,  -93.2743,
        -122.1742, -107.3656,  -98.6024,  -97.6255])
Final projection likelihood: -99.9406
1 mode projection succeeded
New goal: tensor([ 0.0380,  0.5988,  0.4871,  0.6056, -0.1142,  0.4659,  0.8458,  0.9829,
         1.3270,  0.3436,  0.1745,  1.1531,  0.0209,  0.0270, -0.8951],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0040]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -140.446044921875
Adjusted likelihood: -140.446044921875
Likelihood residual: 0.0
Original likelihood: -129.56832885742188
Adjusted likelihood: -129.56832885742188
Likelihood residual: 0.0
{'index': 129.56832885742188, 'thumb_middle': 140.446044921875}
Current yaw: tensor([ 0.0198,  0.0424, -0.0585], device='cuda:1')
12 index
tensor([-0.0076,  0.6126,  0.4116,  0.6014, -0.1236,  0.4275,  0.7938,  1.1088,
         1.3583,  0.3510,  0.1557,  1.1303,  0.0198,  0.0424, -0.0585, -4.5336],
       device='cuda:1')
Solve time for step 1 10.702011246001348
Current ori: tensor([ 0.0198,  0.0424, -0.0585], device='cuda:1')
Middle force: tensor([0.5546, 0.5158, 0.5394, 0.5444], device='cuda:1')
Thumb force: tensor([0.5506, 0.5590, 0.5121, 0.6544], device='cuda:1')
tensor([ 0.0756,  0.5394,  0.4212,  0.5815, -0.1153,  0.4216,  0.8469,  1.0295,
         1.3632,  0.3501,  0.1613,  1.1087,  0.0134,  0.0457, -0.0614, -4.0470],
       device='cuda:1')
Solve time for step 2 4.2599081650259905
Current ori: tensor([ 0.0134,  0.0457, -0.0614], device='cuda:1')
Middle force: tensor([0.5139, 0.5360, 0.5407], device='cuda:1')
Thumb force: tensor([0.5546, 0.5107, 0.6491], device='cuda:1')
tensor([ 0.0875,  0.5374,  0.4322,  0.5803, -0.0972,  0.4318,  0.8541,  1.0131,
         1.3599,  0.3471,  0.1393,  1.1257,  0.0099,  0.0345, -0.0583, -3.9623],
       device='cuda:1')
Solve time for step 3 4.124833812005818
Current ori: tensor([ 0.0099,  0.0345, -0.0583], device='cuda:1')
Middle force: tensor([0.5396, 0.5050], device='cuda:1')
Thumb force: tensor([0.6215, 0.5122], device='cuda:1')
tensor([ 0.0913,  0.5386,  0.4341,  0.5811, -0.0969,  0.4288,  0.8579,  1.0146,
         1.3584,  0.3493,  0.1399,  1.1269,  0.0108,  0.0341, -0.0611, -4.0596],
       device='cuda:1')
Solve time for step 4 3.84755559702171
Current ori: tensor([ 0.0108,  0.0341, -0.0611], device='cuda:1')
Middle force: tensor([0.5400], device='cuda:1')
Thumb force: tensor([0.5308], device='cuda:1')
Storing RECOVERY transition: reward=-0.0029 (scaled=-0.0029), steps=1
Reward stats updated: mean 0.0053 -> 0.0051, std: 0.0718
Collected 51 transitions for RL
Original likelihood: -187.7169952392578
Adjusted likelihood: -187.7169952392578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 179.16098022460938
Projection step: 1, Loss: 163.17132568359375
Projection step: 2, Loss: 147.93109130859375
Projection step: 3, Loss: 128.82789611816406
Projection step: 4, Loss: 123.56515502929688
Projection step: 5, Loss: 114.719482421875
Projection step: 6, Loss: 98.38825988769531
Final likelihood: tensor([ -96.5264,  -91.3184,  -91.2437,  -96.6514,  -99.3776,  -93.2060,
         -98.5343,  -96.2168,  -94.3628,  -89.0454,  -93.1019,  -94.0393,
         -99.3850, -113.4466, -128.5600,  -99.1968])
Final projection likelihood: -98.3883
1 mode projection succeeded
New goal: tensor([ 0.0465,  0.5919,  0.5006,  0.6152, -0.1113,  0.4575,  0.8702,  0.9344,
         1.3380,  0.3433,  0.1629,  1.1395,  0.0064,  0.0315, -0.2001],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -167.48550415039062
Adjusted likelihood: -167.48550415039062
Likelihood residual: 0.0
Original likelihood: -93.71736145019531
Adjusted likelihood: -93.71736145019531
Likelihood residual: 0.0
{'index': 93.71736145019531, 'thumb_middle': 167.48550415039062}
Current yaw: tensor([ 0.0073,  0.0438, -0.0553], device='cuda:1')
13 index
tensor([ 0.0345,  0.5997,  0.4723,  0.5988, -0.1114,  0.4316,  0.8494,  1.0019,
         1.3661,  0.3465,  0.1559,  1.1024,  0.0073,  0.0438, -0.0553, -4.1344],
       device='cuda:1')
Solve time for step 1 10.679587448015809
Current ori: tensor([ 0.0073,  0.0438, -0.0553], device='cuda:1')
Middle force: tensor([0.5119, 0.5389, 0.5858, 0.5382], device='cuda:1')
Thumb force: tensor([0.5848, 0.5742, 0.5953, 0.5261], device='cuda:1')
tensor([ 0.0927,  0.5322,  0.4453,  0.5883, -0.1039,  0.4252,  0.8781,  0.9688,
         1.3617,  0.3501,  0.1494,  1.1077,  0.0055,  0.0393, -0.0549, -4.2670],
       device='cuda:1')
Solve time for step 2 4.261158696957864
Current ori: tensor([ 0.0055,  0.0393, -0.0549], device='cuda:1')
Middle force: tensor([0.5184, 0.5503, 0.5364], device='cuda:1')
Thumb force: tensor([0.6116, 0.5221, 0.5568], device='cuda:1')
tensor([ 9.7304e-02,  5.3332e-01,  4.4792e-01,  5.8786e-01, -9.6821e-02,
         4.2845e-01,  8.8252e-01,  9.6187e-01,  1.3663e+00,  3.4030e-01,
         1.3705e-01,  1.1132e+00,  3.8196e-03,  3.4791e-02, -5.8203e-02,
        -4.5458e+00], device='cuda:1')
Solve time for step 3 4.43228215695126
Current ori: tensor([ 0.0038,  0.0348, -0.0582], device='cuda:1')
Middle force: tensor([0.5782, 0.5335], device='cuda:1')
Thumb force: tensor([0.5804, 0.5222], device='cuda:1')
tensor([ 9.8488e-02,  5.3299e-01,  4.4730e-01,  5.8811e-01, -9.9969e-02,
         4.3144e-01,  8.7855e-01,  9.5570e-01,  1.3718e+00,  3.3469e-01,
         1.3886e-01,  1.1043e+00,  1.4342e-03,  3.7184e-02, -5.8234e-02,
        -4.9024e+00], device='cuda:1')
Solve time for step 4 3.942813250992913
Current ori: tensor([ 0.0014,  0.0372, -0.0582], device='cuda:1')
Middle force: tensor([0.5296], device='cuda:1')
Thumb force: tensor([0.5195], device='cuda:1')
Storing RECOVERY transition: reward=-0.0142 (scaled=-0.0142), steps=1
Reward stats updated: mean 0.0051 -> 0.0048, std: 0.0712
Collected 52 transitions for RL
Original likelihood: -130.76950073242188
Adjusted likelihood: -130.76950073242188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0027,  0.0360, -0.0433], device='cuda:1')
14 turn
Sampling time 3.5865964620024897
tensor([ 4.7969e-02,  5.9192e-01,  4.9064e-01,  6.1010e-01, -9.8541e-02,
         4.3417e-01,  8.7756e-01,  9.5406e-01,  1.3654e+00,  3.4112e-01,
         1.3780e-01,  1.1155e+00,  2.6628e-03,  3.6039e-02, -4.3348e-02,
        -5.0394e+00], device='cuda:1')
Original likelihood: -133.21881103515625
Adjusted likelihood: -133.21881103515625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.126050136983395
Current ori: tensor([ 0.0027,  0.0360, -0.0433], device='cuda:1')
Middle force: tensor([0.7212, 1.0994, 0.5628, 0.5370, 0.5252, 0.7160, 0.5151, 0.5095, 0.4933,
        0.5413, 0.5585, 0.5373], device='cuda:1')
Thumb force: tensor([1.2822, 1.4192, 0.6289, 0.5612, 0.8493, 1.9348, 0.6728, 0.5316, 0.5246,
        0.6829, 0.5544, 0.8181], device='cuda:1')
Index force: tensor([1.0935, 1.4499, 0.9625, 0.7361, 1.2607, 0.6963, 0.5355, 0.7434, 0.7898,
        0.5302, 0.5786, 0.5632], device='cuda:1')
Storing NORMAL transition: reward=0.1065 (scaled=0.1065), steps=1
Reward stats updated: mean 0.0048 -> 0.0067, std: 0.0719
Collected 53 transitions for RL
tensor([ 7.2394e-02,  5.8148e-01,  5.2859e-01,  6.1040e-01, -8.0059e-02,
         3.9948e-01,  9.3424e-01,  9.6783e-01,  1.4261e+00,  2.5069e-01,
         1.2119e-01,  1.0422e+00,  4.3177e-03,  2.3245e-02, -1.4930e-01,
        -4.9027e+00], device='cuda:1')
Original likelihood: -94.20675659179688
Adjusted likelihood: -94.20675659179688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.623928920016624
Current ori: tensor([ 0.0043,  0.0232, -0.1493], device='cuda:1')
Middle force: tensor([0.5428, 0.5776, 0.9377, 0.5240, 0.5625, 0.5639, 1.2041, 1.1027, 0.5150,
        0.5008, 0.6353], device='cuda:1')
Thumb force: tensor([0.6055, 0.5477, 1.1437, 0.5709, 0.6710, 0.8776, 0.7684, 1.0593, 0.5833,
        0.5593, 0.5986], device='cuda:1')
Index force: tensor([0.5284, 0.5567, 0.9540, 0.5253, 0.5514, 0.5899, 0.8489, 1.2127, 0.7011,
        0.7840, 0.5906], device='cuda:1')
Storing NORMAL transition: reward=0.0207 (scaled=0.0207), steps=1
Reward stats updated: mean 0.0067 -> 0.0069, std: 0.0712
Collected 54 transitions for RL
tensor([ 7.2563e-02,  6.0767e-01,  4.9464e-01,  6.0565e-01, -7.3547e-02,
         4.2204e-01,  8.9219e-01,  9.8870e-01,  1.4246e+00,  2.6200e-01,
         1.3668e-01,  9.9857e-01, -1.8101e-03,  2.1879e-02, -1.6993e-01,
        -4.8882e+00], device='cuda:1')
Original likelihood: -95.35752868652344
Adjusted likelihood: -95.35752868652344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.138842285028659
Current ori: tensor([-0.0018,  0.0219, -0.1699], device='cuda:1')
Middle force: tensor([0.5755, 0.9272, 0.5224, 0.5604, 0.5605, 1.1850, 1.0802, 0.5109, 0.5006,
        0.6309], device='cuda:1')
Thumb force: tensor([0.5457, 1.1277, 0.5706, 0.6665, 0.8703, 0.7622, 1.0516, 0.5815, 0.5570,
        0.5963], device='cuda:1')
Index force: tensor([0.5531, 0.9439, 0.5247, 0.5493, 0.5883, 0.8403, 1.1935, 0.7188, 0.7926,
        0.5887], device='cuda:1')
Storing NORMAL transition: reward=0.0772 (scaled=0.0772), steps=1
Reward stats updated: mean 0.0069 -> 0.0082, std: 0.0712
Collected 55 transitions for RL
tensor([ 1.1952e-01,  6.2601e-01,  5.0548e-01,  6.2779e-01, -6.9537e-02,
         3.7514e-01,  1.0882e+00,  1.0140e+00,  1.3925e+00,  3.0503e-01,
         1.3210e-01,  9.8050e-01, -4.0666e-03, -5.9063e-03, -2.4661e-01,
        -4.7320e+00], device='cuda:1')
Original likelihood: -134.61317443847656
Adjusted likelihood: -134.61317443847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.009800597967114
Current ori: tensor([-0.0041, -0.0059, -0.2466], device='cuda:1')
Middle force: tensor([1.0242, 0.5297, 0.5012, 0.5831, 0.5574, 0.5048, 0.5016, 0.5034, 0.5782],
       device='cuda:1')
Thumb force: tensor([1.2365, 0.8936, 0.5280, 0.5344, 0.5399, 1.2985, 0.5447, 0.5616, 0.5534],
       device='cuda:1')
Index force: tensor([0.5269, 0.5399, 0.6423, 0.5167, 0.6475, 0.5260, 0.6149, 0.6137, 0.5331],
       device='cuda:1')
Storing NORMAL transition: reward=0.0257 (scaled=0.0257), steps=1
Reward stats updated: mean 0.0082 -> 0.0085, std: 0.0706
Collected 56 transitions for RL
tensor([-4.1951e-02,  4.7024e-01,  5.5951e-01,  6.4941e-01, -1.3399e-01,
         3.5105e-01,  1.0350e+00,  1.0966e+00,  1.4998e+00,  2.8833e-01,
         6.7146e-02,  8.1411e-01,  4.6104e-03,  3.5073e-02, -2.7441e-01,
        -4.7901e+00], device='cuda:1')
Original likelihood: -208.41864013671875
Adjusted likelihood: -208.41864013671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 178.79408264160156
Projection step: 1, Loss: 194.5843048095703
Projection step: 2, Loss: 196.23866271972656
Projection step: 3, Loss: 177.04226684570312
Projection step: 4, Loss: 163.4405517578125
Projection step: 5, Loss: 155.36502075195312
Projection step: 6, Loss: 134.9062042236328
Projection step: 7, Loss: 148.30343627929688
Projection step: 8, Loss: 139.33628845214844
Projection step: 9, Loss: 136.71917724609375
Projection step: 10, Loss: 122.36540222167969
Projection step: 11, Loss: 119.4206771850586
Projection step: 12, Loss: 114.44621276855469
Projection step: 13, Loss: 107.28353118896484
Projection step: 14, Loss: 99.96929168701172
Final likelihood: tensor([-104.7581,  -73.9195,  -89.6885, -117.5917, -102.3921, -117.0721,
        -122.4421,  -99.0719,  -89.2150, -102.7695,  -93.0219,  -90.4047,
        -116.4587,  -99.9510,  -88.0140,  -92.7377])
Final projection likelihood: -99.9693
1 mode projection succeeded
New goal: tensor([-0.0029,  0.5167,  0.5793,  0.6212, -0.1007,  0.4111,  0.9386,  0.9559,
         1.4256,  0.3395,  0.1379,  1.0437,  0.0029,  0.0222,  0.1548],
       device='cuda:1')
tensor([[0.0096]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -108.85252380371094
Adjusted likelihood: -108.85252380371094
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 108.85252380371094}
Current yaw: tensor([ 0.0046,  0.0351, -0.2744], device='cuda:1')
15 thumb_middle
tensor([-4.1951e-02,  4.7024e-01,  5.5951e-01,  6.4941e-01, -1.3399e-01,
         3.5105e-01,  1.0350e+00,  1.0966e+00,  1.4998e+00,  2.8833e-01,
         6.7146e-02,  8.1411e-01,  4.6104e-03,  3.5073e-02, -2.7441e-01,
        -4.7901e+00], device='cuda:1')
Solve time for step 1 9.116033940052148
Current ori: tensor([ 0.0046,  0.0351, -0.2744], device='cuda:1')
Index force: tensor([0.5841, 0.5971, 0.5546, 0.5967], device='cuda:1')
tensor([-2.1327e-02,  4.7055e-01,  5.8012e-01,  6.4111e-01, -1.9563e-01,
         3.8633e-01,  9.2595e-01,  9.6656e-01,  1.3832e+00,  3.1479e-01,
         5.1405e-02,  9.5925e-01,  3.2009e-03,  2.4578e-02, -2.7437e-01,
        -4.7747e+00], device='cuda:1')
Solve time for step 2 3.399266938038636
Current ori: tensor([ 0.0032,  0.0246, -0.2744], device='cuda:1')
Index force: tensor([0.5853, 0.5459, 0.5880], device='cuda:1')
tensor([-0.0143,  0.4951,  0.5606,  0.6234, -0.1896,  0.4037,  0.9119,  0.9549,
         1.3694,  0.3139,  0.0422,  0.9869, -0.0048,  0.0205, -0.2744, -4.7728],
       device='cuda:1')
Solve time for step 3 3.421842873969581
Current ori: tensor([-0.0048,  0.0205, -0.2744], device='cuda:1')
Index force: tensor([0.5685, 0.5556], device='cuda:1')
tensor([-0.0101,  0.4980,  0.5599,  0.6237, -0.1851,  0.4073,  0.9126,  0.9454,
         1.3707,  0.3183,  0.0335,  0.9907, -0.0056,  0.0182, -0.2744, -4.7692],
       device='cuda:1')
Solve time for step 4 3.384074916015379
Current ori: tensor([-0.0056,  0.0182, -0.2744], device='cuda:1')
Index force: tensor([0.5462], device='cuda:1')
Storing RECOVERY transition: reward=-0.0036 (scaled=-0.0009), steps=4
Reward stats updated: mean 0.0085 -> 0.0084, std: 0.0700
Collected 57 transitions for RL
Original likelihood: -119.42762756347656
Adjusted likelihood: -119.42762756347656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0047,  0.0284, -0.2701], device='cuda:1')
16 turn
Sampling time 3.606964948994573
tensor([-3.1152e-02,  4.9956e-01,  5.4815e-01,  6.0837e-01, -1.2491e-01,
         4.4850e-01,  9.4100e-01,  9.4984e-01,  1.4314e+00,  3.4362e-01,
         9.9018e-02,  1.0175e+00, -4.6685e-03,  2.8386e-02, -2.7010e-01,
        -4.7831e+00], device='cuda:1')
Original likelihood: -120.25621032714844
Adjusted likelihood: -120.25621032714844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.76619185198797
Current ori: tensor([-0.0047,  0.0284, -0.2701], device='cuda:1')
Middle force: tensor([0.8461, 1.5215, 1.1280, 0.5064, 1.3882, 0.6308, 0.6860, 0.5534, 0.6006,
        0.5771, 0.7738, 0.5736], device='cuda:1')
Thumb force: tensor([0.8623, 0.8118, 0.9784, 0.5619, 1.0213, 1.1728, 0.5427, 0.5626, 0.6184,
        1.0804, 0.5910, 0.7030], device='cuda:1')
Index force: tensor([0.8863, 0.8595, 0.5712, 0.8577, 1.2705, 0.5775, 0.6263, 0.5731, 0.6279,
        0.6203, 0.5599, 0.5820], device='cuda:1')
Storing NORMAL transition: reward=-0.0333 (scaled=-0.0333), steps=1
Reward stats updated: mean 0.0084 -> 0.0077, std: 0.0696
Collected 58 transitions for RL
tensor([-0.0060,  0.4573,  0.5578,  0.7447, -0.0441,  0.4594,  0.8332,  1.0115,
         1.4417,  0.3204,  0.0092,  1.1460,  0.0123,  0.0080, -0.2362, -4.7642],
       device='cuda:1')
Original likelihood: -111.53157043457031
Adjusted likelihood: -111.53157043457031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.639461797953118
Current ori: tensor([ 0.0123,  0.0080, -0.2362], device='cuda:1')
Middle force: tensor([1.4744, 1.0897, 0.5045, 1.3413, 0.6295, 0.6793, 0.5480, 0.5942, 0.5723,
        0.7629, 0.5695], device='cuda:1')
Thumb force: tensor([0.7910, 0.9592, 0.5549, 0.9899, 1.1353, 0.5369, 0.5597, 0.6124, 1.0626,
        0.5854, 0.6929], device='cuda:1')
Index force: tensor([0.8323, 0.5683, 0.8718, 1.2536, 0.5707, 0.6218, 0.5698, 0.6233, 0.6156,
        0.5563, 0.5782], device='cuda:1')
Storing NORMAL transition: reward=0.0303 (scaled=0.0303), steps=1
Reward stats updated: mean 0.0077 -> 0.0080, std: 0.0691
Collected 59 transitions for RL
tensor([-0.0299,  0.3820,  0.6146,  0.7896, -0.0547,  0.5058,  0.7225,  0.9999,
         1.4758,  0.2867,  0.0486,  1.0257, -0.0137,  0.0275, -0.2672, -5.3641],
       device='cuda:1')
Original likelihood: -108.07935333251953
Adjusted likelihood: -108.07935333251953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.103782435995527
Current ori: tensor([-0.0137,  0.0275, -0.2672], device='cuda:1')
Middle force: tensor([1.0749, 0.5031, 0.5598, 0.7899, 0.5300, 0.5164, 0.5918, 0.5652, 0.5547,
        0.5142], device='cuda:1')
Thumb force: tensor([0.9476, 0.5535, 1.1856, 1.5453, 0.6741, 0.5516, 0.5787, 0.5523, 0.5151,
        0.5797], device='cuda:1')
Index force: tensor([0.5611, 0.8924, 0.5874, 0.5726, 0.5835, 0.5415, 0.5735, 0.6047, 0.5513,
        0.5706], device='cuda:1')
Storing NORMAL transition: reward=0.0881 (scaled=0.0881), steps=1
Reward stats updated: mean 0.0080 -> 0.0094, std: 0.0692
Collected 60 transitions for RL
tensor([-1.6047e-02,  3.3746e-01,  6.6233e-01,  8.3674e-01, -4.3130e-02,
         4.4910e-01,  7.9649e-01,  1.0332e+00,  1.4705e+00,  3.1026e-01,
         1.0901e-01,  9.1225e-01, -4.2521e-03,  1.8516e-02, -3.5481e-01,
        -5.3122e+00], device='cuda:1')
Original likelihood: -72.71958923339844
Adjusted likelihood: -72.71958923339844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.007047243998386
Current ori: tensor([-0.0043,  0.0185, -0.3548], device='cuda:1')
Middle force: tensor([0.5028, 1.2649, 0.6259, 0.6730, 0.5412, 0.5850, 0.5660, 0.7437, 0.5618],
       device='cuda:1')
Thumb force: tensor([0.5480, 0.9638, 1.0731, 0.5281, 0.5534, 0.6033, 1.0294, 0.5771, 0.6778],
       device='cuda:1')
Index force: tensor([0.8720, 1.2026, 0.5611, 0.6102, 0.5645, 0.6125, 0.6048, 0.5508, 0.5726],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0700 (scaled=-0.0700), steps=1
Reward stats updated: mean 0.0094 -> 0.0081, std: 0.0694
Collected 61 transitions for RL
tensor([-0.0480,  0.3511,  0.6176,  0.8624, -0.1995,  0.5099,  0.8335,  0.9267,
         1.4872,  0.3109,  0.1417,  0.9635,  0.0210,  0.0700, -0.2897, -5.0866],
       device='cuda:1')
Original likelihood: -275.2214050292969
Adjusted likelihood: -275.2214050292969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 259.6688232421875
Projection step: 1, Loss: 272.03961181640625
Projection step: 2, Loss: 252.6830291748047
Projection step: 3, Loss: 271.5292053222656
Projection step: 4, Loss: 250.88905334472656
Projection step: 5, Loss: 253.8804473876953
Projection step: 6, Loss: 238.498046875
Projection step: 7, Loss: 235.42352294921875
Projection step: 8, Loss: 228.5695343017578
Projection step: 9, Loss: 224.24583435058594
Projection step: 10, Loss: 213.29409790039062
Projection step: 11, Loss: 209.2263946533203
Projection step: 12, Loss: 197.19400024414062
Projection step: 13, Loss: 212.90798950195312
Projection step: 14, Loss: 193.5164031982422
Projection step: 15, Loss: 183.08255004882812
Projection step: 16, Loss: 174.63546752929688
Projection step: 17, Loss: 177.98101806640625
Projection step: 18, Loss: 172.19874572753906
Projection step: 19, Loss: 177.2940673828125
Projection step: 20, Loss: 168.43975830078125
Projection step: 21, Loss: 160.82144165039062
Projection step: 22, Loss: 153.40362548828125
Projection step: 23, Loss: 154.2100830078125
Projection step: 24, Loss: 146.99374389648438
Final likelihood: tensor([-151.5029, -126.8605, -138.1991, -150.1757, -135.1928, -141.0285,
        -150.3478, -141.1567, -181.3454, -189.0730, -145.9576, -141.3697,
        -147.2824, -147.7737, -167.8394, -128.8144])
Final projection likelihood: -148.9950
1 mode projection succeeded
New goal: tensor([-0.0268,  0.4759,  0.5700,  0.7297, -0.1459,  0.5200,  0.7023,  0.8832,
         1.3650,  0.3695,  0.0886,  1.1219,  0.0279,  0.0440, -1.5765],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -215.2003173828125
Adjusted likelihood: -215.2003173828125
Likelihood residual: 0.0
Original likelihood: -145.79412841796875
Adjusted likelihood: -145.79412841796875
Likelihood residual: 0.0
{'index': 145.79412841796875, 'thumb_middle': 215.2003173828125}
Current yaw: tensor([ 0.0210,  0.0700, -0.2897], device='cuda:1')
17 index
tensor([-0.0480,  0.3511,  0.6176,  0.8624, -0.1995,  0.5099,  0.8335,  0.9267,
         1.4872,  0.3109,  0.1417,  0.9635,  0.0210,  0.0700, -0.2897, -5.0866],
       device='cuda:1')
Solve time for step 1 10.230770163005218
Current ori: tensor([ 0.0210,  0.0700, -0.2897], device='cuda:1')
Middle force: tensor([0.5092, 0.5952, 0.5805, 0.5612], device='cuda:1')
Thumb force: tensor([0.5204, 0.5815, 0.5288, 0.5550], device='cuda:1')
tensor([ 0.0135,  0.3890,  0.5206,  0.7205, -0.2032,  0.5289,  0.8070,  0.9647,
         1.4710,  0.3542,  0.1334,  0.9857,  0.0202,  0.0682, -0.2856, -3.7556],
       device='cuda:1')
Solve time for step 2 4.085158645000774
Current ori: tensor([ 0.0202,  0.0682, -0.2856], device='cuda:1')
Middle force: tensor([0.5905, 0.5763, 0.5568], device='cuda:1')
Thumb force: tensor([0.5732, 0.5265, 0.5524], device='cuda:1')
tensor([ 0.0247,  0.4084,  0.5074,  0.7013, -0.1609,  0.5555,  0.8006,  0.9639,
         1.4493,  0.3677,  0.0921,  1.0404,  0.0170,  0.0406, -0.2655, -3.1833],
       device='cuda:1')
Solve time for step 3 3.981832927034702
Current ori: tensor([ 0.0170,  0.0406, -0.2655], device='cuda:1')
Middle force: tensor([0.5703, 0.5034], device='cuda:1')
Thumb force: tensor([0.6003, 0.5534], device='cuda:1')
tensor([ 0.0302,  0.4096,  0.5091,  0.6968, -0.1465,  0.5700,  0.7927,  0.9562,
         1.4483,  0.3672,  0.0804,  1.0353,  0.0105,  0.0316, -0.2756, -2.8744],
       device='cuda:1')
Solve time for step 4 3.832265336997807
Current ori: tensor([ 0.0105,  0.0316, -0.2756], device='cuda:1')
Middle force: tensor([0.5029], device='cuda:1')
Thumb force: tensor([0.5459], device='cuda:1')
Storing RECOVERY transition: reward=-0.0113 (scaled=-0.0028), steps=4
Reward stats updated: mean 0.0081 -> 0.0079, std: 0.0689
Collected 62 transitions for RL
Original likelihood: -159.6090545654297
Adjusted likelihood: -159.6090545654297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 151.91867065429688
Projection step: 1, Loss: 133.39154052734375
Projection step: 2, Loss: 126.49845886230469
Projection step: 3, Loss: 122.72706604003906
Projection step: 4, Loss: 118.50657653808594
Projection step: 5, Loss: 115.8990478515625
Projection step: 6, Loss: 105.31871032714844
Projection step: 7, Loss: 98.59866333007812
Final likelihood: tensor([ -90.0262, -110.7430, -112.6620,  -76.5781, -127.5616,  -84.8839,
         -82.1993,  -95.4052, -108.3075,  -88.5716,  -94.3378,  -79.8234,
         -84.4972, -131.6377, -124.4531,  -85.8910])
Final projection likelihood: -98.5987
1 mode projection succeeded
New goal: tensor([ 0.0016,  0.4946,  0.5746,  0.6866, -0.1177,  0.5354,  0.7845,  0.9155,
         1.3892,  0.3625,  0.0971,  1.1019,  0.0119,  0.0254, -1.0535],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -119.1588134765625
Adjusted likelihood: -119.1588134765625
Likelihood residual: 0.0
Original likelihood: -141.31997680664062
Adjusted likelihood: -141.31997680664062
Likelihood residual: 0.0
{'index': 141.31997680664062, 'thumb_middle': 119.1588134765625}
Current yaw: tensor([ 0.0122,  0.0300, -0.2741], device='cuda:1')
18 thumb_middle
tensor([-0.0133,  0.4680,  0.5519,  0.7212, -0.1445,  0.5680,  0.7963,  0.9597,
         1.4454,  0.3756,  0.0720,  1.0515,  0.0122,  0.0300, -0.2741, -2.8155],
       device='cuda:1')
Solve time for step 1 8.926405969017651
Current ori: tensor([ 0.0122,  0.0300, -0.2741], device='cuda:1')
Index force: tensor([0.5577, 0.5037, 0.5999, 0.6020], device='cuda:1')
tensor([-0.0183,  0.4608,  0.5608,  0.7144, -0.2098,  0.5302,  0.7586,  0.9025,
         1.3646,  0.3559,  0.0300,  1.0689,  0.0127,  0.0334, -0.2741, -2.8301],
       device='cuda:1')
Solve time for step 2 3.6027697040117346
Current ori: tensor([ 0.0127,  0.0334, -0.2741], device='cuda:1')
Index force: tensor([0.5030, 0.5934, 0.6002], device='cuda:1')
tensor([-0.0224,  0.4632,  0.5633,  0.6959, -0.2136,  0.5341,  0.7561,  0.8959,
         1.3646,  0.3496,  0.0280,  1.0710,  0.0103,  0.0359, -0.2741, -2.8443],
       device='cuda:1')
Solve time for step 3 3.6585704940371215
Current ori: tensor([ 0.0103,  0.0359, -0.2741], device='cuda:1')
Index force: tensor([0.5860, 0.5930], device='cuda:1')
tensor([-0.0079,  0.4729,  0.5653,  0.6897, -0.2077,  0.5369,  0.7612,  0.8976,
         1.3576,  0.3502,  0.0199,  1.0702,  0.0072,  0.0283, -0.2741, -2.8317],
       device='cuda:1')
Solve time for step 4 3.3945313149597496
Current ori: tensor([ 0.0072,  0.0283, -0.2741], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-0.0000 (scaled=-0.0000), steps=4
Reward stats updated: mean 0.0079 -> 0.0078, std: 0.0683
Collected 63 transitions for RL
Original likelihood: -141.4719696044922
Adjusted likelihood: -141.4719696044922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0080,  0.0268, -0.2852], device='cuda:1')
19 turn
Sampling time 3.5794306830503047
tensor([-0.0093,  0.4848,  0.5510,  0.6817, -0.1417,  0.5641,  0.8178,  0.9401,
         1.4181,  0.3588,  0.0724,  1.0962,  0.0080,  0.0268, -0.2852, -2.7742],
       device='cuda:1')
Original likelihood: -134.67800903320312
Adjusted likelihood: -134.67800903320312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.468321339983959
Current ori: tensor([ 0.0080,  0.0268, -0.2852], device='cuda:1')
Middle force: tensor([1.4280, 1.8829, 0.7256, 0.5005, 0.5958, 0.7519, 0.8174, 0.5814, 0.5494,
        0.5567, 0.5800, 0.7364], device='cuda:1')
Thumb force: tensor([1.5418, 1.0377, 0.5705, 0.5687, 0.6496, 1.5095, 0.5193, 0.5931, 0.6272,
        0.5200, 0.5879, 0.7938], device='cuda:1')
Index force: tensor([0.7201, 1.1485, 0.6092, 0.6904, 0.6243, 0.5497, 0.5068, 0.5500, 0.6310,
        0.5520, 0.6010, 0.8741], device='cuda:1')
Storing NORMAL transition: reward=0.0536 (scaled=0.0536), steps=1
Reward stats updated: mean 0.0078 -> 0.0085, std: 0.0680
Collected 64 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0842, Q2 Loss=1.0842, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0528
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0782, Q2 Loss=1.0782, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0310
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0754, Q2 Loss=1.0754, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0809
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0686, Q2 Loss=1.0686, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0102
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0652, Q2 Loss=1.0652, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0498

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.06s (23.6%)
Q2 update: 0.04s (17.6%)
Actor update: 0.09s (36.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.074324
Q2 loss: 1.074327
Current threshold: -149.9990
Global Scale Offset: 1.0064
Reward stats: mean=0.0085, std=0.0680, count=64
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.0743, Q2 Loss: 1.0743, Entropy: 0.0000, Mean TD Error: 0.0450, Threshold: -149.9990
tensor([ 0.0128,  0.4051,  0.4489,  0.7223, -0.1141,  0.4181,  0.9808,  0.8529,
         1.5000,  0.2899,  0.1425,  0.8233, -0.0038,  0.0346, -0.3394, -1.6170],
       device='cuda:1')
Original likelihood: -179.9750213623047
Adjusted likelihood: -179.9750213623047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 172.68698120117188
Projection step: 1, Loss: 170.20907592773438
Projection step: 2, Loss: 168.42372131347656
Projection step: 3, Loss: 169.0352783203125
Projection step: 4, Loss: 154.83717346191406
Projection step: 5, Loss: 138.80377197265625
Projection step: 6, Loss: 133.99256896972656
Projection step: 7, Loss: 123.52500915527344
Projection step: 8, Loss: 114.7947998046875
Projection step: 9, Loss: 116.0955810546875
Projection step: 10, Loss: 100.2402114868164
Final likelihood: tensor([ -93.5205, -155.6540,  -93.3199,  -88.7923,  -80.9776,  -71.1254,
        -123.0035, -109.1661,  -92.5394, -107.5892, -107.3789, -112.5407,
        -105.4594,  -92.3575,  -85.4078,  -85.0112])
Final projection likelihood: -100.2402
1 mode projection succeeded
New goal: tensor([ 0.0293,  0.4838,  0.4746,  0.7274, -0.0926,  0.4636,  0.9072,  0.8545,
         1.4096,  0.2992,  0.2006,  0.9341, -0.0044,  0.0243, -1.1123],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0138]], device='cuda:1')
Original likelihood: -123.81655883789062
Adjusted likelihood: -123.81655883789062
Likelihood residual: 0.0
{'index': 123.81655883789062, 'thumb_middle': inf}
Current yaw: tensor([-0.0038,  0.0346, -0.3394], device='cuda:1')
20 index
tensor([ 0.0128,  0.4051,  0.4489,  0.7223, -0.1141,  0.4181,  0.9808,  0.8529,
         1.5000,  0.2899,  0.1425,  0.8233, -0.0038,  0.0346, -0.3394, -1.6170],
       device='cuda:1')
Solve time for step 1 10.63528194295941
Current ori: tensor([-0.0038,  0.0346, -0.3394], device='cuda:1')
Middle force: tensor([0.5004, 0.5638, 0.5266, 0.5389], device='cuda:1')
Thumb force: tensor([0.5970, 0.5405, 0.5669, 0.6044], device='cuda:1')
tensor([ 0.0406,  0.4484,  0.4438,  0.7129, -0.0994,  0.4438,  0.9449,  0.8812,
         1.4796,  0.3183,  0.1291,  0.8614, -0.0032,  0.0248, -0.3101, -0.8565],
       device='cuda:1')
Solve time for step 2 4.063028082950041
Current ori: tensor([-0.0032,  0.0248, -0.3101], device='cuda:1')
Middle force: tensor([0.5284, 0.5642, 0.5240], device='cuda:1')
Thumb force: tensor([0.5322, 0.6189, 0.5091], device='cuda:1')
tensor([ 0.0459,  0.4575,  0.4449,  0.7097, -0.1015,  0.4495,  0.9466,  0.8946,
         1.4753,  0.3297,  0.1213,  0.8705, -0.0046,  0.0214, -0.3163, -0.2474],
       device='cuda:1')
Solve time for step 3 4.136048086045776
Current ori: tensor([-0.0046,  0.0214, -0.3163], device='cuda:1')
Middle force: tensor([0.5412, 0.5211], device='cuda:1')
Thumb force: tensor([0.5039, 0.5853], device='cuda:1')
tensor([ 0.0432,  0.4549,  0.4464,  0.7056, -0.0784,  0.4751,  0.9359,  0.8783,
         1.4686,  0.3333,  0.1037,  0.8714, -0.0133,  0.0067, -0.3190,  0.2185],
       device='cuda:1')
Solve time for step 4 3.932398939039558
Current ori: tensor([-0.0133,  0.0067, -0.3190], device='cuda:1')
Middle force: tensor([0.5186], device='cuda:1')
Thumb force: tensor([0.5774], device='cuda:1')
Storing RECOVERY transition: reward=-0.0098 (scaled=-0.0098), steps=1
Reward stats updated: mean 0.0085 -> 0.0082, std: 0.0675
Collected 65 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0597, Q2 Loss=1.0597, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0020
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0553, Q2 Loss=1.0553, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0011
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0511, Q2 Loss=1.0511, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0228
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0479, Q2 Loss=1.0479, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0606
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0425, Q2 Loss=1.0425, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0349

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.051296
Q2 loss: 1.051296
Current threshold: -149.9982
Global Scale Offset: 1.0103
Reward stats: mean=0.0082, std=0.0675, count=65
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.0513, Q2 Loss: 1.0513, Entropy: 0.0000, Mean TD Error: 0.0243, Threshold: -149.9982
Original likelihood: -124.79649353027344
Adjusted likelihood: -124.79649353027344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Marked last transition as done (final step)
{}

Trial 5
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.679241323028691
tensor([ 0.1193,  0.5839,  0.5576,  0.6382, -0.1501,  0.5660,  0.8968,  0.9412,
         1.2322,  0.2897,  0.2247,  1.2391, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -132.82630920410156
Adjusted likelihood: -132.82630920410156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.079349806008395
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([0.7104, 0.7404, 0.5333, 0.5251, 0.6287, 0.9898, 0.9817, 0.5886, 0.4998,
        0.5859, 1.1737, 0.8570], device='cuda:1')
Thumb force: tensor([0.5683, 2.3548, 0.6314, 1.5227, 1.0501, 0.8637, 1.9665, 0.6044, 0.7093,
        0.5734, 0.6263, 1.3673], device='cuda:1')
Index force: tensor([0.5992, 0.5019, 0.6088, 0.5590, 0.5725, 0.5162, 0.5758, 0.6136, 0.7250,
        0.6150, 0.5521, 0.5611], device='cuda:1')
Storing NORMAL transition: reward=0.0163 (scaled=0.0163), steps=1
Reward stats updated: mean 0.0082 -> 0.0083, std: 0.0670
Collected 66 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0387, Q2 Loss=1.0387, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0439
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0360, Q2 Loss=1.0360, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0697
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0310, Q2 Loss=1.0310, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0641
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0245, Q2 Loss=1.0245, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0317
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0207, Q2 Loss=1.0207, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0410

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.030163
Q2 loss: 1.030163
Current threshold: -149.9979
Global Scale Offset: 1.0121
Reward stats: mean=0.0083, std=0.0670, count=66
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.0302, Q2 Loss: 1.0302, Entropy: 0.0000, Mean TD Error: 0.0501, Threshold: -149.9979
tensor([ 0.0888,  0.5111,  0.6292,  0.6367, -0.1786,  0.5462,  0.8260,  1.0707,
         1.2755,  0.2480,  0.2469,  1.2359,  0.0149,  0.0322, -0.0483,  0.2559],
       device='cuda:1')
Original likelihood: -171.36817932128906
Adjusted likelihood: -171.36817932128906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 167.36570739746094
Projection step: 1, Loss: 155.3785400390625
Projection step: 2, Loss: 144.51370239257812
Projection step: 3, Loss: 135.05233764648438
Projection step: 4, Loss: 120.58578491210938
Projection step: 5, Loss: 109.01582336425781
Projection step: 6, Loss: 96.52204895019531
Final likelihood: tensor([ -92.8040,  -90.5495, -112.2155,  -95.5359,  -91.5096,  -88.7085,
         -96.6794,  -98.1526,  -96.3345,  -98.3958, -107.7573,  -93.8642,
         -98.1938,  -96.3917,  -95.2722,  -91.9883])
Final projection likelihood: -96.5220
1 mode projection succeeded
New goal: tensor([ 0.0782,  0.5152,  0.6144,  0.6350, -0.1332,  0.5534,  0.8123,  0.9701,
         1.2778,  0.2801,  0.2246,  1.2024,  0.0157,  0.0265, -0.2782],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -139.82525634765625
Adjusted likelihood: -139.82525634765625
Likelihood residual: 0.0
Original likelihood: -101.09427642822266
Adjusted likelihood: -101.09427642822266
Likelihood residual: 0.0
{'index': 101.09427642822266, 'thumb_middle': 139.82525634765625}
Current yaw: tensor([ 0.0149,  0.0322, -0.0483], device='cuda:1')
2 index
tensor([ 0.0888,  0.5111,  0.6292,  0.6367, -0.1786,  0.5462,  0.8260,  1.0707,
         1.2755,  0.2480,  0.2469,  1.2359,  0.0149,  0.0322, -0.0483,  0.2559],
       device='cuda:1')
Solve time for step 1 10.165566328971181
Current ori: tensor([ 0.0149,  0.0322, -0.0483], device='cuda:1')
Middle force: tensor([0.5555, 0.5139, 0.5175, 0.5799], device='cuda:1')
Thumb force: tensor([0.5722, 0.6104, 0.5432, 0.5748], device='cuda:1')
tensor([ 0.1228,  0.4605,  0.5691,  0.6096, -0.1913,  0.5461,  0.8524,  1.0258,
         1.2780,  0.2570,  0.2573,  1.1993,  0.0016,  0.0373, -0.0607,  1.2418],
       device='cuda:1')
Solve time for step 2 4.085551754978951
Current ori: tensor([ 0.0016,  0.0373, -0.0607], device='cuda:1')
Middle force: tensor([0.5108, 0.5151, 0.5747], device='cuda:1')
Thumb force: tensor([0.6056, 0.5386, 0.5699], device='cuda:1')
tensor([ 0.1306,  0.4661,  0.5609,  0.6073, -0.1687,  0.5712,  0.8416,  1.0038,
         1.2797,  0.2508,  0.2294,  1.1915, -0.0118,  0.0233, -0.0822,  1.7552],
       device='cuda:1')
Solve time for step 3 4.1126812439761125
Current ori: tensor([-0.0118,  0.0233, -0.0822], device='cuda:1')
Middle force: tensor([0.5985, 0.5329], device='cuda:1')
Thumb force: tensor([0.5544, 0.5351], device='cuda:1')
tensor([ 0.1299,  0.4649,  0.5615,  0.6098, -0.1809,  0.5617,  0.8443,  1.0074,
         1.2957,  0.2338,  0.2359,  1.1914, -0.0078,  0.0316, -0.0727,  1.9210],
       device='cuda:1')
Solve time for step 4 3.990515590994619
Current ori: tensor([-0.0078,  0.0316, -0.0727], device='cuda:1')
Middle force: tensor([0.5288], device='cuda:1')
Thumb force: tensor([0.5276], device='cuda:1')
Storing RECOVERY transition: reward=0.0363 (scaled=0.0363), steps=1
Reward stats updated: mean 0.0083 -> 0.0087, std: 0.0666
Collected 67 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.0184, Q2 Loss=1.0184, Entropy=0.0064, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0829
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.0106, Q2 Loss=1.0106, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0060
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.0121, Q2 Loss=1.0121, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0926
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7091, Q2 Loss=0.7091, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0265
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9977, Q2 Loss=0.9977, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0362

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.7%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000003
Q1 loss: 0.949559
Q2 loss: 0.949559
Current threshold: -149.9776
Global Scale Offset: 1.0329
Reward stats: mean=0.0087, std=0.0666, count=67
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9496, Q2 Loss: 0.9496, Entropy: 0.0013, Mean TD Error: 0.0488, Threshold: -149.9776
Original likelihood: -157.56161499023438
Adjusted likelihood: -157.56161499023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 152.3133544921875
Projection step: 1, Loss: 143.96551513671875
Projection step: 2, Loss: 135.4371795654297
Projection step: 3, Loss: 127.10055541992188
Projection step: 4, Loss: 121.94218444824219
Projection step: 5, Loss: 111.9523696899414
Projection step: 6, Loss: 108.61079406738281
Projection step: 7, Loss: 101.4581298828125
Final likelihood: tensor([-102.2587,  -94.8302, -110.9823,  -96.9328, -103.7113,  -93.5718,
        -110.8778, -109.5412,  -99.0379,  -95.9012,  -99.1200, -100.6001,
        -103.9865, -102.9920,  -95.5273, -103.4588])
Final projection likelihood: -101.4581
1 mode projection succeeded
New goal: tensor([ 0.0759,  0.5112,  0.6181,  0.6204, -0.1308,  0.5578,  0.8307,  0.9129,
         1.2922,  0.2602,  0.2035,  1.1760, -0.0101,  0.0277, -0.1567],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -108.59635925292969
Adjusted likelihood: -108.59635925292969
Likelihood residual: 0.0
Original likelihood: -122.45305633544922
Adjusted likelihood: -122.45305633544922
Likelihood residual: 0.0
{'index': 122.45305633544922, 'thumb_middle': 108.59635925292969}
Current yaw: tensor([-0.0094,  0.0324, -0.0846], device='cuda:1')
3 thumb_middle
tensor([ 0.0803,  0.5224,  0.6071,  0.6305, -0.1818,  0.5603,  0.8463,  1.0060,
         1.2861,  0.2535,  0.2363,  1.1940, -0.0094,  0.0324, -0.0846,  1.9265],
       device='cuda:1')
Solve time for step 1 9.170700189017225
Current ori: tensor([-0.0094,  0.0324, -0.0846], device='cuda:1')
Index force: tensor([0.5966, 0.5758, 0.6049, 0.5907], device='cuda:1')
tensor([ 0.0753,  0.5471,  0.5919,  0.5851, -0.2287,  0.5371,  0.8031,  0.9114,
         1.2545,  0.2410,  0.1434,  1.1543, -0.0180,  0.0347, -0.0846,  1.8971],
       device='cuda:1')
Solve time for step 2 3.6344349940191023
Current ori: tensor([-0.0180,  0.0347, -0.0846], device='cuda:1')
Index force: tensor([0.5702, 0.5997, 0.5862], device='cuda:1')
tensor([ 0.0729,  0.5457,  0.5931,  0.5819, -0.2319,  0.5419,  0.8035,  0.8965,
         1.2641,  0.2384,  0.1329,  1.1505, -0.0179,  0.0362, -0.0846,  1.8933],
       device='cuda:1')
Solve time for step 3 3.5146228009834886
Current ori: tensor([-0.0179,  0.0362, -0.0846], device='cuda:1')
Index force: tensor([0.5884, 0.5774], device='cuda:1')
tensor([ 0.0775,  0.5183,  0.6166,  0.6176, -0.2313,  0.5404,  0.8046,  0.8948,
         1.2644,  0.2424,  0.1315,  1.1500, -0.0089,  0.0343, -0.0846,  1.9160],
       device='cuda:1')
Solve time for step 4 3.277319300977979
Current ori: tensor([-0.0089,  0.0343, -0.0846], device='cuda:1')
Index force: tensor([0.5376], device='cuda:1')
Storing RECOVERY transition: reward=0.0485 (scaled=0.0485), steps=1
Reward stats updated: mean 0.0087 -> 0.0093, std: 0.0663
Collected 68 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9944, Q2 Loss=0.9944, Entropy=0.0005, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0568
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9919, Q2 Loss=0.9919, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0912
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.9837, Q2 Loss=0.9837, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0118
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9806, Q2 Loss=0.9806, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0433
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9997, Q2 Loss=0.9997, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1696

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.8%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (37.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.990045
Q2 loss: 0.990045
Current threshold: -149.9634
Global Scale Offset: 1.0480
Reward stats: mean=0.0093, std=0.0663, count=68
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9900, Q2 Loss: 0.9900, Entropy: 0.0001, Mean TD Error: 0.0745, Threshold: -149.9634
Original likelihood: -136.1974639892578
Adjusted likelihood: -136.1974639892578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0072,  0.0355, -0.0970], device='cuda:1')
4 turn
Sampling time 3.814187092008069
tensor([ 0.0750,  0.5143,  0.6143,  0.6285, -0.1707,  0.5763,  0.8331,  0.9165,
         1.3267,  0.2737,  0.1910,  1.1710, -0.0072,  0.0355, -0.0970,  1.9307],
       device='cuda:1')
Original likelihood: -139.97213745117188
Adjusted likelihood: -139.97213745117188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.718317041988485
Current ori: tensor([-0.0072,  0.0355, -0.0970], device='cuda:1')
Middle force: tensor([1.4745, 0.9078, 0.9149, 1.5612, 1.4438, 0.6549, 0.4931, 0.7690, 0.5035,
        0.4774, 0.5112, 0.5074], device='cuda:1')
Thumb force: tensor([0.5576, 0.5145, 0.5805, 0.7055, 1.0292, 1.2509, 0.8503, 0.5723, 0.5712,
        0.5589, 0.5636, 0.6221], device='cuda:1')
Index force: tensor([0.8291, 0.7883, 0.7615, 0.5210, 1.0183, 0.8557, 0.6170, 0.5076, 0.5472,
        0.7567, 0.7436, 0.6803], device='cuda:1')
Storing NORMAL transition: reward=-0.0696 (scaled=-0.0696), steps=1
Reward stats updated: mean 0.0093 -> 0.0082, std: 0.0665
Collected 69 transitions for RL
SAC Update 1/5: Actor Loss=-0.0042, Q1 Loss=0.9727, Q2 Loss=0.9727, Entropy=0.3217, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0574
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6914, Q2 Loss=0.6914, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0483
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8482, Q2 Loss=0.8482, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1796
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8665, Q2 Loss=0.8665, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0489
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9518, Q2 Loss=0.9518, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0023

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.9%)
Actor update: 0.09s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000842
Q1 loss: 0.866137
Q2 loss: 0.866137
Current threshold: -149.9407
Global Scale Offset: 1.0727
Reward stats: mean=0.0082, std=0.0665, count=69
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.8661, Q2 Loss: 0.8661, Entropy: 0.0643, Mean TD Error: 0.0673, Threshold: -149.9407
tensor([ 0.0217,  0.5629,  0.5100,  0.6052, -0.2467,  0.7120,  0.7517,  0.8221,
         1.2970,  0.4144,  0.1657,  1.2429, -0.0212,  0.0583, -0.0294,  1.9391],
       device='cuda:1')
Original likelihood: -214.32981872558594
Adjusted likelihood: -214.32981872558594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 216.45040893554688
Projection step: 1, Loss: 213.27598571777344
Projection step: 2, Loss: 208.9358367919922
Projection step: 3, Loss: 204.69277954101562
Projection step: 4, Loss: 194.68983459472656
Projection step: 5, Loss: 197.15858459472656
Projection step: 6, Loss: 195.23635864257812
Projection step: 7, Loss: 196.5063018798828
Projection step: 8, Loss: 185.2598419189453
Projection step: 9, Loss: 188.46685791015625
Projection step: 10, Loss: 186.7602081298828
Projection step: 11, Loss: 182.44107055664062
Projection step: 12, Loss: 174.72067260742188
Projection step: 13, Loss: 178.62954711914062
Projection step: 14, Loss: 174.2249755859375
Projection step: 15, Loss: 170.9673614501953
Projection step: 16, Loss: 168.49859619140625
Projection step: 17, Loss: 166.7281494140625
Projection step: 18, Loss: 164.7205352783203
Projection step: 19, Loss: 158.513671875
Projection step: 20, Loss: 160.2051544189453
Projection step: 21, Loss: 153.508056640625
Projection step: 22, Loss: 153.09097290039062
Projection step: 23, Loss: 151.0402374267578
Projection step: 24, Loss: 150.20172119140625
Final likelihood: tensor([-134.4671, -171.3823, -150.0659, -138.6012, -146.4421, -152.8172,
        -150.5082, -168.8699, -154.4795, -143.6276, -142.3696, -151.8395,
        -138.3125, -143.2717, -145.4336, -151.3895])
Final projection likelihood: -148.9923
1 mode projection succeeded
New goal: tensor([ 0.0499,  0.5580,  0.5423,  0.6278, -0.1458,  0.6679,  0.7080,  0.7581,
         1.3349,  0.1987,  0.1301,  1.2590, -0.0280,  0.0435,  0.2828],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -154.248046875
Adjusted likelihood: -154.248046875
Likelihood residual: 0.0
Original likelihood: -169.26123046875
Adjusted likelihood: -169.26123046875
Likelihood residual: 0.0
{'index': 169.26123046875, 'thumb_middle': 154.248046875}
Current yaw: tensor([-0.0212,  0.0583, -0.0294], device='cuda:1')
5 thumb_middle
tensor([ 0.0217,  0.5629,  0.5100,  0.6052, -0.2467,  0.7120,  0.7517,  0.8221,
         1.2970,  0.4144,  0.1657,  1.2429, -0.0212,  0.0583, -0.0294,  1.9391],
       device='cuda:1')
Solve time for step 1 8.8947969119763
Current ori: tensor([-0.0212,  0.0583, -0.0294], device='cuda:1')
Index force: tensor([0.5909, 0.5970, 0.5667, 0.6038], device='cuda:1')
tensor([ 0.0155,  0.5592,  0.5120,  0.6002, -0.2549,  0.6821,  0.6991,  0.7532,
         1.3111,  0.2217,  0.0928,  1.2413, -0.0201,  0.0624, -0.0293,  1.9328],
       device='cuda:1')
Solve time for step 2 3.6176343710394576
Current ori: tensor([-0.0201,  0.0624, -0.0293], device='cuda:1')
Index force: tensor([0.5918, 0.5642, 0.6006], device='cuda:1')
tensor([ 0.0346,  0.5586,  0.5252,  0.6106, -0.2505,  0.6896,  0.7036,  0.7462,
         1.3165,  0.1889,  0.0728,  1.2411, -0.0200,  0.0512, -0.0293,  1.9615],
       device='cuda:1')
Solve time for step 3 3.3777741419617087
Current ori: tensor([-0.0200,  0.0512, -0.0293], device='cuda:1')
Index force: tensor([0.5591, 0.5947], device='cuda:1')
tensor([ 0.0530,  0.5660,  0.5276,  0.6191, -0.2453,  0.6908,  0.7071,  0.7482,
         1.3115,  0.1793,  0.0643,  1.2361, -0.0216,  0.0404, -0.0293,  1.9870],
       device='cuda:1')
Solve time for step 4 3.2784410640015267
Current ori: tensor([-0.0216,  0.0404, -0.0293], device='cuda:1')
Index force: tensor([0.5719], device='cuda:1')
Storing RECOVERY transition: reward=-0.0015 (scaled=-0.0015), steps=1
Reward stats updated: mean 0.0082 -> 0.0080, std: 0.0660
Collected 70 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6769, Q2 Loss=0.6769, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0348
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.9432, Q2 Loss=0.9432, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0242
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6348, Q2 Loss=0.6348, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0158
SAC Update 4/5: Actor Loss=-0.0027, Q1 Loss=0.6775, Q2 Loss=0.6775, Entropy=0.3445, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0394
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.8225, Q2 Loss=0.8225, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2068

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.7%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000542
Q1 loss: 0.750981
Q2 loss: 0.750981
Current threshold: -149.9326
Global Scale Offset: 1.0905
Reward stats: mean=0.0080, std=0.0660, count=70
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.7510, Q2 Loss: 0.7510, Entropy: 0.0689, Mean TD Error: 0.0642, Threshold: -149.9326
Original likelihood: -188.23585510253906
Adjusted likelihood: -188.23585510253906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 179.53846740722656
Projection step: 1, Loss: 186.05465698242188
Projection step: 2, Loss: 187.87213134765625
Projection step: 3, Loss: 174.98519897460938
Projection step: 4, Loss: 175.0990447998047
Projection step: 5, Loss: 173.23362731933594
Projection step: 6, Loss: 169.1284942626953
Projection step: 7, Loss: 165.16685485839844
Projection step: 8, Loss: 162.79730224609375
Projection step: 9, Loss: 157.20962524414062
Projection step: 10, Loss: 156.8216552734375
Projection step: 11, Loss: 145.4616241455078
Projection step: 12, Loss: 150.46560668945312
Projection step: 13, Loss: 147.79588317871094
Projection step: 14, Loss: 145.11972045898438
Projection step: 15, Loss: 143.95205688476562
Projection step: 16, Loss: 146.40878295898438
Projection step: 17, Loss: 139.80535888671875
Projection step: 18, Loss: 135.15708923339844
Projection step: 19, Loss: 129.58258056640625
Projection step: 20, Loss: 132.1358642578125
Projection step: 21, Loss: 128.40785217285156
Projection step: 22, Loss: 121.62093353271484
Projection step: 23, Loss: 118.01077270507812
Projection step: 24, Loss: 121.61886596679688
Final likelihood: tensor([-113.2109,  -93.0868, -119.4037, -118.2330, -116.0572, -119.6158,
        -110.5676, -116.4736, -126.2404, -101.2260, -119.5566, -103.0846,
        -120.1117, -111.7210, -111.7200, -103.3765])
Final projection likelihood: -112.7303
1 mode projection succeeded
New goal: tensor([ 0.0674,  0.5638,  0.5507,  0.6086, -0.1117,  0.6440,  0.7470,  0.7580,
         1.3534,  0.1910,  0.1444,  1.2463, -0.0240,  0.0320, -0.5039],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -118.04242706298828
Adjusted likelihood: -118.04242706298828
Likelihood residual: 0.0
Original likelihood: -157.25448608398438
Adjusted likelihood: -157.25448608398438
Likelihood residual: 0.0
{'index': 157.25448608398438, 'thumb_middle': 118.04242706298828}
Current yaw: tensor([-0.0189,  0.0464, -0.0268], device='cuda:1')
6 thumb_middle
tensor([ 0.0425,  0.5573,  0.5271,  0.6248, -0.1891,  0.7141,  0.7247,  0.7616,
         1.3863,  0.2096,  0.1174,  1.2590, -0.0189,  0.0464, -0.0268,  1.9722],
       device='cuda:1')
Solve time for step 1 8.813157905999105
Current ori: tensor([-0.0189,  0.0464, -0.0268], device='cuda:1')
Index force: tensor([0.5337, 0.5003, 0.5010, 0.5874], device='cuda:1')
tensor([ 0.0365,  0.5344,  0.5685,  0.5941, -0.2265,  0.6615,  0.7073,  0.7365,
         1.3271,  0.1613,  0.0786,  1.2451, -0.0161,  0.0504, -0.0268,  1.9617],
       device='cuda:1')
Solve time for step 2 3.6330832060193643
Current ori: tensor([-0.0161,  0.0504, -0.0268], device='cuda:1')
Index force: tensor([0.5002, 0.5001, 0.5786], device='cuda:1')
tensor([ 0.0363,  0.5287,  0.5725,  0.6013, -0.2264,  0.6472,  0.7220,  0.7431,
         1.3283,  0.1664,  0.0786,  1.2284, -0.0141,  0.0506, -0.0268,  1.9643],
       device='cuda:1')
Solve time for step 3 3.370806289021857
Current ori: tensor([-0.0141,  0.0506, -0.0268], device='cuda:1')
Index force: tensor([0.5001, 0.5688], device='cuda:1')
tensor([ 0.0335,  0.5313,  0.5688,  0.5967, -0.2250,  0.6448,  0.7164,  0.7383,
         1.3165,  0.1624,  0.1000,  1.2322, -0.0150,  0.0522, -0.0268,  1.9590],
       device='cuda:1')
Solve time for step 4 3.2292481689946726
Current ori: tensor([-0.0150,  0.0522, -0.0268], device='cuda:1')
Index force: tensor([0.5885], device='cuda:1')
Storing RECOVERY transition: reward=0.0247 (scaled=0.0247), steps=1
Reward stats updated: mean 0.0080 -> 0.0083, std: 0.0656
Collected 71 transitions for RL
SAC Update 1/5: Actor Loss=-0.0022, Q1 Loss=0.9262, Q2 Loss=0.9262, Entropy=0.2504, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0378
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5887, Q2 Loss=0.5887, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0117
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9062, Q2 Loss=0.9062, Entropy=0.0111, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1084
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.9136, Q2 Loss=0.9136, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0351
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6053, Q2 Loss=0.6053, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0228

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000453
Q1 loss: 0.787985
Q2 loss: 0.787985
Current threshold: -149.9465
Global Scale Offset: 1.1225
Reward stats: mean=0.0083, std=0.0656, count=71
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.7880, Q2 Loss: 0.7880, Entropy: 0.0523, Mean TD Error: 0.0432, Threshold: -149.9465
Original likelihood: -154.6036376953125
Adjusted likelihood: -154.6036376953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0096)
State is out of distribution
Projection step: 0, Loss: 149.9600830078125
Projection step: 1, Loss: 143.88308715820312
Projection step: 2, Loss: 148.57321166992188
Projection step: 3, Loss: 147.94088745117188
Projection step: 4, Loss: 141.940185546875
Projection step: 5, Loss: 145.28135681152344
Projection step: 6, Loss: 135.38755798339844
Projection step: 7, Loss: 129.09559631347656
Projection step: 8, Loss: 128.45462036132812
Projection step: 9, Loss: 121.71814727783203
Projection step: 10, Loss: 120.543701171875
Projection step: 11, Loss: 117.3099136352539
Projection step: 12, Loss: 119.56179809570312
Projection step: 13, Loss: 115.96601867675781
Projection step: 14, Loss: 111.71614074707031
Projection step: 15, Loss: 110.62771606445312
Projection step: 16, Loss: 111.91493225097656
Projection step: 17, Loss: 110.39260864257812
Projection step: 18, Loss: 108.64492797851562
Projection step: 19, Loss: 100.75646209716797
Final likelihood: tensor([-101.5632, -102.6014, -100.3411,  -89.9502, -103.6425, -107.7547,
         -93.6211, -108.3152,  -94.4886, -108.7113,  -98.5862, -137.5232,
         -91.5180,  -88.9380,  -91.9071,  -92.6415])
Final projection likelihood: -100.7565
1 mode projection succeeded
New goal: tensor([ 0.0684,  0.5574,  0.5633,  0.5984, -0.1029,  0.6207,  0.7738,  0.7641,
         1.3537,  0.1968,  0.1573,  1.2266, -0.0239,  0.0297, -0.3860],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -128.9488067626953
Adjusted likelihood: -128.9488067626953
Likelihood residual: 0.0
Original likelihood: -134.6902618408203
Adjusted likelihood: -134.6902618408203
Likelihood residual: 0.0
{'index': 134.6902618408203, 'thumb_middle': 128.9488067626953}
Current yaw: tensor([-0.0217,  0.0401, -0.0526], device='cuda:1')
7 thumb_middle
tensor([ 0.0534,  0.5589,  0.5486,  0.5980, -0.1611,  0.6744,  0.7478,  0.7544,
         1.3835,  0.1924,  0.1261,  1.2434, -0.0217,  0.0401, -0.0526,  2.0061],
       device='cuda:1')
Solve time for step 1 9.269383381004445
Current ori: tensor([-0.0217,  0.0401, -0.0526], device='cuda:1')
Index force: tensor([0.5993, 0.6043, 0.5673, 0.5622], device='cuda:1')
tensor([ 0.0489,  0.5584,  0.5496,  0.5885, -0.2088,  0.6124,  0.7365,  0.7403,
         1.3189,  0.1694,  0.0873,  1.2061, -0.0224,  0.0430, -0.0526,  1.9957],
       device='cuda:1')
Solve time for step 2 3.9317144230008125
Current ori: tensor([-0.0224,  0.0430, -0.0526], device='cuda:1')
Index force: tensor([0.5921, 0.5591, 0.5538], device='cuda:1')
tensor([ 0.0672,  0.5645,  0.5567,  0.5924, -0.2029,  0.6129,  0.7437,  0.7433,
         1.3086,  0.1651,  0.0775,  1.1980, -0.0239,  0.0320, -0.0526,  2.0219],
       device='cuda:1')
Solve time for step 3 3.6502638569800183
Current ori: tensor([-0.0239,  0.0320, -0.0526], device='cuda:1')
Index force: tensor([0.5498, 0.5456], device='cuda:1')
tensor([ 0.0606,  0.5522,  0.5612,  0.6046, -0.2048,  0.6119,  0.7434,  0.7402,
         1.3127,  0.1697,  0.0759,  1.1974, -0.0200,  0.0361, -0.0526,  2.0196],
       device='cuda:1')
Solve time for step 4 3.4147834859904833
Current ori: tensor([-0.0200,  0.0361, -0.0526], device='cuda:1')
Index force: tensor([0.5452], device='cuda:1')
Storing RECOVERY transition: reward=0.0624 (scaled=0.0624), steps=1
Reward stats updated: mean 0.0083 -> 0.0090, std: 0.0654
Collected 72 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6765, Q2 Loss=0.6765, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0545
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6749, Q2 Loss=0.6749, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0855
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8578, Q2 Loss=0.8578, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0133
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8143, Q2 Loss=0.8143, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0543
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6456, Q2 Loss=0.6456, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0540

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.6%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (41.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.733819
Q2 loss: 0.733819
Current threshold: -149.9550
Global Scale Offset: 1.1437
Reward stats: mean=0.0090, std=0.0654, count=72
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.7338, Q2 Loss: 0.7338, Entropy: 0.0000, Mean TD Error: 0.0523, Threshold: -149.9550
Original likelihood: -112.6239013671875
Adjusted likelihood: -112.6239013671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0250,  0.0222, -0.0896], device='cuda:1')
8 turn
Sampling time 3.609162379987538
tensor([ 0.0833,  0.5726,  0.5580,  0.5985, -0.1372,  0.6400,  0.7912,  0.7895,
         1.3683,  0.1956,  0.1235,  1.2151, -0.0250,  0.0222, -0.0896,  2.0773],
       device='cuda:1')
Original likelihood: -112.98377990722656
Adjusted likelihood: -112.98377990722656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.016268682025839
Current ori: tensor([-0.0250,  0.0222, -0.0896], device='cuda:1')
Middle force: tensor([0.6203, 0.7141, 0.5406, 1.4795, 0.5602, 0.4916, 0.5260, 0.5591, 0.5318,
        0.5988, 0.7040, 0.5607], device='cuda:1')
Thumb force: tensor([1.5497, 0.7103, 2.2718, 1.0731, 2.0659, 0.5089, 0.6396, 0.6014, 0.6472,
        0.6205, 0.8609, 0.5455], device='cuda:1')
Index force: tensor([0.9171, 0.7741, 0.5627, 0.8921, 0.7151, 0.8071, 0.6643, 0.6008, 0.5924,
        0.6096, 0.5985, 0.5306], device='cuda:1')
Storing NORMAL transition: reward=0.1761 (scaled=0.1761), steps=1
Reward stats updated: mean 0.0090 -> 0.0113, std: 0.0678
Collected 73 transitions for RL
SAC Update 1/5: Actor Loss=-0.0020, Q1 Loss=0.6488, Q2 Loss=0.6488, Entropy=0.3250, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0584
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.8433, Q2 Loss=0.8433, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0260
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8416, Q2 Loss=0.8416, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0196
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5724, Q2 Loss=0.5724, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0989
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6754, Q2 Loss=0.6754, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0328

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000409
Q1 loss: 0.716310
Q2 loss: 0.716310
Current threshold: -149.9507
Global Scale Offset: 1.1653
Reward stats: mean=0.0113, std=0.0678, count=73
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.7163, Q2 Loss: 0.7163, Entropy: 0.0650, Mean TD Error: 0.0471, Threshold: -149.9507
tensor([ 0.0922,  0.5784,  0.5658,  0.5835, -0.1441,  0.5982,  0.8189,  0.8632,
         1.3785,  0.2067,  0.1653,  1.0919, -0.0297,  0.0276, -0.2670,  2.1503],
       device='cuda:1')
Original likelihood: -122.17105102539062
Adjusted likelihood: -122.17105102539062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.479996144014876
Current ori: tensor([-0.0297,  0.0276, -0.2670], device='cuda:1')
Middle force: tensor([0.7000, 0.5386, 1.4559, 0.5556, 0.5019, 0.5247, 0.5549, 0.5298, 0.5950,
        0.6976, 0.5585], device='cuda:1')
Thumb force: tensor([0.7077, 2.2310, 1.0651, 2.0314, 0.5082, 0.6395, 0.6021, 0.6479, 0.6175,
        0.8535, 0.5447], device='cuda:1')
Index force: tensor([0.7643, 0.5602, 0.8780, 0.7094, 0.8571, 0.6579, 0.5972, 0.5892, 0.6072,
        0.5958, 0.5297], device='cuda:1')
Storing NORMAL transition: reward=0.0876 (scaled=0.0876), steps=1
Reward stats updated: mean 0.0113 -> 0.0124, std: 0.0679
Collected 74 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5686, Q2 Loss=0.5686, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1682
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7011, Q2 Loss=0.7011, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0452
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6097, Q2 Loss=0.6097, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0376
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6023, Q2 Loss=0.6023, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0776
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7478, Q2 Loss=0.7478, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2030

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.7%)
Actor update: 0.10s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.645886
Q2 loss: 0.645886
Current threshold: -149.9480
Global Scale Offset: 1.1789
Reward stats: mean=0.0124, std=0.0679, count=74
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6459, Q2 Loss: 0.6459, Entropy: 0.0000, Mean TD Error: 0.1063, Threshold: -149.9480
tensor([ 6.5168e-02,  5.2242e-01,  5.9949e-01,  6.1612e-01, -1.1332e-01,
         5.4364e-01,  8.7639e-01,  9.7472e-01,  1.3109e+00,  2.4931e-01,
         2.1795e-01,  1.0557e+00, -8.0471e-05,  2.8227e-04, -3.5220e-01,
         2.7068e+00], device='cuda:1')
Original likelihood: -72.36117553710938
Adjusted likelihood: -72.36117553710938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.045086987956893
Current ori: tensor([-8.0471e-05,  2.8227e-04, -3.5220e-01], device='cuda:1')
Middle force: tensor([0.6918, 0.7465, 0.5499, 0.5311, 0.6111, 0.5331, 0.7004, 0.5020, 0.5722,
        1.1707], device='cuda:1')
Thumb force: tensor([1.0405, 1.0629, 0.5980, 0.5431, 0.7853, 0.5829, 0.8834, 0.5827, 0.6147,
        0.5655], device='cuda:1')
Index force: tensor([0.6319, 0.5192, 0.6821, 0.5914, 0.5448, 0.5433, 0.7755, 0.6107, 0.5904,
        0.5391], device='cuda:1')
Storing NORMAL transition: reward=0.0383 (scaled=0.0383), steps=1
Reward stats updated: mean 0.0124 -> 0.0127, std: 0.0675
Collected 75 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7709, Q2 Loss=0.7709, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0519
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6033, Q2 Loss=0.6033, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0608
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.8245, Q2 Loss=0.8245, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1136
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7215, Q2 Loss=0.7215, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1207
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.7638, Q2 Loss=0.7638, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0425

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: 0.000000
Q1 loss: 0.736800
Q2 loss: 0.736800
Current threshold: -149.9464
Global Scale Offset: 1.1873
Reward stats: mean=0.0127, std=0.0675, count=75
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.7368, Q2 Loss: 0.7368, Entropy: 0.0000, Mean TD Error: 0.0779, Threshold: -149.9464
tensor([ 0.1902,  0.5352,  0.6323,  0.7580, -0.0531,  0.4943,  0.8356,  0.9564,
         1.3881,  0.1482,  0.1599,  1.0742, -0.0061,  0.0049, -0.3906,  2.7218],
       device='cuda:1')
Original likelihood: -123.21117401123047
Adjusted likelihood: -123.21117401123047
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 4.9606928849825636
Current ori: tensor([-0.0061,  0.0049, -0.3906], device='cuda:1')
Middle force: tensor([1.4039, 0.5459, 0.5013, 0.5214, 0.5470, 0.5245, 0.5841, 0.6828, 0.5514],
       device='cuda:1')
Thumb force: tensor([1.0269, 1.9719, 0.5078, 0.6383, 0.6021, 0.6557, 0.6131, 0.8420, 0.5439],
       device='cuda:1')
Index force: tensor([0.8539, 0.6954, 0.9355, 0.6544, 0.5942, 0.5839, 0.6055, 0.5910, 0.5293],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0236 (scaled=-0.0236), steps=1
Reward stats updated: mean 0.0127 -> 0.0122, std: 0.0672
Collected 76 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6097, Q2 Loss=0.6097, Entropy=0.0155, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0694
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7154, Q2 Loss=0.7154, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0450
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.7880, Q2 Loss=0.7880, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0807
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6772, Q2 Loss=0.6772, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0760
SAC Update 5/5: Actor Loss=-0.0019, Q1 Loss=0.7132, Q2 Loss=0.7132, Entropy=0.2617, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0184

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.12s (41.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000399
Q1 loss: 0.700685
Q2 loss: 0.700685
Current threshold: -149.9475
Global Scale Offset: 1.2012
Reward stats: mean=0.0122, std=0.0672, count=76
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.7007, Q2 Loss: 0.7007, Entropy: 0.0555, Mean TD Error: 0.0579, Threshold: -149.9475
tensor([ 0.2899,  0.5929,  0.6901,  0.7239, -0.0584,  0.4731,  0.7759,  1.0131,
         1.4457,  0.0641,  0.1644,  1.0809,  0.0035,  0.0232, -0.3680,  2.0810],
       device='cuda:1')
Original likelihood: -171.60012817382812
Adjusted likelihood: -171.60012817382812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 179.9637908935547
Projection step: 1, Loss: 172.31248474121094
Projection step: 2, Loss: 197.92013549804688
Projection step: 3, Loss: 157.03282165527344
Projection step: 4, Loss: 162.72669982910156
Projection step: 5, Loss: 158.95806884765625
Projection step: 6, Loss: 161.03155517578125
Projection step: 7, Loss: 141.79266357421875
Projection step: 8, Loss: 144.3883514404297
Projection step: 9, Loss: 153.48760986328125
Projection step: 10, Loss: 144.12991333007812
Projection step: 11, Loss: 139.35186767578125
Projection step: 12, Loss: 127.53765869140625
Projection step: 13, Loss: 128.35385131835938
Projection step: 14, Loss: 127.131591796875
Projection step: 15, Loss: 125.16643524169922
Projection step: 16, Loss: 118.1594467163086
Projection step: 17, Loss: 116.7338638305664
Projection step: 18, Loss: 108.757568359375
Projection step: 19, Loss: 109.61811828613281
Projection step: 20, Loss: 111.01628875732422
Projection step: 21, Loss: 101.12287902832031
Final likelihood: tensor([-102.1175,  -80.7496,  -99.7903,  -85.0859,  -91.4346,  -79.6289,
         -80.1179, -114.8547, -117.4859,  -97.0387, -130.1257, -118.3070,
         -79.4568, -123.4752, -100.5850, -117.7123])
Final projection likelihood: -101.1229
1 mode projection succeeded
New goal: tensor([ 0.1816,  0.5534,  0.6997,  0.7618, -0.0453,  0.5204,  0.8122,  0.9000,
         1.3204,  0.1571,  0.1522,  1.0344,  0.0026,  0.0142,  0.3230],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -134.6183319091797
Adjusted likelihood: -134.6183319091797
Likelihood residual: 0.0
Original likelihood: -145.5707550048828
Adjusted likelihood: -145.5707550048828
Likelihood residual: 0.0
{'index': 145.5707550048828, 'thumb_middle': 134.6183319091797}
Current yaw: tensor([ 0.0035,  0.0232, -0.3680], device='cuda:1')
9 thumb_middle
tensor([ 0.2899,  0.5929,  0.6901,  0.7239, -0.0584,  0.4731,  0.7759,  1.0131,
         1.4457,  0.0641,  0.1644,  1.0809,  0.0035,  0.0232, -0.3680,  2.0810],
       device='cuda:1')
Solve time for step 1 8.6734150639968
Current ori: tensor([ 0.0035,  0.0232, -0.3680], device='cuda:1')
Index force: tensor([0.5886, 0.6271, 0.5046, 0.5016], device='cuda:1')
tensor([ 0.2540,  0.6323,  0.7100,  0.7626, -0.1650,  0.4800,  0.7618,  0.8933,
         1.3402,  0.1343,  0.1362,  1.0451,  0.0270,  0.0796, -0.3679,  1.3871],
       device='cuda:1')
Solve time for step 2 3.5672875699819997
Current ori: tensor([ 0.0270,  0.0796, -0.3679], device='cuda:1')
Index force: tensor([0.5855, 0.5875, 0.5827], device='cuda:1')
tensor([ 0.2056,  0.6949,  0.7362,  0.7412, -0.2158,  0.4744,  0.7417,  0.8617,
         1.3612,  0.1579,  0.1625,  1.0553,  0.0364,  0.1162, -0.3545,  0.6242],
       device='cuda:1')
Solve time for step 3 3.362428947002627
Current ori: tensor([ 0.0364,  0.1162, -0.3545], device='cuda:1')
Index force: tensor([0.5463, 0.5630], device='cuda:1')
tensor([ 0.1593,  0.7299,  0.7781,  0.7663, -0.2402,  0.4740,  0.7209,  0.8469,
         1.3855,  0.1650,  0.1945,  1.0671,  0.0370,  0.1327, -0.3370,  0.0176],
       device='cuda:1')
Solve time for step 4 3.2741136380354874
Current ori: tensor([ 0.0370,  0.1327, -0.3370], device='cuda:1')
Index force: tensor([0.5028], device='cuda:1')
Storing RECOVERY transition: reward=-0.0614 (scaled=-0.0153), steps=4
Reward stats updated: mean 0.0122 -> 0.0119, std: 0.0669
Collected 77 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6855, Q2 Loss=0.6855, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0138
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7073, Q2 Loss=0.7073, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0085
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6899, Q2 Loss=0.6899, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0094
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4714, Q2 Loss=0.4714, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0091
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7333, Q2 Loss=0.7333, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0902

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.657469
Q2 loss: 0.657469
Current threshold: -149.9567
Global Scale Offset: 1.2252
Reward stats: mean=0.0119, std=0.0669, count=77
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.6575, Q2 Loss: 0.6575, Entropy: 0.0000, Mean TD Error: 0.0262, Threshold: -149.9567
Original likelihood: -284.9850769042969
Adjusted likelihood: -284.9850769042969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 310.65887451171875
Projection step: 1, Loss: 309.360595703125
Projection step: 2, Loss: 286.0902099609375
Projection step: 3, Loss: 282.10650634765625
Projection step: 4, Loss: 265.0246276855469
Projection step: 5, Loss: 250.53282165527344
Projection step: 6, Loss: 240.93431091308594
Projection step: 7, Loss: 240.68936157226562
Projection step: 8, Loss: 225.05166625976562
Projection step: 9, Loss: 248.780029296875
Projection step: 10, Loss: 183.58108520507812
Projection step: 11, Loss: 188.40036010742188
Projection step: 12, Loss: 224.63510131835938
Projection step: 13, Loss: 220.985595703125
Projection step: 14, Loss: 216.9108123779297
Projection step: 15, Loss: 233.6917724609375
Projection step: 16, Loss: 230.49903869628906
Projection step: 17, Loss: 238.92218017578125
Projection step: 18, Loss: 210.46688842773438
Projection step: 19, Loss: 212.9709014892578
Projection step: 20, Loss: 204.99176025390625
Projection step: 21, Loss: 211.16542053222656
Projection step: 22, Loss: 223.40670776367188
Projection step: 23, Loss: 219.1869354248047
Projection step: 24, Loss: 241.6059112548828
Final likelihood: tensor([-182.3540, -122.9295, -186.1214, -235.5420, -236.8420, -229.4349,
        -235.3984,  -95.9025, -243.7843, -224.0695, -115.7349, -184.2523,
        -243.3407, -243.3450, -120.6424, -276.7742])
Final projection likelihood: -198.5293
1 mode projection failed, trying anyway
New goal: tensor([ 0.1286,  0.6804,  0.5977,  0.5383, -0.1620,  0.4549,  0.7015,  0.8000,
         1.3663,  0.0219,  0.2673,  1.1290,  0.0556,  0.0958,  1.0571],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -188.387939453125
Adjusted likelihood: -188.387939453125
Likelihood residual: 0.0
Original likelihood: -258.75091552734375
Adjusted likelihood: -258.75091552734375
Likelihood residual: 0.0
{'index': 258.75091552734375, 'thumb_middle': 188.387939453125}
Current yaw: tensor([ 0.0453,  0.1147, -0.3313], device='cuda:1')
10 thumb_middle
tensor([ 0.1627,  0.7557,  0.7923,  0.8025, -0.2121,  0.4617,  0.7480,  0.8761,
         1.4215,  0.1681,  0.3072,  1.1492,  0.0453,  0.1147, -0.3313, -0.1036],
       device='cuda:1')
Solve time for step 1 8.973376973997802
Current ori: tensor([ 0.0453,  0.1147, -0.3313], device='cuda:1')
Index force: tensor([0.5818, 0.5429, 0.5868, 0.5382], device='cuda:1')
tensor([ 0.1153,  0.8721,  0.7018,  0.5935, -0.2570,  0.4750,  0.7091,  0.8095,
         1.4000,  0.0442,  0.2860,  1.1519,  0.0392,  0.1456, -0.3048, -0.1347],
       device='cuda:1')
Solve time for step 2 3.609848955005873
Current ori: tensor([ 0.0392,  0.1456, -0.3048], device='cuda:1')
Index force: tensor([0.5453, 0.5740, 0.5189], device='cuda:1')
tensor([ 0.0988,  0.9045,  0.7179,  0.5779, -0.2638,  0.4800,  0.6994,  0.8027,
         1.4038,  0.0301,  0.2804,  1.1557,  0.0401,  0.1501, -0.2827,  0.1861],
       device='cuda:1')
Solve time for step 3 3.4240691720042378
Current ori: tensor([ 0.0401,  0.1501, -0.2827], device='cuda:1')
Index force: tensor([0.5582, 0.5129], device='cuda:1')
tensor([ 0.0549,  0.9432,  0.7526,  0.5643, -0.2770,  0.4760,  0.7013,  0.7901,
         1.4257,  0.0533,  0.2868,  1.1653,  0.0436,  0.1577, -0.2589,  0.4798],
       device='cuda:1')
Solve time for step 4 3.23492758104112
Current ori: tensor([ 0.0436,  0.1577, -0.2589], device='cuda:1')
Index force: tensor([0.5076], device='cuda:1')
Storing RECOVERY transition: reward=-0.1870 (scaled=-0.0467), steps=4
Reward stats updated: mean 0.0119 -> 0.0111, std: 0.0668
Collected 78 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.7626, Q2 Loss=0.7626, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0719
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7384, Q2 Loss=0.7384, Entropy=0.0023, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0788
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6766, Q2 Loss=0.6766, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1915
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6601, Q2 Loss=0.6601, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0252
SAC Update 5/5: Actor Loss=-0.0062, Q1 Loss=0.6271, Q2 Loss=0.6271, Entropy=0.3453, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0178

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001247
Q1 loss: 0.692964
Q2 loss: 0.692964
Current threshold: -149.9674
Global Scale Offset: 1.2422
Reward stats: mean=0.0111, std=0.0668, count=78
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 0.6930, Q2 Loss: 0.6930, Entropy: 0.0695, Mean TD Error: 0.0771, Threshold: -149.9674
Original likelihood: -255.01858520507812
Adjusted likelihood: -255.01858520507812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 288.0276184082031
Projection step: 1, Loss: 271.9747314453125
Projection step: 2, Loss: 240.3616485595703
Projection step: 3, Loss: 232.78822326660156
Projection step: 4, Loss: 217.909423828125
Projection step: 5, Loss: 215.77923583984375
Projection step: 6, Loss: 197.68490600585938
Projection step: 7, Loss: 201.69808959960938
Projection step: 8, Loss: 184.7897186279297
Projection step: 9, Loss: 186.78204345703125
Projection step: 10, Loss: 178.5462188720703
Projection step: 11, Loss: 159.89572143554688
Projection step: 12, Loss: 157.54107666015625
Projection step: 13, Loss: 149.33168029785156
Projection step: 14, Loss: 145.9808349609375
Projection step: 15, Loss: 147.2982177734375
Projection step: 16, Loss: 147.8799591064453
Projection step: 17, Loss: 149.50909423828125
Projection step: 18, Loss: 146.95437622070312
Projection step: 19, Loss: 135.57333374023438
Projection step: 20, Loss: 134.99476623535156
Projection step: 21, Loss: 136.14593505859375
Projection step: 22, Loss: 150.74862670898438
Projection step: 23, Loss: 138.1984100341797
Projection step: 24, Loss: 134.91798400878906
Final likelihood: tensor([-135.6058, -114.0330, -173.7369, -163.1535, -159.6438, -136.9123,
        -144.0329, -138.9838, -129.2467, -153.5177, -154.2285,  -91.7570,
        -124.0051, -428.3000, -132.0952, -129.0477])
Final projection likelihood: -156.7688
1 mode projection failed, trying anyway
New goal: tensor([ 0.0576,  0.8443,  0.3515,  0.3616, -0.1966,  0.4345,  0.6887,  0.7633,
         1.4416, -0.0241,  0.3687,  1.0684,  0.0518,  0.1326,  0.4571],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[-0.0013]], device='cuda:1')
Original likelihood: -290.1180725097656
Adjusted likelihood: -290.1180725097656
Likelihood residual: 0.0
Original likelihood: -172.1598358154297
Adjusted likelihood: -172.1598358154297
Likelihood residual: 0.0
{'index': 172.1598358154297, 'thumb_middle': 290.1180725097656}
Current yaw: tensor([ 0.0453,  0.1412, -0.2060], device='cuda:1')
11 index
tensor([ 0.0332,  0.9851,  0.7045,  0.5675, -0.2448,  0.4882,  0.7052,  0.7853,
         1.4835,  0.0794,  0.3562,  1.2044,  0.0453,  0.1412, -0.2060,  0.4841],
       device='cuda:1')
Solve time for step 1 10.229335199983325
Current ori: tensor([ 0.0453,  0.1412, -0.2060], device='cuda:1')
Middle force: tensor([0.5317, 0.5001, 0.5517, 0.5004], device='cuda:1')
Thumb force: tensor([0.5752, 0.5091, 0.6152, 0.5892], device='cuda:1')
tensor([ 0.2292,  0.8886,  0.4220,  0.3980, -0.2408,  0.4928,  0.7086,  0.7660,
         1.5000,  0.0558,  0.3500,  1.1464,  0.0303,  0.1396, -0.2886,  0.4288],
       device='cuda:1')
Solve time for step 2 4.3312667880090885
Current ori: tensor([ 0.0303,  0.1396, -0.2886], device='cuda:1')
Middle force: tensor([0.5249, 0.5055, 0.5617], device='cuda:1')
Thumb force: tensor([0.5253, 0.5258, 0.5751], device='cuda:1')
tensor([ 0.2302,  0.8758,  0.3750,  0.3703, -0.2376,  0.4918,  0.7135,  0.7647,
         1.5000,  0.0530,  0.3472,  1.1386,  0.0281,  0.1376, -0.3072,  0.3310],
       device='cuda:1')
Solve time for step 3 4.178417449002154
Current ori: tensor([ 0.0281,  0.1376, -0.3072], device='cuda:1')
Middle force: tensor([0.5165, 0.5016], device='cuda:1')
Thumb force: tensor([0.5620, 0.5280], device='cuda:1')
tensor([ 0.2234,  0.8823,  0.3683,  0.3630, -0.2362,  0.4909,  0.7152,  0.7660,
         1.5000,  0.0495,  0.3500,  1.1392,  0.0295,  0.1367, -0.2996,  0.3088],
       device='cuda:1')
Solve time for step 4 4.242628898995463
Current ori: tensor([ 0.0295,  0.1367, -0.2996], device='cuda:1')
Middle force: tensor([0.5283], device='cuda:1')
Thumb force: tensor([0.5840], device='cuda:1')
Storing RECOVERY transition: reward=-0.1312 (scaled=-0.0328), steps=4
Reward stats updated: mean 0.0111 -> 0.0106, std: 0.0665
Collected 79 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5882, Q2 Loss=0.5882, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0172
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7246, Q2 Loss=0.7246, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0660
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6256, Q2 Loss=0.6256, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0546
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.7146, Q2 Loss=0.7146, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0949
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5738, Q2 Loss=0.5738, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1031

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.3%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (20.6%)
Actor update: 0.12s (42.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.645365
Q2 loss: 0.645365
Current threshold: -149.9903
Global Scale Offset: 1.2579
Reward stats: mean=0.0106, std=0.0665, count=79
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.6454, Q2 Loss: 0.6454, Entropy: 0.0000, Mean TD Error: 0.0672, Threshold: -149.9903
Original likelihood: -181.11358642578125
Adjusted likelihood: -181.11358642578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 183.93264770507812
Projection step: 1, Loss: 176.3563690185547
Projection step: 2, Loss: 189.99435424804688
Projection step: 3, Loss: 164.12088012695312
Projection step: 4, Loss: 191.24114990234375
Projection step: 5, Loss: 171.38421630859375
Projection step: 6, Loss: 182.69277954101562
Projection step: 7, Loss: 160.19039916992188
Projection step: 8, Loss: 162.6728515625
Projection step: 9, Loss: 174.41990661621094
Projection step: 10, Loss: 166.51107788085938
Projection step: 11, Loss: 159.23829650878906
Projection step: 12, Loss: 163.9065399169922
Projection step: 13, Loss: 158.737548828125
Projection step: 14, Loss: 161.60235595703125
Projection step: 15, Loss: 159.10552978515625
Projection step: 16, Loss: 159.49935913085938
Projection step: 17, Loss: 153.3695831298828
Projection step: 18, Loss: 155.666015625
Projection step: 19, Loss: 157.050048828125
Projection step: 20, Loss: 158.03602600097656
Projection step: 21, Loss: 149.953857421875
Projection step: 22, Loss: 145.93756103515625
Projection step: 23, Loss: 166.72247314453125
Projection step: 24, Loss: 147.01126098632812
Final likelihood: tensor([-151.9838, -152.2500, -136.5732, -154.4220, -164.8464, -168.6870,
        -173.4629, -169.8038, -152.9355, -160.6911, -134.9223, -158.4302,
        -129.1940, -133.0719, -179.0267, -147.9734])
Final projection likelihood: -154.2671
1 mode projection failed, trying anyway
New goal: tensor([ 0.1043,  0.8702,  0.3302,  0.3287, -0.2059,  0.4643,  0.6693,  0.8139,
         1.4526, -0.0657,  0.3469,  1.0665,  0.0373,  0.1324,  0.5976],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -185.5164794921875
Adjusted likelihood: -185.5164794921875
Likelihood residual: 0.0
Original likelihood: -168.92953491210938
Adjusted likelihood: -168.92953491210938
Likelihood residual: 0.0
{'index': 168.92953491210938, 'thumb_middle': 185.5164794921875}
Current yaw: tensor([ 0.0299,  0.1394, -0.2635], device='cuda:1')
12 index
tensor([ 0.1072,  0.8880,  0.3678,  0.3637, -0.2381,  0.5010,  0.7034,  0.7516,
         1.5000,  0.0523,  0.3560,  1.1427,  0.0299,  0.1394, -0.2635,  0.2558],
       device='cuda:1')
Solve time for step 1 10.481943810998928
Current ori: tensor([ 0.0299,  0.1394, -0.2635], device='cuda:1')
Middle force: tensor([0.5895, 0.5403, 0.5482, 0.6258], device='cuda:1')
Thumb force: tensor([0.5887, 0.5700, 0.5699, 0.5138], device='cuda:1')
tensor([ 0.2239,  0.8918,  0.3423,  0.3344, -0.2238,  0.5137,  0.6886,  0.7988,
         1.5000,  0.0237,  0.3749,  1.0946,  0.0288,  0.1280, -0.2662,  0.1498],
       device='cuda:1')
Solve time for step 2 4.019184553006198
Current ori: tensor([ 0.0288,  0.1280, -0.2662], device='cuda:1')
Middle force: tensor([0.5456, 0.5218, 0.5222], device='cuda:1')
Thumb force: tensor([0.5307, 0.6092, 0.6407], device='cuda:1')
tensor([ 0.2486,  0.8964,  0.3389,  0.3308, -0.2167,  0.5137,  0.6894,  0.8108,
         1.5000,  0.0136,  0.3884,  1.0508,  0.0269,  0.1235, -0.2904,  0.2414],
       device='cuda:1')
Solve time for step 3 4.001824632985517
Current ori: tensor([ 0.0269,  0.1235, -0.2904], device='cuda:1')
Middle force: tensor([0.5203, 0.5214], device='cuda:1')
Thumb force: tensor([0.5982, 0.6339], device='cuda:1')
tensor([ 0.2651,  0.8956,  0.3366,  0.3297, -0.2068,  0.5128,  0.6945,  0.8180,
         1.5000,  0.0037,  0.3869,  1.0412,  0.0264,  0.1176, -0.3011,  0.3818],
       device='cuda:1')
Solve time for step 4 3.9590740150306374
Current ori: tensor([ 0.0264,  0.1176, -0.3011], device='cuda:1')
Middle force: tensor([0.5005], device='cuda:1')
Thumb force: tensor([0.6179], device='cuda:1')
Storing RECOVERY transition: reward=-0.0683 (scaled=-0.0171), steps=4
Reward stats updated: mean 0.0106 -> 0.0102, std: 0.0662
Collected 80 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6627, Q2 Loss=0.6627, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0063
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7156, Q2 Loss=0.7156, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1076
SAC Update 3/5: Actor Loss=-0.0044, Q1 Loss=0.5221, Q2 Loss=0.5221, Entropy=0.3256, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0655
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.6536, Q2 Loss=0.6536, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1389
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5307, Q2 Loss=0.5307, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1848

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000881
Q1 loss: 0.616972
Q2 loss: 0.616972
Current threshold: -149.9928
Global Scale Offset: 1.2806
Reward stats: mean=0.0102, std=0.0662, count=80
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 0.6170, Q2 Loss: 0.6170, Entropy: 0.0651, Mean TD Error: 0.1006, Threshold: -149.9928
Original likelihood: -231.99642944335938
Adjusted likelihood: -231.99642944335938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 226.3482666015625
Projection step: 1, Loss: 180.78492736816406
Projection step: 2, Loss: 206.58074951171875
Projection step: 3, Loss: 192.00244140625
Projection step: 4, Loss: 193.8546142578125
Projection step: 5, Loss: 179.58180236816406
Projection step: 6, Loss: 195.36676025390625
Projection step: 7, Loss: 172.3338165283203
Projection step: 8, Loss: 214.05474853515625
Projection step: 9, Loss: 186.25856018066406
Projection step: 10, Loss: 194.75567626953125
Projection step: 11, Loss: 208.406005859375
Projection step: 12, Loss: 198.769775390625
Projection step: 13, Loss: 225.05538940429688
Projection step: 14, Loss: 206.44729614257812
Projection step: 15, Loss: 190.54112243652344
Projection step: 16, Loss: 199.25155639648438
Projection step: 17, Loss: 219.9095916748047
Projection step: 18, Loss: 215.9073028564453
Projection step: 19, Loss: 187.04141235351562
Projection step: 20, Loss: 177.57330322265625
Projection step: 21, Loss: 223.7672576904297
Projection step: 22, Loss: 223.51089477539062
Projection step: 23, Loss: 220.9212646484375
Projection step: 24, Loss: 179.76296997070312
Final likelihood: tensor([-208.1047, -147.4661, -241.5264, -218.2823, -215.1755, -216.3921,
        -155.4372, -145.4342, -212.4478, -154.9084, -278.6093, -271.5981,
        -135.3708, -278.7903, -132.5509, -144.9505])
Final projection likelihood: -197.3153
1 mode projection failed, trying anyway
New goal: tensor([ 0.1274,  0.8840,  0.3837,  0.2654, -0.1815,  0.4839,  0.6455,  0.8338,
         1.4438, -0.0822,  0.3619,  1.0033,  0.0315,  0.1051,  1.1817],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -157.7532958984375
Adjusted likelihood: -157.7532958984375
Likelihood residual: 0.0
Original likelihood: -283.95452880859375
Adjusted likelihood: -283.95452880859375
Likelihood residual: 0.0
{'index': 283.95452880859375, 'thumb_middle': 157.7532958984375}
Current yaw: tensor([ 0.0260,  0.1166, -0.3221], device='cuda:1')
13 thumb_middle
tensor([ 0.1529,  0.9056,  0.3427,  0.3300, -0.2055,  0.5084,  0.6965,  0.8296,
         1.5000,  0.0047,  0.3740,  1.0607,  0.0260,  0.1166, -0.3221,  0.4474],
       device='cuda:1')
Solve time for step 1 9.001540296012536
Current ori: tensor([ 0.0260,  0.1166, -0.3221], device='cuda:1')
Index force: tensor([0.5083, 0.5290, 0.5908, 0.6040], device='cuda:1')
tensor([ 0.1340,  0.9321,  0.3591,  0.2816, -0.2415,  0.5122,  0.6440,  0.8168,
         1.4574, -0.0751,  0.3640,  1.0256,  0.0262,  0.1431, -0.3091,  0.4365],
       device='cuda:1')
Solve time for step 2 3.5674377830000594
Current ori: tensor([ 0.0262,  0.1431, -0.3091], device='cuda:1')
Index force: tensor([0.5276, 0.5843, 0.5994], device='cuda:1')
tensor([ 0.0982,  0.9488,  0.4019,  0.2454, -0.2535,  0.5169,  0.6306,  0.8129,
         1.4735, -0.0776,  0.3988,  1.0124,  0.0264,  0.1503, -0.2967,  0.4325],
       device='cuda:1')
Solve time for step 3 3.517723005032167
Current ori: tensor([ 0.0264,  0.1503, -0.2967], device='cuda:1')
Index force: tensor([0.5490, 0.5875], device='cuda:1')
tensor([ 0.0706,  0.9810,  0.4260,  0.2715, -0.2634,  0.5185,  0.6239,  0.8059,
         1.4914, -0.0650,  0.3688,  1.0163,  0.0261,  0.1564, -0.2922,  0.2582],
       device='cuda:1')
Solve time for step 4 3.4132346030091867
Current ori: tensor([ 0.0261,  0.1564, -0.2922], device='cuda:1')
Index force: tensor([0.5666], device='cuda:1')
Storing RECOVERY transition: reward=-0.0920 (scaled=-0.0230), steps=4
Reward stats updated: mean 0.0102 -> 0.0098, std: 0.0659
Collected 81 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6528, Q2 Loss=0.6528, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1377
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.6113, Q2 Loss=0.6113, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0559
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5523, Q2 Loss=0.5523, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0411
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4732, Q2 Loss=0.4732, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0476
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5698, Q2 Loss=0.5698, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0243

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.571882
Q2 loss: 0.571882
Current threshold: -149.9883
Global Scale Offset: 1.3017
Reward stats: mean=0.0098, std=0.0659, count=81
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.5719, Q2 Loss: 0.5719, Entropy: 0.0000, Mean TD Error: 0.0613, Threshold: -149.9883
Original likelihood: -197.56411743164062
Adjusted likelihood: -197.56411743164062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 205.9017333984375
Projection step: 1, Loss: 190.86972045898438
Projection step: 2, Loss: 190.0638427734375
Projection step: 3, Loss: 175.21224975585938
Projection step: 4, Loss: 175.7041473388672
Projection step: 5, Loss: 173.5631866455078
Projection step: 6, Loss: 173.93484497070312
Projection step: 7, Loss: 174.76641845703125
Projection step: 8, Loss: 157.79873657226562
Projection step: 9, Loss: 169.06663513183594
Projection step: 10, Loss: 161.32223510742188
Projection step: 11, Loss: 158.32943725585938
Projection step: 12, Loss: 175.7705078125
Projection step: 13, Loss: 162.42481994628906
Projection step: 14, Loss: 161.5811767578125
Projection step: 15, Loss: 160.36758422851562
Projection step: 16, Loss: 165.571044921875
Projection step: 17, Loss: 162.1190643310547
Projection step: 18, Loss: 160.18157958984375
Projection step: 19, Loss: 158.31814575195312
Projection step: 20, Loss: 174.35626220703125
Projection step: 21, Loss: 159.48336791992188
Projection step: 22, Loss: 157.44769287109375
Projection step: 23, Loss: 158.6011199951172
Projection step: 24, Loss: 155.98233032226562
Final likelihood: tensor([-158.6428, -166.9876, -134.4955, -159.4247, -159.4239, -160.4954,
        -162.0496, -145.0933, -143.8161, -162.4278, -151.0638, -148.0715,
        -135.1752, -147.6995, -143.2726, -156.9845])
Final projection likelihood: -152.1952
1 mode projection failed, trying anyway
New goal: tensor([ 0.1168,  0.9348,  0.3110,  0.2450, -0.1980,  0.4804,  0.5886,  0.8491,
         1.4423, -0.0829,  0.4104,  1.0006,  0.0274,  0.1378,  0.5700],
       device='cuda:1')
tensor([[0.0048]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0018]], device='cuda:1')
Original likelihood: -207.54222106933594
Adjusted likelihood: -207.54222106933594
Likelihood residual: 0.0
Original likelihood: -180.7562255859375
Adjusted likelihood: -180.7562255859375
Likelihood residual: 0.0
{'index': 180.7562255859375, 'thumb_middle': 207.54222106933594}
Current yaw: tensor([ 0.0246,  0.1428, -0.3074], device='cuda:1')
14 index
tensor([ 0.0954,  0.9998,  0.4252,  0.3004, -0.2396,  0.5182,  0.6348,  0.8193,
         1.5000, -0.0026,  0.4379,  1.0603,  0.0246,  0.1428, -0.3074,  0.2922],
       device='cuda:1')
Solve time for step 1 10.549597339995671
Current ori: tensor([ 0.0246,  0.1428, -0.3074], device='cuda:1')
Middle force: tensor([0.5293, 0.5007, 0.6116, 0.5950], device='cuda:1')
Thumb force: tensor([0.5005, 0.5053, 0.5489, 0.5551], device='cuda:1')
tensor([ 0.2293,  0.9698,  0.3359,  0.2538, -0.2237,  0.5405,  0.6275,  0.8518,
         1.5000, -0.0164,  0.4637,  0.9892,  0.0186,  0.1290, -0.2961,  0.2929],
       device='cuda:1')
Solve time for step 2 4.275130291993264
Current ori: tensor([ 0.0186,  0.1290, -0.2961], device='cuda:1')
Middle force: tensor([0.5568, 0.5770, 0.5684], device='cuda:1')
Thumb force: tensor([0.5160, 0.5920, 0.5892], device='cuda:1')
tensor([ 0.2608,  0.9737,  0.3240,  0.2472, -0.2084,  0.5430,  0.6347,  0.8719,
         1.5000, -0.0265,  0.4744,  0.9579,  0.0175,  0.1180, -0.3084,  0.4171],
       device='cuda:1')
Solve time for step 3 4.153480203007348
Current ori: tensor([ 0.0175,  0.1180, -0.3084], device='cuda:1')
Middle force: tensor([0.5733, 0.5657], device='cuda:1')
Thumb force: tensor([0.5859, 0.5852], device='cuda:1')
tensor([ 0.2892,  0.9742,  0.3251,  0.2461, -0.2016,  0.5384,  0.6430,  0.8818,
         1.5000, -0.0326,  0.4649,  0.9550,  0.0161,  0.1133, -0.3385,  0.5492],
       device='cuda:1')
Solve time for step 4 4.038663357961923
Current ori: tensor([ 0.0161,  0.1133, -0.3385], device='cuda:1')
Middle force: tensor([0.5577], device='cuda:1')
Thumb force: tensor([0.5784], device='cuda:1')
Storing RECOVERY transition: reward=-0.0274 (scaled=-0.0069), steps=4
Reward stats updated: mean 0.0098 -> 0.0096, std: 0.0655
Collected 82 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.6031, Q2 Loss=0.6031, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1846
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6487, Q2 Loss=0.6487, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0033
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3907, Q2 Loss=0.3907, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0046
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4757, Q2 Loss=0.4757, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1785
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.6161, Q2 Loss=0.6161, Entropy=0.0227, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1458

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (42.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000016
Q1 loss: 0.546857
Q2 loss: 0.546857
Current threshold: -149.9854
Global Scale Offset: 1.3160
Reward stats: mean=0.0096, std=0.0655, count=82
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.5469, Q2 Loss: 0.5469, Entropy: 0.0045, Mean TD Error: 0.1034, Threshold: -149.9854
Original likelihood: -237.18637084960938
Adjusted likelihood: -237.18637084960938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 284.2578125
Projection step: 1, Loss: 254.64300537109375
Projection step: 2, Loss: 262.45709228515625
Projection step: 3, Loss: 252.50550842285156
Projection step: 4, Loss: 256.465576171875
Projection step: 5, Loss: 240.1636505126953
Projection step: 6, Loss: 263.293701171875
Projection step: 7, Loss: 251.36083984375
Projection step: 8, Loss: 248.34483337402344
Projection step: 9, Loss: 254.19708251953125
Projection step: 10, Loss: 260.95782470703125
Projection step: 11, Loss: 257.3256530761719
Projection step: 12, Loss: 239.52854919433594
Projection step: 13, Loss: 237.3569793701172
Projection step: 14, Loss: 256.98956298828125
Projection step: 15, Loss: 257.829833984375
Projection step: 16, Loss: 262.511474609375
Projection step: 17, Loss: 246.04440307617188
Projection step: 18, Loss: 250.9739227294922
Projection step: 19, Loss: 253.25558471679688
Projection step: 20, Loss: 253.6800537109375
Projection step: 21, Loss: 255.75601196289062
Projection step: 22, Loss: 245.2974090576172
Projection step: 23, Loss: 256.435546875
Projection step: 24, Loss: 238.040283203125
Final likelihood: tensor([-233.5276, -250.0886, -232.8394, -273.3452, -232.6244, -236.1130,
        -267.3581, -261.0412, -265.8249, -234.1008, -253.5104, -265.1267,
        -240.1722, -239.5232, -249.7824, -260.8257])
Final projection likelihood: -249.7377
1 mode projection failed, trying anyway
New goal: tensor([ 1.5161e-01,  9.4368e-01,  4.2672e-01,  1.4817e-01, -1.5947e-01,
         4.9481e-01,  4.9353e-01,  8.0910e-01,  1.4115e+00, -9.4218e-02,
         4.0886e-01,  8.8741e-01, -1.4862e-03,  9.3513e-02,  1.8333e+00],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -181.7269287109375
Adjusted likelihood: -181.7269287109375
Likelihood residual: 0.0
Original likelihood: -261.83966064453125
Adjusted likelihood: -261.83966064453125
Likelihood residual: 0.0
{'index': 261.83966064453125, 'thumb_middle': 181.7269287109375}
Current yaw: tensor([ 0.0070,  0.1068, -0.3612], device='cuda:1')
15 thumb_middle
tensor([ 0.1639,  0.9756,  0.3255,  0.2465, -0.1884,  0.5543,  0.6320,  0.8721,
         1.5000, -0.0388,  0.4479,  0.9591,  0.0070,  0.1068, -0.3612,  0.6523],
       device='cuda:1')
Solve time for step 1 9.099295234016608
Current ori: tensor([ 0.0070,  0.1068, -0.3612], device='cuda:1')
Index force: tensor([0.5076, 0.5678, 0.5158, 0.5832], device='cuda:1')
tensor([ 0.1151,  0.9605,  0.4106,  0.1626, -0.2294,  0.5555,  0.5395,  0.8214,
         1.4479, -0.0786,  0.4516,  0.9221,  0.0069,  0.1481, -0.3615,  0.6516],
       device='cuda:1')
Solve time for step 2 3.6410139380022883
Current ori: tensor([ 0.0069,  0.1481, -0.3615], device='cuda:1')
Index force: tensor([0.5925, 0.5819, 0.5861], device='cuda:1')
tensor([ 0.0636,  1.0200,  0.4302,  0.1198, -0.2438,  0.5594,  0.5205,  0.8137,
         1.4673, -0.0817,  0.4521,  0.9060,  0.0055,  0.1580, -0.3650,  0.6386],
       device='cuda:1')
Solve time for step 3 3.4823920549824834
Current ori: tensor([ 0.0055,  0.1580, -0.3650], device='cuda:1')
Index force: tensor([0.5021, 0.6042], device='cuda:1')
tensor([ 0.0429,  1.0301,  0.4515,  0.1477, -0.2498,  0.5543,  0.5161,  0.8044,
         1.4827, -0.0693,  0.4490,  0.9305,  0.0057,  0.1635, -0.3707,  0.6369],
       device='cuda:1')
Solve time for step 4 3.3791885370155796
Current ori: tensor([ 0.0057,  0.1635, -0.3707], device='cuda:1')
Index force: tensor([0.5763], device='cuda:1')
Storing RECOVERY transition: reward=-0.0135 (scaled=-0.0034), steps=4
Reward stats updated: mean 0.0096 -> 0.0094, std: 0.0651
Collected 83 transitions for RL
SAC Update 1/5: Actor Loss=-0.0027, Q1 Loss=0.5317, Q2 Loss=0.5317, Entropy=0.2747, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0673
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5354, Q2 Loss=0.5354, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0690
SAC Update 3/5: Actor Loss=-0.0038, Q1 Loss=0.5873, Q2 Loss=0.5873, Entropy=0.3275, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0920
SAC Update 4/5: Actor Loss=-0.0045, Q1 Loss=0.4596, Q2 Loss=0.4596, Entropy=0.3278, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0587
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5745, Q2 Loss=0.5745, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0286

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.7%)
Actor update: 0.12s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002215
Q1 loss: 0.537697
Q2 loss: 0.537697
Current threshold: -149.9792
Global Scale Offset: 1.3717
Reward stats: mean=0.0094, std=0.0651, count=83
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 0.5377, Q2 Loss: 0.5377, Entropy: 0.1860, Mean TD Error: 0.0631, Threshold: -149.9792
Original likelihood: -203.74496459960938
Adjusted likelihood: -203.74496459960938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 208.1576385498047
Projection step: 1, Loss: 216.19256591796875
Projection step: 2, Loss: 205.1700439453125
Projection step: 3, Loss: 200.21327209472656
Projection step: 4, Loss: 190.47048950195312
Projection step: 5, Loss: 183.17620849609375
Projection step: 6, Loss: 188.0010223388672
Projection step: 7, Loss: 173.51693725585938
Projection step: 8, Loss: 177.94406127929688
Projection step: 9, Loss: 167.8579559326172
Projection step: 10, Loss: 160.38157653808594
Projection step: 11, Loss: 174.9892120361328
Projection step: 12, Loss: 167.3769989013672
Projection step: 13, Loss: 158.55284118652344
Projection step: 14, Loss: 157.84548950195312
Projection step: 15, Loss: 158.73915100097656
Projection step: 16, Loss: 160.89324951171875
Projection step: 17, Loss: 155.20501708984375
Projection step: 18, Loss: 163.13818359375
Projection step: 19, Loss: 163.0630645751953
Projection step: 20, Loss: 159.57205200195312
Projection step: 21, Loss: 154.20999145507812
Projection step: 22, Loss: 156.74365234375
Projection step: 23, Loss: 154.7048797607422
Projection step: 24, Loss: 156.90087890625
Final likelihood: tensor([-163.3607, -156.9097, -156.2201, -168.0313, -150.2117, -163.6969,
        -156.9445, -148.7968, -161.6522, -144.5208, -153.1047, -143.0040,
        -155.6492, -136.1676, -150.0562, -177.4843])
Final projection likelihood: -155.3632
1 mode projection failed, trying anyway
New goal: tensor([ 0.1028,  0.9782,  0.3281,  0.1550, -0.1770,  0.5081,  0.4981,  0.8381,
         1.4310, -0.0421,  0.4733,  0.8842, -0.0029,  0.1406,  0.2720],
       device='cuda:1')
tensor([[0.0040]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0006]], device='cuda:1')
Original likelihood: -241.68109130859375
Adjusted likelihood: -241.68109130859375
Likelihood residual: 0.0
Original likelihood: -171.88380432128906
Adjusted likelihood: -171.88380432128906
Likelihood residual: 0.0
{'index': 171.88380432128906, 'thumb_middle': 241.68109130859375}
Current yaw: tensor([ 0.0020,  0.1444, -0.3971], device='cuda:1')
16 index
tensor([ 0.0559,  1.0715,  0.4152,  0.1637, -0.2147,  0.5560,  0.5271,  0.8223,
         1.5000, -0.0137,  0.5473,  1.0216,  0.0020,  0.1444, -0.3971,  0.6720],
       device='cuda:1')
Solve time for step 1 10.637502947007306
Current ori: tensor([ 0.0020,  0.1444, -0.3971], device='cuda:1')
Middle force: tensor([0.5339, 0.5663, 0.5093, 0.5044], device='cuda:1')
Thumb force: tensor([0.5335, 0.5800, 0.5002, 0.5311], device='cuda:1')
tensor([ 0.2072,  1.0126,  0.3474,  0.1545, -0.2118,  0.5754,  0.5185,  0.8268,
         1.5000, -0.0062,  0.5838,  0.9167, -0.0121,  0.1411, -0.4346,  0.7525],
       device='cuda:1')
Solve time for step 2 4.248281623993535
Current ori: tensor([-0.0121,  0.1411, -0.4346], device='cuda:1')
Middle force: tensor([0.5493, 0.5980, 0.5680], device='cuda:1')
Thumb force: tensor([0.5099, 0.5293, 0.5517], device='cuda:1')
tensor([ 0.2272,  1.0080,  0.3376,  0.1534, -0.2070,  0.5820,  0.5128,  0.8248,
         1.4986, -0.0064,  0.5850,  0.8899, -0.0188,  0.1394, -0.4685,  0.8737],
       device='cuda:1')
Solve time for step 3 4.054245849954896
Current ori: tensor([-0.0188,  0.1394, -0.4685], device='cuda:1')
Middle force: tensor([0.5922, 0.5614], device='cuda:1')
Thumb force: tensor([0.5243, 0.5461], device='cuda:1')
tensor([ 0.2294,  1.0102,  0.3368,  0.1540, -0.2006,  0.5790,  0.5169,  0.8371,
         1.5000, -0.0140,  0.5744,  0.9007, -0.0185,  0.1353, -0.4811,  0.9656],
       device='cuda:1')
Solve time for step 4 4.002610402007122
Current ori: tensor([-0.0185,  0.1353, -0.4811], device='cuda:1')
Middle force: tensor([0.5542], device='cuda:1')
Thumb force: tensor([0.5371], device='cuda:1')
Storing RECOVERY transition: reward=0.0495 (scaled=0.0124), steps=4
Reward stats updated: mean 0.0094 -> 0.0095, std: 0.0647
Collected 84 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.4939, Q2 Loss=0.4939, Entropy=0.0002, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0452
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4449, Q2 Loss=0.4449, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0450
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4803, Q2 Loss=0.4803, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0697
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4332, Q2 Loss=0.4332, Entropy=0.0001, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0369
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3915, Q2 Loss=0.3915, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0260

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.6%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.448760
Q2 loss: 0.448760
Current threshold: -149.9630
Global Scale Offset: 1.4208
Reward stats: mean=0.0095, std=0.0647, count=84
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4488, Q2 Loss: 0.4488, Entropy: 0.0001, Mean TD Error: 0.0445, Threshold: -149.9630
Original likelihood: -165.66993713378906
Adjusted likelihood: -165.66993713378906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 181.7186737060547
Projection step: 1, Loss: 175.78907775878906
Projection step: 2, Loss: 177.348388671875
Projection step: 3, Loss: 166.11080932617188
Projection step: 4, Loss: 172.59515380859375
Projection step: 5, Loss: 160.6758575439453
Projection step: 6, Loss: 160.72860717773438
Projection step: 7, Loss: 173.92800903320312
Projection step: 8, Loss: 153.29806518554688
Projection step: 9, Loss: 161.46128845214844
Projection step: 10, Loss: 153.04354858398438
Projection step: 11, Loss: 161.14862060546875
Projection step: 12, Loss: 159.71707153320312
Projection step: 13, Loss: 151.9436492919922
Projection step: 14, Loss: 163.4512939453125
Projection step: 15, Loss: 148.26626586914062
Projection step: 16, Loss: 143.85043334960938
Projection step: 17, Loss: 155.00912475585938
Projection step: 18, Loss: 152.38180541992188
Projection step: 19, Loss: 141.0487060546875
Projection step: 20, Loss: 161.2253875732422
Projection step: 21, Loss: 145.9381866455078
Projection step: 22, Loss: 140.8418731689453
Projection step: 23, Loss: 140.3507080078125
Projection step: 24, Loss: 139.97557067871094
Final likelihood: tensor([-129.0927, -149.8883, -120.9350, -140.4375, -136.2014, -125.6435,
        -128.8874, -155.6307, -127.5344, -127.1506, -134.9675, -234.1714,
        -138.4920, -137.2170, -127.0220, -135.7677])
Final projection likelihood: -140.5649
1 mode projection succeeded
New goal: tensor([ 0.1430,  0.9575,  0.3819,  0.1476, -0.1654,  0.5171,  0.5174,  0.8357,
         1.4247, -0.0354,  0.5054,  0.8052, -0.0230,  0.1273,  1.1755],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0012]], device='cuda:1')
Original likelihood: -167.73883056640625
Adjusted likelihood: -167.73883056640625
Likelihood residual: 0.0
Original likelihood: -178.21568298339844
Adjusted likelihood: -178.21568298339844
Likelihood residual: 0.0
{'index': 178.21568298339844, 'thumb_middle': 167.73883056640625}
Current yaw: tensor([-0.0202,  0.1324, -0.4689], device='cuda:1')
17 thumb_middle
tensor([ 0.1173,  1.0094,  0.3378,  0.1546, -0.1948,  0.5870,  0.5118,  0.8281,
         1.4966, -0.0124,  0.5643,  0.9196, -0.0202,  0.1324, -0.4689,  0.9837],
       device='cuda:1')
Solve time for step 1 9.164473933982663
Current ori: tensor([-0.0202,  0.1324, -0.4689], device='cuda:1')
Index force: tensor([0.5516, 0.5030, 0.5774, 0.5811], device='cuda:1')
tensor([ 0.0758,  1.0537,  0.3796,  0.1269, -0.2317,  0.5717,  0.4952,  0.7923,
         1.4404, -0.0463,  0.5228,  0.8279, -0.0291,  0.1627, -0.4924,  4.3160],
       device='cuda:1')
Solve time for step 2 3.6974641190026887
Current ori: tensor([-0.0291,  0.1627, -0.4924], device='cuda:1')
Index force: tensor([0.5017, 0.5608, 0.5650], device='cuda:1')
tensor([ 0.0519,  1.0455,  0.4204,  0.1459, -0.2355,  0.5470,  0.5024,  0.8206,
         1.4492, -0.0282,  0.5189,  0.8118, -0.0281,  0.1674, -0.5305, -1.5876],
       device='cuda:1')
Solve time for step 3 3.6707768499618396
Current ori: tensor([-0.0281,  0.1674, -0.5305], device='cuda:1')
Index force: tensor([0.5432, 0.5523], device='cuda:1')
tensor([ 2.0910e-03,  1.0844e+00,  4.3846e-01,  1.6588e-01, -2.4489e-01,
         5.5177e-01,  4.9077e-01,  8.0274e-01,  1.4712e+00, -4.2151e-02,
         5.3352e-01,  8.3112e-01, -3.7360e-02,  1.7675e-01, -5.6915e-01,
        -5.1894e+00], device='cuda:1')
Solve time for step 4 3.346079604001716
Current ori: tensor([-0.0374,  0.1768, -0.5692], device='cuda:1')
Index force: tensor([0.5442], device='cuda:1')
Storing RECOVERY transition: reward=0.0815 (scaled=0.0204), steps=4
Reward stats updated: mean 0.0095 -> 0.0096, std: 0.0643
Collected 85 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5222, Q2 Loss=0.5222, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1194
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.5682, Q2 Loss=0.5682, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0190
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4635, Q2 Loss=0.4635, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0356
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.3853, Q2 Loss=0.3853, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0356
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4783, Q2 Loss=0.4783, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0690

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.483501
Q2 loss: 0.483501
Current threshold: -149.9533
Global Scale Offset: 1.4513
Reward stats: mean=0.0096, std=0.0643, count=85
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4835, Q2 Loss: 0.4835, Entropy: 0.0000, Mean TD Error: 0.0557, Threshold: -149.9533
Original likelihood: -220.94960021972656
Adjusted likelihood: -220.94960021972656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 220.95675659179688
Projection step: 1, Loss: 217.38430786132812
Projection step: 2, Loss: 234.21405029296875
Projection step: 3, Loss: 216.60409545898438
Projection step: 4, Loss: 202.7479248046875
Projection step: 5, Loss: 211.18951416015625
Projection step: 6, Loss: 205.09791564941406
Projection step: 7, Loss: 191.87896728515625
Projection step: 8, Loss: 218.41036987304688
Projection step: 9, Loss: 200.43150329589844
Projection step: 10, Loss: 183.9149169921875
Projection step: 11, Loss: 199.48550415039062
Projection step: 12, Loss: 185.14462280273438
Projection step: 13, Loss: 178.66653442382812
Projection step: 14, Loss: 181.37954711914062
Projection step: 15, Loss: 174.79693603515625
Projection step: 16, Loss: 179.61224365234375
Projection step: 17, Loss: 176.13619995117188
Projection step: 18, Loss: 176.30517578125
Projection step: 19, Loss: 183.83721923828125
Projection step: 20, Loss: 181.16375732421875
Projection step: 21, Loss: 168.4409942626953
Projection step: 22, Loss: 174.85794067382812
Projection step: 23, Loss: 191.36474609375
Projection step: 24, Loss: 163.25245666503906
Final likelihood: tensor([-196.0547, -175.3721, -323.9747, -175.2819, -159.1773, -167.5206,
        -176.8425, -167.1547, -165.7803, -148.1504, -176.9741, -168.5764,
        -143.9526, -174.9423, -183.4967, -157.0630])
Final projection likelihood: -178.7696
1 mode projection failed, trying anyway
New goal: tensor([ 0.0199,  0.9350,  0.3691,  0.1396, -0.1867,  0.4753,  0.4622,  0.8154,
         1.4669,  0.0077,  0.5308,  0.8072, -0.0424,  0.1519, -0.4920],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0020]], device='cuda:1')
Original likelihood: -243.10092163085938
Adjusted likelihood: -243.10092163085938
Likelihood residual: 0.0
Original likelihood: -155.05606079101562
Adjusted likelihood: -155.05606079101562
Likelihood residual: 0.0
{'index': 155.05606079101562, 'thumb_middle': 243.10092163085938}
Current yaw: tensor([-0.0402,  0.1584, -0.5915], device='cuda:1')
18 index
tensor([-0.0063,  1.0976,  0.4714,  0.1642, -0.2128,  0.5505,  0.5041,  0.8228,
         1.5000,  0.0344,  0.5630,  0.8294, -0.0402,  0.1584, -0.5915,  5.2553],
       device='cuda:1')
Solve time for step 1 10.36703344999114
Current ori: tensor([-0.0402,  0.1584, -0.5915], device='cuda:1')
Middle force: tensor([0.5165, 0.5164, 0.5362, 0.5706], device='cuda:1')
Thumb force: tensor([0.5586, 0.5273, 0.5705, 0.6198], device='cuda:1')
tensor([ 0.2014,  0.9733,  0.3853,  0.1390, -0.1998,  0.5579,  0.4997,  0.8248,
         1.5000,  0.0390,  0.5596,  0.7873, -0.0514,  0.1537, -0.6617,  4.6533],
       device='cuda:1')
Solve time for step 2 4.17998695600545
Current ori: tensor([-0.0514,  0.1537, -0.6617], device='cuda:1')
Middle force: tensor([0.5152, 0.5338, 0.5648], device='cuda:1')
Thumb force: tensor([0.5234, 0.5664, 0.6202], device='cuda:1')
tensor([ 0.1960,  0.9528,  0.3690,  0.1352, -0.1987,  0.5689,  0.4898,  0.8144,
         1.5000,  0.0405,  0.5678,  0.7747, -0.0588,  0.1548, -0.6858,  4.4625],
       device='cuda:1')
Solve time for step 3 3.989374083990697
Current ori: tensor([-0.0588,  0.1548, -0.6858], device='cuda:1')
Middle force: tensor([0.5322, 0.5595], device='cuda:1')
Thumb force: tensor([0.5588, 0.6190], device='cuda:1')
tensor([ 0.1842,  0.9504,  0.3690,  0.1352, -0.2045,  0.5755,  0.4841,  0.8019,
         1.5000,  0.0461,  0.5834,  0.7615, -0.0647,  0.1598, -0.7105,  4.3177],
       device='cuda:1')
Solve time for step 4 3.9371938750264235
Current ori: tensor([-0.0647,  0.1598, -0.7105], device='cuda:1')
Middle force: tensor([0.5567], device='cuda:1')
Thumb force: tensor([0.6094], device='cuda:1')
Storing RECOVERY transition: reward=-0.0091 (scaled=-0.0023), steps=4
Reward stats updated: mean 0.0096 -> 0.0095, std: 0.0640
Collected 86 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5151, Q2 Loss=0.5151, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0301
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4722, Q2 Loss=0.4722, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2031
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4100, Q2 Loss=0.4100, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0915
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5174, Q2 Loss=0.5174, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0979
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5101, Q2 Loss=0.5101, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1693

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.4%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.484965
Q2 loss: 0.484965
Current threshold: -149.9473
Global Scale Offset: 1.4701
Reward stats: mean=0.0095, std=0.0640, count=86
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.4850, Q2 Loss: 0.4850, Entropy: 0.0000, Mean TD Error: 0.1184, Threshold: -149.9473
Original likelihood: -243.2063751220703
Adjusted likelihood: -243.2063751220703
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 194.7860565185547
Projection step: 1, Loss: 183.41299438476562
Projection step: 2, Loss: 203.48391723632812
Projection step: 3, Loss: 202.14425659179688
Projection step: 4, Loss: 208.47409057617188
Projection step: 5, Loss: 180.396728515625
Projection step: 6, Loss: 186.4022216796875
Projection step: 7, Loss: 198.4666290283203
Projection step: 8, Loss: 182.2663116455078
Projection step: 9, Loss: 187.15768432617188
Projection step: 10, Loss: 178.68997192382812
Projection step: 11, Loss: 181.55319213867188
Projection step: 12, Loss: 184.67752075195312
Projection step: 13, Loss: 174.74343872070312
Projection step: 14, Loss: 171.6761474609375
Projection step: 15, Loss: 181.5458526611328
Projection step: 16, Loss: 190.51266479492188
Projection step: 17, Loss: 181.34803771972656
Projection step: 18, Loss: 175.56700134277344
Projection step: 19, Loss: 183.828857421875
Projection step: 20, Loss: 176.0462646484375
Projection step: 21, Loss: 161.46847534179688
Projection step: 22, Loss: 172.80398559570312
Projection step: 23, Loss: 172.37451171875
Projection step: 24, Loss: 169.6807403564453
Final likelihood: tensor([-159.9080, -157.4170, -170.4659, -169.2350, -158.8519, -165.8924,
        -167.2593, -156.1795, -165.2237, -159.1573, -157.1189, -159.1662,
        -153.9639, -295.7327, -151.0977, -168.9385])
Final projection likelihood: -169.7255
1 mode projection failed, trying anyway
New goal: tensor([ 0.0581,  0.8738,  0.4035,  0.1815, -0.1876,  0.5284,  0.4728,  0.7880,
         1.4485,  0.0295,  0.5836,  0.7895, -0.0797,  0.1588,  2.3961],
       device='cuda:1')
tensor([[0.0034]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -194.47711181640625
Adjusted likelihood: -194.47711181640625
Likelihood residual: 0.0
Original likelihood: -186.06346130371094
Adjusted likelihood: -186.06346130371094
Likelihood residual: 0.0
{'index': 186.06346130371094, 'thumb_middle': 194.47711181640625}
Current yaw: tensor([-0.0777,  0.1674, -0.7899], device='cuda:1')
19 index
tensor([ 0.0605,  0.9494,  0.3679,  0.1348, -0.2106,  0.5832,  0.4733,  0.7924,
         1.5000,  0.0503,  0.5943,  0.7687, -0.0777,  0.1674, -0.7899,  4.3543],
       device='cuda:1')
Solve time for step 1 10.261772847967222
Current ori: tensor([-0.0777,  0.1674, -0.7899], device='cuda:1')
Middle force: tensor([0.5230, 0.5005, 0.5804, 0.5571], device='cuda:1')
Thumb force: tensor([0.5100, 0.6391, 0.6022, 0.5909], device='cuda:1')
tensor([ 0.1511,  0.8410,  0.3660,  0.1594, -0.2004,  0.5883,  0.4945,  0.7994,
         1.5000,  0.0427,  0.6164,  0.7104, -0.1115,  0.1664, -0.8525,  4.7524],
       device='cuda:1')
Solve time for step 2 4.205452722962946
Current ori: tensor([-0.1115,  0.1664, -0.8525], device='cuda:1')
Middle force: tensor([0.5004, 0.5771, 0.5550], device='cuda:1')
Thumb force: tensor([0.6292, 0.5982, 0.5877], device='cuda:1')
tensor([ 0.1512,  0.8231,  0.3663,  0.1602, -0.1774,  0.5923,  0.4994,  0.8015,
         1.5000,  0.0875,  0.6065,  0.7309, -0.1464,  0.1658, -0.9304,  4.8547],
       device='cuda:1')
Solve time for step 3 3.9415414570248686
Current ori: tensor([-0.1464,  0.1658, -0.9304], device='cuda:1')
Middle force: tensor([0.5735, 0.5516], device='cuda:1')
Thumb force: tensor([0.5970, 0.5844], device='cuda:1')
tensor([ 0.1320,  0.8377,  0.3731,  0.1659, -0.1734,  0.6522,  0.5263,  0.7993,
         1.5000,  0.0867,  0.5926,  0.7402, -0.3292,  0.2928, -0.9610,  4.5387],
       device='cuda:1')
Solve time for step 4 4.025660519953817
Current ori: tensor([-0.3292,  0.2928, -0.9610], device='cuda:1')
Middle force: tensor([0.5736], device='cuda:1')
Thumb force: tensor([0.5231], device='cuda:1')
Storing RECOVERY transition: reward=-0.7915 (scaled=-0.1979), steps=4
Reward stats updated: mean 0.0095 -> 0.0071, std: 0.0673
Collected 87 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.3997, Q2 Loss=0.3997, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0268
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5296, Q2 Loss=0.5296, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0674
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.4351, Q2 Loss=0.4351, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0546
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.3336, Q2 Loss=0.3336, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1098
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4019, Q2 Loss=0.4019, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1853

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (39.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.419967
Q2 loss: 0.419967
Current threshold: -149.9438
Global Scale Offset: 1.4816
Reward stats: mean=0.0071, std=0.0673, count=87
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.4200, Q2 Loss: 0.4200, Entropy: 0.0000, Mean TD Error: 0.0888, Threshold: -149.9438
Original likelihood: -1736.23779296875
Adjusted likelihood: -1736.23779296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 6
Loaded trajectory sampler
Current yaw: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
Current yaw: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
1 turn
Sampling time 3.594489334966056
tensor([ 0.1430,  0.5696,  0.6077,  0.6241, -0.1176,  0.5355,  0.9137,  0.8735,
         1.2347,  0.2873,  0.2762,  1.1186, -0.0027,  0.0150, -0.0462,  0.3060],
       device='cuda:1')
Original likelihood: -118.02981567382812
Adjusted likelihood: -118.02981567382812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.882625099970028
Current ori: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
Middle force: tensor([0.5690, 0.6702, 0.8273, 1.5028, 0.5094, 0.6220, 0.4962, 0.5298, 0.6411,
        0.6518, 0.5638, 0.5298], device='cuda:1')
Thumb force: tensor([0.5881, 0.7125, 1.1207, 1.2029, 1.7279, 0.5893, 0.5969, 0.5339, 0.6042,
        0.6268, 0.6625, 0.5651], device='cuda:1')
Index force: tensor([0.6083, 0.5445, 0.5941, 0.8202, 0.6325, 0.5461, 0.7504, 0.5048, 0.5991,
        0.5106, 0.6302, 0.5883], device='cuda:1')
Storing NORMAL transition: reward=-0.0438 (scaled=-0.0438), steps=1
Reward stats updated: mean 0.0071 -> 0.0065, std: 0.0672
Collected 88 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4986, Q2 Loss=0.4986, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1474
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4037, Q2 Loss=0.4037, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0356
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3859, Q2 Loss=0.3859, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0462
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4153, Q2 Loss=0.4153, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0471
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3824, Q2 Loss=0.3824, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1010

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (18.0%)
Q2 update: 0.05s (19.0%)
Actor update: 0.11s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.417167
Q2 loss: 0.417167
Current threshold: -149.9416
Global Scale Offset: 1.4886
Reward stats: mean=0.0065, std=0.0672, count=88
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.4172, Q2 Loss: 0.4172, Entropy: 0.0000, Mean TD Error: 0.0755, Threshold: -149.9416
tensor([ 0.1110,  0.5527,  0.5935,  0.6336, -0.1498,  0.6677,  0.7562,  0.8471,
         1.3168,  0.1867,  0.2458,  1.1069, -0.0205,  0.0193, -0.0029,  1.3266],
       device='cuda:1')
Original likelihood: -144.27911376953125
Adjusted likelihood: -144.27911376953125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9900)
Solve time for step 2 5.527690382034052
Current ori: tensor([-0.0205,  0.0193, -0.0029], device='cuda:1')
Middle force: tensor([0.6653, 0.8331, 1.4796, 0.5082, 0.6172, 0.5012, 0.5281, 0.6362, 0.6486,
        0.5601, 0.5306], device='cuda:1')
Thumb force: tensor([0.7091, 1.0871, 1.1888, 1.6781, 0.5858, 0.5843, 0.5308, 0.5972, 0.6275,
        0.6604, 0.5537], device='cuda:1')
Index force: tensor([0.5367, 0.5978, 0.7937, 0.6219, 0.5405, 0.7783, 0.5041, 0.5941, 0.5082,
        0.6219, 0.5893], device='cuda:1')
Storing NORMAL transition: reward=-0.0310 (scaled=-0.0310), steps=1
Reward stats updated: mean 0.0065 -> 0.0061, std: 0.0669
Collected 89 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.4651, Q2 Loss=0.4651, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0300
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3375, Q2 Loss=0.3375, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0636
SAC Update 3/5: Actor Loss=-0.0029, Q1 Loss=0.3827, Q2 Loss=0.3827, Entropy=0.3322, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0689
SAC Update 4/5: Actor Loss=-0.0048, Q1 Loss=0.3445, Q2 Loss=0.3445, Entropy=0.3609, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0721
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4033, Q2 Loss=0.4033, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0087

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001541
Q1 loss: 0.386604
Q2 loss: 0.386604
Current threshold: -149.9274
Global Scale Offset: 1.5113
Reward stats: mean=0.0061, std=0.0669, count=89
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 0.3866, Q2 Loss: 0.3866, Entropy: 0.1386, Mean TD Error: 0.0487, Threshold: -149.9274
tensor([ 1.2862e-01,  4.6777e-01,  6.9759e-01,  6.8580e-01, -1.6867e-01,
         6.6502e-01,  8.1697e-01,  8.1054e-01,  1.3110e+00,  1.3606e-01,
         3.0790e-01,  1.0657e+00, -1.2999e-03,  1.7522e-02,  2.8603e-02,
         1.3913e+00], device='cuda:1')
Original likelihood: -150.98043823242188
Adjusted likelihood: -150.98043823242188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3344)
State is out of distribution
Projection step: 0, Loss: 156.0481414794922
Projection step: 1, Loss: 142.5873260498047
Projection step: 2, Loss: 141.01979064941406
Projection step: 3, Loss: 126.787109375
Projection step: 4, Loss: 126.62727355957031
Projection step: 5, Loss: 118.61954498291016
Projection step: 6, Loss: 113.75282287597656
Projection step: 7, Loss: 112.31646728515625
Projection step: 8, Loss: 100.50283813476562
Final likelihood: tensor([ -93.1023, -104.5594, -126.4749, -107.2317, -100.5871,  -93.4127,
         -86.4328, -109.3788,  -96.1384,  -81.4770, -108.5875,  -93.3594,
        -111.4964, -103.4949, -101.8357,  -90.4764])
Final projection likelihood: -100.5028
1 mode projection succeeded
New goal: tensor([ 1.1535e-01,  4.9452e-01,  6.2993e-01,  6.7822e-01, -1.2650e-01,
         6.4744e-01,  8.9365e-01,  7.9262e-01,  1.3059e+00,  2.3110e-01,
         2.6271e-01,  1.1147e+00,  1.7271e-04,  1.5807e-02,  2.6076e-01],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -156.53106689453125
Adjusted likelihood: -156.53106689453125
Likelihood residual: 0.0
Original likelihood: -134.58941650390625
Adjusted likelihood: -134.58941650390625
Likelihood residual: 0.0
{'index': 134.58941650390625, 'thumb_middle': 156.53106689453125}
Current yaw: tensor([-0.0013,  0.0175,  0.0286], device='cuda:1')
2 index
tensor([ 1.2862e-01,  4.6777e-01,  6.9759e-01,  6.8580e-01, -1.6867e-01,
         6.6502e-01,  8.1697e-01,  8.1054e-01,  1.3110e+00,  1.3606e-01,
         3.0790e-01,  1.0657e+00, -1.2999e-03,  1.7522e-02,  2.8603e-02,
         1.3913e+00], device='cuda:1')
Solve time for step 1 10.201181903015822
Current ori: tensor([-0.0013,  0.0175,  0.0286], device='cuda:1')
Middle force: tensor([0.5373, 0.5962, 0.5463, 0.5488], device='cuda:1')
Thumb force: tensor([0.5422, 0.5057, 0.5003, 0.5148], device='cuda:1')
tensor([ 1.6342e-01,  4.4615e-01,  5.9840e-01,  6.6153e-01, -1.6573e-01,
         6.4327e-01,  8.6313e-01,  7.8504e-01,  1.2914e+00,  1.7369e-01,
         3.0667e-01,  1.0587e+00, -9.1782e-04,  1.4147e-02, -4.6838e-03,
         1.0057e+00], device='cuda:1')
Solve time for step 2 4.191739561967552
Current ori: tensor([-0.0009,  0.0141, -0.0047], device='cuda:1')
Middle force: tensor([0.5907, 0.5439, 0.5453], device='cuda:1')
Thumb force: tensor([0.5045, 0.5001, 0.5128], device='cuda:1')
tensor([ 0.1616,  0.4527,  0.5900,  0.6528, -0.1552,  0.6460,  0.8720,  0.7796,
         1.2847,  0.1768,  0.2923,  1.0676, -0.0028,  0.0057, -0.0177,  0.7275],
       device='cuda:1')
Solve time for step 3 4.119679975032341
Current ori: tensor([-0.0028,  0.0057, -0.0177], device='cuda:1')
Middle force: tensor([0.5095, 0.5451], device='cuda:1')
Thumb force: tensor([0.5840, 0.6267], device='cuda:1')
tensor([ 1.6369e-01,  4.5518e-01,  5.8960e-01,  6.5431e-01, -1.4382e-01,
         6.4366e-01,  8.8392e-01,  7.9016e-01,  1.2802e+00,  1.7243e-01,
         2.6609e-01,  1.1039e+00,  1.2229e-03, -4.1054e-03, -2.5948e-02,
         5.5616e-01], device='cuda:1')
Solve time for step 4 3.9601582399918698
Current ori: tensor([ 0.0012, -0.0041, -0.0259], device='cuda:1')
Middle force: tensor([0.5116], device='cuda:1')
Thumb force: tensor([0.5622], device='cuda:1')
Storing RECOVERY transition: reward=0.0503 (scaled=0.0251), steps=2
Reward stats updated: mean 0.0061 -> 0.0063, std: 0.0666
Collected 90 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3080, Q2 Loss=0.3080, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1693
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3853, Q2 Loss=0.3853, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0491
SAC Update 3/5: Actor Loss=-0.0066, Q1 Loss=0.3294, Q2 Loss=0.3294, Entropy=0.6520, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0760
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.3779, Q2 Loss=0.3779, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0331
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4039, Q2 Loss=0.4039, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1297

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.9%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.06s (20.2%)
Actor update: 0.11s (41.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001329
Q1 loss: 0.360913
Q2 loss: 0.360913
Current threshold: -149.9018
Global Scale Offset: 1.5594
Reward stats: mean=0.0063, std=0.0666, count=90
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 0.3609, Q2 Loss: 0.3609, Entropy: 0.1304, Mean TD Error: 0.0915, Threshold: -149.9018
Original likelihood: -121.02053833007812
Adjusted likelihood: -121.02053833007812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0018, -0.0043, -0.0214], device='cuda:1')
3 turn
Sampling time 3.820398836978711
tensor([ 0.1131,  0.5107,  0.6313,  0.6776, -0.1423,  0.6492,  0.8789,  0.7805,
         1.2749,  0.1809,  0.2686,  1.0983, -0.0018, -0.0043, -0.0214,  0.5080],
       device='cuda:1')
Original likelihood: -120.2999496459961
Adjusted likelihood: -120.2999496459961
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.109416380000766
Current ori: tensor([-0.0018, -0.0043, -0.0214], device='cuda:1')
Middle force: tensor([0.5066, 0.5819, 1.4956, 0.6034, 0.5819, 0.5829, 0.5417, 0.5734, 0.5510,
        2.0313, 0.7771, 0.6613], device='cuda:1')
Thumb force: tensor([0.6802, 0.7748, 1.8204, 0.7585, 1.0393, 0.5845, 0.6247, 0.7293, 2.0739,
        0.5541, 0.5796, 0.5491], device='cuda:1')
Index force: tensor([0.5799, 0.8233, 0.5627, 0.5670, 0.5979, 0.5854, 0.6726, 0.8908, 0.6507,
        0.6669, 0.5359, 0.5797], device='cuda:1')
Storing NORMAL transition: reward=0.0739 (scaled=0.0739), steps=1
Reward stats updated: mean 0.0063 -> 0.0070, std: 0.0666
Collected 91 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3831, Q2 Loss=0.3831, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0776
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3770, Q2 Loss=0.3770, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1156
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.3948, Q2 Loss=0.3948, Entropy=0.0003, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0941
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4133, Q2 Loss=0.4133, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0101
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3521, Q2 Loss=0.3521, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0336

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.0%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (18.4%)
Actor update: 0.08s (39.4%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.384027
Q2 loss: 0.384027
Current threshold: -149.8834
Global Scale Offset: 1.5985
Reward stats: mean=0.0070, std=0.0666, count=91
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.3840, Q2 Loss: 0.3840, Entropy: 0.0001, Mean TD Error: 0.0662, Threshold: -149.8834
tensor([ 0.1303,  0.4877,  0.6452,  0.7405, -0.2832,  0.6119,  0.9877,  0.6952,
         1.2809,  0.2373,  0.3309,  0.9841, -0.0021,  0.0205, -0.0958,  1.0318],
       device='cuda:1')
Original likelihood: -225.70501708984375
Adjusted likelihood: -225.70501708984375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 236.60690307617188
Projection step: 1, Loss: 223.524658203125
Projection step: 2, Loss: 210.4478759765625
Projection step: 3, Loss: 195.09323120117188
Projection step: 4, Loss: 188.42599487304688
Projection step: 5, Loss: 180.30499267578125
Projection step: 6, Loss: 166.81591796875
Projection step: 7, Loss: 166.20970153808594
Projection step: 8, Loss: 155.99908447265625
Projection step: 9, Loss: 154.82257080078125
Projection step: 10, Loss: 137.97915649414062
Projection step: 11, Loss: 129.3026123046875
Projection step: 12, Loss: 134.6437225341797
Projection step: 13, Loss: 127.20918273925781
Projection step: 14, Loss: 132.69471740722656
Projection step: 15, Loss: 113.34815979003906
Projection step: 16, Loss: 116.21116638183594
Projection step: 17, Loss: 113.19708251953125
Projection step: 18, Loss: 108.93235778808594
Projection step: 19, Loss: 110.70706176757812
Projection step: 20, Loss: 99.10196685791016
Final likelihood: tensor([ -80.9862,  -90.8404,  -97.4502, -120.2288, -101.6257,  -89.0141,
         -91.4917,  -93.2297,  -82.3987, -110.8185, -114.6420, -107.4598,
        -102.1315, -101.6798, -108.6598,  -92.9746])
Final projection likelihood: -99.1020
1 mode projection succeeded
New goal: tensor([ 1.2601e-01,  5.0069e-01,  5.9577e-01,  6.9458e-01, -1.2863e-01,
         6.3847e-01,  9.8301e-01,  7.6427e-01,  1.2870e+00,  2.8070e-01,
         2.7475e-01,  1.0629e+00,  1.0029e-04,  1.5532e-02,  4.0127e-01],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0088]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -137.99945068359375
Adjusted likelihood: -137.99945068359375
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 137.99945068359375}
Current yaw: tensor([-0.0021,  0.0205, -0.0958], device='cuda:1')
4 thumb_middle
tensor([ 0.1303,  0.4877,  0.6452,  0.7405, -0.2832,  0.6119,  0.9877,  0.6952,
         1.2809,  0.2373,  0.3309,  0.9841, -0.0021,  0.0205, -0.0958,  1.0318],
       device='cuda:1')
Solve time for step 1 8.888292746967636
Current ori: tensor([-0.0021,  0.0205, -0.0958], device='cuda:1')
Index force: tensor([0.5847, 0.6000, 0.5779, 0.5011], device='cuda:1')
tensor([ 0.1272,  0.4939,  0.6356,  0.7376, -0.2952,  0.6095,  0.9347,  0.7221,
         1.2405,  0.2620,  0.2111,  1.0129, -0.0035,  0.0216, -0.0958,  1.0045],
       device='cuda:1')
Solve time for step 2 3.6674796649604104
Current ori: tensor([-0.0035,  0.0216, -0.0958], device='cuda:1')
Index force: tensor([0.5759, 0.5774, 0.5925], device='cuda:1')
tensor([ 0.1213,  0.5353,  0.6034,  0.6793, -0.2934,  0.6098,  0.9373,  0.7280,
         1.2446,  0.2597,  0.1881,  1.0216, -0.0180,  0.0232, -0.0958,  0.9715],
       device='cuda:1')
Solve time for step 3 3.4851124199922197
Current ori: tensor([-0.0180,  0.0232, -0.0958], device='cuda:1')
Index force: tensor([0.5633, 0.5793], device='cuda:1')
tensor([ 0.1279,  0.5263,  0.6111,  0.7014, -0.2909,  0.6082,  0.9373,  0.7316,
         1.2429,  0.2590,  0.1845,  1.0256, -0.0141,  0.0197, -0.0958,  0.9903],
       device='cuda:1')
Solve time for step 4 3.408115711004939
Current ori: tensor([-0.0141,  0.0197, -0.0958], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0076 (scaled=0.0076), steps=1
Reward stats updated: mean 0.0070 -> 0.0070, std: 0.0662
Collected 92 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3396, Q2 Loss=0.3396, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1063
SAC Update 2/5: Actor Loss=-0.0061, Q1 Loss=0.2769, Q2 Loss=0.2769, Entropy=0.3448, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0901
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3604, Q2 Loss=0.3604, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0484
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.3235, Q2 Loss=0.3235, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0412
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3852, Q2 Loss=0.3852, Entropy=0.0009, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0717

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.8%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.1%)
Actor update: 0.08s (38.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001223
Q1 loss: 0.337127
Q2 loss: 0.337127
Current threshold: -149.8865
Global Scale Offset: 1.6299
Reward stats: mean=0.0070, std=0.0662, count=92
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 0.3371, Q2 Loss: 0.3371, Entropy: 0.0691, Mean TD Error: 0.0715, Threshold: -149.8865
Original likelihood: -161.30116271972656
Adjusted likelihood: -161.30116271972656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 172.29931640625
Projection step: 1, Loss: 162.19839477539062
Projection step: 2, Loss: 159.12335205078125
Projection step: 3, Loss: 150.40438842773438
Projection step: 4, Loss: 154.88369750976562
Projection step: 5, Loss: 143.75070190429688
Projection step: 6, Loss: 143.5951385498047
Projection step: 7, Loss: 134.83175659179688
Projection step: 8, Loss: 130.68170166015625
Projection step: 9, Loss: 125.36028289794922
Projection step: 10, Loss: 120.39559936523438
Projection step: 11, Loss: 116.58018493652344
Projection step: 12, Loss: 117.90345001220703
Projection step: 13, Loss: 116.05036926269531
Projection step: 14, Loss: 115.99906921386719
Projection step: 15, Loss: 108.58012390136719
Projection step: 16, Loss: 107.28182983398438
Projection step: 17, Loss: 109.86053466796875
Projection step: 18, Loss: 109.23471069335938
Projection step: 19, Loss: 109.52437591552734
Projection step: 20, Loss: 102.93460083007812
Final likelihood: tensor([-105.6631,  -89.5648, -101.3039, -118.4123,  -92.6670, -114.0802,
        -115.1203,  -97.7003, -109.5420, -106.8411, -102.8555,  -99.4936,
         -98.7068,  -99.1204, -108.6444,  -87.2380])
Final projection likelihood: -102.9346
1 mode projection succeeded
New goal: tensor([ 0.1090,  0.5284,  0.5933,  0.6789, -0.1040,  0.6183,  0.9216,  0.7695,
         1.3087,  0.2871,  0.2268,  1.1047, -0.0135,  0.0168,  0.5792],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -123.13082885742188
Adjusted likelihood: -123.13082885742188
Likelihood residual: 0.0
Original likelihood: -150.7276611328125
Adjusted likelihood: -150.7276611328125
Likelihood residual: 0.0
{'index': 150.7276611328125, 'thumb_middle': 123.13082885742188}
Current yaw: tensor([-0.0157,  0.0163, -0.1035], device='cuda:1')
5 thumb_middle
tensor([ 0.1266,  0.5290,  0.6094,  0.6950, -0.2194,  0.6442,  0.9657,  0.7500,
         1.3030,  0.2796,  0.2361,  1.0536, -0.0157,  0.0163, -0.1035,  1.0342],
       device='cuda:1')
Solve time for step 1 8.632300953031518
Current ori: tensor([-0.0157,  0.0163, -0.1035], device='cuda:1')
Index force: tensor([0.5830, 0.5849, 0.5925, 0.5858], device='cuda:1')
tensor([ 0.1196,  0.5308,  0.6096,  0.6754, -0.2458,  0.5916,  0.8745,  0.7405,
         1.2629,  0.2712,  0.1533,  1.0490, -0.0177,  0.0213, -0.1035,  1.0042],
       device='cuda:1')
Solve time for step 2 3.659477519977372
Current ori: tensor([-0.0177,  0.0213, -0.1035], device='cuda:1')
Index force: tensor([0.5778, 0.5872, 0.5807], device='cuda:1')
tensor([ 0.1339,  0.5467,  0.6008,  0.6797, -0.2283,  0.5809,  0.8759,  0.7358,
         1.2543,  0.2447,  0.1419,  1.0668, -0.0209,  0.0120, -0.1035,  1.0248],
       device='cuda:1')
Solve time for step 3 3.528709553007502
Current ori: tensor([-0.0209,  0.0120, -0.1035], device='cuda:1')
Index force: tensor([0.5621, 0.5690], device='cuda:1')
tensor([ 0.1257,  0.5332,  0.6080,  0.6855, -0.2315,  0.5842,  0.8701,  0.7280,
         1.2610,  0.2500,  0.1421,  1.0618, -0.0174,  0.0174, -0.1035,  1.0179],
       device='cuda:1')
Solve time for step 4 3.464109328982886
Current ori: tensor([-0.0174,  0.0174, -0.1035], device='cuda:1')
Index force: tensor([0.5575], device='cuda:1')
Storing RECOVERY transition: reward=0.0089 (scaled=0.0089), steps=1
Reward stats updated: mean 0.0070 -> 0.0071, std: 0.0659
Collected 93 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3204, Q2 Loss=0.3204, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0185
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2157, Q2 Loss=0.2157, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0378
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.3061, Q2 Loss=0.3061, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0757
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.3433, Q2 Loss=0.3433, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0295
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.2036, Q2 Loss=0.2036, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0039

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.4%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.04s (17.6%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 0.277802
Q2 loss: 0.277802
Current threshold: -149.8911
Global Scale Offset: 1.6508
Reward stats: mean=0.0071, std=0.0659, count=93
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 0.2778, Q2 Loss: 0.2778, Entropy: 0.0000, Mean TD Error: 0.0331, Threshold: -149.8911
Original likelihood: -140.57162475585938
Adjusted likelihood: -140.57162475585938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Current yaw: tensor([-0.0196,  0.0225, -0.1052], device='cuda:1')
6 turn
Sampling time 3.7888663850026205
tensor([ 0.1081,  0.5376,  0.5849,  0.6853, -0.1732,  0.6258,  0.8937,  0.7399,
         1.3283,  0.2934,  0.1773,  1.1174, -0.0196,  0.0225, -0.1052,  1.0442],
       device='cuda:1')
Original likelihood: -139.5853271484375
Adjusted likelihood: -139.5853271484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.30925233301241
Current ori: tensor([-0.0196,  0.0225, -0.1052], device='cuda:1')
Middle force: tensor([0.5211, 0.5470, 1.4093, 0.5813, 0.5683, 0.5716, 0.5063, 0.5772, 0.5619,
        2.0090, 0.8036, 0.5973], device='cuda:1')
Thumb force: tensor([0.6726, 0.8310, 1.8824, 0.7784, 1.0613, 0.5790, 0.6587, 0.7365, 2.0197,
        0.5489, 0.5769, 0.5870], device='cuda:1')
Index force: tensor([0.5737, 0.7938, 0.5561, 0.5515, 0.6055, 0.5759, 0.6770, 0.8809, 0.6259,
        0.6398, 0.5230, 0.6207], device='cuda:1')
Storing NORMAL transition: reward=-0.0971 (scaled=-0.0971), steps=1
Reward stats updated: mean 0.0071 -> 0.0060, std: 0.0664
Collected 94 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2481, Q2 Loss=0.2481, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0421
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2968, Q2 Loss=0.2968, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0595
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.3231, Q2 Loss=0.3231, Entropy=0.0420, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0255
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.2336, Q2 Loss=0.2336, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0461
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.2236, Q2 Loss=0.2236, Entropy=0.0003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0795

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.4%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.06s (20.2%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000030
Q1 loss: 0.265053
Q2 loss: 0.265053
Current threshold: -149.8933
Global Scale Offset: 1.6698
Reward stats: mean=0.0060, std=0.0664, count=94
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.2651, Q2 Loss: 0.2651, Entropy: 0.0085, Mean TD Error: 0.0506, Threshold: -149.8933
tensor([ 0.0816,  0.5255,  0.5732,  0.6905, -0.1828,  0.6644,  0.8342,  0.7208,
         1.3429,  0.2618,  0.1652,  1.1708, -0.0185,  0.0336, -0.0085,  0.9946],
       device='cuda:1')
Original likelihood: -156.34423828125
Adjusted likelihood: -156.34423828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0074)
State is out of distribution
Projection step: 0, Loss: 153.09225463867188
Projection step: 1, Loss: 151.5863494873047
Projection step: 2, Loss: 143.84095764160156
Projection step: 3, Loss: 138.45217895507812
Projection step: 4, Loss: 144.52288818359375
Projection step: 5, Loss: 137.31005859375
Projection step: 6, Loss: 135.83041381835938
Projection step: 7, Loss: 135.61639404296875
Projection step: 8, Loss: 129.32315063476562
Projection step: 9, Loss: 127.12982177734375
Projection step: 10, Loss: 123.1053695678711
Projection step: 11, Loss: 120.51753997802734
Projection step: 12, Loss: 121.74224853515625
Projection step: 13, Loss: 118.30271911621094
Projection step: 14, Loss: 115.35040283203125
Projection step: 15, Loss: 115.20865631103516
Projection step: 16, Loss: 109.955078125
Projection step: 17, Loss: 114.07073211669922
Projection step: 18, Loss: 109.06913757324219
Projection step: 19, Loss: 105.62049865722656
Projection step: 20, Loss: 103.2490005493164
Final likelihood: tensor([ -86.9541, -101.5022,  -96.7290, -108.8935, -103.5985,  -92.7505,
        -102.7443, -132.7558, -109.9766, -108.1735, -112.7267, -103.1771,
        -103.1395, -111.6388,  -86.9294,  -90.2945])
Final projection likelihood: -103.2490
1 mode projection succeeded
New goal: tensor([ 0.0808,  0.5410,  0.5705,  0.6531, -0.0951,  0.6129,  0.8202,  0.7571,
         1.3265,  0.2550,  0.1808,  1.1737, -0.0195,  0.0235,  0.3135],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -112.36148071289062
Adjusted likelihood: -112.36148071289062
Likelihood residual: 0.0
Original likelihood: -133.3115234375
Adjusted likelihood: -133.3115234375
Likelihood residual: 0.0
{'index': 133.3115234375, 'thumb_middle': 112.36148071289062}
Current yaw: tensor([-0.0185,  0.0336, -0.0085], device='cuda:1')
7 thumb_middle
tensor([ 0.0816,  0.5255,  0.5732,  0.6905, -0.1828,  0.6644,  0.8342,  0.7208,
         1.3429,  0.2618,  0.1652,  1.1708, -0.0185,  0.0336, -0.0085,  0.9946],
       device='cuda:1')
Solve time for step 1 8.792144477949478
Current ori: tensor([-0.0185,  0.0336, -0.0085], device='cuda:1')
Index force: tensor([0.5921, 0.5558, 0.5987, 0.6077], device='cuda:1')
tensor([ 0.0836,  0.5451,  0.5664,  0.6546, -0.2089,  0.5979,  0.7893,  0.7276,
         1.2860,  0.2334,  0.1030,  1.1421, -0.0257,  0.0327, -0.0085,  0.9650],
       device='cuda:1')
Solve time for step 2 3.513446255994495
Current ori: tensor([-0.0257,  0.0327, -0.0085], device='cuda:1')
Index force: tensor([0.5497, 0.5931, 0.6030], device='cuda:1')
tensor([ 0.0784,  0.5519,  0.5595,  0.6398, -0.2113,  0.5986,  0.7847,  0.7330,
         1.2905,  0.2323,  0.0992,  1.1404, -0.0284,  0.0358, -0.0085,  0.9521],
       device='cuda:1')
Solve time for step 3 3.387520588992629
Current ori: tensor([-0.0284,  0.0358, -0.0085], device='cuda:1')
Index force: tensor([0.5883, 0.5996], device='cuda:1')
tensor([ 0.0779,  0.5536,  0.5584,  0.6365, -0.2117,  0.5988,  0.7851,  0.7315,
         1.2926,  0.2312,  0.0961,  1.1422, -0.0290,  0.0360, -0.0085,  0.9500],
       device='cuda:1')
Solve time for step 4 3.41425559198251
Current ori: tensor([-0.0290,  0.0360, -0.0085], device='cuda:1')
Index force: tensor([0.5856], device='cuda:1')
Storing RECOVERY transition: reward=0.0084 (scaled=0.0084), steps=1
Reward stats updated: mean 0.0060 -> 0.0060, std: 0.0660
Collected 95 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2960, Q2 Loss=0.2960, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0243
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2699, Q2 Loss=0.2699, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1873
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.2280, Q2 Loss=0.2280, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0402
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.2112, Q2 Loss=0.2112, Entropy=0.0231, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0415
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.2351, Q2 Loss=0.2351, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1104

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.8%)
Actor update: 0.12s (41.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000006
Q1 loss: 0.248029
Q2 loss: 0.248029
Current threshold: -149.8944
Global Scale Offset: 1.6858
Reward stats: mean=0.0060, std=0.0660, count=95
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.2480, Q2 Loss: 0.2480, Entropy: 0.0046, Mean TD Error: 0.0807, Threshold: -149.8944
Original likelihood: -132.0054168701172
Adjusted likelihood: -132.0054168701172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0246,  0.0289, -0.0169], device='cuda:1')
8 turn
Sampling time 3.576586469018366
tensor([ 0.0842,  0.5411,  0.5704,  0.6589, -0.1496,  0.6303,  0.8174,  0.7525,
         1.3532,  0.2569,  0.1455,  1.1663, -0.0246,  0.0289, -0.0169,  1.0104],
       device='cuda:1')
Original likelihood: -123.17379760742188
Adjusted likelihood: -123.17379760742188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.1219358209637
Current ori: tensor([-0.0246,  0.0289, -0.0169], device='cuda:1')
Middle force: tensor([0.5638, 1.7049, 2.0736, 0.5585, 0.7571, 0.5551, 0.5385, 0.5855, 0.5414,
        0.5862, 0.5919, 0.6040], device='cuda:1')
Thumb force: tensor([0.9647, 1.5692, 0.7206, 0.6024, 0.5393, 1.1810, 0.5413, 1.0403, 0.5917,
        0.6344, 0.5836, 0.6058], device='cuda:1')
Index force: tensor([0.5655, 0.8172, 0.6002, 0.6222, 0.5112, 0.9414, 0.5812, 0.6047, 0.6615,
        0.6038, 0.5585, 0.5958], device='cuda:1')
Storing NORMAL transition: reward=-0.0012 (scaled=-0.0012), steps=1
Reward stats updated: mean 0.0060 -> 0.0059, std: 0.0657
Collected 96 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2531, Q2 Loss=0.2531, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0516
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2970, Q2 Loss=0.2970, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0755
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.2779, Q2 Loss=0.2779, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0237
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.2533, Q2 Loss=0.2533, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1915
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.2503, Q2 Loss=0.2503, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0787

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.06s (21.0%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000000
Q1 loss: 0.266296
Q2 loss: 0.266296
Current threshold: -149.8951
Global Scale Offset: 1.6969
Reward stats: mean=0.0059, std=0.0657, count=96
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.2663, Q2 Loss: 0.2663, Entropy: 0.0000, Mean TD Error: 0.0842, Threshold: -149.8951
tensor([ 0.0524,  0.5542,  0.4847,  0.7351, -0.1904,  0.5647,  0.8497,  0.7095,
         1.3298,  0.2397,  0.2174,  1.0891, -0.0196,  0.0488, -0.0170,  0.9655],
       device='cuda:1')
Original likelihood: -172.52227783203125
Adjusted likelihood: -172.52227783203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 176.59799194335938
Projection step: 1, Loss: 163.95474243164062
Projection step: 2, Loss: 153.69973754882812
Projection step: 3, Loss: 156.96119689941406
Projection step: 4, Loss: 164.8379669189453
Projection step: 5, Loss: 164.9588165283203
Projection step: 6, Loss: 169.58627319335938
Projection step: 7, Loss: 158.67626953125
Projection step: 8, Loss: 151.59213256835938
Projection step: 9, Loss: 149.16793823242188
Projection step: 10, Loss: 150.14175415039062
Projection step: 11, Loss: 157.50274658203125
Projection step: 12, Loss: 156.69503784179688
Projection step: 13, Loss: 151.6737060546875
Projection step: 14, Loss: 151.98245239257812
Projection step: 15, Loss: 151.17312622070312
Projection step: 16, Loss: 145.9900360107422
Projection step: 17, Loss: 141.7459259033203
Projection step: 18, Loss: 133.27980041503906
Projection step: 19, Loss: 129.88568115234375
Projection step: 20, Loss: 133.2626953125
Projection step: 21, Loss: 126.30122375488281
Projection step: 22, Loss: 122.5142593383789
Projection step: 23, Loss: 116.51936340332031
Projection step: 24, Loss: 114.55976104736328
Final likelihood: tensor([-104.9173, -107.6217, -107.4925, -110.6500, -111.8869, -106.6066,
        -112.7146, -109.7897, -109.9773, -114.4635, -113.2102, -113.2323,
        -111.5189, -107.8828, -106.0296, -108.0586])
Final projection likelihood: -109.7533
1 mode projection succeeded
New goal: tensor([ 0.0647,  0.5521,  0.4373,  0.8826, -0.0934,  0.5680,  0.8291,  0.7680,
         1.3478,  0.1973,  0.1302,  1.1757, -0.0298,  0.0260, -0.2121],
       device='cuda:1')
tensor([[0.0053]], device='cuda:1') tensor([[0.0062]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -126.12272644042969
Adjusted likelihood: -126.12272644042969
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 126.12272644042969}
Current yaw: tensor([-0.0196,  0.0488, -0.0170], device='cuda:1')
9 thumb_middle
tensor([ 0.0524,  0.5542,  0.4847,  0.7351, -0.1904,  0.5647,  0.8497,  0.7095,
         1.3298,  0.2397,  0.2174,  1.0891, -0.0196,  0.0488, -0.0170,  0.9655],
       device='cuda:1')
Solve time for step 1 9.073903187003452
Current ori: tensor([-0.0196,  0.0488, -0.0170], device='cuda:1')
Index force: tensor([0.5632, 0.5965, 0.5795, 0.5980], device='cuda:1')
tensor([ 0.0731,  0.5614,  0.4377,  0.8444, -0.1984,  0.5432,  0.7986,  0.7295,
         1.3190,  0.1828,  0.0925,  1.1515, -0.0114,  0.0378, -0.0170,  1.0027],
       device='cuda:1')
Solve time for step 2 3.5870771069894545
Current ori: tensor([-0.0114,  0.0378, -0.0170], device='cuda:1')
Index force: tensor([0.5733, 0.5878, 0.5894], device='cuda:1')
tensor([ 0.0856,  0.5675,  0.4281,  0.8702, -0.1869,  0.5423,  0.7926,  0.7350,
         1.3277,  0.1726,  0.0671,  1.1531, -0.0102,  0.0305, -0.0170,  1.0344],
       device='cuda:1')
Solve time for step 3 3.5333561609731987
Current ori: tensor([-0.0102,  0.0305, -0.0170], device='cuda:1')
Index force: tensor([0.5689, 0.5719], device='cuda:1')
tensor([ 0.0959,  0.5720,  0.4299,  0.8746, -0.1870,  0.5503,  0.7986,  0.7444,
         1.3248,  0.1753,  0.0591,  1.1485, -0.0108,  0.0244, -0.0170,  1.0485],
       device='cuda:1')
Solve time for step 4 3.2584378109895624
Current ori: tensor([-0.0108,  0.0244, -0.0170], device='cuda:1')
Index force: tensor([0.5553], device='cuda:1')
Storing RECOVERY transition: reward=0.0005 (scaled=0.0005), steps=1
Reward stats updated: mean 0.0059 -> 0.0058, std: 0.0653
Collected 97 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2279, Q2 Loss=0.2279, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0120
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3144, Q2 Loss=0.3144, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1724
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.2582, Q2 Loss=0.2582, Entropy=0.0005, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0765
SAC Update 4/5: Actor Loss=-0.0042, Q1 Loss=0.2254, Q2 Loss=0.2254, Entropy=0.3215, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0606
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.2015, Q2 Loss=0.2015, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0143

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (42.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000840
Q1 loss: 0.245476
Q2 loss: 0.245476
Current threshold: -149.9014
Global Scale Offset: 1.7166
Reward stats: mean=0.0058, std=0.0653, count=97
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.2455, Q2 Loss: 0.2455, Entropy: 0.0644, Mean TD Error: 0.0672, Threshold: -149.9014
Original likelihood: -181.71221923828125
Adjusted likelihood: -181.71221923828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 189.72311401367188
Projection step: 1, Loss: 177.30999755859375
Projection step: 2, Loss: 174.89918518066406
Projection step: 3, Loss: 170.3168487548828
Projection step: 4, Loss: 158.7662353515625
Projection step: 5, Loss: 152.4156494140625
Projection step: 6, Loss: 143.98422241210938
Projection step: 7, Loss: 139.7190704345703
Projection step: 8, Loss: 133.11578369140625
Projection step: 9, Loss: 126.1530990600586
Projection step: 10, Loss: 120.53194427490234
Projection step: 11, Loss: 114.5442123413086
Projection step: 12, Loss: 108.58709716796875
Projection step: 13, Loss: 99.10202026367188
Final likelihood: tensor([-108.6412,  -99.0477, -103.3646,  -95.3956,  -92.2460, -100.2225,
         -99.8525,  -92.3833, -100.3365,  -98.2591,  -96.9803,  -94.9910,
        -100.9194, -100.8584, -104.4503,  -97.6840])
Final projection likelihood: -99.1020
1 mode projection succeeded
New goal: tensor([ 0.0833,  0.5554,  0.4114,  0.9338, -0.0906,  0.5849,  0.8151,  0.7822,
         1.3612,  0.2102,  0.1214,  1.2075, -0.0090,  0.0197, -0.7745],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -139.57212829589844
Adjusted likelihood: -139.57212829589844
Likelihood residual: 0.0
Original likelihood: -124.3298568725586
Adjusted likelihood: -124.3298568725586
Likelihood residual: 0.0
{'index': 124.3298568725586, 'thumb_middle': 139.57212829589844}
Current yaw: tensor([-0.0082,  0.0370, -0.0162], device='cuda:1')
10 index
tensor([ 0.0738,  0.5615,  0.4247,  0.8716, -0.1406,  0.5860,  0.8293,  0.7642,
         1.4015,  0.2072,  0.1195,  1.1794, -0.0082,  0.0370, -0.0162,  1.0153],
       device='cuda:1')
Solve time for step 1 10.640720441006124
Current ori: tensor([-0.0082,  0.0370, -0.0162], device='cuda:1')
Middle force: tensor([0.5524, 0.5484, 0.5144, 0.5636], device='cuda:1')
Thumb force: tensor([0.5000, 0.5997, 0.6526, 0.5591], device='cuda:1')
tensor([ 0.1266,  0.5047,  0.3666,  0.8946, -0.1339,  0.5913,  0.8315,  0.7948,
         1.3954,  0.2196,  0.0965,  1.1929, -0.0093,  0.0263, -0.0436,  0.5133],
       device='cuda:1')
Solve time for step 2 4.210868794994894
Current ori: tensor([-0.0093,  0.0263, -0.0436], device='cuda:1')
Middle force: tensor([0.5392, 0.5389, 0.5485], device='cuda:1')
Thumb force: tensor([0.5904, 0.5666, 0.6050], device='cuda:1')
tensor([ 0.1295,  0.5052,  0.3633,  0.9012, -0.1323,  0.5954,  0.8318,  0.7941,
         1.3967,  0.2231,  0.0848,  1.1986, -0.0130,  0.0240, -0.0607,  0.2274],
       device='cuda:1')
Solve time for step 3 3.9619585319887847
Current ori: tensor([-0.0130,  0.0240, -0.0607], device='cuda:1')
Middle force: tensor([0.5355, 0.5449], device='cuda:1')
Thumb force: tensor([0.5630, 0.6011], device='cuda:1')
tensor([ 0.1303,  0.5042,  0.3628,  0.9024, -0.1353,  0.6031,  0.8251,  0.7892,
         1.3992,  0.2183,  0.0835,  1.2016, -0.0137,  0.0251, -0.0475,  0.1149],
       device='cuda:1')
Solve time for step 4 3.966648043016903
Current ori: tensor([-0.0137,  0.0251, -0.0475], device='cuda:1')
Middle force: tensor([0.5908], device='cuda:1')
Thumb force: tensor([0.5306], device='cuda:1')
Storing RECOVERY transition: reward=0.0230 (scaled=0.0230), steps=1
Reward stats updated: mean 0.0058 -> 0.0060, std: 0.0650
Collected 98 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.2402, Q2 Loss=0.2402, Entropy=0.0004, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0854
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.2222, Q2 Loss=0.2222, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0285
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.1500, Q2 Loss=0.1500, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0261
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.2253, Q2 Loss=0.2253, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0802
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.1496, Q2 Loss=0.1496, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0476

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (37.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 0.197449
Q2 loss: 0.197449
Current threshold: -149.9120
Global Scale Offset: 1.7439
Reward stats: mean=0.0060, std=0.0650, count=98
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.1974, Q2 Loss: 0.1974, Entropy: 0.0001, Mean TD Error: 0.0535, Threshold: -149.9120
Original likelihood: -175.00006103515625
Adjusted likelihood: -175.00006103515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 165.540283203125
Projection step: 1, Loss: 156.3255615234375
Projection step: 2, Loss: 154.88479614257812
Projection step: 3, Loss: 142.46505737304688
Projection step: 4, Loss: 135.36801147460938
Projection step: 5, Loss: 130.08811950683594
Projection step: 6, Loss: 124.74966430664062
Projection step: 7, Loss: 119.9413833618164
Projection step: 8, Loss: 114.65036010742188
Projection step: 9, Loss: 108.90589904785156
Projection step: 10, Loss: 104.59793090820312
Final likelihood: tensor([-104.6032, -101.7674, -100.9327, -110.6387, -101.6047,  -99.0453,
        -102.6177, -100.3838,  -97.2781, -101.4368, -127.3970, -100.9982,
        -102.7291, -106.9517, -113.0525, -102.1301])
Final projection likelihood: -104.5979
1 mode projection succeeded
New goal: tensor([ 0.0857,  0.5481,  0.4127,  0.9560, -0.0960,  0.5990,  0.8091,  0.7890,
         1.3615,  0.2126,  0.1111,  1.2145, -0.0150,  0.0189, -0.5502],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -108.28164672851562
Adjusted likelihood: -108.28164672851562
Likelihood residual: 0.0
Original likelihood: -104.99057006835938
Adjusted likelihood: -104.99057006835938
Likelihood residual: 0.0
{'index': 104.99057006835938, 'thumb_middle': 108.28164672851562}
Current yaw: tensor([-0.0132,  0.0303, -0.0384], device='cuda:1')
11 index
tensor([ 0.0783,  0.5577,  0.4041,  0.9295, -0.1427,  0.6030,  0.8214,  0.7866,
         1.4018,  0.2179,  0.0913,  1.1972, -0.0132,  0.0303, -0.0384,  0.0993],
       device='cuda:1')
Solve time for step 1 10.24017476500012
Current ori: tensor([-0.0132,  0.0303, -0.0384], device='cuda:1')
Middle force: tensor([0.5578, 0.5943, 0.5492, 0.5260], device='cuda:1')
Thumb force: tensor([0.5898, 0.5334, 0.6053, 0.6357], device='cuda:1')
tensor([ 0.1334,  0.4963,  0.3656,  0.9243, -0.1321,  0.6112,  0.8146,  0.7946,
         1.4001,  0.2315,  0.0726,  1.1962, -0.0181,  0.0228, -0.0680,  0.3408],
       device='cuda:1')
Solve time for step 2 4.048763046041131
Current ori: tensor([-0.0181,  0.0228, -0.0680], device='cuda:1')
Middle force: tensor([0.5887, 0.5459, 0.5232], device='cuda:1')
Thumb force: tensor([0.5308, 0.6017, 0.6327], device='cuda:1')
tensor([ 0.1322,  0.4970,  0.3616,  0.9233, -0.1315,  0.6113,  0.8207,  0.7941,
         1.4024,  0.2249,  0.0664,  1.2025, -0.0174,  0.0209, -0.0684,  0.5655],
       device='cuda:1')
Solve time for step 3 4.03881655895384
Current ori: tensor([-0.0174,  0.0209, -0.0684], device='cuda:1')
Middle force: tensor([0.5327, 0.5400], device='cuda:1')
Thumb force: tensor([0.5645, 0.5318], device='cuda:1')
tensor([ 0.1299,  0.4957,  0.3616,  0.9206, -0.1311,  0.6138,  0.8196,  0.7923,
         1.4032,  0.2224,  0.0637,  1.2055, -0.0177,  0.0202, -0.0644,  0.7669],
       device='cuda:1')
Solve time for step 4 3.7647324680001475
Current ori: tensor([-0.0177,  0.0202, -0.0644], device='cuda:1')
Middle force: tensor([0.5201], device='cuda:1')
Thumb force: tensor([0.5480], device='cuda:1')
Storing RECOVERY transition: reward=0.0440 (scaled=0.0440), steps=1
Reward stats updated: mean 0.0060 -> 0.0064, std: 0.0648
Collected 99 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.2082, Q2 Loss=0.2082, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0893
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.1675, Q2 Loss=0.1675, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0443
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.1316, Q2 Loss=0.1316, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0475
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.1836, Q2 Loss=0.1836, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0695
SAC Update 5/5: Actor Loss=-0.0022, Q1 Loss=0.1406, Q2 Loss=0.1406, Entropy=0.3359, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0617

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.6%)
Actor update: 0.11s (40.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000446
Q1 loss: 0.166290
Q2 loss: 0.166290
Current threshold: -149.9168
Global Scale Offset: 1.7629
Reward stats: mean=0.0064, std=0.0648, count=99
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.1663, Q2 Loss: 0.1663, Entropy: 0.0672, Mean TD Error: 0.0624, Threshold: -149.9168
Original likelihood: -147.4241943359375
Adjusted likelihood: -147.4241943359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8173)
Current yaw: tensor([-0.0176,  0.0251, -0.0593], device='cuda:1')
12 turn
Sampling time 3.820158600981813
tensor([ 0.0786,  0.5506,  0.4032,  0.9501, -0.1391,  0.6143,  0.8157,  0.7922,
         1.4010,  0.2307,  0.0752,  1.1971, -0.0176,  0.0251, -0.0593,  0.8033],
       device='cuda:1')
Original likelihood: -146.94290161132812
Adjusted likelihood: -146.94290161132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8599)
Solve time for step 1 13.928987706021871
Current ori: tensor([-0.0176,  0.0251, -0.0593], device='cuda:1')
Middle force: tensor([0.5147, 0.9125, 0.4489, 0.8410, 0.4974, 0.4996, 0.5397, 1.2294, 0.5591,
        0.5468, 0.5626, 1.2955], device='cuda:1')
Thumb force: tensor([0.7083, 1.3767, 0.8561, 0.5416, 0.5690, 0.5654, 0.5988, 1.1111, 0.8881,
        0.5599, 0.5733, 0.9773], device='cuda:1')
Index force: tensor([0.6071, 0.5934, 0.7550, 0.6960, 0.6098, 0.6454, 0.5911, 0.5689, 0.5908,
        0.5861, 0.5435, 0.5022], device='cuda:1')
Storing NORMAL transition: reward=0.1798 (scaled=0.1798), steps=1
Reward stats updated: mean 0.0064 -> 0.0081, std: 0.0668
Collected 100 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3416, Q2 Loss=0.3416, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2642
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=3.5110, Q2 Loss=3.5110, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9319
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.9896, Q2 Loss=2.9896, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1480
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5934, Q2 Loss=1.5934, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2854
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.3513, Q2 Loss=0.3513, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5922

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (18.2%)
Q2 update: 0.05s (18.4%)
Actor update: 0.12s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.757394
Q2 loss: 1.757394
Current threshold: -149.9148
Global Scale Offset: 1.7819
Reward stats: mean=0.0081, std=0.0668, count=100
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.7574, Q2 Loss: 1.7574, Entropy: 0.0000, Mean TD Error: 0.8443, Threshold: -149.9148
tensor([ 0.0478,  0.5509,  0.3943,  0.9080, -0.1702,  0.5401,  0.8433,  0.9619,
         1.3855,  0.5303,  0.1236,  1.0066, -0.0216,  0.0435, -0.2417,  0.9367],
       device='cuda:1')
Original likelihood: -228.55015563964844
Adjusted likelihood: -228.55015563964844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 244.03343200683594
Projection step: 1, Loss: 226.39288330078125
Projection step: 2, Loss: 219.05108642578125
Projection step: 3, Loss: 216.23936462402344
Projection step: 4, Loss: 201.88568115234375
Projection step: 5, Loss: 190.41973876953125
Projection step: 6, Loss: 179.63259887695312
Projection step: 7, Loss: 171.7041778564453
Projection step: 8, Loss: 160.64825439453125
Projection step: 9, Loss: 154.2398223876953
Projection step: 10, Loss: 143.23411560058594
Projection step: 11, Loss: 138.36288452148438
Projection step: 12, Loss: 129.96910095214844
Projection step: 13, Loss: 119.89861297607422
Projection step: 14, Loss: 115.31355285644531
Projection step: 15, Loss: 108.87918853759766
Projection step: 16, Loss: 103.51043701171875
Final likelihood: tensor([-103.7338, -110.6495,  -99.6031, -109.2294,  -96.6731, -107.4877,
        -116.6871, -113.9164,  -96.6205,  -96.1795, -104.8778,  -96.9277,
        -103.2982,  -95.5122, -101.2165, -103.5547])
Final projection likelihood: -103.5104
1 mode projection succeeded
New goal: tensor([ 0.0698,  0.5390,  0.3984,  0.9882, -0.0777,  0.5272,  0.7884,  0.8918,
         1.3656,  0.3697,  0.0909,  1.1433, -0.0299,  0.0248, -1.1530],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -122.6412353515625
Adjusted likelihood: -122.6412353515625
Likelihood residual: 0.0
Original likelihood: -126.44458770751953
Adjusted likelihood: -126.44458770751953
Likelihood residual: 0.0
{'index': 126.44458770751953, 'thumb_middle': 122.6412353515625}
Current yaw: tensor([-0.0216,  0.0435, -0.2417], device='cuda:1')
13 thumb_middle
tensor([ 0.0478,  0.5509,  0.3943,  0.9080, -0.1702,  0.5401,  0.8433,  0.9619,
         1.3855,  0.5303,  0.1236,  1.0066, -0.0216,  0.0435, -0.2417,  0.9367],
       device='cuda:1')
Solve time for step 1 8.856629738002084
Current ori: tensor([-0.0216,  0.0435, -0.2417], device='cuda:1')
Index force: tensor([0.5365, 0.6276, 0.5000, 0.5697], device='cuda:1')
tensor([ 0.0431,  0.5532,  0.3709,  0.9382, -0.1999,  0.5033,  0.7559,  0.8627,
         1.3308,  0.3991,  0.0402,  1.1034, -0.0188,  0.0461, -0.2416,  0.9348],
       device='cuda:1')
Solve time for step 2 3.623161889030598
Current ori: tensor([-0.0188,  0.0461, -0.2416], device='cuda:1')
Index force: tensor([0.6045, 0.5928, 0.5001], device='cuda:1')
tensor([ 0.0644,  0.5397,  0.3855,  0.9903, -0.1932,  0.5156,  0.7622,  0.8638,
         1.3306,  0.3637,  0.0299,  1.1028, -0.0104,  0.0333, -0.2417,  0.9821],
       device='cuda:1')
Solve time for step 3 3.4124867180362344
Current ori: tensor([-0.0104,  0.0333, -0.2417], device='cuda:1')
Index force: tensor([0.5000, 0.5450], device='cuda:1')
tensor([ 0.0648,  0.5372,  0.3974,  0.9734, -0.1870,  0.5143,  0.7452,  0.8624,
         1.3289,  0.3634,  0.0253,  1.1171, -0.0118,  0.0332, -0.2417,  0.9776],
       device='cuda:1')
Solve time for step 4 3.5559745309874415
Current ori: tensor([-0.0118,  0.0332, -0.2417], device='cuda:1')
Index force: tensor([0.5458], device='cuda:1')
Storing RECOVERY transition: reward=0.0007 (scaled=0.0007), steps=1
Reward stats updated: mean 0.0081 -> 0.0081, std: 0.0664
Collected 101 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=10.7095, Q2 Loss=10.7095, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8301
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=4.2006, Q2 Loss=4.2006, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8621
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.0950, Q2 Loss=2.0950, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6738
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=5.4751, Q2 Loss=5.4751, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0872
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=12.5355, Q2 Loss=12.5355, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0042

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.7%)
Actor update: 0.11s (39.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 7.003124
Q2 loss: 7.003124
Current threshold: -149.9136
Global Scale Offset: 1.7933
Reward stats: mean=0.0081, std=0.0664, count=101
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 7.0031, Q2 Loss: 7.0031, Entropy: 0.0000, Mean TD Error: 2.8915, Threshold: -149.9136
Original likelihood: -178.57980346679688
Adjusted likelihood: -178.57980346679688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 178.36492919921875
Projection step: 1, Loss: 173.98370361328125
Projection step: 2, Loss: 157.18284606933594
Projection step: 3, Loss: 146.47215270996094
Projection step: 4, Loss: 138.2025909423828
Projection step: 5, Loss: 133.14251708984375
Projection step: 6, Loss: 120.92002868652344
Projection step: 7, Loss: 111.45936584472656
Projection step: 8, Loss: 104.47586822509766
Final likelihood: tensor([-112.0899, -105.1737, -106.9616, -102.7446, -121.0129, -107.2510,
        -101.7765, -100.6410, -102.2373, -103.8970, -101.4231,  -98.2461,
        -104.2606, -103.2159, -102.2927,  -98.3901])
Final projection likelihood: -104.4759
1 mode projection succeeded
New goal: tensor([ 0.0689,  0.5276,  0.4092,  0.9998, -0.0820,  0.5562,  0.7725,  0.8600,
         1.3449,  0.3217,  0.0989,  1.1902, -0.0138,  0.0231, -0.6982],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -127.2531967163086
Adjusted likelihood: -127.2531967163086
Likelihood residual: 0.0
Original likelihood: -119.22743225097656
Adjusted likelihood: -119.22743225097656
Likelihood residual: 0.0
{'index': 119.22743225097656, 'thumb_middle': 127.2531967163086}
Current yaw: tensor([-0.0115,  0.0353, -0.2409], device='cuda:1')
14 index
tensor([ 0.0609,  0.5366,  0.3956,  0.9725, -0.1178,  0.5662,  0.7727,  0.8792,
         1.3709,  0.3816,  0.0870,  1.1632, -0.0115,  0.0353, -0.2409,  0.9748],
       device='cuda:1')
Solve time for step 1 10.609328494989313
Current ori: tensor([-0.0115,  0.0353, -0.2409], device='cuda:1')
Middle force: tensor([0.5164, 0.5322, 0.5565, 0.5701], device='cuda:1')
Thumb force: tensor([0.5666, 0.5001, 0.5029, 0.6036], device='cuda:1')
tensor([ 0.1096,  0.4723,  0.3559,  0.9618, -0.1155,  0.5588,  0.7884,  0.8809,
         1.3861,  0.3540,  0.0676,  1.1769, -0.0089,  0.0325, -0.2499,  1.2496],
       device='cuda:1')
Solve time for step 2 4.121826771006454
Current ori: tensor([-0.0089,  0.0325, -0.2499], device='cuda:1')
Middle force: tensor([0.5288, 0.5533, 0.5649], device='cuda:1')
Thumb force: tensor([0.5001, 0.5024, 0.5993], device='cuda:1')
tensor([ 0.1120,  0.4724,  0.3559,  0.9639, -0.1166,  0.5613,  0.7866,  0.8786,
         1.3964,  0.3382,  0.0613,  1.1728, -0.0109,  0.0330, -0.2547,  1.3508],
       device='cuda:1')
Solve time for step 3 4.088134674006142
Current ori: tensor([-0.0109,  0.0330, -0.2547], device='cuda:1')
Middle force: tensor([0.5430, 0.5204], device='cuda:1')
Thumb force: tensor([0.6247, 0.6244], device='cuda:1')
tensor([ 0.1129,  0.4705,  0.3550,  0.9649, -0.1023,  0.5707,  0.7864,  0.8714,
         1.3908,  0.3423,  0.0489,  1.1784, -0.0143,  0.0240, -0.2597,  1.3456],
       device='cuda:1')
Solve time for step 4 3.9988202690146863
Current ori: tensor([-0.0143,  0.0240, -0.2597], device='cuda:1')
Middle force: tensor([0.6000], device='cuda:1')
Thumb force: tensor([0.5417], device='cuda:1')
Storing RECOVERY transition: reward=0.0087 (scaled=0.0087), steps=1
Reward stats updated: mean 0.0081 -> 0.0081, std: 0.0661
Collected 102 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.5147, Q2 Loss=1.5147, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5947
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9008, Q2 Loss=0.9008, Entropy=0.0001, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9140
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2016, Q2 Loss=1.2016, Entropy=0.0001, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7385
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.2278, Q2 Loss=0.2278, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1456
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.6456, Q2 Loss=1.6456, Entropy=0.0001, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9291

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (19.0%)
Actor update: 0.08s (40.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.098097
Q2 loss: 1.098097
Current threshold: -149.9129
Global Scale Offset: 1.8002
Reward stats: mean=0.0081, std=0.0661, count=102
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.0981, Q2 Loss: 1.0981, Entropy: 0.0000, Mean TD Error: 0.6644, Threshold: -149.9129
Original likelihood: -171.0045166015625
Adjusted likelihood: -171.0045166015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 163.8165283203125
Projection step: 1, Loss: 153.7705535888672
Projection step: 2, Loss: 147.81541442871094
Projection step: 3, Loss: 140.97406005859375
Projection step: 4, Loss: 131.51361083984375
Projection step: 5, Loss: 121.69110870361328
Projection step: 6, Loss: 116.34407043457031
Projection step: 7, Loss: 110.93670654296875
Projection step: 8, Loss: 102.42609405517578
Final likelihood: tensor([-105.4910, -101.0392, -107.7960, -100.3150,  -97.7253, -103.0555,
         -99.8350, -105.7991,  -97.3990,  -97.9776, -104.6525, -100.4558,
         -99.7995, -102.8576, -108.5224, -106.0971])
Final projection likelihood: -102.4261
1 mode projection succeeded
New goal: tensor([ 0.0713,  0.5263,  0.4087,  1.0092, -0.0828,  0.5621,  0.7749,  0.8513,
         1.3556,  0.3001,  0.0900,  1.1928, -0.0176,  0.0225, -0.7472],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -125.517822265625
Adjusted likelihood: -125.517822265625
Likelihood residual: 0.0
Original likelihood: -127.29129791259766
Adjusted likelihood: -127.29129791259766
Likelihood residual: 0.0
{'index': 127.29129791259766, 'thumb_middle': 125.517822265625}
Current yaw: tensor([-0.0154,  0.0331, -0.2489], device='cuda:1')
15 thumb_middle
tensor([ 0.0593,  0.5264,  0.3968,  0.9932, -0.1164,  0.5732,  0.7776,  0.8611,
         1.3977,  0.3376,  0.0615,  1.1651, -0.0154,  0.0331, -0.2489,  1.3131],
       device='cuda:1')
Solve time for step 1 8.9844557819888
Current ori: tensor([-0.0154,  0.0331, -0.2489], device='cuda:1')
Index force: tensor([0.5568, 0.5797, 0.5702, 0.5763], device='cuda:1')
tensor([ 0.0571,  0.5256,  0.3911,  1.0023, -0.1901,  0.5285,  0.7474,  0.8292,
         1.3286,  0.2905,  0.0239,  1.1751, -0.0141,  0.0344, -0.2489,  1.3135],
       device='cuda:1')
Solve time for step 2 3.577899330004584
Current ori: tensor([-0.0141,  0.0344, -0.2489], device='cuda:1')
Index force: tensor([0.5674, 0.5602, 0.5653], device='cuda:1')
tensor([ 0.0762,  0.5348,  0.3973,  1.0009, -0.1873,  0.5613,  0.7446,  0.8293,
         1.3084,  0.2804,  0.0296,  1.1683, -0.0166,  0.0231, -0.2489,  1.3382],
       device='cuda:1')
Solve time for step 3 3.368711863993667
Current ori: tensor([-0.0166,  0.0231, -0.2489], device='cuda:1')
Index force: tensor([0.5472, 0.5527], device='cuda:1')
tensor([ 0.0815,  0.5223,  0.4126,  1.0172, -0.1830,  0.5647,  0.7451,  0.8275,
         1.3171,  0.2812,  0.0175,  1.1592, -0.0117,  0.0199, -0.2489,  1.3553],
       device='cuda:1')
Solve time for step 4 3.249554887006525
Current ori: tensor([-0.0117,  0.0199, -0.2489], device='cuda:1')
Index force: tensor([0.5391], device='cuda:1')
Storing RECOVERY transition: reward=0.0103 (scaled=0.0103), steps=1
Reward stats updated: mean 0.0081 -> 0.0081, std: 0.0658
Collected 103 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=2.5631, Q2 Loss=2.5631, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7108
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.9152, Q2 Loss=2.9152, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9035
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=13.3534, Q2 Loss=13.3534, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2254
SAC Update 4/5: Actor Loss=-0.0032, Q1 Loss=1.1161, Q2 Loss=1.1161, Entropy=0.2960, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6654
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.7369, Q2 Loss=1.7369, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1760

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.9%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000649
Q1 loss: 4.336943
Q2 loss: 4.336943
Current threshold: -149.9174
Global Scale Offset: 1.8215
Reward stats: mean=0.0081, std=0.0658, count=103
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 4.3369, Q2 Loss: 4.3369, Entropy: 0.0592, Mean TD Error: 1.7362, Threshold: -149.9174
Original likelihood: -171.4008026123047
Adjusted likelihood: -171.4008026123047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 164.4215087890625
Projection step: 1, Loss: 158.12965393066406
Projection step: 2, Loss: 149.0419921875
Projection step: 3, Loss: 139.56552124023438
Projection step: 4, Loss: 133.34783935546875
Projection step: 5, Loss: 127.43093872070312
Projection step: 6, Loss: 118.40228271484375
Projection step: 7, Loss: 111.70149993896484
Projection step: 8, Loss: 103.20997619628906
Final likelihood: tensor([-108.6178, -100.6151, -119.4115,  -95.1901, -104.4726,  -97.2493,
        -107.6095, -102.3479, -106.4834, -100.5149,  -99.4407, -103.2167,
        -100.3316, -104.5161, -102.3145,  -99.0279])
Final projection likelihood: -103.2100
1 mode projection succeeded
New goal: tensor([ 0.0743,  0.5202,  0.4155,  1.0216, -0.0886,  0.5865,  0.7725,  0.8373,
         1.3674,  0.2850,  0.0854,  1.1979, -0.0078,  0.0196, -0.6844],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -109.80933380126953
Adjusted likelihood: -109.80933380126953
Likelihood residual: 0.0
Original likelihood: -132.50909423828125
Adjusted likelihood: -132.50909423828125
Likelihood residual: 0.0
{'index': 132.50909423828125, 'thumb_middle': 109.80933380126953}
Current yaw: tensor([-0.0077,  0.0301, -0.2500], device='cuda:1')
16 thumb_middle
tensor([ 0.0634,  0.5095,  0.4101,  1.0252, -0.1251,  0.6005,  0.7764,  0.8296,
         1.4128,  0.3067,  0.0531,  1.1662, -0.0077,  0.0301, -0.2500,  1.3499],
       device='cuda:1')
Solve time for step 1 9.162432026001625
Current ori: tensor([-0.0077,  0.0301, -0.2500], device='cuda:1')
Index force: tensor([0.5911, 0.5339, 0.5778, 0.6012], device='cuda:1')
tensor([ 0.0593,  0.5084,  0.4100,  1.0190, -0.1977,  0.5655,  0.7356,  0.8124,
         1.3407,  0.2719,  0.0174,  1.1690, -0.0082,  0.0329, -0.2499,  1.3272],
       device='cuda:1')
Solve time for step 2 3.63182708597742
Current ori: tensor([-0.0082,  0.0329, -0.2499], device='cuda:1')
Index force: tensor([0.5312, 0.5732, 0.5972], device='cuda:1')
tensor([ 0.0738,  0.5184,  0.4117,  1.0156, -0.1963,  0.5788,  0.7408,  0.8143,
         1.3317,  0.2659,  0.0078,  1.1695, -0.0110,  0.0244, -0.2499,  1.3449],
       device='cuda:1')
Solve time for step 3 3.49280694097979
Current ori: tensor([-0.0110,  0.0244, -0.2499], device='cuda:1')
Index force: tensor([0.5636, 0.5888], device='cuda:1')
tensor([ 0.0781,  0.5179,  0.4122,  1.0247, -0.1875,  0.5753,  0.7402,  0.8122,
         1.3306,  0.2657,  0.0056,  1.1658, -0.0098,  0.0219, -0.2499,  1.3544],
       device='cuda:1')
Solve time for step 4 3.5701900830026716
Current ori: tensor([-0.0098,  0.0219, -0.2499], device='cuda:1')
Index force: tensor([0.5747], device='cuda:1')
Storing RECOVERY transition: reward=0.0089 (scaled=0.0089), steps=1
Reward stats updated: mean 0.0081 -> 0.0081, std: 0.0655
Collected 104 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.3468, Q2 Loss=0.3468, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6671
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.7410, Q2 Loss=2.7410, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8971
SAC Update 3/5: Actor Loss=-0.0033, Q1 Loss=0.7192, Q2 Loss=0.7192, Entropy=0.2968, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6824
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=3.4544, Q2 Loss=3.4544, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4982
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=4.6224, Q2 Loss=4.6224, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7137

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.2%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (20.0%)
Actor update: 0.10s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000659
Q1 loss: 2.376731
Q2 loss: 2.376731
Current threshold: -149.9328
Global Scale Offset: 1.8774
Reward stats: mean=0.0081, std=0.0655, count=104
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 2.3767, Q2 Loss: 2.3767, Entropy: 0.0594, Mean TD Error: 1.2917, Threshold: -149.9328
Original likelihood: -148.6553955078125
Adjusted likelihood: -148.6553955078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6711)
Current yaw: tensor([-0.0044,  0.0237, -0.2480], device='cuda:1')
17 turn
Sampling time 3.622024976008106
tensor([ 0.0739,  0.5041,  0.4207,  1.0403, -0.1247,  0.6180,  0.7716,  0.8333,
         1.3944,  0.2868,  0.0588,  1.2026, -0.0044,  0.0237, -0.2480,  1.3860],
       device='cuda:1')
Original likelihood: -151.07437133789062
Adjusted likelihood: -151.07437133789062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3461)
State is out of distribution
Projection step: 0, Loss: 151.56912231445312
Projection step: 1, Loss: 141.33660888671875
Projection step: 2, Loss: 134.5810546875
Projection step: 3, Loss: 122.96984100341797
Projection step: 4, Loss: 121.94648742675781
Projection step: 5, Loss: 112.80520629882812
Projection step: 6, Loss: 108.8655776977539
Projection step: 7, Loss: 101.85188293457031
Final likelihood: tensor([-103.0397,  -96.6119, -109.1167,  -91.5723, -106.9867, -100.0540,
        -103.7912,  -99.5457, -105.6252, -101.4114, -109.1185,  -94.0945,
         -96.3917, -108.1962,  -97.5728, -106.5016])
Final projection likelihood: -101.8519
1 mode projection succeeded
New goal: tensor([ 0.0792,  0.5174,  0.4225,  1.0246, -0.0898,  0.6009,  0.7736,  0.8348,
         1.3619,  0.2727,  0.0898,  1.2089, -0.0049,  0.0169, -0.5609],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -114.28289794921875
Adjusted likelihood: -114.28289794921875
Likelihood residual: 0.0
Original likelihood: -121.91704559326172
Adjusted likelihood: -121.91704559326172
Likelihood residual: 0.0
{'index': 121.91704559326172, 'thumb_middle': 114.28289794921875}
Current yaw: tensor([-0.0044,  0.0237, -0.2480], device='cuda:1')
18 thumb_middle
tensor([ 0.0739,  0.5041,  0.4207,  1.0403, -0.1247,  0.6180,  0.7716,  0.8333,
         1.3944,  0.2868,  0.0588,  1.2026, -0.0044,  0.0237, -0.2480,  1.3860],
       device='cuda:1')
Solve time for step 1 9.255812756018713
Current ori: tensor([-0.0044,  0.0237, -0.2480], device='cuda:1')
Index force: tensor([0.5696, 0.5835, 0.5674, 0.5609], device='cuda:1')
tensor([ 0.0716,  0.5030,  0.4231,  1.0326, -0.1969,  0.5812,  0.7391,  0.8005,
         1.3372,  0.2527,  0.0114,  1.1834, -0.0052,  0.0255, -0.2479,  1.3648],
       device='cuda:1')
Solve time for step 2 3.6678518740227446
Current ori: tensor([-0.0052,  0.0255, -0.2479], device='cuda:1')
Index force: tensor([0.5713, 0.5583, 0.5531], device='cuda:1')
tensor([ 0.0896,  0.5091,  0.4266,  1.0444, -0.1917,  0.5855,  0.7485,  0.8263,
         1.3239,  0.2543,  0.0023,  1.1838, -0.0051,  0.0149, -0.2479,  1.3925],
       device='cuda:1')
Solve time for step 3 3.5006058090366423
Current ori: tensor([-0.0051,  0.0149, -0.2479], device='cuda:1')
Index force: tensor([0.5432, 0.5404], device='cuda:1')
tensor([ 0.0866,  0.5069,  0.4282,  1.0414, -0.1791,  0.5886,  0.7315,  0.8055,
         1.3205,  0.2607,  0.0139,  1.1667, -0.0049,  0.0167, -0.2479,  1.3881],
       device='cuda:1')
Solve time for step 4 3.4199882629909553
Current ori: tensor([-0.0049,  0.0167, -0.2479], device='cuda:1')
Index force: tensor([0.5663], device='cuda:1')
Storing RECOVERY transition: reward=0.0136 (scaled=0.0136), steps=0
Reward stats updated: mean 0.0081 -> 0.0082, std: 0.0652
Collected 105 transitions for RL
SAC Update 1/5: Actor Loss=-0.0042, Q1 Loss=20.7875, Q2 Loss=20.7875, Entropy=0.3225, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6917
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.4554, Q2 Loss=1.4554, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8916
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.4506, Q2 Loss=2.4506, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2159
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=9.9456, Q2 Loss=9.9456, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1476
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=3.2096, Q2 Loss=3.2096, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5093

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.0%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (42.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000850
Q1 loss: 7.569756
Q2 loss: 7.569756
Current threshold: -149.9576
Global Scale Offset: 1.9517
Reward stats: mean=0.0082, std=0.0652, count=105
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 7.5698, Q2 Loss: 7.5698, Entropy: 0.0645, Mean TD Error: 1.8912, Threshold: -149.9576
Original likelihood: -135.35052490234375
Adjusted likelihood: -135.35052490234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0103,  0.0198, -0.2616], device='cuda:1')
19 turn
Sampling time 3.621031870949082
tensor([ 0.0806,  0.5240,  0.4036,  1.0292, -0.1245,  0.6283,  0.7702,  0.8363,
         1.3901,  0.2842,  0.0539,  1.2079, -0.0103,  0.0198, -0.2616,  1.4078],
       device='cuda:1')
Original likelihood: -136.37445068359375
Adjusted likelihood: -136.37445068359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.351963213994168
Current ori: tensor([-0.0103,  0.0198, -0.2616], device='cuda:1')
Middle force: tensor([0.7725, 0.7373, 0.5665, 1.5740, 0.5569, 0.4893, 0.7056, 0.4945, 0.6022,
        0.5660, 0.5341, 0.5995], device='cuda:1')
Thumb force: tensor([1.4696, 0.7451, 2.2232, 1.1702, 1.8788, 0.5274, 0.9112, 0.5700, 0.6087,
        0.5831, 0.5461, 0.5955], device='cuda:1')
Index force: tensor([0.9580, 0.8269, 0.5577, 0.9231, 0.6616, 0.7921, 0.5471, 0.7430, 0.6181,
        0.6866, 0.5868, 0.6090], device='cuda:1')
Storing NORMAL transition: reward=0.2403 (scaled=0.2403), steps=1
Reward stats updated: mean 0.0082 -> 0.0103, std: 0.0686
Collected 106 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.7336, Q2 Loss=0.7336, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8470
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4439, Q2 Loss=0.4439, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6416
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2242, Q2 Loss=1.2242, Entropy=0.0002, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8582
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.7383, Q2 Loss=2.7383, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4294
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=2.0086, Q2 Loss=2.0086, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1291

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.4%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 1.429733
Q2 loss: 1.429733
Current threshold: -149.9725
Global Scale Offset: 1.9976
Reward stats: mean=0.0103, std=0.0686, count=106
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 1.4297, Q2 Loss: 1.4297, Entropy: 0.0000, Mean TD Error: 0.9811, Threshold: -149.9725
tensor([ 0.0984,  0.4942,  0.5089,  0.9342, -0.1216,  0.5726,  0.8232,  0.9277,
         1.4113,  0.2847,  0.1105,  1.0238, -0.0161,  0.0159, -0.5023,  1.4559],
       device='cuda:1')
Original likelihood: -126.52395629882812
Adjusted likelihood: -126.52395629882812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.729662384022959
Current ori: tensor([-0.0161,  0.0159, -0.5023], device='cuda:1')
Middle force: tensor([0.7309, 0.5670, 1.5527, 0.5588, 0.5030, 0.7014, 0.5019, 0.5990, 0.5659,
        0.5327, 0.5963], device='cuda:1')
Thumb force: tensor([0.7337, 2.1780, 1.1535, 1.8405, 0.5235, 0.9042, 0.5759, 0.6081, 0.5765,
        0.5433, 0.5927], device='cuda:1')
Index force: tensor([0.8149, 0.5561, 0.9190, 0.6550, 0.8445, 0.5447, 0.7675, 0.6150, 0.6858,
        0.5879, 0.6064], device='cuda:1')
Storing NORMAL transition: reward=0.1198 (scaled=0.1198), steps=1
Reward stats updated: mean 0.0103 -> 0.0114, std: 0.0691
Collected 107 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.7128, Q2 Loss=1.7128, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7590
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=17.3745, Q2 Loss=17.3745, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2996
SAC Update 3/5: Actor Loss=-0.0017, Q1 Loss=11.0816, Q2 Loss=11.0816, Entropy=0.2188, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7383
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=3.5976, Q2 Loss=3.5976, Entropy=0.2198, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7781
SAC Update 5/5: Actor Loss=-0.0013, Q1 Loss=3.6998, Q2 Loss=3.6998, Entropy=0.2213, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8113

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (21.0%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (41.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000844
Q1 loss: 7.493227
Q2 loss: 7.493227
Current threshold: -149.9743
Global Scale Offset: 2.0696
Reward stats: mean=0.0114, std=0.0691, count=107
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 7.4932, Q2 Loss: 7.4932, Entropy: 0.1320, Mean TD Error: 2.4773, Threshold: -149.9743
tensor([ 0.1162,  0.4622,  0.5950,  0.8824, -0.1124,  0.5327,  0.8657,  0.9971,
         1.4571,  0.2081,  0.1092,  0.9522, -0.0136,  0.0057, -0.6219,  1.6128],
       device='cuda:1')
Original likelihood: -117.81757354736328
Adjusted likelihood: -117.81757354736328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 5.514639339002315
Current ori: tensor([-0.0136,  0.0057, -0.6219], device='cuda:1')
Middle force: tensor([0.5038, 0.8138, 0.5017, 0.5035, 0.5128, 1.1854, 0.5051, 0.5869, 0.5917,
        0.8831], device='cuda:1')
Thumb force: tensor([0.9070, 0.5290, 0.5562, 0.5556, 0.5817, 0.8913, 0.6094, 0.5488, 0.5399,
        0.8928], device='cuda:1')
Index force: tensor([0.7902, 0.6776, 0.6410, 0.6379, 0.5745, 0.5450, 0.5655, 0.5328, 0.5093,
        0.5400], device='cuda:1')
Storing NORMAL transition: reward=0.0939 (scaled=0.0939), steps=1
Reward stats updated: mean 0.0114 -> 0.0121, std: 0.0692
Collected 108 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3787, Q2 Loss=1.3787, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8772
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.0715, Q2 Loss=2.0715, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5462
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=2.7934, Q2 Loss=2.7934, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6003
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=2.1431, Q2 Loss=2.1431, Entropy=0.0033, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2371
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=17.4270, Q2 Loss=17.4270, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1635

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.2%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.7%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 5.162734
Q2 loss: 5.162734
Current threshold: -149.9675
Global Scale Offset: 2.1631
Reward stats: mean=0.0121, std=0.0692, count=108
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 5.1627, Q2 Loss: 5.1627, Entropy: 0.0007, Mean TD Error: 2.0849, Threshold: -149.9675
tensor([ 0.1835,  0.5659,  0.5008,  0.9290, -0.0715,  0.6463,  0.7490,  1.0738,
         1.4827,  0.1576,  0.1112,  0.7972, -0.0299, -0.0370, -0.7338,  1.7464],
       device='cuda:1')
Original likelihood: -130.36465454101562
Adjusted likelihood: -130.36465454101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 4 5.29952353000408
Current ori: tensor([-0.0299, -0.0370, -0.7338], device='cuda:1')
Middle force: tensor([1.5139, 0.5674, 0.5010, 0.6950, 0.5041, 0.5934, 0.5687, 0.5321, 0.5900],
       device='cuda:1')
Thumb force: tensor([1.1169, 1.7678, 0.5200, 0.8831, 0.5606, 0.6020, 0.5658, 0.5371, 0.5883],
       device='cuda:1')
Index force: tensor([0.8929, 0.6385, 0.9120, 0.5433, 0.7493, 0.6089, 0.6778, 0.5873, 0.6016],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0003 (scaled=-0.0003), steps=1
Reward stats updated: mean 0.0121 -> 0.0120, std: 0.0689
Collected 109 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8722, Q2 Loss=0.8722, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8140
SAC Update 2/5: Actor Loss=-0.0014, Q1 Loss=3.6508, Q2 Loss=3.6508, Entropy=0.2310, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8725
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.7893, Q2 Loss=1.7893, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0997
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.6552, Q2 Loss=1.6552, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8627
SAC Update 5/5: Actor Loss=-0.0014, Q1 Loss=3.2998, Q2 Loss=3.2998, Entropy=0.2348, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8162

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.8%)
Actor update: 0.10s (42.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000563
Q1 loss: 2.253443
Q2 loss: 2.253443
Current threshold: -149.9583
Global Scale Offset: 2.2538
Reward stats: mean=0.0120, std=0.0689, count=109
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 2.2534, Q2 Loss: 2.2534, Entropy: 0.0932, Mean TD Error: 1.4930, Threshold: -149.9583
tensor([ 0.1470,  0.4639,  0.5983,  0.9369, -0.1209,  0.5556,  0.9056,  1.0526,
         1.4437,  0.2538,  0.0498,  0.7361, -0.0052, -0.0174, -0.7172,  2.0085],
       device='cuda:1')
Original likelihood: -157.05755615234375
Adjusted likelihood: -157.05755615234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0159)
State is out of distribution
Projection step: 0, Loss: 155.27142333984375
Projection step: 1, Loss: 140.82095336914062
Projection step: 2, Loss: 144.77154541015625
Projection step: 3, Loss: 136.44662475585938
Projection step: 4, Loss: 130.52273559570312
Projection step: 5, Loss: 117.16419982910156
Projection step: 6, Loss: 123.78952026367188
Projection step: 7, Loss: 127.58650207519531
Projection step: 8, Loss: 124.96798706054688
Projection step: 9, Loss: 121.51630401611328
Projection step: 10, Loss: 121.00048828125
Projection step: 11, Loss: 119.57571411132812
Projection step: 12, Loss: 114.21238708496094
Projection step: 13, Loss: 113.0615463256836
Projection step: 14, Loss: 115.47842407226562
Projection step: 15, Loss: 113.69216918945312
Projection step: 16, Loss: 113.22393798828125
Projection step: 17, Loss: 117.93146514892578
Projection step: 18, Loss: 108.65935516357422
Projection step: 19, Loss: 114.90096282958984
Projection step: 20, Loss: 110.77554321289062
Projection step: 21, Loss: 110.52830505371094
Projection step: 22, Loss: 107.2144546508789
Projection step: 23, Loss: 112.25202941894531
Projection step: 24, Loss: 106.03050994873047
Final likelihood: tensor([-115.3967, -105.9326, -115.0731,  -88.5034, -107.8210, -107.9247,
         -92.2759, -104.9007,  -96.6685,  -96.9650, -104.1577, -105.1033,
        -104.7508, -116.6273, -116.1543, -104.7123])
Final projection likelihood: -105.1855
1 mode projection succeeded
New goal: tensor([ 0.1259,  0.4604,  0.5934,  0.8537, -0.0585,  0.5566,  0.9136,  0.9713,
         1.4096,  0.2896,  0.1378,  0.8966, -0.0048, -0.0059, -0.9049],
       device='cuda:1')
tensor([[0.0145]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -118.24573516845703
Adjusted likelihood: -118.24573516845703
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 118.24573516845703}
Current yaw: tensor([-0.0052, -0.0174, -0.7172], device='cuda:1')
20 thumb_middle
tensor([ 0.1470,  0.4639,  0.5983,  0.9369, -0.1209,  0.5556,  0.9056,  1.0526,
         1.4437,  0.2538,  0.0498,  0.7361, -0.0052, -0.0174, -0.7172,  2.0085],
       device='cuda:1')
Solve time for step 1 9.107800344994757
Current ori: tensor([-0.0052, -0.0174, -0.7172], device='cuda:1')
Index force: tensor([0.5937, 0.6072, 0.5782, 0.5908], device='cuda:1')
tensor([ 0.1455,  0.4550,  0.6230,  0.9038, -0.1864,  0.5246,  0.8585,  0.9563,
         1.3821,  0.2718,  0.0670,  0.8470, -0.0072, -0.0154, -0.7172,  1.9525],
       device='cuda:1')
Solve time for step 2 3.7489520650124177
Current ori: tensor([-0.0072, -0.0154, -0.7172], device='cuda:1')
Index force: tensor([0.6003, 0.5752, 0.5872], device='cuda:1')
tensor([ 0.1392,  0.4794,  0.6056,  0.8592, -0.1895,  0.5321,  0.8620,  0.9434,
         1.3745,  0.2741,  0.0605,  0.8633, -0.0185, -0.0125, -0.7172,  1.9221],
       device='cuda:1')
Solve time for step 3 3.5509879059973173
Current ori: tensor([-0.0185, -0.0125, -0.7172], device='cuda:1')
Index force: tensor([0.5667, 0.5801], device='cuda:1')
tensor([ 0.1429,  0.4707,  0.6127,  0.8765, -0.1888,  0.5336,  0.8601,  0.9411,
         1.3722,  0.2750,  0.0617,  0.8681, -0.0143, -0.0144, -0.7172,  1.9361],
       device='cuda:1')
Solve time for step 4 3.340380447974894
Current ori: tensor([-0.0143, -0.0144, -0.7172], device='cuda:1')
Index force: tensor([0.5577], device='cuda:1')
Storing RECOVERY transition: reward=0.0105 (scaled=0.0026), steps=4
Reward stats updated: mean 0.0120 -> 0.0119, std: 0.0686
Collected 110 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.3635, Q2 Loss=0.3635, Entropy=0.0407, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2290
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.7620, Q2 Loss=1.7620, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7220
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.6361, Q2 Loss=0.6361, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4878
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0631, Q2 Loss=1.0631, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8555
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9770, Q2 Loss=0.9770, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8532

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (17.8%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000002
Q1 loss: 0.960350
Q2 loss: 0.960350
Current threshold: -149.9487
Global Scale Offset: 2.3382
Reward stats: mean=0.0119, std=0.0686, count=110
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 0.9604, Q2 Loss: 0.9604, Entropy: 0.0082, Mean TD Error: 0.8295, Threshold: -149.9487
Original likelihood: -118.57719421386719
Adjusted likelihood: -118.57719421386719
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Marked last transition as done (final step)
{}

Trial 7
Loaded trajectory sampler
Current yaw: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
Current yaw: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
1 turn
Sampling time 3.5992100780131295
tensor([ 0.1458,  0.6182,  0.5511,  0.6093, -0.1164,  0.5544,  0.8545,  0.9416,
         1.1881,  0.3364,  0.2741,  1.1996, -0.0027,  0.0150, -0.0462,  0.3060],
       device='cuda:1')
Original likelihood: -104.48072814941406
Adjusted likelihood: -104.48072814941406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.923051332007162
Current ori: tensor([-0.0027,  0.0150, -0.0462], device='cuda:1')
Middle force: tensor([0.6635, 0.6626, 0.5149, 0.5197, 0.6434, 0.9927, 1.0083, 0.5691, 0.5602,
        0.5083, 0.5245, 0.5079], device='cuda:1')
Thumb force: tensor([0.5405, 2.3778, 0.6583, 1.5419, 1.0395, 0.8781, 1.9857, 0.6223, 0.6488,
        0.6824, 0.5856, 0.6698], device='cuda:1')
Index force: tensor([0.5872, 0.5094, 0.6021, 0.5588, 0.5761, 0.5103, 0.5768, 0.5972, 0.5541,
        0.6219, 0.6035, 0.5339], device='cuda:1')
Storing NORMAL transition: reward=-0.0438 (scaled=-0.0438), steps=1
Reward stats updated: mean 0.0119 -> 0.0114, std: 0.0685
Collected 111 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=5.9587, Q2 Loss=5.9587, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9619
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=6.8742, Q2 Loss=6.8742, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0931
SAC Update 3/5: Actor Loss=-0.0016, Q1 Loss=3.4468, Q2 Loss=3.4468, Entropy=0.2433, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8927
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.4810, Q2 Loss=1.4810, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2124
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2779, Q2 Loss=1.2779, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0377

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (41.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000314
Q1 loss: 3.807716
Q2 loss: 3.807716
Current threshold: -149.9398
Global Scale Offset: 2.4117
Reward stats: mean=0.0114, std=0.0685, count=111
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 3.8077, Q2 Loss: 3.8077, Entropy: 0.0487, Mean TD Error: 2.0395, Threshold: -149.9398
tensor([ 0.0160,  0.5342,  0.5840,  0.5277, -0.2189,  0.5079,  0.8749,  0.9214,
         1.3743,  0.1608,  0.2470,  1.2459,  0.0104,  0.0722, -0.0068,  0.3611],
       device='cuda:1')
Original likelihood: -258.2017822265625
Adjusted likelihood: -258.2017822265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 251.00396728515625
Projection step: 1, Loss: 231.75889587402344
Projection step: 2, Loss: 227.78138732910156
Projection step: 3, Loss: 223.05459594726562
Projection step: 4, Loss: 216.9231719970703
Projection step: 5, Loss: 215.12564086914062
Projection step: 6, Loss: 201.54913330078125
Projection step: 7, Loss: 203.68704223632812
Projection step: 8, Loss: 193.122802734375
Projection step: 9, Loss: 192.4488983154297
Projection step: 10, Loss: 188.90557861328125
Projection step: 11, Loss: 189.23377990722656
Projection step: 12, Loss: 182.93624877929688
Projection step: 13, Loss: 183.2656707763672
Projection step: 14, Loss: 185.58497619628906
Projection step: 15, Loss: 172.92454528808594
Projection step: 16, Loss: 170.4322052001953
Projection step: 17, Loss: 170.24765014648438
Projection step: 18, Loss: 165.28109741210938
Projection step: 19, Loss: 165.23744201660156
Projection step: 20, Loss: 159.53094482421875
Projection step: 21, Loss: 156.49554443359375
Projection step: 22, Loss: 150.37600708007812
Projection step: 23, Loss: 143.8675537109375
Projection step: 24, Loss: 145.50851440429688
Final likelihood: tensor([-140.0941, -121.9521, -129.2457, -167.4279, -160.5408, -143.6477,
        -140.8187, -141.2441, -161.5635, -125.4353, -125.0621, -115.9442,
        -125.1212, -161.5734, -119.7688, -169.4552])
Final projection likelihood: -140.5559
1 mode projection succeeded
New goal: tensor([ 0.0103,  0.5572,  0.5147,  0.6275, -0.1509,  0.5105,  0.8092,  0.8556,
         1.3176,  0.1433,  0.1701,  1.2379,  0.0038,  0.0433, -0.4589],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -172.10671997070312
Adjusted likelihood: -172.10671997070312
Likelihood residual: 0.0
Original likelihood: -155.04928588867188
Adjusted likelihood: -155.04928588867188
Likelihood residual: 0.0
{'index': 155.04928588867188, 'thumb_middle': 172.10671997070312}
Current yaw: tensor([ 0.0104,  0.0722, -0.0068], device='cuda:1')
2 index
tensor([ 0.0160,  0.5342,  0.5840,  0.5277, -0.2189,  0.5079,  0.8749,  0.9214,
         1.3743,  0.1608,  0.2470,  1.2459,  0.0104,  0.0722, -0.0068,  0.3611],
       device='cuda:1')
Solve time for step 1 10.374593865999486
Current ori: tensor([ 0.0104,  0.0722, -0.0068], device='cuda:1')
Middle force: tensor([0.5113, 0.5650, 0.5269, 0.6226], device='cuda:1')
Thumb force: tensor([0.5478, 0.5646, 0.5331, 0.5891], device='cuda:1')
tensor([ 0.0528,  0.4893,  0.4739,  0.5847, -0.2176,  0.5129,  0.8686,  0.9137,
         1.3887,  0.1484,  0.2302,  1.2440,  0.0043,  0.0726, -0.0257,  2.1328],
       device='cuda:1')
Solve time for step 2 4.16009383200435
Current ori: tensor([ 0.0043,  0.0726, -0.0257], device='cuda:1')
Middle force: tensor([0.5604, 0.5251, 0.6185], device='cuda:1')
Thumb force: tensor([0.5589, 0.5302, 0.5870], device='cuda:1')
tensor([ 0.0636,  0.4957,  0.4633,  0.5980, -0.1905,  0.5408,  0.8537,  0.8905,
         1.3833,  0.1433,  0.2025,  1.2421, -0.0091,  0.0571, -0.0386,  2.9088],
       device='cuda:1')
Solve time for step 3 4.35205073596444
Current ori: tensor([-0.0091,  0.0571, -0.0386], device='cuda:1')
Middle force: tensor([0.5223, 0.6147], device='cuda:1')
Thumb force: tensor([0.5280, 0.5839], device='cuda:1')
tensor([ 0.0590,  0.4934,  0.4590,  0.5958, -0.1780,  0.5595,  0.8423,  0.8753,
         1.3763,  0.1478,  0.1915,  1.2388, -0.0167,  0.0495, -0.0394,  3.1573],
       device='cuda:1')
Solve time for step 4 4.063183279999066
Current ori: tensor([-0.0167,  0.0495, -0.0394], device='cuda:1')
Middle force: tensor([0.5046], device='cuda:1')
Thumb force: tensor([0.5002], device='cuda:1')
Storing RECOVERY transition: reward=0.0266 (scaled=0.0266), steps=1
Reward stats updated: mean 0.0114 -> 0.0116, std: 0.0682
Collected 112 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.9267, Q2 Loss=1.9267, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2010
SAC Update 2/5: Actor Loss=-0.0011, Q1 Loss=2.0185, Q2 Loss=2.0185, Entropy=0.2486, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5262
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=12.5702, Q2 Loss=12.5702, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9552
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.5017, Q2 Loss=2.5017, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6428
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4304, Q2 Loss=0.4304, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5550

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.7%)
Q1 update: 0.06s (21.4%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000221
Q1 loss: 3.889520
Q2 loss: 3.889520
Current threshold: -149.9300
Global Scale Offset: 2.4883
Reward stats: mean=0.0116, std=0.0682, count=112
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 3.8895, Q2 Loss: 3.8895, Entropy: 0.0497, Mean TD Error: 1.7760, Threshold: -149.9300
Original likelihood: -165.38246154785156
Adjusted likelihood: -165.38246154785156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 166.4069061279297
Projection step: 1, Loss: 157.95028686523438
Projection step: 2, Loss: 155.2264404296875
Projection step: 3, Loss: 151.1436767578125
Projection step: 4, Loss: 146.36212158203125
Projection step: 5, Loss: 140.73611450195312
Projection step: 6, Loss: 137.58978271484375
Projection step: 7, Loss: 134.78033447265625
Projection step: 8, Loss: 132.38758850097656
Projection step: 9, Loss: 128.90304565429688
Projection step: 10, Loss: 131.44334411621094
Projection step: 11, Loss: 134.01373291015625
Projection step: 12, Loss: 127.09548950195312
Projection step: 13, Loss: 116.58970642089844
Projection step: 14, Loss: 129.66192626953125
Projection step: 15, Loss: 130.75094604492188
Projection step: 16, Loss: 120.9042739868164
Projection step: 17, Loss: 117.05647277832031
Projection step: 18, Loss: 111.96792602539062
Projection step: 19, Loss: 110.82878112792969
Projection step: 20, Loss: 108.1517105102539
Projection step: 21, Loss: 105.91386413574219
Projection step: 22, Loss: 107.79351806640625
Projection step: 23, Loss: 96.57250213623047
Final likelihood: tensor([ -92.4426,  -96.9210,  -98.0261,  -97.3667,  -95.3105, -116.9744,
         -90.5001, -101.7580, -106.7990,  -93.3772,  -87.4919,  -92.5846,
        -103.6361,  -83.2036,  -93.2143,  -95.5539])
Final projection likelihood: -96.5725
1 mode projection succeeded
New goal: tensor([ 0.0365,  0.5536,  0.5358,  0.6058, -0.1272,  0.5018,  0.8553,  0.8647,
         1.3196,  0.1884,  0.1561,  1.1902, -0.0238,  0.0357, -0.4736],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -117.21826171875
Adjusted likelihood: -117.21826171875
Likelihood residual: 0.0
Original likelihood: -130.76004028320312
Adjusted likelihood: -130.76004028320312
Likelihood residual: 0.0
{'index': 130.76004028320312, 'thumb_middle': 117.21826171875}
Current yaw: tensor([-0.0169,  0.0533, -0.0316], device='cuda:1')
3 thumb_middle
tensor([ 0.0104,  0.5567,  0.5020,  0.6191, -0.1830,  0.5605,  0.8385,  0.8716,
         1.3754,  0.1532,  0.2005,  1.2322, -0.0169,  0.0533, -0.0316,  3.1513],
       device='cuda:1')
Solve time for step 1 9.075238939956762
Current ori: tensor([-0.0169,  0.0533, -0.0316], device='cuda:1')
Index force: tensor([0.5710, 0.5659, 0.5801, 0.5862], device='cuda:1')
tensor([ 0.0107,  0.5813,  0.4969,  0.5623, -0.2193,  0.4986,  0.8274,  0.8479,
         1.3142,  0.1729,  0.1164,  1.1809, -0.0273,  0.0531, -0.0317,  3.1341],
       device='cuda:1')
Solve time for step 2 3.5224555790191516
Current ori: tensor([-0.0273,  0.0531, -0.0317], device='cuda:1')
Index force: tensor([0.5588, 0.5718, 0.5785], device='cuda:1')
tensor([ 0.0236,  0.5707,  0.5162,  0.5761, -0.2179,  0.5006,  0.8320,  0.8473,
         1.3114,  0.1725,  0.1066,  1.1753, -0.0243,  0.0457, -0.0317,  3.1572],
       device='cuda:1')
Solve time for step 3 3.660081184003502
Current ori: tensor([-0.0243,  0.0457, -0.0317], device='cuda:1')
Index force: tensor([0.5610, 0.5685], device='cuda:1')
tensor([ 0.0354,  0.5608,  0.5272,  0.6024, -0.2136,  0.4973,  0.8339,  0.8487,
         1.3113,  0.1721,  0.0974,  1.1692, -0.0202,  0.0389, -0.0317,  3.1815],
       device='cuda:1')
Solve time for step 4 3.377387828018982
Current ori: tensor([-0.0202,  0.0389, -0.0317], device='cuda:1')
Index force: tensor([0.5286], device='cuda:1')
Storing RECOVERY transition: reward=0.0315 (scaled=0.0315), steps=1
Reward stats updated: mean 0.0116 -> 0.0117, std: 0.0680
Collected 113 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=5.8423, Q2 Loss=5.8423, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0183
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.3859, Q2 Loss=0.3859, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1696
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.9068, Q2 Loss=1.9068, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3429
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4419, Q2 Loss=0.4419, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5493
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4311, Q2 Loss=0.4311, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6296

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (19.1%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (39.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: 0.000000
Q1 loss: 1.801605
Q2 loss: 1.801605
Current threshold: -149.9236
Global Scale Offset: 2.5391
Reward stats: mean=0.0117, std=0.0680, count=113
----------------------------------------------
SAC Update - Actor Loss: 0.0000, Q1 Loss: 1.8016, Q2 Loss: 1.8016, Entropy: 0.0000, Mean TD Error: 1.1419, Threshold: -149.9236
Original likelihood: -118.93573760986328
Adjusted likelihood: -118.93573760986328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0185,  0.0353, -0.0352], device='cuda:1')
4 turn
Sampling time 3.590065582015086
tensor([ 0.0414,  0.5563,  0.5351,  0.6104, -0.1466,  0.5410,  0.8688,  0.8635,
         1.3724,  0.2035,  0.1476,  1.1976, -0.0185,  0.0353, -0.0352,  3.1939],
       device='cuda:1')
Original likelihood: -112.02039337158203
Adjusted likelihood: -112.02039337158203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.927868205995765
Current ori: tensor([-0.0185,  0.0353, -0.0352], device='cuda:1')
Middle force: tensor([0.5676, 0.6067, 0.5867, 1.8181, 0.5956, 1.2912, 0.5154, 1.1511, 0.6275,
        0.5816, 0.7979, 0.6189], device='cuda:1')
Thumb force: tensor([0.6173, 0.7963, 0.6047, 1.5237, 0.5469, 0.7950, 0.5760, 1.3266, 1.9544,
        0.5392, 0.5598, 0.6244], device='cuda:1')
Index force: tensor([0.7741, 0.5058, 0.5261, 0.5610, 0.5787, 0.6676, 0.7505, 0.6057, 0.5706,
        0.5604, 0.5445, 0.5906], device='cuda:1')
Storing NORMAL transition: reward=0.0115 (scaled=0.0115), steps=1
Reward stats updated: mean 0.0117 -> 0.0117, std: 0.0677
Collected 114 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.0350, Q2 Loss=1.0350, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7106
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.7419, Q2 Loss=1.7419, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2492
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.9504, Q2 Loss=1.9504, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3277
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8996, Q2 Loss=0.8996, Entropy=0.0005, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7942
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=14.2114, Q2 Loss=14.2114, Entropy=0.0005, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2614

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000000
Q1 loss: 3.967665
Q2 loss: 3.967665
Current threshold: -149.9197
Global Scale Offset: 2.5700
Reward stats: mean=0.0117, std=0.0677, count=114
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 3.9677, Q2 Loss: 3.9677, Entropy: 0.0002, Mean TD Error: 1.8686, Threshold: -149.9197
tensor([ 0.1159,  0.5676,  0.4947,  0.4220, -0.0864,  0.5745,  0.8805,  0.9091,
         1.2325,  0.2726,  0.2394,  1.0668, -0.0227, -0.0174, -0.0459,  2.6801],
       device='cuda:1')
Original likelihood: -157.09017944335938
Adjusted likelihood: -157.09017944335938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0248)
State is out of distribution
Projection step: 0, Loss: 163.4881134033203
Projection step: 1, Loss: 152.77032470703125
Projection step: 2, Loss: 136.34368896484375
Projection step: 3, Loss: 129.29702758789062
Projection step: 4, Loss: 118.16900634765625
Projection step: 5, Loss: 108.55997467041016
Projection step: 6, Loss: 100.81515502929688
Final likelihood: tensor([ -98.8668, -108.1088,  -79.7833,  -98.9906, -101.7811, -104.8807,
         -99.6731, -101.3588, -104.0327, -107.9325, -110.5600, -100.3555,
        -109.9147, -100.3618,  -99.5019,  -86.9403])
Final projection likelihood: -100.8152
1 mode projection succeeded
New goal: tensor([ 0.0921,  0.5968,  0.5284,  0.5197, -0.0687,  0.5709,  0.8738,  0.8715,
         1.2720,  0.3049,  0.2128,  1.0702, -0.0213, -0.0135, -0.4165],
       device='cuda:1')
tensor([[0.0035]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0107]], device='cuda:1')
Original likelihood: -147.77053833007812
Adjusted likelihood: -147.77053833007812
Likelihood residual: 0.0
{'index': 147.77053833007812, 'thumb_middle': inf}
Current yaw: tensor([-0.0227, -0.0174, -0.0459], device='cuda:1')
5 index
tensor([ 0.1159,  0.5676,  0.4947,  0.4220, -0.0864,  0.5745,  0.8805,  0.9091,
         1.2325,  0.2726,  0.2394,  1.0668, -0.0227, -0.0174, -0.0459,  2.6801],
       device='cuda:1')
Solve time for step 1 10.80034037400037
Current ori: tensor([-0.0227, -0.0174, -0.0459], device='cuda:1')
Middle force: tensor([0.5003, 0.5185, 0.5343, 0.5991], device='cuda:1')
Thumb force: tensor([0.5446, 0.5177, 0.5857, 0.5656], device='cuda:1')
tensor([ 0.1349,  0.5483,  0.4855,  0.4837, -0.0917,  0.5947,  0.8919,  0.8872,
         1.2614,  0.2534,  0.2277,  1.0399, -0.0381, -0.0230, -0.0511,  2.3502],
       device='cuda:1')
Solve time for step 2 4.295324808044825
Current ori: tensor([-0.0381, -0.0230, -0.0511], device='cuda:1')
Middle force: tensor([0.5171, 0.5321, 0.5947], device='cuda:1')
Thumb force: tensor([0.5155, 0.5808, 0.5610], device='cuda:1')
tensor([ 0.1332,  0.5486,  0.4854,  0.4954, -0.0935,  0.5936,  0.9020,  0.8947,
         1.2588,  0.2609,  0.2185,  1.0515, -0.0399, -0.0248, -0.0537,  2.1850],
       device='cuda:1')
Solve time for step 3 4.28387364000082
Current ori: tensor([-0.0399, -0.0248, -0.0537], device='cuda:1')
Middle force: tensor([0.5457, 0.5357], device='cuda:1')
Thumb force: tensor([0.5583, 0.5642], device='cuda:1')
tensor([ 0.1302,  0.5499,  0.4873,  0.4984, -0.0877,  0.6030,  0.8970,  0.8861,
         1.2547,  0.2670,  0.2154,  1.0428, -0.0445, -0.0288, -0.0593,  2.1670],
       device='cuda:1')
Solve time for step 4 3.8399393360014074
Current ori: tensor([-0.0445, -0.0288, -0.0593], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5919], device='cuda:1')
Storing RECOVERY transition: reward=0.0262 (scaled=0.0262), steps=1
Reward stats updated: mean 0.0117 -> 0.0119, std: 0.0674
Collected 115 transitions for RL
SAC Update 1/5: Actor Loss=-0.0023, Q1 Loss=10.7471, Q2 Loss=10.7471, Entropy=0.2553, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.8354
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.4343, Q2 Loss=0.4343, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4449
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.5330, Q2 Loss=1.5330, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7951
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=1.1024, Q2 Loss=1.1024, Entropy=0.0607, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7149
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.0211, Q2 Loss=2.0211, Entropy=0.0007, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8885

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000491
Q1 loss: 3.167596
Q2 loss: 3.167596
Current threshold: -149.9109
Global Scale Offset: 2.6422
Reward stats: mean=0.0119, std=0.0674, count=115
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 3.1676, Q2 Loss: 3.1676, Entropy: 0.0633, Mean TD Error: 1.5357, Threshold: -149.9109
Original likelihood: -147.51962280273438
Adjusted likelihood: -147.51962280273438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7393)
State is out of distribution
Projection step: 0, Loss: 154.13076782226562
Projection step: 1, Loss: 139.96994018554688
Projection step: 2, Loss: 129.66722106933594
Projection step: 3, Loss: 120.0976791381836
Projection step: 4, Loss: 110.88204956054688
Projection step: 5, Loss: 102.12733459472656
Final likelihood: tensor([-105.1188, -101.2746, -100.8864,  -96.6985,  -92.4090, -104.7506,
        -101.5691,  -96.5671, -101.3143, -100.4832, -107.4015, -109.1070,
        -101.2280, -104.4712, -107.3785, -103.3795])
Final projection likelihood: -102.1273
1 mode projection succeeded
New goal: tensor([ 0.0809,  0.6132,  0.5126,  0.5436, -0.0550,  0.5817,  0.9065,  0.8287,
         1.3025,  0.2833,  0.1718,  1.0608, -0.0383, -0.0300, -0.0716],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -147.97341918945312
Adjusted likelihood: -147.97341918945312
Likelihood residual: 0.0
Original likelihood: -166.43536376953125
Adjusted likelihood: -166.43536376953125
Likelihood residual: 0.0
{'index': 166.43536376953125, 'thumb_middle': 147.97341918945312}
Current yaw: tensor([-0.0415, -0.0333, -0.0743], device='cuda:1')
6 thumb_middle
tensor([ 0.0839,  0.6111,  0.5319,  0.5212, -0.0821,  0.5974,  0.9060,  0.8965,
         1.2506,  0.2712,  0.2023,  1.0625, -0.0415, -0.0333, -0.0743,  2.2079],
       device='cuda:1')
Solve time for step 1 9.11845979600912
Current ori: tensor([-0.0415, -0.0333, -0.0743], device='cuda:1')
Index force: tensor([0.5851, 0.5944, 0.5842, 0.5650], device='cuda:1')
tensor([ 0.0823,  0.6136,  0.5194,  0.5381, -0.1614,  0.5661,  0.8774,  0.8349,
         1.2470,  0.2584,  0.0934,  1.0225, -0.0420, -0.0316, -0.0743,  2.1978],
       device='cuda:1')
Solve time for step 2 3.5416104620089754
Current ori: tensor([-0.0420, -0.0316, -0.0743], device='cuda:1')
Index force: tensor([0.5856, 0.5775, 0.5590], device='cuda:1')
tensor([ 0.0880,  0.6181,  0.5101,  0.5627, -0.1437,  0.5543,  0.8847,  0.8225,
         1.2514,  0.2605,  0.0738,  1.0225, -0.0388, -0.0360, -0.0743,  2.2221],
       device='cuda:1')
Solve time for step 3 3.734981799032539
Current ori: tensor([-0.0388, -0.0360, -0.0743], device='cuda:1')
Index force: tensor([0.5509, 0.5477], device='cuda:1')
tensor([ 0.0890,  0.6244,  0.5102,  0.5388, -0.1322,  0.5543,  0.8759,  0.8209,
         1.2483,  0.2621,  0.0707,  1.0232, -0.0427, -0.0360, -0.0743,  2.2123],
       device='cuda:1')
Solve time for step 4 3.5871328220237046
Current ori: tensor([-0.0427, -0.0360, -0.0743], device='cuda:1')
Index force: tensor([0.5401], device='cuda:1')
Storing RECOVERY transition: reward=0.0171 (scaled=0.0171), steps=1
Reward stats updated: mean 0.0119 -> 0.0119, std: 0.0671
Collected 116 transitions for RL
SAC Update 1/5: Actor Loss=-0.0024, Q1 Loss=10.3773, Q2 Loss=10.3773, Entropy=0.2590, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.8520
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=4.4793, Q2 Loss=4.4793, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6734
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=1.4038, Q2 Loss=1.4038, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0424
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.0111, Q2 Loss=1.0111, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7972
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.6481, Q2 Loss=0.6481, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1884

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000479
Q1 loss: 3.583915
Q2 loss: 3.583915
Current threshold: -149.8990
Global Scale Offset: 2.7396
Reward stats: mean=0.0119, std=0.0671, count=116
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 3.5839, Q2 Loss: 3.5839, Entropy: 0.0518, Mean TD Error: 1.5107, Threshold: -149.8990
Original likelihood: -120.62435913085938
Adjusted likelihood: -120.62435913085938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0412, -0.0249, -0.0646], device='cuda:1')
7 turn
Sampling time 3.5941210159799084
tensor([ 0.0626,  0.6170,  0.4986,  0.5272, -0.0883,  0.6103,  0.8938,  0.8390,
         1.3263,  0.2677,  0.1199,  1.0718, -0.0412, -0.0249, -0.0646,  2.1898],
       device='cuda:1')
Original likelihood: -119.33196258544922
Adjusted likelihood: -119.33196258544922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.001575972011779
Current ori: tensor([-0.0412, -0.0249, -0.0646], device='cuda:1')
Middle force: tensor([0.5980, 0.5586, 1.4065, 0.6244, 0.6624, 0.7833, 0.6530, 0.5745, 0.7896,
        0.5641, 0.6124, 0.5263], device='cuda:1')
Thumb force: tensor([0.6047, 1.0948, 0.9634, 1.1390, 0.5465, 0.5815, 0.5831, 0.5249, 0.6024,
        0.5961, 0.5710, 0.9334], device='cuda:1')
Index force: tensor([0.6171, 0.5163, 1.3841, 0.5726, 0.6039, 0.6084, 0.5933, 0.6924, 0.5464,
        0.6819, 0.5847, 0.5293], device='cuda:1')
Storing NORMAL transition: reward=0.0607 (scaled=0.0607), steps=1
Reward stats updated: mean 0.0119 -> 0.0123, std: 0.0669
Collected 117 transitions for RL
SAC Update 1/5: Actor Loss=-0.0040, Q1 Loss=0.6222, Q2 Loss=0.6222, Entropy=0.3177, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2793
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=13.0685, Q2 Loss=13.0685, Entropy=0.0011, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3064
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.5552, Q2 Loss=1.5552, Entropy=0.0129, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1574
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.8491, Q2 Loss=0.8491, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6173
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.9349, Q2 Loss=0.9349, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0098

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.0%)
Q1 update: 0.06s (19.4%)
Q2 update: 0.06s (20.3%)
Actor update: 0.13s (42.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000814
Q1 loss: 3.405997
Q2 loss: 3.405997
Current threshold: -149.9017
Global Scale Offset: 2.8433
Reward stats: mean=0.0123, std=0.0669, count=117
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 3.4060, Q2 Loss: 3.4060, Entropy: 0.0663, Mean TD Error: 1.4740, Threshold: -149.9017
tensor([ 0.0537,  0.5984,  0.5102,  0.5465, -0.0969,  0.6214,  0.8261,  0.9438,
         1.3498,  0.2403,  0.1353,  1.0222, -0.0400, -0.0188, -0.1251,  2.2173],
       device='cuda:1')
Original likelihood: -107.38788604736328
Adjusted likelihood: -107.38788604736328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.641588888014667
Current ori: tensor([-0.0400, -0.0188, -0.1251], device='cuda:1')
Middle force: tensor([0.5515, 1.3669, 0.6091, 0.6572, 0.7725, 0.6498, 0.6249, 0.6056, 0.5303,
        0.6287, 0.5421], device='cuda:1')
Thumb force: tensor([1.0606, 0.9257, 1.0948, 0.5373, 0.5731, 0.5693, 0.5399, 0.5731, 0.5654,
        0.5937, 0.9514], device='cuda:1')
Index force: tensor([0.5130, 1.3150, 0.5746, 0.5970, 0.6039, 0.5853, 0.5172, 0.5847, 0.7101,
        0.5737, 0.5447], device='cuda:1')
Storing NORMAL transition: reward=-0.0104 (scaled=-0.0104), steps=1
Reward stats updated: mean 0.0123 -> 0.0121, std: 0.0667
Collected 118 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.9446, Q2 Loss=0.9446, Entropy=0.0746, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5725
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.2933, Q2 Loss=1.2933, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0356
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=1.4746, Q2 Loss=1.4746, Entropy=0.2689, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4596
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=2.2894, Q2 Loss=2.2894, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6740
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.4854, Q2 Loss=0.4854, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1363

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000238
Q1 loss: 1.297447
Q2 loss: 1.297447
Current threshold: -149.9020
Global Scale Offset: 2.9346
Reward stats: mean=0.0121, std=0.0667, count=118
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.2974, Q2 Loss: 1.2974, Entropy: 0.0687, Mean TD Error: 1.1756, Threshold: -149.9020
tensor([ 0.0369,  0.6426,  0.4427,  0.5013, -0.0895,  0.5973,  0.8383,  0.9896,
         1.3027,  0.2342,  0.1977,  0.9387, -0.0260, -0.0225, -0.1138,  2.4736],
       device='cuda:1')
Original likelihood: -148.4637451171875
Adjusted likelihood: -148.4637451171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6389)
Solve time for step 3 5.24912683502771
Current ori: tensor([-0.0260, -0.0225, -0.1138], device='cuda:1')
Middle force: tensor([0.8116, 0.6720, 0.8841, 0.5686, 0.8783, 1.5494, 0.6726, 0.5418, 0.5741,
        0.5492], device='cuda:1')
Thumb force: tensor([0.5063, 1.0352, 0.5236, 0.6720, 0.5600, 0.8070, 0.5507, 0.5130, 0.5599,
        1.0811], device='cuda:1')
Index force: tensor([0.8151, 0.6733, 0.6471, 0.5975, 0.5026, 0.9474, 0.5074, 0.5950, 0.5527,
        0.5083], device='cuda:1')
Storing NORMAL transition: reward=-0.0091 (scaled=-0.0091), steps=1
Reward stats updated: mean 0.0121 -> 0.0120, std: 0.0664
Collected 119 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=0.5668, Q2 Loss=0.5668, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6579
SAC Update 2/5: Actor Loss=-0.0049, Q1 Loss=0.6393, Q2 Loss=0.6393, Entropy=0.3336, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6357
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=3.3765, Q2 Loss=3.3765, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2122
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=3.3551, Q2 Loss=3.3551, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2122
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=11.4904, Q2 Loss=11.4904, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1996

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (17.6%)
Q2 update: 0.05s (20.3%)
Actor update: 0.12s (43.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000977
Q1 loss: 3.885609
Q2 loss: 3.885609
Current threshold: -149.9103
Global Scale Offset: 3.0258
Reward stats: mean=0.0120, std=0.0664, count=119
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 3.8856, Q2 Loss: 3.8856, Entropy: 0.0667, Mean TD Error: 1.9835, Threshold: -149.9103
tensor([-0.0279,  0.5393,  0.4756,  0.5994,  0.0113,  0.4780,  0.8804,  0.9354,
         1.2937,  0.1459,  0.1639,  1.0609, -0.0553, -0.0529, -0.1096,  2.6547],
       device='cuda:1')
Original likelihood: -186.1436767578125
Adjusted likelihood: -186.1436767578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 184.46661376953125
Projection step: 1, Loss: 179.5595703125
Projection step: 2, Loss: 177.93643188476562
Projection step: 3, Loss: 166.462158203125
Projection step: 4, Loss: 163.69577026367188
Projection step: 5, Loss: 162.39749145507812
Projection step: 6, Loss: 152.53182983398438
Projection step: 7, Loss: 147.50454711914062
Projection step: 8, Loss: 143.69203186035156
Projection step: 9, Loss: 142.45428466796875
Projection step: 10, Loss: 135.4349822998047
Projection step: 11, Loss: 131.3897247314453
Projection step: 12, Loss: 127.69463348388672
Projection step: 13, Loss: 123.41148376464844
Projection step: 14, Loss: 117.87319946289062
Projection step: 15, Loss: 112.64894104003906
Projection step: 16, Loss: 110.2354736328125
Projection step: 17, Loss: 109.01632690429688
Projection step: 18, Loss: 109.23056030273438
Projection step: 19, Loss: 103.93933868408203
Final likelihood: tensor([-106.7889,  -97.9637, -102.5081, -102.0590, -103.0336, -104.7999,
        -110.3064, -105.6196, -102.1110, -100.4124, -109.2273,  -98.2557,
        -101.0048, -102.1980, -106.2967, -110.4441])
Final projection likelihood: -103.9393
1 mode projection succeeded
New goal: tensor([ 0.0314,  0.4840,  0.5866,  0.5977,  0.0107,  0.5499,  0.7875,  0.9263,
         1.3323,  0.3060,  0.1249,  0.9491, -0.0520, -0.0411, -0.2920],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0081]], device='cuda:1') tensor([[0.0060]], device='cuda:1')
Original likelihood: -157.29344177246094
Adjusted likelihood: -157.29344177246094
Likelihood residual: 0.0
Original likelihood: -178.0957489013672
Adjusted likelihood: -178.0957489013672
Likelihood residual: 0.0
{'index': 178.0957489013672, 'thumb_middle': 157.29344177246094}
Current yaw: tensor([-0.0553, -0.0529, -0.1096], device='cuda:1')
8 thumb_middle
tensor([-0.0279,  0.5393,  0.4756,  0.5994,  0.0113,  0.4780,  0.8804,  0.9354,
         1.2937,  0.1459,  0.1639,  1.0609, -0.0553, -0.0529, -0.1096,  2.6547],
       device='cuda:1')
Solve time for step 1 8.848964869044721
Current ori: tensor([-0.0553, -0.0529, -0.1096], device='cuda:1')
Index force: tensor([0.5672, 0.6064, 0.6006, 0.5899], device='cuda:1')
tensor([-0.0381,  0.5342,  0.5837,  0.5946, -0.0492,  0.5252,  0.7864,  0.9202,
         1.2894,  0.2633,  0.0444,  0.9325, -0.1240, -0.1185, -0.1007,  2.7774],
       device='cuda:1')
Solve time for step 2 3.540845100011211
Current ori: tensor([-0.1240, -0.1185, -0.1007], device='cuda:1')
Index force: tensor([0.5956, 0.5911, 0.5829], device='cuda:1')
tensor([-0.0741,  0.5741,  0.6537,  0.6370, -0.0279,  0.5730,  0.7933,  0.9195,
         1.2743,  0.2874, -0.0116,  0.8910, -0.1799, -0.1634, -0.0374,  2.7550],
       device='cuda:1')
Solve time for step 3 3.5601658590021543
Current ori: tensor([-0.1799, -0.1634, -0.0374], device='cuda:1')
Index force: tensor([0.5000, 0.5720], device='cuda:1')
tensor([-0.0859,  0.5992,  0.6643,  0.6417, -0.0147,  0.6099,  0.7869,  0.9263,
         1.2615,  0.2858, -0.0334,  0.8693, -0.2373, -0.1894,  0.0772,  2.5381],
       device='cuda:1')
Solve time for step 4 3.4296518159681
Current ori: tensor([-0.2373, -0.1894,  0.0772], device='cuda:1')
Index force: tensor([0.5486], device='cuda:1')
Storing RECOVERY transition: reward=-0.4163 (scaled=-0.1388), steps=3
Reward stats updated: mean 0.0120 -> 0.0107, std: 0.0676
Collected 120 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.6066, Q2 Loss=0.6066, Entropy=0.0863, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6178
SAC Update 2/5: Actor Loss=-0.0035, Q1 Loss=3.9466, Q2 Loss=3.9466, Entropy=0.3278, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6831
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.0194, Q2 Loss=2.0194, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4207
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.4843, Q2 Loss=0.4843, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3697
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=11.2378, Q2 Loss=11.2378, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6737

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.6%)
Q1 update: 0.04s (18.0%)
Q2 update: 0.04s (18.7%)
Actor update: 0.11s (44.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000781
Q1 loss: 3.658954
Q2 loss: 3.658954
Current threshold: -149.9121
Global Scale Offset: 3.1427
Reward stats: mean=0.0107, std=0.0676, count=120
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 3.6590, Q2 Loss: 3.6590, Entropy: 0.0828, Mean TD Error: 1.5530, Threshold: -149.9121
Original likelihood: -919.4758911132812
Adjusted likelihood: -919.4758911132812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 8
Loaded trajectory sampler
Current yaw: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
Current yaw: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
1 turn
Sampling time 3.6073218479868956
tensor([ 0.1546,  0.6027,  0.5966,  0.5793, -0.1382,  0.5608,  0.8990,  0.9071,
         1.2500,  0.3295,  0.1968,  1.2100, -0.0030,  0.0151, -0.0456, -0.0677],
       device='cuda:1')
Original likelihood: -130.1527557373047
Adjusted likelihood: -130.1527557373047
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.157438739028294
Current ori: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
Middle force: tensor([0.5023, 0.6418, 0.5464, 0.5043, 0.7699, 1.1278, 0.5842, 0.5620, 0.5111,
        0.5087, 0.5933, 0.6234], device='cuda:1')
Thumb force: tensor([0.9159, 0.7487, 1.6655, 2.5868, 0.9177, 1.8011, 0.6006, 0.6972, 0.6057,
        1.7583, 0.5923, 0.6081], device='cuda:1')
Index force: tensor([0.5675, 0.8949, 0.5989, 0.6045, 0.5906, 0.5905, 0.5912, 0.5150, 0.4887,
        0.9263, 0.5407, 0.5818], device='cuda:1')
Storing NORMAL transition: reward=-0.0356 (scaled=-0.0356), steps=1
Reward stats updated: mean 0.0107 -> 0.0103, std: 0.0674
Collected 121 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.6396, Q2 Loss=0.6396, Entropy=0.1039, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3563
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=2.2473, Q2 Loss=2.2473, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6785
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.8616, Q2 Loss=0.8616, Entropy=0.0968, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9230
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5545, Q2 Loss=0.5545, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4936
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=3.7186, Q2 Loss=3.7186, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3469

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.1%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000198
Q1 loss: 1.604320
Q2 loss: 1.604320
Current threshold: -149.9147
Global Scale Offset: 3.2782
Reward stats: mean=0.0103, std=0.0674, count=121
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 1.6043, Q2 Loss: 1.6043, Entropy: 0.0402, Mean TD Error: 1.1597, Threshold: -149.9147
tensor([ 1.9886e-01,  6.0379e-01,  6.7337e-01,  5.1986e-01, -9.3935e-02,
         5.8713e-01,  8.3644e-01,  9.8584e-01,  1.2226e+00,  3.0247e-01,
         1.8255e-01,  1.2493e+00,  4.0422e-04, -1.5952e-02, -1.0017e-02,
        -2.4185e-01], device='cuda:1')
Original likelihood: -157.33734130859375
Adjusted likelihood: -157.33734130859375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0462)
State is out of distribution
Projection step: 0, Loss: 157.68832397460938
Projection step: 1, Loss: 159.6867218017578
Projection step: 2, Loss: 161.95364379882812
Projection step: 3, Loss: 144.55075073242188
Projection step: 4, Loss: 142.21234130859375
Projection step: 5, Loss: 143.3324737548828
Projection step: 6, Loss: 133.2716064453125
Projection step: 7, Loss: 124.68336486816406
Projection step: 8, Loss: 122.53843688964844
Projection step: 9, Loss: 129.591796875
Projection step: 10, Loss: 115.28919982910156
Projection step: 11, Loss: 118.94918823242188
Projection step: 12, Loss: 120.09280395507812
Projection step: 13, Loss: 111.3004150390625
Projection step: 14, Loss: 108.96244812011719
Projection step: 15, Loss: 107.00065612792969
Projection step: 16, Loss: 97.46908569335938
Final likelihood: tensor([-114.3595, -120.1096,  -87.5906,  -98.9353,  -98.8387,  -88.1152,
         -78.6751, -115.5272, -120.1255,  -97.0700,  -83.6225,  -95.1599,
         -82.6624,  -93.9327,  -84.2777, -100.5032])
Final projection likelihood: -97.4691
1 mode projection succeeded
New goal: tensor([ 1.3992e-01,  5.6214e-01,  6.2733e-01,  6.3452e-01, -6.2923e-02,
         5.6473e-01,  9.1564e-01,  8.5479e-01,  1.2856e+00,  2.9233e-01,
         1.7578e-01,  1.1351e+00, -1.0494e-03, -1.1204e-02, -1.0713e+00],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -94.22003173828125
Adjusted likelihood: -94.22003173828125
Likelihood residual: 0.0
Original likelihood: -142.58538818359375
Adjusted likelihood: -142.58538818359375
Likelihood residual: 0.0
{'index': 142.58538818359375, 'thumb_middle': 94.22003173828125}
Current yaw: tensor([ 0.0004, -0.0160, -0.0100], device='cuda:1')
2 thumb_middle
tensor([ 1.9886e-01,  6.0379e-01,  6.7337e-01,  5.1986e-01, -9.3935e-02,
         5.8713e-01,  8.3644e-01,  9.8584e-01,  1.2226e+00,  3.0247e-01,
         1.8255e-01,  1.2493e+00,  4.0422e-04, -1.5952e-02, -1.0017e-02,
        -2.4185e-01], device='cuda:1')
Solve time for step 1 8.713036002998706
Current ori: tensor([ 0.0004, -0.0160, -0.0100], device='cuda:1')
Index force: tensor([0.5634, 0.5622, 0.5839, 0.5651], device='cuda:1')
tensor([ 0.1872,  0.5890,  0.6354,  0.6065, -0.1750,  0.5257,  0.8545,  0.8601,
         1.2480,  0.2692,  0.1007,  1.1191,  0.0091, -0.0062, -0.0100, -0.2255],
       device='cuda:1')
Solve time for step 2 3.656386768037919
Current ori: tensor([ 0.0091, -0.0062, -0.0100], device='cuda:1')
Index force: tensor([0.5532, 0.5749, 0.5591], device='cuda:1')
tensor([ 0.1863,  0.5822,  0.6331,  0.6267, -0.1781,  0.5332,  0.8596,  0.8305,
         1.2503,  0.2759,  0.0960,  1.1148,  0.0120, -0.0047, -0.0100, -0.2210],
       device='cuda:1')
Solve time for step 3 3.518272256013006
Current ori: tensor([ 0.0120, -0.0047, -0.0100], device='cuda:1')
Index force: tensor([0.5635, 0.5517], device='cuda:1')
tensor([ 0.1924,  0.5930,  0.6229,  0.6317, -0.1753,  0.5304,  0.8674,  0.8383,
         1.2523,  0.2838,  0.0974,  1.0868,  0.0101, -0.0087, -0.0100, -0.2127],
       device='cuda:1')
Solve time for step 4 3.386918162985239
Current ori: tensor([ 0.0101, -0.0087, -0.0100], device='cuda:1')
Index force: tensor([0.5392], device='cuda:1')
Storing RECOVERY transition: reward=-0.0111 (scaled=-0.0111), steps=1
Reward stats updated: mean 0.0103 -> 0.0101, std: 0.0672
Collected 122 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.7426, Q2 Loss=1.7426, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2199
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=11.3843, Q2 Loss=11.3843, Entropy=0.0044, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2921
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6108, Q2 Loss=0.6108, Entropy=0.0962, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4075
SAC Update 4/5: Actor Loss=-0.0057, Q1 Loss=1.7221, Q2 Loss=1.7221, Entropy=0.3474, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3970
SAC Update 5/5: Actor Loss=-0.0052, Q1 Loss=1.1827, Q2 Loss=1.1827, Entropy=0.3378, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6971

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.8%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (37.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002223
Q1 loss: 3.328504
Q2 loss: 3.328504
Current threshold: -149.9145
Global Scale Offset: 3.4019
Reward stats: mean=0.0101, std=0.0672, count=122
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 3.3285, Q2 Loss: 3.3285, Entropy: 0.1571, Mean TD Error: 2.2027, Threshold: -149.9145
Original likelihood: -132.86654663085938
Adjusted likelihood: -132.86654663085938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Current yaw: tensor([0.0160, 0.0072, 0.0011], device='cuda:1')
3 turn
Sampling time 3.8435403059702367
tensor([ 1.6426e-01,  5.6964e-01,  6.2453e-01,  6.3026e-01, -1.2948e-01,
         5.5756e-01,  9.1562e-01,  8.4177e-01,  1.3230e+00,  2.9101e-01,
         1.6125e-01,  1.1437e+00,  1.5979e-02,  7.1784e-03,  1.0525e-03,
        -2.7349e-01], device='cuda:1')
Original likelihood: -127.36448669433594
Adjusted likelihood: -127.36448669433594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 13.909882901003584
Current ori: tensor([0.0160, 0.0072, 0.0011], device='cuda:1')
Middle force: tensor([0.7688, 0.5401, 0.5400, 0.8440, 0.9383, 0.8945, 0.8443, 0.5223, 0.6144,
        0.5261, 0.5584, 0.6087], device='cuda:1')
Thumb force: tensor([0.8193, 3.3600, 1.4021, 0.6052, 0.6985, 0.9262, 0.8302, 0.6708, 0.6045,
        0.6519, 0.6241, 0.5987], device='cuda:1')
Index force: tensor([0.6868, 0.5208, 0.5452, 0.8174, 0.5580, 0.5561, 0.5362, 0.6151, 0.5597,
        0.6900, 0.6156, 0.5930], device='cuda:1')
Storing NORMAL transition: reward=0.3572 (scaled=0.3572), steps=1
Reward stats updated: mean 0.0101 -> 0.0130, std: 0.0738
Collected 123 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=14.4983, Q2 Loss=14.4983, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6985
SAC Update 2/5: Actor Loss=-0.0030, Q1 Loss=7.2806, Q2 Loss=7.2806, Entropy=0.2854, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5024
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8102, Q2 Loss=0.8102, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6640
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.7583, Q2 Loss=0.7583, Entropy=0.2888, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3634
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7484, Q2 Loss=0.7484, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5979

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (41.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000684
Q1 loss: 4.819146
Q2 loss: 4.819146
Current threshold: -149.9103
Global Scale Offset: 3.5728
Reward stats: mean=0.0130, std=0.0738, count=123
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 4.8191, Q2 Loss: 4.8191, Entropy: 0.1148, Mean TD Error: 2.1652, Threshold: -149.9103
tensor([ 0.2276,  0.5257,  0.7251,  0.6883, -0.0147,  0.4679,  1.0892,  1.0312,
         1.4300,  0.1682,  0.0839,  0.9678,  0.0432, -0.0808, -0.3833,  0.3673],
       device='cuda:1')
Original likelihood: -220.84329223632812
Adjusted likelihood: -220.84329223632812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 216.92832946777344
Projection step: 1, Loss: 249.79818725585938
Projection step: 2, Loss: 228.817138671875
Projection step: 3, Loss: 211.94766235351562
Projection step: 4, Loss: 200.82113647460938
Projection step: 5, Loss: 215.19232177734375
Projection step: 6, Loss: 216.97552490234375
Projection step: 7, Loss: 237.81356811523438
Projection step: 8, Loss: 221.37420654296875
Projection step: 9, Loss: 225.1720428466797
Projection step: 10, Loss: 199.18109130859375
Projection step: 11, Loss: 199.55142211914062
Projection step: 12, Loss: 214.4747314453125
Projection step: 13, Loss: 185.8131561279297
Projection step: 14, Loss: 199.37838745117188
Projection step: 15, Loss: 207.468017578125
Projection step: 16, Loss: 195.3557891845703
Projection step: 17, Loss: 194.9354248046875
Projection step: 18, Loss: 190.12567138671875
Projection step: 19, Loss: 207.55007934570312
Projection step: 20, Loss: 201.521240234375
Projection step: 21, Loss: 206.950927734375
Projection step: 22, Loss: 181.50430297851562
Projection step: 23, Loss: 192.3573760986328
Projection step: 24, Loss: 187.56727600097656
Final likelihood: tensor([-227.2872, -195.8566, -196.1068, -199.7323, -180.7776, -198.8329,
        -185.0040, -195.0194, -185.5215, -198.0070, -176.7864, -195.6599,
        -183.4581, -187.4344, -198.0149, -196.2976])
Final projection likelihood: -193.7373
1 mode projection failed, trying anyway
New goal: tensor([ 0.1593,  0.4588,  0.7339,  0.7303,  0.0143,  0.5397,  0.9233,  0.9762,
         1.4576,  0.0672,  0.0632,  1.0144,  0.0379, -0.0698, -0.5996],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -195.67269897460938
Adjusted likelihood: -195.67269897460938
Likelihood residual: 0.0
Original likelihood: -218.76425170898438
Adjusted likelihood: -218.76425170898438
Likelihood residual: 0.0
{'index': 218.76425170898438, 'thumb_middle': 195.67269897460938}
Current yaw: tensor([ 0.0432, -0.0808, -0.3833], device='cuda:1')
4 thumb_middle
tensor([ 0.2276,  0.5257,  0.7251,  0.6883, -0.0147,  0.4679,  1.0892,  1.0312,
         1.4300,  0.1682,  0.0839,  0.9678,  0.0432, -0.0808, -0.3833,  0.3673],
       device='cuda:1')
Solve time for step 1 8.777556732005905
Current ori: tensor([ 0.0432, -0.0808, -0.3833], device='cuda:1')
Index force: tensor([0.5854, 0.5918, 0.5958, 0.5861], device='cuda:1')
tensor([ 0.2115,  0.4769,  0.7465,  0.7347, -0.0786,  0.4979,  0.9048,  0.9581,
         1.4151,  0.0748, -0.0103,  0.9827,  0.0567, -0.0686, -0.3834,  0.3589],
       device='cuda:1')
Solve time for step 2 3.5127896500052884
Current ori: tensor([ 0.0567, -0.0686, -0.3834], device='cuda:1')
Index force: tensor([0.5796, 0.5858, 0.5781], device='cuda:1')
tensor([ 0.2182,  0.4935,  0.7378,  0.7235, -0.0780,  0.5170,  0.8909,  0.9623,
         1.4104,  0.0513, -0.0192,  0.9870,  0.0524, -0.0734, -0.3834,  0.3629],
       device='cuda:1')
Solve time for step 3 3.5366250000079162
Current ori: tensor([ 0.0524, -0.0734, -0.3834], device='cuda:1')
Index force: tensor([0.5773, 0.5716], device='cuda:1')
tensor([ 0.2000,  0.4806,  0.7294,  0.7351, -0.0914,  0.5182,  0.8761,  0.9542,
         1.4287,  0.0442, -0.0177,  0.9812,  0.0544, -0.0629, -0.3834,  0.3422],
       device='cuda:1')
Solve time for step 4 3.606706188991666
Current ori: tensor([ 0.0544, -0.0629, -0.3834], device='cuda:1')
Index force: tensor([0.5548], device='cuda:1')
Storing RECOVERY transition: reward=0.0102 (scaled=0.0102), steps=1
Reward stats updated: mean 0.0130 -> 0.0129, std: 0.0735
Collected 124 transitions for RL
SAC Update 1/5: Actor Loss=-0.0011, Q1 Loss=0.5357, Q2 Loss=0.5357, Entropy=0.3320, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2778
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.9199, Q2 Loss=0.9199, Entropy=0.0514, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4466
SAC Update 3/5: Actor Loss=0.0000, Q1 Loss=0.5659, Q2 Loss=0.5659, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2031
SAC Update 4/5: Actor Loss=-0.0058, Q1 Loss=4.4541, Q2 Loss=4.4541, Entropy=0.3432, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9482
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=0.5032, Q2 Loss=0.5032, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5009

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001423
Q1 loss: 1.395791
Q2 loss: 1.395791
Current threshold: -149.8988
Global Scale Offset: 3.7337
Reward stats: mean=0.0129, std=0.0735, count=124
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 1.3958, Q2 Loss: 1.3958, Entropy: 0.1453, Mean TD Error: 1.0753, Threshold: -149.8988
Original likelihood: -211.69882202148438
Adjusted likelihood: -211.69882202148438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 211.2440185546875
Projection step: 1, Loss: 212.94093322753906
Projection step: 2, Loss: 206.83811950683594
Projection step: 3, Loss: 202.91070556640625
Projection step: 4, Loss: 202.78616333007812
Projection step: 5, Loss: 206.85415649414062
Projection step: 6, Loss: 203.11553955078125
Projection step: 7, Loss: 213.18678283691406
Projection step: 8, Loss: 180.50311279296875
Projection step: 9, Loss: 194.6077880859375
Projection step: 10, Loss: 192.0111846923828
Projection step: 11, Loss: 199.837890625
Projection step: 12, Loss: 191.5948486328125
Projection step: 13, Loss: 195.91439819335938
Projection step: 14, Loss: 189.5567169189453
Projection step: 15, Loss: 178.8433837890625
Projection step: 16, Loss: 196.73849487304688
Projection step: 17, Loss: 187.09103393554688
Projection step: 18, Loss: 182.39605712890625
Projection step: 19, Loss: 177.65713500976562
Projection step: 20, Loss: 186.09698486328125
Projection step: 21, Loss: 188.139404296875
Projection step: 22, Loss: 185.3535614013672
Projection step: 23, Loss: 180.59881591796875
Projection step: 24, Loss: 175.98129272460938
Final likelihood: tensor([-169.4578, -179.5313, -153.7555, -179.8147, -196.6432, -177.9950,
        -176.6825, -205.4791, -188.1641, -162.4449, -157.6627, -184.5017,
        -181.9407, -196.7215, -227.3311, -164.3528])
Final projection likelihood: -181.4049
1 mode projection failed, trying anyway
New goal: tensor([ 1.5216e-01,  4.4085e-01,  7.3176e-01,  7.9442e-01,  1.0220e-03,
         5.8488e-01,  8.7244e-01,  9.2655e-01,  1.4909e+00,  6.4070e-03,
         1.2003e-01,  1.0173e+00,  4.7925e-02, -5.6591e-02, -3.4263e-01],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -185.8912811279297
Adjusted likelihood: -185.8912811279297
Likelihood residual: 0.0
Original likelihood: -205.28482055664062
Adjusted likelihood: -205.28482055664062
Likelihood residual: 0.0
{'index': 205.28482055664062, 'thumb_middle': 185.8912811279297}
Current yaw: tensor([ 0.0536, -0.0670, -0.3917], device='cuda:1')
5 thumb_middle
tensor([ 0.2038,  0.4821,  0.7325,  0.7331, -0.0231,  0.5745,  0.9399,  0.9649,
         1.4930,  0.0800,  0.0381,  1.0223,  0.0536, -0.0670, -0.3917,  0.3136],
       device='cuda:1')
Solve time for step 1 9.001178727019578
Current ori: tensor([ 0.0536, -0.0670, -0.3917], device='cuda:1')
Index force: tensor([0.5853, 0.5052, 0.6085, 0.6100], device='cuda:1')
tensor([ 0.2030,  0.4238,  0.7525,  0.8334, -0.0823,  0.5659,  0.8441,  0.9084,
         1.4358, -0.0073,  0.0246,  0.9785,  0.0775, -0.0607, -0.3916,  0.3470],
       device='cuda:1')
Solve time for step 2 3.487455901049543
Current ori: tensor([ 0.0775, -0.0607, -0.3916], device='cuda:1')
Index force: tensor([0.5046, 0.5996, 0.6029], device='cuda:1')
tensor([ 0.2011,  0.4297,  0.7521,  0.8168, -0.0912,  0.5740,  0.8351,  0.8989,
         1.4400, -0.0178,  0.0195,  0.9815,  0.0741, -0.0607, -0.3916,  0.3384],
       device='cuda:1')
Solve time for step 3 3.488545366039034
Current ori: tensor([ 0.0741, -0.0607, -0.3916], device='cuda:1')
Index force: tensor([0.5911, 0.5973], device='cuda:1')
tensor([ 0.1785,  0.4440,  0.7286,  0.7883, -0.1020,  0.5711,  0.8255,  0.8947,
         1.4408, -0.0198,  0.0245,  0.9750,  0.0650, -0.0521, -0.3916,  0.2955],
       device='cuda:1')
Solve time for step 4 3.3877841960056685
Current ori: tensor([ 0.0650, -0.0521, -0.3916], device='cuda:1')
Index force: tensor([0.5822], device='cuda:1')
Storing RECOVERY transition: reward=0.0272 (scaled=0.0272), steps=1
Reward stats updated: mean 0.0129 -> 0.0131, std: 0.0732
Collected 125 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=7.4638, Q2 Loss=7.4638, Entropy=0.0000, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4826
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.5501, Q2 Loss=1.5501, Entropy=0.0452, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2311
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.2814, Q2 Loss=1.2814, Entropy=0.0002, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1632
SAC Update 4/5: Actor Loss=-0.0006, Q1 Loss=0.9852, Q2 Loss=0.9852, Entropy=0.2950, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5827
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.2295, Q2 Loss=1.2295, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9552

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.6%)
Actor update: 0.09s (37.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000143
Q1 loss: 2.502002
Q2 loss: 2.502002
Current threshold: -149.8853
Global Scale Offset: 3.8704
Reward stats: mean=0.0131, std=0.0732, count=125
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.5020, Q2 Loss: 2.5020, Entropy: 0.0681, Mean TD Error: 1.4829, Threshold: -149.8853
Original likelihood: -194.11846923828125
Adjusted likelihood: -194.11846923828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 194.15699768066406
Projection step: 1, Loss: 188.3162078857422
Projection step: 2, Loss: 191.68319702148438
Projection step: 3, Loss: 189.36456298828125
Projection step: 4, Loss: 188.22213745117188
Projection step: 5, Loss: 182.0207061767578
Projection step: 6, Loss: 179.6765899658203
Projection step: 7, Loss: 184.01878356933594
Projection step: 8, Loss: 191.4502410888672
Projection step: 9, Loss: 181.94090270996094
Projection step: 10, Loss: 173.8695831298828
Projection step: 11, Loss: 177.52249145507812
Projection step: 12, Loss: 180.86318969726562
Projection step: 13, Loss: 199.229736328125
Projection step: 14, Loss: 180.69754028320312
Projection step: 15, Loss: 178.76976013183594
Projection step: 16, Loss: 173.75515747070312
Projection step: 17, Loss: 169.54058837890625
Projection step: 18, Loss: 166.83163452148438
Projection step: 19, Loss: 169.31736755371094
Projection step: 20, Loss: 175.9922637939453
Projection step: 21, Loss: 168.626708984375
Projection step: 22, Loss: 166.26742553710938
Projection step: 23, Loss: 167.12669372558594
Projection step: 24, Loss: 165.4926300048828
Final likelihood: tensor([-157.4441, -155.2485, -158.6488, -154.5757, -151.8976, -138.5858,
        -178.4045, -157.1037, -139.5621, -178.8358, -183.3934, -150.9358,
        -150.8940, -157.3467, -188.2415, -177.4223])
Final projection likelihood: -161.1588
1 mode projection failed, trying anyway
New goal: tensor([ 0.1374,  0.4484,  0.7278,  0.7599, -0.0210,  0.5847,  0.8818,  0.8982,
         1.4716, -0.0144,  0.1785,  1.0200,  0.0554, -0.0459, -0.3228],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -163.31085205078125
Adjusted likelihood: -163.31085205078125
Likelihood residual: 0.0
Original likelihood: -190.7295379638672
Adjusted likelihood: -190.7295379638672
Likelihood residual: 0.0
{'index': 190.7295379638672, 'thumb_middle': 163.31085205078125}
Current yaw: tensor([ 0.0613, -0.0548, -0.4100], device='cuda:1')
6 thumb_middle
tensor([ 0.1767,  0.4514,  0.7211,  0.7807, -0.0346,  0.6205,  0.8720,  0.9222,
         1.5000,  0.0049,  0.0889,  1.0183,  0.0613, -0.0548, -0.4100,  0.2627],
       device='cuda:1')
Solve time for step 1 8.821121161978226
Current ori: tensor([ 0.0613, -0.0548, -0.4100], device='cuda:1')
Index force: tensor([0.5788, 0.5902, 0.5721, 0.5699], device='cuda:1')
tensor([ 0.1640,  0.4373,  0.7295,  0.7748, -0.1047,  0.5604,  0.8407,  0.8901,
         1.4233, -0.0565,  0.0692,  0.9774,  0.0639, -0.0447, -0.4099,  0.2936],
       device='cuda:1')
Solve time for step 2 3.713223310012836
Current ori: tensor([ 0.0639, -0.0447, -0.4099], device='cuda:1')
Index force: tensor([0.5796, 0.5638, 0.5627], device='cuda:1')
tensor([ 0.1607,  0.4330,  0.7341,  0.7700, -0.1183,  0.5841,  0.8269,  0.8637,
         1.4132, -0.0511,  0.0732,  0.9915,  0.0641, -0.0429, -0.4099,  0.2894],
       device='cuda:1')
Solve time for step 3 3.268583870958537
Current ori: tensor([ 0.0641, -0.0429, -0.4099], device='cuda:1')
Index force: tensor([0.5553, 0.5557], device='cuda:1')
tensor([ 0.1589,  0.4238,  0.7393,  0.7799, -0.1211,  0.5761,  0.8395,  0.8585,
         1.4127, -0.0405,  0.0834,  0.9748,  0.0674, -0.0413, -0.4099,  0.2908],
       device='cuda:1')
Solve time for step 4 3.329836504010018
Current ori: tensor([ 0.0674, -0.0413, -0.4099], device='cuda:1')
Index force: tensor([0.5497], device='cuda:1')
Storing RECOVERY transition: reward=0.0460 (scaled=0.0460), steps=1
Reward stats updated: mean 0.0131 -> 0.0133, std: 0.0730
Collected 126 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=6.1229, Q2 Loss=6.1229, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4369
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8945, Q2 Loss=0.8945, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8877
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9810, Q2 Loss=0.9810, Entropy=0.0128, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6005
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=2.4524, Q2 Loss=2.4524, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7631
SAC Update 5/5: Actor Loss=0.0000, Q1 Loss=1.0097, Q2 Loss=1.0097, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7943

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (40.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000001
Q1 loss: 2.292086
Q2 loss: 2.292086
Current threshold: -149.8765
Global Scale Offset: 3.9645
Reward stats: mean=0.0133, std=0.0730, count=126
----------------------------------------------
SAC Update - Actor Loss: -0.0000, Q1 Loss: 2.2921, Q2 Loss: 2.2921, Entropy: 0.0026, Mean TD Error: 1.6965, Threshold: -149.8765
Original likelihood: -178.3760223388672
Adjusted likelihood: -178.3760223388672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 172.41250610351562
Projection step: 1, Loss: 173.20782470703125
Projection step: 2, Loss: 170.44467163085938
Projection step: 3, Loss: 167.5625
Projection step: 4, Loss: 162.740966796875
Projection step: 5, Loss: 167.28900146484375
Projection step: 6, Loss: 161.8435821533203
Projection step: 7, Loss: 160.57542419433594
Projection step: 8, Loss: 159.7891387939453
Projection step: 9, Loss: 160.7528076171875
Projection step: 10, Loss: 162.10487365722656
Projection step: 11, Loss: 161.4355926513672
Projection step: 12, Loss: 172.61366271972656
Projection step: 13, Loss: 153.49142456054688
Projection step: 14, Loss: 157.37283325195312
Projection step: 15, Loss: 159.70877075195312
Projection step: 16, Loss: 157.59371948242188
Projection step: 17, Loss: 150.57611083984375
Projection step: 18, Loss: 152.02024841308594
Projection step: 19, Loss: 147.91763305664062
Projection step: 20, Loss: 150.634521484375
Projection step: 21, Loss: 146.8256378173828
Projection step: 22, Loss: 146.78073120117188
Projection step: 23, Loss: 147.02456665039062
Projection step: 24, Loss: 140.5157012939453
Final likelihood: tensor([-128.7189, -142.2813, -176.6783, -144.5797, -140.6059, -136.1260,
        -143.9510, -140.6150, -135.5861, -142.2419, -123.0711, -126.1364,
        -129.2624, -139.0685, -143.2959, -133.1265])
Final projection likelihood: -139.0841
1 mode projection succeeded
New goal: tensor([ 0.1086,  0.4884,  0.6643,  0.7093, -0.0609,  0.5619,  0.8902,  0.9000,
         1.4303,  0.0800,  0.1498,  1.1639,  0.0535, -0.0255, -1.0038],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0033]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -149.05914306640625
Adjusted likelihood: -149.05914306640625
Likelihood residual: 0.0
Original likelihood: -192.3478546142578
Adjusted likelihood: -192.3478546142578
Likelihood residual: 0.0
{'index': 192.3478546142578, 'thumb_middle': 149.05914306640625}
Current yaw: tensor([ 0.0596, -0.0315, -0.4225], device='cuda:1')
7 thumb_middle
tensor([ 0.1340,  0.4363,  0.7079,  0.7610, -0.0777,  0.6185,  0.8688,  0.9061,
         1.4954, -0.0201,  0.1390,  1.0209,  0.0596, -0.0315, -0.4225,  0.2529],
       device='cuda:1')
Solve time for step 1 9.204922339995392
Current ori: tensor([ 0.0596, -0.0315, -0.4225], device='cuda:1')
Index force: tensor([0.5606, 0.5171, 0.5956, 0.5955], device='cuda:1')
tensor([ 0.1371,  0.4430,  0.6932,  0.7783, -0.1464,  0.5568,  0.8476,  0.8794,
         1.3762,  0.0231,  0.0499,  1.0999,  0.0603, -0.0312, -0.4225,  0.2734],
       device='cuda:1')
Solve time for step 2 3.774488417955581
Current ori: tensor([ 0.0603, -0.0312, -0.4225], device='cuda:1')
Index force: tensor([0.5152, 0.5867, 0.5876], device='cuda:1')
tensor([ 0.1338,  0.4493,  0.6900,  0.7610, -0.1619,  0.5652,  0.8477,  0.8779,
         1.3663,  0.0425,  0.0480,  1.1025,  0.0566, -0.0302, -0.4225,  0.2628],
       device='cuda:1')
Solve time for step 3 3.3441972619621083
Current ori: tensor([ 0.0566, -0.0302, -0.4225], device='cuda:1')
Index force: tensor([0.5757, 0.5796], device='cuda:1')
tensor([ 0.1101,  0.4736,  0.6543,  0.7223, -0.1771,  0.5581,  0.8554,  0.8653,
         1.3648,  0.0444,  0.0367,  1.1316,  0.0452, -0.0198, -0.4225,  0.2275],
       device='cuda:1')
Solve time for step 4 3.3219741220236756
Current ori: tensor([ 0.0452, -0.0198, -0.4225], device='cuda:1')
Index force: tensor([0.5617], device='cuda:1')
Storing RECOVERY transition: reward=0.0590 (scaled=0.0590), steps=1
Reward stats updated: mean 0.0133 -> 0.0137, std: 0.0728
Collected 127 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=3.4730, Q2 Loss=3.4730, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8169
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9109, Q2 Loss=0.9109, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8933
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.7864, Q2 Loss=1.7864, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7751
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6831, Q2 Loss=0.6831, Entropy=0.0001, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6358
SAC Update 5/5: Actor Loss=-0.0026, Q1 Loss=2.1157, Q2 Loss=2.1157, Entropy=0.3631, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7172

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (18.9%)
Q2 update: 0.06s (20.2%)
Actor update: 0.13s (43.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000529
Q1 loss: 1.793808
Q2 loss: 1.793808
Current threshold: -149.8699
Global Scale Offset: 4.0410
Reward stats: mean=0.0137, std=0.0728, count=127
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.7938, Q2 Loss: 1.7938, Entropy: 0.0727, Mean TD Error: 1.5677, Threshold: -149.8699
Original likelihood: -166.11038208007812
Adjusted likelihood: -166.11038208007812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0009)
State is out of distribution
Projection step: 0, Loss: 160.88365173339844
Projection step: 1, Loss: 153.359375
Projection step: 2, Loss: 148.63014221191406
Projection step: 3, Loss: 148.70184326171875
Projection step: 4, Loss: 141.84835815429688
Projection step: 5, Loss: 140.77964782714844
Projection step: 6, Loss: 134.494140625
Projection step: 7, Loss: 132.78643798828125
Projection step: 8, Loss: 129.20968627929688
Projection step: 9, Loss: 129.19021606445312
Projection step: 10, Loss: 126.96611022949219
Projection step: 11, Loss: 116.86305236816406
Projection step: 12, Loss: 118.56341552734375
Projection step: 13, Loss: 114.91439819335938
Projection step: 14, Loss: 115.37252807617188
Projection step: 15, Loss: 109.7322006225586
Projection step: 16, Loss: 101.39013671875
Final likelihood: tensor([ -98.9305, -112.0296,  -96.9411, -100.4370,  -99.9077,  -96.6032,
         -98.5159, -109.2781,  -98.2403,  -92.6778, -106.9571, -103.3562,
        -108.7315,  -97.8483,  -94.1302, -107.6577])
Final projection likelihood: -101.3901
1 mode projection succeeded
New goal: tensor([ 0.0819,  0.5050,  0.6226,  0.6938, -0.0799,  0.5467,  0.8622,  0.9227,
         1.3816,  0.1400,  0.1540,  1.1612,  0.0462, -0.0076, -1.0834],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -131.6804962158203
Adjusted likelihood: -131.6804962158203
Likelihood residual: 0.0
Original likelihood: -160.74765014648438
Adjusted likelihood: -160.74765014648438
Likelihood residual: 0.0
{'index': 160.74765014648438, 'thumb_middle': 131.6804962158203}
Current yaw: tensor([ 0.0519, -0.0076, -0.4285], device='cuda:1')
8 thumb_middle
tensor([ 0.0844,  0.4455,  0.6602,  0.7379, -0.1280,  0.5987,  0.8850,  0.9129,
         1.4389,  0.0741,  0.1121,  1.1497,  0.0519, -0.0076, -0.4285,  0.2006],
       device='cuda:1')
Solve time for step 1 8.858511950005777
Current ori: tensor([ 0.0519, -0.0076, -0.4285], device='cuda:1')
Index force: tensor([0.5538, 0.5111, 0.6013, 0.5959], device='cuda:1')
tensor([ 0.0832,  0.4474,  0.6505,  0.7494, -0.1851,  0.5477,  0.8245,  0.8966,
         1.3429,  0.1068,  0.0735,  1.1313,  0.0535, -0.0047, -0.4285,  0.2149],
       device='cuda:1')
Solve time for step 2 3.6697071449598297
Current ori: tensor([ 0.0535, -0.0047, -0.4285], device='cuda:1')
Index force: tensor([0.5097, 0.5935, 0.5897], device='cuda:1')
tensor([ 0.0830,  0.4543,  0.6524,  0.7260, -0.1825,  0.5416,  0.8233,  0.8839,
         1.3403,  0.1002,  0.0770,  1.1292,  0.0492, -0.0052, -0.4285,  0.2050],
       device='cuda:1')
Solve time for step 3 3.6598639379953966
Current ori: tensor([ 0.0492, -0.0052, -0.4285], device='cuda:1')
Index force: tensor([0.5817, 0.5813], device='cuda:1')
tensor([ 0.0897,  0.4860,  0.6198,  0.7192, -0.1775,  0.5470,  0.8302,  0.8905,
         1.3329,  0.1074,  0.0670,  1.1189,  0.0414, -0.0090, -0.4285,  0.2117],
       device='cuda:1')
Solve time for step 4 3.4008380240411498
Current ori: tensor([ 0.0414, -0.0090, -0.4285], device='cuda:1')
Index force: tensor([0.5675], device='cuda:1')
Storing RECOVERY transition: reward=0.0692 (scaled=0.0692), steps=1
Reward stats updated: mean 0.0137 -> 0.0141, std: 0.0727
Collected 128 transitions for RL
SAC Update 1/5: Actor Loss=-0.0008, Q1 Loss=0.8522, Q2 Loss=0.8522, Entropy=0.1345, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7737
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7337, Q2 Loss=0.7337, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2673
SAC Update 3/5: Actor Loss=-0.0027, Q1 Loss=2.4645, Q2 Loss=2.4645, Entropy=0.3011, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8646
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=0.6134, Q2 Loss=0.6134, Entropy=0.3441, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6497
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6075, Q2 Loss=0.6075, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5032

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000941
Q1 loss: 1.054270
Q2 loss: 1.054270
Current threshold: -149.8597
Global Scale Offset: 4.2365
Reward stats: mean=0.0141, std=0.0727, count=128
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 1.0543, Q2 Loss: 1.0543, Entropy: 0.1559, Mean TD Error: 0.8117, Threshold: -149.8597
Original likelihood: -141.92041015625
Adjusted likelihood: -141.92041015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9287)
Current yaw: tensor([ 0.0426, -0.0061, -0.4351], device='cuda:1')
9 turn
Sampling time 3.6189835959812626
tensor([ 0.0808,  0.4769,  0.6278,  0.7108, -0.1163,  0.5802,  0.8763,  0.9308,
         1.3996,  0.1346,  0.1156,  1.1665,  0.0426, -0.0061, -0.4351,  0.2117],
       device='cuda:1')
Original likelihood: -132.42095947265625
Adjusted likelihood: -132.42095947265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9994)
Solve time for step 1 13.916616533009801
Current ori: tensor([ 0.0426, -0.0061, -0.4351], device='cuda:1')
Middle force: tensor([0.5725, 0.6250, 0.5041, 2.2844, 1.1229, 0.5188, 0.7463, 0.5936, 0.5540,
        0.6455, 0.5480, 0.5893], device='cuda:1')
Thumb force: tensor([0.5869, 0.6829, 1.3013, 1.4991, 1.1473, 0.5627, 0.7573, 0.5204, 1.2148,
        0.5513, 0.5434, 0.5940], device='cuda:1')
Index force: tensor([0.5867, 0.5355, 0.5552, 1.1106, 0.5013, 0.6088, 0.8756, 0.7721, 0.5519,
        0.5279, 0.6141, 0.6142], device='cuda:1')
Storing NORMAL transition: reward=0.0001 (scaled=0.0001), steps=1
Reward stats updated: mean 0.0141 -> 0.0140, std: 0.0724
Collected 129 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.4210, Q2 Loss=1.4210, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2458
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8174, Q2 Loss=0.8174, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4476
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.5835, Q2 Loss=1.5835, Entropy=0.0002, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7224
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6116, Q2 Loss=0.6116, Entropy=0.0106, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3208
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.1622, Q2 Loss=1.1622, Entropy=0.0804, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9180

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.8%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (18.4%)
Actor update: 0.08s (40.5%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000062
Q1 loss: 1.119140
Q2 loss: 1.119140
Current threshold: -149.8505
Global Scale Offset: 4.3879
Reward stats: mean=0.0140, std=0.0724, count=129
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 1.1191, Q2 Loss: 1.1191, Entropy: 0.0182, Mean TD Error: 0.9309, Threshold: -149.8505
tensor([ 0.1725,  0.4449,  0.8071,  0.6069, -0.0229,  0.6748,  0.8285,  0.9271,
         1.3235,  0.1324,  0.1229,  1.0998,  0.0299, -0.0732, -0.4394,  0.0550],
       device='cuda:1')
Original likelihood: -179.5352020263672
Adjusted likelihood: -179.5352020263672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 174.9232940673828
Projection step: 1, Loss: 172.06301879882812
Projection step: 2, Loss: 175.0777130126953
Projection step: 3, Loss: 165.22555541992188
Projection step: 4, Loss: 177.69094848632812
Projection step: 5, Loss: 192.6981658935547
Projection step: 6, Loss: 178.7492218017578
Projection step: 7, Loss: 170.1872100830078
Projection step: 8, Loss: 166.86660766601562
Projection step: 9, Loss: 170.92572021484375
Projection step: 10, Loss: 189.22967529296875
Projection step: 11, Loss: 183.2032012939453
Projection step: 12, Loss: 172.42247009277344
Projection step: 13, Loss: 161.4417724609375
Projection step: 14, Loss: 178.34698486328125
Projection step: 15, Loss: 181.3050994873047
Projection step: 16, Loss: 167.65890502929688
Projection step: 17, Loss: 169.8162078857422
Projection step: 18, Loss: 191.77801513671875
Projection step: 19, Loss: 166.28701782226562
Projection step: 20, Loss: 161.31344604492188
Projection step: 21, Loss: 159.1463165283203
Projection step: 22, Loss: 153.59686279296875
Projection step: 23, Loss: 164.46080017089844
Projection step: 24, Loss: 166.6783447265625
Final likelihood: tensor([-138.2845, -164.0934, -184.7900, -139.9589, -154.2181, -170.0498,
        -138.5837, -156.3528, -151.0213, -145.1884, -206.8849, -173.6822,
        -151.3644, -187.1597, -160.7967, -179.2421])
Final projection likelihood: -162.6044
1 mode projection failed, trying anyway
New goal: tensor([ 0.1285,  0.4615,  0.7245,  0.6681, -0.0060,  0.6423,  0.8313,  0.8479,
         1.4298,  0.0597,  0.1700,  1.0356,  0.0237, -0.0624, -0.4431],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -173.16705322265625
Adjusted likelihood: -173.16705322265625
Likelihood residual: 0.0
Original likelihood: -210.55001831054688
Adjusted likelihood: -210.55001831054688
Likelihood residual: 0.0
{'index': 210.55001831054688, 'thumb_middle': 173.16705322265625}
Current yaw: tensor([ 0.0299, -0.0732, -0.4394], device='cuda:1')
10 thumb_middle
tensor([ 0.1725,  0.4449,  0.8071,  0.6069, -0.0229,  0.6748,  0.8285,  0.9271,
         1.3235,  0.1324,  0.1229,  1.0998,  0.0299, -0.0732, -0.4394,  0.0550],
       device='cuda:1')
Solve time for step 1 8.772158281004522
Current ori: tensor([ 0.0299, -0.0732, -0.4394], device='cuda:1')
Index force: tensor([0.5484, 0.5000, 0.6237, 0.5038], device='cuda:1')
tensor([ 0.1765,  0.4708,  0.7333,  0.6986, -0.0829,  0.6384,  0.7988,  0.8406,
         1.3380,  0.0394,  0.0509,  0.9951,  0.0339, -0.0751, -0.4394,  0.1144],
       device='cuda:1')
Solve time for step 2 3.5465631810366176
Current ori: tensor([ 0.0339, -0.0751, -0.4394], device='cuda:1')
Index force: tensor([0.5000, 0.6226, 0.5001], device='cuda:1')
tensor([ 0.1765,  0.4594,  0.7427,  0.7092, -0.0883,  0.6451,  0.8005,  0.8276,
         1.3551,  0.0266,  0.0439,  0.9829,  0.0369, -0.0755, -0.4394,  0.0987],
       device='cuda:1')
Solve time for step 3 3.554976074025035
Current ori: tensor([ 0.0369, -0.0755, -0.4394], device='cuda:1')
Index force: tensor([0.5001, 0.5500], device='cuda:1')
tensor([ 0.1703,  0.4610,  0.7451,  0.6868, -0.0830,  0.6423,  0.7905,  0.8213,
         1.3452,  0.0269,  0.0598,  0.9759,  0.0332, -0.0728, -0.4394,  0.0820],
       device='cuda:1')
Solve time for step 4 3.3339772109757178
Current ori: tensor([ 0.0332, -0.0728, -0.4394], device='cuda:1')
Index force: tensor([0.5573], device='cuda:1')
Storing RECOVERY transition: reward=0.0025 (scaled=0.0025), steps=1
Reward stats updated: mean 0.0140 -> 0.0139, std: 0.0721
Collected 130 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.1037, Q2 Loss=1.1037, Entropy=0.0003, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9938
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=4.9987, Q2 Loss=4.9987, Entropy=0.0002, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2282
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.5637, Q2 Loss=0.5637, Entropy=0.0001, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7806
SAC Update 4/5: Actor Loss=-0.0052, Q1 Loss=0.8489, Q2 Loss=0.8489, Entropy=0.3372, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7495
SAC Update 5/5: Actor Loss=-0.0012, Q1 Loss=0.6612, Q2 Loss=0.6612, Entropy=0.2583, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4915

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001281
Q1 loss: 1.635261
Q2 loss: 1.635261
Current threshold: -149.8410
Global Scale Offset: 4.5468
Reward stats: mean=0.0139, std=0.0721, count=130
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.6353, Q2 Loss: 1.6353, Entropy: 0.1192, Mean TD Error: 1.4487, Threshold: -149.8410
Original likelihood: -164.32981872558594
Adjusted likelihood: -164.32981872558594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0058)
State is out of distribution
Projection step: 0, Loss: 157.65460205078125
Projection step: 1, Loss: 162.03445434570312
Projection step: 2, Loss: 160.67897033691406
Projection step: 3, Loss: 173.5999298095703
Projection step: 4, Loss: 170.7546844482422
Projection step: 5, Loss: 162.16903686523438
Projection step: 6, Loss: 163.24627685546875
Projection step: 7, Loss: 165.429931640625
Projection step: 8, Loss: 161.945068359375
Projection step: 9, Loss: 163.99676513671875
Projection step: 10, Loss: 158.2241973876953
Projection step: 11, Loss: 151.04388427734375
Projection step: 12, Loss: 159.57498168945312
Projection step: 13, Loss: 155.1911163330078
Projection step: 14, Loss: 155.1897430419922
Projection step: 15, Loss: 154.3645477294922
Projection step: 16, Loss: 155.08213806152344
Projection step: 17, Loss: 151.76138305664062
Projection step: 18, Loss: 147.14999389648438
Projection step: 19, Loss: 147.67919921875
Projection step: 20, Loss: 148.24386596679688
Projection step: 21, Loss: 150.55702209472656
Projection step: 22, Loss: 148.516357421875
Projection step: 23, Loss: 144.57852172851562
Projection step: 24, Loss: 143.18539428710938
Final likelihood: tensor([-146.6562, -149.3093, -139.0629, -135.2948, -182.4461, -143.6741,
        -133.5920, -126.9590, -144.6176, -127.3102, -179.3034, -130.8029,
        -143.2541, -137.2164, -133.7028, -127.6990])
Final projection likelihood: -142.5563
1 mode projection succeeded
New goal: tensor([ 0.1146,  0.4782,  0.6827,  0.7079, -0.0300,  0.6079,  0.8677,  0.8233,
         1.4155,  0.0709,  0.1589,  1.0674,  0.0277, -0.0459, -1.1235],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0031]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -157.92410278320312
Adjusted likelihood: -157.92410278320312
Likelihood residual: 0.0
Original likelihood: -170.87905883789062
Adjusted likelihood: -170.87905883789062
Likelihood residual: 0.0
{'index': 170.87905883789062, 'thumb_middle': 157.92410278320312}
Current yaw: tensor([ 0.0339, -0.0562, -0.4400], device='cuda:1')
11 thumb_middle
tensor([ 0.1397,  0.4464,  0.7329,  0.6899, -0.0388,  0.6811,  0.8270,  0.8458,
         1.4146,  0.0490,  0.1359,  1.0196,  0.0339, -0.0562, -0.4400,  0.0704],
       device='cuda:1')
Solve time for step 1 9.095170326996595
Current ori: tensor([ 0.0339, -0.0562, -0.4400], device='cuda:1')
Index force: tensor([0.5922, 0.5971, 0.5866, 0.5982], device='cuda:1')
tensor([ 0.1174,  0.4609,  0.6875,  0.7004, -0.1161,  0.6065,  0.8226,  0.8034,
         1.3545,  0.0362,  0.0621,  1.0182,  0.0299, -0.0433, -0.4400,  0.0426],
       device='cuda:1')
Solve time for step 2 3.529805631027557
Current ori: tensor([ 0.0299, -0.0433, -0.4400], device='cuda:1')
Index force: tensor([0.5922, 0.5836, 0.5954], device='cuda:1')
tensor([ 0.1205,  0.4626,  0.6827,  0.7117, -0.1226,  0.6083,  0.8301,  0.7991,
         1.3562,  0.0364,  0.0520,  1.0204,  0.0311, -0.0449, -0.4400,  0.0533],
       device='cuda:1')
Solve time for step 3 3.3825707779615186
Current ori: tensor([ 0.0311, -0.0449, -0.4400], device='cuda:1')
Index force: tensor([0.5770, 0.5904], device='cuda:1')
tensor([ 0.1116,  0.4535,  0.6822,  0.7202, -0.1299,  0.6044,  0.8292,  0.7968,
         1.3596,  0.0382,  0.0552,  1.0252,  0.0334, -0.0392, -0.4400,  0.0391],
       device='cuda:1')
Solve time for step 4 3.2891595420078374
Current ori: tensor([ 0.0334, -0.0392, -0.4400], device='cuda:1')
Index force: tensor([0.5875], device='cuda:1')
Storing RECOVERY transition: reward=0.0113 (scaled=0.0113), steps=1
Reward stats updated: mean 0.0139 -> 0.0139, std: 0.0719
Collected 131 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=3.1055, Q2 Loss=3.1055, Entropy=0.0004, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5526
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5106, Q2 Loss=0.5106, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1005
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=3.4516, Q2 Loss=3.4516, Entropy=0.0289, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4279
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=1.0076, Q2 Loss=1.0076, Entropy=0.0849, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9736
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.0262, Q2 Loss=2.0262, Entropy=0.0012, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8949

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000055
Q1 loss: 2.020293
Q2 loss: 2.020293
Current threshold: -149.8320
Global Scale Offset: 4.7494
Reward stats: mean=0.0139, std=0.0719, count=131
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 2.0203, Q2 Loss: 2.0203, Entropy: 0.0231, Mean TD Error: 1.3899, Threshold: -149.8320
Original likelihood: -149.37899780273438
Adjusted likelihood: -149.37899780273438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5304)
State is out of distribution
Projection step: 0, Loss: 140.56747436523438
Projection step: 1, Loss: 150.085205078125
Projection step: 2, Loss: 144.45999145507812
Projection step: 3, Loss: 141.7738037109375
Projection step: 4, Loss: 138.49278259277344
Projection step: 5, Loss: 144.35189819335938
Projection step: 6, Loss: 136.50865173339844
Projection step: 7, Loss: 129.0430908203125
Projection step: 8, Loss: 134.56033325195312
Projection step: 9, Loss: 132.74380493164062
Projection step: 10, Loss: 131.55148315429688
Projection step: 11, Loss: 129.04718017578125
Projection step: 12, Loss: 130.25308227539062
Projection step: 13, Loss: 130.486083984375
Projection step: 14, Loss: 135.1612548828125
Projection step: 15, Loss: 122.52635955810547
Projection step: 16, Loss: 115.24154663085938
Projection step: 17, Loss: 124.25943756103516
Projection step: 18, Loss: 116.21612548828125
Projection step: 19, Loss: 121.76701354980469
Projection step: 20, Loss: 117.1749267578125
Projection step: 21, Loss: 115.86050415039062
Projection step: 22, Loss: 112.62956237792969
Projection step: 23, Loss: 110.36380004882812
Projection step: 24, Loss: 108.34588623046875
Final likelihood: tensor([-101.2953, -108.6904, -103.8741, -105.8861, -107.8618, -106.9071,
        -107.2355, -104.6485, -107.6045, -106.2222, -103.8108, -105.3878,
        -115.2832, -118.6105, -119.4110, -102.8333])
Final projection likelihood: -107.8476
1 mode projection succeeded
New goal: tensor([ 0.0872,  0.5219,  0.6405,  0.6459, -0.0457,  0.5639,  0.8753,  0.8114,
         1.3585,  0.1569,  0.1469,  1.1201,  0.0235, -0.0260, -1.4014],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0032]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -141.14834594726562
Adjusted likelihood: -141.14834594726562
Likelihood residual: 0.0
Original likelihood: -162.15737915039062
Adjusted likelihood: -162.15737915039062
Likelihood residual: 0.0
{'index': 162.15737915039062, 'thumb_middle': 141.14834594726562}
Current yaw: tensor([ 0.0292, -0.0345, -0.4467], device='cuda:1')
12 thumb_middle
tensor([ 0.0984,  0.4675,  0.6628,  0.6957, -0.0735,  0.6431,  0.8666,  0.8178,
         1.4273,  0.0679,  0.1177,  1.0603,  0.0292, -0.0345, -0.4467,  0.0778],
       device='cuda:1')
Solve time for step 1 8.823934646963608
Current ori: tensor([ 0.0292, -0.0345, -0.4467], device='cuda:1')
Index force: tensor([0.5772, 0.6004, 0.5925, 0.5935], device='cuda:1')
tensor([ 0.0977,  0.4720,  0.6616,  0.6840, -0.1214,  0.5692,  0.8401,  0.7898,
         1.3200,  0.1167,  0.0621,  1.0740,  0.0247, -0.0339, -0.4467,  0.0231],
       device='cuda:1')
Solve time for step 2 3.6593691789894365
Current ori: tensor([ 0.0247, -0.0339, -0.4467], device='cuda:1')
Index force: tensor([0.5880, 0.5834, 0.5855], device='cuda:1')
tensor([ 0.0825,  0.5100,  0.6179,  0.6412, -0.1373,  0.5641,  0.8550,  0.7825,
         1.3092,  0.1259,  0.0585,  1.0833,  0.0099, -0.0273, -0.4467, -0.0280],
       device='cuda:1')
Solve time for step 3 3.3698505929787643
Current ori: tensor([ 0.0099, -0.0273, -0.4467], device='cuda:1')
Index force: tensor([0.5713, 0.5751], device='cuda:1')
tensor([ 0.0835,  0.4950,  0.6325,  0.6543, -0.1344,  0.5727,  0.8363,  0.7923,
         1.3075,  0.1205,  0.0599,  1.0884,  0.0152, -0.0273, -0.4467, -0.0181],
       device='cuda:1')
Solve time for step 4 3.297447675955482
Current ori: tensor([ 0.0152, -0.0273, -0.4467], device='cuda:1')
Index force: tensor([0.5672], device='cuda:1')
Storing RECOVERY transition: reward=0.0139 (scaled=0.0139), steps=1
Reward stats updated: mean 0.0139 -> 0.0139, std: 0.0716
Collected 132 transitions for RL
SAC Update 1/5: Actor Loss=0.0000, Q1 Loss=1.3073, Q2 Loss=1.3073, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1174
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5578, Q2 Loss=0.5578, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2062
SAC Update 3/5: Actor Loss=-0.0054, Q1 Loss=0.6744, Q2 Loss=0.6744, Entropy=0.5024, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2011
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6321, Q2 Loss=0.6321, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1021
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.6064, Q2 Loss=1.6064, Entropy=0.0014, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1726

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001085
Q1 loss: 0.955596
Q2 loss: 0.955596
Current threshold: -149.8322
Global Scale Offset: 4.9472
Reward stats: mean=0.0139, std=0.0716, count=132
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 0.9556, Q2 Loss: 0.9556, Entropy: 0.1008, Mean TD Error: 0.5599, Threshold: -149.8322
Original likelihood: -115.01461791992188
Adjusted likelihood: -115.01461791992188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0131, -0.0241, -0.4481], device='cuda:1')
13 turn
Sampling time 3.6169581370195374
tensor([ 0.0709,  0.5100,  0.6102,  0.6337, -0.0769,  0.6080,  0.8910,  0.8011,
         1.3733,  0.1467,  0.1158,  1.1221,  0.0131, -0.0241, -0.4481,  0.0347],
       device='cuda:1')
Original likelihood: -114.27090454101562
Adjusted likelihood: -114.27090454101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.040262932947371
Current ori: tensor([ 0.0131, -0.0241, -0.4481], device='cuda:1')
Middle force: tensor([0.5267, 0.6985, 0.5645, 0.5624, 0.5698, 0.8641, 0.5304, 0.5191, 0.5409,
        0.5995, 0.5672, 0.5711], device='cuda:1')
Thumb force: tensor([0.5522, 0.5570, 0.5338, 0.6618, 0.5416, 1.3327, 0.5273, 0.5589, 0.5608,
        0.5691, 0.5539, 0.5759], device='cuda:1')
Index force: tensor([0.5098, 0.5757, 0.6029, 0.5469, 0.5958, 0.5634, 0.5360, 0.6579, 0.5488,
        0.6152, 0.6071, 0.6146], device='cuda:1')
Storing NORMAL transition: reward=0.1111 (scaled=0.1111), steps=1
Reward stats updated: mean 0.0139 -> 0.0146, std: 0.0718
Collected 133 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.3614, Q2 Loss=2.3614, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7917
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0442, Q2 Loss=1.0442, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1499
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.3740, Q2 Loss=1.3740, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1071
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=1.5720, Q2 Loss=1.5720, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5402
SAC Update 5/5: Actor Loss=-0.0048, Q1 Loss=1.2502, Q2 Loss=1.2502, Entropy=0.3450, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9886

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.4%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (21.9%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000959
Q1 loss: 1.520373
Q2 loss: 1.520373
Current threshold: -149.8336
Global Scale Offset: 5.1034
Reward stats: mean=0.0146, std=0.0718, count=133
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 1.5204, Q2 Loss: 1.5204, Entropy: 0.0690, Mean TD Error: 1.5155, Threshold: -149.8336
tensor([ 0.0614,  0.5200,  0.5712,  0.6670, -0.0900,  0.5888,  0.8919,  0.8550,
         1.3561,  0.2077,  0.1851,  0.9999,  0.0112, -0.0177, -0.5590,  0.1282],
       device='cuda:1')
Original likelihood: -118.9056396484375
Adjusted likelihood: -118.9056396484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 5.582705571956467
Current ori: tensor([ 0.0112, -0.0177, -0.5590], device='cuda:1')
Middle force: tensor([0.9094, 0.5843, 0.5658, 0.8535, 0.8925, 0.5728, 0.7374, 0.5706, 0.5539,
        0.8130, 0.8309], device='cuda:1')
Thumb force: tensor([0.5391, 0.9571, 0.9661, 0.5648, 0.5810, 0.5900, 0.7196, 0.8883, 0.5686,
        0.6827, 0.5684], device='cuda:1')
Index force: tensor([0.9428, 0.5426, 0.5077, 0.5676, 0.5486, 0.6485, 0.5444, 0.5676, 0.5783,
        0.5069, 0.5328], device='cuda:1')
Storing NORMAL transition: reward=0.0774 (scaled=0.0774), steps=1
Reward stats updated: mean 0.0146 -> 0.0151, std: 0.0718
Collected 134 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8285, Q2 Loss=0.8285, Entropy=0.0006, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8550
SAC Update 2/5: Actor Loss=-0.0025, Q1 Loss=1.9490, Q2 Loss=1.9490, Entropy=0.3150, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6913
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=1.0111, Q2 Loss=1.0111, Entropy=0.1065, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9915
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.7788, Q2 Loss=0.7788, Entropy=0.1946, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4167
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.1518, Q2 Loss=1.1518, Entropy=0.0276, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9983

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (18.7%)
Q2 update: 0.06s (20.6%)
Actor update: 0.11s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000712
Q1 loss: 1.143845
Q2 loss: 1.143845
Current threshold: -149.8261
Global Scale Offset: 5.2957
Reward stats: mean=0.0151, std=0.0718, count=134
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 1.1438, Q2 Loss: 1.1438, Entropy: 0.1289, Mean TD Error: 0.9906, Threshold: -149.8261
tensor([ 2.7866e-02,  5.3025e-01,  5.7948e-01,  5.6215e-01, -2.3274e-01,
         6.8292e-01,  8.8596e-01,  9.4564e-01,  1.3968e+00,  2.2334e-01,
         2.2928e-01,  8.5636e-01, -2.5668e-03,  2.9728e-04, -6.3588e-01,
         1.0262e-01], device='cuda:1')
Original likelihood: -198.08572387695312
Adjusted likelihood: -198.08572387695312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 185.3096466064453
Projection step: 1, Loss: 184.07623291015625
Projection step: 2, Loss: 172.41452026367188
Projection step: 3, Loss: 172.62503051757812
Projection step: 4, Loss: 162.42486572265625
Projection step: 5, Loss: 166.63284301757812
Projection step: 6, Loss: 148.98536682128906
Projection step: 7, Loss: 161.70144653320312
Projection step: 8, Loss: 154.3194122314453
Projection step: 9, Loss: 148.2057647705078
Projection step: 10, Loss: 138.14598083496094
Projection step: 11, Loss: 138.00634765625
Projection step: 12, Loss: 130.0245819091797
Projection step: 13, Loss: 128.94386291503906
Projection step: 14, Loss: 129.36949157714844
Projection step: 15, Loss: 111.30732727050781
Projection step: 16, Loss: 112.6729736328125
Projection step: 17, Loss: 105.72052764892578
Projection step: 18, Loss: 99.35127258300781
Final likelihood: tensor([ -86.8707, -102.6746,  -96.5278,  -99.1986, -113.8046,  -96.4489,
         -95.8843,  -79.6701, -120.0665,  -97.0773, -104.9278, -100.8031,
         -98.1606, -107.0726,  -88.2470, -102.1856])
Final projection likelihood: -99.3513
1 mode projection succeeded
New goal: tensor([ 5.0832e-02,  5.3461e-01,  6.2680e-01,  5.8019e-01, -1.2228e-01,
         6.2688e-01,  8.8704e-01,  7.9341e-01,  1.3363e+00,  2.0681e-01,
         1.9904e-01,  1.1078e+00,  6.0348e-04,  9.4547e-03, -9.9968e-01],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -130.27574157714844
Adjusted likelihood: -130.27574157714844
Likelihood residual: 0.0
Original likelihood: -182.41903686523438
Adjusted likelihood: -182.41903686523438
Likelihood residual: 0.0
{'index': 182.41903686523438, 'thumb_middle': 130.27574157714844}
Current yaw: tensor([-2.5668e-03,  2.9728e-04, -6.3588e-01], device='cuda:1')
14 thumb_middle
tensor([ 2.7866e-02,  5.3025e-01,  5.7948e-01,  5.6215e-01, -2.3274e-01,
         6.8292e-01,  8.8596e-01,  9.4564e-01,  1.3968e+00,  2.2334e-01,
         2.2928e-01,  8.5636e-01, -2.5668e-03,  2.9728e-04, -6.3588e-01,
         1.0262e-01], device='cuda:1')
Solve time for step 1 8.7736127259559
Current ori: tensor([-2.5668e-03,  2.9728e-04, -6.3588e-01], device='cuda:1')
Index force: tensor([0.5400, 0.5000, 0.6082, 0.6008], device='cuda:1')
tensor([ 0.0246,  0.5260,  0.5785,  0.5695, -0.2401,  0.6174,  0.8421,  0.7928,
         1.2897,  0.1833,  0.1367,  1.0380, -0.0018,  0.0021, -0.6359,  0.0987],
       device='cuda:1')
Solve time for step 2 3.521609431016259
Current ori: tensor([-0.0018,  0.0021, -0.6359], device='cuda:1')
Index force: tensor([0.5000, 0.6026, 0.5964], device='cuda:1')
tensor([ 0.0228,  0.5230,  0.5874,  0.5571, -0.2379,  0.6204,  0.8403,  0.7698,
         1.2837,  0.1761,  0.1236,  1.0745, -0.0023,  0.0031, -0.6359,  0.0931],
       device='cuda:1')
Solve time for step 3 3.3671447719680145
Current ori: tensor([-0.0023,  0.0031, -0.6359], device='cuda:1')
Index force: tensor([0.5971, 0.5934], device='cuda:1')
tensor([ 0.0386,  0.5145,  0.6070,  0.5702, -0.2268,  0.6283,  0.8479,  0.7675,
         1.2768,  0.1731,  0.1123,  1.0767,  0.0016, -0.0056, -0.6359,  0.1208],
       device='cuda:1')
Solve time for step 4 3.3161706349928863
Current ori: tensor([ 0.0016, -0.0056, -0.6359], device='cuda:1')
Index force: tensor([0.5798], device='cuda:1')
Storing RECOVERY transition: reward=-0.0042 (scaled=-0.0021), steps=2
Reward stats updated: mean 0.0151 -> 0.0150, std: 0.0715
Collected 135 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.0523, Q2 Loss=2.0523, Entropy=0.0027, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6818
SAC Update 2/5: Actor Loss=-0.0011, Q1 Loss=0.9778, Q2 Loss=0.9778, Entropy=0.3171, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2911
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6596, Q2 Loss=0.6596, Entropy=0.0021, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2549
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.9485, Q2 Loss=0.9485, Entropy=0.1155, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9528
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.5218, Q2 Loss=1.5218, Entropy=0.0066, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5631

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000281
Q1 loss: 1.231990
Q2 loss: 1.231990
Current threshold: -149.8195
Global Scale Offset: 5.5053
Reward stats: mean=0.0150, std=0.0715, count=135
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.2320, Q2 Loss: 1.2320, Entropy: 0.0888, Mean TD Error: 1.3487, Threshold: -149.8195
Original likelihood: -145.28338623046875
Adjusted likelihood: -145.28338623046875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7501)
Current yaw: tensor([ 0.0051,  0.0030, -0.6317], device='cuda:1')
15 turn
Sampling time 3.6212128889746964
tensor([ 0.0229,  0.5058,  0.6031,  0.5740, -0.1717,  0.6648,  0.8808,  0.7869,
         1.3455,  0.1997,  0.1766,  1.1127,  0.0051,  0.0030, -0.6317,  0.1126],
       device='cuda:1')
Original likelihood: -140.81246948242188
Adjusted likelihood: -140.81246948242188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9098)
Solve time for step 1 14.005321710021235
Current ori: tensor([ 0.0051,  0.0030, -0.6317], device='cuda:1')
Middle force: tensor([0.9279, 2.3828, 0.5635, 1.4539, 0.7050, 1.0130, 0.5436, 0.8680, 0.5407,
        0.4949, 0.5717, 0.5711], device='cuda:1')
Thumb force: tensor([0.6659, 1.0513, 1.5871, 0.5197, 0.5422, 0.6601, 0.5079, 0.6247, 1.2550,
        0.5552, 0.5069, 1.1563], device='cuda:1')
Index force: tensor([0.5994, 1.6514, 0.6399, 0.6854, 0.7138, 0.7263, 0.5989, 0.7773, 0.5538,
        0.7571, 0.5983, 0.5862], device='cuda:1')
Storing NORMAL transition: reward=0.0545 (scaled=0.0545), steps=1
Reward stats updated: mean 0.0150 -> 0.0153, std: 0.0713
Collected 136 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=2.0536, Q2 Loss=2.0536, Entropy=0.0000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5415
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=3.5782, Q2 Loss=3.5782, Entropy=0.0020, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9078
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.1565, Q2 Loss=1.1565, Entropy=0.0070, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8635
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5715, Q2 Loss=0.5715, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1849
SAC Update 5/5: Actor Loss=-0.0020, Q1 Loss=0.7248, Q2 Loss=0.7248, Entropy=0.3453, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6981

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.6%)
Actor update: 0.12s (42.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000404
Q1 loss: 1.616922
Q2 loss: 1.616922
Current threshold: -149.8143
Global Scale Offset: 5.6645
Reward stats: mean=0.0153, std=0.0713, count=136
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 1.6169, Q2 Loss: 1.6169, Entropy: 0.0709, Mean TD Error: 1.2392, Threshold: -149.8143
tensor([-0.0942,  0.4053,  0.6176,  0.6262, -0.2141,  0.7396,  0.7349,  0.7054,
         1.4601,  0.0895,  0.2584,  0.9013, -0.0203,  0.0566, -0.6900, -0.1735],
       device='cuda:1')
Original likelihood: -246.12753295898438
Adjusted likelihood: -246.12753295898438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 252.93112182617188
Projection step: 1, Loss: 230.43942260742188
Projection step: 2, Loss: 219.63099670410156
Projection step: 3, Loss: 224.37632751464844
Projection step: 4, Loss: 201.43405151367188
Projection step: 5, Loss: 224.13369750976562
Projection step: 6, Loss: 217.5380859375
Projection step: 7, Loss: 224.18765258789062
Projection step: 8, Loss: 214.27757263183594
Projection step: 9, Loss: 216.2071990966797
Projection step: 10, Loss: 199.23922729492188
Projection step: 11, Loss: 204.82098388671875
Projection step: 12, Loss: 194.06906127929688
Projection step: 13, Loss: 187.83753967285156
Projection step: 14, Loss: 186.32872009277344
Projection step: 15, Loss: 180.8686981201172
Projection step: 16, Loss: 175.64056396484375
Projection step: 17, Loss: 178.42190551757812
Projection step: 18, Loss: 172.6014862060547
Projection step: 19, Loss: 172.06173706054688
Projection step: 20, Loss: 168.49365234375
Projection step: 21, Loss: 172.3999481201172
Projection step: 22, Loss: 162.26177978515625
Projection step: 23, Loss: 163.7261962890625
Projection step: 24, Loss: 148.64599609375
Final likelihood: tensor([-153.2357, -150.1256, -146.1973, -381.1611, -148.0158, -167.2851,
        -137.5699, -157.7005, -154.1010, -148.8878, -152.5480, -124.7808,
        -145.6658, -171.8266, -145.9145, -155.1455])
Final projection likelihood: -165.0101
1 mode projection failed, trying anyway
New goal: tensor([-0.0324,  0.4760,  0.6161,  0.6212, -0.1558,  0.6411,  0.6396,  0.8451,
         1.3946,  0.0133,  0.1321,  1.0918, -0.0323,  0.0409, -0.3920],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -157.4929962158203
Adjusted likelihood: -157.4929962158203
Likelihood residual: 0.0
Original likelihood: -215.55531311035156
Adjusted likelihood: -215.55531311035156
Likelihood residual: 0.0
{'index': 215.55531311035156, 'thumb_middle': 157.4929962158203}
Current yaw: tensor([-0.0203,  0.0566, -0.6900], device='cuda:1')
16 thumb_middle
tensor([-0.0942,  0.4053,  0.6176,  0.6262, -0.2141,  0.7396,  0.7349,  0.7054,
         1.4601,  0.0895,  0.2584,  0.9013, -0.0203,  0.0566, -0.6900, -0.1735],
       device='cuda:1')
Solve time for step 1 8.68843331100652
Current ori: tensor([-0.0203,  0.0566, -0.6900], device='cuda:1')
Index force: tensor([0.5876, 0.5795, 0.5649, 0.5984], device='cuda:1')
tensor([-0.0772,  0.4363,  0.5919,  0.6201, -0.2374,  0.6817,  0.6663,  0.8135,
         1.3973,  0.0126,  0.1372,  1.0738, -0.0405,  0.0914, -0.6979, -0.5371],
       device='cuda:1')
Solve time for step 2 3.6683303029858507
Current ori: tensor([-0.0405,  0.0914, -0.6979], device='cuda:1')
Index force: tensor([0.5756, 0.5618, 0.6019], device='cuda:1')
tensor([-0.0496,  0.4445,  0.5966,  0.6301, -0.2501,  0.6884,  0.6354,  0.8148,
         1.4183,  0.0156,  0.1268,  1.1135, -0.0401,  0.1044, -0.6881, -0.8609],
       device='cuda:1')
Solve time for step 3 3.5380219179787673
Current ori: tensor([-0.0401,  0.1044, -0.6881], device='cuda:1')
Index force: tensor([0.5587, 0.5947], device='cuda:1')
tensor([-0.0267,  0.4467,  0.6149,  0.6219, -0.2563,  0.6869,  0.6177,  0.8221,
         1.4396,  0.0063,  0.1395,  1.1054, -0.0372,  0.1116, -0.6844, -1.0762],
       device='cuda:1')
Solve time for step 4 3.425382781017106
Current ori: tensor([-0.0372,  0.1116, -0.6844], device='cuda:1')
Index force: tensor([0.5822], device='cuda:1')
Storing RECOVERY transition: reward=0.0231 (scaled=0.0231), steps=1
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0711
Collected 137 transitions for RL
SAC Update 1/5: Actor Loss=-0.0019, Q1 Loss=0.7940, Q2 Loss=0.7940, Entropy=0.3423, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6754
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.9805, Q2 Loss=0.9805, Entropy=0.0072, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8101
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=1.0311, Q2 Loss=1.0311, Entropy=0.0037, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5901
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5925, Q2 Loss=0.5925, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1408
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.5537, Q2 Loss=0.5537, Entropy=0.2141, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1826

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (18.3%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000452
Q1 loss: 0.790359
Q2 loss: 0.790359
Current threshold: -149.8115
Global Scale Offset: 5.9009
Reward stats: mean=0.0153, std=0.0711, count=137
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.7904, Q2 Loss: 0.7904, Entropy: 0.1135, Mean TD Error: 0.8798, Threshold: -149.8115
Original likelihood: -202.7564697265625
Adjusted likelihood: -202.7564697265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 218.28729248046875
Projection step: 1, Loss: 215.58688354492188
Projection step: 2, Loss: 217.43338012695312
Projection step: 3, Loss: 232.05966186523438
Projection step: 4, Loss: 207.27957153320312
Projection step: 5, Loss: 206.82281494140625
Projection step: 6, Loss: 204.85980224609375
Projection step: 7, Loss: 204.03732299804688
Projection step: 8, Loss: 201.57553100585938
Projection step: 9, Loss: 197.21896362304688
Projection step: 10, Loss: 229.05291748046875
Projection step: 11, Loss: 190.97671508789062
Projection step: 12, Loss: 192.22891235351562
Projection step: 13, Loss: 196.61351013183594
Projection step: 14, Loss: 187.0284423828125
Projection step: 15, Loss: 178.6978759765625
Projection step: 16, Loss: 189.34683227539062
Projection step: 17, Loss: 190.96083068847656
Projection step: 18, Loss: 182.49850463867188
Projection step: 19, Loss: 193.9916229248047
Projection step: 20, Loss: 187.16441345214844
Projection step: 21, Loss: 182.47525024414062
Projection step: 22, Loss: 175.74459838867188
Projection step: 23, Loss: 184.4463348388672
Projection step: 24, Loss: 174.54563903808594
Final likelihood: tensor([-185.5205, -139.8044, -184.8029, -180.4200, -157.8667, -174.6900,
        -183.1719, -178.2115, -236.2569, -160.8891, -228.9404, -167.4919,
        -153.2585, -169.6569, -167.3956, -207.2444])
Final projection likelihood: -179.7263
1 mode projection failed, trying anyway
New goal: tensor([-7.8912e-04,  5.1240e-01,  5.8399e-01,  6.1779e-01, -1.7462e-01,
         6.6766e-01,  5.7723e-01,  7.9971e-01,  1.4142e+00,  3.3160e-02,
         1.2033e-01,  1.1925e+00, -4.6337e-02,  6.9939e-02, -3.4255e-01],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -193.3325653076172
Adjusted likelihood: -193.3325653076172
Likelihood residual: 0.0
Original likelihood: -175.57589721679688
Adjusted likelihood: -175.57589721679688
Likelihood residual: 0.0
{'index': 175.57589721679688, 'thumb_middle': 193.3325653076172}
Current yaw: tensor([-0.0407,  0.0869, -0.7197], device='cuda:1')
17 index
tensor([ 1.1658e-03,  4.5065e-01,  6.1873e-01,  6.4919e-01, -2.2395e-01,
         6.8106e-01,  6.4404e-01,  8.4184e-01,  1.4895e+00,  5.3467e-02,
         1.8399e-01,  1.1389e+00, -4.0695e-02,  8.6945e-02, -7.1971e-01,
        -9.0604e-01], device='cuda:1')
Solve time for step 1 10.88087455398636
Current ori: tensor([-0.0407,  0.0869, -0.7197], device='cuda:1')
Middle force: tensor([0.5491, 0.5852, 0.6060, 0.5134], device='cuda:1')
Thumb force: tensor([0.5486, 0.6008, 0.5889, 0.5503], device='cuda:1')
tensor([ 0.0300,  0.4285,  0.5294,  0.5905, -0.2166,  0.6899,  0.6339,  0.8466,
         1.4993,  0.0416,  0.1612,  1.1395, -0.0453,  0.0820, -0.7366, -0.7601],
       device='cuda:1')
Solve time for step 2 4.325700269022491
Current ori: tensor([-0.0453,  0.0820, -0.7366], device='cuda:1')
Middle force: tensor([0.5151, 0.5238, 0.5473], device='cuda:1')
Thumb force: tensor([0.5535, 0.6408, 0.6447], device='cuda:1')
tensor([ 0.0349,  0.4369,  0.5235,  0.5861, -0.1916,  0.7070,  0.6290,  0.8413,
         1.4820,  0.0515,  0.1316,  1.1610, -0.0514,  0.0643, -0.7412, -0.3301],
       device='cuda:1')
Solve time for step 3 4.090434442972764
Current ori: tensor([-0.0514,  0.0643, -0.7412], device='cuda:1')
Middle force: tensor([0.5868, 0.5020], device='cuda:1')
Thumb force: tensor([0.5137, 0.5732], device='cuda:1')
tensor([ 0.0327,  0.4414,  0.5212,  0.5844, -0.1721,  0.7246,  0.6225,  0.8296,
         1.4814,  0.0359,  0.1075,  1.1668, -0.0590,  0.0505, -0.7494,  0.3091],
       device='cuda:1')
Solve time for step 4 3.697537123982329
Current ori: tensor([-0.0590,  0.0505, -0.7494], device='cuda:1')
Middle force: tensor([0.5012], device='cuda:1')
Thumb force: tensor([0.5624], device='cuda:1')
Storing RECOVERY transition: reward=0.0588 (scaled=0.0588), steps=1
Reward stats updated: mean 0.0153 -> 0.0156, std: 0.0709
Collected 138 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.8968, Q2 Loss=0.8968, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5638
SAC Update 2/5: Actor Loss=-0.0033, Q1 Loss=1.6599, Q2 Loss=1.6599, Entropy=0.4749, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5772
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.7739, Q2 Loss=0.7739, Entropy=0.1413, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8989
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.3905, Q2 Loss=1.3905, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4372
SAC Update 5/5: Actor Loss=-0.0021, Q1 Loss=1.2129, Q2 Loss=1.2129, Entropy=0.3767, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5165

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001136
Q1 loss: 1.186800
Q2 loss: 1.186800
Current threshold: -149.8048
Global Scale Offset: 6.2073
Reward stats: mean=0.0156, std=0.0709, count=138
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 1.1868, Q2 Loss: 1.1868, Entropy: 0.1986, Mean TD Error: 1.1987, Threshold: -149.8048
Original likelihood: -185.1219482421875
Adjusted likelihood: -185.1219482421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 219.0674591064453
Projection step: 1, Loss: 206.7598876953125
Projection step: 2, Loss: 186.82669067382812
Projection step: 3, Loss: 157.9867401123047
Projection step: 4, Loss: 175.81973266601562
Projection step: 5, Loss: 155.07501220703125
Projection step: 6, Loss: 160.38938903808594
Projection step: 7, Loss: 159.7879638671875
Projection step: 8, Loss: 156.27810668945312
Projection step: 9, Loss: 174.33673095703125
Projection step: 10, Loss: 165.64117431640625
Projection step: 11, Loss: 156.94253540039062
Projection step: 12, Loss: 161.12518310546875
Projection step: 13, Loss: 160.67210388183594
Projection step: 14, Loss: 153.036376953125
Projection step: 15, Loss: 164.52749633789062
Projection step: 16, Loss: 161.00674438476562
Projection step: 17, Loss: 162.3293914794922
Projection step: 18, Loss: 158.51812744140625
Projection step: 19, Loss: 159.65467834472656
Projection step: 20, Loss: 149.34498596191406
Projection step: 21, Loss: 151.60919189453125
Projection step: 22, Loss: 143.71072387695312
Projection step: 23, Loss: 148.7057342529297
Projection step: 24, Loss: 141.54241943359375
Final likelihood: tensor([-164.7536, -145.5870, -138.3303, -135.8516, -144.1071, -145.6447,
        -148.2463, -169.6113, -151.7585, -109.5748, -186.5132, -134.3464,
        -136.8452, -143.1694, -151.4698, -118.2586])
Final projection likelihood: -145.2542
1 mode projection succeeded
New goal: tensor([ 0.0330,  0.5164,  0.5553,  0.6756, -0.1154,  0.6352,  0.6174,  0.8645,
         1.4406, -0.0347,  0.0840,  1.1658, -0.0568,  0.0441, -0.3332],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -145.09542846679688
Adjusted likelihood: -145.09542846679688
Likelihood residual: 0.0
Original likelihood: -175.52212524414062
Adjusted likelihood: -175.52212524414062
Likelihood residual: 0.0
{'index': 175.52212524414062, 'thumb_middle': 145.09542846679688}
Current yaw: tensor([-0.0567,  0.0572, -0.7530], device='cuda:1')
18 thumb_middle
tensor([-0.0117,  0.4996,  0.5621,  0.6075, -0.1816,  0.7167,  0.6245,  0.8366,
         1.4877,  0.0415,  0.1052,  1.1712, -0.0567,  0.0572, -0.7530,  0.5216],
       device='cuda:1')
Solve time for step 1 8.995683690009173
Current ori: tensor([-0.0567,  0.0572, -0.7530], device='cuda:1')
Index force: tensor([0.5049, 0.4997, 0.5904, 0.6009], device='cuda:1')
tensor([-0.0175,  0.5087,  0.5178,  0.6594, -0.2143,  0.6740,  0.5950,  0.8362,
         1.4438, -0.0367,  0.0778,  1.1778, -0.0494,  0.0984, -0.7529,  0.0895],
       device='cuda:1')
Solve time for step 2 3.7270878209965304
Current ori: tensor([-0.0494,  0.0984, -0.7529], device='cuda:1')
Index force: tensor([0.5002, 0.5885, 0.5953], device='cuda:1')
tensor([-0.0174,  0.5059,  0.5276,  0.6470, -0.2300,  0.6703,  0.5830,  0.8316,
         1.4745, -0.0347,  0.0895,  1.1867, -0.0451,  0.1112, -0.7440, -0.0544],
       device='cuda:1')
Solve time for step 3 3.771242724964395
Current ori: tensor([-0.0451,  0.1112, -0.7440], device='cuda:1')
Index force: tensor([0.5873, 0.5914], device='cuda:1')
tensor([ 0.0036,  0.5095,  0.5336,  0.6593, -0.2286,  0.6694,  0.5795,  0.8313,
         1.4743, -0.0368,  0.0965,  1.1893, -0.0405,  0.1112, -0.7304, -0.1884],
       device='cuda:1')
Solve time for step 4 3.3422958129667677
Current ori: tensor([-0.0405,  0.1112, -0.7304], device='cuda:1')
Index force: tensor([0.5881], device='cuda:1')
Storing RECOVERY transition: reward=0.0891 (scaled=0.0891), steps=1
Reward stats updated: mean 0.0156 -> 0.0162, std: 0.0709
Collected 139 transitions for RL
SAC Update 1/5: Actor Loss=-0.0024, Q1 Loss=1.6385, Q2 Loss=1.6385, Entropy=0.3240, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5674
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.7652, Q2 Loss=0.7652, Entropy=0.0291, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7359
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7130, Q2 Loss=0.7130, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4919
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=13.2031, Q2 Loss=13.2031, Entropy=0.0064, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8895
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.9529, Q2 Loss=0.9529, Entropy=0.0076, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4767

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.9%)
Q1 update: 0.05s (18.2%)
Q2 update: 0.06s (20.2%)
Actor update: 0.12s (43.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000503
Q1 loss: 3.454546
Q2 loss: 3.454546
Current threshold: -149.7935
Global Scale Offset: 6.5781
Reward stats: mean=0.0162, std=0.0709, count=139
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 3.4545, Q2 Loss: 3.4545, Entropy: 0.0734, Mean TD Error: 1.6323, Threshold: -149.7935
Original likelihood: -215.15679931640625
Adjusted likelihood: -215.15679931640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 212.83639526367188
Projection step: 1, Loss: 206.41587829589844
Projection step: 2, Loss: 212.70738220214844
Projection step: 3, Loss: 205.690185546875
Projection step: 4, Loss: 212.58078002929688
Projection step: 5, Loss: 209.33810424804688
Projection step: 6, Loss: 205.20989990234375
Projection step: 7, Loss: 200.42494201660156
Projection step: 8, Loss: 237.0193328857422
Projection step: 9, Loss: 203.2049560546875
Projection step: 10, Loss: 198.82345581054688
Projection step: 11, Loss: 193.677734375
Projection step: 12, Loss: 193.9180908203125
Projection step: 13, Loss: 196.33273315429688
Projection step: 14, Loss: 199.7161407470703
Projection step: 15, Loss: 194.2156524658203
Projection step: 16, Loss: 179.6461944580078
Projection step: 17, Loss: 181.90589904785156
Projection step: 18, Loss: 181.69754028320312
Projection step: 19, Loss: 181.5172119140625
Projection step: 20, Loss: 176.77471923828125
Projection step: 21, Loss: 168.9607391357422
Projection step: 22, Loss: 172.86074829101562
Projection step: 23, Loss: 171.4241943359375
Projection step: 24, Loss: 169.0118408203125
Final likelihood: tensor([-160.9848, -165.4963, -179.4108, -170.9896, -177.2185, -172.0461,
        -155.2361, -164.2738, -176.9645, -168.4251, -166.2366, -171.1848,
        -156.5060, -159.6236, -131.3486, -162.1819])
Final projection likelihood: -164.8829
1 mode projection failed, trying anyway
New goal: tensor([ 0.0339,  0.5458,  0.5292,  0.6647, -0.1218,  0.6481,  0.5746,  0.8283,
         1.4349, -0.0215,  0.0988,  1.1851, -0.0574,  0.0570, -0.3661],
       device='cuda:1')
tensor([[0.0036]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -168.12985229492188
Adjusted likelihood: -168.12985229492188
Likelihood residual: 0.0
Original likelihood: -155.4671630859375
Adjusted likelihood: -155.4671630859375
Likelihood residual: 0.0
{'index': 155.4671630859375, 'thumb_middle': 168.12985229492188}
Current yaw: tensor([-0.0512,  0.0795, -0.7872], device='cuda:1')
19 index
tensor([ 0.0334,  0.5155,  0.5474,  0.6683, -0.1822,  0.6736,  0.5994,  0.8471,
         1.5000,  0.0128,  0.1418,  1.2081, -0.0512,  0.0795, -0.7872,  0.0405],
       device='cuda:1')
Solve time for step 1 10.42521019896958
Current ori: tensor([-0.0512,  0.0795, -0.7872], device='cuda:1')
Middle force: tensor([0.5634, 0.5456, 0.5825, 0.5568], device='cuda:1')
Thumb force: tensor([0.5921, 0.5027, 0.5770, 0.6269], device='cuda:1')
tensor([ 0.0626,  0.4726,  0.4742,  0.6366, -0.1614,  0.6797,  0.6029,  0.8504,
         1.5000,  0.0154,  0.1179,  1.2054, -0.0603,  0.0654, -0.8208,  1.2251],
       device='cuda:1')
Solve time for step 2 4.18452728696866
Current ori: tensor([-0.0603,  0.0654, -0.8208], device='cuda:1')
Middle force: tensor([0.5419, 0.5776, 0.5525], device='cuda:1')
Thumb force: tensor([0.5024, 0.5767, 0.6235], device='cuda:1')
tensor([ 0.0622,  0.4778,  0.4705,  0.6313, -0.1502,  0.6971,  0.5936,  0.8365,
         1.5000,  0.0061,  0.1055,  1.2019, -0.0673,  0.0578, -0.8240,  2.1539],
       device='cuda:1')
Solve time for step 3 4.096201442007441
Current ori: tensor([-0.0673,  0.0578, -0.8240], device='cuda:1')
Middle force: tensor([0.5216, 0.5903], device='cuda:1')
Thumb force: tensor([0.5870, 0.5406], device='cuda:1')
tensor([ 0.0615,  0.4775,  0.4691,  0.6333, -0.1528,  0.6909,  0.5979,  0.8436,
         1.4992,  0.0086,  0.1066,  1.2102, -0.0642,  0.0591, -0.8173,  2.6369],
       device='cuda:1')
Solve time for step 4 3.92151225899579
Current ori: tensor([-0.0642,  0.0591, -0.8173], device='cuda:1')
Middle force: tensor([0.5018], device='cuda:1')
Thumb force: tensor([0.5230], device='cuda:1')
Storing RECOVERY transition: reward=0.1233 (scaled=0.1233), steps=1
Reward stats updated: mean 0.0162 -> 0.0169, std: 0.0712
Collected 140 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6644, Q2 Loss=0.6644, Entropy=0.0092, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9131
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=0.7705, Q2 Loss=0.7705, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5257
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7929, Q2 Loss=0.7929, Entropy=0.0102, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8555
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.9947, Q2 Loss=0.9947, Entropy=0.6281, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7075
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.8293, Q2 Loss=1.8293, Entropy=0.0114, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8740

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.5%)
Actor update: 0.08s (39.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001503
Q1 loss: 1.010366
Q2 loss: 1.010366
Current threshold: -149.7889
Global Scale Offset: 6.8844
Reward stats: mean=0.0169, std=0.0712, count=140
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 1.0104, Q2 Loss: 1.0104, Entropy: 0.1318, Mean TD Error: 0.9752, Threshold: -149.7889
Original likelihood: -160.20022583007812
Adjusted likelihood: -160.20022583007812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1002)
State is out of distribution
Projection step: 0, Loss: 151.7085723876953
Projection step: 1, Loss: 150.22222900390625
Projection step: 2, Loss: 145.5253143310547
Projection step: 3, Loss: 143.09646606445312
Projection step: 4, Loss: 133.55331420898438
Projection step: 5, Loss: 146.92742919921875
Projection step: 6, Loss: 144.1224365234375
Projection step: 7, Loss: 141.6352996826172
Projection step: 8, Loss: 145.286865234375
Projection step: 9, Loss: 148.62525939941406
Projection step: 10, Loss: 137.48025512695312
Projection step: 11, Loss: 140.46624755859375
Projection step: 12, Loss: 140.41766357421875
Projection step: 13, Loss: 137.57371520996094
Projection step: 14, Loss: 139.6374969482422
Projection step: 15, Loss: 140.9652557373047
Projection step: 16, Loss: 139.01376342773438
Projection step: 17, Loss: 133.2701873779297
Projection step: 18, Loss: 135.00357055664062
Projection step: 19, Loss: 122.2858657836914
Projection step: 20, Loss: 139.09326171875
Projection step: 21, Loss: 126.33880615234375
Projection step: 22, Loss: 123.23573303222656
Projection step: 23, Loss: 123.40847778320312
Projection step: 24, Loss: 121.10218811035156
Final likelihood: tensor([-112.9455, -107.1066, -135.2633, -132.0513, -129.4424, -123.4508,
        -158.9772, -113.2583, -133.5831, -138.9959, -137.4081, -138.4927,
        -105.1933, -132.0555, -120.8956, -138.3272])
Final projection likelihood: -128.5904
1 mode projection succeeded
New goal: tensor([ 0.0594,  0.5252,  0.4760,  0.7886, -0.0900,  0.6094,  0.6439,  0.8660,
         1.4373, -0.0357,  0.1233,  1.1297, -0.0618,  0.0424, -0.8454],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -133.07765197753906
Adjusted likelihood: -133.07765197753906
Likelihood residual: 0.0
Original likelihood: -149.51528930664062
Adjusted likelihood: -149.51528930664062
Likelihood residual: 0.0
{'index': 149.51528930664062, 'thumb_middle': 133.07765197753906}
Current yaw: tensor([-0.0667,  0.0530, -0.8201], device='cuda:1')
20 thumb_middle
tensor([ 0.0179,  0.5392,  0.5077,  0.6546, -0.1437,  0.6977,  0.5978,  0.8356,
         1.4970,  0.0043,  0.0963,  1.2146, -0.0667,  0.0530, -0.8201,  2.7290],
       device='cuda:1')
Solve time for step 1 8.794000199006405
Current ori: tensor([-0.0667,  0.0530, -0.8201], device='cuda:1')
Index force: tensor([0.5374, 0.6129, 0.5979, 0.5716], device='cuda:1')
tensor([ 0.0137,  0.5601,  0.4406,  0.7178, -0.1958,  0.6271,  0.6112,  0.8352,
         1.4285, -0.0510,  0.1167,  1.1609, -0.0581,  0.0937, -0.8201,  2.4065],
       device='cuda:1')
Solve time for step 2 3.603956302977167
Current ori: tensor([-0.0581,  0.0937, -0.8201], device='cuda:1')
Index force: tensor([0.6076, 0.5914, 0.5629], device='cuda:1')
tensor([ 0.0330,  0.5375,  0.4643,  0.7671, -0.2065,  0.6260,  0.5974,  0.8424,
         1.4548, -0.0553,  0.1130,  1.1540, -0.0359,  0.1034, -0.8201,  2.2640],
       device='cuda:1')
Solve time for step 3 3.37549874704564
Current ori: tensor([-0.0359,  0.1034, -0.8201], device='cuda:1')
Index force: tensor([0.5873, 0.5534], device='cuda:1')
tensor([ 0.0509,  0.5454,  0.4618,  0.7805, -0.2149,  0.6218,  0.5986,  0.8493,
         1.4553, -0.0346,  0.1255,  1.1418, -0.0302,  0.1017, -0.8201,  2.2246],
       device='cuda:1')
Solve time for step 4 3.3149390039616264
Current ori: tensor([-0.0302,  0.1017, -0.8201], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.1686 (scaled=0.1686), steps=1
Reward stats updated: mean 0.0169 -> 0.0180, std: 0.0721
Collected 141 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.5894, Q2 Loss=0.5894, Entropy=0.0007, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5639
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7694, Q2 Loss=0.7694, Entropy=0.0003, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7127
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.2499, Q2 Loss=2.2499, Entropy=0.0085, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8018
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.8061, Q2 Loss=0.8061, Entropy=0.0003, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5679
SAC Update 5/5: Actor Loss=-0.0016, Q1 Loss=1.2078, Q2 Loss=1.2078, Entropy=0.2569, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0241

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.7%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000318
Q1 loss: 1.124537
Q2 loss: 1.124537
Current threshold: -149.7880
Global Scale Offset: 7.1611
Reward stats: mean=0.0180, std=0.0721, count=141
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.1245, Q2 Loss: 1.1245, Entropy: 0.0533, Mean TD Error: 0.9341, Threshold: -149.7880
Original likelihood: -220.43643188476562
Adjusted likelihood: -220.43643188476562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 226.633056640625
Projection step: 1, Loss: 217.11026000976562
Projection step: 2, Loss: 226.09149169921875
Projection step: 3, Loss: 225.34388732910156
Projection step: 4, Loss: 225.32546997070312
Projection step: 5, Loss: 224.06375122070312
Projection step: 6, Loss: 220.49102783203125
Projection step: 7, Loss: 209.4219970703125
Projection step: 8, Loss: 208.3876953125
Projection step: 9, Loss: 196.95339965820312
Projection step: 10, Loss: 200.77908325195312
Projection step: 11, Loss: 197.18682861328125
Projection step: 12, Loss: 199.47103881835938
Projection step: 13, Loss: 194.99143981933594
Projection step: 14, Loss: 191.49954223632812
Projection step: 15, Loss: 192.654541015625
Projection step: 16, Loss: 185.7751007080078
Projection step: 17, Loss: 194.98236083984375
Projection step: 18, Loss: 181.27622985839844
Projection step: 19, Loss: 169.4840087890625
Projection step: 20, Loss: 177.060302734375
Projection step: 21, Loss: 165.482666015625
Projection step: 22, Loss: 164.79220581054688
Projection step: 23, Loss: 163.4035186767578
Projection step: 24, Loss: 161.26856994628906
Final likelihood: tensor([-144.7914, -135.5569, -205.3586, -186.8762, -141.0613, -159.3815,
        -181.1142, -173.1660, -202.1563, -157.4310, -183.9108, -150.6719,
        -132.9933, -162.3257, -178.6610, -165.5152])
Final projection likelihood: -166.3107
1 mode projection failed, trying anyway
New goal: tensor([ 0.0379,  0.5768,  0.4353,  0.7505, -0.1285,  0.6333,  0.5879,  0.8336,
         1.4296, -0.0133,  0.1227,  1.1992, -0.0523,  0.0618, -0.3747],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 9
Loaded trajectory sampler
Current yaw: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
Current yaw: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
1 turn
Sampling time 3.6271656139870174
tensor([ 0.1528,  0.6428,  0.5586,  0.5413, -0.1368,  0.5471,  0.9149,  0.9132,
         1.2561,  0.2300,  0.2502,  1.1769, -0.0030,  0.0151, -0.0456, -0.0677],
       device='cuda:1')
Original likelihood: -131.72879028320312
Adjusted likelihood: -131.72879028320312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9841)
Solve time for step 1 13.771791115985252
Current ori: tensor([-0.0030,  0.0151, -0.0456], device='cuda:1')
Middle force: tensor([0.7062, 0.7472, 0.5372, 0.8966, 0.5243, 0.5877, 0.5470, 0.5116, 0.4846,
        0.5159, 0.5014, 0.5632], device='cuda:1')
Thumb force: tensor([0.6291, 0.6969, 0.7395, 1.3171, 1.2234, 1.4554, 1.2646, 0.5009, 0.5453,
        0.6141, 0.7798, 0.6181], device='cuda:1')
Index force: tensor([0.6706, 0.6451, 0.5484, 0.5912, 1.0826, 0.7427, 0.7725, 0.7947, 0.7907,
        0.6171, 0.6447, 0.5756], device='cuda:1')
Storing NORMAL transition: reward=0.0020 (scaled=0.0020), steps=1
Reward stats updated: mean 0.0180 -> 0.0179, std: 0.0719
Collected 142 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=7.0149, Q2 Loss=7.0149, Entropy=0.0409, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5738
SAC Update 2/5: Actor Loss=0.0000, Q1 Loss=1.1579, Q2 Loss=1.1579, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4607
SAC Update 3/5: Actor Loss=-0.0026, Q1 Loss=1.6198, Q2 Loss=1.6198, Entropy=0.3459, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5822
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.7143, Q2 Loss=1.7143, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5363
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.6031, Q2 Loss=2.6031, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9280

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.0%)
Actor update: 0.08s (41.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000549
Q1 loss: 2.821976
Q2 loss: 2.821976
Current threshold: -149.7835
Global Scale Offset: 7.4679
Reward stats: mean=0.0179, std=0.0719, count=142
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 2.8220, Q2 Loss: 2.8220, Entropy: 0.0774, Mean TD Error: 1.8162, Threshold: -149.7835
tensor([ 0.1383,  0.6369,  0.5731,  0.4968, -0.1672,  0.4860,  0.9910,  0.9081,
         1.2197,  0.2719,  0.1995,  1.1328, -0.0051,  0.0177, -0.0477, -0.0737],
       device='cuda:1')
Original likelihood: -143.87591552734375
Adjusted likelihood: -143.87591552734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7508)
Solve time for step 2 5.466989240958355
Current ori: tensor([-0.0051,  0.0177, -0.0477], device='cuda:1')
Middle force: tensor([0.5003, 0.5224, 0.5788, 0.5257, 0.5019, 0.5792, 0.5012, 0.5365, 0.5234,
        0.5003, 0.5846], device='cuda:1')
Thumb force: tensor([0.5293, 0.9404, 1.2417, 0.5206, 0.5654, 1.9474, 0.5345, 0.8228, 0.5799,
        0.6621, 1.0328], device='cuda:1')
Index force: tensor([0.9760, 0.5213, 0.5531, 0.5875, 0.6952, 0.5743, 0.8477, 0.5971, 0.5602,
        0.6721, 0.5737], device='cuda:1')
Storing NORMAL transition: reward=0.0406 (scaled=0.0406), steps=1
Reward stats updated: mean 0.0179 -> 0.0180, std: 0.0716
Collected 143 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=7.8457, Q2 Loss=7.8457, Entropy=0.1165, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0261
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.9712, Q2 Loss=1.9712, Entropy=0.0252, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6789
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=0.8945, Q2 Loss=0.8945, Entropy=0.2201, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5743
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.7975, Q2 Loss=0.7975, Entropy=0.1908, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9153
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=5.4382, Q2 Loss=5.4382, Entropy=0.1487, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0596

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.4%)
Actor update: 0.08s (39.5%)
Target update: 0.00s (2.0%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000590
Q1 loss: 3.389424
Q2 loss: 3.389424
Current threshold: -149.7770
Global Scale Offset: 7.8824
Reward stats: mean=0.0180, std=0.0716, count=143
----------------------------------------------
SAC Update - Actor Loss: -0.0006, Q1 Loss: 3.3894, Q2 Loss: 3.3894, Entropy: 0.1403, Mean TD Error: 2.0508, Threshold: -149.7770
tensor([ 0.1886,  0.6618,  0.5726,  0.5460, -0.1070,  0.5058,  0.9681,  0.9757,
         1.3130,  0.1052,  0.3152,  0.9337, -0.0067, -0.0127, -0.0882,  0.0794],
       device='cuda:1')
Original likelihood: -202.4703369140625
Adjusted likelihood: -202.4703369140625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 280.542236328125
Projection step: 1, Loss: 156.79246520996094
Projection step: 2, Loss: 140.67327880859375
Projection step: 3, Loss: 130.54586791992188
Projection step: 4, Loss: 117.85354614257812
Projection step: 5, Loss: 112.45010375976562
Projection step: 6, Loss: 111.46096801757812
Projection step: 7, Loss: 111.67842102050781
Projection step: 8, Loss: 108.61753845214844
Projection step: 9, Loss: 109.43365478515625
Projection step: 10, Loss: 104.90110778808594
Final likelihood: tensor([ -84.0475, -124.7409,  -98.7699, -116.3815, -116.0962,  -84.7242,
         -98.6576, -103.4973,  -95.5026,  -83.1506, -123.8993, -130.8554,
        -108.3105, -108.6924,  -93.3481, -107.7438])
Final projection likelihood: -104.9011
1 mode projection succeeded
New goal: tensor([ 0.1281,  0.5959,  0.5677,  0.5892, -0.0839,  0.5469,  0.9269,  0.9186,
         1.3359,  0.2200,  0.2162,  1.0603, -0.0048, -0.0088, -0.3349],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -152.31492614746094
Adjusted likelihood: -152.31492614746094
Likelihood residual: 0.0
Original likelihood: -174.04010009765625
Adjusted likelihood: -174.04010009765625
Likelihood residual: 0.0
{'index': 174.04010009765625, 'thumb_middle': 152.31492614746094}
Current yaw: tensor([-0.0067, -0.0127, -0.0882], device='cuda:1')
2 thumb_middle
tensor([ 0.1886,  0.6618,  0.5726,  0.5460, -0.1070,  0.5058,  0.9681,  0.9757,
         1.3130,  0.1052,  0.3152,  0.9337, -0.0067, -0.0127, -0.0882,  0.0794],
       device='cuda:1')
Solve time for step 1 9.050972810015082
Current ori: tensor([-0.0067, -0.0127, -0.0882], device='cuda:1')
Index force: tensor([0.5316, 0.5077, 0.5884, 0.5956], device='cuda:1')
tensor([ 0.1874,  0.6621,  0.5591,  0.5617, -0.1881,  0.5023,  0.8903,  0.9048,
         1.2834,  0.1759,  0.1442,  1.0023, -0.0055, -0.0106, -0.0882,  0.0554],
       device='cuda:1')
Solve time for step 2 3.6200324770179577
Current ori: tensor([-0.0055, -0.0106, -0.0882], device='cuda:1')
Index force: tensor([0.5070, 0.5812, 0.5899], device='cuda:1')
tensor([ 0.1842,  0.6575,  0.5621,  0.5613, -0.2005,  0.5141,  0.8860,  0.8950,
         1.2895,  0.1922,  0.1233,  1.0152, -0.0046, -0.0085, -0.0882,  0.0516],
       device='cuda:1')
Solve time for step 3 3.591714113019407
Current ori: tensor([-0.0046, -0.0085, -0.0882], device='cuda:1')
Index force: tensor([0.5714, 0.5830], device='cuda:1')
tensor([ 0.1625,  0.6128,  0.5812,  0.5964, -0.2141,  0.5066,  0.8781,  0.8918,
         1.3011,  0.1991,  0.1283,  1.0196,  0.0067,  0.0072, -0.0882,  0.0457],
       device='cuda:1')
Solve time for step 4 3.289635812980123
Current ori: tensor([ 0.0067,  0.0072, -0.0882], device='cuda:1')
Index force: tensor([0.5690], device='cuda:1')
Storing RECOVERY transition: reward=0.0086 (scaled=0.0043), steps=2
Reward stats updated: mean 0.0180 -> 0.0179, std: 0.0714
Collected 144 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=1.0084, Q2 Loss=1.0084, Entropy=0.6322, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7531
SAC Update 2/5: Actor Loss=-0.0031, Q1 Loss=2.7784, Q2 Loss=2.7784, Entropy=0.4032, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2944
SAC Update 3/5: Actor Loss=-0.0017, Q1 Loss=0.7945, Q2 Loss=0.7945, Entropy=0.2165, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6814
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=12.1352, Q2 Loss=12.1352, Entropy=0.0270, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8564
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.0769, Q2 Loss=1.0769, Entropy=0.0366, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7514

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (21.0%)
Actor update: 0.12s (41.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002545
Q1 loss: 3.558657
Q2 loss: 3.558657
Current threshold: -149.7583
Global Scale Offset: 8.5834
Reward stats: mean=0.0179, std=0.0714, count=144
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 3.5587, Q2 Loss: 3.5587, Entropy: 0.2631, Mean TD Error: 1.8673, Threshold: -149.7583
Original likelihood: -136.20513916015625
Adjusted likelihood: -136.20513916015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9154)
Current yaw: tensor([ 0.0058,  0.0020, -0.0966], device='cuda:1')
3 turn
Sampling time 3.661287633003667
tensor([ 0.1692,  0.6209,  0.5788,  0.5941, -0.1396,  0.5599,  0.9210,  0.9122,
         1.3556,  0.2201,  0.1788,  1.0540,  0.0058,  0.0020, -0.0966,  0.0609],
       device='cuda:1')
Original likelihood: -143.13320922851562
Adjusted likelihood: -143.13320922851562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7492)
Solve time for step 1 14.129250938014593
Current ori: tensor([ 0.0058,  0.0020, -0.0966], device='cuda:1')
Middle force: tensor([0.5010, 0.5074, 0.5020, 1.4407, 0.6393, 0.4997, 0.5723, 0.6966, 0.6586,
        0.5399, 0.5525, 0.6120], device='cuda:1')
Thumb force: tensor([1.3177, 0.9168, 1.3610, 0.6809, 0.5311, 1.0140, 1.2122, 0.5662, 0.5937,
        0.5864, 0.9388, 0.6103], device='cuda:1')
Index force: tensor([0.5097, 0.8042, 0.7124, 0.7391, 0.5586, 0.5899, 0.6718, 0.8030, 0.5630,
        0.5754, 0.6119, 0.6063], device='cuda:1')
Storing NORMAL transition: reward=0.1402 (scaled=0.1402), steps=1
Reward stats updated: mean 0.0179 -> 0.0188, std: 0.0719
Collected 145 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=5.1871, Q2 Loss=5.1871, Entropy=0.0320, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4487
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.4460, Q2 Loss=1.4460, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2087
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=0.9365, Q2 Loss=0.9365, Entropy=0.3246, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2085
SAC Update 4/5: Actor Loss=-0.0053, Q1 Loss=1.2696, Q2 Loss=1.2696, Entropy=0.3511, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9872
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.5932, Q2 Loss=0.5932, Entropy=0.0518, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4098

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.0%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.5%)
Actor update: 0.11s (43.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001286
Q1 loss: 1.886473
Q2 loss: 1.886473
Current threshold: -149.7429
Global Scale Offset: 9.2225
Reward stats: mean=0.0188, std=0.0719, count=145
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.8865, Q2 Loss: 1.8865, Entropy: 0.1519, Mean TD Error: 1.4526, Threshold: -149.7429
tensor([ 0.1466,  0.5840,  0.5888,  0.6258, -0.2634,  0.6160,  0.9165,  0.8892,
         1.4412,  0.5472,  0.1100,  0.9246,  0.0155,  0.0194, -0.2376,  0.1447],
       device='cuda:1')
Original likelihood: -231.95541381835938
Adjusted likelihood: -231.95541381835938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 230.50967407226562
Projection step: 1, Loss: 208.10977172851562
Projection step: 2, Loss: 198.8087921142578
Projection step: 3, Loss: 194.13461303710938
Projection step: 4, Loss: 175.195556640625
Projection step: 5, Loss: 169.72886657714844
Projection step: 6, Loss: 170.93386840820312
Projection step: 7, Loss: 154.11764526367188
Projection step: 8, Loss: 144.82183837890625
Projection step: 9, Loss: 144.72817993164062
Projection step: 10, Loss: 137.65567016601562
Projection step: 11, Loss: 123.23577880859375
Projection step: 12, Loss: 119.94520568847656
Projection step: 13, Loss: 118.91265869140625
Projection step: 14, Loss: 118.698974609375
Projection step: 15, Loss: 113.81288146972656
Projection step: 16, Loss: 116.34857177734375
Projection step: 17, Loss: 108.81004333496094
Projection step: 18, Loss: 104.5361328125
Final likelihood: tensor([-106.8716, -111.8561, -116.7229,  -98.1332, -104.9765,  -98.3818,
         -94.9541, -103.0501, -105.1229, -116.5557, -101.7829, -102.4717,
        -100.2386, -114.7100, -106.2158,  -90.5343])
Final projection likelihood: -104.5361
1 mode projection succeeded
New goal: tensor([ 0.1530,  0.5439,  0.5613,  0.6613, -0.1218,  0.6028,  0.9479,  0.8874,
         1.4496,  0.4942,  0.1799,  1.0378,  0.0123,  0.0162,  2.5996],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0061]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -137.02200317382812
Adjusted likelihood: -137.02200317382812
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 137.02200317382812}
Current yaw: tensor([ 0.0155,  0.0194, -0.2376], device='cuda:1')
4 thumb_middle
tensor([ 0.1466,  0.5840,  0.5888,  0.6258, -0.2634,  0.6160,  0.9165,  0.8892,
         1.4412,  0.5472,  0.1100,  0.9246,  0.0155,  0.0194, -0.2376,  0.1447],
       device='cuda:1')
Solve time for step 1 8.940839842951391
Current ori: tensor([ 0.0155,  0.0194, -0.2376], device='cuda:1')
Index force: tensor([0.5847, 0.5999, 0.6020, 0.6090], device='cuda:1')
tensor([ 0.1432,  0.5856,  0.5722,  0.6445, -0.2687,  0.5741,  0.8884,  0.8533,
         1.3710,  0.4901,  0.0540,  0.9578,  0.0165,  0.0207, -0.2376,  0.1748],
       device='cuda:1')
Solve time for step 2 3.6399654450360686
Current ori: tensor([ 0.0165,  0.0207, -0.2376], device='cuda:1')
Index force: tensor([0.5883, 0.5923, 0.6008], device='cuda:1')
tensor([ 0.1498,  0.5727,  0.5836,  0.6714, -0.2622,  0.5762,  0.8866,  0.8494,
         1.3655,  0.4819,  0.0476,  0.9661,  0.0211,  0.0182, -0.2376,  0.1989],
       device='cuda:1')
Solve time for step 3 3.515944946964737
Current ori: tensor([ 0.0211,  0.0182, -0.2376], device='cuda:1')
Index force: tensor([0.5793, 0.5900], device='cuda:1')
tensor([ 0.1574,  0.5617,  0.5951,  0.6940, -0.2578,  0.5703,  0.8885,  0.8513,
         1.3633,  0.4786,  0.0477,  0.9673,  0.0254,  0.0151, -0.2376,  0.2170],
       device='cuda:1')
Solve time for step 4 3.390540764958132
Current ori: tensor([ 0.0254,  0.0151, -0.2376], device='cuda:1')
Index force: tensor([0.5613], device='cuda:1')
Storing RECOVERY transition: reward=-0.0037 (scaled=-0.0037), steps=1
Reward stats updated: mean 0.0188 -> 0.0186, std: 0.0717
Collected 146 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=1.0992, Q2 Loss=1.0992, Entropy=0.0536, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0009
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.8737, Q2 Loss=0.8737, Entropy=0.0150, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5814
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.6047, Q2 Loss=0.6047, Entropy=0.2525, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4007
SAC Update 4/5: Actor Loss=-0.0061, Q1 Loss=1.4576, Q2 Loss=1.4576, Entropy=0.3445, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5289
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.3121, Q2 Loss=1.3121, Entropy=0.0433, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1153

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001360
Q1 loss: 1.069461
Q2 loss: 1.069461
Current threshold: -149.7327
Global Scale Offset: 9.7814
Reward stats: mean=0.0186, std=0.0717, count=146
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 1.0695, Q2 Loss: 1.0695, Entropy: 0.1418, Mean TD Error: 1.1254, Threshold: -149.7327
Original likelihood: -186.0450439453125
Adjusted likelihood: -186.0450439453125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0005)
State is out of distribution
Projection step: 0, Loss: 178.632568359375
Projection step: 1, Loss: 167.22140502929688
Projection step: 2, Loss: 161.93331909179688
Projection step: 3, Loss: 157.80587768554688
Projection step: 4, Loss: 149.74163818359375
Projection step: 5, Loss: 138.2481689453125
Projection step: 6, Loss: 137.41409301757812
Projection step: 7, Loss: 127.02427673339844
Projection step: 8, Loss: 132.9267578125
Projection step: 9, Loss: 123.58031463623047
Projection step: 10, Loss: 121.08798217773438
Projection step: 11, Loss: 118.85362243652344
Projection step: 12, Loss: 111.43473815917969
Projection step: 13, Loss: 115.37335205078125
Projection step: 14, Loss: 112.9118881225586
Projection step: 15, Loss: 106.7876968383789
Projection step: 16, Loss: 104.65674591064453
Final likelihood: tensor([-116.8605, -106.7261, -114.0372,  -87.9578,  -99.7660, -109.1653,
        -110.8562, -109.6904,  -89.4691, -111.4659, -102.8528, -103.0384,
        -106.5296, -107.1060, -101.6705,  -97.3161])
Final projection likelihood: -104.6567
1 mode projection succeeded
New goal: tensor([ 0.1414,  0.5316,  0.5687,  0.6883, -0.1061,  0.5742,  0.9456,  0.8729,
         1.4128,  0.4609,  0.1853,  1.0620,  0.0253,  0.0172, -0.9533],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -120.68926239013672
Adjusted likelihood: -120.68926239013672
Likelihood residual: 0.0
Original likelihood: -165.92129516601562
Adjusted likelihood: -165.92129516601562
Likelihood residual: 0.0
{'index': 165.92129516601562, 'thumb_middle': 120.68926239013672}
Current yaw: tensor([ 0.0323,  0.0182, -0.2349], device='cuda:1')
5 thumb_middle
tensor([ 0.1405,  0.5476,  0.5956,  0.6969, -0.2036,  0.6020,  0.9279,  0.8760,
         1.4236,  0.4890,  0.1044,  1.0094,  0.0323,  0.0182, -0.2349,  0.1266],
       device='cuda:1')
Solve time for step 1 8.930406430969015
Current ori: tensor([ 0.0323,  0.0182, -0.2349], device='cuda:1')
Index force: tensor([0.6051, 0.6063, 0.5999, 0.5796], device='cuda:1')
tensor([ 0.1382,  0.5479,  0.5930,  0.6951, -0.2462,  0.5413,  0.8850,  0.8386,
         1.3502,  0.4517,  0.0690,  0.9976,  0.0326,  0.0214, -0.2348,  0.1915],
       device='cuda:1')
Solve time for step 2 3.4091654969961382
Current ori: tensor([ 0.0326,  0.0214, -0.2348], device='cuda:1')
Index force: tensor([0.5995, 0.5943, 0.5749], device='cuda:1')
tensor([ 0.1495,  0.5514,  0.5935,  0.7091, -0.2436,  0.5448,  0.8895,  0.8391,
         1.3443,  0.4496,  0.0608,  0.9997,  0.0336,  0.0145, -0.2348,  0.1925],
       device='cuda:1')
Solve time for step 3 3.2975689290324226
Current ori: tensor([ 0.0336,  0.0145, -0.2348], device='cuda:1')
Index force: tensor([0.5825, 0.5660], device='cuda:1')
tensor([ 0.1442,  0.5437,  0.5957,  0.7143, -0.2410,  0.5416,  0.8877,  0.8364,
         1.3463,  0.4484,  0.0624,  1.0009,  0.0356,  0.0180, -0.2348,  0.1928],
       device='cuda:1')
Solve time for step 4 3.255594435031526
Current ori: tensor([ 0.0356,  0.0180, -0.2348], device='cuda:1')
Index force: tensor([0.5750], device='cuda:1')
Storing RECOVERY transition: reward=-0.0072 (scaled=-0.0072), steps=1
Reward stats updated: mean 0.0186 -> 0.0185, std: 0.0714
Collected 147 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.6299, Q2 Loss=0.6299, Entropy=0.3512, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1057
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=1.9160, Q2 Loss=1.9160, Entropy=0.2466, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7115
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.7256, Q2 Loss=2.7256, Entropy=0.0002, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9188
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.9542, Q2 Loss=0.9542, Entropy=0.0285, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2861
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.8982, Q2 Loss=1.8982, Entropy=0.0012, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4343

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.8%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000547
Q1 loss: 1.624749
Q2 loss: 1.624749
Current threshold: -149.7272
Global Scale Offset: 10.4030
Reward stats: mean=0.0185, std=0.0714, count=147
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 1.6247, Q2 Loss: 1.6247, Entropy: 0.1255, Mean TD Error: 1.4913, Threshold: -149.7272
Original likelihood: -171.19342041015625
Adjusted likelihood: -171.19342041015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.0333)
Current yaw: tensor([ 0.0402,  0.0206, -0.2323], device='cuda:1')
6 turn
Sampling time 3.59490161301801
tensor([ 0.1176,  0.5375,  0.5821,  0.7059, -0.1834,  0.5760,  0.9257,  0.8584,
         1.4031,  0.4595,  0.1239,  1.0428,  0.0402,  0.0206, -0.2323, -0.0134],
       device='cuda:1')
Original likelihood: -167.49472045898438
Adjusted likelihood: -167.49472045898438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0644)
State is out of distribution
Projection step: 0, Loss: 171.73239135742188
Projection step: 1, Loss: 163.0806427001953
Projection step: 2, Loss: 156.025390625
Projection step: 3, Loss: 150.21533203125
Projection step: 4, Loss: 146.22283935546875
Projection step: 5, Loss: 139.56053161621094
Projection step: 6, Loss: 131.94097900390625
Projection step: 7, Loss: 127.87359619140625
Projection step: 8, Loss: 132.3334503173828
Projection step: 9, Loss: 117.70619201660156
Projection step: 10, Loss: 113.99560546875
Projection step: 11, Loss: 116.20169067382812
Projection step: 12, Loss: 116.28221130371094
Projection step: 13, Loss: 110.11209869384766
Projection step: 14, Loss: 106.97999572753906
Projection step: 15, Loss: 110.69775390625
Projection step: 16, Loss: 106.2960433959961
Projection step: 17, Loss: 103.08319854736328
Final likelihood: tensor([ -95.4830,  -89.6124, -119.4673, -106.5101,  -97.3123,  -99.6694,
        -112.8791, -111.1683,  -93.8066, -102.0040, -103.4788,  -93.4545,
         -95.9700, -120.5600, -107.5742, -100.3812])
Final projection likelihood: -103.0832
1 mode projection succeeded
New goal: tensor([ 0.1175,  0.5348,  0.5683,  0.6679, -0.0936,  0.5507,  0.9136,  0.8691,
         1.3823,  0.4276,  0.2009,  1.0970,  0.0322,  0.0173, -1.1359],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -106.45990753173828
Adjusted likelihood: -106.45990753173828
Likelihood residual: 0.0
Original likelihood: -167.63442993164062
Adjusted likelihood: -167.63442993164062
Likelihood residual: 0.0
{'index': 167.63442993164062, 'thumb_middle': 106.45990753173828}
Current yaw: tensor([ 0.0402,  0.0206, -0.2323], device='cuda:1')
7 thumb_middle
tensor([ 0.1176,  0.5375,  0.5821,  0.7059, -0.1834,  0.5760,  0.9257,  0.8584,
         1.4031,  0.4595,  0.1239,  1.0428,  0.0402,  0.0206, -0.2323, -0.0134],
       device='cuda:1')
Solve time for step 1 9.022779752966017
Current ori: tensor([ 0.0402,  0.0206, -0.2323], device='cuda:1')
Index force: tensor([0.5858, 0.6023, 0.5937, 0.6087], device='cuda:1')
tensor([ 0.1180,  0.5475,  0.5814,  0.6808, -0.2221,  0.5250,  0.8676,  0.8364,
         1.3190,  0.4167,  0.0833,  1.0361,  0.0346,  0.0248, -0.2322,  0.0497],
       device='cuda:1')
Solve time for step 2 3.509761505003553
Current ori: tensor([ 0.0346,  0.0248, -0.2322], device='cuda:1')
Index force: tensor([0.5911, 0.5845, 0.5995], device='cuda:1')
tensor([ 0.1276,  0.5523,  0.5852,  0.6793, -0.2200,  0.5260,  0.8634,  0.8375,
         1.3153,  0.4133,  0.0806,  1.0355,  0.0334,  0.0194, -0.2322,  0.0599],
       device='cuda:1')
Solve time for step 3 3.571665111987386
Current ori: tensor([ 0.0334,  0.0194, -0.2322], device='cuda:1')
Index force: tensor([0.5729, 0.5889], device='cuda:1')
tensor([ 0.1210,  0.5434,  0.5851,  0.6898, -0.2224,  0.5246,  0.8612,  0.8351,
         1.3173,  0.4113,  0.0840,  1.0398,  0.0362,  0.0237, -0.2322,  0.0580],
       device='cuda:1')
Solve time for step 4 3.2385042320238426
Current ori: tensor([ 0.0362,  0.0237, -0.2322], device='cuda:1')
Index force: tensor([0.5588], device='cuda:1')
Storing RECOVERY transition: reward=0.0031 (scaled=0.0031), steps=0
Reward stats updated: mean 0.0185 -> 0.0184, std: 0.0712
Collected 148 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=1.6511, Q2 Loss=1.6511, Entropy=0.0114, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4223
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5821, Q2 Loss=0.5821, Entropy=0.1227, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3936
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.0469, Q2 Loss=2.0469, Entropy=0.0095, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7585
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=1.3305, Q2 Loss=1.3305, Entropy=0.2707, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1958
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.3914, Q2 Loss=1.3914, Entropy=0.0194, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1077

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000336
Q1 loss: 1.400411
Q2 loss: 1.400411
Current threshold: -149.7226
Global Scale Offset: 10.9321
Reward stats: mean=0.0184, std=0.0712, count=148
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 1.4004, Q2 Loss: 1.4004, Entropy: 0.0867, Mean TD Error: 1.1756, Threshold: -149.7226
Original likelihood: -141.700439453125
Adjusted likelihood: -141.700439453125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7440)
Current yaw: tensor([ 0.0375,  0.0230, -0.2353], device='cuda:1')
8 turn
Sampling time 3.630671810999047
tensor([ 0.1008,  0.5437,  0.5745,  0.6717, -0.1597,  0.5602,  0.8989,  0.8576,
         1.3732,  0.4222,  0.1409,  1.0780,  0.0375,  0.0230, -0.2353, -0.1225],
       device='cuda:1')
Original likelihood: -135.03564453125
Adjusted likelihood: -135.03564453125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8850)
Solve time for step 1 14.000170073006302
Current ori: tensor([ 0.0375,  0.0230, -0.2353], device='cuda:1')
Middle force: tensor([0.6580, 0.5887, 0.5261, 0.5835, 1.4237, 0.4945, 0.4740, 0.5049, 0.5078,
        0.6968, 0.5867, 0.7719], device='cuda:1')
Thumb force: tensor([1.5967, 0.5207, 1.3280, 3.0283, 1.1538, 0.5290, 0.7475, 0.5340, 0.5385,
        0.8952, 0.5831, 0.5992], device='cuda:1')
Index force: tensor([0.5141, 0.5376, 0.7086, 0.7219, 0.5936, 0.6963, 0.6867, 0.6132, 0.5575,
        0.5552, 0.6002, 0.5629], device='cuda:1')
Storing NORMAL transition: reward=0.0031 (scaled=0.0031), steps=1
Reward stats updated: mean 0.0184 -> 0.0183, std: 0.0710
Collected 149 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=6.5799, Q2 Loss=6.5799, Entropy=0.0000, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6524
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=1.5621, Q2 Loss=1.5621, Entropy=0.0809, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5148
SAC Update 3/5: Actor Loss=-0.0058, Q1 Loss=0.8445, Q2 Loss=0.8445, Entropy=0.3431, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0348
SAC Update 4/5: Actor Loss=-0.0027, Q1 Loss=1.0699, Q2 Loss=1.0699, Entropy=0.2769, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5498
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.2041, Q2 Loss=1.2041, Entropy=0.2163, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9673

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001993
Q1 loss: 2.252092
Q2 loss: 2.252092
Current threshold: -149.7208
Global Scale Offset: 11.5884
Reward stats: mean=0.0183, std=0.0710, count=149
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 2.2521, Q2 Loss: 2.2521, Entropy: 0.1834, Mean TD Error: 1.1438, Threshold: -149.7208
tensor([ 0.0547,  0.5110,  0.5849,  0.6502, -0.1667,  0.5494,  0.8239,  1.0245,
         1.4873,  0.3695,  0.0185,  0.8997,  0.0503,  0.0306, -0.2399, -0.3023],
       device='cuda:1')
Original likelihood: -209.01031494140625
Adjusted likelihood: -209.01031494140625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 204.98129272460938
Projection step: 1, Loss: 193.73345947265625
Projection step: 2, Loss: 178.12759399414062
Projection step: 3, Loss: 177.40382385253906
Projection step: 4, Loss: 175.35879516601562
Projection step: 5, Loss: 166.72317504882812
Projection step: 6, Loss: 161.69989013671875
Projection step: 7, Loss: 158.0397491455078
Projection step: 8, Loss: 155.75894165039062
Projection step: 9, Loss: 147.7967071533203
Projection step: 10, Loss: 145.31443786621094
Projection step: 11, Loss: 143.54217529296875
Projection step: 12, Loss: 137.63299560546875
Projection step: 13, Loss: 130.35269165039062
Projection step: 14, Loss: 127.6258316040039
Projection step: 15, Loss: 125.0960922241211
Projection step: 16, Loss: 124.9813461303711
Projection step: 17, Loss: 118.43887329101562
Projection step: 18, Loss: 119.1743392944336
Projection step: 19, Loss: 111.174072265625
Projection step: 20, Loss: 113.93392181396484
Projection step: 21, Loss: 107.48567962646484
Projection step: 22, Loss: 105.932861328125
Projection step: 23, Loss: 106.31036376953125
Projection step: 24, Loss: 102.50421142578125
Final likelihood: tensor([ -94.3436,  -95.0238,  -99.9473,  -83.5890, -111.0889, -113.8018,
        -105.8674, -109.5836, -103.6488,  -90.1563,  -93.2010, -104.8984,
         -95.6131, -121.0520, -108.3059, -109.9465])
Final projection likelihood: -102.5042
1 mode projection succeeded
New goal: tensor([ 0.0579,  0.5741,  0.5519,  0.5858, -0.0939,  0.5000,  0.7843,  0.8963,
         1.4084,  0.3650,  0.1581,  1.0748,  0.0398,  0.0222, -1.7088],
       device='cuda:1')
tensor([[0.0120]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -103.44129943847656
Adjusted likelihood: -103.44129943847656
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 103.44129943847656}
Current yaw: tensor([ 0.0503,  0.0306, -0.2399], device='cuda:1')
9 thumb_middle
tensor([ 0.0547,  0.5110,  0.5849,  0.6502, -0.1667,  0.5494,  0.8239,  1.0245,
         1.4873,  0.3695,  0.0185,  0.8997,  0.0503,  0.0306, -0.2399, -0.3023],
       device='cuda:1')
Solve time for step 1 9.068580663995817
Current ori: tensor([ 0.0503,  0.0306, -0.2399], device='cuda:1')
Index force: tensor([0.5892, 0.5929, 0.6025, 0.5832], device='cuda:1')
tensor([ 0.0533,  0.5580,  0.5492,  0.5925, -0.1863,  0.5009,  0.7634,  0.8994,
         1.3757,  0.3524,  0.0562,  1.0043,  0.0342,  0.0303, -0.2399, -0.3337],
       device='cuda:1')
Solve time for step 2 3.548290460021235
Current ori: tensor([ 0.0342,  0.0303, -0.2399], device='cuda:1')
Index force: tensor([0.5856, 0.5964, 0.5783], device='cuda:1')
tensor([ 0.0495,  0.5553,  0.5473,  0.5964, -0.1876,  0.5031,  0.7600,  0.8796,
         1.3661,  0.3511,  0.0596,  1.0258,  0.0352,  0.0324, -0.2399, -0.3373],
       device='cuda:1')
Solve time for step 3 3.4194467199849896
Current ori: tensor([ 0.0352,  0.0324, -0.2399], device='cuda:1')
Index force: tensor([0.5869, 0.5716], device='cuda:1')
tensor([ 0.0507,  0.5466,  0.5546,  0.6078, -0.1849,  0.5015,  0.7590,  0.8787,
         1.3642,  0.3474,  0.0618,  1.0301,  0.0381,  0.0322, -0.2399, -0.3316],
       device='cuda:1')
Solve time for step 4 3.2965894549852237
Current ori: tensor([ 0.0381,  0.0322, -0.2399], device='cuda:1')
Index force: tensor([0.6210], device='cuda:1')
Storing RECOVERY transition: reward=0.0078 (scaled=0.0078), steps=1
Reward stats updated: mean 0.0183 -> 0.0182, std: 0.0708
Collected 150 transitions for RL
SAC Update 1/5: Actor Loss=-0.0064, Q1 Loss=0.8337, Q2 Loss=0.8337, Entropy=0.5567, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6297
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=5.2188, Q2 Loss=5.2188, Entropy=0.0092, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6140
SAC Update 3/5: Actor Loss=-0.0026, Q1 Loss=1.2867, Q2 Loss=1.2867, Entropy=0.3936, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4433
SAC Update 4/5: Actor Loss=-0.0027, Q1 Loss=1.6621, Q2 Loss=1.6621, Entropy=0.2852, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2715
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.4499, Q2 Loss=1.4499, Entropy=0.0036, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9692

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002339
Q1 loss: 2.090251
Q2 loss: 2.090251
Current threshold: -149.7209
Global Scale Offset: 12.4928
Reward stats: mean=0.0182, std=0.0708, count=150
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 2.0903, Q2 Loss: 2.0903, Entropy: 0.2497, Mean TD Error: 1.7856, Threshold: -149.7209
Original likelihood: -138.65530395507812
Adjusted likelihood: -138.65530395507812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7886)
Current yaw: tensor([ 0.0344,  0.0285, -0.2463], device='cuda:1')
10 turn
Sampling time 3.6908830140018836
tensor([ 0.0536,  0.5586,  0.5502,  0.5894, -0.1102,  0.5484,  0.7977,  0.8994,
         1.4191,  0.3612,  0.1167,  1.0644,  0.0344,  0.0285, -0.2463, -0.2841],
       device='cuda:1')
Original likelihood: -120.74295043945312
Adjusted likelihood: -120.74295043945312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9821)
Solve time for step 1 14.109157553990372
Current ori: tensor([ 0.0344,  0.0285, -0.2463], device='cuda:1')
Middle force: tensor([1.2931, 0.5039, 0.5040, 0.5199, 0.5839, 0.6069, 1.0197, 0.7988, 0.7634,
        0.5884, 0.5166, 0.5813], device='cuda:1')
Thumb force: tensor([1.8798, 1.8287, 1.3357, 0.5480, 1.0616, 0.7692, 1.4686, 0.5811, 0.7105,
        0.6387, 0.5298, 0.5855], device='cuda:1')
Index force: tensor([0.5612, 0.8279, 0.7279, 0.6322, 0.5539, 0.5519, 0.5723, 0.5208, 0.5429,
        0.5675, 0.5020, 0.5659], device='cuda:1')
Storing NORMAL transition: reward=0.1946 (scaled=0.1946), steps=1
Reward stats updated: mean 0.0182 -> 0.0194, std: 0.0720
Collected 151 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=1.9455, Q2 Loss=1.9455, Entropy=0.0980, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5888
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.6190, Q2 Loss=0.6190, Entropy=0.2125, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3148
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=2.3530, Q2 Loss=2.3530, Entropy=0.1575, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7298
SAC Update 4/5: Actor Loss=-0.0040, Q1 Loss=0.5676, Q2 Loss=0.5676, Entropy=0.4336, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3208
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.2270, Q2 Loss=1.2270, Entropy=0.0568, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8190

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.1%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (43.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001075
Q1 loss: 1.342409
Q2 loss: 1.342409
Current threshold: -149.7190
Global Scale Offset: 13.5122
Reward stats: mean=0.0194, std=0.0720, count=151
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 1.3424, Q2 Loss: 1.3424, Entropy: 0.1917, Mean TD Error: 1.1546, Threshold: -149.7190
tensor([ 0.0409,  0.5335,  0.5113,  0.6885, -0.0313,  0.5022,  0.9009,  1.0311,
         1.3884,  0.4278,  0.1714,  0.9360,  0.0639, -0.0315, -0.4468, -1.3183],
       device='cuda:1')
Original likelihood: -198.0782470703125
Adjusted likelihood: -198.0782470703125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0006)
State is out of distribution
Projection step: 0, Loss: 171.03076171875
Projection step: 1, Loss: 188.9681396484375
Projection step: 2, Loss: 167.11013793945312
Projection step: 3, Loss: 165.62176513671875
Projection step: 4, Loss: 166.81661987304688
Projection step: 5, Loss: 158.6483612060547
Projection step: 6, Loss: 155.81582641601562
Projection step: 7, Loss: 156.29449462890625
Projection step: 8, Loss: 148.1678009033203
Projection step: 9, Loss: 146.89816284179688
Projection step: 10, Loss: 140.89337158203125
Projection step: 11, Loss: 154.00074768066406
Projection step: 12, Loss: 142.25155639648438
Projection step: 13, Loss: 138.14837646484375
Projection step: 14, Loss: 137.94732666015625
Projection step: 15, Loss: 137.40728759765625
Projection step: 16, Loss: 129.69456481933594
Projection step: 17, Loss: 133.57778930664062
Projection step: 18, Loss: 127.96831512451172
Projection step: 19, Loss: 119.01863098144531
Projection step: 20, Loss: 123.88973999023438
Projection step: 21, Loss: 118.40316772460938
Projection step: 22, Loss: 120.92230987548828
Projection step: 23, Loss: 126.53387451171875
Projection step: 24, Loss: 117.61004638671875
Final likelihood: tensor([-104.1475, -107.7958, -134.0338, -123.1740, -122.6004, -105.7173,
        -120.9918, -106.2578, -116.9173,  -95.6982, -117.6631, -101.4682,
        -144.4099,  -97.6386, -134.9870,  -99.8801])
Final projection likelihood: -114.5863
1 mode projection succeeded
New goal: tensor([ 0.0734,  0.5268,  0.5914,  0.6538, -0.0483,  0.5005,  0.8751,  0.9170,
         1.3082,  0.2628,  0.1866,  1.1660,  0.0565, -0.0186, -1.2333],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -152.822021484375
Adjusted likelihood: -152.822021484375
Likelihood residual: 0.0
Original likelihood: -205.2135467529297
Adjusted likelihood: -205.2135467529297
Likelihood residual: 0.0
{'index': 205.2135467529297, 'thumb_middle': 152.822021484375}
Current yaw: tensor([ 0.0639, -0.0315, -0.4468], device='cuda:1')
11 thumb_middle
tensor([ 0.0409,  0.5335,  0.5113,  0.6885, -0.0313,  0.5022,  0.9009,  1.0311,
         1.3884,  0.4278,  0.1714,  0.9360,  0.0639, -0.0315, -0.4468, -1.3183],
       device='cuda:1')
Solve time for step 1 8.795978087000549
Current ori: tensor([ 0.0639, -0.0315, -0.4468], device='cuda:1')
Index force: tensor([0.5379, 0.4999, 0.5742, 0.5821], device='cuda:1')
tensor([ 0.0338,  0.5305,  0.5629,  0.6632, -0.1129,  0.5004,  0.8526,  0.9170,
         1.2645,  0.2729,  0.0968,  1.0886,  0.1387, -0.0439, -0.4468, -0.7089],
       device='cuda:1')
Solve time for step 2 3.5888504899921827
Current ori: tensor([ 0.1387, -0.0439, -0.4468], device='cuda:1')
Index force: tensor([0.5000, 0.5669, 0.5748], device='cuda:1')
tensor([ 0.0236,  0.5579,  0.5881,  0.6466, -0.0970,  0.5213,  0.8638,  0.9075,
         1.2763,  0.2507,  0.1075,  1.1243,  0.2506, -0.1116, -0.4312,  0.0571],
       device='cuda:1')
Solve time for step 3 3.444818641000893
Current ori: tensor([ 0.2506, -0.1116, -0.4312], device='cuda:1')
Index force: tensor([0.6446, 0.5025], device='cuda:1')
tensor([ 0.0176,  0.5799,  0.8853,  0.8635, -0.0132,  0.5678,  0.9193,  0.9325,
         1.2973,  0.2542,  0.1385,  1.1541,  0.2712, -0.1510, -0.3616,  0.5884],
       device='cuda:1')
Solve time for step 4 3.4273266410455108
Current ori: tensor([ 0.2712, -0.1510, -0.3616], device='cuda:1')
Index force: tensor([0.5586], device='cuda:1')
Storing RECOVERY transition: reward=-0.2289 (scaled=-0.2289), steps=1
Reward stats updated: mean 0.0194 -> 0.0177, std: 0.0745
Collected 152 transitions for RL
SAC Update 1/5: Actor Loss=-0.0015, Q1 Loss=1.0849, Q2 Loss=1.0849, Entropy=0.2796, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0422
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=1.0599, Q2 Loss=1.0599, Entropy=0.0038, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8798
SAC Update 3/5: Actor Loss=-0.0042, Q1 Loss=1.1991, Q2 Loss=1.1991, Entropy=0.4916, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0119
SAC Update 4/5: Actor Loss=-0.0053, Q1 Loss=1.7404, Q2 Loss=1.7404, Entropy=0.4531, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3447
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.4805, Q2 Loss=1.4805, Entropy=0.0508, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4542

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (40.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002241
Q1 loss: 1.312968
Q2 loss: 1.312968
Current threshold: -149.7138
Global Scale Offset: 14.7420
Reward stats: mean=0.0177, std=0.0745, count=152
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 1.3130, Q2 Loss: 1.3130, Entropy: 0.2558, Mean TD Error: 1.1465, Threshold: -149.7138
Original likelihood: -340.64276123046875
Adjusted likelihood: -340.64276123046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 343.5968017578125
Projection step: 1, Loss: 335.95635986328125
Projection step: 2, Loss: 337.8329772949219
Projection step: 3, Loss: 337.7205505371094
Projection step: 4, Loss: 332.73968505859375
Projection step: 5, Loss: 351.2862854003906
Projection step: 6, Loss: 327.4808044433594
Projection step: 7, Loss: 333.0673522949219
Projection step: 8, Loss: 341.76708984375
Projection step: 9, Loss: 315.5393371582031
Projection step: 10, Loss: 335.21099853515625
Projection step: 11, Loss: 338.3412170410156
Projection step: 12, Loss: 333.42889404296875
Projection step: 13, Loss: 326.66351318359375
Projection step: 14, Loss: 333.46282958984375
Projection step: 15, Loss: 323.6434326171875
Projection step: 16, Loss: 322.145751953125
Projection step: 17, Loss: 336.51715087890625
Projection step: 18, Loss: 332.880615234375
Projection step: 19, Loss: 312.902587890625
Projection step: 20, Loss: 321.494873046875
Projection step: 21, Loss: 320.37921142578125
Projection step: 22, Loss: 307.3309326171875
Projection step: 23, Loss: 322.2638854980469
Projection step: 24, Loss: 314.8609619140625
Final likelihood: tensor([-317.8782, -331.6740, -317.3111, -313.7207, -359.0535, -261.7860,
        -387.5490, -290.5447, -308.5571, -320.2444, -308.7131, -301.9398,
        -343.0267, -328.2946, -233.9473, -309.0111])
Final projection likelihood: -314.5782
1 mode projection failed, trying anyway
New goal: tensor([ 0.0277,  0.5528,  0.6261,  0.7805,  0.1545,  0.6510,  0.9791,  0.9631,
         1.3173,  0.1950,  0.2821,  1.2911,  0.2598, -0.1451, -0.2122],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0019]], device='cuda:1')
Original likelihood: -344.51776123046875
Adjusted likelihood: -344.51776123046875
Likelihood residual: 0.0
Original likelihood: -397.0045166015625
Adjusted likelihood: -397.0045166015625
Likelihood residual: 0.0
{'index': 397.0045166015625, 'thumb_middle': 344.51776123046875}
Current yaw: tensor([ 0.2655, -0.1533, -0.3015], device='cuda:1')
12 thumb_middle
tensor([-0.0132,  0.6038,  0.6645,  0.6908,  0.1878,  0.6962,  1.0675,  1.0112,
         1.3289,  0.2476,  0.2340,  1.2324,  0.2655, -0.1533, -0.3015,  0.7204],
       device='cuda:1')
Solve time for step 1 9.062157342035789
Current ori: tensor([ 0.2655, -0.1533, -0.3015], device='cuda:1')
Index force: tensor([0.6038, 0.5686, 0.5850, 0.6049], device='cuda:1')
tensor([-0.0030,  0.6982,  0.6316,  0.7744,  0.1356,  0.6867,  0.9782,  0.9491,
         1.2623,  0.1931,  0.1301,  1.1953,  0.3581, -0.2844, -0.1666, -1.2083],
       device='cuda:1')
Solve time for step 2 3.4676199040259235
Current ori: tensor([ 0.3581, -0.2844, -0.1666], device='cuda:1')
Index force: tensor([0.5497, 0.5482, 0.5481], device='cuda:1')
tensor([-0.0214,  0.7604,  0.5955,  0.7544,  0.1942,  0.7259,  1.0321,  0.9870,
         1.2670,  0.1925,  0.1403,  1.2255,  0.3735, -0.3304, -0.1219, -4.9757],
       device='cuda:1')
Solve time for step 3 3.420589703018777
Current ori: tensor([ 0.3735, -0.3304, -0.1219], device='cuda:1')
Index force: tensor([0.5397, 0.5385], device='cuda:1')
tensor([-0.0374,  0.6942,  0.6061,  0.7763,  0.1970,  0.7049,  1.0411,  0.9710,
         1.2607,  0.2066,  0.1877,  1.2787,  0.3727, -0.3273, -0.1389,  5.1813],
       device='cuda:1')
Solve time for step 4 3.4511286439956166
Current ori: tensor([ 0.3727, -0.3273, -0.1389], device='cuda:1')
Index force: tensor([0.5314], device='cuda:1')
Storing RECOVERY transition: reward=-0.4451 (scaled=-0.4451), steps=1
Reward stats updated: mean 0.0177 -> 0.0147, std: 0.0831
Collected 153 transitions for RL
SAC Update 1/5: Actor Loss=-0.0023, Q1 Loss=5.3662, Q2 Loss=5.3662, Entropy=0.2526, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4755
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=10.5505, Q2 Loss=10.5505, Entropy=0.0060, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8800
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=1.1786, Q2 Loss=1.1786, Entropy=0.0818, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0114
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=3.3861, Q2 Loss=3.3861, Entropy=0.1801, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2947
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=2.7088, Q2 Loss=2.7088, Entropy=0.0120, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1436

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.1%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (42.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000772
Q1 loss: 4.638032
Q2 loss: 4.638032
Current threshold: -149.7048
Global Scale Offset: 16.1668
Reward stats: mean=0.0147, std=0.0831, count=153
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 4.6380, Q2 Loss: 4.6380, Entropy: 0.1065, Mean TD Error: 3.1610, Threshold: -149.7048
Original likelihood: -1155.7884521484375
Adjusted likelihood: -1155.7884521484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 10
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
1 turn
Sampling time 3.5700103280250914
tensor([ 1.3350e-01,  5.9651e-01,  5.7067e-01,  6.0602e-01, -1.0669e-01,
         5.1194e-01,  9.4543e-01,  8.5605e-01,  1.2687e+00,  2.7632e-01,
         2.2700e-01,  1.1382e+00, -9.0228e-04,  1.4547e-02, -4.3402e-02,
         1.9825e-01], device='cuda:1')
Original likelihood: -107.44157409667969
Adjusted likelihood: -107.44157409667969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9921)
Solve time for step 1 14.296549721970223
Current ori: tensor([-0.0009,  0.0145, -0.0434], device='cuda:1')
Middle force: tensor([1.1713, 1.7542, 0.8311, 0.5279, 0.5711, 0.8913, 1.1481, 0.5132, 0.6971,
        0.8816, 0.8495, 0.4953], device='cuda:1')
Thumb force: tensor([0.8823, 1.3736, 0.5750, 0.5551, 0.5409, 1.2568, 0.6562, 0.5535, 0.6028,
        1.2107, 1.5885, 0.5547], device='cuda:1')
Index force: tensor([0.9266, 1.8154, 0.5677, 0.5993, 0.5908, 0.8101, 0.5444, 0.5928, 0.5955,
        0.5489, 0.6096, 0.7531], device='cuda:1')
Storing NORMAL transition: reward=0.0147 (scaled=0.0147), steps=1
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0828
Collected 154 transitions for RL
SAC Update 1/5: Actor Loss=-0.0038, Q1 Loss=1.2389, Q2 Loss=1.2389, Entropy=0.3488, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9630
SAC Update 2/5: Actor Loss=-0.0051, Q1 Loss=1.4064, Q2 Loss=1.4064, Entropy=0.4356, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6982
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8318, Q2 Loss=0.8318, Entropy=0.0001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6224
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=3.1304, Q2 Loss=3.1304, Entropy=0.0807, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2380
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5615, Q2 Loss=0.5615, Entropy=0.0037, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2832

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.05s (20.0%)
Actor update: 0.12s (42.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001851
Q1 loss: 1.433800
Q2 loss: 1.433800
Current threshold: -149.6936
Global Scale Offset: 17.5665
Reward stats: mean=0.0147, std=0.0828, count=154
----------------------------------------------
SAC Update - Actor Loss: -0.0019, Q1 Loss: 1.4338, Q2 Loss: 1.4338, Entropy: 0.1738, Mean TD Error: 1.3610, Threshold: -149.6936
tensor([ 0.1126,  0.6261,  0.5216,  0.5803, -0.1230,  0.5367,  0.8791,  0.8947,
         1.2631,  0.3017,  0.2722,  1.0719, -0.0101,  0.0177, -0.0583,  0.3168],
       device='cuda:1')
Original likelihood: -87.31282043457031
Adjusted likelihood: -87.31282043457031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 2 5.462376036040951
Current ori: tensor([-0.0101,  0.0177, -0.0583], device='cuda:1')
Middle force: tensor([1.7345, 0.8236, 0.5272, 0.5692, 0.8816, 1.1330, 0.5120, 0.6913, 0.8732,
        0.8363, 0.5016], device='cuda:1')
Thumb force: tensor([1.3203, 0.5711, 0.5509, 0.5380, 1.2299, 0.6498, 0.5493, 0.5977, 1.1908,
        1.5602, 0.5509], device='cuda:1')
Index force: tensor([1.7815, 0.5648, 0.5965, 0.5877, 0.8016, 0.5420, 0.5936, 0.5918, 0.5462,
        0.6059, 0.7751], device='cuda:1')
Storing NORMAL transition: reward=0.2219 (scaled=0.2219), steps=1
Reward stats updated: mean 0.0147 -> 0.0160, std: 0.0842
Collected 155 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=4.5760, Q2 Loss=4.5760, Entropy=0.0355, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0997
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=1.1802, Q2 Loss=1.1802, Entropy=0.1169, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9829
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=1.0716, Q2 Loss=1.0716, Entropy=0.1944, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8565
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=1.7590, Q2 Loss=1.7590, Entropy=0.1193, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9158
SAC Update 5/5: Actor Loss=-0.0019, Q1 Loss=0.7732, Q2 Loss=0.7732, Entropy=0.4679, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0577

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.3%)
Actor update: 0.09s (39.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000811
Q1 loss: 1.871995
Q2 loss: 1.871995
Current threshold: -149.6853
Global Scale Offset: 19.0084
Reward stats: mean=0.0160, std=0.0842, count=155
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 1.8720, Q2 Loss: 1.8720, Entropy: 0.1868, Mean TD Error: 1.5825, Threshold: -149.6853
tensor([ 0.1951,  0.7359,  0.4562,  0.5898, -0.0316,  0.5398,  0.9015,  0.9930,
         1.2797,  0.3319,  0.1640,  1.0073, -0.0280, -0.0411, -0.2842,  0.7211],
       device='cuda:1')
Original likelihood: -155.7564697265625
Adjusted likelihood: -155.7564697265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3828)
Solve time for step 3 5.123444191005547
Current ori: tensor([-0.0280, -0.0411, -0.2842], device='cuda:1')
Middle force: tensor([0.8062, 0.5278, 0.5690, 0.8880, 1.1071, 0.5110, 0.6797, 0.8730, 0.8182,
        0.5007], device='cuda:1')
Thumb force: tensor([0.5680, 0.5439, 0.5341, 1.1907, 0.6468, 0.5439, 0.5938, 1.1629, 1.5361,
        0.5469], device='cuda:1')
Index force: tensor([0.5644, 0.5967, 0.5869, 0.7947, 0.5416, 0.5924, 0.5906, 0.5435, 0.6009,
        0.8097], device='cuda:1')
Storing NORMAL transition: reward=0.0184 (scaled=0.0184), steps=1
Reward stats updated: mean 0.0160 -> 0.0160, std: 0.0839
Collected 156 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=1.1318, Q2 Loss=1.1318, Entropy=0.2043, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6868
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.5794, Q2 Loss=0.5794, Entropy=0.0024, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9498
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.5665, Q2 Loss=0.5665, Entropy=0.3843, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6189
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=0.9228, Q2 Loss=0.9228, Entropy=0.3468, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6518
SAC Update 5/5: Actor Loss=-0.0015, Q1 Loss=7.7269, Q2 Loss=7.7269, Entropy=0.2176, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1363

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (38.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002034
Q1 loss: 2.185484
Q2 loss: 2.185484
Current threshold: -149.6793
Global Scale Offset: 20.6062
Reward stats: mean=0.0160, std=0.0839, count=156
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 2.1855, Q2 Loss: 2.1855, Entropy: 0.2311, Mean TD Error: 1.4087, Threshold: -149.6793
tensor([ 0.1367,  0.6490,  0.5005,  0.5925,  0.0342,  0.5616,  0.9458,  0.9857,
         1.2593,  0.3135,  0.0792,  1.0891, -0.0198, -0.0908, -0.3148,  1.0425],
       device='cuda:1')
Original likelihood: -174.2013397216797
Adjusted likelihood: -174.2013397216797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1321)
State is out of distribution
Projection step: 0, Loss: 168.6974334716797
Projection step: 1, Loss: 170.95968627929688
Projection step: 2, Loss: 172.86810302734375
Projection step: 3, Loss: 165.3846435546875
Projection step: 4, Loss: 172.10997009277344
Projection step: 5, Loss: 187.7378387451172
Projection step: 6, Loss: 185.5345458984375
Projection step: 7, Loss: 177.89512634277344
Projection step: 8, Loss: 179.27040100097656
Projection step: 9, Loss: 177.696044921875
Projection step: 10, Loss: 176.20269775390625
Projection step: 11, Loss: 175.78384399414062
Projection step: 12, Loss: 171.15304565429688
Projection step: 13, Loss: 166.36489868164062
Projection step: 14, Loss: 178.47030639648438
Projection step: 15, Loss: 171.9365234375
Projection step: 16, Loss: 176.748779296875
Projection step: 17, Loss: 164.27920532226562
Projection step: 18, Loss: 160.74070739746094
Projection step: 19, Loss: 164.15481567382812
Projection step: 20, Loss: 164.83633422851562
Projection step: 21, Loss: 161.33599853515625
Projection step: 22, Loss: 161.49534606933594
Projection step: 23, Loss: 157.79757690429688
Projection step: 24, Loss: 157.0245361328125
Final likelihood: tensor([-151.2206, -134.5245, -135.5725, -159.9655, -149.8579, -149.8105,
        -142.8944, -162.9417, -127.8852, -144.4997, -170.7651, -158.9786,
        -162.6940, -136.3169, -130.6967, -145.3023])
Final projection likelihood: -147.7454
1 mode projection succeeded
New goal: tensor([ 0.1145,  0.6075,  0.4723,  0.6569,  0.0266,  0.5541,  0.8631,  0.7874,
         1.3116,  0.2152,  0.1213,  0.9598, -0.0204, -0.0759, -1.0338],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -195.952880859375
Adjusted likelihood: -195.952880859375
Likelihood residual: 0.0
Original likelihood: -217.78146362304688
Adjusted likelihood: -217.78146362304688
Likelihood residual: 0.0
{'index': 217.78146362304688, 'thumb_middle': 195.952880859375}
Current yaw: tensor([-0.0198, -0.0908, -0.3148], device='cuda:1')
2 thumb_middle
tensor([ 0.1367,  0.6490,  0.5005,  0.5925,  0.0342,  0.5616,  0.9458,  0.9857,
         1.2593,  0.3135,  0.0792,  1.0891, -0.0198, -0.0908, -0.3148,  1.0425],
       device='cuda:1')
Solve time for step 1 8.805552437959705
Current ori: tensor([-0.0198, -0.0908, -0.3148], device='cuda:1')
Index force: tensor([0.5345, 0.6246, 0.5004, 0.5001], device='cuda:1')
tensor([ 0.1388,  0.6540,  0.4808,  0.6213, -0.0114,  0.5596,  0.8610,  0.8032,
         1.2736,  0.2196,  0.0320,  0.9570, -0.0290, -0.0919, -0.3148,  0.8903],
       device='cuda:1')
Solve time for step 2 3.519132641959004
Current ori: tensor([-0.0290, -0.0919, -0.3148], device='cuda:1')
Index force: tensor([0.5894, 0.5889, 0.5807], device='cuda:1')
tensor([ 0.1076,  0.6140,  0.4878,  0.6537, -0.0377,  0.5590,  0.8461,  0.7827,
         1.2899,  0.2120,  0.0442,  0.9438, -0.0195, -0.0706, -0.3148,  0.8844],
       device='cuda:1')
Solve time for step 3 3.392199139983859
Current ori: tensor([-0.0195, -0.0706, -0.3148], device='cuda:1')
Index force: tensor([0.5818, 0.5756], device='cuda:1')
tensor([ 0.0935,  0.6080,  0.4775,  0.6622, -0.0545,  0.5624,  0.8463,  0.7665,
         1.3012,  0.2085,  0.0511,  0.9306, -0.0183, -0.0616, -0.3148,  0.8651],
       device='cuda:1')
Solve time for step 4 3.4299424489727244
Current ori: tensor([-0.0183, -0.0616, -0.3148], device='cuda:1')
Index force: tensor([0.5509], device='cuda:1')
Storing RECOVERY transition: reward=0.0052 (scaled=0.0017), steps=3
Reward stats updated: mean 0.0160 -> 0.0160, std: 0.0837
Collected 157 transitions for RL
SAC Update 1/5: Actor Loss=-0.0027, Q1 Loss=0.7610, Q2 Loss=0.7610, Entropy=0.3547, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3876
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.5997, Q2 Loss=0.5997, Entropy=0.1372, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3885
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.7384, Q2 Loss=2.7384, Entropy=0.0073, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7467
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=1.3675, Q2 Loss=1.3675, Entropy=0.2257, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3862
SAC Update 5/5: Actor Loss=-0.0012, Q1 Loss=1.1106, Q2 Loss=1.1106, Entropy=0.2640, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2294

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001000
Q1 loss: 1.315412
Q2 loss: 1.315412
Current threshold: -149.6717
Global Scale Offset: 22.0582
Reward stats: mean=0.0160, std=0.0837, count=157
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 1.3154, Q2 Loss: 1.3154, Entropy: 0.1978, Mean TD Error: 1.2277, Threshold: -149.6717
Original likelihood: -125.71998596191406
Adjusted likelihood: -125.71998596191406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.8468)
State is out of distribution
Projection step: 0, Loss: 127.55496215820312
Projection step: 1, Loss: 121.02710723876953
Projection step: 2, Loss: 127.77749633789062
Projection step: 3, Loss: 124.34959411621094
Projection step: 4, Loss: 122.95030975341797
Projection step: 5, Loss: 130.59994506835938
Projection step: 6, Loss: 123.99710083007812
Projection step: 7, Loss: 131.2307586669922
Projection step: 8, Loss: 126.01666259765625
Projection step: 9, Loss: 126.56790161132812
Projection step: 10, Loss: 120.15914916992188
Projection step: 11, Loss: 122.3016128540039
Projection step: 12, Loss: 122.68928527832031
Projection step: 13, Loss: 115.66445922851562
Projection step: 14, Loss: 110.57719421386719
Projection step: 15, Loss: 108.60253143310547
Projection step: 16, Loss: 105.8128662109375
Projection step: 17, Loss: 106.85942077636719
Projection step: 18, Loss: 101.23658752441406
Final likelihood: tensor([ -96.4409,  -94.2261,  -93.9105, -100.0578,  -94.5124, -111.2553,
         -93.4577, -101.5368,  -99.0417,  -87.9688, -101.8897, -126.1786,
        -106.3252, -112.0377, -100.5535, -100.3924])
Final projection likelihood: -101.2366
1 mode projection succeeded
New goal: tensor([ 0.0527,  0.5737,  0.4528,  0.7730,  0.0111,  0.5854,  0.9129,  0.6243,
         1.3191,  0.2217,  0.2297,  0.8768, -0.0206, -0.0506, -1.1341],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -130.65415954589844
Adjusted likelihood: -130.65415954589844
Likelihood residual: 0.0
Original likelihood: -154.91824340820312
Adjusted likelihood: -154.91824340820312
Likelihood residual: 0.0
{'index': 154.91824340820312, 'thumb_middle': 130.65415954589844}
Current yaw: tensor([-0.0181, -0.0578, -0.3106], device='cuda:1')
3 thumb_middle
tensor([ 0.0808,  0.6115,  0.4606,  0.6588, -0.0111,  0.6252,  0.8805,  0.7849,
         1.3478,  0.2274,  0.1221,  0.9758, -0.0181, -0.0578, -0.3106,  0.8226],
       device='cuda:1')
Solve time for step 1 9.10747899702983
Current ori: tensor([-0.0181, -0.0578, -0.3106], device='cuda:1')
Index force: tensor([0.6664, 0.5017, 0.6088, 0.5076], device='cuda:1')
tensor([ 0.0837,  0.5541,  0.4588,  0.8281, -0.0620,  0.5821,  0.8815,  0.6370,
         1.2871,  0.2074,  0.1363,  0.8641,  0.0037, -0.0517, -0.3105,  0.7186],
       device='cuda:1')
Solve time for step 2 3.592386764008552
Current ori: tensor([ 0.0037, -0.0517, -0.3105], device='cuda:1')
Index force: tensor([0.5015, 0.6061, 0.5004], device='cuda:1')
tensor([ 0.0882,  0.5542,  0.4632,  0.8259, -0.0702,  0.5846,  0.8867,  0.6133,
         1.2875,  0.2069,  0.1423,  0.8463,  0.0062, -0.0556, -0.3105,  0.7558],
       device='cuda:1')
Solve time for step 3 3.4890097649767995
Current ori: tensor([ 0.0062, -0.0556, -0.3105], device='cuda:1')
Index force: tensor([0.5000, 0.5810], device='cuda:1')
tensor([ 8.2932e-02,  5.6324e-01,  4.6070e-01,  7.9569e-01, -7.4106e-02,
         5.8667e-01,  8.8473e-01,  6.0186e-01,  1.2932e+00,  1.8939e-01,
         1.4000e-01,  8.4459e-01, -5.3670e-04, -5.2884e-02, -3.1054e-01,
         7.3164e-01], device='cuda:1')
Solve time for step 4 3.4620353460195474
Current ori: tensor([-0.0005, -0.0529, -0.3105], device='cuda:1')
Index force: tensor([0.5644], device='cuda:1')
Storing RECOVERY transition: reward=0.0093 (scaled=0.0031), steps=3
Reward stats updated: mean 0.0160 -> 0.0159, std: 0.0834
Collected 158 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=1.2225, Q2 Loss=1.2225, Entropy=0.1963, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6690
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=1.4157, Q2 Loss=1.4157, Entropy=0.3040, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2065
SAC Update 3/5: Actor Loss=-0.0044, Q1 Loss=0.9782, Q2 Loss=0.9782, Entropy=0.4757, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4149
SAC Update 4/5: Actor Loss=-0.0016, Q1 Loss=2.1603, Q2 Loss=2.1603, Entropy=0.3771, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5153
SAC Update 5/5: Actor Loss=-0.0036, Q1 Loss=0.6723, Q2 Loss=0.6723, Entropy=0.5173, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3123

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.6%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002331
Q1 loss: 1.289809
Q2 loss: 1.289809
Current threshold: -149.6637
Global Scale Offset: 24.2400
Reward stats: mean=0.0159, std=0.0834, count=158
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 1.2898, Q2 Loss: 1.2898, Entropy: 0.3741, Mean TD Error: 1.4236, Threshold: -149.6637
Original likelihood: -124.18466186523438
Adjusted likelihood: -124.18466186523438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8402)
Current yaw: tensor([-0.0066, -0.0528, -0.3130], device='cuda:1')
4 turn
Sampling time 3.5757779339910485
tensor([ 0.0745,  0.5913,  0.4334,  0.7544, -0.0110,  0.6290,  0.9308,  0.6254,
         1.3343,  0.2243,  0.2115,  0.8706, -0.0066, -0.0528, -0.3130,  0.7838],
       device='cuda:1')
Original likelihood: -126.560302734375
Adjusted likelihood: -126.560302734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8166)
Solve time for step 1 14.292792386026122
Current ori: tensor([-0.0066, -0.0528, -0.3130], device='cuda:1')
Middle force: tensor([0.5361, 1.0322, 1.9821, 0.5375, 1.1811, 0.5345, 0.6673, 0.6428, 1.0621,
        0.6204, 0.5762, 0.5242], device='cuda:1')
Thumb force: tensor([0.9977, 1.8443, 1.6403, 0.5307, 0.5502, 0.5416, 0.5958, 0.5143, 0.9509,
        0.5813, 0.6073, 0.8030], device='cuda:1')
Index force: tensor([0.5718, 0.6174, 0.5488, 0.5053, 0.8397, 0.5019, 0.5465, 0.5531, 0.5307,
        0.5741, 0.5956, 0.5120], device='cuda:1')
Storing NORMAL transition: reward=0.1325 (scaled=0.1325), steps=1
Reward stats updated: mean 0.0159 -> 0.0166, std: 0.0836
Collected 159 transitions for RL
SAC Update 1/5: Actor Loss=-0.0013, Q1 Loss=0.9420, Q2 Loss=0.9420, Entropy=0.1911, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4688
SAC Update 2/5: Actor Loss=-0.0024, Q1 Loss=1.6542, Q2 Loss=1.6542, Entropy=0.4154, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7727
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=1.0859, Q2 Loss=1.0859, Entropy=0.0635, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6168
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.5565, Q2 Loss=0.5565, Entropy=0.6212, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8349
SAC Update 5/5: Actor Loss=-0.0011, Q1 Loss=0.6601, Q2 Loss=0.6601, Entropy=0.3210, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2503

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.8%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (17.4%)
Actor update: 0.08s (37.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001620
Q1 loss: 0.979745
Q2 loss: 0.979745
Current threshold: -149.6558
Global Scale Offset: 26.9838
Reward stats: mean=0.0166, std=0.0836, count=159
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 0.9797, Q2 Loss: 0.9797, Entropy: 0.3224, Mean TD Error: 0.7887, Threshold: -149.6558
tensor([ 0.1054,  0.5859,  0.4660,  0.7656,  0.0021,  0.6292,  0.8694,  0.8733,
         1.2007,  0.5030,  0.3662,  0.7081,  0.0115, -0.0712, -0.4495,  1.0298],
       device='cuda:1')
Original likelihood: -202.69029235839844
Adjusted likelihood: -202.69029235839844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0307)
State is out of distribution
Projection step: 0, Loss: 209.4400634765625
Projection step: 1, Loss: 198.04629516601562
Projection step: 2, Loss: 207.8773651123047
Projection step: 3, Loss: 189.34060668945312
Projection step: 4, Loss: 185.40159606933594
Projection step: 5, Loss: 187.99072265625
Projection step: 6, Loss: 187.17266845703125
Projection step: 7, Loss: 178.95730590820312
Projection step: 8, Loss: 175.20115661621094
Projection step: 9, Loss: 174.39111328125
Projection step: 10, Loss: 171.53805541992188
Projection step: 11, Loss: 174.03076171875
Projection step: 12, Loss: 156.1981201171875
Projection step: 13, Loss: 154.530029296875
Projection step: 14, Loss: 154.93923950195312
Projection step: 15, Loss: 164.357421875
Projection step: 16, Loss: 157.97044372558594
Projection step: 17, Loss: 148.8994598388672
Projection step: 18, Loss: 143.41867065429688
Projection step: 19, Loss: 150.9077606201172
Projection step: 20, Loss: 147.10354614257812
Projection step: 21, Loss: 136.78924560546875
Projection step: 22, Loss: 133.74057006835938
Projection step: 23, Loss: 139.8509521484375
Projection step: 24, Loss: 132.84552001953125
Final likelihood: tensor([-128.9784, -115.4083, -141.2306, -118.7426, -123.0677, -134.8297,
        -118.3768, -121.8226, -130.3027, -158.3806, -121.7151, -131.7488,
        -138.4411, -139.9014, -144.1823, -134.3306])
Final projection likelihood: -131.3412
1 mode projection succeeded
New goal: tensor([ 0.0874,  0.5324,  0.5265,  0.7932,  0.0123,  0.5737,  0.8307,  0.7861,
         1.2913,  0.2769,  0.2159,  0.9565,  0.0063, -0.0551, -0.5162],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -163.3135986328125
Adjusted likelihood: -163.3135986328125
Likelihood residual: 0.0
Original likelihood: -215.25588989257812
Adjusted likelihood: -215.25588989257812
Likelihood residual: 0.0
{'index': 215.25588989257812, 'thumb_middle': 163.3135986328125}
Current yaw: tensor([ 0.0115, -0.0712, -0.4495], device='cuda:1')
5 thumb_middle
tensor([ 0.1054,  0.5859,  0.4660,  0.7656,  0.0021,  0.6292,  0.8694,  0.8733,
         1.2007,  0.5030,  0.3662,  0.7081,  0.0115, -0.0712, -0.4495,  1.0298],
       device='cuda:1')
Solve time for step 1 8.836059833003674
Current ori: tensor([ 0.0115, -0.0712, -0.4495], device='cuda:1')
Index force: tensor([0.5924, 0.5999, 0.6005, 0.5967], device='cuda:1')
tensor([ 0.0833,  0.5324,  0.5096,  0.7847, -0.0563,  0.5854,  0.8107,  0.7808,
         1.2324,  0.3055,  0.1677,  0.8827,  0.0242, -0.0546, -0.4492,  0.9804],
       device='cuda:1')
Solve time for step 2 3.4094262089929543
Current ori: tensor([ 0.0242, -0.0546, -0.4492], device='cuda:1')
Index force: tensor([0.5007, 0.5839, 0.6069], device='cuda:1')
tensor([ 0.0847,  0.5300,  0.5106,  0.7901, -0.0662,  0.5868,  0.8103,  0.7734,
         1.2512,  0.2707,  0.1406,  0.9147,  0.0274, -0.0559, -0.4492,  1.0094],
       device='cuda:1')
Solve time for step 3 3.5310772069497034
Current ori: tensor([ 0.0274, -0.0559, -0.4492], device='cuda:1')
Index force: tensor([0.5775, 0.6031], device='cuda:1')
tensor([ 0.0789,  0.5273,  0.5139,  0.7815, -0.0850,  0.5943,  0.8225,  0.7790,
         1.2547,  0.2653,  0.1344,  0.9220,  0.0249, -0.0524, -0.4492,  0.9816],
       device='cuda:1')
Solve time for step 4 3.417912826000247
Current ori: tensor([ 0.0249, -0.0524, -0.4492], device='cuda:1')
Index force: tensor([0.5898], device='cuda:1')
Storing RECOVERY transition: reward=-0.0041 (scaled=-0.0041), steps=1
Reward stats updated: mean 0.0166 -> 0.0165, std: 0.0834
Collected 160 transitions for RL
SAC Update 1/5: Actor Loss=-0.0026, Q1 Loss=0.7685, Q2 Loss=0.7685, Entropy=0.3317, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4961
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.7539, Q2 Loss=0.7539, Entropy=0.2018, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8190
SAC Update 3/5: Actor Loss=-0.0021, Q1 Loss=0.8378, Q2 Loss=0.8378, Entropy=0.3279, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2510
SAC Update 4/5: Actor Loss=-0.0006, Q1 Loss=0.7892, Q2 Loss=0.7892, Entropy=0.1816, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4621
SAC Update 5/5: Actor Loss=-0.0059, Q1 Loss=0.7608, Q2 Loss=0.7608, Entropy=0.5648, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4138

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.06s (20.3%)
Actor update: 0.11s (41.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002339
Q1 loss: 0.782038
Q2 loss: 0.782038
Current threshold: -149.6509
Global Scale Offset: 29.9177
Reward stats: mean=0.0165, std=0.0834, count=160
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 0.7820, Q2 Loss: 0.7820, Entropy: 0.3216, Mean TD Error: 0.4884, Threshold: -149.6509
Original likelihood: -155.05398559570312
Adjusted likelihood: -155.05398559570312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4315)
Current yaw: tensor([ 0.0285, -0.0451, -0.4423], device='cuda:1')
6 turn
Sampling time 3.795410991006065
tensor([ 0.0594,  0.5261,  0.4999,  0.7739, -0.0392,  0.6325,  0.8670,  0.8095,
         1.3156,  0.2775,  0.2049,  0.9655,  0.0285, -0.0451, -0.4423,  1.0063],
       device='cuda:1')
Original likelihood: -145.708984375
Adjusted likelihood: -145.708984375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5501)
Solve time for step 1 14.055543185968418
Current ori: tensor([ 0.0285, -0.0451, -0.4423], device='cuda:1')
Middle force: tensor([0.6029, 0.8069, 0.8981, 0.9584, 0.7802, 0.6890, 0.5601, 0.6818, 0.5485,
        1.0870, 0.7182, 0.5793], device='cuda:1')
Thumb force: tensor([0.5438, 0.5032, 1.0032, 1.1321, 0.5569, 0.9936, 0.5222, 0.5736, 0.8831,
        0.7328, 0.5930, 0.5983], device='cuda:1')
Index force: tensor([0.5602, 0.7629, 0.6800, 0.5641, 0.5010, 0.5365, 0.5385, 0.5650, 0.5481,
        0.5319, 0.5355, 0.6013], device='cuda:1')
Storing NORMAL transition: reward=-0.0143 (scaled=-0.0143), steps=1
Reward stats updated: mean 0.0165 -> 0.0163, std: 0.0832
Collected 161 transitions for RL
SAC Update 1/5: Actor Loss=-0.0019, Q1 Loss=1.0497, Q2 Loss=1.0497, Entropy=0.2350, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7314
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8436, Q2 Loss=0.8436, Entropy=0.1401, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8165
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.7843, Q2 Loss=0.7843, Entropy=0.2515, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5252
SAC Update 4/5: Actor Loss=-0.0057, Q1 Loss=0.9411, Q2 Loss=0.9411, Entropy=0.5353, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1225
SAC Update 5/5: Actor Loss=-0.0043, Q1 Loss=2.3070, Q2 Loss=2.3070, Entropy=0.5748, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5746

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.0%)
Q2 update: 0.04s (19.3%)
Actor update: 0.08s (40.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002586
Q1 loss: 1.185161
Q2 loss: 1.185161
Current threshold: -149.6482
Global Scale Offset: 33.0333
Reward stats: mean=0.0163, std=0.0832, count=161
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 1.1852, Q2 Loss: 1.1852, Entropy: 0.3473, Mean TD Error: 1.5540, Threshold: -149.6482
tensor([ 0.2080,  0.5953,  0.4931,  0.7648, -0.1152,  0.7324,  0.8363,  0.8602,
         1.3068,  0.1282,  0.0786,  1.0708,  0.0718, -0.1137, -0.4423,  2.8123],
       device='cuda:1')
Original likelihood: -243.04888916015625
Adjusted likelihood: -243.04888916015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0033)
State is out of distribution
Projection step: 0, Loss: 260.69073486328125
Projection step: 1, Loss: 257.829833984375
Projection step: 2, Loss: 261.32135009765625
Projection step: 3, Loss: 250.53273010253906
Projection step: 4, Loss: 256.7120361328125
Projection step: 5, Loss: 257.427001953125
Projection step: 6, Loss: 241.3583526611328
Projection step: 7, Loss: 246.36245727539062
Projection step: 8, Loss: 244.14215087890625
Projection step: 9, Loss: 240.57467651367188
Projection step: 10, Loss: 248.83340454101562
Projection step: 11, Loss: 220.77359008789062
Projection step: 12, Loss: 240.34100341796875
Projection step: 13, Loss: 237.95819091796875
Projection step: 14, Loss: 231.87612915039062
Projection step: 15, Loss: 231.77230834960938
Projection step: 16, Loss: 230.64532470703125
Projection step: 17, Loss: 225.0610809326172
Projection step: 18, Loss: 226.02578735351562
Projection step: 19, Loss: 224.5819854736328
Projection step: 20, Loss: 217.47491455078125
Projection step: 21, Loss: 228.9221649169922
Projection step: 22, Loss: 227.2936248779297
Projection step: 23, Loss: 209.63145446777344
Projection step: 24, Loss: 227.15615844726562
Final likelihood: tensor([-191.4265, -218.9277, -220.8530, -181.9307, -219.7364, -224.3138,
        -225.6318, -227.1792, -202.9494, -204.4841, -177.4720, -162.7480,
        -165.1948, -245.2057, -216.8405, -206.4914])
Final projection likelihood: -205.7115
1 mode projection failed, trying anyway
New goal: tensor([ 0.1858,  0.5286,  0.6312,  0.7963, -0.0311,  0.7191,  0.8825,  0.8336,
         1.3515,  0.1171,  0.0920,  1.1500,  0.0661, -0.1020, -0.8090],
       device='cuda:1')
tensor([[0.0073]], device='cuda:1') tensor([[0.0133]], device='cuda:1') tensor([[0.0063]], device='cuda:1')
Original likelihood: -182.48956298828125
Adjusted likelihood: -182.48956298828125
Likelihood residual: 0.0
Original likelihood: -201.8292999267578
Adjusted likelihood: -201.8292999267578
Likelihood residual: 0.0
{'index': 201.8292999267578, 'thumb_middle': 182.48956298828125}
Current yaw: tensor([ 0.0718, -0.1137, -0.4423], device='cuda:1')
7 thumb_middle
tensor([ 0.2080,  0.5953,  0.4931,  0.7648, -0.1152,  0.7324,  0.8363,  0.8602,
         1.3068,  0.1282,  0.0786,  1.0708,  0.0718, -0.1137, -0.4423,  2.8123],
       device='cuda:1')
Solve time for step 1 9.218880612985231
Current ori: tensor([ 0.0718, -0.1137, -0.4423], device='cuda:1')
Index force: tensor([0.5542, 0.5004, 0.5906, 0.5893], device='cuda:1')
tensor([ 0.1414,  0.5797,  0.5946,  0.7466, -0.1108,  0.7107,  0.8388,  0.8148,
         1.3007,  0.1021,  0.0071,  1.1007,  0.1793, -0.2862, -0.4423,  4.5408],
       device='cuda:1')
Solve time for step 2 3.632056650996674
Current ori: tensor([ 0.1793, -0.2862, -0.4423], device='cuda:1')
Index force: tensor([0.5004, 0.5831, 0.5805], device='cuda:1')
tensor([ 0.0983,  0.6675,  0.6858,  0.7774, -0.0440,  0.7710,  0.8934,  0.8323,
         1.2849,  0.0996, -0.0442,  1.0900,  0.2564, -0.3741, -0.5352,  5.3584],
       device='cuda:1')
Solve time for step 3 3.435936138033867
Current ori: tensor([ 0.2564, -0.3741, -0.5352], device='cuda:1')
Index force: tensor([0.5829, 0.5669], device='cuda:1')
tensor([ 0.0857,  0.8910,  0.9771,  0.9553,  0.0570,  0.8505,  0.9290,  0.8364,
         1.2554,  0.1159, -0.0921,  1.0742,  0.2737, -0.3894, -0.6365,  4.6025],
       device='cuda:1')
Solve time for step 4 3.335091512009967
Current ori: tensor([ 0.2737, -0.3894, -0.6365], device='cuda:1')
Index force: tensor([0.5758], device='cuda:1')
Storing RECOVERY transition: reward=0.0244 (scaled=0.0244), steps=1
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.0829
Collected 162 transitions for RL
SAC Update 1/5: Actor Loss=-0.0012, Q1 Loss=1.5472, Q2 Loss=1.5472, Entropy=0.2405, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4507
SAC Update 2/5: Actor Loss=-0.0054, Q1 Loss=4.5640, Q2 Loss=4.5640, Entropy=0.4162, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3030
SAC Update 3/5: Actor Loss=-0.0067, Q1 Loss=0.7693, Q2 Loss=0.7693, Entropy=0.4018, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2399
SAC Update 4/5: Actor Loss=-0.0051, Q1 Loss=0.9145, Q2 Loss=0.9145, Entropy=0.3519, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5602
SAC Update 5/5: Actor Loss=-0.0044, Q1 Loss=1.2726, Q2 Loss=1.2726, Entropy=0.5574, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3704

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (18.0%)
Q2 update: 0.05s (17.7%)
Actor update: 0.11s (41.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004557
Q1 loss: 1.813530
Q2 loss: 1.813530
Current threshold: -149.6461
Global Scale Offset: 36.4796
Reward stats: mean=0.0163, std=0.0829, count=162
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 1.8135, Q2 Loss: 1.8135, Entropy: 0.3936, Mean TD Error: 1.1849, Threshold: -149.6461
Original likelihood: -1254.504638671875
Adjusted likelihood: -1254.504638671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 11
Loaded trajectory sampler
Current yaw: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
Current yaw: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
1 turn
Sampling time 3.5699475369765423
tensor([ 1.2690e-01,  5.8599e-01,  5.8351e-01,  5.9558e-01, -1.1160e-01,
         5.4717e-01,  8.9590e-01,  8.4268e-01,  1.2395e+00,  2.1686e-01,
         2.7820e-01,  1.2155e+00, -7.6254e-04,  1.4815e-02, -2.8589e-02,
         1.5561e-01], device='cuda:1')
Original likelihood: -102.83760833740234
Adjusted likelihood: -102.83760833740234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8918)
Solve time for step 1 14.007860954967327
Current ori: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
Middle force: tensor([0.5315, 0.5043, 1.2101, 0.9135, 0.5527, 0.4977, 0.4996, 0.7697, 0.5766,
        0.5841, 0.5218, 0.5794], device='cuda:1')
Thumb force: tensor([0.6346, 3.2744, 1.6670, 1.0117, 0.6234, 0.6125, 0.9681, 0.7721, 0.5789,
        0.5986, 0.5528, 0.6168], device='cuda:1')
Index force: tensor([0.5312, 0.7853, 0.5284, 0.7730, 0.5382, 0.6135, 0.6158, 0.6447, 0.5994,
        0.5948, 0.5521, 0.5941], device='cuda:1')
Storing NORMAL transition: reward=0.0091 (scaled=0.0091), steps=1
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.0827
Collected 163 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.6081, Q2 Loss=0.6081, Entropy=0.2613, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3210
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=1.0065, Q2 Loss=1.0065, Entropy=0.6049, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1194
SAC Update 3/5: Actor Loss=-0.0060, Q1 Loss=3.0080, Q2 Loss=3.0080, Entropy=0.4415, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8871
SAC Update 4/5: Actor Loss=-0.0054, Q1 Loss=1.1984, Q2 Loss=1.1984, Entropy=0.5360, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9825
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=1.0631, Q2 Loss=1.0631, Entropy=0.6127, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2636

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (39.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005806
Q1 loss: 1.376834
Q2 loss: 1.376834
Current threshold: -149.6449
Global Scale Offset: 40.5090
Reward stats: mean=0.0163, std=0.0827, count=163
----------------------------------------------
SAC Update - Actor Loss: -0.0058, Q1 Loss: 1.3768, Q2 Loss: 1.3768, Entropy: 0.4913, Mean TD Error: 0.9147, Threshold: -149.6449
tensor([ 0.0682,  0.5968,  0.5596,  0.4812, -0.0307,  0.5110,  0.9027,  0.8101,
         1.3056,  0.2583,  0.1800,  1.0577, -0.0226, -0.0107, -0.0381,  0.3579],
       device='cuda:1')
Original likelihood: -50.482696533203125
Adjusted likelihood: -50.482696533203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9910)
Solve time for step 2 5.494219178974163
Current ori: tensor([-0.0226, -0.0107, -0.0381], device='cuda:1')
Middle force: tensor([0.5091, 1.2167, 0.9592, 0.5839, 0.5049, 0.5005, 0.7820, 0.5741, 0.5932,
        0.5212, 0.5812], device='cuda:1')
Thumb force: tensor([3.1533, 1.6412, 0.9575, 0.5788, 0.5602, 0.9243, 0.7490, 0.5749, 0.5835,
        0.5495, 0.6043], device='cuda:1')
Index force: tensor([0.7260, 0.5342, 0.7650, 0.5347, 0.5909, 0.6173, 0.6417, 0.5977, 0.5915,
        0.5501, 0.5938], device='cuda:1')
Storing NORMAL transition: reward=0.0817 (scaled=0.0817), steps=1
Reward stats updated: mean 0.0163 -> 0.0167, std: 0.0826
Collected 164 transitions for RL
SAC Update 1/5: Actor Loss=-0.0036, Q1 Loss=2.2634, Q2 Loss=2.2634, Entropy=0.3311, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6870
SAC Update 2/5: Actor Loss=-0.0037, Q1 Loss=1.8237, Q2 Loss=1.8237, Entropy=0.4789, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5581
SAC Update 3/5: Actor Loss=-0.0039, Q1 Loss=1.5171, Q2 Loss=1.5171, Entropy=0.5511, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0465
SAC Update 4/5: Actor Loss=-0.0022, Q1 Loss=3.1234, Q2 Loss=3.1234, Entropy=0.4134, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3265
SAC Update 5/5: Actor Loss=-0.0047, Q1 Loss=0.7242, Q2 Loss=0.7242, Entropy=0.6430, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7666

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (38.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003626
Q1 loss: 1.890349
Q2 loss: 1.890349
Current threshold: -149.6421
Global Scale Offset: 45.6864
Reward stats: mean=0.0167, std=0.0826, count=164
----------------------------------------------
SAC Update - Actor Loss: -0.0036, Q1 Loss: 1.8903, Q2 Loss: 1.8903, Entropy: 0.4835, Mean TD Error: 1.6769, Threshold: -149.6421
tensor([ 0.2291,  0.7021,  0.5355,  0.6028,  0.0373,  0.5964,  0.8701,  0.7628,
         1.3441,  0.4101,  0.1313,  0.8563, -0.0512, -0.0602, -0.1264, -0.0963],
       device='cuda:1')
Original likelihood: -227.63946533203125
Adjusted likelihood: -227.63946533203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0488)
State is out of distribution
Projection step: 0, Loss: 239.82498168945312
Projection step: 1, Loss: 227.14541625976562
Projection step: 2, Loss: 220.3040771484375
Projection step: 3, Loss: 221.82321166992188
Projection step: 4, Loss: 207.12789916992188
Projection step: 5, Loss: 198.65399169921875
Projection step: 6, Loss: 210.65460205078125
Projection step: 7, Loss: 200.73773193359375
Projection step: 8, Loss: 186.18527221679688
Projection step: 9, Loss: 182.55819702148438
Projection step: 10, Loss: 177.99343872070312
Projection step: 11, Loss: 175.572021484375
Projection step: 12, Loss: 171.46070861816406
Projection step: 13, Loss: 155.05767822265625
Projection step: 14, Loss: 163.5706329345703
Projection step: 15, Loss: 158.9778289794922
Projection step: 16, Loss: 152.24298095703125
Projection step: 17, Loss: 151.97140502929688
Projection step: 18, Loss: 149.86968994140625
Projection step: 19, Loss: 145.36131286621094
Projection step: 20, Loss: 140.61483764648438
Projection step: 21, Loss: 139.29330444335938
Projection step: 22, Loss: 134.41744995117188
Projection step: 23, Loss: 133.37442016601562
Projection step: 24, Loss: 132.99024963378906
Final likelihood: tensor([-124.6998, -133.0640, -141.3464, -134.9143, -133.1531,  -89.9728,
        -124.7314, -133.6044,  -95.7173, -136.8637, -136.3936, -124.5331,
        -142.0931, -133.3938, -138.7065, -132.0412])
Final projection likelihood: -128.4518
1 mode projection succeeded
New goal: tensor([ 1.5619e-01,  6.4054e-01,  3.5977e-01,  8.4626e-01, -8.8051e-05,
         5.7720e-01,  9.1900e-01,  7.4747e-01,  1.3044e+00,  3.0584e-01,
         1.8695e-01,  8.2015e-01, -4.1621e-02, -5.0089e-02, -1.2424e+00],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -161.23965454101562
Adjusted likelihood: -161.23965454101562
Likelihood residual: 0.0
Original likelihood: -175.6782684326172
Adjusted likelihood: -175.6782684326172
Likelihood residual: 0.0
{'index': 175.6782684326172, 'thumb_middle': 161.23965454101562}
Current yaw: tensor([-0.0512, -0.0602, -0.1264], device='cuda:1')
2 thumb_middle
tensor([ 0.2291,  0.7021,  0.5355,  0.6028,  0.0373,  0.5964,  0.8701,  0.7628,
         1.3441,  0.4101,  0.1313,  0.8563, -0.0512, -0.0602, -0.1264, -0.0963],
       device='cuda:1')
Solve time for step 1 8.772066542005632
Current ori: tensor([-0.0512, -0.0602, -0.1264], device='cuda:1')
Index force: tensor([0.5887, 0.6058, 0.5047, 0.6129], device='cuda:1')
tensor([ 0.2212,  0.6789,  0.4351,  0.8399, -0.0851,  0.5498,  0.8748,  0.7309,
         1.2961,  0.3204,  0.1254,  0.8046, -0.0287, -0.0514, -0.1264, -0.0167],
       device='cuda:1')
Solve time for step 2 3.6397118160384707
Current ori: tensor([-0.0287, -0.0514, -0.1264], device='cuda:1')
Index force: tensor([0.5961, 0.5002, 0.6095], device='cuda:1')
tensor([ 0.2098,  0.6393,  0.4237,  0.9448, -0.1026,  0.5491,  0.8780,  0.7249,
         1.3075,  0.3070,  0.1343,  0.8031, -0.0103, -0.0405, -0.1264,  0.0068],
       device='cuda:1')
Solve time for step 3 3.7323021180345677
Current ori: tensor([-0.0103, -0.0405, -0.1264], device='cuda:1')
Index force: tensor([0.5001, 0.5978], device='cuda:1')
tensor([ 0.2075,  0.6490,  0.4177,  0.9230, -0.1045,  0.5484,  0.8792,  0.7211,
         1.3026,  0.3019,  0.1384,  0.8038, -0.0150, -0.0400, -0.1264, -0.0046],
       device='cuda:1')
Solve time for step 4 3.3520159680047072
Current ori: tensor([-0.0150, -0.0400, -0.1264], device='cuda:1')
Index force: tensor([0.5849], device='cuda:1')
Storing RECOVERY transition: reward=0.0266 (scaled=0.0133), steps=2
Reward stats updated: mean 0.0167 -> 0.0167, std: 0.0823
Collected 165 transitions for RL
SAC Update 1/5: Actor Loss=-0.0034, Q1 Loss=1.1595, Q2 Loss=1.1595, Entropy=0.5320, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3215
SAC Update 2/5: Actor Loss=-0.0064, Q1 Loss=0.9623, Q2 Loss=0.9623, Entropy=0.6154, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7057
SAC Update 3/5: Actor Loss=-0.0021, Q1 Loss=0.7219, Q2 Loss=0.7219, Entropy=0.4641, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4609
SAC Update 4/5: Actor Loss=-0.0051, Q1 Loss=5.7809, Q2 Loss=5.7809, Entropy=0.5456, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0969
SAC Update 5/5: Actor Loss=-0.0065, Q1 Loss=2.3784, Q2 Loss=2.3784, Entropy=0.6359, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0063

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.7%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004710
Q1 loss: 2.200596
Q2 loss: 2.200596
Current threshold: -149.6391
Global Scale Offset: 51.9019
Reward stats: mean=0.0167, std=0.0823, count=165
----------------------------------------------
SAC Update - Actor Loss: -0.0047, Q1 Loss: 2.2006, Q2 Loss: 2.2006, Entropy: 0.5586, Mean TD Error: 1.7183, Threshold: -149.6391
Original likelihood: -148.9197998046875
Adjusted likelihood: -148.9197998046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5054)
State is out of distribution
Projection step: 0, Loss: 155.56634521484375
Projection step: 1, Loss: 140.47683715820312
Projection step: 2, Loss: 134.53070068359375
Projection step: 3, Loss: 131.39230346679688
Projection step: 4, Loss: 127.84721374511719
Projection step: 5, Loss: 125.61488342285156
Projection step: 6, Loss: 120.9980239868164
Projection step: 7, Loss: 121.19938659667969
Projection step: 8, Loss: 114.41273498535156
Projection step: 9, Loss: 105.91791534423828
Projection step: 10, Loss: 110.26140594482422
Projection step: 11, Loss: 108.11531066894531
Projection step: 12, Loss: 102.70314025878906
Final likelihood: tensor([ -90.4240,  -88.8230, -123.3820, -141.1012, -123.2423,  -91.2780,
         -84.0721,  -93.0496, -103.3360,  -89.2034,  -94.4162, -128.1232,
        -101.9767,  -95.3658,  -93.7368, -101.7201])
Final projection likelihood: -102.7031
1 mode projection succeeded
New goal: tensor([ 0.1334,  0.6022,  0.4478,  0.8610, -0.0193,  0.6230,  0.8901,  0.7626,
         1.3688,  0.3008,  0.1606,  0.9026, -0.0260, -0.0252, -0.1168],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -127.29458618164062
Adjusted likelihood: -127.29458618164062
Likelihood residual: 0.0
Original likelihood: -125.3270034790039
Adjusted likelihood: -125.3270034790039
Likelihood residual: 0.0
{'index': 125.3270034790039, 'thumb_middle': 127.29458618164062}
Current yaw: tensor([-0.0267, -0.0307, -0.1477], device='cuda:1')
3 index
tensor([ 0.1827,  0.6715,  0.3879,  0.8638, -0.0499,  0.5972,  0.9055,  0.7545,
         1.3523,  0.3287,  0.1915,  0.8534, -0.0267, -0.0307, -0.1477, -0.0465],
       device='cuda:1')
Solve time for step 1 10.88407264201669
Current ori: tensor([-0.0267, -0.0307, -0.1477], device='cuda:1')
Middle force: tensor([0.5167, 0.5440, 0.5669, 0.5927], device='cuda:1')
Thumb force: tensor([0.6303, 0.5936, 0.5931, 0.5815], device='cuda:1')
tensor([ 0.1954,  0.5586,  0.3877,  0.8319, -0.0465,  0.5997,  0.8984,  0.7718,
         1.3722,  0.2901,  0.1676,  0.8715, -0.0249, -0.0334, -0.1518, -0.6888],
       device='cuda:1')
Solve time for step 2 4.215240183984861
Current ori: tensor([-0.0249, -0.0334, -0.1518], device='cuda:1')
Middle force: tensor([0.5422, 0.5629, 0.5866], device='cuda:1')
Thumb force: tensor([0.5852, 0.5923, 0.5806], device='cuda:1')
tensor([ 0.1919,  0.5497,  0.3927,  0.8297, -0.0365,  0.6072,  0.8965,  0.7738,
         1.3726,  0.2844,  0.1528,  0.8811, -0.0261, -0.0406, -0.1599, -1.2035],
       device='cuda:1')
Solve time for step 3 4.139110924967099
Current ori: tensor([-0.0261, -0.0406, -0.1599], device='cuda:1')
Middle force: tensor([0.5604, 0.5003], device='cuda:1')
Thumb force: tensor([0.5483, 0.5061], device='cuda:1')
tensor([ 0.1881,  0.5469,  0.3924,  0.8295, -0.0320,  0.6258,  0.8816,  0.7560,
         1.3580,  0.3137,  0.1650,  0.8537, -0.0350, -0.0440, -0.1622, -1.7500],
       device='cuda:1')
Solve time for step 4 3.6638829330331646
Current ori: tensor([-0.0350, -0.0440, -0.1622], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5032], device='cuda:1')
Storing RECOVERY transition: reward=0.0389 (scaled=0.0194), steps=2
Reward stats updated: mean 0.0167 -> 0.0167, std: 0.0821
Collected 166 transitions for RL
SAC Update 1/5: Actor Loss=-0.0026, Q1 Loss=0.9984, Q2 Loss=0.9984, Entropy=0.3368, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8864
SAC Update 2/5: Actor Loss=-0.0063, Q1 Loss=0.8285, Q2 Loss=0.8285, Entropy=0.6377, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2736
SAC Update 3/5: Actor Loss=-0.0032, Q1 Loss=1.0013, Q2 Loss=1.0013, Entropy=0.4853, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8954
SAC Update 4/5: Actor Loss=-0.0054, Q1 Loss=0.9212, Q2 Loss=0.9212, Entropy=0.5851, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6796
SAC Update 5/5: Actor Loss=-0.0013, Q1 Loss=0.9187, Q2 Loss=0.9187, Entropy=0.3753, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2144

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (17.9%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003752
Q1 loss: 0.933633
Q2 loss: 0.933633
Current threshold: -149.6384
Global Scale Offset: 58.9180
Reward stats: mean=0.0167, std=0.0821, count=166
----------------------------------------------
SAC Update - Actor Loss: -0.0038, Q1 Loss: 0.9336, Q2 Loss: 0.9336, Entropy: 0.4840, Mean TD Error: 1.1899, Threshold: -149.6384
Original likelihood: -133.03579711914062
Adjusted likelihood: -133.03579711914062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6084)
Current yaw: tensor([-0.0281, -0.0482, -0.1620], device='cuda:1')
4 turn
Sampling time 3.5699377470300533
tensor([ 0.1392,  0.6015,  0.4392,  0.8564, -0.0262,  0.6177,  0.8925,  0.7709,
         1.3779,  0.2696,  0.1273,  0.9034, -0.0281, -0.0482, -0.1620, -1.9248],
       device='cuda:1')
Original likelihood: -139.38006591796875
Adjusted likelihood: -139.38006591796875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5675)
Solve time for step 1 14.168860558012966
Current ori: tensor([-0.0281, -0.0482, -0.1620], device='cuda:1')
Middle force: tensor([0.5294, 0.9638, 1.9377, 0.6756, 0.6873, 1.1875, 0.5615, 0.5815, 0.9221,
        0.5046, 0.7584, 1.1816], device='cuda:1')
Thumb force: tensor([1.0462, 1.8044, 1.6478, 0.5575, 0.7730, 1.2106, 0.7834, 0.5738, 0.5603,
        0.5439, 0.5818, 1.4365], device='cuda:1')
Index force: tensor([0.5615, 0.6254, 0.5386, 0.5609, 0.5589, 0.6050, 0.6114, 0.6128, 0.5722,
        0.5032, 0.6885, 0.6162], device='cuda:1')
Storing NORMAL transition: reward=-0.0243 (scaled=-0.0243), steps=1
Reward stats updated: mean 0.0167 -> 0.0164, std: 0.0819
Collected 167 transitions for RL
SAC Update 1/5: Actor Loss=-0.0059, Q1 Loss=1.3173, Q2 Loss=1.3173, Entropy=0.6616, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2773
SAC Update 2/5: Actor Loss=-0.0061, Q1 Loss=0.7602, Q2 Loss=0.7602, Entropy=0.5089, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3728
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=1.2125, Q2 Loss=1.2125, Entropy=0.6595, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6906
SAC Update 4/5: Actor Loss=-0.0055, Q1 Loss=0.8029, Q2 Loss=0.8029, Entropy=0.6790, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7987
SAC Update 5/5: Actor Loss=-0.0051, Q1 Loss=1.0173, Q2 Loss=1.0173, Entropy=0.5444, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2672

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.006340
Q1 loss: 1.022008
Q2 loss: 1.022008
Current threshold: -149.6354
Global Scale Offset: 66.0229
Reward stats: mean=0.0164, std=0.0819, count=167
----------------------------------------------
SAC Update - Actor Loss: -0.0063, Q1 Loss: 1.0220, Q2 Loss: 1.0220, Entropy: 0.6107, Mean TD Error: 0.8813, Threshold: -149.6354
tensor([ 0.1190,  0.5823,  0.4334,  0.8795, -0.0476,  0.6032,  0.8955,  0.7635,
         1.3761,  0.2825,  0.1577,  0.8871, -0.0255, -0.0327, -0.1363, -1.9785],
       device='cuda:1')
Original likelihood: -121.81353759765625
Adjusted likelihood: -121.81353759765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6600)
Solve time for step 2 5.643470957002137
Current ori: tensor([-0.0255, -0.0327, -0.1363], device='cuda:1')
Middle force: tensor([0.9479, 1.8974, 0.6711, 0.6820, 1.1720, 0.5599, 0.5788, 0.9119, 0.5043,
        0.7491, 1.1638], device='cuda:1')
Thumb force: tensor([1.7721, 1.6185, 0.5562, 0.7660, 1.1908, 0.7758, 0.5716, 0.5583, 0.5433,
        0.5806, 1.4128], device='cuda:1')
Index force: tensor([0.6172, 0.5374, 0.5592, 0.5570, 0.6018, 0.6084, 0.6094, 0.5699, 0.5030,
        0.6842, 0.6131], device='cuda:1')
Storing NORMAL transition: reward=0.1294 (scaled=0.1294), steps=1
Reward stats updated: mean 0.0164 -> 0.0171, std: 0.0821
Collected 168 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=2.0471, Q2 Loss=2.0471, Entropy=0.6914, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7543
SAC Update 2/5: Actor Loss=-0.0047, Q1 Loss=2.2551, Q2 Loss=2.2551, Entropy=0.6111, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6160
SAC Update 3/5: Actor Loss=-0.0066, Q1 Loss=7.8286, Q2 Loss=7.8286, Entropy=0.5656, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2253
SAC Update 4/5: Actor Loss=-0.0057, Q1 Loss=1.5703, Q2 Loss=1.5703, Entropy=0.6574, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3192
SAC Update 5/5: Actor Loss=-0.0035, Q1 Loss=0.6191, Q2 Loss=0.6191, Entropy=0.5013, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1794

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.006434
Q1 loss: 2.864019
Q2 loss: 2.864019
Current threshold: -149.6295
Global Scale Offset: 73.7918
Reward stats: mean=0.0171, std=0.0821, count=168
----------------------------------------------
SAC Update - Actor Loss: -0.0064, Q1 Loss: 2.8640, Q2 Loss: 2.8640, Entropy: 0.6054, Mean TD Error: 2.2189, Threshold: -149.6295
tensor([ 0.1732,  0.4794,  0.5271,  1.0684,  0.0219,  0.5564,  0.9794,  0.8409,
         1.4106,  0.1752,  0.0689,  0.9452, -0.0055, -0.0803, -0.2719, -2.1666],
       device='cuda:1')
Original likelihood: -189.5048065185547
Adjusted likelihood: -189.5048065185547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2980)
Solve time for step 3 5.2544999870005995
Current ori: tensor([-0.0055, -0.0803, -0.2719], device='cuda:1')
Middle force: tensor([1.8526, 0.6732, 0.6690, 1.1417, 0.5568, 0.5774, 0.8985, 0.5048, 0.7681,
        1.1461], device='cuda:1')
Thumb force: tensor([1.5862, 0.5545, 0.7629, 1.1871, 0.7719, 0.5701, 0.5572, 0.5397, 0.5698,
        1.3898], device='cuda:1')
Index force: tensor([0.5376, 0.5583, 0.5611, 0.6057, 0.6060, 0.6080, 0.5685, 0.5028, 0.6703,
        0.6101], device='cuda:1')
Storing NORMAL transition: reward=0.0450 (scaled=0.0450), steps=1
Reward stats updated: mean 0.0171 -> 0.0173, std: 0.0819
Collected 169 transitions for RL
SAC Update 1/5: Actor Loss=-0.0068, Q1 Loss=0.8506, Q2 Loss=0.8506, Entropy=0.6565, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4394
SAC Update 2/5: Actor Loss=-0.0024, Q1 Loss=0.5559, Q2 Loss=0.5559, Entropy=0.5765, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7412
SAC Update 3/5: Actor Loss=-0.0069, Q1 Loss=0.7010, Q2 Loss=0.7010, Entropy=0.5828, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3068
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=0.9440, Q2 Loss=0.9440, Entropy=0.6269, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5575
SAC Update 5/5: Actor Loss=-0.0063, Q1 Loss=1.5446, Q2 Loss=1.5446, Entropy=0.6493, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3047

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.4%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006129
Q1 loss: 0.919243
Q2 loss: 0.919243
Current threshold: -149.6244
Global Scale Offset: 81.8985
Reward stats: mean=0.0173, std=0.0819, count=169
----------------------------------------------
SAC Update - Actor Loss: -0.0061, Q1 Loss: 0.9192, Q2 Loss: 0.9192, Entropy: 0.6184, Mean TD Error: 0.6699, Threshold: -149.6244
tensor([ 0.1024,  0.4011,  0.5660,  1.0653, -0.1521,  0.6740,  0.8829,  0.9095,
         1.3904,  0.2828,  0.1781,  0.8693,  0.0041, -0.0303, -0.3104, -2.4455],
       device='cuda:1')
Original likelihood: -183.4705810546875
Adjusted likelihood: -183.4705810546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3423)
State is out of distribution
Projection step: 0, Loss: 172.28738403320312
Projection step: 1, Loss: 187.6940460205078
Projection step: 2, Loss: 185.27685546875
Projection step: 3, Loss: 168.92926025390625
Projection step: 4, Loss: 167.59805297851562
Projection step: 5, Loss: 152.10345458984375
Projection step: 6, Loss: 157.33981323242188
Projection step: 7, Loss: 144.88026428222656
Projection step: 8, Loss: 149.40579223632812
Projection step: 9, Loss: 145.9989776611328
Projection step: 10, Loss: 146.42694091796875
Projection step: 11, Loss: 139.78677368164062
Projection step: 12, Loss: 139.1010284423828
Projection step: 13, Loss: 125.74815368652344
Projection step: 14, Loss: 138.40267944335938
Projection step: 15, Loss: 129.63563537597656
Projection step: 16, Loss: 128.07522583007812
Projection step: 17, Loss: 120.8832015991211
Projection step: 18, Loss: 113.15843963623047
Projection step: 19, Loss: 128.5959014892578
Projection step: 20, Loss: 121.56712341308594
Projection step: 21, Loss: 115.21603393554688
Projection step: 22, Loss: 112.16592407226562
Projection step: 23, Loss: 105.91077423095703
Projection step: 24, Loss: 105.93118286132812
Final likelihood: tensor([-120.8359,  -94.0457, -115.5200, -119.6168, -100.1364,  -82.5972,
        -109.3832, -102.0098,  -94.5063,  -94.6631,  -99.3497,  -93.2843,
         -82.4200,  -96.6468,  -93.9979, -130.1078])
Final projection likelihood: -101.8201
1 mode projection succeeded
New goal: tensor([ 0.0990,  0.4555,  0.5922,  0.9335, -0.0449,  0.5983,  0.8580,  0.8633,
         1.3669,  0.1928,  0.2010,  0.8937,  0.0016, -0.0206, -0.7513],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -132.08428955078125
Adjusted likelihood: -132.08428955078125
Likelihood residual: 0.0
Original likelihood: -183.89517211914062
Adjusted likelihood: -183.89517211914062
Likelihood residual: 0.0
{'index': 183.89517211914062, 'thumb_middle': 132.08428955078125}
Current yaw: tensor([ 0.0041, -0.0303, -0.3104], device='cuda:1')
5 thumb_middle
tensor([ 0.1024,  0.4011,  0.5660,  1.0653, -0.1521,  0.6740,  0.8829,  0.9095,
         1.3904,  0.2828,  0.1781,  0.8693,  0.0041, -0.0303, -0.3104, -2.4455],
       device='cuda:1')
Solve time for step 1 9.094568583997898
Current ori: tensor([ 0.0041, -0.0303, -0.3104], device='cuda:1')
Index force: tensor([0.5878, 0.6205, 0.6065, 0.5076], device='cuda:1')
tensor([ 0.1031,  0.3846,  0.6109,  1.0202, -0.1525,  0.5864,  0.8245,  0.8470,
         1.3352,  0.1932,  0.1267,  0.8586,  0.0037, -0.0310, -0.3103, -2.4241],
       device='cuda:1')
Solve time for step 2 3.572882999025751
Current ori: tensor([ 0.0037, -0.0310, -0.3103], device='cuda:1')
Index force: tensor([0.6126, 0.5917, 0.5845], device='cuda:1')
tensor([ 0.0958,  0.4172,  0.5901,  0.9659, -0.1497,  0.5842,  0.8210,  0.8385,
         1.3341,  0.1785,  0.1176,  0.8576, -0.0094, -0.0290, -0.3103, -2.3813],
       device='cuda:1')
Solve time for step 3 3.4012766249943525
Current ori: tensor([-0.0094, -0.0290, -0.3103], device='cuda:1')
Index force: tensor([0.5821, 0.5771], device='cuda:1')
tensor([ 0.1009,  0.4304,  0.5882,  0.9414, -0.1472,  0.5872,  0.8232,  0.8409,
         1.3297,  0.1780,  0.1127,  0.8574, -0.0157, -0.0316, -0.3103, -2.3908],
       device='cuda:1')
Solve time for step 4 3.319915065949317
Current ori: tensor([-0.0157, -0.0316, -0.3103], device='cuda:1')
Index force: tensor([0.5618], device='cuda:1')
Storing RECOVERY transition: reward=-0.0050 (scaled=-0.0017), steps=3
Reward stats updated: mean 0.0173 -> 0.0172, std: 0.0817
Collected 170 transitions for RL
SAC Update 1/5: Actor Loss=-0.0064, Q1 Loss=2.9104, Q2 Loss=2.9104, Entropy=0.6138, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4800
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=1.3494, Q2 Loss=1.3494, Entropy=0.6794, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3020
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=1.6612, Q2 Loss=1.6612, Entropy=0.5411, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2893
SAC Update 4/5: Actor Loss=-0.0062, Q1 Loss=1.5114, Q2 Loss=1.5114, Entropy=0.6441, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0882
SAC Update 5/5: Actor Loss=-0.0035, Q1 Loss=0.7387, Q2 Loss=0.7387, Entropy=0.6061, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0696

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006158
Q1 loss: 1.634222
Q2 loss: 1.634222
Current threshold: -149.6202
Global Scale Offset: 90.2220
Reward stats: mean=0.0172, std=0.0817, count=170
----------------------------------------------
SAC Update - Actor Loss: -0.0062, Q1 Loss: 1.6342, Q2 Loss: 1.6342, Entropy: 0.6169, Mean TD Error: 1.6458, Threshold: -149.6202
Original likelihood: -131.0686492919922
Adjusted likelihood: -131.0686492919922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5802)
Current yaw: tensor([-0.0070, -0.0280, -0.3052], device='cuda:1')
6 turn
Sampling time 3.8184757119743153
tensor([ 0.0909,  0.4137,  0.5945,  0.9579, -0.0891,  0.6305,  0.8628,  0.8625,
         1.3938,  0.1965,  0.1773,  0.8968, -0.0070, -0.0280, -0.3052, -2.3710],
       device='cuda:1')
Original likelihood: -124.87100219726562
Adjusted likelihood: -124.87100219726562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6064)
Solve time for step 1 13.96391615102766
Current ori: tensor([-0.0070, -0.0280, -0.3052], device='cuda:1')
Middle force: tensor([0.5753, 1.2164, 0.6410, 0.5495, 0.6583, 0.6697, 1.6394, 0.8022, 0.5249,
        0.4946, 0.6610, 0.8018], device='cuda:1')
Thumb force: tensor([0.5490, 0.5755, 0.8067, 0.6345, 0.5048, 0.5683, 0.5445, 0.8946, 0.5764,
        0.5213, 0.5489, 1.0920], device='cuda:1')
Index force: tensor([0.5579, 0.5651, 0.5270, 0.6035, 0.7042, 0.5218, 0.5720, 0.5425, 0.5249,
        0.7229, 0.5262, 0.5693], device='cuda:1')
Storing NORMAL transition: reward=-0.0018 (scaled=-0.0018), steps=1
Reward stats updated: mean 0.0172 -> 0.0171, std: 0.0814
Collected 171 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.9169, Q2 Loss=0.9169, Entropy=0.6635, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8155
SAC Update 2/5: Actor Loss=-0.0054, Q1 Loss=0.6700, Q2 Loss=0.6700, Entropy=0.5497, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9613
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=4.9578, Q2 Loss=4.9578, Entropy=0.6481, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9657
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=1.6696, Q2 Loss=1.6696, Entropy=0.6313, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7885
SAC Update 5/5: Actor Loss=-0.0057, Q1 Loss=0.8626, Q2 Loss=0.8626, Entropy=0.6626, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2127

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006934
Q1 loss: 1.815387
Q2 loss: 1.815387
Current threshold: -149.6172
Global Scale Offset: 98.6500
Reward stats: mean=0.0171, std=0.0814, count=171
----------------------------------------------
SAC Update - Actor Loss: -0.0069, Q1 Loss: 1.8154, Q2 Loss: 1.8154, Entropy: 0.6311, Mean TD Error: 1.7488, Threshold: -149.6172
tensor([-0.0504,  0.2800,  0.6737,  0.9262, -0.1538,  0.6035,  0.7527,  0.8152,
         1.3887,  0.1576,  0.3231,  0.7901,  0.0209,  0.0360, -0.3043, -2.3350],
       device='cuda:1')
Original likelihood: -203.52105712890625
Adjusted likelihood: -203.52105712890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2951)
Solve time for step 2 5.6450044339871965
Current ori: tensor([ 0.0209,  0.0360, -0.3043], device='cuda:1')
Middle force: tensor([1.1799, 0.6445, 0.5459, 0.6513, 0.6730, 1.6161, 0.8014, 0.5229, 0.5022,
        0.6520, 0.7833], device='cuda:1')
Thumb force: tensor([0.5659, 0.7814, 0.6300, 0.5037, 0.5599, 0.5415, 0.8703, 0.5682, 0.5157,
        0.5468, 1.0783], device='cuda:1')
Index force: tensor([0.5627, 0.5235, 0.6028, 0.6980, 0.5194, 0.5606, 0.5381, 0.5234, 0.7556,
        0.5244, 0.5666], device='cuda:1')
Storing NORMAL transition: reward=-0.1237 (scaled=-0.1237), steps=1
Reward stats updated: mean 0.0171 -> 0.0162, std: 0.0819
Collected 172 transitions for RL
SAC Update 1/5: Actor Loss=-0.0057, Q1 Loss=1.8778, Q2 Loss=1.8778, Entropy=0.6177, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5267
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=1.0942, Q2 Loss=1.0942, Entropy=0.6784, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3125
SAC Update 3/5: Actor Loss=-0.0062, Q1 Loss=0.5803, Q2 Loss=0.5803, Entropy=0.6383, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3303
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=1.8386, Q2 Loss=1.8386, Entropy=0.6606, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4722
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=1.2489, Q2 Loss=1.2489, Entropy=0.6641, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8513

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008264
Q1 loss: 1.327969
Q2 loss: 1.327969
Current threshold: -149.6160
Global Scale Offset: 107.4802
Reward stats: mean=0.0162, std=0.0819, count=172
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.3280, Q2 Loss: 1.3280, Entropy: 0.6518, Mean TD Error: 1.2986, Threshold: -149.6160
tensor([-0.2137,  0.3138,  0.5713,  0.8266, -0.2052,  0.5696,  0.7913,  0.9237,
         1.4565,  0.2324,  0.3923,  0.6333,  0.0707,  0.0698, -0.1866, -1.8307],
       device='cuda:1')
Original likelihood: -143.25735473632812
Adjusted likelihood: -143.25735473632812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5233)
State is out of distribution
Projection step: 0, Loss: 155.90457153320312
Projection step: 1, Loss: 146.18728637695312
Projection step: 2, Loss: 134.41165161132812
Projection step: 3, Loss: 134.2310028076172
Projection step: 4, Loss: 125.42949676513672
Projection step: 5, Loss: 120.70477294921875
Projection step: 6, Loss: 116.64332580566406
Projection step: 7, Loss: 113.50579833984375
Projection step: 8, Loss: 109.7795181274414
Projection step: 9, Loss: 110.49346923828125
Projection step: 10, Loss: 101.43055725097656
Final likelihood: tensor([-104.0040, -109.2167,  -97.5642,  -95.4937, -102.5381,  -99.3380,
         -95.9609, -104.7424,  -99.4156,  -98.5182, -106.2636, -106.5473,
        -100.7787, -103.6189, -102.7955,  -96.0930])
Final projection likelihood: -101.4306
1 mode projection succeeded
New goal: tensor([-0.1773,  0.2724,  0.6232,  0.8059, -0.1946,  0.5310,  0.7295,  0.8889,
         1.4532,  0.2364,  0.4646,  0.7135,  0.0698,  0.0722,  0.3117],
       device='cuda:1')
tensor([[0.0056]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -144.074462890625
Adjusted likelihood: -144.074462890625
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 144.074462890625}
Current yaw: tensor([ 0.0707,  0.0698, -0.1866], device='cuda:1')
7 thumb_middle
tensor([-0.2137,  0.3138,  0.5713,  0.8266, -0.2052,  0.5696,  0.7913,  0.9237,
         1.4565,  0.2324,  0.3923,  0.6333,  0.0707,  0.0698, -0.1866, -1.8307],
       device='cuda:1')
Solve time for step 1 8.897726668976247
Current ori: tensor([ 0.0707,  0.0698, -0.1866], device='cuda:1')
Index force: tensor([0.5886, 0.6037, 0.5943, 0.5542], device='cuda:1')
tensor([-0.2087,  0.2709,  0.6368,  0.8153, -0.2452,  0.5672,  0.7399,  0.8811,
         1.3938,  0.2105,  0.3568,  0.6536,  0.0951,  0.0725, -0.1866, -1.5738],
       device='cuda:1')
Solve time for step 2 3.514438645041082
Current ori: tensor([ 0.0951,  0.0725, -0.1866], device='cuda:1')
Index force: tensor([0.5959, 0.5890, 0.5498], device='cuda:1')
tensor([-0.2048,  0.2728,  0.6285,  0.8227, -0.2474,  0.5679,  0.7361,  0.8814,
         1.3933,  0.2166,  0.3595,  0.6745,  0.1412,  0.0857, -0.1866, -1.1811],
       device='cuda:1')
Solve time for step 3 3.415265496005304
Current ori: tensor([ 0.1412,  0.0857, -0.1866], device='cuda:1')
Index force: tensor([0.5791, 0.5426], device='cuda:1')
tensor([-0.1877,  0.2855,  0.6308,  0.8111, -0.2508,  0.5631,  0.7303,  0.8828,
         1.4149,  0.2112,  0.3812,  0.6745,  0.1810,  0.1132, -0.1574, -0.5776],
       device='cuda:1')
Solve time for step 4 3.3812838830053806
Current ori: tensor([ 0.1810,  0.1132, -0.1574], device='cuda:1')
Index force: tensor([0.5316], device='cuda:1')
Storing RECOVERY transition: reward=-0.1101 (scaled=-0.0550), steps=2
Reward stats updated: mean 0.0162 -> 0.0158, std: 0.0818
Collected 173 transitions for RL
SAC Update 1/5: Actor Loss=-0.0039, Q1 Loss=0.7932, Q2 Loss=0.7932, Entropy=0.5851, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6458
SAC Update 2/5: Actor Loss=-0.0032, Q1 Loss=0.6158, Q2 Loss=0.6158, Entropy=0.6165, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8203
SAC Update 3/5: Actor Loss=-0.0057, Q1 Loss=1.8004, Q2 Loss=1.8004, Entropy=0.5778, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6468
SAC Update 4/5: Actor Loss=-0.0056, Q1 Loss=1.0715, Q2 Loss=1.0715, Entropy=0.5854, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7516
SAC Update 5/5: Actor Loss=-0.0032, Q1 Loss=0.5826, Q2 Loss=0.5826, Entropy=0.6139, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6255

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.0%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004321
Q1 loss: 0.972726
Q2 loss: 0.972726
Current threshold: -149.6148
Global Scale Offset: 118.2435
Reward stats: mean=0.0158, std=0.0818, count=173
----------------------------------------------
SAC Update - Actor Loss: -0.0043, Q1 Loss: 0.9727, Q2 Loss: 0.9727, Entropy: 0.5957, Mean TD Error: 0.8980, Threshold: -149.6148
Original likelihood: -213.07012939453125
Adjusted likelihood: -213.07012939453125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2980)
State is out of distribution
Projection step: 0, Loss: 235.31773376464844
Projection step: 1, Loss: 233.66632080078125
Projection step: 2, Loss: 224.91009521484375
Projection step: 3, Loss: 210.4136962890625
Projection step: 4, Loss: 223.67721557617188
Projection step: 5, Loss: 211.03704833984375
Projection step: 6, Loss: 214.1721649169922
Projection step: 7, Loss: 216.83995056152344
Projection step: 8, Loss: 212.4608154296875
Projection step: 9, Loss: 207.19927978515625
Projection step: 10, Loss: 214.57472229003906
Projection step: 11, Loss: 207.42160034179688
Projection step: 12, Loss: 205.36541748046875
Projection step: 13, Loss: 194.0079345703125
Projection step: 14, Loss: 193.57421875
Projection step: 15, Loss: 197.26071166992188
Projection step: 16, Loss: 199.775634765625
Projection step: 17, Loss: 196.72335815429688
Projection step: 18, Loss: 191.87051391601562
Projection step: 19, Loss: 186.93984985351562
Projection step: 20, Loss: 179.63458251953125
Projection step: 21, Loss: 185.75100708007812
Projection step: 22, Loss: 179.28871154785156
Projection step: 23, Loss: 187.6026153564453
Projection step: 24, Loss: 188.685546875
Final likelihood: tensor([-164.7419, -176.8869, -159.7175, -203.1894, -194.0637, -154.3226,
        -154.5247, -131.6409, -189.6747, -139.7972, -197.8096, -199.6435,
        -168.5054, -190.1141, -209.9281, -207.2400])
Final projection likelihood: -177.6125
1 mode projection failed, trying anyway
New goal: tensor([-0.1447,  0.3425,  0.6772,  0.7275, -0.1730,  0.5278,  0.7428,  1.0008,
         1.4297,  0.1314,  0.4621,  0.6758,  0.2001,  0.0815,  0.3676],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -138.4403076171875
Adjusted likelihood: -138.4403076171875
Likelihood residual: 0.0
Original likelihood: -227.67144775390625
Adjusted likelihood: -227.67144775390625
Likelihood residual: 0.0
{'index': 227.67144775390625, 'thumb_middle': 138.4403076171875}
Current yaw: tensor([ 0.2085,  0.0786, -0.1023], device='cuda:1')
8 thumb_middle
tensor([-0.1898,  0.3267,  0.6301,  0.7868, -0.1805,  0.5940,  0.7761,  0.9044,
         1.5000,  0.2483,  0.4854,  0.7381,  0.2085,  0.0786, -0.1023, -0.7646],
       device='cuda:1')
Solve time for step 1 9.069802101992536
Current ori: tensor([ 0.2085,  0.0786, -0.1023], device='cuda:1')
Index force: tensor([0.5622, 0.6212, 0.5861, 0.6425], device='cuda:1')
tensor([-0.1987,  0.3336,  0.6902,  0.7536, -0.2644,  0.4856,  0.7594,  1.0043,
         1.4408,  0.1384,  0.4668,  0.7116,  0.3062,  0.1077, -0.1273, -0.4740],
       device='cuda:1')
Solve time for step 2 3.6470204580109566
Current ori: tensor([ 0.3062,  0.1077, -0.1273], device='cuda:1')
Index force: tensor([0.6157, 0.5000, 0.5003], device='cuda:1')
tensor([-0.1574,  0.3755,  0.8234,  0.9004, -0.2637,  0.3636,  0.8153,  1.0389,
         1.4730,  0.1425,  0.4717,  0.6918,  0.2994,  0.1064, -0.1355, -0.1115],
       device='cuda:1')
Solve time for step 3 3.5401498550199904
Current ori: tensor([ 0.2994,  0.1064, -0.1355], device='cuda:1')
Index force: tensor([0.5000, 0.5001], device='cuda:1')
tensor([-0.1533,  0.3694,  0.8434,  0.8385, -0.2648,  0.3432,  0.8061,  1.0438,
         1.4908,  0.1435,  0.5094,  0.6948,  0.3010,  0.1081, -0.1296, -0.0445],
       device='cuda:1')
Solve time for step 4 3.382377630972769
Current ori: tensor([ 0.3010,  0.1081, -0.1296], device='cuda:1')
Index force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=-0.1316 (scaled=-0.0658), steps=2
Reward stats updated: mean 0.0158 -> 0.0154, std: 0.0818
Collected 174 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7567, Q2 Loss=0.7567, Entropy=0.6855, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4319
SAC Update 2/5: Actor Loss=-0.0029, Q1 Loss=0.7057, Q2 Loss=0.7057, Entropy=0.6045, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4337
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=1.0638, Q2 Loss=1.0638, Entropy=0.6600, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3778
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=2.0894, Q2 Loss=2.0894, Entropy=0.6831, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0182
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.9837, Q2 Loss=0.9837, Entropy=0.6596, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2295

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007439
Q1 loss: 1.119840
Q2 loss: 1.119840
Current threshold: -149.6140
Global Scale Offset: 129.1317
Reward stats: mean=0.0154, std=0.0818, count=174
----------------------------------------------
SAC Update - Actor Loss: -0.0074, Q1 Loss: 1.1198, Q2 Loss: 1.1198, Entropy: 0.6586, Mean TD Error: 1.0982, Threshold: -149.6140
Original likelihood: -725.62646484375
Adjusted likelihood: -725.62646484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 12
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
1 turn
Sampling time 3.6150965319829993
tensor([ 1.1729e-01,  5.3559e-01,  6.0990e-01,  6.6128e-01, -1.0959e-01,
         5.1306e-01,  9.1741e-01,  8.8022e-01,  1.2163e+00,  3.1152e-01,
         2.4788e-01,  1.2226e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:1')
Original likelihood: -94.74305725097656
Adjusted likelihood: -94.74305725097656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6629)
Solve time for step 1 14.180028175003827
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:1')
Middle force: tensor([0.5184, 0.5666, 0.5840, 1.8525, 0.5667, 1.3245, 0.5090, 1.1039, 0.5030,
        0.5166, 0.5341, 0.5259], device='cuda:1')
Thumb force: tensor([0.6554, 0.8336, 0.5812, 1.4947, 0.5539, 0.8436, 0.5826, 1.3259, 0.5800,
        0.5393, 0.5764, 0.7628], device='cuda:1')
Index force: tensor([0.7686, 0.5051, 0.5112, 0.5253, 0.5812, 0.6475, 0.7556, 0.6035, 0.6261,
        0.6237, 0.5714, 0.6592], device='cuda:1')
Storing NORMAL transition: reward=0.0743 (scaled=0.0743), steps=1
Reward stats updated: mean 0.0154 -> 0.0157, std: 0.0817
Collected 175 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=1.3741, Q2 Loss=1.3741, Entropy=0.6707, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0589
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.8582, Q2 Loss=0.8582, Entropy=0.6736, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6866
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.9972, Q2 Loss=0.9972, Entropy=0.6015, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1607
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=1.0031, Q2 Loss=1.0031, Entropy=0.6677, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1480
SAC Update 5/5: Actor Loss=-0.0065, Q1 Loss=1.1871, Q2 Loss=1.1871, Entropy=0.6089, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0212

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007947
Q1 loss: 1.083938
Q2 loss: 1.083938
Current threshold: -149.6111
Global Scale Offset: 141.0585
Reward stats: mean=0.0157, std=0.0817, count=175
----------------------------------------------
SAC Update - Actor Loss: -0.0079, Q1 Loss: 1.0839, Q2 Loss: 1.0839, Entropy: 0.6445, Mean TD Error: 0.6151, Threshold: -149.6111
tensor([ 0.1553,  0.6662,  0.5221,  0.5330, -0.1718,  0.4624,  0.9128,  0.9621,
         1.3068,  0.2219,  0.2978,  1.1250,  0.0086,  0.0491, -0.1057, -0.5657],
       device='cuda:1')
Original likelihood: -214.6022491455078
Adjusted likelihood: -214.6022491455078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3242)
Solve time for step 2 5.563975879980717
Current ori: tensor([ 0.0086,  0.0491, -0.1057], device='cuda:1')
Middle force: tensor([0.5591, 0.5668, 1.8100, 0.5545, 1.3132, 0.5058, 1.0754, 0.5025, 0.5119,
        0.5265, 0.5181], device='cuda:1')
Thumb force: tensor([0.8249, 0.6085, 1.4809, 0.5583, 0.8343, 0.6361, 1.3087, 0.6377, 0.5640,
        0.6017, 0.8083], device='cuda:1')
Index force: tensor([0.5040, 0.5078, 0.5243, 0.5766, 0.6388, 0.7115, 0.6009, 0.5848, 0.5916,
        0.5545, 0.6428], device='cuda:1')
Storing NORMAL transition: reward=0.0687 (scaled=0.0687), steps=1
Reward stats updated: mean 0.0157 -> 0.0160, std: 0.0816
Collected 176 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=3.0713, Q2 Loss=3.0713, Entropy=0.6614, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3937
SAC Update 2/5: Actor Loss=-0.0065, Q1 Loss=0.7833, Q2 Loss=0.7833, Entropy=0.6467, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9467
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8798, Q2 Loss=0.8798, Entropy=0.6736, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5339
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=1.4797, Q2 Loss=1.4797, Entropy=0.6615, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7137
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=0.9924, Q2 Loss=0.9924, Entropy=0.6318, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8590

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.5%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.7%)
Actor update: 0.08s (38.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.007749
Q1 loss: 1.441276
Q2 loss: 1.441276
Current threshold: -149.6087
Global Scale Offset: 153.8969
Reward stats: mean=0.0160, std=0.0816, count=176
----------------------------------------------
SAC Update - Actor Loss: -0.0077, Q1 Loss: 1.4413, Q2 Loss: 1.4413, Entropy: 0.6550, Mean TD Error: 1.2894, Threshold: -149.6087
tensor([ 0.1240,  0.6220,  0.5556,  0.5452, -0.1210,  0.4675,  0.9658,  0.9412,
         1.2493,  0.3119,  0.3229,  0.9688, -0.0025,  0.0128, -0.1718, -0.0207],
       device='cuda:1')
Original likelihood: -95.9620590209961
Adjusted likelihood: -95.9620590209961
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6351)
Solve time for step 3 5.093298511987086
Current ori: tensor([-0.0025,  0.0128, -0.1718], device='cuda:1')
Middle force: tensor([0.5678, 1.7863, 0.5580, 1.2981, 0.5071, 1.0639, 0.5029, 0.5130, 0.5271,
        0.5204], device='cuda:1')
Thumb force: tensor([0.5804, 1.4375, 0.5464, 0.8174, 0.5911, 1.2713, 0.5922, 0.5408, 0.5754,
        0.7605], device='cuda:1')
Index force: tensor([0.5086, 0.5224, 0.5745, 0.6325, 0.7288, 0.5968, 0.6044, 0.6082, 0.5622,
        0.6481], device='cuda:1')
Storing NORMAL transition: reward=-0.0959 (scaled=-0.0959), steps=1
Reward stats updated: mean 0.0160 -> 0.0154, std: 0.0818
Collected 177 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=2.1290, Q2 Loss=2.1290, Entropy=0.6632, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6288
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.0226, Q2 Loss=1.0226, Entropy=0.6522, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0591
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=2.4018, Q2 Loss=2.4018, Entropy=0.6314, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9313
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=0.8933, Q2 Loss=0.8933, Entropy=0.6793, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7656
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=0.9699, Q2 Loss=0.9699, Entropy=0.6817, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1466

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.6%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009378
Q1 loss: 1.483310
Q2 loss: 1.483310
Current threshold: -149.6078
Global Scale Offset: 166.0895
Reward stats: mean=0.0154, std=0.0818, count=177
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.4833, Q2 Loss: 1.4833, Entropy: 0.6616, Mean TD Error: 0.9063, Threshold: -149.6078
tensor([ 0.0351,  0.4810,  0.5089,  0.4564, -0.0364,  0.5451,  0.8702,  0.8774,
         1.2498,  0.2767,  0.2169,  1.1075, -0.0064, -0.0215, -0.0762, -0.5643],
       device='cuda:1')
Original likelihood: -126.75802612304688
Adjusted likelihood: -126.75802612304688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5542)
Solve time for step 4 5.006606640992686
Current ori: tensor([-0.0064, -0.0215, -0.0762], device='cuda:1')
Middle force: tensor([1.8012, 0.5885, 1.2768, 0.5278, 1.0595, 0.5107, 0.5326, 0.5499, 0.5587],
       device='cuda:1')
Thumb force: tensor([1.4112, 0.5300, 0.8119, 0.5418, 1.2350, 0.5496, 0.5222, 0.5506, 0.6936],
       device='cuda:1')
Index force: tensor([0.5168, 0.5629, 0.6288, 0.6644, 0.5923, 0.5678, 0.5784, 0.5464, 0.5889],
       device='cuda:1')
Storing NORMAL transition: reward=0.0520 (scaled=0.0520), steps=1
Reward stats updated: mean 0.0154 -> 0.0156, std: 0.0816
Collected 178 transitions for RL
SAC Update 1/5: Actor Loss=-0.0100, Q1 Loss=0.9663, Q2 Loss=0.9663, Entropy=0.6763, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0700
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.0215, Q2 Loss=1.0215, Entropy=0.6746, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2082
SAC Update 3/5: Actor Loss=-0.0087, Q1 Loss=1.5705, Q2 Loss=1.5705, Entropy=0.6858, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4158
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=1.1916, Q2 Loss=1.1916, Entropy=0.6709, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5603
SAC Update 5/5: Actor Loss=-0.0070, Q1 Loss=0.8486, Q2 Loss=0.8486, Entropy=0.6743, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8142

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008624
Q1 loss: 1.119703
Q2 loss: 1.119703
Current threshold: -149.6067
Global Scale Offset: 177.4767
Reward stats: mean=0.0156, std=0.0816, count=178
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1197, Q2 Loss: 1.1197, Entropy: 0.6764, Mean TD Error: 1.0137, Threshold: -149.6067
tensor([-0.0138,  0.4899,  0.5720,  0.6059, -0.0894,  0.5507,  0.8021,  0.9213,
         1.3073,  0.2495,  0.2582,  1.0147, -0.0212,  0.0151, -0.1285, -0.7734],
       device='cuda:1')
Original likelihood: -80.53972625732422
Adjusted likelihood: -80.53972625732422
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6503)
State is out of distribution
Projection step: 0, Loss: 79.55683898925781
Final likelihood: tensor([-77.5657, -82.1585, -79.6519, -76.8599, -85.2265, -78.9662, -78.7328,
        -78.5239, -72.9247, -81.4259, -83.5055, -83.0672, -77.8910, -82.0567,
        -77.0184, -77.3346])
Final projection likelihood: -79.5568
1 mode projection succeeded
New goal: tensor([-0.0138,  0.4899,  0.5720,  0.6059, -0.0894,  0.5507,  0.8021,  0.9213,
         1.3073,  0.2495,  0.2582,  1.0147, -0.0212,  0.0151, -0.1285],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0212,  0.0151, -0.1285], device='cuda:1')
2 turn
Sampling time 3.630705972958822
tensor([-0.0138,  0.4899,  0.5720,  0.6059, -0.0894,  0.5507,  0.8021,  0.9213,
         1.3073,  0.2495,  0.2582,  1.0147, -0.0212,  0.0151, -0.1285, -0.7734],
       device='cuda:1')
Original likelihood: -78.95339965820312
Adjusted likelihood: -78.95339965820312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6535)
Solve time for step 1 14.337726847967133
Current ori: tensor([-0.0212,  0.0151, -0.1285], device='cuda:1')
Middle force: tensor([0.7987, 0.5351, 0.4979, 0.8615, 0.6081, 0.5799, 0.6537, 0.5169, 0.9299,
        0.9716, 0.9051, 0.7882], device='cuda:1')
Thumb force: tensor([0.5786, 0.7809, 0.7147, 1.4443, 0.8540, 0.5850, 0.7113, 0.9470, 0.8284,
        0.6519, 0.8056, 1.1720], device='cuda:1')
Index force: tensor([0.5742, 0.8317, 0.5649, 0.6078, 0.6192, 0.5668, 0.5746, 0.5462, 0.5652,
        0.8257, 0.5536, 0.5566], device='cuda:1')
Storing NORMAL transition: reward=-0.0025 (scaled=-0.0025), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0814
Collected 179 transitions for RL
SAC Update 1/5: Actor Loss=-0.0051, Q1 Loss=0.6185, Q2 Loss=0.6185, Entropy=0.6623, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7715
SAC Update 2/5: Actor Loss=-0.0067, Q1 Loss=1.4329, Q2 Loss=1.4329, Entropy=0.6794, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0048
SAC Update 3/5: Actor Loss=-0.0045, Q1 Loss=0.6435, Q2 Loss=0.6435, Entropy=0.6234, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6939
SAC Update 4/5: Actor Loss=-0.0139, Q1 Loss=2.3776, Q2 Loss=2.3776, Entropy=0.6778, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1520
SAC Update 5/5: Actor Loss=-0.0055, Q1 Loss=0.7590, Q2 Loss=0.7590, Entropy=0.6637, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8102

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007136
Q1 loss: 1.166317
Q2 loss: 1.166317
Current threshold: -149.6068
Global Scale Offset: 188.0632
Reward stats: mean=0.0155, std=0.0814, count=179
----------------------------------------------
SAC Update - Actor Loss: -0.0071, Q1 Loss: 1.1663, Q2 Loss: 1.1663, Entropy: 0.6613, Mean TD Error: 1.4865, Threshold: -149.6068
tensor([-0.0308,  0.5046,  0.5154,  0.6554, -0.0798,  0.4975,  0.8444,  0.9279,
         1.3491,  0.1807,  0.1725,  1.1818, -0.0087,  0.0173, -0.1257, -0.6406],
       device='cuda:1')
Original likelihood: -55.225975036621094
Adjusted likelihood: -55.225975036621094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6908)
Solve time for step 2 5.636290946044028
Current ori: tensor([-0.0087,  0.0173, -0.1257], device='cuda:1')
Middle force: tensor([0.5332, 0.5011, 0.8393, 0.8814, 0.5627, 0.6512, 0.5388, 0.9401, 0.8168,
        0.7595, 0.6041], device='cuda:1')
Thumb force: tensor([0.8095, 0.6852, 1.4355, 0.5293, 0.6263, 0.5402, 0.7098, 0.9023, 0.5310,
        0.7896, 0.5867], device='cuda:1')
Index force: tensor([0.8233, 0.5714, 0.6072, 0.5587, 0.6625, 0.5539, 0.8721, 0.5836, 0.7906,
        0.5632, 0.5851], device='cuda:1')
Storing NORMAL transition: reward=0.0448 (scaled=0.0448), steps=1
Reward stats updated: mean 0.0155 -> 0.0156, std: 0.0812
Collected 180 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=4.7820, Q2 Loss=4.7820, Entropy=0.6902, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5007
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=4.7667, Q2 Loss=4.7667, Entropy=0.6902, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5007
SAC Update 3/5: Actor Loss=-0.0120, Q1 Loss=1.2158, Q2 Loss=1.2158, Entropy=0.6893, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7939
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7807, Q2 Loss=0.7807, Entropy=0.6817, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7406
SAC Update 5/5: Actor Loss=-0.0058, Q1 Loss=0.6846, Q2 Loss=0.6846, Entropy=0.6686, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3517

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.3%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.0%)
Actor update: 0.08s (37.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009331
Q1 loss: 2.445964
Q2 loss: 2.445964
Current threshold: -149.6059
Global Scale Offset: 197.4825
Reward stats: mean=0.0156, std=0.0812, count=180
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 2.4460, Q2 Loss: 2.4460, Entropy: 0.6840, Mean TD Error: 1.7775, Threshold: -149.6059
tensor([-0.0381,  0.4782,  0.5373,  0.6739, -0.0942,  0.5099,  0.7790,  1.0103,
         1.4193,  0.0849,  0.1660,  1.1365, -0.0123,  0.0278, -0.1711, -0.7538],
       device='cuda:1')
Original likelihood: -93.91400146484375
Adjusted likelihood: -93.91400146484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6102)
Solve time for step 3 5.2440587430028245
Current ori: tensor([-0.0123,  0.0278, -0.1711], device='cuda:1')
Middle force: tensor([0.5012, 0.8310, 0.8731, 0.5577, 0.6450, 0.5334, 0.9270, 0.7998, 0.7500,
        0.6014], device='cuda:1')
Thumb force: tensor([0.6772, 1.4086, 0.5282, 0.6244, 0.5392, 0.7057, 0.8925, 0.5308, 0.7831,
        0.5835], device='cuda:1')
Index force: tensor([0.5660, 0.6063, 0.5577, 0.6629, 0.5530, 0.8771, 0.5815, 0.7874, 0.5616,
        0.5825], device='cuda:1')
Storing NORMAL transition: reward=-0.0095 (scaled=-0.0095), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0810
Collected 181 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=0.8729, Q2 Loss=0.8729, Entropy=0.6881, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8412
SAC Update 2/5: Actor Loss=-0.0060, Q1 Loss=0.6792, Q2 Loss=0.6792, Entropy=0.6710, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2112
SAC Update 3/5: Actor Loss=-0.0048, Q1 Loss=0.8383, Q2 Loss=0.8383, Entropy=0.6262, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7884
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=1.4653, Q2 Loss=1.4653, Entropy=0.6825, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0311
SAC Update 5/5: Actor Loss=-0.0066, Q1 Loss=0.7082, Q2 Loss=0.7082, Entropy=0.6829, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5977

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006495
Q1 loss: 0.912792
Q2 loss: 0.912792
Current threshold: -149.6063
Global Scale Offset: 208.0600
Reward stats: mean=0.0155, std=0.0810, count=181
----------------------------------------------
SAC Update - Actor Loss: -0.0065, Q1 Loss: 0.9128, Q2 Loss: 0.9128, Entropy: 0.6702, Mean TD Error: 1.0939, Threshold: -149.6063
tensor([-0.1063,  0.4014,  0.5864,  0.6864, -0.0430,  0.4622,  0.6376,  1.0083,
         1.3490,  0.4527,  0.2548,  0.9073,  0.0124,  0.0528, -0.1637, -0.7696],
       device='cuda:1')
Original likelihood: -243.98634338378906
Adjusted likelihood: -243.98634338378906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3262)
State is out of distribution
Projection step: 0, Loss: 241.46990966796875
Projection step: 1, Loss: 230.93475341796875
Projection step: 2, Loss: 217.75808715820312
Projection step: 3, Loss: 195.19906616210938
Projection step: 4, Loss: 198.98580932617188
Projection step: 5, Loss: 185.56439208984375
Projection step: 6, Loss: 159.6956787109375
Projection step: 7, Loss: 158.8458251953125
Projection step: 8, Loss: 149.66168212890625
Projection step: 9, Loss: 132.5469512939453
Projection step: 10, Loss: 125.53009033203125
Projection step: 11, Loss: 110.80033874511719
Projection step: 12, Loss: 101.33320617675781
Final likelihood: tensor([-103.0700, -101.7353,  -90.1823,  -96.8884, -100.8938, -105.8817,
        -106.5689, -108.0119,  -99.4976, -101.2696,  -94.9697,  -99.1272,
        -100.2265,  -97.2773, -109.6437, -106.0876])
Final projection likelihood: -101.3332
1 mode projection succeeded
New goal: tensor([-0.0689,  0.4630,  0.5556,  0.6825, -0.0546,  0.5111,  0.6691,  0.9506,
         1.3274,  0.3894,  0.2250,  1.0265,  0.0130,  0.0321, -1.0291],
       device='cuda:1')
tensor([[0.0036]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -136.471435546875
Adjusted likelihood: -136.471435546875
Likelihood residual: 0.0
Original likelihood: -174.54693603515625
Adjusted likelihood: -174.54693603515625
Likelihood residual: 0.0
{'index': 174.54693603515625, 'thumb_middle': 136.471435546875}
Current yaw: tensor([ 0.0124,  0.0528, -0.1637], device='cuda:1')
3 thumb_middle
tensor([-0.1063,  0.4014,  0.5864,  0.6864, -0.0430,  0.4622,  0.6376,  1.0083,
         1.3490,  0.4527,  0.2548,  0.9073,  0.0124,  0.0528, -0.1637, -0.7696],
       device='cuda:1')
Solve time for step 1 8.93662689102348
Current ori: tensor([ 0.0124,  0.0528, -0.1637], device='cuda:1')
Index force: tensor([0.5789, 0.5828, 0.5869, 0.6010], device='cuda:1')
tensor([-9.2565e-02,  4.2582e-01,  5.5829e-01,  6.9666e-01, -1.5269e-01,
         4.8777e-01,  6.3500e-01,  9.4615e-01,  1.2941e+00,  3.9617e-01,
         1.5821e-01,  9.8507e-01,  8.4303e-04,  5.6446e-02, -1.6366e-01,
        -8.6595e-01], device='cuda:1')
Solve time for step 2 3.609365160984453
Current ori: tensor([ 0.0008,  0.0564, -0.1637], device='cuda:1')
Index force: tensor([0.5085, 0.6194, 0.6047], device='cuda:1')
tensor([-9.6207e-02,  4.2957e-01,  5.5455e-01,  6.8711e-01, -1.7714e-01,
         4.9100e-01,  6.3098e-01,  9.2700e-01,  1.3025e+00,  3.8330e-01,
         1.5490e-01,  9.9889e-01, -5.1387e-04,  5.7898e-02, -1.6366e-01,
        -8.6165e-01], device='cuda:1')
Solve time for step 3 3.429937284963671
Current ori: tensor([-0.0005,  0.0579, -0.1637], device='cuda:1')
Index force: tensor([0.6078, 0.5950], device='cuda:1')
tensor([-7.5725e-02,  4.3178e-01,  5.5620e-01,  7.0885e-01, -1.6613e-01,
         5.0813e-01,  6.3859e-01,  9.2522e-01,  1.2950e+00,  3.7762e-01,
         1.4912e-01,  9.9364e-01, -3.9538e-04,  4.8548e-02, -1.6366e-01,
        -8.7346e-01], device='cuda:1')
Solve time for step 4 3.4423551380168647
Current ori: tensor([-0.0004,  0.0485, -0.1637], device='cuda:1')
Index force: tensor([0.5580], device='cuda:1')
Storing RECOVERY transition: reward=0.0029 (scaled=0.0010), steps=3
Reward stats updated: mean 0.0155 -> 0.0154, std: 0.0808
Collected 182 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.4137, Q2 Loss=1.4137, Entropy=0.6839, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5724
SAC Update 2/5: Actor Loss=-0.0063, Q1 Loss=0.5904, Q2 Loss=0.5904, Entropy=0.6742, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3159
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=0.8578, Q2 Loss=0.8578, Entropy=0.6879, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2188
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.6635, Q2 Loss=0.6635, Entropy=0.6636, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4146
SAC Update 5/5: Actor Loss=-0.0122, Q1 Loss=1.6707, Q2 Loss=1.6707, Entropy=0.6912, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3635

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (15.2%)
Q1 update: 0.06s (21.7%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008693
Q1 loss: 1.039201
Q2 loss: 1.039201
Current threshold: -149.6068
Global Scale Offset: 218.5885
Reward stats: mean=0.0154, std=0.0808, count=182
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.0392, Q2 Loss: 1.0392, Entropy: 0.6802, Mean TD Error: 0.7770, Threshold: -149.6068
Original likelihood: -138.2021484375
Adjusted likelihood: -138.2021484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5207)
Current yaw: tensor([ 0.0034,  0.0367, -0.1650], device='cuda:1')
4 turn
Sampling time 3.5872427470167167
tensor([-0.0593,  0.4101,  0.5878,  0.7290, -0.0882,  0.5692,  0.6822,  0.9305,
         1.3474,  0.3947,  0.1898,  1.0260,  0.0034,  0.0367, -0.1650, -0.8216],
       device='cuda:1')
Original likelihood: -134.9144287109375
Adjusted likelihood: -134.9144287109375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5266)
State is out of distribution
Projection step: 0, Loss: 132.39584350585938
Projection step: 1, Loss: 123.80442810058594
Projection step: 2, Loss: 111.60240173339844
Projection step: 3, Loss: 104.97593688964844
Final likelihood: tensor([-108.8070, -104.2090, -102.6276, -109.0861,  -97.0246, -109.0318,
        -100.5702, -110.8663, -103.1630, -110.8198, -104.4434,  -96.1796,
         -94.4206, -112.6614, -110.2761, -105.4285])
Final projection likelihood: -104.9759
1 mode projection succeeded
New goal: tensor([-0.0429,  0.3958,  0.6039,  0.7485, -0.0775,  0.5590,  0.6675,  0.9463,
         1.3360,  0.3767,  0.1917,  1.0525,  0.0026,  0.0327, -0.2187],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -129.86546325683594
Adjusted likelihood: -129.86546325683594
Likelihood residual: 0.0
Original likelihood: -124.501220703125
Adjusted likelihood: -124.501220703125
Likelihood residual: 0.0
{'index': 124.501220703125, 'thumb_middle': 129.86546325683594}
Current yaw: tensor([ 0.0034,  0.0367, -0.1650], device='cuda:1')
5 index
tensor([-0.0593,  0.4101,  0.5878,  0.7290, -0.0882,  0.5692,  0.6822,  0.9305,
         1.3474,  0.3947,  0.1898,  1.0260,  0.0034,  0.0367, -0.1650, -0.8216],
       device='cuda:1')
Solve time for step 1 10.424700347008184
Current ori: tensor([ 0.0034,  0.0367, -0.1650], device='cuda:1')
Middle force: tensor([0.5653, 0.5896, 0.5229, 0.5969], device='cuda:1')
Thumb force: tensor([0.5507, 0.5428, 0.7072, 0.5811], device='cuda:1')
tensor([-0.0153,  0.3438,  0.5506,  0.7171, -0.0893,  0.5587,  0.6859,  0.9633,
         1.3589,  0.3767,  0.1791,  1.0353,  0.0078,  0.0359, -0.1820, -0.7425],
       device='cuda:1')
Solve time for step 2 4.0912050229962915
Current ori: tensor([ 0.0078,  0.0359, -0.1820], device='cuda:1')
Middle force: tensor([0.5836, 0.5197, 0.5924], device='cuda:1')
Thumb force: tensor([0.5385, 0.7024, 0.5778], device='cuda:1')
tensor([-0.0094,  0.3439,  0.5535,  0.7166, -0.0772,  0.5723,  0.6804,  0.9560,
         1.3615,  0.3697,  0.1641,  1.0371,  0.0034,  0.0280, -0.1886, -0.5356],
       device='cuda:1')
Solve time for step 3 3.962191733997315
Current ori: tensor([ 0.0034,  0.0280, -0.1886], device='cuda:1')
Middle force: tensor([0.5490, 0.5358], device='cuda:1')
Thumb force: tensor([0.5363, 0.5601], device='cuda:1')
tensor([-0.0110,  0.3444,  0.5525,  0.7162, -0.0814,  0.5769,  0.6794,  0.9528,
         1.3655,  0.3641,  0.1628,  1.0341,  0.0020,  0.0289, -0.1875, -0.2954],
       device='cuda:1')
Solve time for step 4 3.80235294502927
Current ori: tensor([ 0.0020,  0.0289, -0.1875], device='cuda:1')
Middle force: tensor([0.5431], device='cuda:1')
Thumb force: tensor([0.5567], device='cuda:1')
Storing RECOVERY transition: reward=0.0230 (scaled=0.0230), steps=0
Reward stats updated: mean 0.0154 -> 0.0155, std: 0.0806
Collected 183 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=1.8227, Q2 Loss=1.8227, Entropy=0.6795, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6348
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=0.8318, Q2 Loss=0.8318, Entropy=0.6909, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3870
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.6169, Q2 Loss=0.6169, Entropy=0.6912, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2454
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=0.7356, Q2 Loss=0.7356, Entropy=0.6770, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1504
SAC Update 5/5: Actor Loss=-0.0082, Q1 Loss=0.7556, Q2 Loss=0.7556, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4226

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008561
Q1 loss: 0.952509
Q2 loss: 0.952509
Current threshold: -149.6057
Global Scale Offset: 228.3362
Reward stats: mean=0.0155, std=0.0806, count=183
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 0.9525, Q2 Loss: 0.9525, Entropy: 0.6862, Mean TD Error: 0.5680, Threshold: -149.6057
Original likelihood: -93.22638702392578
Adjusted likelihood: -93.22638702392578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5969)
Current yaw: tensor([ 0.0034,  0.0244, -0.1873], device='cuda:1')
6 turn
Sampling time 3.591659966041334
tensor([-0.0490,  0.4003,  0.5988,  0.7457, -0.0745,  0.5766,  0.6833,  0.9575,
         1.3590,  0.3705,  0.1582,  1.0438,  0.0034,  0.0244, -0.1873, -0.2143],
       device='cuda:1')
Original likelihood: -91.12449645996094
Adjusted likelihood: -91.12449645996094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6005)
Solve time for step 1 13.844288163003512
Current ori: tensor([ 0.0034,  0.0244, -0.1873], device='cuda:1')
Middle force: tensor([0.5886, 0.6376, 0.5327, 0.5254, 0.7055, 0.6529, 0.7799, 0.7930, 0.5451,
        0.5799, 1.6681, 0.5355], device='cuda:1')
Thumb force: tensor([0.6215, 0.5405, 0.5671, 0.5601, 0.5194, 0.5650, 0.5408, 0.6370, 0.5183,
        0.5592, 0.9751, 0.6462], device='cuda:1')
Index force: tensor([0.5808, 0.5134, 0.6424, 0.6294, 0.7795, 0.5345, 0.8075, 0.5405, 0.5067,
        0.6518, 0.8182, 0.5604], device='cuda:1')
Storing NORMAL transition: reward=0.0287 (scaled=0.0287), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0803
Collected 184 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.8859, Q2 Loss=0.8859, Entropy=0.6850, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5481
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=2.1105, Q2 Loss=2.1105, Entropy=0.6663, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4054
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=2.0930, Q2 Loss=2.0930, Entropy=0.6902, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0558
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=1.0110, Q2 Loss=1.0110, Entropy=0.6833, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7248
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=2.6127, Q2 Loss=2.6127, Entropy=0.6866, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3992

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008827
Q1 loss: 1.742613
Q2 loss: 1.742613
Current threshold: -149.6042
Global Scale Offset: 237.6735
Reward stats: mean=0.0155, std=0.0803, count=184
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.7426, Q2 Loss: 1.7426, Entropy: 0.6823, Mean TD Error: 1.6267, Threshold: -149.6042
tensor([-0.0322,  0.4683,  0.5607,  0.6591, -0.0580,  0.6361,  0.6003,  0.9901,
         1.4615,  0.3074,  0.0578,  1.0021, -0.0131,  0.0130, -0.2158, -0.0901],
       device='cuda:1')
Original likelihood: -108.50163269042969
Adjusted likelihood: -108.50163269042969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5682)
State is out of distribution
Projection step: 0, Loss: 113.89697265625
Projection step: 1, Loss: 106.12191009521484
Projection step: 2, Loss: 101.48307800292969
Final likelihood: tensor([ -99.1209,  -83.1398, -154.7343,  -89.7516,  -84.3563, -103.4532,
         -91.5004,  -88.5262, -100.9572,  -86.6102,  -83.1590,  -98.6954,
        -125.2952, -133.6221, -104.9323,  -95.8753])
Final projection likelihood: -101.4831
1 mode projection succeeded
New goal: tensor([-0.0272,  0.4836,  0.5631,  0.6627, -0.0584,  0.6264,  0.5896,  0.9951,
         1.4452,  0.3100,  0.0700,  1.0091, -0.0134,  0.0111, -0.3153],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -158.52293395996094
Adjusted likelihood: -158.52293395996094
Likelihood residual: 0.0
Original likelihood: -132.044677734375
Adjusted likelihood: -132.044677734375
Likelihood residual: 0.0
{'index': 132.044677734375, 'thumb_middle': 158.52293395996094}
Current yaw: tensor([-0.0131,  0.0130, -0.2158], device='cuda:1')
7 index
tensor([-0.0322,  0.4683,  0.5607,  0.6591, -0.0580,  0.6361,  0.6003,  0.9901,
         1.4615,  0.3074,  0.0578,  1.0021, -0.0131,  0.0130, -0.2158, -0.0901],
       device='cuda:1')
Solve time for step 1 10.534616882971022
Current ori: tensor([-0.0131,  0.0130, -0.2158], device='cuda:1')
Middle force: tensor([0.5571, 0.5383, 0.5553, 0.5758], device='cuda:1')
Thumb force: tensor([0.6411, 0.5423, 0.6083, 0.5928], device='cuda:1')
tensor([ 0.0063,  0.4171,  0.5086,  0.6318, -0.0602,  0.6324,  0.5989,  1.0029,
         1.4648,  0.3018,  0.0575,  1.0037, -0.0111,  0.0142, -0.2195,  4.9185],
       device='cuda:1')
Solve time for step 2 4.237569632008672
Current ori: tensor([-0.0111,  0.0142, -0.2195], device='cuda:1')
Middle force: tensor([0.5262, 0.5145, 0.5320], device='cuda:1')
Thumb force: tensor([0.5271, 0.5055, 0.5278], device='cuda:1')
tensor([ 0.0077,  0.4212,  0.5049,  0.6296, -0.0576,  0.6472,  0.5859,  0.9843,
         1.4699,  0.2934,  0.0561,  0.9847, -0.0185,  0.0130, -0.2248, -4.5436],
       device='cuda:1')
Solve time for step 3 4.297314443974756
Current ori: tensor([-0.0185,  0.0130, -0.2248], device='cuda:1')
Middle force: tensor([0.5004, 0.5628], device='cuda:1')
Thumb force: tensor([0.5344, 0.5608], device='cuda:1')
tensor([ 0.0068,  0.4204,  0.5049,  0.6303, -0.0515,  0.6374,  0.5976,  1.0022,
         1.4600,  0.3123,  0.0467,  1.0134, -0.0131,  0.0088, -0.2295, -2.6749],
       device='cuda:1')
Solve time for step 4 4.144251652003732
Current ori: tensor([-0.0131,  0.0088, -0.2295], device='cuda:1')
Middle force: tensor([0.5477], device='cuda:1')
Thumb force: tensor([0.5015], device='cuda:1')
Storing RECOVERY transition: reward=0.0041 (scaled=0.0041), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0801
Collected 185 transitions for RL
SAC Update 1/5: Actor Loss=-0.0058, Q1 Loss=0.6324, Q2 Loss=0.6324, Entropy=0.6641, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4627
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.7760, Q2 Loss=1.7760, Entropy=0.6856, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0635
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.6340, Q2 Loss=1.6340, Entropy=0.6708, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5270
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=0.9820, Q2 Loss=0.9820, Entropy=0.6866, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4885
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=4.4735, Q2 Loss=4.4735, Entropy=0.6808, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4233

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009556
Q1 loss: 1.899575
Q2 loss: 1.899575
Current threshold: -149.6024
Global Scale Offset: 245.1467
Reward stats: mean=0.0155, std=0.0801, count=185
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.8996, Q2 Loss: 1.8996, Entropy: 0.6776, Mean TD Error: 1.5930, Threshold: -149.6024
Original likelihood: -106.7445068359375
Adjusted likelihood: -106.7445068359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5690)
Current yaw: tensor([-0.0147,  0.0088, -0.2198], device='cuda:1')
8 turn
Sampling time 3.5891101399902254
tensor([-0.0321,  0.4780,  0.5489,  0.6531, -0.0569,  0.6470,  0.5963,  0.9949,
         1.4594,  0.3125,  0.0458,  1.0141, -0.0147,  0.0088, -0.2198, -2.3269],
       device='cuda:1')
Original likelihood: -100.7996597290039
Adjusted likelihood: -100.7996597290039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5784)
Solve time for step 1 14.305153867986519
Current ori: tensor([-0.0147,  0.0088, -0.2198], device='cuda:1')
Middle force: tensor([1.5783, 0.5687, 0.5769, 0.5840, 0.5422, 0.6330, 0.5630, 0.6081, 0.5933,
        0.6310, 0.5755, 0.6017], device='cuda:1')
Thumb force: tensor([1.3526, 1.6527, 0.5398, 1.1334, 0.5908, 0.5351, 0.5787, 1.3237, 0.5039,
        0.5750, 1.0673, 0.5648], device='cuda:1')
Index force: tensor([0.9462, 0.5957, 0.6549, 0.8406, 0.5546, 0.6706, 0.5535, 0.6063, 0.6035,
        0.5809, 0.6229, 0.5970], device='cuda:1')
Storing NORMAL transition: reward=-0.0376 (scaled=-0.0376), steps=1
Reward stats updated: mean 0.0155 -> 0.0152, std: 0.0800
Collected 186 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.8871, Q2 Loss=0.8871, Entropy=0.6886, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2773
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.7691, Q2 Loss=0.7691, Entropy=0.6916, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6428
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=1.2331, Q2 Loss=1.2331, Entropy=0.6885, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2660
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=1.2598, Q2 Loss=1.2598, Entropy=0.6630, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3592
SAC Update 5/5: Actor Loss=-0.0051, Q1 Loss=0.7663, Q2 Loss=0.7663, Entropy=0.6616, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0638

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007296
Q1 loss: 0.983087
Q2 loss: 0.983087
Current threshold: -149.6008
Global Scale Offset: 252.8292
Reward stats: mean=0.0152, std=0.0800, count=186
----------------------------------------------
SAC Update - Actor Loss: -0.0073, Q1 Loss: 0.9831, Q2 Loss: 0.9831, Entropy: 0.6786, Mean TD Error: 1.1218, Threshold: -149.6008
tensor([-0.0377,  0.4393,  0.5956,  0.6672, -0.1126,  0.5624,  0.6561,  1.1559,
         1.4121,  0.3921,  0.0912,  1.1302,  0.0474,  0.0305, -0.1848, -1.8970],
       device='cuda:1')
Original likelihood: -193.0094451904297
Adjusted likelihood: -193.0094451904297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4322)
State is out of distribution
Projection step: 0, Loss: 179.97256469726562
Projection step: 1, Loss: 177.88311767578125
Projection step: 2, Loss: 172.35394287109375
Projection step: 3, Loss: 176.20941162109375
Projection step: 4, Loss: 162.11683654785156
Projection step: 5, Loss: 165.0400390625
Projection step: 6, Loss: 160.8125
Projection step: 7, Loss: 153.63104248046875
Projection step: 8, Loss: 148.25302124023438
Projection step: 9, Loss: 141.83816528320312
Projection step: 10, Loss: 140.3173828125
Projection step: 11, Loss: 136.23818969726562
Projection step: 12, Loss: 130.57012939453125
Projection step: 13, Loss: 124.78240203857422
Projection step: 14, Loss: 127.62611389160156
Projection step: 15, Loss: 119.47126770019531
Projection step: 16, Loss: 115.2708740234375
Projection step: 17, Loss: 114.63519287109375
Projection step: 18, Loss: 115.51691436767578
Projection step: 19, Loss: 114.36346435546875
Projection step: 20, Loss: 107.78711700439453
Projection step: 21, Loss: 108.10466003417969
Projection step: 22, Loss: 103.96195983886719
Final likelihood: tensor([-119.4803,  -95.3839,  -95.0592, -109.6883, -111.6364,  -98.0517,
        -131.9437,  -96.1911,  -93.9642,  -90.8285, -108.9699,  -84.2544,
        -112.3593, -106.4346, -105.4316, -103.7140])
Final projection likelihood: -103.9620
1 mode projection succeeded
New goal: tensor([ 0.0136,  0.5107,  0.6160,  0.6396, -0.0979,  0.5382,  0.7118,  0.9737,
         1.3079,  0.3454,  0.1660,  1.1300,  0.0387,  0.0223, -1.6189],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -136.55348205566406
Adjusted likelihood: -136.55348205566406
Likelihood residual: 0.0
Original likelihood: -125.87728118896484
Adjusted likelihood: -125.87728118896484
Likelihood residual: 0.0
{'index': 125.87728118896484, 'thumb_middle': 136.55348205566406}
Current yaw: tensor([ 0.0474,  0.0305, -0.1848], device='cuda:1')
9 index
tensor([-0.0377,  0.4393,  0.5956,  0.6672, -0.1126,  0.5624,  0.6561,  1.1559,
         1.4121,  0.3921,  0.0912,  1.1302,  0.0474,  0.0305, -0.1848, -1.8970],
       device='cuda:1')
Solve time for step 1 11.403646913007833
Current ori: tensor([ 0.0474,  0.0305, -0.1848], device='cuda:1')
Middle force: tensor([0.6007, 0.5990, 0.5498, 0.5573], device='cuda:1')
Thumb force: tensor([0.5827, 0.5595, 0.5324, 0.6518], device='cuda:1')
tensor([ 0.0604,  0.4310,  0.5528,  0.6147, -0.1051,  0.5388,  0.7368,  1.0475,
         1.4090,  0.4000,  0.0963,  1.1034,  0.0372,  0.0271, -0.1964, -2.3090],
       device='cuda:1')
Solve time for step 2 4.254306962015107
Current ori: tensor([ 0.0372,  0.0271, -0.1964], device='cuda:1')
Middle force: tensor([0.5944, 0.5474, 0.5539], device='cuda:1')
Thumb force: tensor([0.5554, 0.5305, 0.6489], device='cuda:1')
tensor([ 0.0700,  0.4404,  0.5513,  0.6081, -0.1112,  0.5440,  0.7493,  1.0203,
         1.4126,  0.3968,  0.0984,  1.0893,  0.0324,  0.0280, -0.1988, -2.3515],
       device='cuda:1')
Solve time for step 3 4.031828684965149
Current ori: tensor([ 0.0324,  0.0280, -0.1988], device='cuda:1')
Middle force: tensor([0.5003, 0.5200], device='cuda:1')
Thumb force: tensor([0.6055, 0.5007], device='cuda:1')
tensor([ 0.0730,  0.4429,  0.5512,  0.6070, -0.1041,  0.5418,  0.7573,  1.0234,
         1.4033,  0.4156,  0.0918,  1.1034,  0.0336,  0.0232, -0.2047, -2.1647],
       device='cuda:1')
Solve time for step 4 3.8314618039876223
Current ori: tensor([ 0.0336,  0.0232, -0.2047], device='cuda:1')
Middle force: tensor([0.5465], device='cuda:1')
Thumb force: tensor([0.6343], device='cuda:1')
Storing RECOVERY transition: reward=0.0144 (scaled=0.0144), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0798
Collected 187 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.3040, Q2 Loss=1.3040, Entropy=0.6638, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8652
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.8105, Q2 Loss=0.8105, Entropy=0.6833, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5818
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.8056, Q2 Loss=0.8056, Entropy=0.6899, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2164
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=2.0449, Q2 Loss=2.0449, Entropy=0.6875, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2514
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=2.8763, Q2 Loss=2.8763, Entropy=0.6847, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5378

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008348
Q1 loss: 1.568267
Q2 loss: 1.568267
Current threshold: -149.5994
Global Scale Offset: 263.7565
Reward stats: mean=0.0152, std=0.0798, count=187
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.5683, Q2 Loss: 1.5683, Entropy: 0.6818, Mean TD Error: 1.6905, Threshold: -149.5994
Original likelihood: -144.07080078125
Adjusted likelihood: -144.07080078125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5083)
State is out of distribution
Projection step: 0, Loss: 136.92132568359375
Projection step: 1, Loss: 133.27389526367188
Projection step: 2, Loss: 125.11315155029297
Projection step: 3, Loss: 125.6187973022461
Projection step: 4, Loss: 113.98777770996094
Projection step: 5, Loss: 113.44131469726562
Projection step: 6, Loss: 106.31224060058594
Projection step: 7, Loss: 106.5418701171875
Projection step: 8, Loss: 104.88414001464844
Final likelihood: tensor([-124.6081,  -98.7594,  -99.7863, -101.0995,  -92.3563, -107.8443,
        -122.8788,  -89.8348,  -95.7189, -100.2995,  -90.1209,  -89.5397,
        -113.5538, -115.6418,  -98.5659, -137.5379])
Final projection likelihood: -104.8841
1 mode projection succeeded
New goal: tensor([ 0.0431,  0.5364,  0.5912,  0.6237, -0.1035,  0.5233,  0.7631,  0.9370,
         1.3674,  0.3943,  0.1267,  1.1228,  0.0290,  0.0237, -0.9220],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -115.07917785644531
Adjusted likelihood: -115.07917785644531
Likelihood residual: 0.0
Original likelihood: -117.64994812011719
Adjusted likelihood: -117.64994812011719
Likelihood residual: 0.0
{'index': 117.64994812011719, 'thumb_middle': 115.07917785644531}
Current yaw: tensor([ 0.0315,  0.0287, -0.1979], device='cuda:1')
10 thumb_middle
tensor([ 0.0228,  0.4959,  0.5913,  0.6275, -0.1119,  0.5435,  0.7519,  1.0126,
         1.4118,  0.4055,  0.0961,  1.0912,  0.0315,  0.0287, -0.1979, -2.1044],
       device='cuda:1')
Solve time for step 1 9.094393291976303
Current ori: tensor([ 0.0315,  0.0287, -0.1979], device='cuda:1')
Index force: tensor([0.5755, 0.5871, 0.5008, 0.5926], device='cuda:1')
tensor([ 0.0380,  0.5108,  0.5885,  0.6193, -0.1681,  0.5245,  0.7198,  0.9366,
         1.3320,  0.3824,  0.0481,  1.0726,  0.0281,  0.0210, -0.1979, -2.0743],
       device='cuda:1')
Solve time for step 2 3.7377188929822296
Current ori: tensor([ 0.0281,  0.0210, -0.1979], device='cuda:1')
Index force: tensor([0.5751, 0.5000, 0.5859], device='cuda:1')
tensor([ 0.0536,  0.5085,  0.6086,  0.6133, -0.1694,  0.5303,  0.7483,  0.9191,
         1.3276,  0.3930,  0.0340,  1.0781,  0.0282,  0.0129, -0.1979, -2.0543],
       device='cuda:1')
Solve time for step 3 3.558341051975731
Current ori: tensor([ 0.0282,  0.0129, -0.1979], device='cuda:1')
Index force: tensor([0.5000, 0.5748], device='cuda:1')
tensor([ 0.0473,  0.5126,  0.6009,  0.6051, -0.1784,  0.5249,  0.7352,  0.9346,
         1.3344,  0.3803,  0.0389,  1.0758,  0.0264,  0.0160, -0.1979, -2.0660],
       device='cuda:1')
Solve time for step 4 3.5278859619866125
Current ori: tensor([ 0.0264,  0.0160, -0.1979], device='cuda:1')
Index force: tensor([0.5606], device='cuda:1')
Storing RECOVERY transition: reward=0.0045 (scaled=0.0045), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0796
Collected 188 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.7640, Q2 Loss=0.7640, Entropy=0.6887, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4353
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.0047, Q2 Loss=1.0047, Entropy=0.6719, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4901
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=1.7539, Q2 Loss=1.7539, Entropy=0.6883, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1506
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=0.8611, Q2 Loss=0.8611, Entropy=0.6895, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6103
SAC Update 5/5: Actor Loss=-0.0052, Q1 Loss=0.6378, Q2 Loss=0.6378, Entropy=0.6801, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4554

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.8%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008121
Q1 loss: 1.004315
Q2 loss: 1.004315
Current threshold: -149.5980
Global Scale Offset: 274.8359
Reward stats: mean=0.0151, std=0.0796, count=188
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.0043, Q2 Loss: 1.0043, Entropy: 0.6837, Mean TD Error: 0.8283, Threshold: -149.5980
Original likelihood: -141.1448211669922
Adjusted likelihood: -141.1448211669922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5122)
State is out of distribution
Projection step: 0, Loss: 138.67733764648438
Projection step: 1, Loss: 135.67730712890625
Projection step: 2, Loss: 121.92628479003906
Projection step: 3, Loss: 116.21839904785156
Projection step: 4, Loss: 118.67337036132812
Projection step: 5, Loss: 109.04102325439453
Projection step: 6, Loss: 97.14067077636719
Final likelihood: tensor([ -90.8035,  -98.7995,  -90.2624,  -94.2968, -105.8851,  -99.5750,
         -88.5850, -111.6477, -104.0944,  -83.6248,  -88.8532,  -96.7068,
        -110.3237,  -91.0600, -100.8961,  -98.8367])
Final projection likelihood: -97.1407
1 mode projection succeeded
New goal: tensor([ 0.0300,  0.5339,  0.5901,  0.6098, -0.1228,  0.5405,  0.7739,  0.9024,
         1.3546,  0.3873,  0.1184,  1.1497,  0.0279,  0.0287, -0.6953],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -116.39260864257812
Adjusted likelihood: -116.39260864257812
Likelihood residual: 0.0
Original likelihood: -119.84246826171875
Adjusted likelihood: -119.84246826171875
Likelihood residual: 0.0
{'index': 119.84246826171875, 'thumb_middle': 116.39260864257812}
Current yaw: tensor([ 0.0290,  0.0329, -0.1881], device='cuda:1')
11 thumb_middle
tensor([ 0.0133,  0.5060,  0.5763,  0.6135, -0.1322,  0.5640,  0.7814,  0.9287,
         1.3905,  0.3990,  0.1040,  1.1232,  0.0290,  0.0329, -0.1881, -2.0942],
       device='cuda:1')
Solve time for step 1 9.126418827974703
Current ori: tensor([ 0.0290,  0.0329, -0.1881], device='cuda:1')
Index force: tensor([0.5763, 0.5859, 0.5908, 0.5844], device='cuda:1')
tensor([ 0.0092,  0.5046,  0.5785,  0.6050, -0.2065,  0.5366,  0.7446,  0.8858,
         1.3297,  0.3788,  0.0535,  1.1163,  0.0284,  0.0360, -0.1881, -2.1244],
       device='cuda:1')
Solve time for step 2 3.65478283399716
Current ori: tensor([ 0.0284,  0.0360, -0.1881], device='cuda:1')
Index force: tensor([0.5790, 0.5856, 0.5791], device='cuda:1')
tensor([ 0.0220,  0.5236,  0.5745,  0.5840, -0.2041,  0.5421,  0.7501,  0.8854,
         1.3236,  0.3743,  0.0398,  1.1161,  0.0219,  0.0289, -0.1881, -2.1204],
       device='cuda:1')
Solve time for step 3 3.441050650959369
Current ori: tensor([ 0.0219,  0.0289, -0.1881], device='cuda:1')
Index force: tensor([0.5756, 0.5722], device='cuda:1')
tensor([ 0.0224,  0.5059,  0.5828,  0.6165, -0.2037,  0.5399,  0.7515,  0.8844,
         1.3256,  0.3776,  0.0405,  1.1154,  0.0290,  0.0292, -0.1881, -2.1040],
       device='cuda:1')
Solve time for step 4 3.354017661011312
Current ori: tensor([ 0.0290,  0.0292, -0.1881], device='cuda:1')
Index force: tensor([0.5721], device='cuda:1')
Storing RECOVERY transition: reward=0.0031 (scaled=0.0031), steps=1
Reward stats updated: mean 0.0151 -> 0.0151, std: 0.0794
Collected 189 transitions for RL
SAC Update 1/5: Actor Loss=-0.0067, Q1 Loss=0.7432, Q2 Loss=0.7432, Entropy=0.6888, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5611
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=1.1328, Q2 Loss=1.1328, Entropy=0.6879, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7796
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.7701, Q2 Loss=0.7701, Entropy=0.6864, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6890
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.7643, Q2 Loss=0.7643, Entropy=0.6877, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4461
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=1.4244, Q2 Loss=1.4244, Entropy=0.6911, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1377

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (19.6%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008207
Q1 loss: 0.966932
Q2 loss: 0.966932
Current threshold: -149.5963
Global Scale Offset: 285.1554
Reward stats: mean=0.0151, std=0.0794, count=189
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.9669, Q2 Loss: 0.9669, Entropy: 0.6884, Mean TD Error: 0.9227, Threshold: -149.5963
Original likelihood: -174.326904296875
Adjusted likelihood: -174.326904296875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4656)
Current yaw: tensor([ 0.0291,  0.0415, -0.1873], device='cuda:1')
12 turn
Sampling time 3.6912552890134975
tensor([-0.0033,  0.5037,  0.5704,  0.6033, -0.1655,  0.5873,  0.7868,  0.9088,
         1.3870,  0.3906,  0.1026,  1.1519,  0.0291,  0.0415, -0.1873, -2.1159],
       device='cuda:1')
Original likelihood: -170.0279083251953
Adjusted likelihood: -170.0279083251953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4716)
State is out of distribution
Projection step: 0, Loss: 161.8167266845703
Projection step: 1, Loss: 155.16299438476562
Projection step: 2, Loss: 154.10769653320312
Projection step: 3, Loss: 145.11181640625
Projection step: 4, Loss: 141.4603271484375
Projection step: 5, Loss: 141.8289031982422
Projection step: 6, Loss: 130.99224853515625
Projection step: 7, Loss: 129.0537109375
Projection step: 8, Loss: 119.89926147460938
Projection step: 9, Loss: 120.2097396850586
Projection step: 10, Loss: 115.57315063476562
Projection step: 11, Loss: 115.38034057617188
Projection step: 12, Loss: 111.26873016357422
Projection step: 13, Loss: 110.25349426269531
Projection step: 14, Loss: 100.79446411132812
Final likelihood: tensor([ -93.1658,  -86.2621, -115.7339,  -95.7493,  -90.0890, -121.4776,
         -86.4528, -108.9100,  -95.5654,  -96.7019,  -93.7781, -125.0670,
         -90.4117,  -92.6092, -107.7303, -113.0075])
Final projection likelihood: -100.7945
1 mode projection succeeded
New goal: tensor([ 0.0282,  0.5406,  0.5873,  0.5948, -0.1297,  0.5451,  0.7634,  0.8935,
         1.3184,  0.3486,  0.1316,  1.1841,  0.0280,  0.0304, -1.2866],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -118.24531555175781
Adjusted likelihood: -118.24531555175781
Likelihood residual: 0.0
Original likelihood: -143.35699462890625
Adjusted likelihood: -143.35699462890625
Likelihood residual: 0.0
{'index': 143.35699462890625, 'thumb_middle': 118.24531555175781}
Current yaw: tensor([ 0.0291,  0.0415, -0.1873], device='cuda:1')
13 thumb_middle
tensor([-0.0033,  0.5037,  0.5704,  0.6033, -0.1655,  0.5873,  0.7868,  0.9088,
         1.3870,  0.3906,  0.1026,  1.1519,  0.0291,  0.0415, -0.1873, -2.1159],
       device='cuda:1')
Solve time for step 1 8.936901688051876
Current ori: tensor([ 0.0291,  0.0415, -0.1873], device='cuda:1')
Index force: tensor([0.5474, 0.5025, 0.5808, 0.5861], device='cuda:1')
tensor([-0.0101,  0.4971,  0.5757,  0.5988, -0.2214,  0.5551,  0.7561,  0.8634,
         1.3140,  0.3402,  0.0753,  1.1563,  0.0299,  0.0458, -0.1873, -2.1521],
       device='cuda:1')
Solve time for step 2 3.7411237619817257
Current ori: tensor([ 0.0299,  0.0458, -0.1873], device='cuda:1')
Index force: tensor([0.5022, 0.5756, 0.5799], device='cuda:1')
tensor([-0.0121,  0.4982,  0.5799,  0.5840, -0.2209,  0.5595,  0.7338,  0.8793,
         1.3136,  0.3315,  0.0739,  1.1588,  0.0284,  0.0467, -0.1873, -2.1595],
       device='cuda:1')
Solve time for step 3 3.5152347910334356
Current ori: tensor([ 0.0284,  0.0467, -0.1873], device='cuda:1')
Index force: tensor([0.5699, 0.5752], device='cuda:1')
tensor([ 0.0075,  0.5104,  0.5715,  0.6011, -0.2147,  0.5584,  0.7564,  0.8775,
         1.3001,  0.3317,  0.0613,  1.1704,  0.0267,  0.0367, -0.1873, -2.1303],
       device='cuda:1')
Solve time for step 4 3.542116563010495
Current ori: tensor([ 0.0267,  0.0367, -0.1873], device='cuda:1')
Index force: tensor([0.5640], device='cuda:1')
Storing RECOVERY transition: reward=0.0028 (scaled=0.0028), steps=0
Reward stats updated: mean 0.0151 -> 0.0150, std: 0.0792
Collected 190 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.8202, Q2 Loss=0.8202, Entropy=0.6867, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8246
SAC Update 2/5: Actor Loss=-0.0095, Q1 Loss=1.2538, Q2 Loss=1.2538, Entropy=0.6866, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1485
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=0.9009, Q2 Loss=0.9009, Entropy=0.6911, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6806
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=2.4131, Q2 Loss=2.4131, Entropy=0.6922, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8040
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.8285, Q2 Loss=0.8285, Entropy=0.6791, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4762

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.5%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008759
Q1 loss: 1.243297
Q2 loss: 1.243297
Current threshold: -149.5947
Global Scale Offset: 295.3776
Reward stats: mean=0.0150, std=0.0792, count=190
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.2433, Q2 Loss: 1.2433, Entropy: 0.6871, Mean TD Error: 1.1868, Threshold: -149.5947
Original likelihood: -153.10922241210938
Adjusted likelihood: -153.10922241210938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4953)
Current yaw: tensor([ 0.0278,  0.0329, -0.1894], device='cuda:1')
14 turn
Sampling time 3.9370546469581313
tensor([ 0.0132,  0.5047,  0.5848,  0.6000, -0.1499,  0.5989,  0.7811,  0.8988,
         1.3565,  0.3483,  0.1227,  1.1958,  0.0278,  0.0329, -0.1894, -2.1075],
       device='cuda:1')
Original likelihood: -127.67707824707031
Adjusted likelihood: -127.67707824707031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5294)
Solve time for step 1 14.409203739953227
Current ori: tensor([ 0.0278,  0.0329, -0.1894], device='cuda:1')
Middle force: tensor([1.4704, 0.9794, 0.9461, 1.5224, 1.4341, 0.7035, 0.5303, 0.8055, 0.6850,
        0.5658, 0.5322, 1.0324], device='cuda:1')
Thumb force: tensor([0.5885, 0.5089, 0.5697, 0.6727, 0.9569, 1.1915, 0.8875, 0.5680, 0.7200,
        0.5618, 0.5506, 0.5453], device='cuda:1')
Index force: tensor([0.8342, 0.8316, 0.7294, 0.5178, 0.9607, 0.8198, 0.5777, 0.5146, 0.5273,
        0.5995, 0.6242, 0.9541], device='cuda:1')
Storing NORMAL transition: reward=-0.0198 (scaled=-0.0198), steps=1
Reward stats updated: mean 0.0150 -> 0.0148, std: 0.0790
Collected 191 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7596, Q2 Loss=0.7596, Entropy=0.6832, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4681
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=1.0002, Q2 Loss=1.0002, Entropy=0.6898, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0321
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=1.5075, Q2 Loss=1.5075, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3044
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=1.2600, Q2 Loss=1.2600, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7462
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.8177, Q2 Loss=0.8177, Entropy=0.6874, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8240

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (38.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008980
Q1 loss: 1.068997
Q2 loss: 1.068997
Current threshold: -149.5932
Global Scale Offset: 305.7970
Reward stats: mean=0.0148, std=0.0790, count=191
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.0690, Q2 Loss: 1.0690, Entropy: 0.6890, Mean TD Error: 1.0749, Threshold: -149.5932
tensor([ 0.1307,  0.5464,  0.6356,  0.6054, -0.1782,  0.6573,  0.6764,  0.8788,
         1.3045,  0.3859,  0.0233,  1.3081,  0.0219, -0.0281, -0.1690, -2.0206],
       device='cuda:1')
Original likelihood: -247.52804565429688
Adjusted likelihood: -247.52804565429688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3750)
State is out of distribution
Projection step: 0, Loss: 231.64996337890625
Projection step: 1, Loss: 217.32464599609375
Projection step: 2, Loss: 212.35545349121094
Projection step: 3, Loss: 201.2137451171875
Projection step: 4, Loss: 192.50399780273438
Projection step: 5, Loss: 182.73089599609375
Projection step: 6, Loss: 164.99591064453125
Projection step: 7, Loss: 157.44224548339844
Projection step: 8, Loss: 147.12359619140625
Projection step: 9, Loss: 139.7089080810547
Projection step: 10, Loss: 128.10743713378906
Projection step: 11, Loss: 123.44922637939453
Projection step: 12, Loss: 132.22401428222656
Projection step: 13, Loss: 123.49626922607422
Projection step: 14, Loss: 121.5802001953125
Projection step: 15, Loss: 109.66812896728516
Projection step: 16, Loss: 118.24072265625
Projection step: 17, Loss: 112.92823028564453
Projection step: 18, Loss: 104.549560546875
Final likelihood: tensor([ -96.7372,  -96.7041,  -90.0888, -120.1396, -126.4069, -101.9830,
        -121.7551,  -99.2917, -122.9055, -108.0428, -108.9093,  -88.9281,
         -97.8549, -108.7126,  -97.5346,  -86.7988])
Final projection likelihood: -104.5496
1 mode projection succeeded
New goal: tensor([ 0.1156,  0.5413,  0.6255,  0.6583, -0.0768,  0.6285,  0.8586,  0.8157,
         1.3125,  0.2691,  0.1396,  1.2121,  0.0194, -0.0185, -1.1818],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0159]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -134.2718505859375
Adjusted likelihood: -134.2718505859375
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 134.2718505859375}
Current yaw: tensor([ 0.0219, -0.0281, -0.1690], device='cuda:1')
15 thumb_middle
tensor([ 0.1307,  0.5464,  0.6356,  0.6054, -0.1782,  0.6573,  0.6764,  0.8788,
         1.3045,  0.3859,  0.0233,  1.3081,  0.0219, -0.0281, -0.1690, -2.0206],
       device='cuda:1')
Solve time for step 1 9.020620891009457
Current ori: tensor([ 0.0219, -0.0281, -0.1690], device='cuda:1')
Index force: tensor([0.5642, 0.5798, 0.5736, 0.5771], device='cuda:1')
tensor([ 0.1270,  0.5461,  0.6216,  0.6251, -0.1775,  0.6127,  0.8152,  0.8122,
         1.2656,  0.2552,  0.0300,  1.1866,  0.0233, -0.0262, -0.1689, -2.0001],
       device='cuda:1')
Solve time for step 2 3.7200151889701374
Current ori: tensor([ 0.0233, -0.0262, -0.1689], device='cuda:1')
Index force: tensor([0.5694, 0.5655, 0.5680], device='cuda:1')
tensor([ 0.1225,  0.5415,  0.6155,  0.6415, -0.1727,  0.6258,  0.8123,  0.7899,
         1.2656,  0.2521,  0.0352,  1.1682,  0.0256, -0.0233, -0.1689, -2.0008],
       device='cuda:1')
Solve time for step 3 3.4776095249690115
Current ori: tensor([ 0.0256, -0.0233, -0.1689], device='cuda:1')
Index force: tensor([0.5542, 0.5581], device='cuda:1')
tensor([ 0.1225,  0.5270,  0.6161,  0.6794, -0.1674,  0.6109,  0.8209,  0.7967,
         1.2654,  0.2390,  0.0461,  1.1627,  0.0328, -0.0219, -0.1689, -1.9826],
       device='cuda:1')
Solve time for step 4 3.3825074700289406
Current ori: tensor([ 0.0328, -0.0219, -0.1689], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0004 (scaled=0.0004), steps=1
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0788
Collected 192 transitions for RL
SAC Update 1/5: Actor Loss=-0.0056, Q1 Loss=0.7198, Q2 Loss=0.7198, Entropy=0.6690, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7768
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=1.7010, Q2 Loss=1.7010, Entropy=0.6876, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0484
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=0.9824, Q2 Loss=0.9824, Entropy=0.6901, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3937
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.9196, Q2 Loss=0.9196, Entropy=0.6889, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7572
SAC Update 5/5: Actor Loss=-0.0107, Q1 Loss=1.2408, Q2 Loss=1.2408, Entropy=0.6865, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8647

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (20.8%)
Q2 update: 0.05s (20.3%)
Actor update: 0.10s (39.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008653
Q1 loss: 1.112723
Q2 loss: 1.112723
Current threshold: -149.5915
Global Scale Offset: 317.2861
Reward stats: mean=0.0147, std=0.0788, count=192
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.1127, Q2 Loss: 1.1127, Entropy: 0.6844, Mean TD Error: 0.9681, Threshold: -149.5915
Original likelihood: -135.29556274414062
Adjusted likelihood: -135.29556274414062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5179)
State is out of distribution
Projection step: 0, Loss: 127.77103424072266
Projection step: 1, Loss: 124.1300277709961
Projection step: 2, Loss: 118.46440887451172
Projection step: 3, Loss: 118.36326599121094
Projection step: 4, Loss: 122.17313385009766
Projection step: 5, Loss: 119.205810546875
Projection step: 6, Loss: 112.49317932128906
Projection step: 7, Loss: 118.95634460449219
Projection step: 8, Loss: 114.281005859375
Projection step: 9, Loss: 106.44760131835938
Projection step: 10, Loss: 103.9537353515625
Final likelihood: tensor([-127.8268, -126.2984, -129.7547,  -96.8153,  -89.8189,  -91.1467,
         -96.8612,  -94.3421,  -96.0610,  -99.8563,  -92.7396,  -97.4060,
        -120.2606, -108.5287,  -94.4495, -101.0940])
Final projection likelihood: -103.9537
1 mode projection succeeded
New goal: tensor([ 0.1180,  0.5449,  0.6192,  0.6469, -0.0720,  0.6172,  0.8726,  0.8118,
         1.3154,  0.2469,  0.1572,  1.1934,  0.0286, -0.0212, -0.3906],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -128.58740234375
Adjusted likelihood: -128.58740234375
Likelihood residual: 0.0
Original likelihood: -141.49502563476562
Adjusted likelihood: -141.49502563476562
Likelihood residual: 0.0
{'index': 141.49502563476562, 'thumb_middle': 128.58740234375}
Current yaw: tensor([ 0.0307, -0.0251, -0.1696], device='cuda:1')
16 thumb_middle
tensor([ 0.1204,  0.5335,  0.6143,  0.6597, -0.0983,  0.6596,  0.8575,  0.8185,
         1.3200,  0.2618,  0.1036,  1.2063,  0.0307, -0.0251, -0.1696, -1.8914],
       device='cuda:1')
Solve time for step 1 8.78558324003825
Current ori: tensor([ 0.0307, -0.0251, -0.1696], device='cuda:1')
Index force: tensor([0.5848, 0.5918, 0.5778, 0.5818], device='cuda:1')
tensor([ 0.1128,  0.5309,  0.6161,  0.6490, -0.1671,  0.5991,  0.8380,  0.7927,
         1.2673,  0.2238,  0.0546,  1.1626,  0.0294, -0.0207, -0.1696, -1.9185],
       device='cuda:1')
Solve time for step 2 3.523462567012757
Current ori: tensor([ 0.0294, -0.0207, -0.1696], device='cuda:1')
Index force: tensor([0.5793, 0.5670, 0.5720], device='cuda:1')
tensor([ 0.1054,  0.5189,  0.6207,  0.6578, -0.1792,  0.6115,  0.8247,  0.7885,
         1.2646,  0.2228,  0.0723,  1.1444,  0.0328, -0.0162, -0.1696, -1.9235],
       device='cuda:1')
Solve time for step 3 3.3849550109589472
Current ori: tensor([ 0.0328, -0.0162, -0.1696], device='cuda:1')
Index force: tensor([0.5734, 0.5812], device='cuda:1')
tensor([ 0.1085,  0.5287,  0.6163,  0.6463, -0.1747,  0.6053,  0.8314,  0.7888,
         1.2668,  0.2241,  0.0608,  1.1477,  0.0294, -0.0185, -0.1696, -1.9257],
       device='cuda:1')
Solve time for step 4 3.274106369004585
Current ori: tensor([ 0.0294, -0.0185, -0.1696], device='cuda:1')
Index force: tensor([0.5646], device='cuda:1')
Storing RECOVERY transition: reward=0.0063 (scaled=0.0063), steps=1
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0786
Collected 193 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=1.9518, Q2 Loss=1.9518, Entropy=0.6897, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6593
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.1232, Q2 Loss=1.1232, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6831
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=3.2921, Q2 Loss=3.2921, Entropy=0.6891, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7029
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=1.0288, Q2 Loss=1.0288, Entropy=0.6898, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8058
SAC Update 5/5: Actor Loss=-0.0130, Q1 Loss=1.5542, Q2 Loss=1.5542, Entropy=0.6889, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4298

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010125
Q1 loss: 1.790031
Q2 loss: 1.790031
Current threshold: -149.5893
Global Scale Offset: 328.4683
Reward stats: mean=0.0147, std=0.0786, count=193
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.7900, Q2 Loss: 1.7900, Entropy: 0.6900, Mean TD Error: 1.8562, Threshold: -149.5893
Original likelihood: -115.31272888183594
Adjusted likelihood: -115.31272888183594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5414)
Current yaw: tensor([ 0.0308, -0.0230, -0.1755], device='cuda:1')
17 turn
Sampling time 3.6785905240103602
tensor([ 0.1139,  0.5281,  0.6186,  0.6535, -0.1058,  0.6513,  0.8756,  0.8105,
         1.3269,  0.2432,  0.1169,  1.1843,  0.0308, -0.0230, -0.1755, -1.8505],
       device='cuda:1')
Original likelihood: -128.46261596679688
Adjusted likelihood: -128.46261596679688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5255)
Solve time for step 1 14.065482822014019
Current ori: tensor([ 0.0308, -0.0230, -0.1755], device='cuda:1')
Middle force: tensor([1.3546, 0.5239, 0.4974, 0.4947, 0.5604, 0.5499, 1.1507, 0.8476, 0.7953,
        0.5761, 0.5397, 0.4894], device='cuda:1')
Thumb force: tensor([1.8783, 1.9934, 1.3819, 0.5906, 1.0934, 0.7979, 1.4718, 0.5432, 0.7376,
        0.6968, 0.5389, 0.5539], device='cuda:1')
Index force: tensor([0.5456, 0.8083, 0.6856, 0.5953, 0.5182, 0.5273, 0.5484, 0.5141, 0.5752,
        0.5380, 0.4655, 0.6181], device='cuda:1')
Storing NORMAL transition: reward=-0.1444 (scaled=-0.1444), steps=1
Reward stats updated: mean 0.0147 -> 0.0139, std: 0.0792
Collected 194 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=1.1399, Q2 Loss=1.1399, Entropy=0.6859, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4604
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.1900, Q2 Loss=1.1900, Entropy=0.6892, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4640
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=3.2241, Q2 Loss=3.2241, Entropy=0.6893, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6712
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.1372, Q2 Loss=1.1372, Entropy=0.6872, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1175
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=2.3063, Q2 Loss=2.3063, Entropy=0.6888, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3618

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008806
Q1 loss: 1.799515
Q2 loss: 1.799515
Current threshold: -149.5878
Global Scale Offset: 339.0614
Reward stats: mean=0.0139, std=0.0792, count=194
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.7995, Q2 Loss: 1.7995, Entropy: 0.6881, Mean TD Error: 2.0150, Threshold: -149.5878
tensor([ 0.1407,  0.5132,  0.5759,  0.6131, -0.2744,  0.5965,  0.8658,  0.8699,
         1.4033,  0.2361,  0.2199,  1.2342,  0.0883,  0.0831, -0.0407, -2.0181],
       device='cuda:1')
Original likelihood: -208.38064575195312
Adjusted likelihood: -208.38064575195312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4315)
Solve time for step 2 5.534536877996288
Current ori: tensor([ 0.0883,  0.0831, -0.0407], device='cuda:1')
Middle force: tensor([0.5113, 0.5028, 0.5030, 0.5517, 0.5354, 1.0954, 0.7975, 0.7577, 0.5668,
        0.5396, 0.5027], device='cuda:1')
Thumb force: tensor([1.9669, 1.4174, 0.6243, 1.0951, 0.8627, 1.4587, 0.5724, 0.7613, 0.7095,
        0.5548, 0.5769], device='cuda:1')
Index force: tensor([0.8504, 0.7704, 0.6095, 0.5158, 0.5160, 0.5461, 0.5089, 0.5675, 0.5340,
        0.5039, 0.6047], device='cuda:1')
Storing NORMAL transition: reward=0.0479 (scaled=0.0479), steps=1
Reward stats updated: mean 0.0139 -> 0.0140, std: 0.0791
Collected 195 transitions for RL
SAC Update 1/5: Actor Loss=-0.0119, Q1 Loss=7.8439, Q2 Loss=7.8439, Entropy=0.6867, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3862
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.0256, Q2 Loss=1.0256, Entropy=0.6903, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4920
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=1.2007, Q2 Loss=1.2007, Entropy=0.6888, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6125
SAC Update 4/5: Actor Loss=-0.0109, Q1 Loss=0.9795, Q2 Loss=0.9795, Entropy=0.6904, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2365
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=1.0419, Q2 Loss=1.0419, Entropy=0.6908, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6404

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (18.9%)
Actor update: 0.12s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011347
Q1 loss: 2.418317
Q2 loss: 2.418317
Current threshold: -149.5867
Global Scale Offset: 349.6502
Reward stats: mean=0.0140, std=0.0791, count=195
----------------------------------------------
SAC Update - Actor Loss: -0.0113, Q1 Loss: 2.4183, Q2 Loss: 2.4183, Entropy: 0.6894, Mean TD Error: 1.4735, Threshold: -149.5867
tensor([ 0.1852,  0.6017,  0.5449,  0.6145, -0.2317,  0.6048,  0.8786,  0.8813,
         1.3967,  0.2328,  0.1668,  1.2414,  0.0813,  0.0523, -0.0852, -1.4158],
       device='cuda:1')
Original likelihood: -211.112548828125
Adjusted likelihood: -211.112548828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4304)
Solve time for step 3 5.369082761986647
Current ori: tensor([ 0.0813,  0.0523, -0.0852], device='cuda:1')
Middle force: tensor([0.5058, 0.9848, 0.5505, 0.5111, 0.5517, 0.5327, 0.7513, 0.6381, 1.1501,
        1.1761], device='cuda:1')
Thumb force: tensor([0.5627, 1.3657, 0.9092, 0.6449, 0.6006, 0.5518, 0.7775, 0.5513, 0.5803,
        0.5288], device='cuda:1')
Index force: tensor([0.5415, 0.5258, 0.5520, 0.5655, 0.5044, 0.6376, 0.7658, 0.5315, 0.5921,
        0.5191], device='cuda:1')
Storing NORMAL transition: reward=0.0351 (scaled=0.0351), steps=1
Reward stats updated: mean 0.0140 -> 0.0142, std: 0.0789
Collected 196 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.9168, Q2 Loss=0.9168, Entropy=0.6855, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6804
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=1.4647, Q2 Loss=1.4647, Entropy=0.6919, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4725
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=0.7959, Q2 Loss=0.7959, Entropy=0.6885, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1296
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=2.2840, Q2 Loss=2.2840, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2467
SAC Update 5/5: Actor Loss=-0.0108, Q1 Loss=5.0955, Q2 Loss=5.0955, Entropy=0.6896, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7157

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.5%)
Q1 update: 0.04s (19.7%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009040
Q1 loss: 2.111383
Q2 loss: 2.111383
Current threshold: -149.5856
Global Scale Offset: 358.4610
Reward stats: mean=0.0142, std=0.0789, count=196
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 2.1114, Q2 Loss: 2.1114, Entropy: 0.6897, Mean TD Error: 2.0489, Threshold: -149.5856
tensor([ 0.1388,  0.6266,  0.4635,  0.6448, -0.2327,  0.6443,  0.8362,  0.9018,
         1.4393,  0.1635,  0.1402,  1.1932,  0.0651,  0.0456, -0.1181, -0.6943],
       device='cuda:1')
Original likelihood: -203.14642333984375
Adjusted likelihood: -203.14642333984375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4408)
Solve time for step 4 4.8838110390352085
Current ori: tensor([ 0.0651,  0.0456, -0.1181], device='cuda:1')
Middle force: tensor([0.9864, 0.5519, 0.5108, 0.5522, 0.5318, 0.7448, 0.6391, 1.1358, 1.1694],
       device='cuda:1')
Thumb force: tensor([1.3728, 0.9050, 0.6392, 0.5938, 0.5475, 0.7632, 0.5468, 0.5723, 0.5259],
       device='cuda:1')
Index force: tensor([0.5209, 0.5532, 0.5577, 0.5036, 0.6336, 0.7623, 0.5293, 0.5926, 0.5169],
       device='cuda:1')
Storing NORMAL transition: reward=0.0063 (scaled=0.0063), steps=1
Reward stats updated: mean 0.0142 -> 0.0141, std: 0.0787
Collected 197 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=0.9879, Q2 Loss=0.9879, Entropy=0.6894, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1097
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=2.0923, Q2 Loss=2.0923, Entropy=0.6811, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3835
SAC Update 3/5: Actor Loss=-0.0067, Q1 Loss=0.7314, Q2 Loss=0.7314, Entropy=0.6845, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7050
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.7930, Q2 Loss=0.7930, Entropy=0.6879, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4608
SAC Update 5/5: Actor Loss=-0.0128, Q1 Loss=1.5358, Q2 Loss=1.5358, Entropy=0.6897, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4286

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.3%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.3%)
Actor update: 0.08s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009273
Q1 loss: 1.228092
Q2 loss: 1.228092
Current threshold: -149.5847
Global Scale Offset: 367.6298
Reward stats: mean=0.0141, std=0.0787, count=197
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.2281, Q2 Loss: 1.2281, Entropy: 0.6865, Mean TD Error: 1.0175, Threshold: -149.5847
tensor([ 0.1736,  0.6706,  0.4692,  0.6710, -0.1594,  0.5398,  0.9166,  0.9624,
         1.4531,  0.1550,  0.0320,  1.1544,  0.0901,  0.0154, -0.1263, -0.8371],
       device='cuda:1')
Original likelihood: -241.90640258789062
Adjusted likelihood: -241.90640258789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4012)
Solve time for step 5 4.720929968985729
Current ori: tensor([ 0.0901,  0.0154, -0.1263], device='cuda:1')
Middle force: tensor([0.5511, 0.5364, 1.0078, 0.7592, 0.7316, 0.5633, 0.5311, 0.5016],
       device='cuda:1')
Thumb force: tensor([0.9718, 0.8120, 1.3321, 0.5676, 0.7177, 0.6706, 0.5450, 0.5678],
       device='cuda:1')
Index force: tensor([0.5169, 0.5064, 0.5469, 0.5060, 0.5548, 0.5263, 0.5029, 0.5924],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0170 (scaled=-0.0170), steps=1
Reward stats updated: mean 0.0141 -> 0.0140, std: 0.0785
Collected 198 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=2.3670, Q2 Loss=2.3670, Entropy=0.6890, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3939
SAC Update 2/5: Actor Loss=-0.0125, Q1 Loss=1.1212, Q2 Loss=1.1212, Entropy=0.6911, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3250
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=1.5734, Q2 Loss=1.5734, Entropy=0.6824, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9338
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.6582, Q2 Loss=0.6582, Entropy=0.6819, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2707
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.7356, Q2 Loss=1.7356, Entropy=0.6828, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6392

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.3%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (42.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009194
Q1 loss: 1.491094
Q2 loss: 1.491094
Current threshold: -149.5834
Global Scale Offset: 377.3951
Reward stats: mean=0.0140, std=0.0785, count=198
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.4911, Q2 Loss: 1.4911, Entropy: 0.6854, Mean TD Error: 1.5125, Threshold: -149.5834
tensor([ 0.2687,  0.6660,  0.5550,  0.5929, -0.0956,  0.5498,  0.8052,  0.8983,
         1.4872,  0.2020,  0.0793,  1.2471,  0.1508,  0.0519, -0.1237, -0.9258],
       device='cuda:1')
Original likelihood: -144.94078063964844
Adjusted likelihood: -144.94078063964844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5049)
Solve time for step 6 4.625084001978394
Current ori: tensor([ 0.1508,  0.0519, -0.1237], device='cuda:1')
Middle force: tensor([0.5325, 0.9697, 0.7334, 0.6915, 0.5525, 0.5288, 0.5014],
       device='cuda:1')
Thumb force: tensor([0.8268, 1.3201, 0.5733, 0.7607, 0.6875, 0.5384, 0.5627],
       device='cuda:1')
Index force: tensor([0.5045, 0.5480, 0.5062, 0.5461, 0.5241, 0.5032, 0.5898],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0157 (scaled=-0.0157), steps=1
Reward stats updated: mean 0.0140 -> 0.0138, std: 0.0783
Collected 199 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8970, Q2 Loss=0.8970, Entropy=0.6920, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7000
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.7710, Q2 Loss=0.7710, Entropy=0.6872, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5856
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.7173, Q2 Loss=0.7173, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3543
SAC Update 4/5: Actor Loss=-0.0067, Q1 Loss=0.8759, Q2 Loss=0.8759, Entropy=0.6856, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2857
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.5770, Q2 Loss=1.5770, Entropy=0.6901, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1078

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.9%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (17.8%)
Actor update: 0.08s (38.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008172
Q1 loss: 0.967649
Q2 loss: 0.967649
Current threshold: -149.5824
Global Scale Offset: 387.4835
Reward stats: mean=0.0138, std=0.0783, count=199
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.9676, Q2 Loss: 0.9676, Entropy: 0.6894, Mean TD Error: 0.8067, Threshold: -149.5824
tensor([ 0.1518,  0.5997,  0.5043,  0.6294, -0.1588,  0.5515,  0.8086,  0.8125,
         1.2980,  0.4560,  0.1185,  1.2406,  0.1748,  0.0891, -0.1185, -0.6719],
       device='cuda:1')
Original likelihood: -143.0177001953125
Adjusted likelihood: -143.0177001953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5067)
State is out of distribution
Projection step: 0, Loss: 141.53753662109375
Projection step: 1, Loss: 145.27313232421875
Projection step: 2, Loss: 157.20974731445312
Projection step: 3, Loss: 143.9002685546875
Projection step: 4, Loss: 129.89691162109375
Projection step: 5, Loss: 135.5497283935547
Projection step: 6, Loss: 133.23562622070312
Projection step: 7, Loss: 140.73789978027344
Projection step: 8, Loss: 129.4392852783203
Projection step: 9, Loss: 121.53849029541016
Projection step: 10, Loss: 131.3946533203125
Projection step: 11, Loss: 135.0102081298828
Projection step: 12, Loss: 123.7286376953125
Projection step: 13, Loss: 120.05677795410156
Projection step: 14, Loss: 123.75334930419922
Projection step: 15, Loss: 121.15325927734375
Projection step: 16, Loss: 121.33773803710938
Projection step: 17, Loss: 128.6897430419922
Projection step: 18, Loss: 116.79107666015625
Projection step: 19, Loss: 119.19873046875
Projection step: 20, Loss: 113.6729736328125
Projection step: 21, Loss: 121.26390075683594
Projection step: 22, Loss: 117.03260040283203
Projection step: 23, Loss: 114.68053436279297
Projection step: 24, Loss: 109.15674591064453
Final likelihood: tensor([-156.3987,  -82.4082, -105.4436, -133.7597,  -87.7636, -118.3687,
        -132.5871, -101.4899,  -95.8032, -107.9531, -106.0347,  -94.2923,
        -151.2728, -112.0949, -104.4398, -116.3067])
Final projection likelihood: -112.9011
1 mode projection succeeded
New goal: tensor([ 0.1045,  0.5739,  0.5145,  0.6570, -0.1564,  0.5069,  0.7615,  0.8753,
         1.3624,  0.3906,  0.1849,  1.1251,  0.1692,  0.0878,  0.0749],
       device='cuda:1')
tensor([[0.0189]], device='cuda:1') tensor([[0.0019]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -128.22044372558594
Adjusted likelihood: -128.22044372558594
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 128.22044372558594}
Current yaw: tensor([ 0.1748,  0.0891, -0.1185], device='cuda:1')
18 thumb_middle
tensor([ 0.1518,  0.5997,  0.5043,  0.6294, -0.1588,  0.5515,  0.8086,  0.8125,
         1.2980,  0.4560,  0.1185,  1.2406,  0.1748,  0.0891, -0.1185, -0.6719],
       device='cuda:1')
Solve time for step 1 8.735015733982436
Current ori: tensor([ 0.1748,  0.0891, -0.1185], device='cuda:1')
Index force: tensor([0.6006, 0.5058, 0.5054, 0.5086], device='cuda:1')
tensor([ 0.1833,  0.5968,  0.5507,  0.6141, -0.2498,  0.4984,  0.7425,  0.8678,
         1.3735,  0.4094,  0.1619,  1.1368,  0.2179,  0.1083, -0.1482, -1.2960],
       device='cuda:1')
Solve time for step 2 3.4653261289931834
Current ori: tensor([ 0.2179,  0.1083, -0.1482], device='cuda:1')
Index force: tensor([0.5049, 0.5025, 0.5037], device='cuda:1')
tensor([ 0.2075,  0.6359,  0.5005,  0.5897, -0.2787,  0.4565,  0.7490,  0.8700,
         1.3953,  0.4040,  0.1778,  1.1440,  0.2388,  0.1122, -0.1244, -1.3168],
       device='cuda:1')
Solve time for step 3 3.317352761980146
Current ori: tensor([ 0.2388,  0.1122, -0.1244], device='cuda:1')
Index force: tensor([0.5016, 0.6038], device='cuda:1')
tensor([ 0.2380,  0.6640,  0.4871,  0.6383, -0.2641,  0.4617,  0.7564,  0.8765,
         1.4076,  0.4035,  0.1972,  1.1516,  0.2381,  0.1092, -0.1835, -0.8960],
       device='cuda:1')
Solve time for step 4 3.1764259019983
Current ori: tensor([ 0.2381,  0.1092, -0.1835], device='cuda:1')
Index force: tensor([0.5874], device='cuda:1')
Storing RECOVERY transition: reward=0.0464 (scaled=0.0077), steps=6
Reward stats updated: mean 0.0138 -> 0.0138, std: 0.0781
Collected 200 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.3187, Q2 Loss=1.3187, Entropy=0.6891, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1469
SAC Update 2/5: Actor Loss=-0.0114, Q1 Loss=1.6448, Q2 Loss=1.6448, Entropy=0.6900, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4057
SAC Update 3/5: Actor Loss=-0.0064, Q1 Loss=0.7523, Q2 Loss=0.7523, Entropy=0.6822, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8516
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=1.4325, Q2 Loss=1.4325, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0010
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=1.1546, Q2 Loss=1.1546, Entropy=0.6834, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6423

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (19.9%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (17.2%)
Actor update: 0.10s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008939
Q1 loss: 1.260579
Q2 loss: 1.260579
Current threshold: -149.5813
Global Scale Offset: 398.7483
Reward stats: mean=0.0138, std=0.0781, count=200
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.2606, Q2 Loss: 1.2606, Entropy: 0.6873, Mean TD Error: 1.2095, Threshold: -149.5813
Original likelihood: -428.77569580078125
Adjusted likelihood: -428.77569580078125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2427)
State is out of distribution
Projection step: 0, Loss: 413.3635559082031
Projection step: 1, Loss: 435.15289306640625
Projection step: 2, Loss: 407.81884765625
Projection step: 3, Loss: 413.46807861328125
Projection step: 4, Loss: 429.60357666015625
Projection step: 5, Loss: 405.27423095703125
Projection step: 6, Loss: 381.05157470703125
Projection step: 7, Loss: 397.1667175292969
Projection step: 8, Loss: 414.77783203125
Projection step: 9, Loss: 398.06927490234375
Projection step: 10, Loss: 391.314697265625
Projection step: 11, Loss: 396.2035217285156
Projection step: 12, Loss: 406.90704345703125
Projection step: 13, Loss: 367.3529052734375
Projection step: 14, Loss: 396.13525390625
Projection step: 15, Loss: 362.51171875
Projection step: 16, Loss: 367.0794982910156
Projection step: 17, Loss: 381.951904296875
Projection step: 18, Loss: 383.5318603515625
Projection step: 19, Loss: 391.7747497558594
Projection step: 20, Loss: 345.2967529296875
Projection step: 21, Loss: 358.70501708984375
Projection step: 22, Loss: 365.24957275390625
Projection step: 23, Loss: 378.42333984375
Projection step: 24, Loss: 357.5500793457031
Final likelihood: tensor([-357.6685, -362.4373, -341.3125, -276.3236, -357.6522, -377.3529,
        -320.1505, -433.1740, -329.7911, -405.8958, -377.0042, -468.7156,
        -329.5805, -324.0114, -309.3944, -361.9587])
Final projection likelihood: -358.2765
1 mode projection failed, trying anyway
New goal: tensor([ 0.2584,  0.6235,  0.5006,  0.6988, -0.1912,  0.4710,  0.8473,  0.9707,
         1.3041,  0.3903,  0.3381,  1.1149,  0.2264,  0.1017, -0.1504],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -416.2579345703125
Adjusted likelihood: -416.2579345703125
Likelihood residual: 0.0
Original likelihood: -391.1802978515625
Adjusted likelihood: -391.1802978515625
Likelihood residual: 0.0
{'index': 391.1802978515625, 'thumb_middle': 416.2579345703125}
Current yaw: tensor([ 0.2342,  0.0983, -0.1928], device='cuda:1')
19 index
tensor([ 0.2765,  0.6870,  0.4928,  0.6546, -0.2173,  0.4711,  0.7878,  0.8987,
         1.4205,  0.3745,  0.2955,  1.2338,  0.2342,  0.0983, -0.1928, -0.9254],
       device='cuda:1')
Solve time for step 1 10.603255956957582
Current ori: tensor([ 0.2342,  0.0983, -0.1928], device='cuda:1')
Middle force: tensor([0.5014, 0.5647, 0.5698, 0.6003], device='cuda:1')
Thumb force: tensor([0.5794, 0.5811, 0.6180, 0.5697], device='cuda:1')
tensor([ 0.4675,  0.5993,  0.5155,  0.6926, -0.2226,  0.4682,  0.7916,  0.9602,
         1.4034,  0.4065,  0.3471,  1.1557,  0.2311,  0.0999, -0.2328, -0.8059],
       device='cuda:1')
Solve time for step 2 4.217700944980606
Current ori: tensor([ 0.2311,  0.0999, -0.2328], device='cuda:1')
Middle force: tensor([0.5582, 0.5643, 0.5966], device='cuda:1')
Thumb force: tensor([0.5753, 0.6132, 0.5669], device='cuda:1')
tensor([ 0.4700,  0.5876,  0.5161,  0.7002, -0.2194,  0.4786,  0.7904,  0.9675,
         1.3951,  0.4205,  0.3599,  1.1315,  0.2271,  0.0991, -0.2314, -0.5436],
       device='cuda:1')
Solve time for step 3 4.035885971970856
Current ori: tensor([ 0.2271,  0.0991, -0.2314], device='cuda:1')
Middle force: tensor([0.5313, 0.5282], device='cuda:1')
Thumb force: tensor([0.5390, 0.5577], device='cuda:1')
tensor([ 0.4349,  0.6400,  0.5185,  0.7011, -0.2200,  0.4777,  0.7928,  0.9719,
         1.3927,  0.4216,  0.3586,  1.1396,  0.2282,  0.0990, -0.2204, -0.4812],
       device='cuda:1')
Solve time for step 4 4.018444238987286
Current ori: tensor([ 0.2282,  0.0990, -0.2204], device='cuda:1')
Middle force: tensor([0.5241], device='cuda:1')
Thumb force: tensor([0.5515], device='cuda:1')
Storing RECOVERY transition: reward=0.0583 (scaled=0.0097), steps=6
Reward stats updated: mean 0.0138 -> 0.0138, std: 0.0779
Collected 201 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=1.4111, Q2 Loss=1.4111, Entropy=0.6828, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1883
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=1.7551, Q2 Loss=1.7551, Entropy=0.6881, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6540
SAC Update 3/5: Actor Loss=-0.0055, Q1 Loss=1.1241, Q2 Loss=1.1241, Entropy=0.6797, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0573
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.0709, Q2 Loss=1.0709, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7212
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=2.1103, Q2 Loss=2.1103, Entropy=0.6907, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7546

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008620
Q1 loss: 1.494330
Q2 loss: 1.494330
Current threshold: -149.5807
Global Scale Offset: 412.7559
Reward stats: mean=0.0138, std=0.0779, count=201
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.4943, Q2 Loss: 1.4943, Entropy: 0.6867, Mean TD Error: 2.0751, Threshold: -149.5807
Original likelihood: -416.32354736328125
Adjusted likelihood: -416.32354736328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2598)
Current yaw: tensor([ 0.2312,  0.0971, -0.2045], device='cuda:1')
20 turn
Sampling time 3.5858022900065407
tensor([ 0.2799,  0.6881,  0.5243,  0.7001, -0.2165,  0.4692,  0.8322,  0.9732,
         1.3821,  0.4289,  0.3553,  1.1632,  0.2312,  0.0971, -0.2045, -0.6782],
       device='cuda:1')
Original likelihood: -400.85870361328125
Adjusted likelihood: -400.85870361328125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2720)
State is out of distribution
Projection step: 0, Loss: 418.61151123046875
Projection step: 1, Loss: 402.8466796875
Projection step: 2, Loss: 364.49969482421875
Projection step: 3, Loss: 391.9356689453125
Projection step: 4, Loss: 367.51806640625
Projection step: 5, Loss: 376.9920654296875
Projection step: 6, Loss: 370.9222412109375
Projection step: 7, Loss: 369.67791748046875
Projection step: 8, Loss: 367.8244934082031
Projection step: 9, Loss: 356.125244140625
Projection step: 10, Loss: 380.829833984375
Projection step: 11, Loss: 364.7517395019531
Projection step: 12, Loss: 359.22265625
Projection step: 13, Loss: 346.0068664550781
Projection step: 14, Loss: 359.688720703125
Projection step: 15, Loss: 356.3046569824219
Projection step: 16, Loss: 369.18121337890625
Projection step: 17, Loss: 357.23248291015625
Projection step: 18, Loss: 343.73150634765625
Projection step: 19, Loss: 336.4216003417969
Projection step: 20, Loss: 353.10223388671875
Projection step: 21, Loss: 321.38714599609375
Projection step: 22, Loss: 363.9106750488281
Projection step: 23, Loss: 347.1085205078125
Projection step: 24, Loss: 356.35943603515625
Final likelihood: tensor([-290.5023, -357.6811, -364.9664, -331.2853, -356.0134, -359.9970,
        -344.5801, -388.0902, -263.2845, -410.9374, -308.0189, -254.6685,
        -310.3938, -335.8690, -293.7769, -333.0945])
Final projection likelihood: -331.4474
1 mode projection failed, trying anyway
New goal: tensor([ 0.2601,  0.6109,  0.5135,  0.7331, -0.1889,  0.4594,  0.8649,  1.0021,
         1.2712,  0.4491,  0.3969,  1.0390,  0.2234,  0.0997, -0.1950],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 13
Loaded trajectory sampler
Current yaw: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
Current yaw: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
1 turn
Sampling time 3.6071772309951484
tensor([ 1.4526e-01,  5.9465e-01,  5.5693e-01,  6.6101e-01, -9.5234e-02,
         4.8281e-01,  9.5019e-01,  8.7050e-01,  1.1989e+00,  3.5557e-01,
         2.5009e-01,  1.2093e+00, -7.6254e-04,  1.4815e-02, -2.8589e-02,
         1.5561e-01], device='cuda:1')
Original likelihood: -113.033447265625
Adjusted likelihood: -113.033447265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5352)
Solve time for step 1 14.015188589983154
Current ori: tensor([-0.0008,  0.0148, -0.0286], device='cuda:1')
Middle force: tensor([0.5830, 0.5735, 1.2202, 0.5724, 1.1670, 0.6440, 0.5361, 0.5223, 0.5139,
        0.6369, 0.5909, 0.4943], device='cuda:1')
Thumb force: tensor([0.8783, 0.8970, 0.7410, 1.0270, 0.9869, 0.6641, 0.5262, 0.9023, 0.5460,
        0.5868, 0.6019, 0.6551], device='cuda:1')
Index force: tensor([0.6060, 0.6100, 0.5635, 0.5794, 0.8363, 0.5419, 1.0419, 0.9442, 0.5913,
        0.5882, 0.5907, 0.8248], device='cuda:1')
Storing NORMAL transition: reward=0.0328 (scaled=0.0328), steps=1
Reward stats updated: mean 0.0138 -> 0.0139, std: 0.0778
Collected 202 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.6256, Q2 Loss=1.6256, Entropy=0.6920, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7409
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=1.2879, Q2 Loss=1.2879, Entropy=0.6904, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4694
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=1.1757, Q2 Loss=1.1757, Entropy=0.6915, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8003
SAC Update 4/5: Actor Loss=-0.0067, Q1 Loss=0.6321, Q2 Loss=0.6321, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8821
SAC Update 5/5: Actor Loss=-0.0062, Q1 Loss=0.6130, Q2 Loss=0.6130, Entropy=0.6878, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2548

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.3%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008209
Q1 loss: 1.066856
Q2 loss: 1.066856
Current threshold: -149.5794
Global Scale Offset: 426.0193
Reward stats: mean=0.0139, std=0.0778, count=202
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 1.0669, Q2 Loss: 1.0669, Entropy: 0.6906, Mean TD Error: 1.4295, Threshold: -149.5794
tensor([ 0.1215,  0.5586,  0.5704,  0.6819, -0.0628,  0.4649,  0.8498,  0.8889,
         1.2626,  0.3131,  0.2173,  1.2103, -0.0041,  0.0243, -0.0618,  0.4878],
       device='cuda:1')
Original likelihood: -97.7560043334961
Adjusted likelihood: -97.7560043334961
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5482)
Solve time for step 2 5.497109578049276
Current ori: tensor([-0.0041,  0.0243, -0.0618], device='cuda:1')
Middle force: tensor([0.5704, 1.1977, 0.5681, 1.1403, 0.6377, 0.5315, 0.5201, 0.5125, 0.6291,
        0.5871, 0.5019], device='cuda:1')
Thumb force: tensor([0.8796, 0.7302, 1.0135, 0.9661, 0.6558, 0.5235, 0.8881, 0.5407, 0.5818,
        0.5951, 0.6687], device='cuda:1')
Index force: tensor([0.6012, 0.5601, 0.5744, 0.8299, 0.5396, 1.0354, 0.9374, 0.5925, 0.5851,
        0.5881, 0.8388], device='cuda:1')
Storing NORMAL transition: reward=0.1132 (scaled=0.1132), steps=1
Reward stats updated: mean 0.0139 -> 0.0143, std: 0.0779
Collected 203 transitions for RL
SAC Update 1/5: Actor Loss=-0.0114, Q1 Loss=1.1128, Q2 Loss=1.1128, Entropy=0.6923, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7426
SAC Update 2/5: Actor Loss=-0.0122, Q1 Loss=1.0914, Q2 Loss=1.0914, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4361
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=0.8646, Q2 Loss=0.8646, Entropy=0.6871, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4231
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=1.0210, Q2 Loss=1.0210, Entropy=0.6897, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5528
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=1.9177, Q2 Loss=1.9177, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6850

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009767
Q1 loss: 1.201512
Q2 loss: 1.201512
Current threshold: -149.5783
Global Scale Offset: 438.2429
Reward stats: mean=0.0143, std=0.0779, count=203
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.2015, Q2 Loss: 1.2015, Entropy: 0.6908, Mean TD Error: 1.1679, Threshold: -149.5783
tensor([ 0.1086,  0.5517,  0.5318,  0.6122, -0.0775,  0.4437,  0.8272,  0.9813,
         1.3324,  0.2399,  0.2185,  1.1270, -0.0094,  0.0346, -0.1761, -0.1985],
       device='cuda:1')
Original likelihood: -130.2732391357422
Adjusted likelihood: -130.2732391357422
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5175)
State is out of distribution
Projection step: 0, Loss: 131.43438720703125
Projection step: 1, Loss: 127.72801208496094
Projection step: 2, Loss: 116.1103515625
Projection step: 3, Loss: 100.7138442993164
Final likelihood: tensor([ -95.4020, -103.9048, -107.5898,  -98.0303,  -87.5697, -109.4665,
         -95.9120,  -98.7295, -102.0623,  -92.7878, -108.5102,  -88.1214,
         -98.3172, -107.3279, -108.4900, -109.2002])
Final projection likelihood: -100.7139
1 mode projection succeeded
New goal: tensor([ 0.0942,  0.5587,  0.5505,  0.6204, -0.0795,  0.4602,  0.8281,  0.9541,
         1.3173,  0.2495,  0.2133,  1.1264, -0.0103,  0.0303, -0.5180],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0067]], device='cuda:1')
Original likelihood: -121.10397338867188
Adjusted likelihood: -121.10397338867188
Likelihood residual: 0.0
{'index': 121.10397338867188, 'thumb_middle': inf}
Current yaw: tensor([-0.0094,  0.0346, -0.1761], device='cuda:1')
2 index
tensor([ 0.1086,  0.5517,  0.5318,  0.6122, -0.0775,  0.4437,  0.8272,  0.9813,
         1.3324,  0.2399,  0.2185,  1.1270, -0.0094,  0.0346, -0.1761, -0.1985],
       device='cuda:1')
Solve time for step 1 10.6931094879983
Current ori: tensor([-0.0094,  0.0346, -0.1761], device='cuda:1')
Middle force: tensor([0.5646, 0.5446, 0.5265, 0.5270], device='cuda:1')
Thumb force: tensor([0.5463, 0.5234, 0.6512, 0.5488], device='cuda:1')
tensor([ 0.1350,  0.5107,  0.5062,  0.5980, -0.0696,  0.4458,  0.8358,  0.9695,
         1.3343,  0.2366,  0.2110,  1.1185, -0.0133,  0.0301, -0.1971, -0.5311],
       device='cuda:1')
Solve time for step 2 4.192208699998446
Current ori: tensor([-0.0133,  0.0301, -0.1971], device='cuda:1')
Middle force: tensor([0.5403, 0.5232, 0.5248], device='cuda:1')
Thumb force: tensor([0.5205, 0.6459, 0.5445], device='cuda:1')
tensor([ 0.1358,  0.5117,  0.5049,  0.5971, -0.0681,  0.4531,  0.8310,  0.9649,
         1.3396,  0.2290,  0.2062,  1.1140, -0.0163,  0.0289, -0.2003, -0.5690],
       device='cuda:1')
Solve time for step 3 4.244215911952779
Current ori: tensor([-0.0163,  0.0289, -0.2003], device='cuda:1')
Middle force: tensor([0.5774, 0.5145], device='cuda:1')
Thumb force: tensor([0.5777, 0.5578], device='cuda:1')
tensor([ 0.1358,  0.5122,  0.5042,  0.5977, -0.0725,  0.4536,  0.8303,  0.9626,
         1.3381,  0.2434,  0.2045,  1.1134, -0.0207,  0.0319, -0.2230, -0.3900],
       device='cuda:1')
Solve time for step 4 3.935773513978347
Current ori: tensor([-0.0207,  0.0319, -0.2230], device='cuda:1')
Middle force: tensor([0.5114], device='cuda:1')
Thumb force: tensor([0.5641], device='cuda:1')
Storing RECOVERY transition: reward=0.0519 (scaled=0.0259), steps=2
Reward stats updated: mean 0.0143 -> 0.0144, std: 0.0777
Collected 204 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.6967, Q2 Loss=0.6967, Entropy=0.6919, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3846
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.7203, Q2 Loss=0.7203, Entropy=0.6913, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5625
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=1.4562, Q2 Loss=1.4562, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8730
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=1.3272, Q2 Loss=1.3272, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0089
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.4015, Q2 Loss=1.4015, Entropy=0.6844, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2723

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009290
Q1 loss: 1.120376
Q2 loss: 1.120376
Current threshold: -149.5772
Global Scale Offset: 449.5827
Reward stats: mean=0.0144, std=0.0777, count=204
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.1204, Q2 Loss: 1.1204, Entropy: 0.6905, Mean TD Error: 1.0203, Threshold: -149.5772
Original likelihood: -113.01752471923828
Adjusted likelihood: -113.01752471923828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5323)
Current yaw: tensor([-0.0236,  0.0362, -0.2291], device='cuda:1')
3 turn
Sampling time 3.64399345300626
tensor([ 0.0817,  0.5707,  0.5475,  0.6194, -0.0798,  0.4554,  0.8269,  0.9587,
         1.3444,  0.2433,  0.1970,  1.1246, -0.0236,  0.0362, -0.2291, -0.3164],
       device='cuda:1')
Original likelihood: -101.66258239746094
Adjusted likelihood: -101.66258239746094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5423)
Solve time for step 1 14.17654830898391
Current ori: tensor([-0.0236,  0.0362, -0.2291], device='cuda:1')
Middle force: tensor([0.5190, 0.5685, 1.2586, 1.3057, 0.5039, 0.7947, 0.7463, 0.5008, 1.0284,
        0.5679, 0.6973, 0.5989], device='cuda:1')
Thumb force: tensor([0.5235, 0.8337, 0.7124, 1.9012, 0.9065, 0.6297, 1.5098, 0.5372, 0.5835,
        0.5941, 0.5739, 0.5151], device='cuda:1')
Index force: tensor([0.9557, 0.5481, 0.7936, 0.5476, 0.5046, 0.9178, 0.5238, 0.5569, 0.5815,
        0.6094, 0.5462, 0.6202], device='cuda:1')
Storing NORMAL transition: reward=0.0970 (scaled=0.0970), steps=1
Reward stats updated: mean 0.0144 -> 0.0148, std: 0.0777
Collected 205 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.9335, Q2 Loss=0.9335, Entropy=0.6848, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7507
SAC Update 2/5: Actor Loss=-0.0065, Q1 Loss=0.7662, Q2 Loss=0.7662, Entropy=0.6812, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0799
SAC Update 3/5: Actor Loss=-0.0108, Q1 Loss=1.4338, Q2 Loss=1.4338, Entropy=0.6857, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1671
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=1.1639, Q2 Loss=1.1639, Entropy=0.6899, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0023
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=4.4370, Q2 Loss=4.4370, Entropy=0.6871, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5912

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.8%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009635
Q1 loss: 1.746887
Q2 loss: 1.746887
Current threshold: -149.5763
Global Scale Offset: 461.6640
Reward stats: mean=0.0148, std=0.0777, count=205
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.7469, Q2 Loss: 1.7469, Entropy: 0.6858, Mean TD Error: 1.5182, Threshold: -149.5763
tensor([ 0.1255,  0.5075,  0.6688,  0.6356, -0.0399,  0.3876,  0.9587,  0.9440,
         1.3308,  0.2423,  0.1730,  1.1322, -0.0099,  0.0102, -0.3246, -0.0155],
       device='cuda:1')
Original likelihood: -114.2236328125
Adjusted likelihood: -114.2236328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5304)
Solve time for step 2 5.518530074041337
Current ori: tensor([-0.0099,  0.0102, -0.3246], device='cuda:1')
Middle force: tensor([0.5283, 0.5002, 0.6129, 0.6163, 0.5068, 0.5366, 0.5134, 0.8189, 0.5290,
        0.5039, 0.5859], device='cuda:1')
Thumb force: tensor([0.5756, 0.5762, 0.7643, 0.5333, 0.6756, 0.9727, 1.5832, 0.5652, 0.5715,
        0.5751, 0.6143], device='cuda:1')
Index force: tensor([0.5675, 0.7977, 0.6604, 0.5981, 0.6434, 0.5341, 0.5510, 0.7608, 0.6832,
        0.5142, 0.5797], device='cuda:1')
Storing NORMAL transition: reward=0.0029 (scaled=0.0029), steps=1
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0775
Collected 206 transitions for RL
SAC Update 1/5: Actor Loss=-0.0109, Q1 Loss=2.9221, Q2 Loss=2.9221, Entropy=0.6904, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6115
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9066, Q2 Loss=0.9066, Entropy=0.6909, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0138
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.9099, Q2 Loss=0.9099, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6158
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=1.3212, Q2 Loss=1.3212, Entropy=0.6915, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4507
SAC Update 5/5: Actor Loss=-0.0122, Q1 Loss=3.6073, Q2 Loss=3.6073, Entropy=0.6903, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8042

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.8%)
Q1 update: 0.04s (17.8%)
Q2 update: 0.05s (20.0%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009486
Q1 loss: 1.933412
Q2 loss: 1.933412
Current threshold: -149.5750
Global Scale Offset: 473.7104
Reward stats: mean=0.0147, std=0.0775, count=206
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.9334, Q2 Loss: 1.9334, Entropy: 0.6912, Mean TD Error: 1.8992, Threshold: -149.5750
tensor([ 0.1339,  0.4465,  0.6707,  0.6660, -0.0425,  0.4112,  0.9232,  0.9358,
         1.3424,  0.1450,  0.0942,  1.0726, -0.0220,  0.0140, -0.3281,  0.4372],
       device='cuda:1')
Original likelihood: -124.81570434570312
Adjusted likelihood: -124.81570434570312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5208)
Solve time for step 3 5.251716637983918
Current ori: tensor([-0.0220,  0.0140, -0.3281], device='cuda:1')
Middle force: tensor([1.1922, 1.2641, 0.5031, 0.8020, 0.7324, 0.5003, 0.9879, 0.5657, 0.6825,
        0.5878], device='cuda:1')
Thumb force: tensor([0.6677, 1.7765, 0.8741, 0.5823, 1.4289, 0.5287, 0.5727, 0.5745, 0.5623,
        0.5123], device='cuda:1')
Index force: tensor([0.7653, 0.5396, 0.5033, 0.9005, 0.5196, 0.5512, 0.5732, 0.5978, 0.5419,
        0.6095], device='cuda:1')
Storing NORMAL transition: reward=-0.0246 (scaled=-0.0246), steps=1
Reward stats updated: mean 0.0147 -> 0.0146, std: 0.0774
Collected 207 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.6599, Q2 Loss=0.6599, Entropy=0.6919, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2546
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.6938, Q2 Loss=1.6938, Entropy=0.6914, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0047
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=2.5777, Q2 Loss=2.5777, Entropy=0.6896, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3300
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.5929, Q2 Loss=0.5929, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1678
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.8228, Q2 Loss=0.8228, Entropy=0.6915, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6361

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.5%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008454
Q1 loss: 1.269414
Q2 loss: 1.269414
Current threshold: -149.5739
Global Scale Offset: 485.4403
Reward stats: mean=0.0146, std=0.0774, count=207
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 1.2694, Q2 Loss: 1.2694, Entropy: 0.6915, Mean TD Error: 1.4786, Threshold: -149.5739
tensor([ 0.1174,  0.4811,  0.6768,  0.6666,  0.0227,  0.4617,  0.9290,  0.9166,
         1.3676,  0.0831,  0.1488,  0.9369, -0.0190, -0.0334, -0.3043,  0.7083],
       device='cuda:1')
Original likelihood: -122.2222900390625
Adjusted likelihood: -122.2222900390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5224)
Solve time for step 4 4.999990523967426
Current ori: tensor([-0.0190, -0.0334, -0.3043], device='cuda:1')
Middle force: tensor([1.2539, 0.5035, 0.8599, 0.7458, 0.5003, 0.9719, 0.5709, 0.6787, 0.5851],
       device='cuda:1')
Thumb force: tensor([1.7003, 0.8439, 0.5450, 1.3724, 0.5244, 0.5682, 0.5649, 0.5562, 0.5108],
       device='cuda:1')
Index force: tensor([0.5361, 0.5028, 0.8917, 0.5179, 0.5465, 0.5691, 0.5879, 0.5400, 0.6048],
       device='cuda:1')
Storing NORMAL transition: reward=0.0382 (scaled=0.0382), steps=1
Reward stats updated: mean 0.0146 -> 0.0147, std: 0.0772
Collected 208 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6547, Q2 Loss=0.6547, Entropy=0.6920, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6749
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=1.1561, Q2 Loss=1.1561, Entropy=0.6910, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3319
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.0270, Q2 Loss=1.0270, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7655
SAC Update 4/5: Actor Loss=-0.0066, Q1 Loss=0.5799, Q2 Loss=0.5799, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2694
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.9188, Q2 Loss=0.9188, Entropy=0.6900, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3423

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.0%)
Actor update: 0.10s (41.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008003
Q1 loss: 0.867283
Q2 loss: 0.867283
Current threshold: -149.5734
Global Scale Offset: 495.5004
Reward stats: mean=0.0147, std=0.0772, count=208
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 0.8673, Q2 Loss: 0.8673, Entropy: 0.6916, Mean TD Error: 1.0768, Threshold: -149.5734
tensor([ 0.1112,  0.5193,  0.6455,  0.6144,  0.0463,  0.4823,  0.8962,  0.9751,
         1.3328,  0.2051,  0.2112,  0.8820, -0.0183, -0.0483, -0.3441,  0.9263],
       device='cuda:1')
Original likelihood: -121.42915344238281
Adjusted likelihood: -121.42915344238281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5226)
Solve time for step 5 4.712027114001103
Current ori: tensor([-0.0183, -0.0483, -0.3441], device='cuda:1')
Middle force: tensor([0.5009, 0.8328, 0.5130, 0.9582, 0.5276, 0.8017, 0.5693, 0.5782],
       device='cuda:1')
Thumb force: tensor([0.7037, 0.7814, 0.8891, 0.6740, 0.5266, 0.6553, 1.0268, 0.5599],
       device='cuda:1')
Index force: tensor([0.6242, 0.6149, 0.5818, 0.5068, 0.5340, 0.5068, 0.5006, 0.5104],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0066 (scaled=-0.0066), steps=1
Reward stats updated: mean 0.0147 -> 0.0146, std: 0.0771
Collected 209 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=3.3525, Q2 Loss=3.3525, Entropy=0.6845, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2758
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=0.8633, Q2 Loss=0.8633, Entropy=0.6908, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0851
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8109, Q2 Loss=0.8109, Entropy=0.6922, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9312
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.1725, Q2 Loss=1.1725, Entropy=0.6912, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8124
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=0.8213, Q2 Loss=0.8213, Entropy=0.6872, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1785

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.9%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009329
Q1 loss: 1.404090
Q2 loss: 1.404090
Current threshold: -149.5734
Global Scale Offset: 507.4240
Reward stats: mean=0.0146, std=0.0771, count=209
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.4041, Q2 Loss: 1.4041, Entropy: 0.6892, Mean TD Error: 1.0566, Threshold: -149.5734
tensor([ 0.1798,  0.5364,  0.6978,  0.6051, -0.1175,  0.5471,  0.9235,  0.9117,
         1.3478,  0.2651,  0.1196,  0.8783, -0.0151, -0.0892, -0.3442,  1.0051],
       device='cuda:1')
Original likelihood: -179.24072265625
Adjusted likelihood: -179.24072265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4768)
Solve time for step 6 4.653493202000391
Current ori: tensor([-0.0151, -0.0892, -0.3442], device='cuda:1')
Middle force: tensor([0.5180, 0.5350, 0.5102, 0.8709, 0.5852, 0.5027, 0.6502],
       device='cuda:1')
Thumb force: tensor([0.5880, 0.9110, 1.4714, 0.5240, 0.5245, 0.5609, 0.5620],
       device='cuda:1')
Index force: tensor([0.5973, 0.5294, 0.5446, 0.7436, 0.6163, 0.5124, 0.5480],
       device='cuda:1')
Storing NORMAL transition: reward=0.0096 (scaled=0.0096), steps=1
Reward stats updated: mean 0.0146 -> 0.0145, std: 0.0769
Collected 210 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8798, Q2 Loss=0.8798, Entropy=0.6864, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8833
SAC Update 2/5: Actor Loss=-0.0099, Q1 Loss=1.4762, Q2 Loss=1.4762, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8202
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.6950, Q2 Loss=0.6950, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3716
SAC Update 4/5: Actor Loss=-0.0100, Q1 Loss=0.9373, Q2 Loss=0.9373, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7021
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=1.1258, Q2 Loss=1.1258, Entropy=0.6909, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1990

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (19.6%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (39.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009114
Q1 loss: 1.022820
Q2 loss: 1.022820
Current threshold: -149.5731
Global Scale Offset: 518.5611
Reward stats: mean=0.0145, std=0.0769, count=210
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.0228, Q2 Loss: 1.0228, Entropy: 0.6910, Mean TD Error: 0.9952, Threshold: -149.5731
tensor([ 0.1380,  0.5715,  0.5725,  0.6543, -0.1119,  0.7013,  0.9554,  0.8624,
         1.3221,  0.2780,  0.2573,  0.7056, -0.0134, -0.0787, -0.3518,  1.2539],
       device='cuda:1')
Original likelihood: -169.9257354736328
Adjusted likelihood: -169.9257354736328
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4844)
State is out of distribution
Projection step: 0, Loss: 163.5443115234375
Projection step: 1, Loss: 168.1282958984375
Projection step: 2, Loss: 154.75112915039062
Projection step: 3, Loss: 152.04818725585938
Projection step: 4, Loss: 144.28076171875
Projection step: 5, Loss: 144.5861053466797
Projection step: 6, Loss: 144.91375732421875
Projection step: 7, Loss: 144.20733642578125
Projection step: 8, Loss: 142.244140625
Projection step: 9, Loss: 135.46864318847656
Projection step: 10, Loss: 134.28741455078125
Projection step: 11, Loss: 131.6517333984375
Projection step: 12, Loss: 138.6360626220703
Projection step: 13, Loss: 128.72116088867188
Projection step: 14, Loss: 124.29597473144531
Projection step: 15, Loss: 128.79026794433594
Projection step: 16, Loss: 138.30075073242188
Projection step: 17, Loss: 130.3284149169922
Projection step: 18, Loss: 136.86582946777344
Projection step: 19, Loss: 125.35475158691406
Projection step: 20, Loss: 120.61317443847656
Projection step: 21, Loss: 122.0114517211914
Projection step: 22, Loss: 125.12471771240234
Projection step: 23, Loss: 128.02978515625
Projection step: 24, Loss: 124.17158508300781
Final likelihood: tensor([-121.7782, -124.0535, -118.4111, -145.9227, -106.2055, -165.7346,
        -115.1966, -121.9176, -169.6092, -113.9479, -109.1285, -106.2623,
        -106.6279, -114.4327, -107.8199, -123.0595])
Final projection likelihood: -123.1317
1 mode projection succeeded
New goal: tensor([ 0.1293,  0.4902,  0.6835,  0.6406, -0.0521,  0.6890,  0.8953,  0.8098,
         1.3569,  0.2979,  0.2348,  0.7897, -0.0173, -0.0666, -1.1558],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0033]], device='cuda:1')
Original likelihood: -166.17022705078125
Adjusted likelihood: -166.17022705078125
Likelihood residual: 0.0
Original likelihood: -154.42303466796875
Adjusted likelihood: -154.42303466796875
Likelihood residual: 0.0
{'index': 154.42303466796875, 'thumb_middle': 166.17022705078125}
Current yaw: tensor([-0.0134, -0.0787, -0.3518], device='cuda:1')
4 index
tensor([ 0.1380,  0.5715,  0.5725,  0.6543, -0.1119,  0.7013,  0.9554,  0.8624,
         1.3221,  0.2780,  0.2573,  0.7056, -0.0134, -0.0787, -0.3518,  1.2539],
       device='cuda:1')
Solve time for step 1 10.646441682998557
Current ori: tensor([-0.0134, -0.0787, -0.3518], device='cuda:1')
Middle force: tensor([0.5749, 0.5300, 0.5395, 0.5793], device='cuda:1')
Thumb force: tensor([0.6007, 0.5195, 0.5684, 0.5222], device='cuda:1')
tensor([ 0.1654,  0.4520,  0.6123,  0.6144, -0.0930,  0.7304,  0.9394,  0.8384,
         1.3471,  0.2271,  0.2198,  0.6915, -0.0278, -0.0939, -0.3683,  1.7043],
       device='cuda:1')
Solve time for step 2 4.1817138500045985
Current ori: tensor([-0.0278, -0.0939, -0.3683], device='cuda:1')
Middle force: tensor([0.5266, 0.5353, 0.5738], device='cuda:1')
Thumb force: tensor([0.5162, 0.5639, 0.5204], device='cuda:1')
tensor([ 0.1686,  0.4415,  0.6279,  0.6112, -0.1033,  0.7516,  0.9576,  0.8489,
         1.3142,  0.2794,  0.2032,  0.7512, -0.0154, -0.1068, -0.3892,  2.4881],
       device='cuda:1')
Solve time for step 3 4.006480093987193
Current ori: tensor([-0.0154, -0.1068, -0.3892], device='cuda:1')
Middle force: tensor([0.5353, 0.5274], device='cuda:1')
Thumb force: tensor([0.5179, 0.5230], device='cuda:1')
tensor([ 0.1649,  0.4385,  0.6294,  0.6104, -0.1188,  0.7709,  0.9624,  0.8451,
         1.3135,  0.2765,  0.1979,  0.7670, -0.0087, -0.1100, -0.4095,  3.4644],
       device='cuda:1')
Solve time for step 4 3.8916961530339904
Current ori: tensor([-0.0087, -0.1100, -0.4095], device='cuda:1')
Middle force: tensor([0.5060], device='cuda:1')
Thumb force: tensor([0.5119], device='cuda:1')
Storing RECOVERY transition: reward=0.0835 (scaled=0.0139), steps=6
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0767
Collected 211 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=1.4360, Q2 Loss=1.4360, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5121
SAC Update 2/5: Actor Loss=-0.0068, Q1 Loss=0.8679, Q2 Loss=0.8679, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3088
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=0.9523, Q2 Loss=0.9523, Entropy=0.6891, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2146
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.7964, Q2 Loss=0.7964, Entropy=0.6893, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9003
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.7470, Q2 Loss=0.7470, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6743

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.1%)
Actor update: 0.09s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008596
Q1 loss: 0.959928
Q2 loss: 0.959928
Current threshold: -149.5723
Global Scale Offset: 529.0895
Reward stats: mean=0.0145, std=0.0767, count=211
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 0.9599, Q2 Loss: 0.9599, Entropy: 0.6910, Mean TD Error: 1.1220, Threshold: -149.5723
Original likelihood: -194.6743927001953
Adjusted likelihood: -194.6743927001953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4661)
Current yaw: tensor([-0.0035, -0.1169, -0.4492], device='cuda:1')
5 turn
Sampling time 3.5883963750093244
tensor([ 1.2073e-01,  4.9396e-01,  6.7466e-01,  6.3690e-01, -1.3401e-01,
         8.0417e-01,  9.5829e-01,  8.2937e-01,  1.3136e+00,  2.7379e-01,
         1.9198e-01,  7.7222e-01, -3.5452e-03, -1.1692e-01, -4.4922e-01,
         3.9164e+00], device='cuda:1')
Original likelihood: -199.31314086914062
Adjusted likelihood: -199.31314086914062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4627)
State is out of distribution
Projection step: 0, Loss: 190.00692749023438
Projection step: 1, Loss: 190.9295654296875
Projection step: 2, Loss: 185.58383178710938
Projection step: 3, Loss: 187.32960510253906
Projection step: 4, Loss: 181.1827392578125
Projection step: 5, Loss: 178.2602081298828
Projection step: 6, Loss: 177.54876708984375
Projection step: 7, Loss: 172.7624969482422
Projection step: 8, Loss: 172.27828979492188
Projection step: 9, Loss: 168.55667114257812
Projection step: 10, Loss: 166.781982421875
Projection step: 11, Loss: 162.6327362060547
Projection step: 12, Loss: 159.98165893554688
Projection step: 13, Loss: 158.8311767578125
Projection step: 14, Loss: 159.9581298828125
Projection step: 15, Loss: 157.77413940429688
Projection step: 16, Loss: 156.805908203125
Projection step: 17, Loss: 150.60665893554688
Projection step: 18, Loss: 150.51580810546875
Projection step: 19, Loss: 150.67019653320312
Projection step: 20, Loss: 145.220703125
Projection step: 21, Loss: 150.03060913085938
Projection step: 22, Loss: 144.52667236328125
Projection step: 23, Loss: 147.02972412109375
Projection step: 24, Loss: 146.54953002929688
Final likelihood: tensor([-134.3446, -155.8542, -133.8062, -147.0051, -142.0943, -138.1488,
        -152.3282, -142.2209, -154.0753, -148.0879, -145.8483, -139.5062,
        -142.4734, -153.3163, -144.4756, -133.6247])
Final projection likelihood: -144.2006
1 mode projection succeeded
New goal: tensor([ 0.1332,  0.4432,  0.7944,  0.6478, -0.0721,  0.7463,  0.9832,  0.7334,
         1.3738,  0.2827,  0.2017,  0.7665, -0.0106, -0.1020, -1.3049],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -180.7261962890625
Adjusted likelihood: -180.7261962890625
Likelihood residual: 0.0
Original likelihood: -175.2869873046875
Adjusted likelihood: -175.2869873046875
Likelihood residual: 0.0
{'index': 175.2869873046875, 'thumb_middle': 180.7261962890625}
Current yaw: tensor([-0.0035, -0.1169, -0.4492], device='cuda:1')
6 index
tensor([ 1.2073e-01,  4.9396e-01,  6.7466e-01,  6.3690e-01, -1.3401e-01,
         8.0417e-01,  9.5829e-01,  8.2937e-01,  1.3136e+00,  2.7379e-01,
         1.9198e-01,  7.7222e-01, -3.5452e-03, -1.1692e-01, -4.4922e-01,
         3.9164e+00], device='cuda:1')
Solve time for step 1 10.757176697952673
Current ori: tensor([-0.0035, -0.1169, -0.4492], device='cuda:1')
Middle force: tensor([0.6102, 0.5658, 0.5483, 0.5082], device='cuda:1')
Thumb force: tensor([0.5122, 0.5482, 0.5910, 0.5442], device='cuda:1')
tensor([ 0.1525,  0.3868,  0.7107,  0.6102, -0.1295,  0.8043,  1.0100,  0.7633,
         1.3235,  0.2519,  0.1721,  0.7629, -0.0092, -0.1292, -0.4787,  3.3743],
       device='cuda:1')
Solve time for step 2 4.124159529979806
Current ori: tensor([-0.0092, -0.1292, -0.4787], device='cuda:1')
Middle force: tensor([0.5594, 0.5461, 0.5071], device='cuda:1')
Thumb force: tensor([0.5455, 0.5887, 0.5431], device='cuda:1')
tensor([ 0.1571,  0.3810,  0.7207,  0.6067, -0.1427,  0.8234,  1.0222,  0.7486,
         1.3176,  0.2620,  0.1741,  0.7611, -0.0042, -0.1360, -0.5194,  3.3698],
       device='cuda:1')
Solve time for step 3 4.013183567032684
Current ori: tensor([-0.0042, -0.1360, -0.5194], device='cuda:1')
Middle force: tensor([0.5530, 0.5696], device='cuda:1')
Thumb force: tensor([0.5457, 0.5085], device='cuda:1')
tensor([ 0.1551,  0.3782,  0.7250,  0.6068, -0.1564,  0.8501,  1.0220,  0.7350,
         1.3169,  0.2596,  0.1714,  0.7713,  0.0048, -0.1414, -0.5638,  3.7566],
       device='cuda:1')
Solve time for step 4 3.876865319965873
Current ori: tensor([ 0.0048, -0.1414, -0.5638], device='cuda:1')
Middle force: tensor([0.5173], device='cuda:1')
Thumb force: tensor([0.5759], device='cuda:1')
Storing RECOVERY transition: reward=0.1348 (scaled=0.1348), steps=0
Reward stats updated: mean 0.0145 -> 0.0151, std: 0.0770
Collected 212 transitions for RL
SAC Update 1/5: Actor Loss=-0.0112, Q1 Loss=2.2867, Q2 Loss=2.2867, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2900
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8649, Q2 Loss=0.8649, Entropy=0.6887, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6321
SAC Update 3/5: Actor Loss=-0.0103, Q1 Loss=2.1452, Q2 Loss=2.1452, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6281
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8662, Q2 Loss=0.8662, Entropy=0.6862, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6837
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.6911, Q2 Loss=0.6911, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2685

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009059
Q1 loss: 1.370841
Q2 loss: 1.370841
Current threshold: -149.5716
Global Scale Offset: 540.9507
Reward stats: mean=0.0151, std=0.0770, count=212
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.3708, Q2 Loss: 1.3708, Entropy: 0.6904, Mean TD Error: 1.1005, Threshold: -149.5716
Original likelihood: -240.8418731689453
Adjusted likelihood: -240.8418731689453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4332)
Current yaw: tensor([ 0.0219, -0.1410, -0.5972], device='cuda:1')
7 turn
Sampling time 3.5882845550077036
tensor([ 0.1307,  0.4401,  0.7767,  0.6368, -0.1719,  0.8674,  1.0203,  0.7282,
         1.3153,  0.2575,  0.1748,  0.7984,  0.0219, -0.1410, -0.5972,  4.0119],
       device='cuda:1')
Original likelihood: -250.17279052734375
Adjusted likelihood: -250.17279052734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4264)
Solve time for step 1 13.98702055303147
Current ori: tensor([ 0.0219, -0.1410, -0.5972], device='cuda:1')
Middle force: tensor([2.1901, 0.8875, 0.6934, 0.5458, 0.5962, 0.6516, 0.5951, 0.7834, 1.0023,
        0.7404, 1.0886, 0.9475], device='cuda:1')
Thumb force: tensor([1.3762, 0.8910, 0.7224, 1.2239, 0.5814, 1.9273, 0.6065, 0.8626, 1.0655,
        0.6744, 1.2749, 0.9933], device='cuda:1')
Index force: tensor([1.2299, 0.6222, 0.5485, 0.5259, 0.6012, 0.7001, 0.5890, 0.6031, 0.5417,
        0.5861, 0.5522, 0.5590], device='cuda:1')
Storing NORMAL transition: reward=0.0413 (scaled=0.0413), steps=1
Reward stats updated: mean 0.0151 -> 0.0152, std: 0.0768
Collected 213 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.9476, Q2 Loss=0.9476, Entropy=0.6904, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2858
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.0500, Q2 Loss=1.0500, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6018
SAC Update 3/5: Actor Loss=-0.0064, Q1 Loss=0.7425, Q2 Loss=0.7425, Entropy=0.6905, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1232
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=0.9731, Q2 Loss=0.9731, Entropy=0.6914, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9399
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.0500, Q2 Loss=1.0500, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7306

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.7%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (20.6%)
Actor update: 0.12s (42.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008440
Q1 loss: 0.952642
Q2 loss: 0.952642
Current threshold: -149.5711
Global Scale Offset: 553.7173
Reward stats: mean=0.0152, std=0.0768, count=213
----------------------------------------------
SAC Update - Actor Loss: -0.0084, Q1 Loss: 0.9526, Q2 Loss: 0.9526, Entropy: 0.6915, Mean TD Error: 1.5362, Threshold: -149.5711
tensor([ 1.2380e-03,  3.7306e-01,  8.4935e-01,  6.8486e-01, -1.8347e-01,
         9.0211e-01,  9.3156e-01,  8.4090e-01,  1.2840e+00,  3.2356e-01,
         2.3290e-01,  7.7022e-01,  3.7686e-02, -1.3396e-01, -6.3917e-01,
         4.4846e+00], device='cuda:1')
Original likelihood: -264.5821533203125
Adjusted likelihood: -264.5821533203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4179)
Solve time for step 2 5.54817224497674
Current ori: tensor([ 0.0377, -0.1340, -0.6392], device='cuda:1')
Middle force: tensor([0.8364, 0.6933, 0.5437, 0.5854, 0.6516, 0.5832, 0.7773, 0.9920, 0.7335,
        1.0857, 0.9346], device='cuda:1')
Thumb force: tensor([0.9195, 0.7359, 1.2223, 0.5810, 1.8896, 0.6058, 0.8551, 1.0531, 0.6720,
        1.2505, 0.9827], device='cuda:1')
Index force: tensor([0.6722, 0.5549, 0.5264, 0.6099, 0.6940, 0.5945, 0.6000, 0.5403, 0.5847,
        0.5492, 0.5574], device='cuda:1')
Storing NORMAL transition: reward=-0.0221 (scaled=-0.0221), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0767
Collected 214 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.8148, Q2 Loss=0.8148, Entropy=0.6897, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1033
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.7698, Q2 Loss=0.7698, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7472
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.8667, Q2 Loss=0.8667, Entropy=0.6910, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9469
SAC Update 4/5: Actor Loss=-0.0097, Q1 Loss=2.8619, Q2 Loss=2.8619, Entropy=0.6910, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1084
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=1.7626, Q2 Loss=1.7626, Entropy=0.6862, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7262

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (17.9%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (42.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008123
Q1 loss: 1.415171
Q2 loss: 1.415171
Current threshold: -149.5704
Global Scale Offset: 566.5794
Reward stats: mean=0.0151, std=0.0767, count=214
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.4152, Q2 Loss: 1.4152, Entropy: 0.6902, Mean TD Error: 1.7264, Threshold: -149.5704
tensor([-0.0375,  0.3242,  0.9191,  0.6682, -0.1886,  0.9052,  0.9093,  0.8910,
         1.4070,  0.1183,  0.1637,  0.8191,  0.0580, -0.1297, -0.6170,  4.2946],
       device='cuda:1')
Original likelihood: -275.00592041015625
Adjusted likelihood: -275.00592041015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4126)
Solve time for step 3 5.0144555469742045
Current ori: tensor([ 0.0580, -0.1297, -0.6170], device='cuda:1')
Middle force: tensor([0.6678, 0.5386, 0.5829, 0.6468, 0.5802, 0.7699, 0.9798, 0.7305, 1.0714,
        0.9201], device='cuda:1')
Thumb force: tensor([0.7621, 1.2324, 0.5808, 1.8583, 0.6019, 0.8506, 1.0427, 0.6665, 1.2367,
        0.9712], device='cuda:1')
Index force: tensor([0.5496, 0.5276, 0.6078, 0.6844, 0.5876, 0.5980, 0.5399, 0.5811, 0.5473,
        0.5578], device='cuda:1')
Storing NORMAL transition: reward=-0.0137 (scaled=-0.0137), steps=1
Reward stats updated: mean 0.0151 -> 0.0149, std: 0.0765
Collected 215 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=1.0978, Q2 Loss=1.0978, Entropy=0.6912, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6018
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=0.9278, Q2 Loss=0.9278, Entropy=0.6867, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7808
SAC Update 3/5: Actor Loss=-0.0149, Q1 Loss=1.1731, Q2 Loss=1.1731, Entropy=0.6867, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4951
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.2298, Q2 Loss=1.2298, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0403
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=2.6840, Q2 Loss=2.6840, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0192

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010637
Q1 loss: 1.422501
Q2 loss: 1.422501
Current threshold: -149.5690
Global Scale Offset: 575.8572
Reward stats: mean=0.0149, std=0.0765, count=215
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.4225, Q2 Loss: 1.4225, Entropy: 0.6898, Mean TD Error: 1.3874, Threshold: -149.5690
tensor([-0.1333,  0.2880,  0.8254,  0.6738, -0.1974,  0.9576,  0.9264,  0.8865,
         1.4597,  0.2159,  0.1336,  0.6478,  0.1314, -0.2408, -0.6590,  4.4215],
       device='cuda:1')
Original likelihood: -464.3984069824219
Adjusted likelihood: -464.3984069824219
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2928)
Solve time for step 4 4.841574871970806
Current ori: tensor([ 0.1314, -0.2408, -0.6590], device='cuda:1')
Middle force: tensor([0.5668, 0.5797, 0.6430, 0.5789, 0.7632, 0.9643, 0.7220, 1.0605, 0.9070],
       device='cuda:1')
Thumb force: tensor([1.1760, 0.5789, 1.8122, 0.5951, 0.8477, 1.0334, 0.6661, 1.2204, 0.9509],
       device='cuda:1')
Index force: tensor([0.5219, 0.6026, 0.6817, 0.5813, 0.5949, 0.5400, 0.5795, 0.5456, 0.5557],
       device='cuda:1')
Storing NORMAL transition: reward=0.0250 (scaled=0.0250), steps=1
Reward stats updated: mean 0.0149 -> 0.0150, std: 0.0763
Collected 216 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=0.7333, Q2 Loss=0.7333, Entropy=0.6862, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2439
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.7539, Q2 Loss=0.7539, Entropy=0.6918, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7275
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=1.2594, Q2 Loss=1.2594, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8968
SAC Update 4/5: Actor Loss=-0.0106, Q1 Loss=1.8150, Q2 Loss=1.8150, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8692
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.7640, Q2 Loss=0.7640, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5656

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.11s (39.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008718
Q1 loss: 1.065118
Q2 loss: 1.065118
Current threshold: -149.5677
Global Scale Offset: 584.0793
Reward stats: mean=0.0150, std=0.0763, count=216
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.0651, Q2 Loss: 1.0651, Entropy: 0.6908, Mean TD Error: 1.0606, Threshold: -149.5677
tensor([-0.0274,  0.3656,  0.8522,  0.6933, -0.3013,  1.0880,  0.8892,  0.9523,
         1.5000,  0.1499,  0.0978,  0.7992,  0.2201, -0.2796, -0.7525,  4.8565],
       device='cuda:1')
Original likelihood: -1074.1611328125
Adjusted likelihood: -1074.1611328125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0572)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 14
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.5708897260483354
tensor([ 0.1378,  0.6140,  0.5734,  0.5613, -0.1183,  0.5454,  0.8851,  0.9209,
         1.2120,  0.3173,  0.2583,  1.1852, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -106.60540771484375
Adjusted likelihood: -106.60540771484375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5292)
Solve time for step 1 14.475985437980853
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([0.5142, 0.4961, 1.3161, 1.4009, 0.5665, 0.5362, 0.5173, 0.5544, 0.5970,
        0.5928, 0.6045, 0.5803], device='cuda:1')
Thumb force: tensor([0.7419, 0.5998, 1.2043, 1.0673, 0.7427, 0.8884, 0.5404, 1.1893, 0.6048,
        0.5287, 0.5984, 0.5431], device='cuda:1')
Index force: tensor([0.5102, 0.6726, 0.6187, 0.5351, 0.9256, 0.5451, 0.5940, 0.4981, 0.6227,
        0.5919, 0.6183, 0.5844], device='cuda:1')
Storing NORMAL transition: reward=0.1043 (scaled=0.1043), steps=1
Reward stats updated: mean 0.0150 -> 0.0154, std: 0.0764
Collected 217 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7564, Q2 Loss=0.7564, Entropy=0.6901, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8493
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=1.0130, Q2 Loss=1.0130, Entropy=0.6911, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5643
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=0.9969, Q2 Loss=0.9969, Entropy=0.6863, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3359
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.9037, Q2 Loss=0.9037, Entropy=0.6884, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6973
SAC Update 5/5: Actor Loss=-0.0122, Q1 Loss=2.4969, Q2 Loss=2.4969, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1817

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.9%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009617
Q1 loss: 1.233367
Q2 loss: 1.233367
Current threshold: -149.5670
Global Scale Offset: 593.0932
Reward stats: mean=0.0154, std=0.0764, count=217
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.2334, Q2 Loss: 1.2334, Entropy: 0.6896, Mean TD Error: 1.1257, Threshold: -149.5670
tensor([ 1.3145e-01,  5.5524e-01,  6.3356e-01,  5.8866e-01, -1.1134e-01,
         5.0606e-01,  8.6539e-01,  1.0021e+00,  1.4455e+00,  6.0512e-02,
         1.4010e-01,  1.0933e+00, -1.2082e-04,  1.4038e-02, -1.3527e-01,
         8.9459e-01], device='cuda:1')
Original likelihood: -116.63217163085938
Adjusted likelihood: -116.63217163085938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5221)
State is out of distribution
Projection step: 0, Loss: 118.95750427246094
Projection step: 1, Loss: 119.9366226196289
Projection step: 2, Loss: 107.05880737304688
Projection step: 3, Loss: 100.37379455566406
Final likelihood: tensor([-104.7785,  -90.5826,  -88.8373, -110.3718,  -91.2684, -111.8002,
        -118.9990, -102.0171, -112.6152, -105.9798,  -99.3835,  -95.7488,
        -106.4583,  -92.1469,  -98.0405,  -76.9530])
Final projection likelihood: -100.3738
1 mode projection succeeded
New goal: tensor([ 1.1887e-01,  5.5531e-01,  6.1337e-01,  6.1139e-01, -1.0052e-01,
         5.1602e-01,  8.7778e-01,  9.7392e-01,  1.4387e+00,  8.8231e-02,
         1.5146e-01,  1.0949e+00,  4.8666e-04,  1.3533e-02, -2.0633e-01],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -185.26693725585938
Adjusted likelihood: -185.26693725585938
Likelihood residual: 0.0
Original likelihood: -137.54505920410156
Adjusted likelihood: -137.54505920410156
Likelihood residual: 0.0
{'index': 137.54505920410156, 'thumb_middle': 185.26693725585938}
Current yaw: tensor([-1.2082e-04,  1.4038e-02, -1.3527e-01], device='cuda:1')
2 index
tensor([ 1.3145e-01,  5.5524e-01,  6.3356e-01,  5.8866e-01, -1.1134e-01,
         5.0606e-01,  8.6539e-01,  1.0021e+00,  1.4455e+00,  6.0512e-02,
         1.4010e-01,  1.0933e+00, -1.2082e-04,  1.4038e-02, -1.3527e-01,
         8.9459e-01], device='cuda:1')
Solve time for step 1 10.573282856028527
Current ori: tensor([-1.2082e-04,  1.4038e-02, -1.3527e-01], device='cuda:1')
Middle force: tensor([0.6106, 0.5426, 0.5172, 0.5300], device='cuda:1')
Thumb force: tensor([0.5329, 0.5835, 0.5121, 0.5258], device='cuda:1')
tensor([ 0.1707,  0.5018,  0.5660,  0.5825, -0.1225,  0.5165,  0.8823,  0.9842,
         1.4427,  0.0709,  0.1326,  1.0806, -0.0120,  0.0128, -0.1498,  1.8634],
       device='cuda:1')
Solve time for step 2 4.302007385005709
Current ori: tensor([-0.0120,  0.0128, -0.1498], device='cuda:1')
Middle force: tensor([0.5395, 0.5161, 0.5281], device='cuda:1')
Thumb force: tensor([0.5794, 0.5111, 0.5240], device='cuda:1')
tensor([ 0.1718,  0.5008,  0.5625,  0.5847, -0.1280,  0.5193,  0.8762,  0.9781,
         1.4502,  0.0636,  0.1401,  1.0645, -0.0149,  0.0171, -0.1505,  2.3950],
       device='cuda:1')
Solve time for step 3 4.168444942042697
Current ori: tensor([-0.0149,  0.0171, -0.1505], device='cuda:1')
Middle force: tensor([0.5149, 0.5256], device='cuda:1')
Thumb force: tensor([0.5095, 0.5217], device='cuda:1')
tensor([ 0.1700,  0.5021,  0.5612,  0.5852, -0.1282,  0.5117,  0.8846,  0.9866,
         1.4448,  0.0744,  0.1289,  1.0924, -0.0117,  0.0165, -0.1584,  2.6189],
       device='cuda:1')
Solve time for step 4 3.967490156996064
Current ori: tensor([-0.0117,  0.0165, -0.1584], device='cuda:1')
Middle force: tensor([0.5934], device='cuda:1')
Thumb force: tensor([0.5627], device='cuda:1')
Storing RECOVERY transition: reward=0.0082 (scaled=0.0082), steps=1
Reward stats updated: mean 0.0154 -> 0.0153, std: 0.0762
Collected 218 transitions for RL
SAC Update 1/5: Actor Loss=-0.0096, Q1 Loss=0.8633, Q2 Loss=0.8633, Entropy=0.6509, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5503
SAC Update 2/5: Actor Loss=-0.0114, Q1 Loss=1.4590, Q2 Loss=1.4590, Entropy=0.6914, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2453
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.8565, Q2 Loss=0.8565, Entropy=0.6901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1721
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.6000, Q2 Loss=0.6000, Entropy=0.6890, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3113
SAC Update 5/5: Actor Loss=-0.0126, Q1 Loss=1.4682, Q2 Loss=1.4682, Entropy=0.6905, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0780

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.9%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.4%)
Actor update: 0.13s (42.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009653
Q1 loss: 1.049408
Q2 loss: 1.049408
Current threshold: -149.5663
Global Scale Offset: 600.2691
Reward stats: mean=0.0153, std=0.0762, count=218
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.0494, Q2 Loss: 1.0494, Entropy: 0.6824, Mean TD Error: 0.8714, Threshold: -149.5663
Original likelihood: -131.37371826171875
Adjusted likelihood: -131.37371826171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5121)
Current yaw: tensor([-0.0166,  0.0247, -0.1443], device='cuda:1')
3 turn
Sampling time 3.5699938210309483
tensor([ 0.1125,  0.5576,  0.6024,  0.6054, -0.1393,  0.5207,  0.8713,  0.9689,
         1.4530,  0.0708,  0.1400,  1.0758, -0.0166,  0.0247, -0.1443,  2.6258],
       device='cuda:1')
Original likelihood: -130.081298828125
Adjusted likelihood: -130.081298828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5129)
State is out of distribution
Projection step: 0, Loss: 132.82032775878906
Projection step: 1, Loss: 130.2643585205078
Projection step: 2, Loss: 119.37518310546875
Projection step: 3, Loss: 121.2088394165039
Projection step: 4, Loss: 117.64151000976562
Projection step: 5, Loss: 111.41661834716797
Projection step: 6, Loss: 108.7282943725586
Projection step: 7, Loss: 113.06143951416016
Projection step: 8, Loss: 112.35549926757812
Projection step: 9, Loss: 105.1722412109375
Projection step: 10, Loss: 104.17832946777344
Final likelihood: tensor([ -87.1385,  -98.3921, -125.5242,  -86.8189,  -99.3722, -109.9545,
        -126.9737,  -95.2767, -111.6599, -107.1006, -121.4400, -104.6012,
         -89.0945,  -85.6754, -100.7866, -117.0442])
Final projection likelihood: -104.1783
1 mode projection succeeded
New goal: tensor([ 0.0939,  0.5572,  0.5642,  0.6380, -0.1026,  0.5385,  0.8708,  0.8819,
         1.4262,  0.1339,  0.1631,  1.1097, -0.0175,  0.0205, -0.5485],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -114.89564514160156
Adjusted likelihood: -114.89564514160156
Likelihood residual: 0.0
Original likelihood: -108.87928771972656
Adjusted likelihood: -108.87928771972656
Likelihood residual: 0.0
{'index': 108.87928771972656, 'thumb_middle': 114.89564514160156}
Current yaw: tensor([-0.0166,  0.0247, -0.1443], device='cuda:1')
4 index
tensor([ 0.1125,  0.5576,  0.6024,  0.6054, -0.1393,  0.5207,  0.8713,  0.9689,
         1.4530,  0.0708,  0.1400,  1.0758, -0.0166,  0.0247, -0.1443,  2.6258],
       device='cuda:1')
Solve time for step 1 10.652815819950774
Current ori: tensor([-0.0166,  0.0247, -0.1443], device='cuda:1')
Middle force: tensor([0.5835, 0.5832, 0.5781, 0.5366], device='cuda:1')
Thumb force: tensor([0.5249, 0.5820, 0.5787, 0.5704], device='cuda:1')
tensor([ 0.1429,  0.5016,  0.5219,  0.6071, -0.1283,  0.5254,  0.8920,  0.9230,
         1.4267,  0.1121,  0.1407,  1.0696, -0.0233,  0.0181, -0.1440,  2.8771],
       device='cuda:1')
Solve time for step 2 4.210309817979578
Current ori: tensor([-0.0233,  0.0181, -0.1440], device='cuda:1')
Middle force: tensor([0.5800, 0.5740, 0.5346], device='cuda:1')
Thumb force: tensor([0.5762, 0.5767, 0.5677], device='cuda:1')
tensor([ 0.1436,  0.5037,  0.5156,  0.6111, -0.1303,  0.5252,  0.8937,  0.9180,
         1.4294,  0.1123,  0.1372,  1.0699, -0.0259,  0.0196, -0.1565,  2.8774],
       device='cuda:1')
Solve time for step 3 4.061188965977635
Current ori: tensor([-0.0259,  0.0196, -0.1565], device='cuda:1')
Middle force: tensor([0.5223, 0.5018], device='cuda:1')
Thumb force: tensor([0.6015, 0.5067], device='cuda:1')
tensor([ 0.1418,  0.5034,  0.5143,  0.6120, -0.1225,  0.5306,  0.8946,  0.9122,
         1.4289,  0.1068,  0.1254,  1.0805, -0.0272,  0.0143, -0.1544,  2.7036],
       device='cuda:1')
Solve time for step 4 3.893058820045553
Current ori: tensor([-0.0272,  0.0143, -0.1544], device='cuda:1')
Middle force: tensor([0.5464], device='cuda:1')
Thumb force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=0.0015 (scaled=0.0015), steps=0
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0760
Collected 219 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=1.8657, Q2 Loss=1.8657, Entropy=0.6913, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7299
SAC Update 2/5: Actor Loss=-0.0124, Q1 Loss=1.1424, Q2 Loss=1.1424, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5811
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=1.6566, Q2 Loss=1.6566, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6494
SAC Update 4/5: Actor Loss=-0.0098, Q1 Loss=1.8881, Q2 Loss=1.8881, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2053
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.8079, Q2 Loss=0.8079, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4161

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.6%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.0%)
Actor update: 0.08s (39.5%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010479
Q1 loss: 1.472161
Q2 loss: 1.472161
Current threshold: -149.5655
Global Scale Offset: 609.8321
Reward stats: mean=0.0153, std=0.0760, count=219
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.4722, Q2 Loss: 1.4722, Entropy: 0.6922, Mean TD Error: 1.3164, Threshold: -149.5655
Original likelihood: -101.28526306152344
Adjusted likelihood: -101.28526306152344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5315)
State is out of distribution
Projection step: 0, Loss: 104.45359802246094
Final likelihood: tensor([-106.2482,  -94.4830,  -97.4788, -102.7442, -105.5610, -106.9458,
         -98.1171,  -93.9722, -128.9690,  -90.3624, -104.3911, -134.1468,
        -106.2149, -120.0852,  -92.5550,  -88.9829])
Final projection likelihood: -104.4536
1 mode projection succeeded
New goal: tensor([ 0.0904,  0.5639,  0.5581,  0.6345, -0.1223,  0.5348,  0.8913,  0.9080,
         1.4236,  0.1156,  0.1275,  1.0808, -0.0280,  0.0141, -0.1459],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0280,  0.0141, -0.1459], device='cuda:1')
5 turn
Sampling time 3.813112639996689
tensor([ 0.0904,  0.5639,  0.5581,  0.6345, -0.1223,  0.5348,  0.8913,  0.9080,
         1.4236,  0.1156,  0.1275,  1.0808, -0.0280,  0.0141, -0.1459,  2.6160],
       device='cuda:1')
Original likelihood: -113.73530578613281
Adjusted likelihood: -113.73530578613281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5234)
State is out of distribution
Projection step: 0, Loss: 103.46279907226562
Final likelihood: tensor([-119.2994,  -96.9567, -128.2930,  -92.5998, -114.5675, -105.6753,
         -91.5189,  -97.2057,  -90.7675, -104.2195,  -90.6476, -110.2600,
        -106.5354, -105.7780, -110.2666,  -90.8139])
Final projection likelihood: -103.4628
1 mode projection succeeded
New goal: tensor([ 0.0904,  0.5639,  0.5581,  0.6345, -0.1223,  0.5348,  0.8913,  0.9080,
         1.4236,  0.1156,  0.1275,  1.0808, -0.0280,  0.0141, -0.1459],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0280,  0.0141, -0.1459], device='cuda:1')
6 turn
Sampling time 3.5846316069946624
tensor([ 0.0904,  0.5639,  0.5581,  0.6345, -0.1223,  0.5348,  0.8913,  0.9080,
         1.4236,  0.1156,  0.1275,  1.0808, -0.0280,  0.0141, -0.1459,  2.6160],
       device='cuda:1')
Original likelihood: -100.42790985107422
Adjusted likelihood: -100.42790985107422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5320)
Solve time for step 1 14.050744755018968
Current ori: tensor([-0.0280,  0.0141, -0.1459], device='cuda:1')
Middle force: tensor([0.5541, 0.5545, 0.5817, 1.7969, 0.5586, 1.1933, 0.5001, 1.1447, 0.7170,
        0.7207, 0.6003, 0.5582], device='cuda:1')
Thumb force: tensor([0.5896, 0.7292, 0.5461, 1.4587, 0.5556, 0.7552, 0.5444, 1.3153, 1.8525,
        0.5949, 0.6299, 0.8901], device='cuda:1')
Index force: tensor([0.7040, 0.5015, 0.5569, 0.5180, 0.5559, 0.6357, 0.7261, 0.5947, 0.5793,
        0.5170, 0.6174, 0.6205], device='cuda:1')
Storing NORMAL transition: reward=0.0446 (scaled=0.0446), steps=1
Reward stats updated: mean 0.0153 -> 0.0154, std: 0.0759
Collected 220 transitions for RL
SAC Update 1/5: Actor Loss=-0.0119, Q1 Loss=0.9398, Q2 Loss=0.9398, Entropy=0.6887, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2716
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.6641, Q2 Loss=0.6641, Entropy=0.6861, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3729
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=0.6254, Q2 Loss=0.6254, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2962
SAC Update 4/5: Actor Loss=-0.0117, Q1 Loss=1.0148, Q2 Loss=1.0148, Entropy=0.6852, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7961
SAC Update 5/5: Actor Loss=-0.0070, Q1 Loss=0.8493, Q2 Loss=0.8493, Entropy=0.6909, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5093

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (19.6%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009089
Q1 loss: 0.818666
Q2 loss: 0.818666
Current threshold: -149.5643
Global Scale Offset: 616.0404
Reward stats: mean=0.0154, std=0.0759, count=220
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.8187, Q2 Loss: 0.8187, Entropy: 0.6886, Mean TD Error: 0.6492, Threshold: -149.5643
tensor([ 0.0907,  0.5461,  0.5748,  0.6503, -0.1235,  0.5198,  0.8932,  0.9526,
         1.3779,  0.2016,  0.1682,  1.0442, -0.0226,  0.0144, -0.1904,  2.6668],
       device='cuda:1')
Original likelihood: -93.07630920410156
Adjusted likelihood: -93.07630920410156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5364)
Solve time for step 2 5.669440469995607
Current ori: tensor([-0.0226,  0.0144, -0.1904], device='cuda:1')
Middle force: tensor([0.5525, 0.5810, 1.7696, 0.5576, 1.1798, 0.5001, 1.1304, 0.7110, 0.7185,
        0.5974, 0.5568], device='cuda:1')
Thumb force: tensor([0.7221, 0.5445, 1.4329, 0.5532, 0.7471, 0.5428, 1.2936, 1.8195, 0.5922,
        0.6260, 0.8795], device='cuda:1')
Index force: tensor([0.5014, 0.5546, 0.5175, 0.5542, 0.6313, 0.7235, 0.5919, 0.5768, 0.5156,
        0.6153, 0.6175], device='cuda:1')
Storing NORMAL transition: reward=0.1145 (scaled=0.1145), steps=1
Reward stats updated: mean 0.0154 -> 0.0159, std: 0.0760
Collected 221 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8396, Q2 Loss=0.8396, Entropy=0.6910, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0411
SAC Update 2/5: Actor Loss=-0.0135, Q1 Loss=1.0759, Q2 Loss=1.0759, Entropy=0.6882, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4218
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.1156, Q2 Loss=1.1156, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1381
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=1.7669, Q2 Loss=1.7669, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6636
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=0.9127, Q2 Loss=0.9127, Entropy=0.6903, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2196

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.7%)
Actor update: 0.10s (42.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009956
Q1 loss: 1.142132
Q2 loss: 1.142132
Current threshold: -149.5629
Global Scale Offset: 620.6223
Reward stats: mean=0.0159, std=0.0760, count=221
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.1421, Q2 Loss: 1.1421, Entropy: 0.6910, Mean TD Error: 1.0968, Threshold: -149.5629
tensor([ 9.4570e-02,  5.0398e-01,  5.7687e-01,  6.5643e-01, -8.8515e-02,
         4.4864e-01,  9.0734e-01,  1.1593e+00,  1.3794e+00,  1.6940e-01,
         1.5644e-01,  1.0810e+00,  1.3420e-02, -2.8241e-03, -3.0436e-01,
         3.5029e+00], device='cuda:1')
Original likelihood: -108.53530883789062
Adjusted likelihood: -108.53530883789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5263)
Solve time for step 3 5.4044456710107625
Current ori: tensor([ 0.0134, -0.0028, -0.3044], device='cuda:1')
Middle force: tensor([0.5921, 1.7391, 0.5727, 1.1822, 0.5003, 1.1265, 0.7139, 0.7177, 0.6068,
        0.5630], device='cuda:1')
Thumb force: tensor([0.5345, 1.4126, 0.5415, 0.7299, 0.5301, 1.2621, 1.7782, 0.5877, 0.6104,
        0.8581], device='cuda:1')
Index force: tensor([0.5529, 0.5158, 0.5495, 0.6229, 0.6984, 0.5897, 0.5748, 0.5150, 0.6112,
        0.6093], device='cuda:1')
Storing NORMAL transition: reward=0.0009 (scaled=0.0009), steps=1
Reward stats updated: mean 0.0159 -> 0.0158, std: 0.0759
Collected 222 transitions for RL
SAC Update 1/5: Actor Loss=-0.0118, Q1 Loss=1.6972, Q2 Loss=1.6972, Entropy=0.6913, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4617
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=1.1647, Q2 Loss=1.1647, Entropy=0.6911, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8896
SAC Update 3/5: Actor Loss=-0.0064, Q1 Loss=0.6995, Q2 Loss=0.6995, Entropy=0.6890, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4043
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=0.8314, Q2 Loss=0.8314, Entropy=0.6901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6883
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.7895, Q2 Loss=0.7895, Entropy=0.6920, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5916

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (13.9%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (42.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008859
Q1 loss: 1.036471
Q2 loss: 1.036471
Current threshold: -149.5623
Global Scale Offset: 629.6805
Reward stats: mean=0.0158, std=0.0759, count=222
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.0365, Q2 Loss: 1.0365, Entropy: 0.6907, Mean TD Error: 1.2071, Threshold: -149.5623
tensor([ 6.4627e-02,  5.1385e-01,  5.8134e-01,  6.7480e-01, -9.5435e-02,
         4.4840e-01,  9.1639e-01,  1.1217e+00,  1.3665e+00,  2.0248e-01,
         1.7753e-01,  1.0484e+00,  5.8288e-03,  2.2949e-03, -3.0509e-01,
         3.5585e+00], device='cuda:1')
Original likelihood: -88.51083374023438
Adjusted likelihood: -88.51083374023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5385)
State is out of distribution
Projection step: 0, Loss: 97.70266723632812
Final likelihood: tensor([-101.4676,  -78.2396,  -97.9470, -117.8053,  -95.4227, -114.0766,
         -98.5811,  -90.2917, -107.6996,  -78.4459,  -96.5082,  -75.6809,
        -111.2948, -103.2455,  -99.6518,  -96.8842])
Final projection likelihood: -97.7027
1 mode projection succeeded
New goal: tensor([ 0.0646,  0.5139,  0.5813,  0.6748, -0.0954,  0.4484,  0.9164,  1.1217,
         1.3665,  0.2025,  0.1775,  1.0484,  0.0058,  0.0023, -0.3051],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0058,  0.0023, -0.3051], device='cuda:1')
7 turn
Sampling time 3.5922698249923997
tensor([ 6.4627e-02,  5.1385e-01,  5.8134e-01,  6.7480e-01, -9.5435e-02,
         4.4840e-01,  9.1639e-01,  1.1217e+00,  1.3665e+00,  2.0248e-01,
         1.7753e-01,  1.0484e+00,  5.8288e-03,  2.2949e-03, -3.0509e-01,
         3.5585e+00], device='cuda:1')
Original likelihood: -92.54585266113281
Adjusted likelihood: -92.54585266113281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5360)
State is out of distribution
Projection step: 0, Loss: 92.11378479003906
Final likelihood: tensor([ -92.6836,  -99.0107,  -89.3629, -107.9032, -107.2420,  -92.4242,
         -83.1722,  -76.4737,  -90.6972,  -92.1525, -101.1915,  -95.7312,
         -78.0241,  -88.5357,  -85.8661,  -93.3495])
Final projection likelihood: -92.1138
1 mode projection succeeded
New goal: tensor([ 0.0646,  0.5139,  0.5813,  0.6748, -0.0954,  0.4484,  0.9164,  1.1217,
         1.3665,  0.2025,  0.1775,  1.0484,  0.0058,  0.0023, -0.3051],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0058,  0.0023, -0.3051], device='cuda:1')
8 turn
Sampling time 3.5845729910070077
tensor([ 6.4627e-02,  5.1385e-01,  5.8134e-01,  6.7480e-01, -9.5435e-02,
         4.4840e-01,  9.1639e-01,  1.1217e+00,  1.3665e+00,  2.0248e-01,
         1.7753e-01,  1.0484e+00,  5.8288e-03,  2.2949e-03, -3.0509e-01,
         3.5585e+00], device='cuda:1')
Original likelihood: -91.55270385742188
Adjusted likelihood: -91.55270385742188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5366)
Solve time for step 1 14.510631737997755
Current ori: tensor([ 0.0058,  0.0023, -0.3051], device='cuda:1')
Middle force: tensor([0.5918, 0.6407, 0.5076, 2.3640, 1.1891, 0.5258, 0.7483, 0.5896, 0.5606,
        0.5342, 0.5546, 0.5888], device='cuda:1')
Thumb force: tensor([0.5853, 0.6559, 1.3448, 1.4837, 1.1914, 0.5568, 0.7730, 0.5209, 1.2177,
        0.6838, 0.5985, 0.5838], device='cuda:1')
Index force: tensor([0.5760, 0.5363, 0.5593, 1.1311, 0.5173, 0.5864, 0.9084, 0.8054, 0.5547,
        0.5035, 0.6518, 0.6196], device='cuda:1')
Storing NORMAL transition: reward=0.0021 (scaled=0.0021), steps=1
Reward stats updated: mean 0.0158 -> 0.0157, std: 0.0757
Collected 223 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.8019, Q2 Loss=1.8019, Entropy=0.6929, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2989
SAC Update 2/5: Actor Loss=-0.0105, Q1 Loss=1.5816, Q2 Loss=1.5816, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6247
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7132, Q2 Loss=0.7132, Entropy=0.6907, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2883
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=1.0359, Q2 Loss=1.0359, Entropy=0.6916, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1211
SAC Update 5/5: Actor Loss=-0.0089, Q1 Loss=2.6314, Q2 Loss=2.6314, Entropy=0.6904, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0491

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008827
Q1 loss: 1.552786
Q2 loss: 1.552786
Current threshold: -149.5623
Global Scale Offset: 640.7835
Reward stats: mean=0.0157, std=0.0757, count=223
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.5528, Q2 Loss: 1.5528, Entropy: 0.6915, Mean TD Error: 1.8764, Threshold: -149.5623
tensor([ 5.1260e-02,  4.9101e-01,  6.5979e-01,  5.5814e-01,  4.4523e-02,
         2.7163e-01,  9.4506e-01,  1.0900e+00,  1.2392e+00,  3.3280e-01,
         2.1415e-01,  9.6440e-01,  2.0087e-03,  9.1726e-03, -3.0728e-01,
         3.5180e+00], device='cuda:1')
Original likelihood: -175.42446899414062
Adjusted likelihood: -175.42446899414062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4839)
State is out of distribution
Projection step: 0, Loss: 164.38551330566406
Projection step: 1, Loss: 152.53982543945312
Projection step: 2, Loss: 144.48931884765625
Projection step: 3, Loss: 135.97499084472656
Projection step: 4, Loss: 125.6913070678711
Projection step: 5, Loss: 119.9830551147461
Projection step: 6, Loss: 109.91836547851562
Projection step: 7, Loss: 107.54280090332031
Projection step: 8, Loss: 96.21891784667969
Final likelihood: tensor([-118.6782,  -92.7556, -114.9962,  -86.7990,  -84.7793, -114.4489,
        -103.7796,  -95.7999,  -80.7027, -110.7408,  -92.1458,  -87.1356,
         -95.3255, -109.8989,  -92.4027,  -59.1139])
Final projection likelihood: -96.2189
1 mode projection succeeded
New goal: tensor([ 0.0536,  0.5190,  0.6470,  0.6306,  0.0123,  0.3783,  0.8756,  0.9930,
         1.2583,  0.3370,  0.1950,  1.0802,  0.0023,  0.0104, -0.1484],
       device='cuda:1')
tensor([[0.0120]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -119.32855224609375
Adjusted likelihood: -119.32855224609375
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 119.32855224609375}
Current yaw: tensor([ 0.0020,  0.0092, -0.3073], device='cuda:1')
9 thumb_middle
tensor([ 5.1260e-02,  4.9101e-01,  6.5979e-01,  5.5814e-01,  4.4523e-02,
         2.7163e-01,  9.4506e-01,  1.0900e+00,  1.2392e+00,  3.3280e-01,
         2.1415e-01,  9.6440e-01,  2.0087e-03,  9.1726e-03, -3.0728e-01,
         3.5180e+00], device='cuda:1')
Solve time for step 1 9.17363292799564
Current ori: tensor([ 0.0020,  0.0092, -0.3073], device='cuda:1')
Index force: tensor([0.5875, 0.5929, 0.5788, 0.5800], device='cuda:1')
tensor([ 4.9400e-02,  5.0166e-01,  6.2414e-01,  5.9436e-01, -7.9270e-02,
         3.2529e-01,  8.5036e-01,  9.8617e-01,  1.2348e+00,  3.2627e-01,
         1.5564e-01,  1.0476e+00,  2.7132e-03,  1.0510e-02, -3.0728e-01,
         3.5251e+00], device='cuda:1')
Solve time for step 2 3.5919933390105143
Current ori: tensor([ 0.0027,  0.0105, -0.3073], device='cuda:1')
Index force: tensor([0.5800, 0.5698, 0.5723], device='cuda:1')
tensor([ 6.9449e-02,  5.0405e-01,  6.2925e-01,  6.1515e-01, -7.7994e-02,
         3.6123e-01,  8.4814e-01,  9.7931e-01,  1.2357e+00,  3.2803e-01,
         1.3176e-01,  1.0510e+00,  4.6888e-03, -5.9385e-04, -3.0728e-01,
         3.5588e+00], device='cuda:1')
Solve time for step 3 3.573648565041367
Current ori: tensor([ 0.0047, -0.0006, -0.3073], device='cuda:1')
Index force: tensor([0.5592, 0.5626], device='cuda:1')
tensor([ 7.5117e-02,  4.9254e-01,  6.3890e-01,  6.3740e-01, -7.6419e-02,
         3.6368e-01,  8.5085e-01,  9.7783e-01,  1.2373e+00,  3.2846e-01,
         1.2959e-01,  1.0479e+00,  9.9068e-03, -3.2998e-03, -3.0728e-01,
         3.5770e+00], device='cuda:1')
Solve time for step 4 3.3386934800073504
Current ori: tensor([ 0.0099, -0.0033, -0.3073], device='cuda:1')
Index force: tensor([0.5455], device='cuda:1')
Storing RECOVERY transition: reward=-0.0032 (scaled=-0.0032), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0755
Collected 224 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.8583, Q2 Loss=0.8583, Entropy=0.6921, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7110
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=1.1177, Q2 Loss=1.1177, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5450
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.8011, Q2 Loss=0.8011, Entropy=0.6915, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8352
SAC Update 4/5: Actor Loss=-0.0117, Q1 Loss=4.3578, Q2 Loss=4.3578, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3504
SAC Update 5/5: Actor Loss=-0.0120, Q1 Loss=1.6124, Q2 Loss=1.6124, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4036

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.6%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.04s (17.4%)
Actor update: 0.09s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010242
Q1 loss: 1.749455
Q2 loss: 1.749455
Current threshold: -149.5618
Global Scale Offset: 653.2080
Reward stats: mean=0.0157, std=0.0755, count=224
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.7495, Q2 Loss: 1.7495, Entropy: 0.6920, Mean TD Error: 1.3690, Threshold: -149.5618
Original likelihood: -58.49065399169922
Adjusted likelihood: -58.49065399169922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5553)
Current yaw: tensor([ 0.0125,  0.0138, -0.3044], device='cuda:1')
10 turn
Sampling time 3.629753310990054
tensor([ 0.0440,  0.4798,  0.6276,  0.6383, -0.0375,  0.4054,  0.8796,  0.9934,
         1.3126,  0.3526,  0.1948,  1.0712,  0.0125,  0.0138, -0.3044,  3.5416],
       device='cuda:1')
Original likelihood: -62.81721496582031
Adjusted likelihood: -62.81721496582031
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5527)
State is out of distribution
Projection step: 0, Loss: 61.34584426879883
Final likelihood: tensor([-59.3460, -63.9352, -57.9559, -63.7572, -39.4833, -52.3708, -60.3155,
        -71.9876, -51.9401, -72.3489, -69.8506, -74.1705, -59.3899, -63.4016,
        -69.8450, -51.4355])
Final projection likelihood: -61.3458
1 mode projection succeeded
New goal: tensor([ 0.0440,  0.4798,  0.6276,  0.6383, -0.0375,  0.4054,  0.8796,  0.9934,
         1.3126,  0.3526,  0.1948,  1.0712,  0.0125,  0.0138, -0.3044],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0125,  0.0138, -0.3044], device='cuda:1')
11 turn
Sampling time 3.677873635024298
tensor([ 0.0440,  0.4798,  0.6276,  0.6383, -0.0375,  0.4054,  0.8796,  0.9934,
         1.3126,  0.3526,  0.1948,  1.0712,  0.0125,  0.0138, -0.3044,  3.5416],
       device='cuda:1')
Original likelihood: -58.986610412597656
Adjusted likelihood: -58.986610412597656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5550)
Solve time for step 1 14.031653999001719
Current ori: tensor([ 0.0125,  0.0138, -0.3044], device='cuda:1')
Middle force: tensor([1.2752, 0.6671, 0.5987, 0.6600, 0.5029, 1.2091, 0.8254, 0.6399, 0.5555,
        0.5358, 0.6052, 0.5741], device='cuda:1')
Thumb force: tensor([0.8507, 0.6013, 0.5582, 0.7431, 0.5247, 0.8245, 0.5369, 0.6747, 0.5002,
        0.5888, 0.5966, 0.9256], device='cuda:1')
Index force: tensor([1.5654, 0.8406, 0.5970, 1.0782, 0.5681, 1.4059, 0.7000, 0.5704, 0.5710,
        0.7548, 0.6354, 0.5666], device='cuda:1')
Storing NORMAL transition: reward=0.1333 (scaled=0.1333), steps=1
Reward stats updated: mean 0.0157 -> 0.0162, std: 0.0758
Collected 225 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=1.8033, Q2 Loss=1.8033, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7352
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=1.1910, Q2 Loss=1.1910, Entropy=0.6916, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5134
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8495, Q2 Loss=0.8495, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1788
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=1.2593, Q2 Loss=1.2593, Entropy=0.6895, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4000
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=0.8899, Q2 Loss=0.8899, Entropy=0.6898, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6503

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.0%)
Actor update: 0.08s (40.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009147
Q1 loss: 1.198589
Q2 loss: 1.198589
Current threshold: -149.5607
Global Scale Offset: 666.0512
Reward stats: mean=0.0162, std=0.0758, count=225
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.1986, Q2 Loss: 1.1986, Entropy: 0.6911, Mean TD Error: 1.4956, Threshold: -149.5607
tensor([ 1.5433e-01,  5.8984e-01,  5.6280e-01,  5.2771e-01, -2.8806e-02,
         3.9241e-01,  9.4744e-01,  1.0847e+00,  1.3976e+00,  2.3650e-01,
         1.5539e-01,  9.7035e-01, -7.1300e-03, -3.3291e-03, -4.3744e-01,
         3.5755e+00], device='cuda:1')
Original likelihood: -149.91293334960938
Adjusted likelihood: -149.91293334960938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4998)
State is out of distribution
Projection step: 0, Loss: 159.43084716796875
Projection step: 1, Loss: 143.41876220703125
Projection step: 2, Loss: 129.10232543945312
Projection step: 3, Loss: 123.0811767578125
Projection step: 4, Loss: 104.29891967773438
Final likelihood: tensor([-100.9953,  -85.6592, -124.5414, -110.3813, -122.4965, -109.4635,
         -86.2827, -117.2765,  -94.7780,  -96.9020,  -96.5700, -100.9459,
         -87.0904, -141.8379, -123.9507,  -69.6114])
Final projection likelihood: -104.2989
1 mode projection succeeded
New goal: tensor([ 0.1341,  0.5796,  0.5783,  0.5581, -0.0421,  0.4129,  0.9098,  1.1007,
         1.3768,  0.2784,  0.1462,  1.0015, -0.0066, -0.0019, -0.7011],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0067]], device='cuda:1')
Original likelihood: -143.53579711914062
Adjusted likelihood: -143.53579711914062
Likelihood residual: 0.0
{'index': 143.53579711914062, 'thumb_middle': inf}
Current yaw: tensor([-0.0071, -0.0033, -0.4374], device='cuda:1')
12 index
tensor([ 1.5433e-01,  5.8984e-01,  5.6280e-01,  5.2771e-01, -2.8806e-02,
         3.9241e-01,  9.4744e-01,  1.0847e+00,  1.3976e+00,  2.3650e-01,
         1.5539e-01,  9.7035e-01, -7.1300e-03, -3.3291e-03, -4.3744e-01,
         3.5755e+00], device='cuda:1')
Solve time for step 1 10.654405269015115
Current ori: tensor([-0.0071, -0.0033, -0.4374], device='cuda:1')
Middle force: tensor([0.5626, 0.5373, 0.5060, 0.5875], device='cuda:1')
Thumb force: tensor([0.5243, 0.5253, 0.5537, 0.5643], device='cuda:1')
tensor([ 0.1790,  0.5348,  0.5354,  0.5366, -0.0163,  0.4077,  0.9273,  1.1080,
         1.3909,  0.2517,  0.1380,  0.9879, -0.0093, -0.0098, -0.4626,  3.4996],
       device='cuda:1')
Solve time for step 2 4.349249765975401
Current ori: tensor([-0.0093, -0.0098, -0.4626], device='cuda:1')
Middle force: tensor([0.5335, 0.5050, 0.5817], device='cuda:1')
Thumb force: tensor([0.5240, 0.5509, 0.5630], device='cuda:1')
tensor([ 0.1766,  0.5384,  0.5316,  0.5324, -0.0224,  0.4200,  0.9226,  1.1080,
         1.3877,  0.2547,  0.1358,  0.9922, -0.0095, -0.0114, -0.4575,  3.4122],
       device='cuda:1')
Solve time for step 3 4.286497786990367
Current ori: tensor([-0.0095, -0.0114, -0.4575], device='cuda:1')
Middle force: tensor([0.5043, 0.5798], device='cuda:1')
Thumb force: tensor([0.5025, 0.6048], device='cuda:1')
tensor([ 0.1776,  0.5391,  0.5335,  0.5353, -0.0141,  0.4254,  0.9223,  1.1080,
         1.3803,  0.2636,  0.1268,  1.0048, -0.0096, -0.0166, -0.4574,  3.3521],
       device='cuda:1')
Solve time for step 4 4.021959449979477
Current ori: tensor([-0.0096, -0.0166, -0.4574], device='cuda:1')
Middle force: tensor([0.5200], device='cuda:1')
Thumb force: tensor([0.5314], device='cuda:1')
Storing RECOVERY transition: reward=0.0039 (scaled=0.0039), steps=1
Reward stats updated: mean 0.0162 -> 0.0161, std: 0.0756
Collected 226 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=1.2606, Q2 Loss=1.2606, Entropy=0.6910, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5448
SAC Update 2/5: Actor Loss=-0.0070, Q1 Loss=0.6380, Q2 Loss=0.6380, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2032
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=0.8912, Q2 Loss=0.8912, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2843
SAC Update 4/5: Actor Loss=-0.0108, Q1 Loss=1.1287, Q2 Loss=1.1287, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8431
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.9620, Q2 Loss=0.9620, Entropy=0.6896, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2609

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008948
Q1 loss: 0.976095
Q2 loss: 0.976095
Current threshold: -149.5600
Global Scale Offset: 679.7942
Reward stats: mean=0.0161, std=0.0756, count=226
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9761, Q2 Loss: 0.9761, Entropy: 0.6914, Mean TD Error: 0.8273, Threshold: -149.5600
Original likelihood: -119.27722930908203
Adjusted likelihood: -119.27722930908203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5177)
State is out of distribution
Projection step: 0, Loss: 114.7288589477539
Projection step: 1, Loss: 109.15997314453125
Projection step: 2, Loss: 106.98551940917969
Projection step: 3, Loss: 101.31126403808594
Final likelihood: tensor([-100.3419,  -94.3558,  -94.3529,  -99.9327, -129.5175,  -92.3028,
        -121.2349,  -96.3525, -105.6925, -100.7713,  -92.4275,  -91.6038,
         -94.0765, -117.5271,  -97.7871,  -92.7035])
Final projection likelihood: -101.3113
1 mode projection succeeded
New goal: tensor([ 0.1187,  0.5830,  0.5751,  0.5720, -0.0153,  0.4437,  0.8950,  1.0775,
         1.3603,  0.2880,  0.1228,  1.0221, -0.0113, -0.0210, -0.2942],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -127.69796752929688
Adjusted likelihood: -127.69796752929688
Likelihood residual: 0.0
Original likelihood: -144.08636474609375
Adjusted likelihood: -144.08636474609375
Likelihood residual: 0.0
{'index': 144.08636474609375, 'thumb_middle': 127.69796752929688}
Current yaw: tensor([-0.0123, -0.0215, -0.4420], device='cuda:1')
13 thumb_middle
tensor([ 0.1237,  0.6013,  0.5796,  0.5583, -0.0076,  0.4366,  0.9173,  1.0974,
         1.3744,  0.2680,  0.1178,  1.0143, -0.0123, -0.0215, -0.4420,  3.3320],
       device='cuda:1')
Solve time for step 1 9.027307371026836
Current ori: tensor([-0.0123, -0.0215, -0.4420], device='cuda:1')
Index force: tensor([0.5338, 0.5617, 0.5542, 0.5653], device='cuda:1')
tensor([ 0.1260,  0.6041,  0.5686,  0.5762, -0.0959,  0.4074,  0.8572,  1.0665,
         1.3116,  0.2596,  0.0669,  0.9904, -0.0112, -0.0222, -0.4420,  3.3317],
       device='cuda:1')
Solve time for step 2 3.5976586890174076
Current ori: tensor([-0.0112, -0.0222, -0.4420], device='cuda:1')
Index force: tensor([0.5542, 0.5580, 0.5634], device='cuda:1')
tensor([ 0.1192,  0.6091,  0.5681,  0.5509, -0.0976,  0.4139,  0.8520,  1.0516,
         1.3156,  0.2817,  0.0523,  0.9874, -0.0148, -0.0189, -0.4420,  3.3121],
       device='cuda:1')
Solve time for step 3 3.475153192994185
Current ori: tensor([-0.0148, -0.0189, -0.4420], device='cuda:1')
Index force: tensor([0.5491, 0.5552], device='cuda:1')
tensor([ 0.1310,  0.6054,  0.5696,  0.5818, -0.0934,  0.4178,  0.8548,  1.0601,
         1.3122,  0.2660,  0.0464,  0.9984, -0.0107, -0.0252, -0.4420,  3.3404],
       device='cuda:1')
Solve time for step 4 3.240181545028463
Current ori: tensor([-0.0107, -0.0252, -0.4420], device='cuda:1')
Index force: tensor([0.5410], device='cuda:1')
Storing RECOVERY transition: reward=0.0106 (scaled=0.0106), steps=1
Reward stats updated: mean 0.0161 -> 0.0161, std: 0.0754
Collected 227 transitions for RL
SAC Update 1/5: Actor Loss=-0.0118, Q1 Loss=9.1061, Q2 Loss=9.1061, Entropy=0.6922, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3173
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.7123, Q2 Loss=1.7123, Entropy=0.6920, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1397
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.7974, Q2 Loss=0.7974, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0333
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=0.7862, Q2 Loss=0.7862, Entropy=0.6916, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4827
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=1.7325, Q2 Loss=1.7325, Entropy=0.6900, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8508

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (21.2%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009324
Q1 loss: 2.826905
Q2 loss: 2.826905
Current threshold: -149.5591
Global Scale Offset: 694.6499
Reward stats: mean=0.0161, std=0.0754, count=227
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 2.8269, Q2 Loss: 2.8269, Entropy: 0.6914, Mean TD Error: 2.1648, Threshold: -149.5591
Original likelihood: -105.04196166992188
Adjusted likelihood: -105.04196166992188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5255)
Current yaw: tensor([-0.0125, -0.0181, -0.4486], device='cuda:1')
14 turn
Sampling time 3.803102804988157
tensor([ 0.1176,  0.6011,  0.5744,  0.5569, -0.0290,  0.4698,  0.8894,  1.0585,
         1.3790,  0.2678,  0.1053,  1.0345, -0.0125, -0.0181, -0.4486,  3.3330],
       device='cuda:1')
Original likelihood: -104.66529083251953
Adjusted likelihood: -104.66529083251953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5257)
Solve time for step 1 13.619303738989402
Current ori: tensor([-0.0125, -0.0181, -0.4486], device='cuda:1')
Middle force: tensor([0.7735, 1.9095, 0.7311, 0.5497, 1.0217, 0.4730, 0.5011, 0.8657, 0.4800,
        0.5558, 0.5696, 0.7915], device='cuda:1')
Thumb force: tensor([0.6375, 1.4234, 1.9055, 1.4757, 0.9564, 0.5043, 0.5425, 0.9270, 0.5319,
        0.8067, 1.2949, 1.0409], device='cuda:1')
Index force: tensor([0.7473, 1.3674, 0.5711, 0.5059, 1.2848, 0.6552, 0.5219, 0.5917, 0.7897,
        0.5811, 0.5466, 0.5778], device='cuda:1')
Storing NORMAL transition: reward=-0.0410 (scaled=-0.0410), steps=1
Reward stats updated: mean 0.0161 -> 0.0158, std: 0.0754
Collected 228 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.0216, Q2 Loss=1.0216, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6039
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=1.5859, Q2 Loss=1.5859, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2904
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8596, Q2 Loss=0.8596, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4946
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.7992, Q2 Loss=0.7992, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4740
SAC Update 5/5: Actor Loss=-0.0063, Q1 Loss=0.8089, Q2 Loss=0.8089, Entropy=0.6902, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3349

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.6%)
Q1 update: 0.05s (21.1%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (37.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007813
Q1 loss: 1.015067
Q2 loss: 1.015067
Current threshold: -149.5582
Global Scale Offset: 707.8630
Reward stats: mean=0.0158, std=0.0754, count=228
----------------------------------------------
SAC Update - Actor Loss: -0.0078, Q1 Loss: 1.0151, Q2 Loss: 1.0151, Entropy: 0.6920, Mean TD Error: 1.8396, Threshold: -149.5582
tensor([ 0.1303,  0.5227,  0.6497,  0.6438, -0.0883,  0.4704,  0.9918,  1.0162,
         1.2762,  0.3662,  0.1364,  0.9913,  0.0140, -0.0208, -0.4078,  3.3614],
       device='cuda:1')
Original likelihood: -155.126220703125
Adjusted likelihood: -155.126220703125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4969)
Solve time for step 2 5.356239981018007
Current ori: tensor([ 0.0140, -0.0208, -0.4078], device='cuda:1')
Middle force: tensor([1.7255, 0.6958, 0.5433, 0.8918, 0.5385, 0.5735, 0.5396, 0.5085, 0.5173,
        1.2238, 0.5647], device='cuda:1')
Thumb force: tensor([1.2746, 1.7079, 1.3556, 0.8773, 0.6897, 0.5009, 0.5060, 0.5369, 1.0987,
        0.8796, 0.5330], device='cuda:1')
Index force: tensor([1.2358, 0.5448, 0.5028, 1.1722, 0.5863, 0.5153, 0.5780, 0.6373, 0.5688,
        0.5015, 0.5594], device='cuda:1')
Storing NORMAL transition: reward=0.0559 (scaled=0.0559), steps=1
Reward stats updated: mean 0.0158 -> 0.0160, std: 0.0753
Collected 229 transitions for RL
SAC Update 1/5: Actor Loss=-0.0106, Q1 Loss=1.5074, Q2 Loss=1.5074, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5833
SAC Update 2/5: Actor Loss=-0.0070, Q1 Loss=0.6214, Q2 Loss=0.6214, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1765
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.8022, Q2 Loss=1.8022, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3415
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=0.7146, Q2 Loss=0.7146, Entropy=0.6895, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8497
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=0.8179, Q2 Loss=0.8179, Entropy=0.6871, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2549

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008808
Q1 loss: 1.092718
Q2 loss: 1.092718
Current threshold: -149.5578
Global Scale Offset: 721.0966
Reward stats: mean=0.0160, std=0.0753, count=229
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.0927, Q2 Loss: 1.0927, Entropy: 0.6909, Mean TD Error: 0.8412, Threshold: -149.5578
tensor([ 0.1118,  0.5353,  0.6166,  0.6376, -0.1003,  0.4896,  0.9254,  1.0911,
         1.3707,  0.3337,  0.2247,  0.8505,  0.0089, -0.0117, -0.4633,  3.4010],
       device='cuda:1')
Original likelihood: -109.50190734863281
Adjusted likelihood: -109.50190734863281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5221)
Solve time for step 3 5.18242572498275
Current ori: tensor([ 0.0089, -0.0117, -0.4633], device='cuda:1')
Middle force: tensor([0.6619, 0.5386, 0.8438, 0.5337, 0.5645, 0.5337, 0.5101, 0.5147, 1.1745,
        0.5592], device='cuda:1')
Thumb force: tensor([1.6170, 1.2751, 0.8497, 0.6756, 0.5006, 0.5055, 0.5280, 1.0486, 0.8454,
        0.5281], device='cuda:1')
Index force: tensor([0.5372, 0.5025, 1.1181, 0.5792, 0.5135, 0.5696, 0.6127, 0.5620, 0.5011,
        0.5545], device='cuda:1')
Storing NORMAL transition: reward=0.0094 (scaled=0.0094), steps=1
Reward stats updated: mean 0.0160 -> 0.0160, std: 0.0751
Collected 230 transitions for RL
SAC Update 1/5: Actor Loss=-0.0125, Q1 Loss=3.8325, Q2 Loss=3.8325, Entropy=0.6923, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0409
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.8718, Q2 Loss=0.8718, Entropy=0.6926, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5286
SAC Update 3/5: Actor Loss=-0.0132, Q1 Loss=1.2188, Q2 Loss=1.2188, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5182
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7892, Q2 Loss=0.7892, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9741
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.9210, Q2 Loss=0.9210, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6437

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.1%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (40.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009827
Q1 loss: 1.526641
Q2 loss: 1.526641
Current threshold: -149.5576
Global Scale Offset: 733.3843
Reward stats: mean=0.0160, std=0.0751, count=230
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.5266, Q2 Loss: 1.5266, Entropy: 0.6926, Mean TD Error: 1.5411, Threshold: -149.5576
tensor([ 0.2699,  0.5669,  0.6103,  0.5963, -0.1579,  0.4651,  0.9107,  1.0849,
         1.3931,  0.3365,  0.3057,  0.7348,  0.0049,  0.0288, -0.4733,  1.7555],
       device='cuda:1')
Original likelihood: -190.85623168945312
Adjusted likelihood: -190.85623168945312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4776)
State is out of distribution
Projection step: 0, Loss: 242.74383544921875
Projection step: 1, Loss: 182.0429229736328
Projection step: 2, Loss: 168.2578582763672
Projection step: 3, Loss: 160.10101318359375
Projection step: 4, Loss: 150.40277099609375
Projection step: 5, Loss: 143.26666259765625
Projection step: 6, Loss: 141.60330200195312
Projection step: 7, Loss: 133.2540740966797
Projection step: 8, Loss: 125.18792724609375
Projection step: 9, Loss: 118.70075988769531
Projection step: 10, Loss: 115.48463439941406
Projection step: 11, Loss: 116.73422241210938
Projection step: 12, Loss: 111.94434356689453
Projection step: 13, Loss: 109.7921142578125
Projection step: 14, Loss: 107.07832336425781
Projection step: 15, Loss: 105.62164306640625
Projection step: 16, Loss: 100.43365478515625
Final likelihood: tensor([ -85.9674, -159.6788, -100.0101,  -98.7992, -111.7683, -100.8980,
        -102.4556, -100.2767,  -86.4738, -103.2770, -104.3139,  -98.8928,
         -77.9089,  -85.2954,  -99.5775,  -91.3449])
Final projection likelihood: -100.4337
1 mode projection succeeded
New goal: tensor([ 0.2080,  0.4963,  0.6215,  0.6712, -0.1063,  0.5111,  0.9807,  1.0990,
         1.3743,  0.4708,  0.2765,  0.9604,  0.0042,  0.0163, -1.0076],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0101]], device='cuda:1')
Original likelihood: -132.52626037597656
Adjusted likelihood: -132.52626037597656
Likelihood residual: 0.0
{'index': 132.52626037597656, 'thumb_middle': inf}
Current yaw: tensor([ 0.0049,  0.0288, -0.4733], device='cuda:1')
15 index
tensor([ 0.2699,  0.5669,  0.6103,  0.5963, -0.1579,  0.4651,  0.9107,  1.0849,
         1.3931,  0.3365,  0.3057,  0.7348,  0.0049,  0.0288, -0.4733,  1.7555],
       device='cuda:1')
Solve time for step 1 10.82183862599777
Current ori: tensor([ 0.0049,  0.0288, -0.4733], device='cuda:1')
Middle force: tensor([0.5581, 0.5420, 0.5863, 0.5842], device='cuda:1')
Thumb force: tensor([0.6146, 0.6219, 0.5236, 0.5713], device='cuda:1')
tensor([ 0.2297,  0.4964,  0.6032,  0.6478, -0.1094,  0.4526,  0.9635,  1.1118,
         1.3242,  0.4172,  0.2612,  0.8766,  0.0248, -0.0076, -0.4785,  0.6398],
       device='cuda:1')
Solve time for step 2 4.6627796399989165
Current ori: tensor([ 0.0248, -0.0076, -0.4785], device='cuda:1')
Middle force: tensor([0.5388, 0.5818, 0.5800], device='cuda:1')
Thumb force: tensor([0.6136, 0.5222, 0.5679], device='cuda:1')
tensor([ 0.2233,  0.4900,  0.6052,  0.6579, -0.0984,  0.4572,  0.9679,  1.1102,
         1.3239,  0.4128,  0.2448,  0.8930,  0.0248, -0.0150, -0.4818, -0.1704],
       device='cuda:1')
Solve time for step 3 4.284003698034212
Current ori: tensor([ 0.0248, -0.0150, -0.4818], device='cuda:1')
Middle force: tensor([0.5112, 0.5623], device='cuda:1')
Thumb force: tensor([0.5000, 0.5358], device='cuda:1')
tensor([ 0.2210,  0.4886,  0.6038,  0.6607, -0.1004,  0.4636,  0.9663,  1.1041,
         1.3264,  0.4092,  0.2426,  0.8897,  0.0226, -0.0153, -0.4794, -0.7977],
       device='cuda:1')
Solve time for step 4 3.9545401799841784
Current ori: tensor([ 0.0226, -0.0153, -0.4794], device='cuda:1')
Middle force: tensor([0.5555], device='cuda:1')
Thumb force: tensor([0.5289], device='cuda:1')
Storing RECOVERY transition: reward=0.0069 (scaled=0.0023), steps=3
Reward stats updated: mean 0.0160 -> 0.0159, std: 0.0749
Collected 231 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7481, Q2 Loss=0.7481, Entropy=0.6901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5515
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.9005, Q2 Loss=0.9005, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0938
SAC Update 3/5: Actor Loss=-0.0115, Q1 Loss=4.4562, Q2 Loss=4.4562, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4276
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=0.7834, Q2 Loss=0.7834, Entropy=0.6906, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3175
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=0.8292, Q2 Loss=0.8292, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4485

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (41.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008748
Q1 loss: 1.543506
Q2 loss: 1.543506
Current threshold: -149.5574
Global Scale Offset: 746.7626
Reward stats: mean=0.0159, std=0.0749, count=231
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.5435, Q2 Loss: 1.5435, Entropy: 0.6911, Mean TD Error: 1.1678, Threshold: -149.5574
Original likelihood: -172.25729370117188
Adjusted likelihood: -172.25729370117188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4879)
State is out of distribution
Projection step: 0, Loss: 153.09112548828125
Projection step: 1, Loss: 154.92532348632812
Projection step: 2, Loss: 148.69244384765625
Projection step: 3, Loss: 135.9525146484375
Projection step: 4, Loss: 133.83432006835938
Projection step: 5, Loss: 135.1922149658203
Projection step: 6, Loss: 131.34246826171875
Projection step: 7, Loss: 134.55397033691406
Projection step: 8, Loss: 133.36636352539062
Projection step: 9, Loss: 129.292236328125
Projection step: 10, Loss: 121.88996124267578
Projection step: 11, Loss: 122.61212921142578
Projection step: 12, Loss: 117.36058044433594
Projection step: 13, Loss: 108.57881927490234
Projection step: 14, Loss: 114.36384582519531
Projection step: 15, Loss: 112.39959716796875
Projection step: 16, Loss: 110.90150451660156
Projection step: 17, Loss: 110.47592163085938
Projection step: 18, Loss: 107.16432189941406
Projection step: 19, Loss: 106.85604858398438
Projection step: 20, Loss: 97.18357849121094
Final likelihood: tensor([ -79.9080,  -97.5883,  -80.5612,  -89.1684,  -96.7512, -113.7927,
        -119.0937,  -89.4295, -115.8458,  -96.5284,  -74.7903,  -79.4469,
         -98.4279, -101.2604, -111.3574, -110.9869])
Final projection likelihood: -97.1836
1 mode projection succeeded
New goal: tensor([ 0.1194,  0.5038,  0.5992,  0.7071, -0.0630,  0.5110,  0.9277,  0.9793,
         1.3567,  0.3678,  0.1648,  1.0375,  0.0156, -0.0072, -1.0723],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -112.94562530517578
Adjusted likelihood: -112.94562530517578
Likelihood residual: 0.0
Original likelihood: -151.623779296875
Adjusted likelihood: -151.623779296875
Likelihood residual: 0.0
{'index': 151.623779296875, 'thumb_middle': 112.94562530517578}
Current yaw: tensor([ 0.0183, -0.0200, -0.4801], device='cuda:1')
16 thumb_middle
tensor([ 0.1744,  0.5424,  0.6474,  0.6842, -0.0966,  0.4773,  0.9637,  1.0953,
         1.3277,  0.4161,  0.2327,  0.8879,  0.0183, -0.0200, -0.4801, -0.9524],
       device='cuda:1')
Solve time for step 1 9.325518522004131
Current ori: tensor([ 0.0183, -0.0200, -0.4801], device='cuda:1')
Index force: tensor([0.5826, 0.5884, 0.6023, 0.5783], device='cuda:1')
tensor([ 0.1512,  0.5420,  0.6174,  0.6971, -0.1808,  0.4721,  0.8831,  0.9695,
         1.3037,  0.3639,  0.0975,  0.9769,  0.0187, -0.0069, -0.4801, -0.9819],
       device='cuda:1')
Solve time for step 2 3.5604676990187727
Current ori: tensor([ 0.0187, -0.0069, -0.4801], device='cuda:1')
Index force: tensor([0.5772, 0.5919, 0.5698], device='cuda:1')
tensor([ 0.1498,  0.5444,  0.6092,  0.7041, -0.1856,  0.4843,  0.8764,  0.9527,
         1.3085,  0.3571,  0.0801,  0.9942,  0.0187, -0.0060, -0.4801, -0.9822],
       device='cuda:1')
Solve time for step 3 3.452401859976817
Current ori: tensor([ 0.0187, -0.0060, -0.4801], device='cuda:1')
Index force: tensor([0.5797, 0.5604], device='cuda:1')
tensor([ 0.1540,  0.5442,  0.6123,  0.7071, -0.1832,  0.4877,  0.8778,  0.9479,
         1.3085,  0.3516,  0.0753,  0.9980,  0.0192, -0.0082, -0.4801, -0.9750],
       device='cuda:1')
Solve time for step 4 3.351516646973323
Current ori: tensor([ 0.0192, -0.0082, -0.4801], device='cuda:1')
Index force: tensor([0.5489], device='cuda:1')
Storing RECOVERY transition: reward=0.0076 (scaled=0.0025), steps=3
Reward stats updated: mean 0.0159 -> 0.0159, std: 0.0748
Collected 232 transitions for RL
SAC Update 1/5: Actor Loss=-0.0099, Q1 Loss=1.5978, Q2 Loss=1.5978, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1396
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=2.8873, Q2 Loss=2.8873, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7426
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.0253, Q2 Loss=1.0253, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7673
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=0.7485, Q2 Loss=0.7485, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5545
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.6735, Q2 Loss=0.6735, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5355

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.4%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008744
Q1 loss: 1.386478
Q2 loss: 1.386478
Current threshold: -149.5569
Global Scale Offset: 758.7552
Reward stats: mean=0.0159, std=0.0748, count=232
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.3865, Q2 Loss: 1.3865, Entropy: 0.6926, Mean TD Error: 1.5479, Threshold: -149.5569
Original likelihood: -121.0142822265625
Adjusted likelihood: -121.0142822265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5150)
State is out of distribution
Projection step: 0, Loss: 109.52128601074219
Projection step: 1, Loss: 111.47821807861328
Projection step: 2, Loss: 107.56462097167969
Projection step: 3, Loss: 104.36250305175781
Final likelihood: tensor([-132.0086, -129.7506,  -75.8038, -108.4268, -109.4227,  -81.1622,
         -99.8752, -106.2605, -119.8322,  -98.6844, -118.5225,  -87.2451,
         -80.6054, -102.6124, -114.0212, -105.5665])
Final projection likelihood: -104.3625
1 mode projection succeeded
New goal: tensor([ 0.1308,  0.5178,  0.6101,  0.7079, -0.1037,  0.5316,  0.9273,  0.9688,
         1.3686,  0.3746,  0.1497,  1.0584,  0.0227,  0.0036, -0.5449],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -112.92445373535156
Adjusted likelihood: -112.92445373535156
Likelihood residual: 0.0
Original likelihood: -122.1591796875
Adjusted likelihood: -122.1591796875
Likelihood residual: 0.0
{'index': 122.1591796875, 'thumb_middle': 112.92445373535156}
Current yaw: tensor([ 0.0233,  0.0020, -0.4807], device='cuda:1')
17 thumb_middle
tensor([ 0.1356,  0.5229,  0.6235,  0.7045, -0.1220,  0.5327,  0.9046,  0.9705,
         1.3705,  0.3702,  0.1365,  1.0470,  0.0233,  0.0020, -0.4807, -0.9953],
       device='cuda:1')
Solve time for step 1 8.933970373007469
Current ori: tensor([ 0.0233,  0.0020, -0.4807], device='cuda:1')
Index force: tensor([0.5875, 0.5836, 0.5964, 0.6027], device='cuda:1')
tensor([ 0.1355,  0.5233,  0.6196,  0.7097, -0.2149,  0.5010,  0.8683,  0.9426,
         1.3186,  0.3490,  0.0764,  1.0282,  0.0236,  0.0029, -0.4806, -0.9948],
       device='cuda:1')
Solve time for step 2 3.697799029003363
Current ori: tensor([ 0.0236,  0.0029, -0.4806], device='cuda:1')
Index force: tensor([0.5743, 0.5881, 0.5947], device='cuda:1')
tensor([ 0.1443,  0.5349,  0.6112,  0.7142, -0.2124,  0.5061,  0.8852,  0.9360,
         1.3192,  0.3583,  0.0568,  1.0272,  0.0216, -0.0023, -0.4806, -0.9839],
       device='cuda:1')
Solve time for step 3 3.4948599180206656
Current ori: tensor([ 0.0216, -0.0023, -0.4806], device='cuda:1')
Index force: tensor([0.5774, 0.5858], device='cuda:1')
tensor([ 0.1528,  0.5293,  0.6243,  0.7208, -0.2143,  0.5220,  0.8814,  0.9368,
         1.3165,  0.3784,  0.0597,  1.0129,  0.0238, -0.0065, -0.4806, -0.9681],
       device='cuda:1')
Solve time for step 4 3.3882710530306213
Current ori: tensor([ 0.0238, -0.0065, -0.4806], device='cuda:1')
Index force: tensor([0.5687], device='cuda:1')
Storing RECOVERY transition: reward=0.0113 (scaled=0.0038), steps=3
Reward stats updated: mean 0.0159 -> 0.0158, std: 0.0746
Collected 233 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=5.4094, Q2 Loss=5.4094, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5065
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.0763, Q2 Loss=1.0763, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7774
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=1.0166, Q2 Loss=1.0166, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1781
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=0.9452, Q2 Loss=0.9452, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2845
SAC Update 5/5: Actor Loss=-0.0132, Q1 Loss=1.6078, Q2 Loss=1.6078, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2145

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.1%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010433
Q1 loss: 2.011068
Q2 loss: 2.011068
Current threshold: -149.5567
Global Scale Offset: 769.3774
Reward stats: mean=0.0158, std=0.0746, count=233
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 2.0111, Q2 Loss: 2.0111, Entropy: 0.6926, Mean TD Error: 1.5922, Threshold: -149.5567
Original likelihood: -147.56944274902344
Adjusted likelihood: -147.56944274902344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5010)
State is out of distribution
Projection step: 0, Loss: 142.28836059570312
Projection step: 1, Loss: 141.23240661621094
Projection step: 2, Loss: 129.76515197753906
Projection step: 3, Loss: 128.39950561523438
Projection step: 4, Loss: 124.94747161865234
Projection step: 5, Loss: 118.519287109375
Projection step: 6, Loss: 119.35338592529297
Projection step: 7, Loss: 95.47099304199219
Final likelihood: tensor([ -76.3974,  -85.5501, -108.7418, -103.4888, -102.3036, -116.8442,
        -110.5901,  -76.7166,  -91.3285, -101.7118,  -79.8756,  -95.0250,
         -99.9255, -112.9530,  -93.0416,  -73.0423])
Final projection likelihood: -95.4710
1 mode projection succeeded
New goal: tensor([ 0.1265,  0.5052,  0.5969,  0.7262, -0.1063,  0.5502,  0.9481,  0.9392,
         1.3836,  0.3795,  0.1629,  1.0560,  0.0272,  0.0092, -0.5963],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -110.01776123046875
Adjusted likelihood: -110.01776123046875
Likelihood residual: 0.0
Original likelihood: -130.5202178955078
Adjusted likelihood: -130.5202178955078
Likelihood residual: 0.0
{'index': 130.5202178955078, 'thumb_middle': 110.01776123046875}
Current yaw: tensor([ 0.0298,  0.0089, -0.4848], device='cuda:1')
18 thumb_middle
tensor([ 0.1248,  0.5017,  0.6312,  0.7247, -0.1640,  0.5524,  0.9288,  0.9547,
         1.3933,  0.3688,  0.1225,  1.0538,  0.0298,  0.0089, -0.4848, -0.9984],
       device='cuda:1')
Solve time for step 1 8.96159429801628
Current ori: tensor([ 0.0298,  0.0089, -0.4848], device='cuda:1')
Index force: tensor([0.5777, 0.5910, 0.6099, 0.5956], device='cuda:1')
tensor([ 0.1218,  0.5085,  0.6177,  0.7261, -0.2392,  0.5145,  0.8850,  0.9065,
         1.3330,  0.3633,  0.0772,  1.0184,  0.0282,  0.0109, -0.4848, -1.0108],
       device='cuda:1')
Solve time for step 2 3.5457000720198266
Current ori: tensor([ 0.0282,  0.0109, -0.4848], device='cuda:1')
Index force: tensor([0.5830, 0.6027, 0.5892], device='cuda:1')
tensor([ 0.1254,  0.5338,  0.5999,  0.7015, -0.2388,  0.5233,  0.8894,  0.9036,
         1.3297,  0.3621,  0.0646,  1.0134,  0.0202,  0.0077, -0.4848, -1.0103],
       device='cuda:1')
Solve time for step 3 3.593124317994807
Current ori: tensor([ 0.0202,  0.0077, -0.4848], device='cuda:1')
Index force: tensor([0.5928, 0.5816], device='cuda:1')
tensor([ 0.1255,  0.5207,  0.6041,  0.7289, -0.2394,  0.5204,  0.8900,  0.9042,
         1.3319,  0.3656,  0.0648,  1.0144,  0.0256,  0.0086, -0.4847, -0.9980],
       device='cuda:1')
Solve time for step 4 3.440023048024159
Current ori: tensor([ 0.0256,  0.0086, -0.4847], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0216 (scaled=0.0072), steps=3
Reward stats updated: mean 0.0158 -> 0.0158, std: 0.0745
Collected 234 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6680, Q2 Loss=0.6680, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1961
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=0.7204, Q2 Loss=0.7204, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2922
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.7851, Q2 Loss=0.7851, Entropy=0.6890, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5242
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=1.1323, Q2 Loss=1.1323, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0268
SAC Update 5/5: Actor Loss=-0.0115, Q1 Loss=1.3645, Q2 Loss=1.3645, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1300

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.4%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008867
Q1 loss: 0.934051
Q2 loss: 0.934051
Current threshold: -149.5561
Global Scale Offset: 779.4148
Reward stats: mean=0.0158, std=0.0745, count=234
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9341, Q2 Loss: 0.9341, Entropy: 0.6919, Mean TD Error: 0.6339, Threshold: -149.5561
Original likelihood: -143.84811401367188
Adjusted likelihood: -143.84811401367188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5029)
State is out of distribution
Projection step: 0, Loss: 143.9222869873047
Projection step: 1, Loss: 139.2364501953125
Projection step: 2, Loss: 134.4072265625
Projection step: 3, Loss: 128.54991149902344
Projection step: 4, Loss: 120.48797607421875
Projection step: 5, Loss: 116.63613891601562
Projection step: 6, Loss: 111.37060546875
Projection step: 7, Loss: 107.73298645019531
Projection step: 8, Loss: 100.36723327636719
Final likelihood: tensor([ -99.7175, -105.1871,  -80.6667, -101.6047, -109.2379, -110.5008,
        -101.6057, -101.2952, -122.4278, -115.1547,  -99.0392,  -90.8635,
         -87.2503,  -85.0323,  -82.0156, -114.2768])
Final projection likelihood: -100.3672
1 mode projection succeeded
New goal: tensor([ 0.1249,  0.5137,  0.5875,  0.7265, -0.1027,  0.5580,  0.9509,  0.9213,
         1.3825,  0.3854,  0.1648,  1.0534,  0.0224,  0.0080, -0.6126],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -124.5351791381836
Adjusted likelihood: -124.5351791381836
Likelihood residual: 0.0
Original likelihood: -137.60189819335938
Adjusted likelihood: -137.60189819335938
Likelihood residual: 0.0
{'index': 137.60189819335938, 'thumb_middle': 124.5351791381836}
Current yaw: tensor([ 0.0248,  0.0053, -0.4947], device='cuda:1')
19 thumb_middle
tensor([ 0.1248,  0.5221,  0.6094,  0.7122, -0.1667,  0.5697,  0.9343,  0.9296,
         1.3898,  0.3763,  0.1208,  1.0467,  0.0248,  0.0053, -0.4947, -1.0555],
       device='cuda:1')
Solve time for step 1 9.026350420026574
Current ori: tensor([ 0.0248,  0.0053, -0.4947], device='cuda:1')
Index force: tensor([0.5678, 0.5944, 0.5807, 0.5957], device='cuda:1')
tensor([ 0.1245,  0.5256,  0.5958,  0.7293, -0.2285,  0.5170,  0.8939,  0.8765,
         1.3255,  0.3806,  0.0735,  1.0189,  0.0251,  0.0076, -0.4947, -1.0003],
       device='cuda:1')
Solve time for step 2 3.6744250599876978
Current ori: tensor([ 0.0251,  0.0076, -0.4947], device='cuda:1')
Index force: tensor([0.5852, 0.5740, 0.5889], device='cuda:1')
tensor([ 0.1304,  0.5145,  0.6142,  0.7354, -0.2311,  0.5293,  0.8864,  0.8904,
         1.3372,  0.3678,  0.0667,  0.9988,  0.0284,  0.0048, -0.4947, -0.9875],
       device='cuda:1')
Solve time for step 3 3.5462062699953094
Current ori: tensor([ 0.0284,  0.0048, -0.4947], device='cuda:1')
Index force: tensor([0.5612, 0.5779], device='cuda:1')
tensor([ 0.1436,  0.5214,  0.6066,  0.7589, -0.2325,  0.5354,  0.9088,  0.8794,
         1.3199,  0.3696,  0.0682,  1.0112,  0.0293, -0.0021, -0.4947, -0.9665],
       device='cuda:1')
Solve time for step 4 3.719175832986366
Current ori: tensor([ 0.0293, -0.0021, -0.4947], device='cuda:1')
Index force: tensor([0.5722], device='cuda:1')
Storing RECOVERY transition: reward=0.0213 (scaled=0.0071), steps=3
Reward stats updated: mean 0.0158 -> 0.0157, std: 0.0743
Collected 235 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.7448, Q2 Loss=0.7448, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6118
SAC Update 2/5: Actor Loss=-0.0116, Q1 Loss=4.4428, Q2 Loss=4.4428, Entropy=0.6916, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4441
SAC Update 3/5: Actor Loss=-0.0116, Q1 Loss=4.4348, Q2 Loss=4.4348, Entropy=0.6916, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4129
SAC Update 4/5: Actor Loss=-0.0126, Q1 Loss=1.0318, Q2 Loss=1.0318, Entropy=0.6891, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5467
SAC Update 5/5: Actor Loss=-0.0109, Q1 Loss=1.8510, Q2 Loss=1.8510, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9092

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.2%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.06s (21.2%)
Actor update: 0.12s (42.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011038
Q1 loss: 2.501022
Q2 loss: 2.501022
Current threshold: -149.5558
Global Scale Offset: 789.6936
Reward stats: mean=0.0157, std=0.0743, count=235
----------------------------------------------
SAC Update - Actor Loss: -0.0110, Q1 Loss: 2.5010, Q2 Loss: 2.5010, Entropy: 0.6916, Mean TD Error: 1.5849, Threshold: -149.5558
Original likelihood: -149.50494384765625
Adjusted likelihood: -149.50494384765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5000)
Current yaw: tensor([ 0.0265,  0.0083, -0.4946], device='cuda:1')
20 turn
Sampling time 3.6945117869763635
tensor([ 0.1181,  0.5194,  0.6004,  0.7255, -0.1616,  0.5763,  0.9185,  0.8995,
         1.4003,  0.3679,  0.1140,  1.0509,  0.0265,  0.0083, -0.4946, -1.0701],
       device='cuda:1')
Original likelihood: -131.1437225341797
Adjusted likelihood: -131.1437225341797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5093)
Solve time for step 1 14.175327549979556
Current ori: tensor([ 0.0265,  0.0083, -0.4946], device='cuda:1')
Middle force: tensor([1.3250, 1.7298, 1.8021, 0.5654, 0.6101, 0.5393, 0.5625, 0.5076, 0.4909,
        0.5667, 0.5485, 0.5376], device='cuda:1')
Thumb force: tensor([0.5333, 1.8389, 0.5748, 0.6477, 0.5945, 0.5492, 0.5002, 0.7811, 0.6624,
        0.6174, 0.7568, 0.6668], device='cuda:1')
Index force: tensor([0.6582, 0.7494, 0.5703, 0.5233, 0.5641, 0.6183, 0.5820, 0.6417, 0.8194,
        0.5950, 0.6106, 0.6079], device='cuda:1')
Storing NORMAL transition: reward=-0.0748 (scaled=-0.0748), steps=1
Reward stats updated: mean 0.0157 -> 0.0154, std: 0.0744
Collected 236 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=0.9572, Q2 Loss=0.9572, Entropy=0.6923, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3793
SAC Update 2/5: Actor Loss=-0.0072, Q1 Loss=1.0356, Q2 Loss=1.0356, Entropy=0.6925, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1798
SAC Update 3/5: Actor Loss=-0.0071, Q1 Loss=1.0387, Q2 Loss=1.0387, Entropy=0.6914, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4814
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=0.7165, Q2 Loss=0.7165, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8493
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.8750, Q2 Loss=0.8750, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0218

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.8%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (41.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008037
Q1 loss: 0.924580
Q2 loss: 0.924580
Current threshold: -149.5556
Global Scale Offset: 799.6203
Reward stats: mean=0.0154, std=0.0744, count=236
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 0.9246, Q2 Loss: 0.9246, Entropy: 0.6922, Mean TD Error: 1.5823, Threshold: -149.5556
tensor([ 0.1097,  0.5010,  0.6391,  0.6829, -0.1733,  0.6712,  0.7247,  1.0276,
         1.4343,  0.3023,  0.0823,  1.0847,  0.0266,  0.0166, -0.4198, -1.0764],
       device='cuda:1')
Original likelihood: -154.5547637939453
Adjusted likelihood: -154.5547637939453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4975)
Solve time for step 2 5.507272854971234
Current ori: tensor([ 0.0266,  0.0166, -0.4198], device='cuda:1')
Middle force: tensor([1.6947, 1.7703, 0.5604, 0.6019, 0.5364, 0.5593, 0.5065, 0.5032, 0.5635,
        0.5452, 0.5344], device='cuda:1')
Thumb force: tensor([1.7968, 0.5726, 0.6393, 0.5921, 0.5463, 0.5001, 0.7788, 0.6717, 0.6148,
        0.7506, 0.6662], device='cuda:1')
Index force: tensor([0.7363, 0.5659, 0.5220, 0.5598, 0.6146, 0.5776, 0.6351, 0.8248, 0.5906,
        0.6059, 0.6029], device='cuda:1')
Storing NORMAL transition: reward=0.0667 (scaled=0.0667), steps=1
Reward stats updated: mean 0.0154 -> 0.0156, std: 0.0743
Collected 237 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=0.8583, Q2 Loss=0.8583, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0651
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=0.9132, Q2 Loss=0.9132, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5367
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=0.9703, Q2 Loss=0.9703, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7630
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=0.8693, Q2 Loss=0.8693, Entropy=0.6916, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6736
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.7859, Q2 Loss=0.7859, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6204

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.7%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (20.3%)
Actor update: 0.10s (39.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008852
Q1 loss: 0.879391
Q2 loss: 0.879391
Current threshold: -149.5551
Global Scale Offset: 811.1835
Reward stats: mean=0.0156, std=0.0743, count=237
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.8794, Q2 Loss: 0.8794, Entropy: 0.6919, Mean TD Error: 0.7318, Threshold: -149.5551
tensor([ 2.3254e-01,  5.1850e-01,  6.7057e-01,  8.0288e-01,  1.3859e-02,
         6.3935e-01,  6.7278e-01,  8.3712e-01,  1.4916e+00,  1.7459e-01,
         1.5122e-02,  1.1991e+00,  7.7799e-02,  3.5722e-04, -4.9147e-01,
        -7.7770e-01], device='cuda:1')
Original likelihood: -235.45120239257812
Adjusted likelihood: -235.45120239257812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4579)
State is out of distribution
Projection step: 0, Loss: 236.4537353515625
Projection step: 1, Loss: 244.85879516601562
Projection step: 2, Loss: 218.46192932128906
Projection step: 3, Loss: 216.93423461914062
Projection step: 4, Loss: 218.52659606933594
Projection step: 5, Loss: 216.18536376953125
Projection step: 6, Loss: 205.77639770507812
Projection step: 7, Loss: 204.39260864257812
Projection step: 8, Loss: 201.9156036376953
Projection step: 9, Loss: 198.12673950195312
Projection step: 10, Loss: 197.79989624023438
Projection step: 11, Loss: 186.1080322265625
Projection step: 12, Loss: 182.36941528320312
Projection step: 13, Loss: 188.01834106445312
Projection step: 14, Loss: 183.50611877441406
Projection step: 15, Loss: 184.3027801513672
Projection step: 16, Loss: 179.91688537597656
Projection step: 17, Loss: 175.8057403564453
Projection step: 18, Loss: 174.27627563476562
Projection step: 19, Loss: 174.16357421875
Projection step: 20, Loss: 177.56790161132812
Projection step: 21, Loss: 175.16749572753906
Projection step: 22, Loss: 169.80288696289062
Projection step: 23, Loss: 165.8245086669922
Projection step: 24, Loss: 170.3805694580078
Final likelihood: tensor([-157.4997, -162.1062, -164.0042, -179.6339, -149.4384, -154.9727,
        -153.7911, -171.2136, -162.2700, -156.3733, -173.6693, -170.0376,
        -161.5487, -157.2031, -168.8157, -166.2006])
Final projection likelihood: -163.0486
1 mode projection failed, trying anyway
New goal: tensor([ 0.1842,  0.5277,  0.7376,  0.7630, -0.0117,  0.5519,  0.8161,  0.9753,
         1.3903,  0.1277,  0.1103,  1.1074,  0.0659, -0.0049,  0.6384],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 15
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
1 turn
Sampling time 3.6070015499717556
tensor([ 0.1364,  0.5747,  0.6160,  0.5808, -0.1191,  0.4981,  0.9644,  0.8939,
         1.2625,  0.2633,  0.2112,  1.2053, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:1')
Original likelihood: -109.03742218017578
Adjusted likelihood: -109.03742218017578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5199)
Solve time for step 1 14.031707027985249
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:1')
Middle force: tensor([0.5096, 0.5600, 1.3011, 1.3912, 0.5125, 0.8117, 0.7521, 0.5254, 1.0591,
        0.9974, 0.4997, 0.5720], device='cuda:1')
Thumb force: tensor([0.5346, 0.8092, 0.7389, 1.9260, 0.9194, 0.6833, 1.5082, 0.5387, 0.5606,
        0.6064, 0.6064, 0.5829], device='cuda:1')
Index force: tensor([0.9736, 0.5424, 0.8428, 0.5414, 0.5131, 0.8876, 0.5282, 0.5597, 0.5802,
        0.6710, 0.8313, 0.5590], device='cuda:1')
Storing NORMAL transition: reward=-0.0158 (scaled=-0.0158), steps=1
Reward stats updated: mean 0.0156 -> 0.0154, std: 0.0742
Collected 238 transitions for RL
SAC Update 1/5: Actor Loss=-0.0098, Q1 Loss=1.0493, Q2 Loss=1.0493, Entropy=0.6922, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9308
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.2870, Q2 Loss=1.2870, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4713
SAC Update 3/5: Actor Loss=-0.0103, Q1 Loss=1.0861, Q2 Loss=1.0861, Entropy=0.6919, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8411
SAC Update 4/5: Actor Loss=-0.0114, Q1 Loss=0.9679, Q2 Loss=0.9679, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1259
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=0.9072, Q2 Loss=0.9072, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2456

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (41.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010295
Q1 loss: 1.059493
Q2 loss: 1.059493
Current threshold: -149.5548
Global Scale Offset: 823.3900
Reward stats: mean=0.0154, std=0.0742, count=238
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.0595, Q2 Loss: 1.0595, Entropy: 0.6924, Mean TD Error: 0.7229, Threshold: -149.5548
tensor([ 0.0735,  0.6255,  0.5421,  0.4427, -0.1662,  0.4940,  0.9926,  0.7971,
         1.3606,  0.2384,  0.1472,  0.9397, -0.0202,  0.0376, -0.0166,  0.2296],
       device='cuda:1')
Original likelihood: -174.0628662109375
Adjusted likelihood: -174.0628662109375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4881)
Solve time for step 2 5.816230778989848
Current ori: tensor([-0.0202,  0.0376, -0.0166], device='cuda:1')
Middle force: tensor([0.5485, 1.5183, 0.5984, 0.5920, 0.5551, 0.5282, 0.5236, 0.5237, 0.5945,
        1.0771, 0.6159], device='cuda:1')
Thumb force: tensor([0.8203, 1.8021, 0.7129, 1.0335, 0.5816, 0.6108, 0.8471, 2.0179, 0.5834,
        0.5630, 0.5892], device='cuda:1')
Index force: tensor([0.7936, 0.5705, 0.5538, 0.6091, 0.5859, 0.6594, 0.9286, 0.6329, 0.6096,
        0.5516, 0.5778], device='cuda:1')
Storing NORMAL transition: reward=-0.0311 (scaled=-0.0311), steps=1
Reward stats updated: mean 0.0154 -> 0.0153, std: 0.0741
Collected 239 transitions for RL
SAC Update 1/5: Actor Loss=-0.0099, Q1 Loss=1.0742, Q2 Loss=1.0742, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0696
SAC Update 2/5: Actor Loss=-0.0106, Q1 Loss=5.6734, Q2 Loss=5.6734, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.6263
SAC Update 3/5: Actor Loss=-0.0115, Q1 Loss=1.8989, Q2 Loss=1.8989, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8610
SAC Update 4/5: Actor Loss=-0.0107, Q1 Loss=1.5782, Q2 Loss=1.5782, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7754
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.7854, Q2 Loss=0.7854, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5899

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.7%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (41.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010216
Q1 loss: 2.202019
Q2 loss: 2.202019
Current threshold: -149.5546
Global Scale Offset: 834.4230
Reward stats: mean=0.0153, std=0.0741, count=239
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 2.2020, Q2 Loss: 2.2020, Entropy: 0.6928, Mean TD Error: 1.9845, Threshold: -149.5546
tensor([ 0.0885,  0.6528,  0.5022,  0.4765, -0.1528,  0.5266,  0.9507,  0.8096,
         1.4142,  0.2389,  0.1701,  0.9584, -0.0248,  0.0291,  0.0149,  0.2006],
       device='cuda:1')
Original likelihood: -129.22506713867188
Adjusted likelihood: -129.22506713867188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5097)
State is out of distribution
Projection step: 0, Loss: 123.6333999633789
Projection step: 1, Loss: 124.74638366699219
Projection step: 2, Loss: 108.98463439941406
Projection step: 3, Loss: 117.49359893798828
Projection step: 4, Loss: 117.74522399902344
Projection step: 5, Loss: 118.55826568603516
Projection step: 6, Loss: 112.42061614990234
Projection step: 7, Loss: 109.74130249023438
Projection step: 8, Loss: 100.81513977050781
Final likelihood: tensor([ -81.5883, -126.6662,  -71.2298, -142.1775, -113.7892,  -74.7277,
         -96.2794,  -80.5116,  -86.1205, -125.3833, -134.9020,  -67.5633,
         -88.0691,  -80.8139, -123.8639, -119.3566])
Final projection likelihood: -100.8151
1 mode projection succeeded
New goal: tensor([ 0.0795,  0.6296,  0.4854,  0.5430, -0.1171,  0.5305,  0.9163,  0.8000,
         1.4032,  0.2423,  0.1943,  1.0781, -0.0259,  0.0252, -0.5417],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -108.58245086669922
Adjusted likelihood: -108.58245086669922
Likelihood residual: 0.0
Original likelihood: -107.87882232666016
Adjusted likelihood: -107.87882232666016
Likelihood residual: 0.0
{'index': 107.87882232666016, 'thumb_middle': 108.58245086669922}
Current yaw: tensor([-0.0248,  0.0291,  0.0149], device='cuda:1')
2 index
tensor([ 0.0885,  0.6528,  0.5022,  0.4765, -0.1528,  0.5266,  0.9507,  0.8096,
         1.4142,  0.2389,  0.1701,  0.9584, -0.0248,  0.0291,  0.0149,  0.2006],
       device='cuda:1')
Solve time for step 1 10.900084948982112
Current ori: tensor([-0.0248,  0.0291,  0.0149], device='cuda:1')
Middle force: tensor([0.5404, 0.5464, 0.5267, 0.5695], device='cuda:1')
Thumb force: tensor([0.5535, 0.6162, 0.5554, 0.5314], device='cuda:1')
tensor([ 0.1288,  0.5727,  0.4406,  0.5091, -0.1579,  0.5188,  0.9543,  0.8374,
         1.4146,  0.2325,  0.1603,  0.9937, -0.0151,  0.0291,  0.0254,  0.5714],
       device='cuda:1')
Solve time for step 2 4.167032464989461
Current ori: tensor([-0.0151,  0.0291,  0.0254], device='cuda:1')
Middle force: tensor([0.5429, 0.5243, 0.5654], device='cuda:1')
Thumb force: tensor([0.6086, 0.5527, 0.5295], device='cuda:1')
tensor([ 0.1320,  0.5744,  0.4387,  0.5202, -0.1373,  0.5365,  0.9494,  0.8305,
         1.4109,  0.2279,  0.1350,  1.0055, -0.0213,  0.0143,  0.0170,  0.8637],
       device='cuda:1')
Solve time for step 3 4.212837005034089
Current ori: tensor([-0.0213,  0.0143,  0.0170], device='cuda:1')
Middle force: tensor([0.5084, 0.5464], device='cuda:1')
Thumb force: tensor([0.5068, 0.5786], device='cuda:1')
tensor([ 0.1337,  0.5760,  0.4375,  0.5205, -0.1425,  0.5423,  0.9536,  0.8332,
         1.4042,  0.2367,  0.1338,  1.0165, -0.0193,  0.0130,  0.0244,  1.0776],
       device='cuda:1')
Solve time for step 4 4.047621048986912
Current ori: tensor([-0.0193,  0.0130,  0.0244], device='cuda:1')
Middle force: tensor([0.5491], device='cuda:1')
Thumb force: tensor([0.5347], device='cuda:1')
Storing RECOVERY transition: reward=-0.0113 (scaled=-0.0057), steps=2
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0739
Collected 240 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=1.2845, Q2 Loss=1.2845, Entropy=0.6906, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4362
SAC Update 2/5: Actor Loss=-0.0110, Q1 Loss=1.5499, Q2 Loss=1.5499, Entropy=0.6900, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3746
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.6475, Q2 Loss=0.6475, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4037
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=2.7511, Q2 Loss=2.7511, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6779
SAC Update 5/5: Actor Loss=-0.0082, Q1 Loss=0.8642, Q2 Loss=0.8642, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5157

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.8%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009432
Q1 loss: 1.419445
Q2 loss: 1.419445
Current threshold: -149.5542
Global Scale Offset: 848.4059
Reward stats: mean=0.0152, std=0.0739, count=240
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.4194, Q2 Loss: 1.4194, Entropy: 0.6917, Mean TD Error: 1.2816, Threshold: -149.5542
Original likelihood: -102.33882141113281
Adjusted likelihood: -102.33882141113281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5222)
Current yaw: tensor([-0.0231,  0.0123,  0.0269], device='cuda:1')
3 turn
Sampling time 3.7493050289922394
tensor([ 0.0780,  0.6414,  0.4836,  0.5427, -0.1430,  0.5507,  0.9497,  0.8264,
         1.4059,  0.2343,  0.1334,  1.0079, -0.0231,  0.0123,  0.0269,  1.1372],
       device='cuda:1')
Original likelihood: -101.78140258789062
Adjusted likelihood: -101.78140258789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5224)
Solve time for step 1 14.206540294049773
Current ori: tensor([-0.0231,  0.0123,  0.0269], device='cuda:1')
Middle force: tensor([0.9471, 0.6585, 0.6877, 0.4950, 0.5225, 0.8070, 1.0963, 0.7074, 0.5206,
        0.5822, 0.5571, 0.6524], device='cuda:1')
Thumb force: tensor([0.9789, 1.4258, 0.5311, 0.5448, 0.8230, 1.4121, 0.5840, 0.5133, 0.7548,
        1.2609, 0.5458, 1.1260], device='cuda:1')
Index force: tensor([0.8449, 0.7256, 0.5483, 0.6517, 0.9312, 0.5314, 0.4732, 0.5299, 0.5880,
        0.5456, 0.6095, 0.5559], device='cuda:1')
Storing NORMAL transition: reward=-0.0366 (scaled=-0.0366), steps=1
Reward stats updated: mean 0.0152 -> 0.0150, std: 0.0739
Collected 241 transitions for RL
SAC Update 1/5: Actor Loss=-0.0115, Q1 Loss=1.9122, Q2 Loss=1.9122, Entropy=0.6927, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8794
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=0.8860, Q2 Loss=0.8860, Entropy=0.6910, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6497
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.7909, Q2 Loss=1.7909, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5636
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8207, Q2 Loss=0.8207, Entropy=0.6914, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7305
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=1.0847, Q2 Loss=1.0847, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2043

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.1%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.1%)
Actor update: 0.13s (41.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009695
Q1 loss: 1.298888
Q2 loss: 1.298888
Current threshold: -149.5538
Global Scale Offset: 863.3284
Reward stats: mean=0.0150, std=0.0739, count=241
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.2989, Q2 Loss: 1.2989, Entropy: 0.6921, Mean TD Error: 1.6055, Threshold: -149.5538
tensor([ 0.0662,  0.5930,  0.5459,  0.5167, -0.0898,  0.5670,  1.0061,  0.7490,
         1.4031,  0.2113,  0.0182,  1.1358, -0.0243, -0.0273,  0.0630,  1.1796],
       device='cuda:1')
Original likelihood: -150.68472290039062
Adjusted likelihood: -150.68472290039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4995)
State is out of distribution
Projection step: 0, Loss: 149.10716247558594
Projection step: 1, Loss: 138.5714111328125
Projection step: 2, Loss: 131.62416076660156
Projection step: 3, Loss: 131.57315063476562
Projection step: 4, Loss: 128.1082763671875
Projection step: 5, Loss: 115.80724334716797
Projection step: 6, Loss: 117.79244995117188
Projection step: 7, Loss: 112.43067932128906
Projection step: 8, Loss: 103.27949523925781
Final likelihood: tensor([-108.3157,  -97.6110, -102.2907, -105.2751, -104.7046, -103.9403,
        -106.9088, -106.9554, -101.8856, -103.9682, -107.8423, -107.6004,
        -103.5427,  -83.8544, -101.2526, -106.5243])
Final projection likelihood: -103.2795
1 mode projection succeeded
New goal: tensor([ 0.0701,  0.5775,  0.5838,  0.5463, -0.0609,  0.5649,  0.9901,  0.7221,
         1.3892,  0.2051,  0.1192,  0.9974, -0.0256, -0.0241,  0.1336],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -114.46630859375
Adjusted likelihood: -114.46630859375
Likelihood residual: 0.0
Original likelihood: -156.4587860107422
Adjusted likelihood: -156.4587860107422
Likelihood residual: 0.0
{'index': 156.4587860107422, 'thumb_middle': 114.46630859375}
Current yaw: tensor([-0.0243, -0.0273,  0.0630], device='cuda:1')
4 thumb_middle
tensor([ 0.0662,  0.5930,  0.5459,  0.5167, -0.0898,  0.5670,  1.0061,  0.7490,
         1.4031,  0.2113,  0.0182,  1.1358, -0.0243, -0.0273,  0.0630,  1.1796],
       device='cuda:1')
Solve time for step 1 9.121322978986427
Current ori: tensor([-0.0243, -0.0273,  0.0630], device='cuda:1')
Index force: tensor([0.5494, 0.5773, 0.5579, 0.5037], device='cuda:1')
tensor([ 0.0654,  0.5876,  0.5499,  0.5286, -0.1539,  0.5269,  0.9519,  0.7080,
         1.3620,  0.1880,  0.0255,  0.9705, -0.0224, -0.0254,  0.0628,  1.1365],
       device='cuda:1')
Solve time for step 2 3.640348693006672
Current ori: tensor([-0.0224, -0.0254,  0.0628], device='cuda:1')
Index force: tensor([0.5829, 0.6059, 0.5983], device='cuda:1')
tensor([ 0.0710,  0.5854,  0.5600,  0.5258, -0.1569,  0.5375,  0.9567,  0.7021,
         1.3616,  0.1875,  0.0225,  0.9551, -0.0214, -0.0291,  0.0628,  1.1453],
       device='cuda:1')
Solve time for step 3 3.3394890099880286
Current ori: tensor([-0.0214, -0.0291,  0.0628], device='cuda:1')
Index force: tensor([0.6006, 0.5950], device='cuda:1')
tensor([ 0.0662,  0.5784,  0.5648,  0.5289, -0.1619,  0.5386,  0.9564,  0.7015,
         1.3638,  0.1880,  0.0240,  0.9545, -0.0199, -0.0260,  0.0628,  1.1418],
       device='cuda:1')
Solve time for step 4 3.4176692490000278
Current ori: tensor([-0.0199, -0.0260,  0.0628], device='cuda:1')
Index force: tensor([0.5807], device='cuda:1')
Storing RECOVERY transition: reward=-0.0014 (scaled=-0.0014), steps=1
Reward stats updated: mean 0.0150 -> 0.0149, std: 0.0737
Collected 242 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=0.9004, Q2 Loss=0.9004, Entropy=0.6918, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5038
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=0.9825, Q2 Loss=0.9825, Entropy=0.6894, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9514
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=2.4512, Q2 Loss=2.4512, Entropy=0.6909, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0845
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=1.0329, Q2 Loss=1.0329, Entropy=0.6912, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6458
SAC Update 5/5: Actor Loss=-0.0154, Q1 Loss=1.0807, Q2 Loss=1.0807, Entropy=0.6725, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1754

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (19.8%)
Actor update: 0.10s (38.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011063
Q1 loss: 1.289545
Q2 loss: 1.289545
Current threshold: -149.5534
Global Scale Offset: 875.4895
Reward stats: mean=0.0149, std=0.0737, count=242
----------------------------------------------
SAC Update - Actor Loss: -0.0111, Q1 Loss: 1.2895, Q2 Loss: 1.2895, Entropy: 0.6871, Mean TD Error: 1.0722, Threshold: -149.5534
Original likelihood: -138.0037078857422
Adjusted likelihood: -138.0037078857422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5053)
Current yaw: tensor([-0.0176, -0.0277,  0.0646], device='cuda:1')
5 turn
Sampling time 3.598708692996297
tensor([ 0.0677,  0.5753,  0.5672,  0.5358, -0.0951,  0.5871,  0.9977,  0.7221,
         1.4218,  0.2073,  0.0822,  0.9905, -0.0176, -0.0277,  0.0646,  1.1597],
       device='cuda:1')
Original likelihood: -132.23924255371094
Adjusted likelihood: -132.23924255371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5079)
Solve time for step 1 14.180212419014424
Current ori: tensor([-0.0176, -0.0277,  0.0646], device='cuda:1')
Middle force: tensor([1.1279, 1.8096, 0.8324, 0.6293, 0.6365, 0.6470, 0.5256, 0.5755, 0.5917,
        0.5581, 0.6286, 0.5366], device='cuda:1')
Thumb force: tensor([0.9543, 0.6142, 0.5499, 1.4386, 0.5689, 0.5087, 0.6228, 0.5230, 0.6057,
        0.5951, 0.5654, 0.6030], device='cuda:1')
Index force: tensor([1.5388, 1.6137, 0.8953, 0.5553, 0.6530, 0.5129, 0.6076, 0.5898, 0.6011,
        0.5913, 0.6795, 0.6265], device='cuda:1')
Storing NORMAL transition: reward=0.1120 (scaled=0.1120), steps=1
Reward stats updated: mean 0.0149 -> 0.0153, std: 0.0738
Collected 243 transitions for RL
SAC Update 1/5: Actor Loss=-0.0124, Q1 Loss=1.4627, Q2 Loss=1.4627, Entropy=0.6925, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1266
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.7644, Q2 Loss=0.7644, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6581
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.8519, Q2 Loss=0.8519, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5007
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.9076, Q2 Loss=0.9076, Entropy=0.6906, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6678
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=1.1460, Q2 Loss=1.1460, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3886

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009407
Q1 loss: 1.026499
Q2 loss: 1.026499
Current threshold: -149.5528
Global Scale Offset: 883.1767
Reward stats: mean=0.0153, std=0.0738, count=243
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.0265, Q2 Loss: 1.0265, Entropy: 0.6921, Mean TD Error: 0.8684, Threshold: -149.5528
tensor([ 0.0853,  0.6012,  0.6050,  0.4168, -0.1054,  0.5186,  0.9439,  0.6457,
         1.4935,  0.1326,  0.1660,  0.8529, -0.0070,  0.0140, -0.0467,  1.6793],
       device='cuda:1')
Original likelihood: -155.55300903320312
Adjusted likelihood: -155.55300903320312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4973)
State is out of distribution
Projection step: 0, Loss: 150.3066864013672
Projection step: 1, Loss: 138.22447204589844
Projection step: 2, Loss: 132.9758758544922
Projection step: 3, Loss: 122.01677703857422
Projection step: 4, Loss: 116.48455810546875
Projection step: 5, Loss: 111.82086181640625
Projection step: 6, Loss: 111.95648193359375
Projection step: 7, Loss: 100.16358184814453
Final likelihood: tensor([ -92.5750,  -99.8598, -118.3218, -111.1970,  -95.9366,  -85.7575,
         -79.9332, -113.2510, -105.9949, -111.6728, -107.2138,  -77.9075,
        -100.2267,  -97.8910, -131.9280,  -72.9505])
Final projection likelihood: -100.1636
1 mode projection succeeded
New goal: tensor([ 0.0709,  0.5980,  0.5647,  0.4839, -0.0914,  0.5434,  0.8987,  0.7107,
         1.4726,  0.1560,  0.1986,  1.0638, -0.0061,  0.0133, -0.2842],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0050]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -127.82891845703125
Adjusted likelihood: -127.82891845703125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 127.82891845703125}
Current yaw: tensor([-0.0070,  0.0140, -0.0467], device='cuda:1')
6 thumb_middle
tensor([ 0.0853,  0.6012,  0.6050,  0.4168, -0.1054,  0.5186,  0.9439,  0.6457,
         1.4935,  0.1326,  0.1660,  0.8529, -0.0070,  0.0140, -0.0467,  1.6793],
       device='cuda:1')
Solve time for step 1 9.11262547899969
Current ori: tensor([-0.0070,  0.0140, -0.0467], device='cuda:1')
Index force: tensor([0.5896, 0.5889, 0.5016, 0.6013], device='cuda:1')
tensor([ 7.9315e-02,  5.9231e-01,  5.8406e-01,  4.8520e-01, -1.7939e-01,
         5.1835e-01,  8.7784e-01,  6.8075e-01,  1.3957e+00,  1.1575e-01,
         8.6213e-02,  9.7120e-01,  4.5972e-04,  1.5303e-02, -4.6618e-02,
         1.7144e+00], device='cuda:1')
Solve time for step 2 3.588498293014709
Current ori: tensor([ 0.0005,  0.0153, -0.0466], device='cuda:1')
Index force: tensor([0.5009, 0.5811, 0.5790], device='cuda:1')
tensor([ 0.0724,  0.5992,  0.5719,  0.4761, -0.1986,  0.5236,  0.8808,  0.6934,
         1.3921,  0.1166,  0.0860,  0.9821, -0.0018,  0.0189, -0.0466,  1.7012],
       device='cuda:1')
Solve time for step 3 3.5333746949909255
Current ori: tensor([-0.0018,  0.0189, -0.0466], device='cuda:1')
Index force: tensor([0.5696, 0.5691], device='cuda:1')
tensor([ 0.0777,  0.5916,  0.5734,  0.5048, -0.1871,  0.5361,  0.8585,  0.7026,
         1.3943,  0.1118,  0.0690,  0.9983,  0.0021,  0.0167, -0.0466,  1.7165],
       device='cuda:1')
Solve time for step 4 3.4289071570383385
Current ori: tensor([ 0.0021,  0.0167, -0.0466], device='cuda:1')
Index force: tensor([0.5569], device='cuda:1')
Storing RECOVERY transition: reward=-0.0007 (scaled=-0.0007), steps=1
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0737
Collected 244 transitions for RL
SAC Update 1/5: Actor Loss=-0.0099, Q1 Loss=1.1452, Q2 Loss=1.1452, Entropy=0.6925, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1404
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.9037, Q2 Loss=0.9037, Entropy=0.6925, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8426
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.8409, Q2 Loss=0.8409, Entropy=0.6919, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2120
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=4.4067, Q2 Loss=4.4067, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5136
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=1.2893, Q2 Loss=1.2893, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6162

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.5%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009448
Q1 loss: 1.717184
Q2 loss: 1.717184
Current threshold: -149.5521
Global Scale Offset: 894.3936
Reward stats: mean=0.0152, std=0.0737, count=244
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.7172, Q2 Loss: 1.7172, Entropy: 0.6924, Mean TD Error: 1.4649, Threshold: -149.5521
Original likelihood: -130.50103759765625
Adjusted likelihood: -130.50103759765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5085)
Current yaw: tensor([ 0.0003,  0.0252, -0.0465], device='cuda:1')
7 turn
Sampling time 3.600178731023334
tensor([ 5.8766e-02,  5.9557e-01,  5.6030e-01,  4.8406e-01, -1.2854e-01,
         5.7221e-01,  8.9677e-01,  7.1060e-01,  1.4621e+00,  1.3803e-01,
         1.2225e-01,  1.0340e+00,  3.1053e-04,  2.5196e-02, -4.6461e-02,
         1.6956e+00], device='cuda:1')
Original likelihood: -124.76134490966797
Adjusted likelihood: -124.76134490966797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5110)
Solve time for step 1 14.17755483899964
Current ori: tensor([ 0.0003,  0.0252, -0.0465], device='cuda:1')
Middle force: tensor([1.1826, 0.4918, 0.5428, 0.5421, 1.4133, 0.5256, 0.5650, 0.5201, 0.5216,
        0.5306, 0.6142, 0.5317], device='cuda:1')
Thumb force: tensor([1.2705, 0.5439, 0.5883, 1.7779, 0.8458, 0.5444, 0.5298, 0.9068, 0.5090,
        1.5078, 0.5606, 0.6150], device='cuda:1')
Index force: tensor([0.5874, 0.5437, 0.5853, 0.5032, 0.5739, 0.6771, 0.6057, 0.5306, 0.6487,
        0.6982, 0.5685, 0.6363], device='cuda:1')
Storing NORMAL transition: reward=-0.0182 (scaled=-0.0182), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0736
Collected 245 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.8570, Q2 Loss=0.8570, Entropy=0.6911, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1723
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=1.0313, Q2 Loss=1.0313, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4496
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.3939, Q2 Loss=1.3939, Entropy=0.6922, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8195
SAC Update 4/5: Actor Loss=-0.0096, Q1 Loss=0.9412, Q2 Loss=0.9412, Entropy=0.6909, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2240
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8814, Q2 Loss=0.8814, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8998

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008502
Q1 loss: 1.020957
Q2 loss: 1.020957
Current threshold: -149.5515
Global Scale Offset: 905.3297
Reward stats: mean=0.0151, std=0.0736, count=245
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 1.0210, Q2 Loss: 1.0210, Entropy: 0.6918, Mean TD Error: 1.5130, Threshold: -149.5515
tensor([ 0.1025,  0.5672,  0.6281,  0.5107, -0.0657,  0.6142,  0.8922,  0.7414,
         1.4952,  0.2378,  0.0215,  0.9813,  0.0124, -0.0233, -0.0283,  2.0992],
       device='cuda:1')
Original likelihood: -153.5649871826172
Adjusted likelihood: -153.5649871826172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4982)
Solve time for step 2 5.506591210025363
Current ori: tensor([ 0.0124, -0.0233, -0.0283], device='cuda:1')
Middle force: tensor([0.5051, 0.5586, 0.5339, 1.3931, 0.5314, 0.5763, 0.5276, 0.5220, 0.5370,
        0.6123, 0.5469], device='cuda:1')
Thumb force: tensor([0.5375, 0.5689, 1.7789, 0.8206, 0.5332, 0.5239, 0.8679, 0.5074, 1.4743,
        0.5576, 0.5882], device='cuda:1')
Index force: tensor([0.5391, 0.5708, 0.5025, 0.5725, 0.6609, 0.5961, 0.5237, 0.6397, 0.6678,
        0.5649, 0.6156], device='cuda:1')
Storing NORMAL transition: reward=-0.0385 (scaled=-0.0385), steps=1
Reward stats updated: mean 0.0151 -> 0.0149, std: 0.0735
Collected 246 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=1.3705, Q2 Loss=1.3705, Entropy=0.6922, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6444
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=2.5510, Q2 Loss=2.5510, Entropy=0.6916, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6929
SAC Update 3/5: Actor Loss=-0.0095, Q1 Loss=1.7906, Q2 Loss=1.7906, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2374
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.7348, Q2 Loss=0.7348, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4885
SAC Update 5/5: Actor Loss=-0.0066, Q1 Loss=0.6241, Q2 Loss=0.6241, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2371

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.2%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.0%)
Actor update: 0.08s (39.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.007991
Q1 loss: 1.414198
Q2 loss: 1.414198
Current threshold: -149.5509
Global Scale Offset: 916.9316
Reward stats: mean=0.0149, std=0.0735, count=246
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 1.4142, Q2 Loss: 1.4142, Entropy: 0.6921, Mean TD Error: 1.8601, Threshold: -149.5509
tensor([ 0.1199,  0.5288,  0.6048,  0.6278, -0.0859,  0.6807,  0.8986,  0.7689,
         1.3919,  0.4133,  0.0507,  1.0767,  0.0415, -0.0438,  0.0077, -4.7997],
       device='cuda:1')
Original likelihood: -189.0589599609375
Adjusted likelihood: -189.0589599609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4828)
Solve time for step 3 5.085883757041302
Current ori: tensor([ 0.0415, -0.0438,  0.0077], device='cuda:1')
Middle force: tensor([0.5651, 0.5329, 1.3825, 0.5435, 0.5918, 0.5363, 0.5291, 0.5533, 0.6160,
        0.5745], device='cuda:1')
Thumb force: tensor([0.5600, 1.7420, 0.8035, 0.5236, 0.5189, 0.8409, 0.5054, 1.4299, 0.5522,
        0.5690], device='cuda:1')
Index force: tensor([0.5610, 0.5022, 0.5668, 0.6392, 0.5851, 0.5177, 0.6259, 0.6306, 0.5606,
        0.5850], device='cuda:1')
Storing NORMAL transition: reward=-0.0146 (scaled=-0.0146), steps=1
Reward stats updated: mean 0.0149 -> 0.0147, std: 0.0734
Collected 247 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.9437, Q2 Loss=0.9437, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8947
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=0.9130, Q2 Loss=0.9130, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1060
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=1.0950, Q2 Loss=1.0950, Entropy=0.6911, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5283
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=1.7521, Q2 Loss=1.7521, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4357
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=1.7085, Q2 Loss=1.7085, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2004

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.9%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (40.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008303
Q1 loss: 1.282459
Q2 loss: 1.282459
Current threshold: -149.5506
Global Scale Offset: 929.2595
Reward stats: mean=0.0147, std=0.0734, count=247
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.2825, Q2 Loss: 1.2825, Entropy: 0.6922, Mean TD Error: 2.0330, Threshold: -149.5506
tensor([-2.0038e-03,  4.2808e-01,  4.9091e-01,  6.3116e-01, -1.7161e-01,
         7.3111e-01,  1.0504e+00,  7.1039e-01,  1.3225e+00,  4.0163e-01,
         1.8662e-01,  9.8832e-01,  1.1094e-01, -1.0008e-01,  6.4606e-03,
         3.5452e+00], device='cuda:1')
Original likelihood: -379.8885192871094
Adjusted likelihood: -379.8885192871094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4023)
State is out of distribution
Projection step: 0, Loss: 368.6297607421875
Projection step: 1, Loss: 352.77838134765625
Projection step: 2, Loss: 355.62469482421875
Projection step: 3, Loss: 346.65924072265625
Projection step: 4, Loss: 331.9534912109375
Projection step: 5, Loss: 345.1251220703125
Projection step: 6, Loss: 321.55999755859375
Projection step: 7, Loss: 322.25140380859375
Projection step: 8, Loss: 302.6647644042969
Projection step: 9, Loss: 313.6376953125
Projection step: 10, Loss: 315.2377624511719
Projection step: 11, Loss: 285.4365539550781
Projection step: 12, Loss: 286.2266540527344
Projection step: 13, Loss: 285.25067138671875
Projection step: 14, Loss: 273.3193359375
Projection step: 15, Loss: 299.64288330078125
Projection step: 16, Loss: 266.6551513671875
Projection step: 17, Loss: 262.1065673828125
Projection step: 18, Loss: 274.51129150390625
Projection step: 19, Loss: 260.02508544921875
Projection step: 20, Loss: 269.5953369140625
Projection step: 21, Loss: 262.196533203125
Projection step: 22, Loss: 256.0504150390625
Projection step: 23, Loss: 278.00262451171875
Projection step: 24, Loss: 256.789306640625
Final likelihood: tensor([-296.8385, -191.7282, -271.3752, -167.6433, -179.9317, -211.0553,
        -254.7359, -168.7712, -285.3824, -285.9318, -263.0329, -267.9880,
        -253.0572, -204.3151, -278.7703, -263.8121])
Final projection likelihood: -240.2731
1 mode projection failed, trying anyway
New goal: tensor([ 0.0218,  0.4637,  0.5918,  0.8086, -0.0644,  0.6502,  0.9128,  0.7279,
         1.3014,  0.2270,  0.1346,  1.0631,  0.1087, -0.0920, -0.6086],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0086]], device='cuda:1') tensor([[0.0177]], device='cuda:1')
Original likelihood: -257.9349060058594
Adjusted likelihood: -257.9349060058594
Likelihood residual: 0.0
Original likelihood: -294.1268310546875
Adjusted likelihood: -294.1268310546875
Likelihood residual: 0.0
{'index': 294.1268310546875, 'thumb_middle': 257.9349060058594}
Current yaw: tensor([ 0.1109, -0.1001,  0.0065], device='cuda:1')
8 thumb_middle
tensor([-2.0038e-03,  4.2808e-01,  4.9091e-01,  6.3116e-01, -1.7161e-01,
         7.3111e-01,  1.0504e+00,  7.1039e-01,  1.3225e+00,  4.0163e-01,
         1.8662e-01,  9.8832e-01,  1.1094e-01, -1.0008e-01,  6.4606e-03,
         3.5452e+00], device='cuda:1')
Solve time for step 1 8.907677345967386
Current ori: tensor([ 0.1109, -0.1001,  0.0065], device='cuda:1')
Index force: tensor([0.6006, 0.5408, 0.5913, 0.5807], device='cuda:1')
tensor([-0.0916,  0.5053,  0.5785,  0.7612, -0.1400,  0.6559,  0.9136,  0.7111,
         1.3044,  0.2553,  0.0952,  1.0272,  0.2772, -0.2499,  0.0065,  1.4655],
       device='cuda:1')
Solve time for step 2 3.6482551639783196
Current ori: tensor([ 0.2772, -0.2499,  0.0065], device='cuda:1')
Index force: tensor([0.5379, 0.5789, 0.5736], device='cuda:1')
tensor([ 0.0594,  0.6454,  0.9031,  0.9888, -0.0501,  0.7226,  0.9707,  0.7476,
         1.2935,  0.2365,  0.0613,  1.0294,  0.3742, -0.3351, -0.0070,  0.5942],
       device='cuda:1')
Solve time for step 3 3.4330838290043175
Current ori: tensor([ 0.3742, -0.3351, -0.0070], device='cuda:1')
Index force: tensor([0.5823, 0.5626], device='cuda:1')
tensor([ 0.0798,  0.8675,  1.1466,  1.1095,  0.0591,  0.7806,  1.0218,  0.7671,
         1.1824,  0.2542,  0.0578,  1.0937,  0.3889, -0.3727,  0.1615, -1.6208],
       device='cuda:1')
Solve time for step 4 3.328179321018979
Current ori: tensor([ 0.3889, -0.3727,  0.1615], device='cuda:1')
Index force: tensor([0.5548], device='cuda:1')
Storing RECOVERY transition: reward=-0.2715 (scaled=-0.0905), steps=3
Reward stats updated: mean 0.0147 -> 0.0143, std: 0.0735
Collected 248 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=1.0967, Q2 Loss=1.0967, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9060
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=0.9116, Q2 Loss=0.9116, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4528
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.5920, Q2 Loss=1.5920, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2607
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.9202, Q2 Loss=0.9202, Entropy=0.6925, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7646
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=1.0054, Q2 Loss=1.0054, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9818

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.0%)
Actor update: 0.12s (42.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009675
Q1 loss: 1.105172
Q2 loss: 1.105172
Current threshold: -149.5502
Global Scale Offset: 942.9717
Reward stats: mean=0.0143, std=0.0735, count=248
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.1052, Q2 Loss: 1.1052, Entropy: 0.6925, Mean TD Error: 1.0732, Threshold: -149.5502
Original likelihood: -1244.0107421875
Adjusted likelihood: -1244.0107421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1233)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 16
Loaded trajectory sampler
Current yaw: tensor([-0.0018,  0.0148, -0.0223], device='cuda:1')
Current yaw: tensor([-0.0018,  0.0148, -0.0223], device='cuda:1')
1 turn
Sampling time 3.6170095670386218
tensor([ 0.1340,  0.5819,  0.6073,  0.5741, -0.1254,  0.5570,  0.8779,  0.9167,
         1.2124,  0.2837,  0.2625,  1.2181, -0.0018,  0.0148, -0.0223,  0.3724],
       device='cuda:1')
Original likelihood: -119.54031372070312
Adjusted likelihood: -119.54031372070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5127)
Solve time for step 1 13.980651251971722
Current ori: tensor([-0.0018,  0.0148, -0.0223], device='cuda:1')
Middle force: tensor([0.5032, 0.6085, 0.4860, 0.7256, 2.0172, 0.5478, 0.6624, 0.5031, 0.7789,
        1.1605, 0.4968, 0.5591], device='cuda:1')
Thumb force: tensor([0.6499, 0.9341, 0.5173, 0.5387, 1.8093, 0.5189, 0.7322, 0.5894, 0.5271,
        1.0965, 0.6973, 0.6146], device='cuda:1')
Index force: tensor([0.6677, 0.6850, 0.7777, 0.5059, 0.5565, 0.5752, 0.5964, 0.5820, 0.4964,
        0.5387, 0.6338, 0.5624], device='cuda:1')
Storing NORMAL transition: reward=-0.0223 (scaled=-0.0223), steps=1
Reward stats updated: mean 0.0143 -> 0.0142, std: 0.0734
Collected 249 transitions for RL
SAC Update 1/5: Actor Loss=-0.0121, Q1 Loss=4.2752, Q2 Loss=4.2752, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5852
SAC Update 2/5: Actor Loss=-0.0070, Q1 Loss=0.7425, Q2 Loss=0.7425, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4680
SAC Update 3/5: Actor Loss=-0.0127, Q1 Loss=1.5412, Q2 Loss=1.5412, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2070
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=1.0969, Q2 Loss=1.0969, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3542
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=1.0275, Q2 Loss=1.0275, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7310

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.2%)
Actor update: 0.08s (39.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010222
Q1 loss: 1.736642
Q2 loss: 1.736642
Current threshold: -149.5495
Global Scale Offset: 957.4900
Reward stats: mean=0.0142, std=0.0734, count=249
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.7366, Q2 Loss: 1.7366, Entropy: 0.6924, Mean TD Error: 1.4691, Threshold: -149.5495
tensor([ 1.2993e-01,  6.3055e-01,  5.0607e-01,  6.3445e-01, -1.0043e-01,
         5.9756e-01,  7.5022e-01,  9.6089e-01,  1.3961e+00,  3.0573e-02,
         1.3561e-01,  1.3638e+00, -7.6866e-03,  1.0630e-02,  1.1254e-04,
         4.9038e-01], device='cuda:1')
Original likelihood: -142.66909790039062
Adjusted likelihood: -142.66909790039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5029)
State is out of distribution
Projection step: 0, Loss: 148.20602416992188
Projection step: 1, Loss: 139.88906860351562
Projection step: 2, Loss: 127.07780456542969
Projection step: 3, Loss: 130.401123046875
Projection step: 4, Loss: 120.67598724365234
Projection step: 5, Loss: 113.7269515991211
Projection step: 6, Loss: 109.9838638305664
Projection step: 7, Loss: 109.028564453125
Projection step: 8, Loss: 96.7515869140625
Final likelihood: tensor([ -94.3444, -111.3703,  -89.8199, -107.2380,  -91.6288,  -85.6131,
         -84.6967,  -83.0942,  -84.5975,  -91.8604,  -87.0371,  -96.3699,
        -100.7187, -119.6203, -132.5230,  -87.4931])
Final projection likelihood: -96.7516
1 mode projection succeeded
New goal: tensor([ 0.0987,  0.6116,  0.5170,  0.5813, -0.0929,  0.5910,  0.8092,  0.8841,
         1.3855,  0.0984,  0.1425,  1.2426, -0.0054,  0.0126, -0.6788],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -125.21139526367188
Adjusted likelihood: -125.21139526367188
Likelihood residual: 0.0
Original likelihood: -139.49356079101562
Adjusted likelihood: -139.49356079101562
Likelihood residual: 0.0
{'index': 139.49356079101562, 'thumb_middle': 125.21139526367188}
Current yaw: tensor([-0.0077,  0.0106,  0.0001], device='cuda:1')
2 thumb_middle
tensor([ 1.2993e-01,  6.3055e-01,  5.0607e-01,  6.3445e-01, -1.0043e-01,
         5.9756e-01,  7.5022e-01,  9.6089e-01,  1.3961e+00,  3.0573e-02,
         1.3561e-01,  1.3638e+00, -7.6866e-03,  1.0630e-02,  1.1254e-04,
         4.9038e-01], device='cuda:1')
Solve time for step 1 9.056027409969829
Current ori: tensor([-0.0077,  0.0106,  0.0001], device='cuda:1')
Index force: tensor([0.5589, 0.5704, 0.5703, 0.5780], device='cuda:1')
tensor([ 1.1228e-01,  6.1958e-01,  5.2360e-01,  5.9283e-01, -1.9592e-01,
         5.6551e-01,  7.4860e-01,  8.7160e-01,  1.3365e+00,  5.0439e-02,
         7.5279e-02,  1.2332e+00, -9.0011e-03,  2.1525e-02,  1.8107e-05,
         4.4336e-01], device='cuda:1')
Solve time for step 2 3.7248353239847347
Current ori: tensor([-9.0011e-03,  2.1525e-02,  1.8107e-05], device='cuda:1')
Index force: tensor([0.5531, 0.5498, 0.5445], device='cuda:1')
tensor([ 1.0370e-01,  6.2562e-01,  5.1698e-01,  5.7240e-01, -1.9931e-01,
         5.6186e-01,  7.5179e-01,  8.4285e-01,  1.3446e+00,  5.1527e-02,
         6.6273e-02,  1.2321e+00, -1.1772e-02,  2.5985e-02,  1.8092e-05,
         4.2502e-01], device='cuda:1')
Solve time for step 3 3.597736482974142
Current ori: tensor([-1.1772e-02,  2.5985e-02,  1.8092e-05], device='cuda:1')
Index force: tensor([0.5415, 0.5376], device='cuda:1')
tensor([ 1.1186e-01,  6.3732e-01,  5.1114e-01,  5.6851e-01, -2.0893e-01,
         5.6874e-01,  7.6837e-01,  8.5211e-01,  1.3436e+00,  6.1632e-02,
         5.8615e-02,  1.2098e+00, -1.4668e-02,  2.0733e-02,  1.8095e-05,
         4.3299e-01], device='cuda:1')
Solve time for step 4 3.4508263090392575
Current ori: tensor([-1.4668e-02,  2.0733e-02,  1.8095e-05], device='cuda:1')
Index force: tensor([0.5263], device='cuda:1')
Storing RECOVERY transition: reward=0.0047 (scaled=0.0047), steps=1
Reward stats updated: mean 0.0142 -> 0.0141, std: 0.0733
Collected 250 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=2.4679, Q2 Loss=2.4679, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6918
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=2.4606, Q2 Loss=2.4606, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6789
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.9114, Q2 Loss=0.9114, Entropy=0.6916, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6178
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=1.1826, Q2 Loss=1.1826, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3946
SAC Update 5/5: Actor Loss=-0.0123, Q1 Loss=1.2557, Q2 Loss=1.2557, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9838

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.5%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009242
Q1 loss: 1.655616
Q2 loss: 1.655616
Current threshold: -149.5488
Global Scale Offset: 971.6817
Reward stats: mean=0.0141, std=0.0733, count=250
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.6556, Q2 Loss: 1.6556, Entropy: 0.6924, Mean TD Error: 2.0734, Threshold: -149.5488
Original likelihood: -133.07461547851562
Adjusted likelihood: -133.07461547851562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5068)
State is out of distribution
Projection step: 0, Loss: 135.10943603515625
Projection step: 1, Loss: 125.66893768310547
Projection step: 2, Loss: 133.956787109375
Projection step: 3, Loss: 131.67715454101562
Projection step: 4, Loss: 121.61682891845703
Projection step: 5, Loss: 115.64794921875
Projection step: 6, Loss: 125.92227172851562
Projection step: 7, Loss: 111.28614044189453
Projection step: 8, Loss: 113.77267456054688
Projection step: 9, Loss: 110.54078674316406
Projection step: 10, Loss: 108.16293334960938
Projection step: 11, Loss: 108.89800262451172
Projection step: 12, Loss: 100.24994659423828
Final likelihood: tensor([ -91.5948,  -97.7670,  -84.6339,  -96.4972, -102.3710,  -99.6748,
         -85.2237, -103.4741,  -78.9447, -110.8456, -110.2696, -107.6838,
         -95.7984, -133.3176,  -97.6218, -108.2811])
Final projection likelihood: -100.2499
1 mode projection succeeded
New goal: tensor([ 0.0864,  0.5902,  0.5436,  0.5554, -0.1035,  0.6070,  0.8168,  0.8071,
         1.3893,  0.1565,  0.1510,  1.2026, -0.0089,  0.0188, -1.0716],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -119.75543212890625
Adjusted likelihood: -119.75543212890625
Likelihood residual: 0.0
Original likelihood: -123.79407501220703
Adjusted likelihood: -123.79407501220703
Likelihood residual: 0.0
{'index': 123.79407501220703, 'thumb_middle': 119.75543212890625}
Current yaw: tensor([-0.0092,  0.0236, -0.0050], device='cuda:1')
3 thumb_middle
tensor([ 0.1071,  0.6202,  0.5229,  0.5824, -0.1449,  0.6011,  0.8087,  0.8889,
         1.4155,  0.0977,  0.1021,  1.2506, -0.0092,  0.0236, -0.0050,  0.4432],
       device='cuda:1')
Solve time for step 1 9.127600492967758
Current ori: tensor([-0.0092,  0.0236, -0.0050], device='cuda:1')
Index force: tensor([0.5672, 0.5606, 0.5725, 0.5564], device='cuda:1')
tensor([ 0.1015,  0.6038,  0.5544,  0.5540, -0.2134,  0.5849,  0.7844,  0.7957,
         1.3427,  0.1107,  0.0605,  1.1896, -0.0084,  0.0277, -0.0050,  0.4267],
       device='cuda:1')
Solve time for step 2 3.5431318289483897
Current ori: tensor([-0.0084,  0.0277, -0.0050], device='cuda:1')
Index force: tensor([0.5513, 0.5635, 0.5484], device='cuda:1')
tensor([ 0.1047,  0.6088,  0.5495,  0.5565, -0.2094,  0.5788,  0.7855,  0.7980,
         1.3405,  0.1169,  0.0550,  1.1830, -0.0094,  0.0257, -0.0050,  0.4307],
       device='cuda:1')
Solve time for step 3 3.4065301039954647
Current ori: tensor([-0.0094,  0.0257, -0.0050], device='cuda:1')
Index force: tensor([0.5528, 0.5401], device='cuda:1')
tensor([ 0.0844,  0.5996,  0.5427,  0.5548, -0.2095,  0.5766,  0.7706,  0.7858,
         1.3460,  0.1372,  0.0694,  1.1598, -0.0071,  0.0377, -0.0050,  0.3968],
       device='cuda:1')
Solve time for step 4 3.2922055879607797
Current ori: tensor([-0.0071,  0.0377, -0.0050], device='cuda:1')
Index force: tensor([0.5281], device='cuda:1')
Storing RECOVERY transition: reward=-0.0008 (scaled=-0.0008), steps=1
Reward stats updated: mean 0.0141 -> 0.0141, std: 0.0731
Collected 251 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=0.8108, Q2 Loss=0.8108, Entropy=0.6919, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2915
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=4.3472, Q2 Loss=4.3472, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7813
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=0.8650, Q2 Loss=0.8650, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8886
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.7849, Q2 Loss=0.7849, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6620
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=3.3694, Q2 Loss=3.3694, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4656

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (38.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009285
Q1 loss: 2.035461
Q2 loss: 2.035461
Current threshold: -149.5481
Global Scale Offset: 985.4925
Reward stats: mean=0.0141, std=0.0731, count=251
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 2.0355, Q2 Loss: 2.0355, Entropy: 0.6920, Mean TD Error: 1.8178, Threshold: -149.5481
Original likelihood: -162.91787719726562
Adjusted likelihood: -162.91787719726562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4946)
Current yaw: tensor([-0.0039,  0.0427, -0.0006], device='cuda:1')
4 turn
Sampling time 3.596914210997056
tensor([ 7.4901e-02,  5.9258e-01,  5.3537e-01,  5.7015e-01, -1.7324e-01,
         6.1910e-01,  8.1435e-01,  7.8629e-01,  1.4273e+00,  1.4732e-01,
         1.2151e-01,  1.1902e+00, -3.9106e-03,  4.2683e-02, -5.7689e-04,
         4.0405e-01], device='cuda:1')
Original likelihood: -170.16819763183594
Adjusted likelihood: -170.16819763183594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4917)
State is out of distribution
Projection step: 0, Loss: 164.42251586914062
Projection step: 1, Loss: 153.73495483398438
Projection step: 2, Loss: 161.42178344726562
Projection step: 3, Loss: 141.86936950683594
Projection step: 4, Loss: 140.90115356445312
Projection step: 5, Loss: 154.27740478515625
Projection step: 6, Loss: 134.27047729492188
Projection step: 7, Loss: 131.537109375
Projection step: 8, Loss: 123.31805419921875
Projection step: 9, Loss: 132.4506072998047
Projection step: 10, Loss: 123.5722427368164
Projection step: 11, Loss: 126.27073669433594
Projection step: 12, Loss: 116.01634216308594
Projection step: 13, Loss: 114.82376098632812
Projection step: 14, Loss: 109.43353271484375
Projection step: 15, Loss: 108.41165161132812
Projection step: 16, Loss: 102.06724548339844
Final likelihood: tensor([ -98.1622,  -99.2829,  -95.9220, -101.4501, -102.7193,  -94.9312,
         -96.0046,  -95.6854, -103.5387, -117.1783, -108.4307, -100.7918,
        -103.8182,  -98.0153, -108.3414, -108.8038])
Final projection likelihood: -102.0672
1 mode projection succeeded
New goal: tensor([ 0.0739,  0.5640,  0.5731,  0.5597, -0.1219,  0.6104,  0.8082,  0.7721,
         1.3556,  0.1744,  0.1673,  1.2343, -0.0104,  0.0292, -0.9464],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -137.51486206054688
Adjusted likelihood: -137.51486206054688
Likelihood residual: 0.0
Original likelihood: -136.07058715820312
Adjusted likelihood: -136.07058715820312
Likelihood residual: 0.0
{'index': 136.07058715820312, 'thumb_middle': 137.51486206054688}
Current yaw: tensor([-0.0039,  0.0427, -0.0006], device='cuda:1')
5 index
tensor([ 7.4901e-02,  5.9258e-01,  5.3537e-01,  5.7015e-01, -1.7324e-01,
         6.1910e-01,  8.1435e-01,  7.8629e-01,  1.4273e+00,  1.4732e-01,
         1.2151e-01,  1.1902e+00, -3.9106e-03,  4.2683e-02, -5.7689e-04,
         4.0405e-01], device='cuda:1')
Solve time for step 1 10.517557799990755
Current ori: tensor([-0.0039,  0.0427, -0.0006], device='cuda:1')
Middle force: tensor([0.6002, 0.5206, 0.5780, 0.6041], device='cuda:1')
Thumb force: tensor([0.5157, 0.5825, 0.5189, 0.5731], device='cuda:1')
tensor([ 0.1222,  0.5133,  0.5176,  0.5369, -0.1595,  0.6265,  0.8175,  0.7809,
         1.4073,  0.1763,  0.1192,  1.1775, -0.0099,  0.0324, -0.0280,  1.5797],
       device='cuda:1')
Solve time for step 2 4.157638933043927
Current ori: tensor([-0.0099,  0.0324, -0.0280], device='cuda:1')
Middle force: tensor([0.5198, 0.5758, 0.6008], device='cuda:1')
Thumb force: tensor([0.5765, 0.5179, 0.5707], device='cuda:1')
tensor([ 0.1217,  0.5100,  0.5221,  0.5353, -0.1666,  0.6134,  0.8298,  0.7958,
         1.4059,  0.1876,  0.1116,  1.2019, -0.0059,  0.0352, -0.0434,  2.1685],
       device='cuda:1')
Solve time for step 3 4.2521450180211104
Current ori: tensor([-0.0059,  0.0352, -0.0434], device='cuda:1')
Middle force: tensor([0.5001, 0.5409], device='cuda:1')
Thumb force: tensor([0.5398, 0.6005], device='cuda:1')
tensor([ 0.1217,  0.5099,  0.5195,  0.5419, -0.1615,  0.6188,  0.8294,  0.7848,
         1.3963,  0.2018,  0.1056,  1.2150, -0.0079,  0.0321, -0.0353,  2.3268],
       device='cuda:1')
Solve time for step 4 3.926363819045946
Current ori: tensor([-0.0079,  0.0321, -0.0353], device='cuda:1')
Middle force: tensor([0.5144], device='cuda:1')
Thumb force: tensor([0.5181], device='cuda:1')
Storing RECOVERY transition: reward=0.0105 (scaled=0.0105), steps=0
Reward stats updated: mean 0.0141 -> 0.0141, std: 0.0730
Collected 252 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.7706, Q2 Loss=0.7706, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4128
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=1.0513, Q2 Loss=1.0513, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8525
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=1.0906, Q2 Loss=1.0906, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6703
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=1.4232, Q2 Loss=1.4232, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0476
SAC Update 5/5: Actor Loss=-0.0115, Q1 Loss=1.2214, Q2 Loss=1.2214, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9613

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008977
Q1 loss: 1.111423
Q2 loss: 1.111423
Current threshold: -149.5475
Global Scale Offset: 999.3023
Reward stats: mean=0.0141, std=0.0730, count=252
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.1114, Q2 Loss: 1.1114, Entropy: 0.6928, Mean TD Error: 1.3889, Threshold: -149.5475
Original likelihood: -145.80908203125
Adjusted likelihood: -145.80908203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5015)
Current yaw: tensor([-0.0121,  0.0297, -0.0103], device='cuda:1')
6 turn
Sampling time 3.6174626650172286
tensor([ 0.0701,  0.5727,  0.5649,  0.5598, -0.1562,  0.6341,  0.8165,  0.7684,
         1.3921,  0.2046,  0.1015,  1.2183, -0.0121,  0.0297, -0.0103,  2.2990],
       device='cuda:1')
Original likelihood: -158.0364990234375
Adjusted likelihood: -158.0364990234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4966)
Solve time for step 1 14.000464505981654
Current ori: tensor([-0.0121,  0.0297, -0.0103], device='cuda:1')
Middle force: tensor([0.5329, 0.7140, 0.5634, 0.5031, 0.7379, 1.0143, 0.5801, 0.5516, 0.5753,
        0.5638, 0.6004, 0.5911], device='cuda:1')
Thumb force: tensor([0.8336, 0.6389, 1.5774, 2.3243, 0.8397, 1.7033, 0.5726, 0.7457, 0.5588,
        1.5210, 0.5293, 0.5434], device='cuda:1')
Index force: tensor([0.5432, 0.8732, 0.5943, 0.5868, 0.5912, 0.5859, 0.5707, 0.5159, 0.5001,
        0.7939, 0.7236, 0.6081], device='cuda:1')
Storing NORMAL transition: reward=0.0027 (scaled=0.0027), steps=1
Reward stats updated: mean 0.0141 -> 0.0140, std: 0.0728
Collected 253 transitions for RL
SAC Update 1/5: Actor Loss=-0.0099, Q1 Loss=2.8110, Q2 Loss=2.8110, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2714
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=1.0155, Q2 Loss=1.0155, Entropy=0.6903, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7284
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=4.5523, Q2 Loss=4.5523, Entropy=0.6842, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1089
SAC Update 4/5: Actor Loss=-0.0112, Q1 Loss=1.3627, Q2 Loss=1.3627, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3020
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.6444, Q2 Loss=0.6444, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0804

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (41.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009985
Q1 loss: 2.077166
Q2 loss: 2.077166
Current threshold: -149.5470
Global Scale Offset: 1012.6021
Reward stats: mean=0.0140, std=0.0728, count=253
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 2.0772, Q2 Loss: 2.0772, Entropy: 0.6906, Mean TD Error: 1.6982, Threshold: -149.5470
tensor([ 0.2802,  0.6105,  0.6509,  0.5723, -0.2429,  0.6883,  0.7571,  0.7608,
         1.4509,  0.3299,  0.0075,  1.2530, -0.0222,  0.0738, -0.0177, -0.3779],
       device='cuda:1')
Original likelihood: -271.42498779296875
Adjusted likelihood: -271.42498779296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4522)
State is out of distribution
Projection step: 0, Loss: 271.197021484375
Projection step: 1, Loss: 272.296875
Projection step: 2, Loss: 257.0682678222656
Projection step: 3, Loss: 266.65911865234375
Projection step: 4, Loss: 248.42694091796875
Projection step: 5, Loss: 245.31301879882812
Projection step: 6, Loss: 238.39178466796875
Projection step: 7, Loss: 231.87586975097656
Projection step: 8, Loss: 235.1431121826172
Projection step: 9, Loss: 225.48837280273438
Projection step: 10, Loss: 213.2098388671875
Projection step: 11, Loss: 205.69384765625
Projection step: 12, Loss: 216.18826293945312
Projection step: 13, Loss: 212.75216674804688
Projection step: 14, Loss: 202.43350219726562
Projection step: 15, Loss: 210.5142364501953
Projection step: 16, Loss: 208.441162109375
Projection step: 17, Loss: 200.63229370117188
Projection step: 18, Loss: 199.6533203125
Projection step: 19, Loss: 202.83102416992188
Projection step: 20, Loss: 187.79434204101562
Projection step: 21, Loss: 195.414794921875
Projection step: 22, Loss: 194.79624938964844
Projection step: 23, Loss: 192.08944702148438
Projection step: 24, Loss: 180.3743896484375
Final likelihood: tensor([-176.5985, -178.8833, -182.1799, -172.0149, -183.3469, -197.4037,
        -172.7842, -165.5233, -178.8111, -177.3943, -179.6257, -186.4489,
        -171.5044, -180.0485, -181.4265, -184.0186])
Final projection likelihood: -179.2508
1 mode projection failed, trying anyway
New goal: tensor([ 0.1887,  0.5482,  0.6057,  0.5863, -0.1832,  0.7191,  0.8023,  0.8214,
         1.4582,  0.2929,  0.0922,  1.2644, -0.0324,  0.0544,  2.3505],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0091]], device='cuda:1')
Original likelihood: -203.78265380859375
Adjusted likelihood: -203.78265380859375
Likelihood residual: 0.0
{'index': 203.78265380859375, 'thumb_middle': inf}
Current yaw: tensor([-0.0222,  0.0738, -0.0177], device='cuda:1')
7 index
tensor([ 0.2802,  0.6105,  0.6509,  0.5723, -0.2429,  0.6883,  0.7571,  0.7608,
         1.4509,  0.3299,  0.0075,  1.2530, -0.0222,  0.0738, -0.0177, -0.3779],
       device='cuda:1')
Solve time for step 1 10.33950357901631
Current ori: tensor([-0.0222,  0.0738, -0.0177], device='cuda:1')
Middle force: tensor([0.5300, 0.5036, 0.5744, 0.5494], device='cuda:1')
Thumb force: tensor([0.5472, 0.6507, 0.5223, 0.6407], device='cuda:1')
tensor([ 0.2309,  0.5283,  0.5874,  0.5690, -0.2448,  0.6850,  0.7525,  0.7844,
         1.4632,  0.3113,  0.0049,  1.2370, -0.0226,  0.0741, -0.0509, -1.7188],
       device='cuda:1')
Solve time for step 2 4.2478837089729495
Current ori: tensor([-0.0226,  0.0741, -0.0509], device='cuda:1')
Middle force: tensor([0.5030, 0.5706, 0.5461], device='cuda:1')
Thumb force: tensor([0.6432, 0.5204, 0.6350], device='cuda:1')
tensor([ 0.2165,  0.5222,  0.5792,  0.5702, -0.2380,  0.6838,  0.7558,  0.7950,
         1.4601,  0.3104, -0.0059,  1.2554, -0.0195,  0.0685, -0.0474, -2.2826],
       device='cuda:1')
Solve time for step 3 3.9724398140097037
Current ori: tensor([-0.0195,  0.0685, -0.0474], device='cuda:1')
Middle force: tensor([0.5432, 0.5171], device='cuda:1')
Thumb force: tensor([0.5464, 0.5931], device='cuda:1')
tensor([ 2.1373e-01,  5.2175e-01,  5.7784e-01,  5.7237e-01, -2.4145e-01,
         6.9668e-01,  7.3941e-01,  7.7485e-01,  1.4662e+00,  3.0520e-01,
        -6.5802e-05,  1.2353e+00, -2.6887e-02,  7.3099e-02, -4.1696e-02,
        -2.5491e+00], device='cuda:1')
Solve time for step 4 3.8346298309625126
Current ori: tensor([-0.0269,  0.0731, -0.0417], device='cuda:1')
Middle force: tensor([0.5161], device='cuda:1')
Thumb force: tensor([0.5821], device='cuda:1')
Storing RECOVERY transition: reward=0.0416 (scaled=0.0416), steps=1
Reward stats updated: mean 0.0140 -> 0.0141, std: 0.0727
Collected 254 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=1.0833, Q2 Loss=1.0833, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5014
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.7885, Q2 Loss=0.7885, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4286
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.6619, Q2 Loss=1.6619, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0044
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=2.4202, Q2 Loss=2.4202, Entropy=0.6845, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1157
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=5.0166, Q2 Loss=5.0166, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0673

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.05s (19.5%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008780
Q1 loss: 2.194107
Q2 loss: 2.194107
Current threshold: -149.5466
Global Scale Offset: 1028.1238
Reward stats: mean=0.0141, std=0.0727, count=254
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 2.1941, Q2 Loss: 2.1941, Entropy: 0.6909, Mean TD Error: 2.8235, Threshold: -149.5466
Original likelihood: -208.26663208007812
Adjusted likelihood: -208.26663208007812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4773)
State is out of distribution
Projection step: 0, Loss: 217.73130798339844
Projection step: 1, Loss: 208.77548217773438
Projection step: 2, Loss: 217.150634765625
Projection step: 3, Loss: 203.35678100585938
Projection step: 4, Loss: 198.97958374023438
Projection step: 5, Loss: 212.78262329101562
Projection step: 6, Loss: 203.48031616210938
Projection step: 7, Loss: 202.15301513671875
Projection step: 8, Loss: 193.78878784179688
Projection step: 9, Loss: 187.9080810546875
Projection step: 10, Loss: 185.7227325439453
Projection step: 11, Loss: 186.59182739257812
Projection step: 12, Loss: 188.5834197998047
Projection step: 13, Loss: 188.0911865234375
Projection step: 14, Loss: 183.68441772460938
Projection step: 15, Loss: 174.70706176757812
Projection step: 16, Loss: 168.98849487304688
Projection step: 17, Loss: 183.73150634765625
Projection step: 18, Loss: 168.19752502441406
Projection step: 19, Loss: 168.47360229492188
Projection step: 20, Loss: 174.36070251464844
Projection step: 21, Loss: 178.79995727539062
Projection step: 22, Loss: 183.19403076171875
Projection step: 23, Loss: 170.54415893554688
Projection step: 24, Loss: 163.59828186035156
Final likelihood: tensor([-193.9241, -168.4818, -167.6317, -166.0880, -149.6205, -166.1101,
        -150.9913, -195.9747, -187.3830, -178.8691, -155.3562, -137.7540,
        -136.8071, -168.1276, -176.9670, -197.8659])
Final projection likelihood: -168.6220
1 mode projection failed, trying anyway
New goal: tensor([ 0.1021,  0.5592,  0.5651,  0.6503, -0.1666,  0.6948,  0.7323,  0.7841,
         1.4478,  0.2225,  0.0902,  1.2342, -0.0364,  0.0508,  1.2039],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0021]], device='cuda:1')
Original likelihood: -193.75155639648438
Adjusted likelihood: -193.75155639648438
Likelihood residual: 0.0
Original likelihood: -184.0894775390625
Adjusted likelihood: -184.0894775390625
Likelihood residual: 0.0
{'index': 184.0894775390625, 'thumb_middle': 193.75155639648438}
Current yaw: tensor([-0.0299,  0.0690, -0.0596], device='cuda:1')
8 index
tensor([ 0.1471,  0.5730,  0.6191,  0.5924, -0.2358,  0.6984,  0.7408,  0.7755,
         1.4682,  0.3061, -0.0135,  1.2402, -0.0299,  0.0690, -0.0596, -2.5586],
       device='cuda:1')
Solve time for step 1 10.7863612799556
Current ori: tensor([-0.0299,  0.0690, -0.0596], device='cuda:1')
Middle force: tensor([0.5843, 0.5724, 0.5921, 0.5600], device='cuda:1')
Thumb force: tensor([0.5186, 0.6017, 0.5361, 0.5718], device='cuda:1')
tensor([ 0.1551,  0.5003,  0.5262,  0.6166, -0.2380,  0.7075,  0.7249,  0.7736,
         1.4906,  0.2699, -0.0207,  1.2165, -0.0368,  0.0718, -0.0793,  1.1632],
       device='cuda:1')
Solve time for step 2 4.585331964015495
Current ori: tensor([-0.0368,  0.0718, -0.0793], device='cuda:1')
Middle force: tensor([0.5693, 0.5878, 0.5571], device='cuda:1')
Thumb force: tensor([0.5925, 0.5328, 0.5683], device='cuda:1')
tensor([ 0.1455,  0.5001,  0.5164,  0.6195, -0.2435,  0.7000,  0.7296,  0.7822,
         1.4970,  0.2605, -0.0198,  1.2158, -0.0341,  0.0751, -0.0863, -4.4067],
       device='cuda:1')
Solve time for step 3 4.015196997963358
Current ori: tensor([-0.0341,  0.0751, -0.0863], device='cuda:1')
Middle force: tensor([0.5632, 0.5680], device='cuda:1')
Thumb force: tensor([0.5438, 0.5764], device='cuda:1')
tensor([ 0.1405,  0.4989,  0.5090,  0.6253, -0.2422,  0.7010,  0.7294,  0.7816,
         1.4999,  0.2538, -0.0238,  1.2170, -0.0345,  0.0742, -0.0868,  4.7502],
       device='cuda:1')
Solve time for step 4 3.9006130499765277
Current ori: tensor([-0.0345,  0.0742, -0.0868], device='cuda:1')
Middle force: tensor([0.5619], device='cuda:1')
Thumb force: tensor([0.5687], device='cuda:1')
Storing RECOVERY transition: reward=0.0632 (scaled=0.0632), steps=1
Reward stats updated: mean 0.0141 -> 0.0143, std: 0.0726
Collected 255 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=1.9805, Q2 Loss=1.9805, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9453
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.6574, Q2 Loss=0.6574, Entropy=0.6922, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1600
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=0.9632, Q2 Loss=0.9632, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0316
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=0.8307, Q2 Loss=0.8307, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4985
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.6976, Q2 Loss=0.6976, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4661

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.04s (18.6%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008882
Q1 loss: 1.025887
Q2 loss: 1.025887
Current threshold: -149.5465
Global Scale Offset: 1045.6282
Reward stats: mean=0.0143, std=0.0726, count=255
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.0259, Q2 Loss: 1.0259, Entropy: 0.6925, Mean TD Error: 0.8203, Threshold: -149.5465
Original likelihood: -201.08587646484375
Adjusted likelihood: -201.08587646484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4804)
State is out of distribution
Projection step: 0, Loss: 199.41152954101562
Projection step: 1, Loss: 194.7490234375
Projection step: 2, Loss: 188.7602081298828
Projection step: 3, Loss: 189.62692260742188
Projection step: 4, Loss: 192.11398315429688
Projection step: 5, Loss: 195.03573608398438
Projection step: 6, Loss: 187.1468048095703
Projection step: 7, Loss: 191.85397338867188
Projection step: 8, Loss: 182.31724548339844
Projection step: 9, Loss: 205.0477294921875
Projection step: 10, Loss: 195.26475524902344
Projection step: 11, Loss: 181.99038696289062
Projection step: 12, Loss: 181.81533813476562
Projection step: 13, Loss: 200.79010009765625
Projection step: 14, Loss: 186.25953674316406
Projection step: 15, Loss: 170.6597900390625
Projection step: 16, Loss: 178.89146423339844
Projection step: 17, Loss: 186.498291015625
Projection step: 18, Loss: 184.02493286132812
Projection step: 19, Loss: 186.73126220703125
Projection step: 20, Loss: 185.96649169921875
Projection step: 21, Loss: 186.7210693359375
Projection step: 22, Loss: 191.01406860351562
Projection step: 23, Loss: 180.91131591796875
Projection step: 24, Loss: 181.02951049804688
Final likelihood: tensor([-218.8154, -190.3142, -167.4619, -203.7355, -182.1272, -181.0024,
        -148.3255, -195.1281, -172.9501, -161.0675, -209.0769, -155.0107,
        -171.7770, -197.9856, -167.9884, -210.0406])
Final projection likelihood: -183.3005
1 mode projection failed, trying anyway
New goal: tensor([ 0.0716,  0.5618,  0.5331,  0.6760, -0.1736,  0.6951,  0.6774,  0.7897,
         1.4570,  0.1947,  0.0684,  1.2202, -0.0423,  0.0577,  0.4561],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -176.9494171142578
Adjusted likelihood: -176.9494171142578
Likelihood residual: 0.0
Original likelihood: -193.05760192871094
Adjusted likelihood: -193.05760192871094
Likelihood residual: 0.0
{'index': 193.05760192871094, 'thumb_middle': 176.9494171142578}
Current yaw: tensor([-0.0369,  0.0750, -0.0829], device='cuda:1')
9 thumb_middle
tensor([ 0.0880,  0.5539,  0.5560,  0.6453, -0.2424,  0.7064,  0.7227,  0.7756,
         1.4959,  0.2630, -0.0182,  1.2102, -0.0369,  0.0750, -0.0829,  4.1139],
       device='cuda:1')
Solve time for step 1 9.111111789010465
Current ori: tensor([-0.0369,  0.0750, -0.0829], device='cuda:1')
Index force: tensor([0.5754, 0.5840, 0.5993, 0.5626], device='cuda:1')
tensor([ 0.0821,  0.5616,  0.5309,  0.6592, -0.2663,  0.7007,  0.6582,  0.7725,
         1.4246,  0.1855, -0.0189,  1.1906, -0.0320,  0.0862, -0.0828,  4.0227],
       device='cuda:1')
Solve time for step 2 3.511953995039221
Current ori: tensor([-0.0320,  0.0862, -0.0828], device='cuda:1')
Index force: tensor([0.5742, 0.5901, 0.5549], device='cuda:1')
tensor([ 0.0991,  0.5716,  0.5318,  0.6646, -0.2642,  0.7030,  0.6789,  0.7590,
         1.4157,  0.1731, -0.0107,  1.1841, -0.0363,  0.0739, -0.0828,  4.0612],
       device='cuda:1')
Solve time for step 3 3.5118581440183334
Current ori: tensor([-0.0363,  0.0739, -0.0828], device='cuda:1')
Index force: tensor([0.5766, 0.5457], device='cuda:1')
tensor([ 0.1064,  0.5702,  0.5329,  0.6805, -0.2628,  0.7091,  0.6546,  0.7754,
         1.4091,  0.1619, -0.0104,  1.1955, -0.0357,  0.0690, -0.0828,  4.0833],
       device='cuda:1')
Solve time for step 4 3.4208619839628227
Current ori: tensor([-0.0357,  0.0690, -0.0828], device='cuda:1')
Index force: tensor([0.5490], device='cuda:1')
Storing RECOVERY transition: reward=0.0817 (scaled=0.0817), steps=1
Reward stats updated: mean 0.0143 -> 0.0146, std: 0.0726
Collected 256 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.8024, Q2 Loss=1.8024, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1860
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.1140, Q2 Loss=1.1140, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3580
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=1.3510, Q2 Loss=1.3510, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8297
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=0.8713, Q2 Loss=0.8713, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5201
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.7393, Q2 Loss=0.7393, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3122

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (17.7%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009074
Q1 loss: 1.175635
Q2 loss: 1.175635
Current threshold: -149.5461
Global Scale Offset: 1060.7339
Reward stats: mean=0.0146, std=0.0726, count=256
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.1756, Q2 Loss: 1.1756, Entropy: 0.6926, Mean TD Error: 1.2412, Threshold: -149.5461
Original likelihood: -208.9337158203125
Adjusted likelihood: -208.9337158203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4777)
Current yaw: tensor([-0.0376,  0.0729, -0.1014], device='cuda:1')
10 turn
Sampling time 3.793189370946493
tensor([ 0.0885,  0.5625,  0.5309,  0.6729, -0.2305,  0.7214,  0.6767,  0.7992,
         1.4790,  0.1998,  0.0350,  1.2187, -0.0376,  0.0729, -0.1014,  4.1557],
       device='cuda:1')
Original likelihood: -187.732421875
Adjusted likelihood: -187.732421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4857)
State is out of distribution
Projection step: 0, Loss: 193.82810974121094
Projection step: 1, Loss: 184.96517944335938
Projection step: 2, Loss: 189.12782287597656
Projection step: 3, Loss: 197.12701416015625
Projection step: 4, Loss: 186.17405700683594
Projection step: 5, Loss: 201.53433227539062
Projection step: 6, Loss: 197.3115234375
Projection step: 7, Loss: 197.5823516845703
Projection step: 8, Loss: 211.05667114257812
Projection step: 9, Loss: 194.1839599609375
Projection step: 10, Loss: 185.49896240234375
Projection step: 11, Loss: 182.7655792236328
Projection step: 12, Loss: 207.64608764648438
Projection step: 13, Loss: 188.73204040527344
Projection step: 14, Loss: 183.0879669189453
Projection step: 15, Loss: 190.77880859375
Projection step: 16, Loss: 181.25904846191406
Projection step: 17, Loss: 185.37191772460938
Projection step: 18, Loss: 201.88804626464844
Projection step: 19, Loss: 190.17581176757812
Projection step: 20, Loss: 181.51229858398438
Projection step: 21, Loss: 171.33909606933594
Projection step: 22, Loss: 188.6058807373047
Projection step: 23, Loss: 179.63916015625
Projection step: 24, Loss: 185.04344177246094
Final likelihood: tensor([-168.6646, -208.5237, -184.6438, -149.2540, -161.5206, -240.3574,
        -160.1935, -182.7542, -196.4506, -158.0308, -162.0555, -172.7925,
        -169.4795, -161.5480, -180.0152, -198.6541])
Final projection likelihood: -178.4336
1 mode projection failed, trying anyway
New goal: tensor([ 0.0692,  0.5685,  0.5225,  0.6665, -0.1618,  0.7129,  0.6443,  0.7820,
         1.4415,  0.1132,  0.0829,  1.2348, -0.0443,  0.0544,  0.4210],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -175.789306640625
Adjusted likelihood: -175.789306640625
Likelihood residual: 0.0
Original likelihood: -178.97085571289062
Adjusted likelihood: -178.97085571289062
Likelihood residual: 0.0
{'index': 178.97085571289062, 'thumb_middle': 175.789306640625}
Current yaw: tensor([-0.0376,  0.0729, -0.1014], device='cuda:1')
11 thumb_middle
tensor([ 0.0885,  0.5625,  0.5309,  0.6729, -0.2305,  0.7214,  0.6767,  0.7992,
         1.4790,  0.1998,  0.0350,  1.2187, -0.0376,  0.0729, -0.1014,  4.1557],
       device='cuda:1')
Solve time for step 1 9.089912817988079
Current ori: tensor([-0.0376,  0.0729, -0.1014], device='cuda:1')
Index force: tensor([0.5726, 0.6033, 0.5859, 0.4998], device='cuda:1')
tensor([ 0.0929,  0.5840,  0.5135,  0.6549, -0.2517,  0.7171,  0.6350,  0.7696,
         1.4089,  0.1020,  0.0197,  1.2136, -0.0393,  0.0773, -0.1013,  4.0664],
       device='cuda:1')
Solve time for step 2 3.530027622997295
Current ori: tensor([-0.0393,  0.0773, -0.1013], device='cuda:1')
Index force: tensor([0.5632, 0.5761, 0.5795], device='cuda:1')
tensor([ 0.1003,  0.5828,  0.5124,  0.6745, -0.2526,  0.7178,  0.6363,  0.7670,
         1.4129,  0.0727,  0.0312,  1.2246, -0.0383,  0.0726, -0.1013,  4.0847],
       device='cuda:1')
Solve time for step 3 3.3195651170099154
Current ori: tensor([-0.0383,  0.0726, -0.1013], device='cuda:1')
Index force: tensor([0.5620, 0.5667], device='cuda:1')
tensor([ 0.1030,  0.5853,  0.5169,  0.6645, -0.2528,  0.7229,  0.6276,  0.7633,
         1.4090,  0.0900,  0.0223,  1.2208, -0.0400,  0.0706, -0.1013,  4.0879],
       device='cuda:1')
Solve time for step 4 3.13688851200277
Current ori: tensor([-0.0400,  0.0706, -0.1013], device='cuda:1')
Index force: tensor([0.5548], device='cuda:1')
Storing RECOVERY transition: reward=0.0026 (scaled=0.0026), steps=0
Reward stats updated: mean 0.0146 -> 0.0145, std: 0.0725
Collected 257 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=0.8578, Q2 Loss=0.8578, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5034
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=1.2112, Q2 Loss=1.2112, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5861
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.2932, Q2 Loss=1.2932, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4849
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=2.7604, Q2 Loss=2.7604, Entropy=0.6915, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7419
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=0.8148, Q2 Loss=0.8148, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5572

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (21.9%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (17.3%)
Actor update: 0.08s (37.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009486
Q1 loss: 1.387478
Q2 loss: 1.387478
Current threshold: -149.5455
Global Scale Offset: 1076.5535
Reward stats: mean=0.0145, std=0.0725, count=257
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.3875, Q2 Loss: 1.3875, Entropy: 0.6926, Mean TD Error: 1.3747, Threshold: -149.5455
Original likelihood: -226.8152313232422
Adjusted likelihood: -226.8152313232422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4714)
Current yaw: tensor([-0.0369,  0.0672, -0.1032], device='cuda:1')
12 turn
Sampling time 3.606396090995986
tensor([ 0.0998,  0.5658,  0.5237,  0.6995, -0.2162,  0.7443,  0.6549,  0.7731,
         1.4811,  0.1126,  0.0560,  1.2585, -0.0369,  0.0672, -0.1032,  4.1727],
       device='cuda:1')
Original likelihood: -227.27066040039062
Adjusted likelihood: -227.27066040039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4713)
State is out of distribution
Projection step: 0, Loss: 188.60202026367188
Projection step: 1, Loss: 193.861328125
Projection step: 2, Loss: 196.13436889648438
Projection step: 3, Loss: 191.2236328125
Projection step: 4, Loss: 209.96978759765625
Projection step: 5, Loss: 199.0613250732422
Projection step: 6, Loss: 201.768310546875
Projection step: 7, Loss: 196.6710205078125
Projection step: 8, Loss: 202.04519653320312
Projection step: 9, Loss: 177.0921173095703
Projection step: 10, Loss: 183.9760284423828
Projection step: 11, Loss: 180.63429260253906
Projection step: 12, Loss: 196.396240234375
Projection step: 13, Loss: 176.241943359375
Projection step: 14, Loss: 175.7277374267578
Projection step: 15, Loss: 174.4021759033203
Projection step: 16, Loss: 186.00250244140625
Projection step: 17, Loss: 183.32766723632812
Projection step: 18, Loss: 191.33328247070312
Projection step: 19, Loss: 190.30320739746094
Projection step: 20, Loss: 178.84829711914062
Projection step: 21, Loss: 177.3697509765625
Projection step: 22, Loss: 174.28717041015625
Projection step: 23, Loss: 172.573486328125
Projection step: 24, Loss: 171.855224609375
Final likelihood: tensor([-150.3357, -154.5788, -172.7312, -166.9070, -160.6166, -167.1283,
        -161.8636, -192.4048, -154.3904, -182.4092, -162.2629, -214.0685,
        -158.1076, -166.3155, -179.0269, -167.3793])
Final projection likelihood: -169.4079
1 mode projection failed, trying anyway
New goal: tensor([ 0.0743,  0.5639,  0.5268,  0.6775, -0.1510,  0.7190,  0.6525,  0.7643,
         1.4419,  0.0604,  0.0897,  1.2425, -0.0448,  0.0476,  0.6498],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -178.50775146484375
Adjusted likelihood: -178.50775146484375
Likelihood residual: 0.0
Original likelihood: -185.52914428710938
Adjusted likelihood: -185.52914428710938
Likelihood residual: 0.0
{'index': 185.52914428710938, 'thumb_middle': 178.50775146484375}
Current yaw: tensor([-0.0369,  0.0672, -0.1032], device='cuda:1')
13 thumb_middle
tensor([ 0.0998,  0.5658,  0.5237,  0.6995, -0.2162,  0.7443,  0.6549,  0.7731,
         1.4811,  0.1126,  0.0560,  1.2585, -0.0369,  0.0672, -0.1032,  4.1727],
       device='cuda:1')
Solve time for step 1 9.10996009898372
Current ori: tensor([-0.0369,  0.0672, -0.1032], device='cuda:1')
Index force: tensor([0.5239, 0.5002, 0.5001, 0.5945], device='cuda:1')
tensor([ 0.0921,  0.5682,  0.4933,  0.7348, -0.2473,  0.7161,  0.6348,  0.7403,
         1.4315,  0.0440,  0.0389,  1.2257, -0.0310,  0.0773, -0.1032,  4.1183],
       device='cuda:1')
Solve time for step 2 3.572380814992357
Current ori: tensor([-0.0310,  0.0773, -0.1032], device='cuda:1')
Index force: tensor([0.5008, 0.5835, 0.5921], device='cuda:1')
tensor([ 0.0906,  0.5616,  0.5171,  0.7033, -0.2494,  0.7207,  0.6316,  0.7427,
         1.4344,  0.0411,  0.0400,  1.2269, -0.0317,  0.0784, -0.1032,  4.1063],
       device='cuda:1')
Solve time for step 3 3.421018441033084
Current ori: tensor([-0.0317,  0.0784, -0.1032], device='cuda:1')
Index force: tensor([0.5742, 0.5828], device='cuda:1')
tensor([ 0.1033,  0.5775,  0.5218,  0.6770, -0.2463,  0.7264,  0.6295,  0.7426,
         1.4235,  0.0364,  0.0361,  1.2280, -0.0366,  0.0700, -0.1032,  4.1147],
       device='cuda:1')
Solve time for step 4 3.265038701996673
Current ori: tensor([-0.0366,  0.0700, -0.1032], device='cuda:1')
Index force: tensor([0.5616], device='cuda:1')
Storing RECOVERY transition: reward=0.0102 (scaled=0.0102), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0723
Collected 258 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=1.1440, Q2 Loss=1.1440, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8626
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=2.3899, Q2 Loss=2.3899, Entropy=0.6859, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0948
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.5439, Q2 Loss=1.5439, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1040
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.7845, Q2 Loss=0.7845, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9116
SAC Update 5/5: Actor Loss=-0.0104, Q1 Loss=1.0525, Q2 Loss=1.0525, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6430

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009830
Q1 loss: 1.382944
Q2 loss: 1.382944
Current threshold: -149.5452
Global Scale Offset: 1094.7044
Reward stats: mean=0.0145, std=0.0723, count=258
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.3829, Q2 Loss: 1.3829, Entropy: 0.6915, Mean TD Error: 1.3232, Threshold: -149.5452
Original likelihood: -214.19430541992188
Adjusted likelihood: -214.19430541992188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4765)
Current yaw: tensor([-0.0368,  0.0690, -0.1138], device='cuda:1')
14 turn
Sampling time 3.6731421219883487
tensor([ 0.0958,  0.5654,  0.5268,  0.6870, -0.2134,  0.7455,  0.6495,  0.7585,
         1.4935,  0.0702,  0.0760,  1.2427, -0.0368,  0.0690, -0.1138,  4.1852],
       device='cuda:1')
Original likelihood: -210.95599365234375
Adjusted likelihood: -210.95599365234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4777)
State is out of distribution
Projection step: 0, Loss: 200.97161865234375
Projection step: 1, Loss: 191.40213012695312
Projection step: 2, Loss: 209.24176025390625
Projection step: 3, Loss: 202.2007293701172
Projection step: 4, Loss: 194.58724975585938
Projection step: 5, Loss: 192.02903747558594
Projection step: 6, Loss: 191.92849731445312
Projection step: 7, Loss: 203.40316772460938
Projection step: 8, Loss: 196.3828887939453
Projection step: 9, Loss: 194.8470916748047
Projection step: 10, Loss: 200.90989685058594
Projection step: 11, Loss: 188.18179321289062
Projection step: 12, Loss: 179.14614868164062
Projection step: 13, Loss: 181.29608154296875
Projection step: 14, Loss: 176.71347045898438
Projection step: 15, Loss: 179.73818969726562
Projection step: 16, Loss: 180.66873168945312
Projection step: 17, Loss: 172.68505859375
Projection step: 18, Loss: 180.9532012939453
Projection step: 19, Loss: 171.43699645996094
Projection step: 20, Loss: 171.87013244628906
Projection step: 21, Loss: 175.79139709472656
Projection step: 22, Loss: 171.5503387451172
Projection step: 23, Loss: 168.5450897216797
Projection step: 24, Loss: 166.21502685546875
Final likelihood: tensor([-159.8026, -179.2094, -146.7137, -186.2385, -146.0915, -184.2480,
        -178.0878, -161.6478, -192.4008, -175.3250, -158.4226, -159.2848,
        -149.8036, -171.8520, -167.8092, -179.1584])
Final projection likelihood: -168.5060
1 mode projection failed, trying anyway
New goal: tensor([ 0.0728,  0.5689,  0.5410,  0.6397, -0.1500,  0.7180,  0.6494,  0.7450,
         1.4516,  0.0517,  0.0947,  1.2410, -0.0432,  0.0502,  0.5736],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -199.774658203125
Adjusted likelihood: -199.774658203125
Likelihood residual: 0.0
Original likelihood: -169.37991333007812
Adjusted likelihood: -169.37991333007812
Likelihood residual: 0.0
{'index': 169.37991333007812, 'thumb_middle': 199.774658203125}
Current yaw: tensor([-0.0368,  0.0690, -0.1138], device='cuda:1')
15 index
tensor([ 0.0958,  0.5654,  0.5268,  0.6870, -0.2134,  0.7455,  0.6495,  0.7585,
         1.4935,  0.0702,  0.0760,  1.2427, -0.0368,  0.0690, -0.1138,  4.1852],
       device='cuda:1')
Solve time for step 1 10.352302005980164
Current ori: tensor([-0.0368,  0.0690, -0.1138], device='cuda:1')
Middle force: tensor([0.5890, 0.5148, 0.5839, 0.5700], device='cuda:1')
Thumb force: tensor([0.5947, 0.5706, 0.5206, 0.5655], device='cuda:1')
tensor([ 0.1219,  0.5055,  0.4865,  0.6217, -0.2070,  0.7481,  0.6550,  0.7469,
         1.5000,  0.0661,  0.0629,  1.2272, -0.0412,  0.0645, -0.1272,  4.1750],
       device='cuda:1')
Solve time for step 2 4.050477826967835
Current ori: tensor([-0.0412,  0.0645, -0.1272], device='cuda:1')
Middle force: tensor([0.5138, 0.5788, 0.5663], device='cuda:1')
Thumb force: tensor([0.5645, 0.5195, 0.5624], device='cuda:1')
tensor([ 0.1207,  0.5078,  0.4863,  0.6127, -0.2021,  0.7464,  0.6599,  0.7519,
         1.5000,  0.0659,  0.0498,  1.2367, -0.0402,  0.0600, -0.1325,  4.1752],
       device='cuda:1')
Solve time for step 3 4.011606190004386
Current ori: tensor([-0.0402,  0.0600, -0.1325], device='cuda:1')
Middle force: tensor([0.5320, 0.5380], device='cuda:1')
Thumb force: tensor([0.5829, 0.5325], device='cuda:1')
tensor([ 0.1185,  0.5057,  0.4868,  0.6115, -0.2034,  0.7439,  0.6623,  0.7549,
         1.5000,  0.0660,  0.0504,  1.2395, -0.0388,  0.0607, -0.1313,  4.1734],
       device='cuda:1')
Solve time for step 4 4.0389102440094575
Current ori: tensor([-0.0388,  0.0607, -0.1313], device='cuda:1')
Middle force: tensor([0.5136], device='cuda:1')
Thumb force: tensor([0.5302], device='cuda:1')
Storing RECOVERY transition: reward=0.0246 (scaled=0.0246), steps=0
Reward stats updated: mean 0.0145 -> 0.0146, std: 0.0722
Collected 259 transitions for RL
SAC Update 1/5: Actor Loss=-0.0099, Q1 Loss=1.0006, Q2 Loss=1.0006, Entropy=0.6919, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7162
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.9279, Q2 Loss=0.9279, Entropy=0.6913, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8037
SAC Update 3/5: Actor Loss=-0.0116, Q1 Loss=1.0769, Q2 Loss=1.0769, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4961
SAC Update 4/5: Actor Loss=-0.0105, Q1 Loss=2.3217, Q2 Loss=2.3217, Entropy=0.6912, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7646
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=4.2884, Q2 Loss=4.2884, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4995

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.06s (21.1%)
Q2 update: 0.06s (18.8%)
Actor update: 0.12s (39.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010189
Q1 loss: 1.923100
Q2 loss: 1.923100
Current threshold: -149.5448
Global Scale Offset: 1113.6493
Reward stats: mean=0.0146, std=0.0722, count=259
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.9231, Q2 Loss: 1.9231, Entropy: 0.6919, Mean TD Error: 1.4560, Threshold: -149.5448
Original likelihood: -180.584716796875
Adjusted likelihood: -180.584716796875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4889)
State is out of distribution
Projection step: 0, Loss: 191.62698364257812
Projection step: 1, Loss: 186.68023681640625
Projection step: 2, Loss: 178.65899658203125
Projection step: 3, Loss: 189.15316772460938
Projection step: 4, Loss: 182.22215270996094
Projection step: 5, Loss: 184.7995147705078
Projection step: 6, Loss: 184.9886016845703
Projection step: 7, Loss: 177.01388549804688
Projection step: 8, Loss: 176.70571899414062
Projection step: 9, Loss: 192.22970581054688
Projection step: 10, Loss: 181.352783203125
Projection step: 11, Loss: 171.99319458007812
Projection step: 12, Loss: 169.89706420898438
Projection step: 13, Loss: 172.75990295410156
Projection step: 14, Loss: 174.92987060546875
Projection step: 15, Loss: 182.89419555664062
Projection step: 16, Loss: 171.61166381835938
Projection step: 17, Loss: 157.10214233398438
Projection step: 18, Loss: 173.9035186767578
Projection step: 19, Loss: 154.88893127441406
Projection step: 20, Loss: 166.11741638183594
Projection step: 21, Loss: 170.2222900390625
Projection step: 22, Loss: 154.97918701171875
Projection step: 23, Loss: 145.408203125
Projection step: 24, Loss: 141.39126586914062
Final likelihood: tensor([-336.7800, -180.3468, -121.5502, -142.8665, -172.8248, -160.9588,
        -150.5140, -159.5614, -136.9095, -156.1754, -140.4215, -116.1709,
        -134.0881, -140.5822, -136.7022, -147.9594])
Final projection likelihood: -158.4007
1 mode projection failed, trying anyway
New goal: tensor([ 0.0777,  0.5549,  0.5216,  0.7025, -0.1306,  0.6993,  0.6761,  0.7477,
         1.4448,  0.0451,  0.0822,  1.2259, -0.0472,  0.0370,  0.3233],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -148.12484741210938
Adjusted likelihood: -148.12484741210938
Likelihood residual: 0.0
Original likelihood: -173.3760223388672
Adjusted likelihood: -173.3760223388672
Likelihood residual: 0.0
{'index': 173.3760223388672, 'thumb_middle': 148.12484741210938}
Current yaw: tensor([-0.0437,  0.0543, -0.1374], device='cuda:1')
16 thumb_middle
tensor([ 0.0686,  0.5651,  0.5314,  0.6360, -0.1943,  0.7533,  0.6574,  0.7465,
         1.4976,  0.0634,  0.0410,  1.2380, -0.0437,  0.0543, -0.1374,  4.2070],
       device='cuda:1')
Solve time for step 1 9.394769132020883
Current ori: tensor([-0.0437,  0.0543, -0.1374], device='cuda:1')
Index force: tensor([0.5499, 0.5711, 0.5910, 0.5635], device='cuda:1')
tensor([ 8.2583e-02,  5.6795e-01,  5.2443e-01,  6.6826e-01, -2.2162e-01,
         7.1049e-01,  6.5024e-01,  7.2650e-01,  1.4158e+00,  3.8752e-03,
         2.7306e-02,  1.2269e+00, -4.1807e-02,  4.7400e-02, -1.3740e-01,
         4.2173e+00], device='cuda:1')
Solve time for step 2 3.9784984510042705
Current ori: tensor([-0.0418,  0.0474, -0.1374], device='cuda:1')
Index force: tensor([0.5644, 0.5841, 0.5628], device='cuda:1')
tensor([ 0.0914,  0.5764,  0.5139,  0.6828, -0.2195,  0.7122,  0.6517,  0.7271,
         1.4092,  0.0216,  0.0202,  1.1984, -0.0429,  0.0415, -0.1374,  4.2348],
       device='cuda:1')
Solve time for step 3 3.5297361399861984
Current ori: tensor([-0.0429,  0.0415, -0.1374], device='cuda:1')
Index force: tensor([0.5734, 0.5552], device='cuda:1')
tensor([ 0.0841,  0.5653,  0.5128,  0.7013, -0.2207,  0.7006,  0.6627,  0.7286,
         1.4156,  0.0058,  0.0279,  1.2057, -0.0386,  0.0465, -0.1374,  4.2287],
       device='cuda:1')
Solve time for step 4 3.459332280966919
Current ori: tensor([-0.0386,  0.0465, -0.1374], device='cuda:1')
Index force: tensor([0.5654], device='cuda:1')
Storing RECOVERY transition: reward=0.0274 (scaled=0.0274), steps=0
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0721
Collected 260 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=1.1095, Q2 Loss=1.1095, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8322
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=0.9869, Q2 Loss=0.9869, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6307
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=0.8452, Q2 Loss=0.8452, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4938
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=0.8096, Q2 Loss=0.8096, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3497
SAC Update 5/5: Actor Loss=-0.0104, Q1 Loss=1.8798, Q2 Loss=1.8798, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1670

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.4%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.8%)
Actor update: 0.12s (41.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008963
Q1 loss: 1.126212
Q2 loss: 1.126212
Current threshold: -149.5446
Global Scale Offset: 1131.3518
Reward stats: mean=0.0146, std=0.0721, count=260
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.1262, Q2 Loss: 1.1262, Entropy: 0.6926, Mean TD Error: 0.8947, Threshold: -149.5446
Original likelihood: -173.79635620117188
Adjusted likelihood: -173.79635620117188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4915)
Current yaw: tensor([-0.0368,  0.0440, -0.1386], device='cuda:1')
17 turn
Sampling time 3.6327058550086804
tensor([ 0.0806,  0.5550,  0.5207,  0.7076, -0.1844,  0.7394,  0.6898,  0.7490,
         1.4843,  0.0474,  0.0659,  1.2234, -0.0368,  0.0440, -0.1386,  4.2627],
       device='cuda:1')
Original likelihood: -189.11997985839844
Adjusted likelihood: -189.11997985839844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4861)
State is out of distribution
Projection step: 0, Loss: 184.18338012695312
Projection step: 1, Loss: 171.98779296875
Projection step: 2, Loss: 169.31187438964844
Projection step: 3, Loss: 168.1872100830078
Projection step: 4, Loss: 168.658935546875
Projection step: 5, Loss: 172.62290954589844
Projection step: 6, Loss: 170.67588806152344
Projection step: 7, Loss: 154.3963623046875
Projection step: 8, Loss: 165.65553283691406
Projection step: 9, Loss: 161.05923461914062
Projection step: 10, Loss: 154.21368408203125
Projection step: 11, Loss: 151.1817169189453
Projection step: 12, Loss: 163.82015991210938
Projection step: 13, Loss: 145.59896850585938
Projection step: 14, Loss: 161.17918395996094
Projection step: 15, Loss: 137.96165466308594
Projection step: 16, Loss: 147.67811584472656
Projection step: 17, Loss: 136.47885131835938
Projection step: 18, Loss: 136.4664306640625
Projection step: 19, Loss: 136.89990234375
Projection step: 20, Loss: 142.50123596191406
Projection step: 21, Loss: 138.10671997070312
Projection step: 22, Loss: 134.65133666992188
Projection step: 23, Loss: 131.994873046875
Projection step: 24, Loss: 130.2371826171875
Final likelihood: tensor([-130.6839, -124.7448, -133.2063, -127.9702, -122.2236, -126.5261,
        -130.5735, -131.6389, -129.4320, -107.3254, -126.6171, -145.1894,
        -136.7986, -128.8455, -139.1241, -153.5191])
Final projection likelihood: -130.9012
1 mode projection succeeded
New goal: tensor([ 0.0882,  0.5471,  0.4917,  0.7999, -0.1254,  0.6890,  0.6738,  0.7754,
         1.4540,  0.0558,  0.0922,  1.1590, -0.0437,  0.0298,  0.6285],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -152.6819305419922
Adjusted likelihood: -152.6819305419922
Likelihood residual: 0.0
Original likelihood: -165.0909881591797
Adjusted likelihood: -165.0909881591797
Likelihood residual: 0.0
{'index': 165.0909881591797, 'thumb_middle': 152.6819305419922}
Current yaw: tensor([-0.0368,  0.0440, -0.1386], device='cuda:1')
18 thumb_middle
tensor([ 0.0806,  0.5550,  0.5207,  0.7076, -0.1844,  0.7394,  0.6898,  0.7490,
         1.4843,  0.0474,  0.0659,  1.2234, -0.0368,  0.0440, -0.1386,  4.2627],
       device='cuda:1')
Solve time for step 1 9.136481777008157
Current ori: tensor([-0.0368,  0.0440, -0.1386], device='cuda:1')
Index force: tensor([0.5753, 0.5833, 0.5885, 0.5868], device='cuda:1')
tensor([ 0.0843,  0.5568,  0.4845,  0.7812, -0.2208,  0.6957,  0.6515,  0.7759,
         1.4196,  0.0369,  0.0259,  1.1470, -0.0306,  0.0424, -0.1386,  4.2733],
       device='cuda:1')
Solve time for step 2 3.7598979769973084
Current ori: tensor([-0.0306,  0.0424, -0.1386], device='cuda:1')
Index force: tensor([0.5740, 0.5799, 0.5783], device='cuda:1')
tensor([ 0.0876,  0.5508,  0.4965,  0.7807, -0.2202,  0.6998,  0.6524,  0.7476,
         1.4200,  0.0294,  0.0270,  1.1339, -0.0294,  0.0404, -0.1386,  4.2793],
       device='cuda:1')
Solve time for step 3 3.707054060010705
Current ori: tensor([-0.0294,  0.0404, -0.1386], device='cuda:1')
Index force: tensor([0.5681, 0.5685], device='cuda:1')
tensor([ 0.0967,  0.5588,  0.4871,  0.7946, -0.2162,  0.7005,  0.6474,  0.7681,
         1.4176,  0.0185,  0.0208,  1.1434, -0.0298,  0.0358, -0.1386,  4.2995],
       device='cuda:1')
Solve time for step 4 3.495394908997696
Current ori: tensor([-0.0298,  0.0358, -0.1386], device='cuda:1')
Index force: tensor([0.5384], device='cuda:1')
Storing RECOVERY transition: reward=0.0090 (scaled=0.0090), steps=0
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0719
Collected 261 transitions for RL
SAC Update 1/5: Actor Loss=-0.0125, Q1 Loss=2.4917, Q2 Loss=2.4917, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3171
SAC Update 2/5: Actor Loss=-0.0104, Q1 Loss=1.2887, Q2 Loss=1.2887, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2446
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=0.8673, Q2 Loss=0.8673, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4189
SAC Update 4/5: Actor Loss=-0.0129, Q1 Loss=1.3238, Q2 Loss=1.3238, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9005
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.9743, Q2 Loss=0.9743, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6303

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010569
Q1 loss: 1.389130
Q2 loss: 1.389130
Current threshold: -149.5444
Global Scale Offset: 1148.2540
Reward stats: mean=0.0146, std=0.0719, count=261
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.3891, Q2 Loss: 1.3891, Entropy: 0.6926, Mean TD Error: 1.3023, Threshold: -149.5444
Original likelihood: -155.2681884765625
Adjusted likelihood: -155.2681884765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4980)
Current yaw: tensor([-0.0281,  0.0256, -0.1459], device='cuda:1')
19 turn
Sampling time 3.5760479089803994
tensor([ 0.1056,  0.5536,  0.4944,  0.8130, -0.1521,  0.7350,  0.6835,  0.7783,
         1.4872,  0.0608,  0.0491,  1.1525, -0.0281,  0.0256, -0.1459,  4.3662],
       device='cuda:1')
Original likelihood: -159.81137084960938
Adjusted likelihood: -159.81137084960938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4964)
Solve time for step 1 13.78832416498335
Current ori: tensor([-0.0281,  0.0256, -0.1459], device='cuda:1')
Middle force: tensor([0.5451, 1.1945, 0.6624, 0.5301, 0.5024, 0.6659, 1.5183, 0.7312, 0.6899,
        1.1762, 0.5318, 0.5797], device='cuda:1')
Thumb force: tensor([0.5055, 0.5474, 0.8091, 0.6092, 0.6968, 0.5842, 0.5533, 0.8108, 0.7918,
        0.8658, 1.1157, 0.5806], device='cuda:1')
Index force: tensor([0.5252, 0.5875, 0.5247, 0.5918, 0.7504, 0.5300, 0.5441, 0.5358, 0.6135,
        0.5881, 0.5539, 0.6292], device='cuda:1')
Storing NORMAL transition: reward=0.0753 (scaled=0.0753), steps=1
Reward stats updated: mean 0.0146 -> 0.0148, std: 0.0719
Collected 262 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.7568, Q2 Loss=0.7568, Entropy=0.6929, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3101
SAC Update 2/5: Actor Loss=-0.0103, Q1 Loss=1.1508, Q2 Loss=1.1508, Entropy=0.6918, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8915
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=1.0803, Q2 Loss=1.0803, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5073
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=1.4225, Q2 Loss=1.4225, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0893
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=2.4243, Q2 Loss=2.4243, Entropy=0.6864, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1612

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008896
Q1 loss: 1.366942
Q2 loss: 1.366942
Current threshold: -149.5441
Global Scale Offset: 1164.0937
Reward stats: mean=0.0148, std=0.0719, count=262
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.3669, Q2 Loss: 1.3669, Entropy: 0.6913, Mean TD Error: 1.5919, Threshold: -149.5441
tensor([ 0.1519,  0.4654,  0.5983,  0.9343, -0.1243,  0.7041,  0.6565,  0.9196,
         1.4327,  0.1531,  0.0660,  1.1473, -0.0126,  0.0112, -0.2202,  4.4794],
       device='cuda:1')
Original likelihood: -126.98262786865234
Adjusted likelihood: -126.98262786865234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5077)
Solve time for step 2 5.499970445991494
Current ori: tensor([-0.0126,  0.0112, -0.2202], device='cuda:1')
Middle force: tensor([1.1492, 0.6461, 0.5264, 0.5014, 0.6500, 1.4355, 0.7084, 0.6690, 1.1338,
        0.5295, 0.5705], device='cuda:1')
Thumb force: tensor([0.5386, 0.7857, 0.6009, 0.7104, 0.5781, 0.5473, 0.7934, 0.7835, 0.8652,
        1.0895, 0.5704], device='cuda:1')
Index force: tensor([0.5712, 0.5215, 0.5835, 0.7354, 0.5265, 0.5364, 0.5311, 0.6046, 0.5799,
        0.5477, 0.6237], device='cuda:1')
Storing NORMAL transition: reward=0.0011 (scaled=0.0011), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0718
Collected 263 transitions for RL
SAC Update 1/5: Actor Loss=-0.0127, Q1 Loss=1.4156, Q2 Loss=1.4156, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0877
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=1.6820, Q2 Loss=1.6820, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0546
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=0.7872, Q2 Loss=0.7872, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3739
SAC Update 4/5: Actor Loss=-0.0095, Q1 Loss=2.2985, Q2 Loss=2.2985, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0774
SAC Update 5/5: Actor Loss=-0.0117, Q1 Loss=1.1012, Q2 Loss=1.1012, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1198

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010484
Q1 loss: 1.456890
Q2 loss: 1.456890
Current threshold: -149.5439
Global Scale Offset: 1181.0748
Reward stats: mean=0.0148, std=0.0718, count=263
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.4569, Q2 Loss: 1.4569, Entropy: 0.6928, Mean TD Error: 1.3427, Threshold: -149.5439
tensor([ 0.2258,  0.5920,  0.4939,  0.8832, -0.0452,  0.7755,  0.5966,  1.0171,
         1.4399,  0.0040, -0.0644,  0.9554, -0.0116, -0.0607, -0.2252,  3.3727],
       device='cuda:1')
Original likelihood: -198.26107788085938
Adjusted likelihood: -198.26107788085938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4836)
Solve time for step 3 5.173746276006568
Current ori: tensor([-0.0116, -0.0607, -0.2252], device='cuda:1')
Middle force: tensor([0.6289, 0.5291, 0.5129, 0.6349, 1.3423, 0.6892, 0.6534, 1.1225, 0.5334,
        0.5655], device='cuda:1')
Thumb force: tensor([0.7663, 0.5894, 0.5510, 0.5736, 0.5454, 0.7751, 0.7703, 0.8185, 1.0455,
        0.5618], device='cuda:1')
Index force: tensor([0.5194, 0.5781, 0.6685, 0.5249, 0.5335, 0.5286, 0.5992, 0.5814, 0.5421,
        0.6159], device='cuda:1')
Storing NORMAL transition: reward=-0.0275 (scaled=-0.0275), steps=1
Reward stats updated: mean 0.0148 -> 0.0146, std: 0.0717
Collected 264 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=1.4679, Q2 Loss=1.4679, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4298
SAC Update 2/5: Actor Loss=-0.0131, Q1 Loss=1.5571, Q2 Loss=1.5571, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1421
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.7496, Q2 Loss=0.7496, Entropy=0.6914, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5888
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=0.9116, Q2 Loss=0.9116, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3095
SAC Update 5/5: Actor Loss=-0.0098, Q1 Loss=1.5363, Q2 Loss=1.5363, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4936

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (40.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009433
Q1 loss: 1.244498
Q2 loss: 1.244498
Current threshold: -149.5437
Global Scale Offset: 1196.1380
Reward stats: mean=0.0146, std=0.0717, count=264
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.2445, Q2 Loss: 1.2445, Entropy: 0.6926, Mean TD Error: 1.5928, Threshold: -149.5437
tensor([ 0.1785,  0.5409,  0.5449,  0.9026, -0.0597,  0.7510,  0.6648,  0.9918,
         1.4701,  0.0946,  0.0170,  1.0349, -0.0033, -0.0514, -0.1962,  3.2384],
       device='cuda:1')
Original likelihood: -170.5687713623047
Adjusted likelihood: -170.5687713623047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4930)
State is out of distribution
Projection step: 0, Loss: 172.46466064453125
Projection step: 1, Loss: 165.3695068359375
Projection step: 2, Loss: 160.92764282226562
Projection step: 3, Loss: 155.947265625
Projection step: 4, Loss: 159.8419189453125
Projection step: 5, Loss: 147.59658813476562
Projection step: 6, Loss: 163.70245361328125
Projection step: 7, Loss: 149.81832885742188
Projection step: 8, Loss: 151.815185546875
Projection step: 9, Loss: 166.2381591796875
Projection step: 10, Loss: 142.723876953125
Projection step: 11, Loss: 146.83953857421875
Projection step: 12, Loss: 148.12716674804688
Projection step: 13, Loss: 141.5873565673828
Projection step: 14, Loss: 139.09840393066406
Projection step: 15, Loss: 142.25421142578125
Projection step: 16, Loss: 138.7569580078125
Projection step: 17, Loss: 140.18414306640625
Projection step: 18, Loss: 132.5679931640625
Projection step: 19, Loss: 134.91323852539062
Projection step: 20, Loss: 135.95962524414062
Projection step: 21, Loss: 127.36032104492188
Projection step: 22, Loss: 133.11117553710938
Projection step: 23, Loss: 123.92385864257812
Projection step: 24, Loss: 132.87351989746094
Final likelihood: tensor([-100.2269, -151.2464, -135.9396, -124.8282, -116.1768, -108.9301,
        -126.2850, -112.6970, -102.3154, -155.0928, -129.8438, -114.2740,
        -130.3154, -108.3360, -128.3694, -135.4931])
Final projection likelihood: -123.7731
1 mode projection succeeded
New goal: tensor([ 0.1438,  0.5254,  0.5635,  0.8931, -0.0151,  0.6781,  0.8165,  0.8113,
         1.4568,  0.0560,  0.1051,  0.9744, -0.0088, -0.0433, -1.1552],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -137.7368621826172
Adjusted likelihood: -137.7368621826172
Likelihood residual: 0.0
Original likelihood: -140.6820068359375
Adjusted likelihood: -140.6820068359375
Likelihood residual: 0.0
{'index': 140.6820068359375, 'thumb_middle': 137.7368621826172}
Current yaw: tensor([-0.0033, -0.0514, -0.1962], device='cuda:1')
20 thumb_middle
tensor([ 0.1785,  0.5409,  0.5449,  0.9026, -0.0597,  0.7510,  0.6648,  0.9918,
         1.4701,  0.0946,  0.0170,  1.0349, -0.0033, -0.0514, -0.1962,  3.2384],
       device='cuda:1')
Solve time for step 1 8.995469620043878
Current ori: tensor([-0.0033, -0.0514, -0.1962], device='cuda:1')
Index force: tensor([0.5378, 0.5002, 0.5653, 0.5834], device='cuda:1')
tensor([ 1.8059e-01,  5.3111e-01,  5.6445e-01,  8.9370e-01, -1.1500e-01,
         6.5480e-01,  7.5656e-01,  8.1206e-01,  1.4029e+00,  2.6705e-02,
         2.1426e-02,  9.3890e-01, -1.9569e-03, -5.2020e-02, -1.9618e-01,
         3.2266e+00], device='cuda:1')
Solve time for step 2 3.555048472015187
Current ori: tensor([-0.0020, -0.0520, -0.1962], device='cuda:1')
Index force: tensor([0.5001, 0.5569, 0.5738], device='cuda:1')
tensor([ 1.7560e-01,  5.2916e-01,  5.6644e-01,  8.8406e-01, -1.1356e-01,
         6.5194e-01,  7.5431e-01,  7.9271e-01,  1.4087e+00,  4.0144e-02,
         1.0964e-02,  9.3453e-01, -3.0836e-03, -4.9154e-02, -1.9618e-01,
         3.2170e+00], device='cuda:1')
Solve time for step 3 3.3821123160305433
Current ori: tensor([-0.0031, -0.0492, -0.1962], device='cuda:1')
Index force: tensor([0.5475, 0.5665], device='cuda:1')
tensor([ 1.8065e-01,  5.3111e-01,  5.6807e-01,  8.8759e-01, -1.0845e-01,
         6.5455e-01,  7.6378e-01,  7.8904e-01,  1.4061e+00,  2.9866e-02,
         6.3896e-03,  9.3317e-01, -2.5889e-03, -5.2251e-02, -1.9618e-01,
         3.2257e+00], device='cuda:1')
Solve time for step 4 3.395544573024381
Current ori: tensor([-0.0026, -0.0523, -0.1962], device='cuda:1')
Index force: tensor([0.5761], device='cuda:1')
Storing RECOVERY transition: reward=0.0063 (scaled=0.0021), steps=3
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0715
Collected 265 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=1.5622, Q2 Loss=1.5622, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4684
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=0.9432, Q2 Loss=0.9432, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6310
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.1143, Q2 Loss=1.1143, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2452
SAC Update 4/5: Actor Loss=-0.0107, Q1 Loss=1.1992, Q2 Loss=1.1992, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0490
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=1.5725, Q2 Loss=1.5725, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4616

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.7%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (42.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009724
Q1 loss: 1.278260
Q2 loss: 1.278260
Current threshold: -149.5432
Global Scale Offset: 1207.9851
Reward stats: mean=0.0146, std=0.0715, count=265
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.2783, Q2 Loss: 1.2783, Entropy: 0.6929, Mean TD Error: 1.5710, Threshold: -149.5432
Original likelihood: -156.87481689453125
Adjusted likelihood: -156.87481689453125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4976)
Marked last transition as done (final step)
{}

Trial 17
Loaded trajectory sampler
Current yaw: tensor([-0.0020,  0.0147, -0.0243], device='cuda:1')
Current yaw: tensor([-0.0020,  0.0147, -0.0243], device='cuda:1')
1 turn
Sampling time 3.6870765929925255
tensor([ 0.1493,  0.6107,  0.5622,  0.6145, -0.1247,  0.5466,  0.8916,  0.9191,
         1.2146,  0.2675,  0.2712,  1.2180, -0.0020,  0.0147, -0.0243,  0.2069],
       device='cuda:1')
Original likelihood: -122.45117950439453
Adjusted likelihood: -122.45117950439453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5089)
State is out of distribution
Projection step: 0, Loss: 131.9859619140625
Projection step: 1, Loss: 121.58894348144531
Projection step: 2, Loss: 104.26869201660156
Final likelihood: tensor([ -95.2015,  -97.7570,  -83.4924, -100.0507,  -96.7870, -106.3290,
        -112.8132, -157.3046, -105.1268,  -77.3156,  -80.8566, -114.4772,
        -111.5743, -102.4835,  -87.1618, -139.5679])
Final projection likelihood: -104.2687
1 mode projection succeeded
New goal: tensor([ 0.1388,  0.5997,  0.5639,  0.6080, -0.1140,  0.5494,  0.8936,  0.9054,
         1.2300,  0.2851,  0.2603,  1.1902, -0.0014,  0.0147, -0.0092],
       device='cuda:1')
tensor([[0.0038]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -129.49855041503906
Adjusted likelihood: -129.49855041503906
Likelihood residual: 0.0
Original likelihood: -132.78196716308594
Adjusted likelihood: -132.78196716308594
Likelihood residual: 0.0
{'index': 132.78196716308594, 'thumb_middle': 129.49855041503906}
Current yaw: tensor([-0.0020,  0.0147, -0.0243], device='cuda:1')
2 thumb_middle
tensor([ 0.1493,  0.6107,  0.5622,  0.6145, -0.1247,  0.5466,  0.8916,  0.9191,
         1.2146,  0.2675,  0.2712,  1.2180, -0.0020,  0.0147, -0.0243,  0.2069],
       device='cuda:1')
Solve time for step 1 8.888052995025646
Current ori: tensor([-0.0020,  0.0147, -0.0243], device='cuda:1')
Index force: tensor([0.5610, 0.5667, 0.5680, 0.5812], device='cuda:1')
tensor([ 0.1377,  0.6191,  0.5498,  0.5913, -0.2134,  0.5044,  0.8490,  0.8844,
         1.1981,  0.2554,  0.1886,  1.1589, -0.0056,  0.0206, -0.0246,  0.1887],
       device='cuda:1')
Solve time for step 2 3.612746257975232
Current ori: tensor([-0.0056,  0.0206, -0.0246], device='cuda:1')
Index force: tensor([0.5583, 0.5613, 0.5728], device='cuda:1')
tensor([ 0.1308,  0.6114,  0.5533,  0.5906, -0.2254,  0.5179,  0.8413,  0.8797,
         1.2014,  0.2539,  0.1884,  1.1619, -0.0041,  0.0248, -0.0246,  0.1767],
       device='cuda:1')
Solve time for step 3 3.748811313009355
Current ori: tensor([-0.0041,  0.0248, -0.0246], device='cuda:1')
Index force: tensor([0.5528, 0.5644], device='cuda:1')
tensor([ 0.1469,  0.6159,  0.5518,  0.6146, -0.2252,  0.5235,  0.8490,  0.8857,
         1.1818,  0.2626,  0.1868,  1.1744, -0.0034,  0.0159, -0.0246,  0.2067],
       device='cuda:1')
Solve time for step 4 3.6721717590116896
Current ori: tensor([-0.0034,  0.0159, -0.0246], device='cuda:1')
Index force: tensor([0.5484], device='cuda:1')
Storing RECOVERY transition: reward=0.0159 (scaled=0.0159), steps=0
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0714
Collected 266 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.0636, Q2 Loss=1.0636, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8797
SAC Update 2/5: Actor Loss=-0.0110, Q1 Loss=2.1957, Q2 Loss=2.1957, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4203
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.5817, Q2 Loss=1.5817, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1543
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=1.2296, Q2 Loss=1.2296, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9687
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.7498, Q2 Loss=0.7498, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3436

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.0%)
Q1 update: 0.05s (21.6%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (38.6%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009997
Q1 loss: 1.364092
Q2 loss: 1.364092
Current threshold: -149.5427
Global Scale Offset: 1219.4231
Reward stats: mean=0.0146, std=0.0714, count=266
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.3641, Q2 Loss: 1.3641, Entropy: 0.6930, Mean TD Error: 1.1533, Threshold: -149.5427
Original likelihood: -123.0
Adjusted likelihood: -123.0
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5087)
Current yaw: tensor([-0.0015,  0.0118, -0.0402], device='cuda:1')
3 turn
Sampling time 3.726603974995669
tensor([ 0.1537,  0.6044,  0.5784,  0.6079, -0.1498,  0.5668,  0.8980,  0.9041,
         1.2628,  0.2851,  0.2256,  1.1721, -0.0015,  0.0118, -0.0402,  0.2501],
       device='cuda:1')
Original likelihood: -130.98387145996094
Adjusted likelihood: -130.98387145996094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5061)
State is out of distribution
Projection step: 0, Loss: 128.05247497558594
Projection step: 1, Loss: 120.25289916992188
Projection step: 2, Loss: 113.81929016113281
Projection step: 3, Loss: 118.39840698242188
Projection step: 4, Loss: 100.36986541748047
Final likelihood: tensor([ -96.9054,  -92.5107, -108.0925,  -76.7076, -105.4256,  -60.8331,
        -107.6565,  -71.0774, -100.4697, -138.6394, -110.8797, -134.2848,
         -82.2866, -112.7017,  -90.1542, -117.2929])
Final projection likelihood: -100.3699
1 mode projection succeeded
New goal: tensor([ 1.3585e-01,  5.8709e-01,  5.7224e-01,  6.0864e-01, -1.1988e-01,
         5.7722e-01,  9.1187e-01,  8.8246e-01,  1.2763e+00,  2.9916e-01,
         2.2683e-01,  1.1558e+00, -2.4091e-04,  1.3036e-02,  3.5969e-02],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -115.6060562133789
Adjusted likelihood: -115.6060562133789
Likelihood residual: 0.0
Original likelihood: -110.09327697753906
Adjusted likelihood: -110.09327697753906
Likelihood residual: 0.0
{'index': 110.09327697753906, 'thumb_middle': 115.6060562133789}
Current yaw: tensor([-0.0015,  0.0118, -0.0402], device='cuda:1')
4 index
tensor([ 0.1537,  0.6044,  0.5784,  0.6079, -0.1498,  0.5668,  0.8980,  0.9041,
         1.2628,  0.2851,  0.2256,  1.1721, -0.0015,  0.0118, -0.0402,  0.2501],
       device='cuda:1')
Solve time for step 1 10.593856325023808
Current ori: tensor([-0.0015,  0.0118, -0.0402], device='cuda:1')
Middle force: tensor([0.5640, 0.5834, 0.5070, 0.5530], device='cuda:1')
Thumb force: tensor([0.6136, 0.5493, 0.5016, 0.5719], device='cuda:1')
tensor([ 0.1873,  0.5390,  0.5266,  0.5867, -0.1501,  0.5625,  0.9089,  0.8916,
         1.2723,  0.2800,  0.2286,  1.1454, -0.0064,  0.0124, -0.0684,  1.1404],
       device='cuda:1')
Solve time for step 2 4.138788647018373
Current ori: tensor([-0.0064,  0.0124, -0.0684], device='cuda:1')
Middle force: tensor([0.5796, 0.5062, 0.5495], device='cuda:1')
Thumb force: tensor([0.5445, 0.5012, 0.5683], device='cuda:1')
tensor([ 0.1860,  0.5375,  0.5259,  0.5849, -0.1530,  0.5579,  0.9140,  0.8941,
         1.2950,  0.2517,  0.2109,  1.1575, -0.0058,  0.0138, -0.0783,  1.6703],
       device='cuda:1')
Solve time for step 3 3.962323914980516
Current ori: tensor([-0.0058,  0.0138, -0.0783], device='cuda:1')
Middle force: tensor([0.5056, 0.5466], device='cuda:1')
Thumb force: tensor([0.5009, 0.5651], device='cuda:1')
tensor([ 0.1870,  0.5392,  0.5249,  0.5846, -0.1391,  0.5755,  0.9034,  0.8776,
         1.2732,  0.2805,  0.2123,  1.1454, -0.0142,  0.0056, -0.0785,  1.9400],
       device='cuda:1')
Solve time for step 4 3.9859221120132133
Current ori: tensor([-0.0142,  0.0056, -0.0785], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5225], device='cuda:1')
Storing RECOVERY transition: reward=0.0393 (scaled=0.0393), steps=0
Reward stats updated: mean 0.0146 -> 0.0147, std: 0.0713
Collected 267 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.0558, Q2 Loss=1.0558, Entropy=0.6918, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3265
SAC Update 2/5: Actor Loss=-0.0094, Q1 Loss=1.1437, Q2 Loss=1.1437, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4612
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=1.1327, Q2 Loss=1.1327, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2088
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=2.3644, Q2 Loss=2.3644, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1166
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=1.1537, Q2 Loss=1.1537, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2138

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.1%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.06s (20.9%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009993
Q1 loss: 1.370062
Q2 loss: 1.370062
Current threshold: -149.5422
Global Scale Offset: 1229.7958
Reward stats: mean=0.0147, std=0.0713, count=267
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.3701, Q2 Loss: 1.3701, Entropy: 0.6926, Mean TD Error: 1.4654, Threshold: -149.5422
Original likelihood: -129.0478515625
Adjusted likelihood: -129.0478515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5066)
State is out of distribution
Projection step: 0, Loss: 133.01504516601562
Projection step: 1, Loss: 122.64395141601562
Projection step: 2, Loss: 114.91485595703125
Projection step: 3, Loss: 106.5027084350586
Projection step: 4, Loss: 109.30210876464844
Projection step: 5, Loss: 108.21272277832031
Projection step: 6, Loss: 104.72712707519531
Final likelihood: tensor([-106.0858, -125.3470, -124.8852,  -88.4297, -105.1886, -109.9156,
        -116.6670,  -98.6264, -101.5912,  -84.1097, -116.0134,  -72.6098,
        -108.0815, -107.0387, -113.6371,  -97.4076])
Final projection likelihood: -104.7271
1 mode projection succeeded
New goal: tensor([ 0.1152,  0.5766,  0.5735,  0.6072, -0.1045,  0.5826,  0.9144,  0.8481,
         1.2868,  0.3065,  0.2135,  1.1326, -0.0132,  0.0117, -0.2076],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -110.04000091552734
Adjusted likelihood: -110.04000091552734
Likelihood residual: 0.0
Original likelihood: -132.90866088867188
Adjusted likelihood: -132.90866088867188
Likelihood residual: 0.0
{'index': 132.90866088867188, 'thumb_middle': 110.04000091552734}
Current yaw: tensor([-0.0142,  0.0082, -0.0796], device='cuda:1')
5 thumb_middle
tensor([ 0.1317,  0.5970,  0.5680,  0.6070, -0.1456,  0.5750,  0.9054,  0.8795,
         1.2725,  0.2879,  0.2074,  1.1602, -0.0142,  0.0082, -0.0796,  1.9880],
       device='cuda:1')
Solve time for step 1 9.129517013963778
Current ori: tensor([-0.0142,  0.0082, -0.0796], device='cuda:1')
Index force: tensor([0.5977, 0.6017, 0.5909, 0.5926], device='cuda:1')
tensor([ 0.1261,  0.5935,  0.5695,  0.6013, -0.2256,  0.5517,  0.8622,  0.8170,
         1.2320,  0.2878,  0.1392,  1.1160, -0.0139,  0.0118, -0.0797,  1.9762],
       device='cuda:1')
Solve time for step 2 3.6274554869742133
Current ori: tensor([-0.0139,  0.0118, -0.0797], device='cuda:1')
Index force: tensor([0.5942, 0.5859, 0.5874], device='cuda:1')
tensor([ 0.1350,  0.5879,  0.5826,  0.6095, -0.2289,  0.5604,  0.8673,  0.8321,
         1.2437,  0.2922,  0.1106,  1.1079, -0.0119,  0.0068, -0.0797,  1.9924],
       device='cuda:1')
Solve time for step 3 3.4727136850124225
Current ori: tensor([-0.0119,  0.0068, -0.0797], device='cuda:1')
Index force: tensor([0.5762, 0.5787], device='cuda:1')
tensor([ 0.1236,  0.5813,  0.5771,  0.6147, -0.2254,  0.5446,  0.8682,  0.8217,
         1.2543,  0.2914,  0.1223,  1.0800, -0.0101,  0.0138, -0.0797,  1.9778],
       device='cuda:1')
Solve time for step 4 3.2648920139763504
Current ori: tensor([-0.0101,  0.0138, -0.0797], device='cuda:1')
Index force: tensor([0.5719], device='cuda:1')
Storing RECOVERY transition: reward=0.0423 (scaled=0.0423), steps=0
Reward stats updated: mean 0.0147 -> 0.0148, std: 0.0712
Collected 268 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.7985, Q2 Loss=0.7985, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4990
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=2.0456, Q2 Loss=2.0456, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6462
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.8838, Q2 Loss=0.8838, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5281
SAC Update 4/5: Actor Loss=-0.0113, Q1 Loss=2.3028, Q2 Loss=2.3028, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4798
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.9274, Q2 Loss=0.9274, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7222

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (41.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009051
Q1 loss: 1.391602
Q2 loss: 1.391602
Current threshold: -149.5418
Global Scale Offset: 1242.2094
Reward stats: mean=0.0148, std=0.0712, count=268
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.3916, Q2 Loss: 1.3916, Entropy: 0.6928, Mean TD Error: 1.5751, Threshold: -149.5418
Original likelihood: -122.1353988647461
Adjusted likelihood: -122.1353988647461
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5088)
Current yaw: tensor([-0.0087,  0.0151, -0.0826], device='cuda:1')
6 turn
Sampling time 3.608337215031497
tensor([ 0.1212,  0.5778,  0.5782,  0.6174, -0.1650,  0.5981,  0.8953,  0.8475,
         1.3110,  0.3044,  0.1828,  1.1272, -0.0087,  0.0151, -0.0826,  1.9741],
       device='cuda:1')
Original likelihood: -122.60267639160156
Adjusted likelihood: -122.60267639160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5086)
State is out of distribution
Projection step: 0, Loss: 122.46012878417969
Projection step: 1, Loss: 121.95954132080078
Projection step: 2, Loss: 118.86009216308594
Projection step: 3, Loss: 118.47386932373047
Projection step: 4, Loss: 108.98753356933594
Projection step: 5, Loss: 105.65756225585938
Projection step: 6, Loss: 99.45986938476562
Final likelihood: tensor([ -95.8947, -127.2889, -119.4187, -100.7618, -103.4106, -114.8970,
         -71.8528, -110.3486,  -79.0890,  -84.3869,  -83.5609, -122.5734,
        -126.0568,  -90.7639,  -91.7293,  -69.3246])
Final projection likelihood: -99.4599
1 mode projection succeeded
New goal: tensor([ 0.1132,  0.5630,  0.5815,  0.6239, -0.1189,  0.6058,  0.9008,  0.8162,
         1.3048,  0.3007,  0.2000,  1.1302, -0.0071,  0.0159, -0.0515],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -127.3338851928711
Adjusted likelihood: -127.3338851928711
Likelihood residual: 0.0
Original likelihood: -121.53062438964844
Adjusted likelihood: -121.53062438964844
Likelihood residual: 0.0
{'index': 121.53062438964844, 'thumb_middle': 127.3338851928711}
Current yaw: tensor([-0.0087,  0.0151, -0.0826], device='cuda:1')
7 index
tensor([ 0.1212,  0.5778,  0.5782,  0.6174, -0.1650,  0.5981,  0.8953,  0.8475,
         1.3110,  0.3044,  0.1828,  1.1272, -0.0087,  0.0151, -0.0826,  1.9741],
       device='cuda:1')
Solve time for step 1 10.247605754993856
Current ori: tensor([-0.0087,  0.0151, -0.0826], device='cuda:1')
Middle force: tensor([0.5642, 0.5560, 0.5165, 0.5120], device='cuda:1')
Thumb force: tensor([0.5929, 0.6045, 0.5307, 0.5125], device='cuda:1')
tensor([ 0.1636,  0.5130,  0.5335,  0.5994, -0.1590,  0.6042,  0.8973,  0.8270,
         1.3204,  0.2987,  0.1703,  1.1142, -0.0178,  0.0122, -0.1051,  4.0241],
       device='cuda:1')
Solve time for step 2 4.270231091009919
Current ori: tensor([-0.0178,  0.0122, -0.1051], device='cuda:1')
Middle force: tensor([0.5537, 0.5154, 0.5111], device='cuda:1')
Thumb force: tensor([0.5977, 0.5291, 0.5116], device='cuda:1')
tensor([ 0.1663,  0.5134,  0.5337,  0.5996, -0.1639,  0.6027,  0.9065,  0.8273,
         1.3239,  0.2991,  0.1610,  1.1247, -0.0194,  0.0128, -0.1169,  5.2418],
       device='cuda:1')
Solve time for step 3 3.7758644089917652
Current ori: tensor([-0.0194,  0.0128, -0.1169], device='cuda:1')
Middle force: tensor([0.5456, 0.5719], device='cuda:1')
Thumb force: tensor([0.5447, 0.5890], device='cuda:1')
tensor([ 0.1635,  0.5128,  0.5321,  0.5989, -0.1661,  0.6045,  0.9091,  0.8279,
         1.3202,  0.3015,  0.1606,  1.1370, -0.0164,  0.0125, -0.1032,  6.0248],
       device='cuda:1')
Solve time for step 4 3.7122630489757285
Current ori: tensor([-0.0164,  0.0125, -0.1032], device='cuda:1')
Middle force: tensor([0.5416], device='cuda:1')
Thumb force: tensor([0.5689], device='cuda:1')
Storing RECOVERY transition: reward=0.0140 (scaled=0.0140), steps=0
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0710
Collected 269 transitions for RL
SAC Update 1/5: Actor Loss=-0.0118, Q1 Loss=1.4905, Q2 Loss=1.4905, Entropy=0.6919, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2297
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.7362, Q2 Loss=0.7362, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5232
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.8453, Q2 Loss=0.8453, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5029
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8130, Q2 Loss=0.8130, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0613
SAC Update 5/5: Actor Loss=-0.0109, Q1 Loss=1.0695, Q2 Loss=1.0695, Entropy=0.6918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9626

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.9%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.1%)
Actor update: 0.08s (37.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009331
Q1 loss: 0.990895
Q2 loss: 0.990895
Current threshold: -149.5416
Global Scale Offset: 1255.9471
Reward stats: mean=0.0148, std=0.0710, count=269
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 0.9909, Q2 Loss: 0.9909, Entropy: 0.6925, Mean TD Error: 1.0559, Threshold: -149.5416
Original likelihood: -142.07437133789062
Adjusted likelihood: -142.07437133789062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5024)
State is out of distribution
Projection step: 0, Loss: 136.97984313964844
Projection step: 1, Loss: 132.02207946777344
Projection step: 2, Loss: 129.40036010742188
Projection step: 3, Loss: 124.92091369628906
Projection step: 4, Loss: 114.30139923095703
Projection step: 5, Loss: 123.23417663574219
Projection step: 6, Loss: 108.98789978027344
Projection step: 7, Loss: 114.37953186035156
Projection step: 8, Loss: 108.03192901611328
Projection step: 9, Loss: 99.46987915039062
Final likelihood: tensor([-125.6967, -110.7996,  -84.8134,  -82.8175,  -95.2120,  -79.8690,
        -106.1249,  -96.5116,  -89.3900, -110.8018, -111.7794, -100.5554,
        -120.3606, -100.4044,  -74.2317, -102.1501])
Final projection likelihood: -99.4699
1 mode projection succeeded
New goal: tensor([ 1.0143e-01,  5.5598e-01,  5.7439e-01,  6.3253e-01, -1.1460e-01,
         6.0873e-01,  8.8932e-01,  7.8904e-01,  1.3186e+00,  2.9001e-01,
         1.9564e-01,  1.1281e+00, -1.7554e-02,  1.9444e-02, -9.4687e-04],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -122.19136810302734
Adjusted likelihood: -122.19136810302734
Likelihood residual: 0.0
Original likelihood: -124.39453887939453
Adjusted likelihood: -124.39453887939453
Likelihood residual: 0.0
{'index': 124.39453887939453, 'thumb_middle': 122.19136810302734}
Current yaw: tensor([-0.0179,  0.0202, -0.0971], device='cuda:1')
8 thumb_middle
tensor([ 0.1068,  0.5686,  0.5748,  0.6205, -0.1763,  0.6047,  0.9017,  0.8225,
         1.3249,  0.3013,  0.1753,  1.1196, -0.0179,  0.0202, -0.0971,  6.2068],
       device='cuda:1')
Solve time for step 1 9.073260090022814
Current ori: tensor([-0.0179,  0.0202, -0.0971], device='cuda:1')
Index force: tensor([0.5870, 0.6097, 0.6002, 0.6087], device='cuda:1')
tensor([ 0.0846,  0.5673,  0.5610,  0.6085, -0.2375,  0.5744,  0.8488,  0.7681,
         1.2780,  0.2744,  0.1226,  1.0981, -0.0177,  0.0336, -0.0971,  6.1619],
       device='cuda:1')
Solve time for step 2 3.558420990011655
Current ori: tensor([-0.0177,  0.0336, -0.0971], device='cuda:1')
Index force: tensor([0.6041, 0.5961, 0.6051], device='cuda:1')
tensor([ 0.0932,  0.5677,  0.5641,  0.6177, -0.2387,  0.5803,  0.8484,  0.7637,
         1.2816,  0.2700,  0.1116,  1.0946, -0.0172,  0.0286, -0.0971,  6.1764],
       device='cuda:1')
Solve time for step 3 3.412196636025328
Current ori: tensor([-0.0172,  0.0286, -0.0971], device='cuda:1')
Index force: tensor([0.5847, 0.5957], device='cuda:1')
tensor([ 0.0985,  0.5674,  0.5661,  0.6247, -0.2372,  0.5802,  0.8490,  0.7633,
         1.2789,  0.2697,  0.1101,  1.0941, -0.0166,  0.0255, -0.0971,  6.1857],
       device='cuda:1')
Solve time for step 4 3.402653960045427
Current ori: tensor([-0.0166,  0.0255, -0.0971], device='cuda:1')
Index force: tensor([0.5784], device='cuda:1')
Storing RECOVERY transition: reward=0.0218 (scaled=0.0218), steps=0
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0709
Collected 270 transitions for RL
SAC Update 1/5: Actor Loss=-0.0067, Q1 Loss=0.6771, Q2 Loss=0.6771, Entropy=0.6915, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1738
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=1.6366, Q2 Loss=1.6366, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0538
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.7486, Q2 Loss=0.7486, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1616
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=1.3360, Q2 Loss=1.3360, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9702
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=2.1997, Q2 Loss=2.1997, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7263

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.6%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (43.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008383
Q1 loss: 1.319599
Q2 loss: 1.319599
Current threshold: -149.5417
Global Scale Offset: 1266.2693
Reward stats: mean=0.0148, std=0.0709, count=270
----------------------------------------------
SAC Update - Actor Loss: -0.0084, Q1 Loss: 1.3196, Q2 Loss: 1.3196, Entropy: 0.6927, Mean TD Error: 1.8171, Threshold: -149.5417
Original likelihood: -144.39462280273438
Adjusted likelihood: -144.39462280273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5016)
Current yaw: tensor([-0.0145,  0.0249, -0.1050], device='cuda:1')
9 turn
Sampling time 3.7904756810166873
tensor([ 0.0995,  0.5603,  0.5728,  0.6328, -0.1776,  0.6195,  0.8812,  0.7818,
         1.3424,  0.2909,  0.1646,  1.1229, -0.0145,  0.0249, -0.1050,  6.2031],
       device='cuda:1')
Original likelihood: -141.3295135498047
Adjusted likelihood: -141.3295135498047
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5026)
Solve time for step 1 14.210804078029469
Current ori: tensor([-0.0145,  0.0249, -0.1050], device='cuda:1')
Middle force: tensor([0.5688, 1.7781, 2.3155, 0.5636, 0.8081, 0.5775, 0.5210, 0.7824, 0.5018,
        0.5154, 0.8222, 0.6243], device='cuda:1')
Thumb force: tensor([0.9606, 1.5903, 0.7416, 0.5938, 0.5069, 1.2391, 1.3597, 1.7098, 0.5222,
        0.6603, 0.5993, 0.5997], device='cuda:1')
Index force: tensor([0.6034, 0.8250, 0.5783, 0.6276, 0.5330, 0.9664, 0.5281, 0.5694, 0.6165,
        0.6619, 0.8110, 0.6041], device='cuda:1')
Storing NORMAL transition: reward=0.0160 (scaled=0.0160), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0708
Collected 271 transitions for RL
SAC Update 1/5: Actor Loss=-0.0130, Q1 Loss=1.4216, Q2 Loss=1.4216, Entropy=0.6923, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8507
SAC Update 2/5: Actor Loss=-0.0127, Q1 Loss=1.3055, Q2 Loss=1.3055, Entropy=0.6922, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6879
SAC Update 3/5: Actor Loss=-0.0124, Q1 Loss=1.5355, Q2 Loss=1.5355, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3456
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.7056, Q2 Loss=0.7056, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8692
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8331, Q2 Loss=0.8331, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3797

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.06s (20.0%)
Actor update: 0.11s (39.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010568
Q1 loss: 1.160256
Q2 loss: 1.160256
Current threshold: -149.5417
Global Scale Offset: 1280.0549
Reward stats: mean=0.0148, std=0.0708, count=271
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.1603, Q2 Loss: 1.1603, Entropy: 0.6925, Mean TD Error: 1.0266, Threshold: -149.5417
tensor([ 0.0605,  0.5597,  0.5676,  0.5719, -0.1463,  0.5189,  0.7777,  0.8087,
         1.4156,  0.2593,  0.0809,  1.1988, -0.0178,  0.0479, -0.1228,  6.1428],
       device='cuda:1')
Original likelihood: -149.17919921875
Adjusted likelihood: -149.17919921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5001)
State is out of distribution
Projection step: 0, Loss: 149.52090454101562
Projection step: 1, Loss: 143.41598510742188
Projection step: 2, Loss: 153.06053161621094
Projection step: 3, Loss: 145.04019165039062
Projection step: 4, Loss: 142.74285888671875
Projection step: 5, Loss: 142.43035888671875
Projection step: 6, Loss: 142.43887329101562
Projection step: 7, Loss: 138.4965057373047
Projection step: 8, Loss: 135.81085205078125
Projection step: 9, Loss: 138.2614288330078
Projection step: 10, Loss: 134.2642822265625
Projection step: 11, Loss: 129.46807861328125
Projection step: 12, Loss: 125.93943786621094
Projection step: 13, Loss: 124.58909606933594
Projection step: 14, Loss: 116.08148956298828
Projection step: 15, Loss: 112.3106689453125
Projection step: 16, Loss: 106.09584045410156
Projection step: 17, Loss: 102.22481536865234
Final likelihood: tensor([ -92.1278, -118.7218, -106.0085,  -96.6285,  -94.4725,  -92.9070,
         -90.5882, -105.9771,  -95.3742, -103.3197, -114.0130, -105.2914,
         -89.4615, -100.7858, -130.2599,  -99.6602])
Final projection likelihood: -102.2248
1 mode projection succeeded
New goal: tensor([ 0.0587,  0.5679,  0.5356,  0.6280, -0.1007,  0.5169,  0.8079,  0.8326,
         1.3609,  0.2364,  0.1401,  1.1905, -0.0229,  0.0353, -0.6032],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0066]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -130.86424255371094
Adjusted likelihood: -130.86424255371094
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 130.86424255371094}
Current yaw: tensor([-0.0178,  0.0479, -0.1228], device='cuda:1')
10 thumb_middle
tensor([ 0.0605,  0.5597,  0.5676,  0.5719, -0.1463,  0.5189,  0.7777,  0.8087,
         1.4156,  0.2593,  0.0809,  1.1988, -0.0178,  0.0479, -0.1228,  6.1428],
       device='cuda:1')
Solve time for step 1 9.096061085001566
Current ori: tensor([-0.0178,  0.0479, -0.1228], device='cuda:1')
Index force: tensor([0.5672, 0.5805, 0.5990, 0.6088], device='cuda:1')
tensor([ 0.0648,  0.5780,  0.5311,  0.6005, -0.1968,  0.5002,  0.7750,  0.8093,
         1.3301,  0.2177,  0.0652,  1.1682, -0.0202,  0.0449, -0.1228,  6.1558],
       device='cuda:1')
Solve time for step 2 3.6199302750173956
Current ori: tensor([-0.0202,  0.0449, -0.1228], device='cuda:1')
Index force: tensor([0.5738, 0.5928, 0.6027], device='cuda:1')
tensor([ 0.0638,  0.5795,  0.5215,  0.6133, -0.1994,  0.5016,  0.7803,  0.8152,
         1.3275,  0.2173,  0.0660,  1.1637, -0.0194,  0.0456, -0.1228,  6.1573],
       device='cuda:1')
Solve time for step 3 3.5140366310370155
Current ori: tensor([-0.0194,  0.0456, -0.1228], device='cuda:1')
Index force: tensor([0.5813, 0.5931], device='cuda:1')
tensor([ 0.0613,  0.5779,  0.5196,  0.6167, -0.2008,  0.5028,  0.7800,  0.8132,
         1.3297,  0.2133,  0.0662,  1.1636, -0.0187,  0.0471, -0.1228,  6.1549],
       device='cuda:1')
Solve time for step 4 3.443963790021371
Current ori: tensor([-0.0187,  0.0471, -0.1228], device='cuda:1')
Index force: tensor([0.5784], device='cuda:1')
Storing RECOVERY transition: reward=0.0072 (scaled=0.0072), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0706
Collected 272 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=0.7881, Q2 Loss=0.7881, Entropy=0.6925, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2917
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.7705, Q2 Loss=0.7705, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7408
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.4124, Q2 Loss=1.4124, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8640
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=0.9699, Q2 Loss=0.9699, Entropy=0.6916, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2772
SAC Update 5/5: Actor Loss=-0.0119, Q1 Loss=1.1141, Q2 Loss=1.1141, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4874

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010297
Q1 loss: 1.011017
Q2 loss: 1.011017
Current threshold: -149.5418
Global Scale Offset: 1294.8432
Reward stats: mean=0.0148, std=0.0706, count=272
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.0110, Q2 Loss: 1.0110, Entropy: 0.6924, Mean TD Error: 0.5322, Threshold: -149.5418
Original likelihood: -154.5670166015625
Adjusted likelihood: -154.5670166015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4985)
State is out of distribution
Projection step: 0, Loss: 154.8550262451172
Projection step: 1, Loss: 155.74493408203125
Projection step: 2, Loss: 153.87158203125
Projection step: 3, Loss: 143.2437744140625
Projection step: 4, Loss: 140.66310119628906
Projection step: 5, Loss: 134.23928833007812
Projection step: 6, Loss: 135.00045776367188
Projection step: 7, Loss: 127.51654052734375
Projection step: 8, Loss: 125.78754425048828
Projection step: 9, Loss: 116.73896789550781
Projection step: 10, Loss: 115.587158203125
Projection step: 11, Loss: 110.03822326660156
Projection step: 12, Loss: 117.42491149902344
Projection step: 13, Loss: 105.025390625
Projection step: 14, Loss: 106.89791107177734
Projection step: 15, Loss: 101.0110092163086
Final likelihood: tensor([-114.1407,  -96.1761,  -91.4343,  -93.8985, -110.6749, -102.7264,
        -105.8386,  -91.0249,  -87.9163, -115.8044, -110.9224,  -95.8514,
         -95.5210, -100.2210, -111.8185,  -92.2067])
Final projection likelihood: -101.0110
1 mode projection succeeded
New goal: tensor([ 0.0620,  0.5627,  0.5220,  0.6597, -0.1100,  0.5297,  0.8248,  0.8239,
         1.3379,  0.2270,  0.1624,  1.1856, -0.0206,  0.0349, -0.6747],
       device='cuda:1')
tensor([[0.0019]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -135.08018493652344
Adjusted likelihood: -135.08018493652344
Likelihood residual: 0.0
Original likelihood: -136.94088745117188
Adjusted likelihood: -136.94088745117188
Likelihood residual: 0.0
{'index': 136.94088745117188, 'thumb_middle': 135.08018493652344}
Current yaw: tensor([-0.0160,  0.0481, -0.1300], device='cuda:1')
11 thumb_middle
tensor([ 0.0589,  0.5684,  0.5262,  0.6256, -0.1412,  0.5447,  0.8133,  0.8325,
         1.3974,  0.2417,  0.1205,  1.1922, -0.0160,  0.0481, -0.1300,  6.1719],
       device='cuda:1')
Solve time for step 1 8.868607888987754
Current ori: tensor([-0.0160,  0.0481, -0.1300], device='cuda:1')
Index force: tensor([0.6001, 0.6024, 0.5998, 0.5539], device='cuda:1')
tensor([ 0.0548,  0.5689,  0.5161,  0.6349, -0.2098,  0.5088,  0.7901,  0.8071,
         1.3184,  0.2106,  0.1020,  1.1691, -0.0149,  0.0513, -0.1298,  6.1585],
       device='cuda:1')
Solve time for step 2 3.6140183500247076
Current ori: tensor([-0.0149,  0.0513, -0.1298], device='cuda:1')
Index force: tensor([0.5923, 0.5934, 0.5483], device='cuda:1')
tensor([ 0.0751,  0.5741,  0.5207,  0.6507, -0.2043,  0.5164,  0.7959,  0.8029,
         1.3080,  0.2037,  0.0933,  1.1615, -0.0154,  0.0393, -0.1298,  6.1905],
       device='cuda:1')
Solve time for step 3 3.4254671529633924
Current ori: tensor([-0.0154,  0.0393, -0.1298], device='cuda:1')
Index force: tensor([0.5848, 0.5431], device='cuda:1')
tensor([ 0.0659,  0.5670,  0.5149,  0.6641, -0.2064,  0.5141,  0.7945,  0.8017,
         1.3117,  0.2078,  0.0929,  1.1637, -0.0124,  0.0449, -0.1298,  6.1821],
       device='cuda:1')
Solve time for step 4 3.3962721480056643
Current ori: tensor([-0.0124,  0.0449, -0.1298], device='cuda:1')
Index force: tensor([0.5666], device='cuda:1')
Storing RECOVERY transition: reward=0.0256 (scaled=0.0256), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0705
Collected 273 transitions for RL
SAC Update 1/5: Actor Loss=-0.0096, Q1 Loss=1.1052, Q2 Loss=1.1052, Entropy=0.6881, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0218
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=1.0620, Q2 Loss=1.0620, Entropy=0.6880, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9998
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=0.9211, Q2 Loss=0.9211, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6576
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=0.8870, Q2 Loss=0.8870, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2217
SAC Update 5/5: Actor Loss=-0.0131, Q1 Loss=1.1797, Q2 Loss=1.1797, Entropy=0.6919, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4619

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (41.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010131
Q1 loss: 1.031000
Q2 loss: 1.031000
Current threshold: -149.5416
Global Scale Offset: 1312.3878
Reward stats: mean=0.0148, std=0.0705, count=273
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0310, Q2 Loss: 1.0310, Entropy: 0.6908, Mean TD Error: 0.6725, Threshold: -149.5416
Original likelihood: -140.6392822265625
Adjusted likelihood: -140.6392822265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5027)
Current yaw: tensor([-0.0191,  0.0413, -0.1479], device='cuda:1')
12 turn
Sampling time 3.5822948150453158
tensor([ 0.0706,  0.5876,  0.5046,  0.6371, -0.1417,  0.5572,  0.8285,  0.8219,
         1.3754,  0.2313,  0.1445,  1.1881, -0.0191,  0.0413, -0.1479,  6.2050],
       device='cuda:1')
Original likelihood: -134.28636169433594
Adjusted likelihood: -134.28636169433594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5046)
State is out of distribution
Projection step: 0, Loss: 140.02906799316406
Projection step: 1, Loss: 128.6295928955078
Projection step: 2, Loss: 128.20767211914062
Projection step: 3, Loss: 120.60981750488281
Projection step: 4, Loss: 111.09773254394531
Projection step: 5, Loss: 112.5886001586914
Projection step: 6, Loss: 108.65591430664062
Projection step: 7, Loss: 112.2375717163086
Projection step: 8, Loss: 103.29510498046875
Final likelihood: tensor([ -99.0612, -101.6504,  -99.7618, -101.7121, -119.2068, -101.2068,
         -98.6449,  -98.7309, -114.2244,  -93.9784, -107.7029,  -99.8922,
        -104.2548,  -97.3493,  -95.5596, -119.7852])
Final projection likelihood: -103.2951
1 mode projection succeeded
New goal: tensor([ 0.0673,  0.5739,  0.5067,  0.6647, -0.1229,  0.5467,  0.8412,  0.8104,
         1.3456,  0.2259,  0.1672,  1.1922, -0.0209,  0.0348, -0.4024],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -115.78398895263672
Adjusted likelihood: -115.78398895263672
Likelihood residual: 0.0
Original likelihood: -132.99627685546875
Adjusted likelihood: -132.99627685546875
Likelihood residual: 0.0
{'index': 132.99627685546875, 'thumb_middle': 115.78398895263672}
Current yaw: tensor([-0.0191,  0.0413, -0.1479], device='cuda:1')
13 thumb_middle
tensor([ 0.0706,  0.5876,  0.5046,  0.6371, -0.1417,  0.5572,  0.8285,  0.8219,
         1.3754,  0.2313,  0.1445,  1.1881, -0.0191,  0.0413, -0.1479,  6.2050],
       device='cuda:1')
Solve time for step 1 8.988924207049422
Current ori: tensor([-0.0191,  0.0413, -0.1479], device='cuda:1')
Index force: tensor([0.5658, 0.5950, 0.5818, 0.5940], device='cuda:1')
tensor([ 0.0571,  0.5889,  0.4838,  0.6485, -0.2172,  0.5360,  0.8094,  0.7906,
         1.3209,  0.2010,  0.0942,  1.1653, -0.0182,  0.0496, -0.1479,  6.1797],
       device='cuda:1')
Solve time for step 2 3.6869497449952178
Current ori: tensor([-0.0182,  0.0496, -0.1479], device='cuda:1')
Index force: tensor([0.5841, 0.5733, 0.5849], device='cuda:1')
tensor([ 0.0647,  0.5794,  0.5003,  0.6566, -0.2156,  0.5368,  0.8120,  0.7795,
         1.2985,  0.2106,  0.1075,  1.1714, -0.0157,  0.0453, -0.1479,  6.1943],
       device='cuda:1')
Solve time for step 3 3.4769456650246866
Current ori: tensor([-0.0157,  0.0453, -0.1479], device='cuda:1')
Index force: tensor([0.5364, 0.5511], device='cuda:1')
tensor([ 0.0752,  0.5979,  0.4874,  0.6510, -0.2130,  0.5407,  0.8100,  0.7846,
         1.3069,  0.2062,  0.0899,  1.1578, -0.0207,  0.0388, -0.1479,  6.2044],
       device='cuda:1')
Solve time for step 4 3.4449280459666625
Current ori: tensor([-0.0207,  0.0388, -0.1479], device='cuda:1')
Index force: tensor([0.5388], device='cuda:1')
Storing RECOVERY transition: reward=0.0000 (scaled=0.0000), steps=0
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0704
Collected 274 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.7975, Q2 Loss=1.7975, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3002
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=0.8400, Q2 Loss=0.8400, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7327
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.8152, Q2 Loss=0.8152, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2162
SAC Update 4/5: Actor Loss=-0.0117, Q1 Loss=1.3474, Q2 Loss=1.3474, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0172
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8499, Q2 Loss=0.8499, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4285

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009274
Q1 loss: 1.129980
Q2 loss: 1.129980
Current threshold: -149.5414
Global Scale Offset: 1327.1555
Reward stats: mean=0.0147, std=0.0704, count=274
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.1300, Q2 Loss: 1.1300, Entropy: 0.6928, Mean TD Error: 0.9390, Threshold: -149.5414
Original likelihood: -138.5098876953125
Adjusted likelihood: -138.5098876953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5033)
State is out of distribution
Projection step: 0, Loss: 152.76895141601562
Projection step: 1, Loss: 142.6470184326172
Projection step: 2, Loss: 138.09909057617188
Projection step: 3, Loss: 142.43832397460938
Projection step: 4, Loss: 129.94473266601562
Projection step: 5, Loss: 127.22601318359375
Projection step: 6, Loss: 121.97509765625
Projection step: 7, Loss: 124.15560150146484
Projection step: 8, Loss: 124.3302230834961
Projection step: 9, Loss: 115.93702697753906
Projection step: 10, Loss: 116.33794403076172
Projection step: 11, Loss: 112.76614379882812
Projection step: 12, Loss: 113.82136535644531
Projection step: 13, Loss: 107.86141204833984
Projection step: 14, Loss: 116.53865051269531
Projection step: 15, Loss: 106.29881286621094
Projection step: 16, Loss: 100.70426940917969
Final likelihood: tensor([ -89.0272, -111.2969,  -92.7241,  -90.1885, -100.6338, -112.3042,
         -87.8247, -108.4316, -104.6597,  -89.6898, -108.9200, -107.9483,
         -86.9961, -104.2413, -105.4964, -110.8858])
Final projection likelihood: -100.7043
1 mode projection succeeded
New goal: tensor([ 0.0710,  0.5623,  0.5288,  0.6655, -0.1102,  0.5540,  0.8465,  0.7786,
         1.3329,  0.2252,  0.1837,  1.1841, -0.0196,  0.0313, -0.5382],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -133.22569274902344
Adjusted likelihood: -133.22569274902344
Likelihood residual: 0.0
Original likelihood: -130.8243408203125
Adjusted likelihood: -130.8243408203125
Likelihood residual: 0.0
{'index': 130.8243408203125, 'thumb_middle': 133.22569274902344}
Current yaw: tensor([-0.0160,  0.0428, -0.1480], device='cuda:1')
14 index
tensor([ 0.0680,  0.5772,  0.5084,  0.6530, -0.1594,  0.5758,  0.8397,  0.7997,
         1.3810,  0.2265,  0.1420,  1.1917, -0.0160,  0.0428, -0.1480,  6.2069],
       device='cuda:1')
Solve time for step 1 10.53651736897882
Current ori: tensor([-0.0160,  0.0428, -0.1480], device='cuda:1')
Middle force: tensor([0.5834, 0.5643, 0.5235, 0.5407], device='cuda:1')
Thumb force: tensor([0.5445, 0.5341, 0.6199, 0.5674], device='cuda:1')
tensor([ 0.1123,  0.5064,  0.4749,  0.6403, -0.1703,  0.5669,  0.8555,  0.7898,
         1.3792,  0.2375,  0.1604,  1.1623, -0.0189,  0.0486, -0.1656,  5.6437],
       device='cuda:1')
Solve time for step 2 4.2664964239811525
Current ori: tensor([-0.0189,  0.0486, -0.1656], device='cuda:1')
Middle force: tensor([0.5610, 0.5214, 0.5362], device='cuda:1')
Thumb force: tensor([0.5298, 0.6148, 0.5616], device='cuda:1')
tensor([ 0.1140,  0.5044,  0.4769,  0.6371, -0.1666,  0.5658,  0.8596,  0.7915,
         1.3774,  0.2453,  0.1506,  1.1668, -0.0219,  0.0464, -0.1943,  5.5812],
       device='cuda:1')
Solve time for step 3 4.13247756898636
Current ori: tensor([-0.0219,  0.0464, -0.1943], device='cuda:1')
Middle force: tensor([0.5098, 0.5085], device='cuda:1')
Thumb force: tensor([0.5802, 0.5237], device='cuda:1')
tensor([ 0.1140,  0.5042,  0.4759,  0.6397, -0.1612,  0.5777,  0.8509,  0.7785,
         1.3799,  0.2384,  0.1413,  1.1722, -0.0256,  0.0434, -0.1798,  5.7795],
       device='cuda:1')
Solve time for step 4 3.94308739900589
Current ori: tensor([-0.0256,  0.0434, -0.1798], device='cuda:1')
Middle force: tensor([0.5036], device='cuda:1')
Thumb force: tensor([0.5653], device='cuda:1')
Storing RECOVERY transition: reward=0.0551 (scaled=0.0551), steps=0
Reward stats updated: mean 0.0147 -> 0.0149, std: 0.0703
Collected 275 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=0.9295, Q2 Loss=0.9295, Entropy=0.6926, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3655
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=1.0049, Q2 Loss=1.0049, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4875
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.7249, Q2 Loss=0.7249, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3108
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=1.6813, Q2 Loss=1.6813, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5463
SAC Update 5/5: Actor Loss=-0.0121, Q1 Loss=1.0988, Q2 Loss=1.0988, Entropy=0.6909, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5157

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.3%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (17.4%)
Actor update: 0.09s (38.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009189
Q1 loss: 1.087883
Q2 loss: 1.087883
Current threshold: -149.5412
Global Scale Offset: 1341.2302
Reward stats: mean=0.0149, std=0.0703, count=275
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.0879, Q2 Loss: 1.0879, Entropy: 0.6924, Mean TD Error: 1.2452, Threshold: -149.5412
Original likelihood: -163.79647827148438
Adjusted likelihood: -163.79647827148438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4958)
Current yaw: tensor([-0.0257,  0.0493, -0.2043], device='cuda:1')
15 turn
Sampling time 3.793997988977935
tensor([ 0.0613,  0.5627,  0.5175,  0.6607, -0.1702,  0.5680,  0.8567,  0.7861,
         1.3780,  0.2551,  0.1438,  1.1750, -0.0257,  0.0493, -0.2043,  5.9013],
       device='cuda:1')
Original likelihood: -141.2733154296875
Adjusted likelihood: -141.2733154296875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5025)
Solve time for step 1 14.012140651000664
Current ori: tensor([-0.0257,  0.0493, -0.2043], device='cuda:1')
Middle force: tensor([0.5634, 1.8130, 2.2379, 0.5541, 0.7614, 0.4822, 1.0239, 1.0075, 0.7361,
        0.5835, 0.7118, 0.7423], device='cuda:1')
Thumb force: tensor([1.0393, 1.6045, 0.8735, 0.5812, 0.5489, 0.5924, 1.1342, 0.5640, 0.5541,
        0.5969, 0.5528, 0.5441], device='cuda:1')
Index force: tensor([0.6338, 0.8319, 0.5575, 0.5893, 0.5277, 0.6053, 0.5313, 0.7784, 0.5379,
        0.5878, 0.5529, 0.8595], device='cuda:1')
Storing NORMAL transition: reward=-0.0225 (scaled=-0.0225), steps=1
Reward stats updated: mean 0.0149 -> 0.0148, std: 0.0702
Collected 276 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6566, Q2 Loss=0.6566, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1266
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=4.6715, Q2 Loss=4.6715, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5674
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=1.0754, Q2 Loss=1.0754, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5809
SAC Update 4/5: Actor Loss=-0.0116, Q1 Loss=1.4790, Q2 Loss=1.4790, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3630
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=1.7834, Q2 Loss=1.7834, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5882

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.4%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.08s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008827
Q1 loss: 1.933201
Q2 loss: 1.933201
Current threshold: -149.5411
Global Scale Offset: 1352.1436
Reward stats: mean=0.0148, std=0.0702, count=276
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.9332, Q2 Loss: 1.9332, Entropy: 0.6928, Mean TD Error: 2.4452, Threshold: -149.5411
tensor([ 1.0372e-01,  5.1339e-01,  5.7730e-01,  7.2696e-01, -2.1918e-01,
         5.5120e-01,  7.6796e-01,  8.1259e-01,  1.3580e+00,  2.3344e-01,
         2.5956e-01,  1.3720e+00, -4.5774e-03,  9.9494e-02, -1.8802e-01,
         5.0757e+00], device='cuda:1')
Original likelihood: -291.6439514160156
Adjusted likelihood: -291.6439514160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4582)
State is out of distribution
Projection step: 0, Loss: 289.9471435546875
Projection step: 1, Loss: 283.6863708496094
Projection step: 2, Loss: 288.15869140625
Projection step: 3, Loss: 274.6541748046875
Projection step: 4, Loss: 270.45758056640625
Projection step: 5, Loss: 259.677734375
Projection step: 6, Loss: 257.6904296875
Projection step: 7, Loss: 247.58509826660156
Projection step: 8, Loss: 242.37918090820312
Projection step: 9, Loss: 239.9811248779297
Projection step: 10, Loss: 240.78292846679688
Projection step: 11, Loss: 228.0261688232422
Projection step: 12, Loss: 232.52188110351562
Projection step: 13, Loss: 217.25241088867188
Projection step: 14, Loss: 220.4984130859375
Projection step: 15, Loss: 219.2157440185547
Projection step: 16, Loss: 212.83489990234375
Projection step: 17, Loss: 206.0467529296875
Projection step: 18, Loss: 205.33518981933594
Projection step: 19, Loss: 207.5468292236328
Projection step: 20, Loss: 198.46652221679688
Projection step: 21, Loss: 196.09814453125
Projection step: 22, Loss: 200.78990173339844
Projection step: 23, Loss: 199.1981201171875
Projection step: 24, Loss: 191.21554565429688
Final likelihood: tensor([-149.7964, -190.0048, -186.7373, -192.5645, -202.5698, -202.9645,
        -187.0752, -236.3420, -184.4815, -211.3868, -181.7660, -177.4196,
        -232.7885, -180.8750, -228.2521, -189.7107])
Final projection likelihood: -195.9209
1 mode projection failed, trying anyway
New goal: tensor([ 0.0482,  0.5286,  0.5863,  0.6182, -0.1833,  0.5981,  0.7657,  0.7657,
         1.3268,  0.1559,  0.2219,  1.2651, -0.0206,  0.0723,  0.5177],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -208.70724487304688
Adjusted likelihood: -208.70724487304688
Likelihood residual: 0.0
Original likelihood: -176.718505859375
Adjusted likelihood: -176.718505859375
Likelihood residual: 0.0
{'index': 176.718505859375, 'thumb_middle': 208.70724487304688}
Current yaw: tensor([-0.0046,  0.0995, -0.1880], device='cuda:1')
16 index
tensor([ 1.0372e-01,  5.1339e-01,  5.7730e-01,  7.2696e-01, -2.1918e-01,
         5.5120e-01,  7.6796e-01,  8.1259e-01,  1.3580e+00,  2.3344e-01,
         2.5956e-01,  1.3720e+00, -4.5774e-03,  9.9494e-02, -1.8802e-01,
         5.0757e+00], device='cuda:1')
Solve time for step 1 10.30795180099085
Current ori: tensor([-0.0046,  0.0995, -0.1880], device='cuda:1')
Middle force: tensor([0.5020, 0.5193, 0.6003, 0.5196], device='cuda:1')
Thumb force: tensor([0.5396, 0.5664, 0.5102, 0.5484], device='cuda:1')
tensor([ 0.0998,  0.4624,  0.5309,  0.6089, -0.2023,  0.5880,  0.7451,  0.7555,
         1.3836,  0.2054,  0.2355,  1.3192, -0.0304,  0.0934, -0.2372,  5.9843],
       device='cuda:1')
Solve time for step 2 4.1075083909672685
Current ori: tensor([-0.0304,  0.0934, -0.2372], device='cuda:1')
Middle force: tensor([0.5433, 0.5663, 0.5174], device='cuda:1')
Thumb force: tensor([0.5742, 0.6020, 0.5930], device='cuda:1')
tensor([ 0.0934,  0.4656,  0.5272,  0.5920, -0.2003,  0.6015,  0.7346,  0.7373,
         1.3923,  0.2001,  0.2271,  1.3065, -0.0405,  0.0935, -0.2598, -5.5887],
       device='cuda:1')
Solve time for step 3 4.069576306035742
Current ori: tensor([-0.0405,  0.0935, -0.2598], device='cuda:1')
Middle force: tensor([0.5613, 0.5143], device='cuda:1')
Thumb force: tensor([0.5924, 0.5880], device='cuda:1')
tensor([ 0.0915,  0.4629,  0.5304,  0.5888, -0.1968,  0.6026,  0.7346,  0.7383,
         1.4024,  0.1826,  0.2145,  1.3194, -0.0398,  0.0911, -0.2549, -4.8729],
       device='cuda:1')
Solve time for step 4 4.022102364979219
Current ori: tensor([-0.0398,  0.0911, -0.2549], device='cuda:1')
Middle force: tensor([0.5403], device='cuda:1')
Thumb force: tensor([0.6238], device='cuda:1')
Storing RECOVERY transition: reward=0.0692 (scaled=0.0692), steps=1
Reward stats updated: mean 0.0148 -> 0.0150, std: 0.0702
Collected 277 transitions for RL
SAC Update 1/5: Actor Loss=-0.0134, Q1 Loss=1.7053, Q2 Loss=1.7053, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3355
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.8266, Q2 Loss=0.8266, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6345
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.0138, Q2 Loss=1.0138, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3941
SAC Update 4/5: Actor Loss=-0.0096, Q1 Loss=0.8584, Q2 Loss=0.8584, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2145
SAC Update 5/5: Actor Loss=-0.0131, Q1 Loss=1.2799, Q2 Loss=1.2799, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4284

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (41.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010641
Q1 loss: 1.136797
Q2 loss: 1.136797
Current threshold: -149.5408
Global Scale Offset: 1366.4756
Reward stats: mean=0.0150, std=0.0702, count=277
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.1368, Q2 Loss: 1.1368, Entropy: 0.6928, Mean TD Error: 0.8014, Threshold: -149.5408
Original likelihood: -208.462158203125
Adjusted likelihood: -208.462158203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4828)
State is out of distribution
Projection step: 0, Loss: 222.9222869873047
Projection step: 1, Loss: 198.40176391601562
Projection step: 2, Loss: 199.505126953125
Projection step: 3, Loss: 194.76010131835938
Projection step: 4, Loss: 193.74566650390625
Projection step: 5, Loss: 197.04493713378906
Projection step: 6, Loss: 195.76287841796875
Projection step: 7, Loss: 181.73486328125
Projection step: 8, Loss: 182.11569213867188
Projection step: 9, Loss: 189.41273498535156
Projection step: 10, Loss: 180.2638397216797
Projection step: 11, Loss: 182.5745849609375
Projection step: 12, Loss: 178.5138397216797
Projection step: 13, Loss: 176.58580017089844
Projection step: 14, Loss: 183.82766723632812
Projection step: 15, Loss: 187.78883361816406
Projection step: 16, Loss: 176.86578369140625
Projection step: 17, Loss: 184.7559814453125
Projection step: 18, Loss: 185.06643676757812
Projection step: 19, Loss: 173.82083129882812
Projection step: 20, Loss: 177.71365356445312
Projection step: 21, Loss: 180.61166381835938
Projection step: 22, Loss: 174.41595458984375
Projection step: 23, Loss: 170.50181579589844
Projection step: 24, Loss: 185.0718994140625
Final likelihood: tensor([-188.7947, -163.2382, -157.9049, -178.1612, -192.4136, -166.0535,
        -163.1553, -182.1546, -173.6991, -177.7911, -172.5584, -161.1432,
        -197.8674, -167.3092, -177.5592, -140.0446])
Final projection likelihood: -172.4905
1 mode projection failed, trying anyway
New goal: tensor([ 0.0294,  0.5480,  0.5510,  0.6097, -0.1513,  0.5813,  0.6922,  0.7715,
         1.3563,  0.1370,  0.1869,  1.2043, -0.0436,  0.0713,  0.0349],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -191.038818359375
Adjusted likelihood: -191.038818359375
Likelihood residual: 0.0
Original likelihood: -180.03318786621094
Adjusted likelihood: -180.03318786621094
Likelihood residual: 0.0
{'index': 180.03318786621094, 'thumb_middle': 191.038818359375}
Current yaw: tensor([-0.0376,  0.0912, -0.2584], device='cuda:1')
17 index
tensor([ 0.0398,  0.5206,  0.5749,  0.6124, -0.1979,  0.5971,  0.7379,  0.7489,
         1.3987,  0.1877,  0.2155,  1.3256, -0.0376,  0.0912, -0.2584, -4.7238],
       device='cuda:1')
Solve time for step 1 10.54928330500843
Current ori: tensor([-0.0376,  0.0912, -0.2584], device='cuda:1')
Middle force: tensor([0.5473, 0.5481, 0.6078, 0.5946], device='cuda:1')
Thumb force: tensor([0.5134, 0.5941, 0.5221, 0.5806], device='cuda:1')
tensor([ 0.0683,  0.4750,  0.5005,  0.5845, -0.1960,  0.6245,  0.6962,  0.7498,
         1.4154,  0.1714,  0.2171,  1.2701, -0.0529,  0.0925, -0.3055, -4.6152],
       device='cuda:1')
Solve time for step 2 4.245219194970559
Current ori: tensor([-0.0529,  0.0925, -0.3055], device='cuda:1')
Middle force: tensor([0.5464, 0.6038, 0.5907], device='cuda:1')
Thumb force: tensor([0.5870, 0.5204, 0.5768], device='cuda:1')
tensor([ 0.0694,  0.4794,  0.4963,  0.5792, -0.1886,  0.6390,  0.6817,  0.7444,
         1.4259,  0.1578,  0.2015,  1.2664, -0.0619,  0.0886, -0.3353, -4.8082],
       device='cuda:1')
Solve time for step 3 4.0953132639988326
Current ori: tensor([-0.0619,  0.0886, -0.3353], device='cuda:1')
Middle force: tensor([0.5312, 0.5359], device='cuda:1')
Thumb force: tensor([0.6188, 0.6096], device='cuda:1')
tensor([ 0.0691,  0.4792,  0.4948,  0.5813, -0.1883,  0.6437,  0.6772,  0.7379,
         1.4264,  0.1651,  0.1956,  1.2752, -0.0681,  0.0894, -0.3641, -5.0270],
       device='cuda:1')
Solve time for step 4 4.072088843968231
Current ori: tensor([-0.0681,  0.0894, -0.3641], device='cuda:1')
Middle force: tensor([0.5253], device='cuda:1')
Thumb force: tensor([0.5851], device='cuda:1')
Storing RECOVERY transition: reward=0.1744 (scaled=0.1744), steps=1
Reward stats updated: mean 0.0150 -> 0.0155, std: 0.0707
Collected 278 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=1.2373, Q2 Loss=1.2373, Entropy=0.6917, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9575
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8620, Q2 Loss=0.8620, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6953
SAC Update 3/5: Actor Loss=-0.0121, Q1 Loss=1.9922, Q2 Loss=1.9922, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9813
SAC Update 4/5: Actor Loss=-0.0119, Q1 Loss=1.2259, Q2 Loss=1.2259, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7442
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=1.0452, Q2 Loss=1.0452, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4120

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010386
Q1 loss: 1.272520
Q2 loss: 1.272520
Current threshold: -149.5405
Global Scale Offset: 1383.6080
Reward stats: mean=0.0155, std=0.0707, count=278
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.2725, Q2 Loss: 1.2725, Entropy: 0.6927, Mean TD Error: 1.1581, Threshold: -149.5405
Original likelihood: -213.1099395751953
Adjusted likelihood: -213.1099395751953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4817)
Current yaw: tensor([-0.0682,  0.0953, -0.3721], device='cuda:1')
18 turn
Sampling time 3.656172684044577
tensor([ 0.0206,  0.5379,  0.5349,  0.6023, -0.1964,  0.6382,  0.6809,  0.7357,
         1.4235,  0.1785,  0.2014,  1.2903, -0.0682,  0.0953, -0.3721, -5.0523],
       device='cuda:1')
Original likelihood: -219.55642700195312
Adjusted likelihood: -219.55642700195312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4798)
State is out of distribution
Projection step: 0, Loss: 224.05490112304688
Projection step: 1, Loss: 215.26329040527344
Projection step: 2, Loss: 218.33917236328125
Projection step: 3, Loss: 206.95770263671875
Projection step: 4, Loss: 203.9998779296875
Projection step: 5, Loss: 215.1851806640625
Projection step: 6, Loss: 211.38552856445312
Projection step: 7, Loss: 216.09523010253906
Projection step: 8, Loss: 208.3410186767578
Projection step: 9, Loss: 215.34994506835938
Projection step: 10, Loss: 225.60586547851562
Projection step: 11, Loss: 209.4766845703125
Projection step: 12, Loss: 203.0490264892578
Projection step: 13, Loss: 209.4141387939453
Projection step: 14, Loss: 219.25643920898438
Projection step: 15, Loss: 217.60275268554688
Projection step: 16, Loss: 241.26589965820312
Projection step: 17, Loss: 229.87486267089844
Projection step: 18, Loss: 221.17684936523438
Projection step: 19, Loss: 220.78628540039062
Projection step: 20, Loss: 235.09213256835938
Projection step: 21, Loss: 212.4974822998047
Projection step: 22, Loss: 204.38912963867188
Projection step: 23, Loss: 213.28884887695312
Projection step: 24, Loss: 222.79766845703125
Final likelihood: tensor([-212.7454, -219.3054, -245.9157, -217.3273, -226.3910, -218.2971,
        -224.1347, -194.9178, -206.5004, -223.8314, -203.2216, -229.0504,
        -379.0819, -202.8550, -241.6061, -246.4827])
Final projection likelihood: -230.7290
1 mode projection failed, trying anyway
New goal: tensor([ 0.0120,  0.5456,  0.5491,  0.5901, -0.1577,  0.6285,  0.6037,  0.7470,
         1.3780,  0.0954,  0.1602,  1.2380, -0.0692,  0.0832, -0.0200],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -190.37673950195312
Adjusted likelihood: -190.37673950195312
Likelihood residual: 0.0
Original likelihood: -191.78433227539062
Adjusted likelihood: -191.78433227539062
Likelihood residual: 0.0
{'index': 191.78433227539062, 'thumb_middle': 190.37673950195312}
Current yaw: tensor([-0.0682,  0.0953, -0.3721], device='cuda:1')
19 thumb_middle
tensor([ 0.0206,  0.5379,  0.5349,  0.6023, -0.1964,  0.6382,  0.6809,  0.7357,
         1.4235,  0.1785,  0.2014,  1.2903, -0.0682,  0.0953, -0.3721, -5.0523],
       device='cuda:1')
Solve time for step 1 9.203027367999312
Current ori: tensor([-0.0682,  0.0953, -0.3721], device='cuda:1')
Index force: tensor([0.5831, 0.5890, 0.5881, 0.6048], device='cuda:1')
tensor([ 0.0376,  0.5485,  0.5396,  0.5875, -0.2188,  0.6518,  0.6174,  0.7382,
         1.3690,  0.0903,  0.1498,  1.2512, -0.0595,  0.1157, -0.3721, -5.2961],
       device='cuda:1')
Solve time for step 2 3.7589787140022963
Current ori: tensor([-0.0595,  0.1157, -0.3721], device='cuda:1')
Index force: tensor([0.5814, 0.5820, 0.6011], device='cuda:1')
tensor([ 0.0459,  0.5540,  0.5396,  0.5843, -0.2290,  0.6535,  0.6015,  0.7357,
         1.3912,  0.0881,  0.1475,  1.2476, -0.0508,  0.1238, -0.3719, -5.4385],
       device='cuda:1')
Solve time for step 3 3.5848598550073802
Current ori: tensor([-0.0508,  0.1238, -0.3719], device='cuda:1')
Index force: tensor([0.5763, 0.5951], device='cuda:1')
tensor([ 0.0547,  0.5710,  0.5406,  0.5804, -0.2357,  0.6524,  0.5926,  0.7313,
         1.3990,  0.0902,  0.1514,  1.2490, -0.0695,  0.1338, -0.4042, -5.4290],
       device='cuda:1')
Solve time for step 4 3.381932372052688
Current ori: tensor([-0.0695,  0.1338, -0.4042], device='cuda:1')
Index force: tensor([0.5790], device='cuda:1')
Storing RECOVERY transition: reward=0.0688 (scaled=0.0688), steps=0
Reward stats updated: mean 0.0155 -> 0.0157, std: 0.0706
Collected 279 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=1.1853, Q2 Loss=1.1853, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6122
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.7194, Q2 Loss=0.7194, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9246
SAC Update 3/5: Actor Loss=-0.0125, Q1 Loss=1.2457, Q2 Loss=1.2457, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5919
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.2619, Q2 Loss=1.2619, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8031
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=0.9451, Q2 Loss=0.9451, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3818

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.6%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (20.5%)
Actor update: 0.11s (42.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009612
Q1 loss: 1.071467
Q2 loss: 1.071467
Current threshold: -149.5401
Global Scale Offset: 1394.1724
Reward stats: mean=0.0157, std=0.0706, count=279
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.0715, Q2 Loss: 1.0715, Entropy: 0.6928, Mean TD Error: 1.2627, Threshold: -149.5401
Original likelihood: -230.62774658203125
Adjusted likelihood: -230.62774658203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4768)
State is out of distribution
Projection step: 0, Loss: 208.60321044921875
Projection step: 1, Loss: 239.61529541015625
Projection step: 2, Loss: 223.88034057617188
Projection step: 3, Loss: 221.143310546875
Projection step: 4, Loss: 212.06817626953125
Projection step: 5, Loss: 208.62380981445312
Projection step: 6, Loss: 231.68228149414062
Projection step: 7, Loss: 208.68746948242188
Projection step: 8, Loss: 213.17398071289062
Projection step: 9, Loss: 206.5702667236328
Projection step: 10, Loss: 203.53448486328125
Projection step: 11, Loss: 212.7227783203125
Projection step: 12, Loss: 209.42575073242188
Projection step: 13, Loss: 203.4937744140625
Projection step: 14, Loss: 203.42068481445312
Projection step: 15, Loss: 208.83938598632812
Projection step: 16, Loss: 221.59202575683594
Projection step: 17, Loss: 207.9484100341797
Projection step: 18, Loss: 233.69944763183594
Projection step: 19, Loss: 222.13473510742188
Projection step: 20, Loss: 214.5242156982422
Projection step: 21, Loss: 208.87928771972656
Projection step: 22, Loss: 217.4358673095703
Projection step: 23, Loss: 192.22576904296875
Projection step: 24, Loss: 225.96328735351562
Final likelihood: tensor([-274.2641, -208.5323, -249.3954, -253.7481, -249.2634, -239.2052,
        -244.9536, -237.4112, -156.3144, -242.3432, -255.2910, -263.7370,
        -217.1279, -196.1093, -246.2650, -209.7959])
Final projection likelihood: -233.9848
1 mode projection failed, trying anyway
New goal: tensor([ 0.0431,  0.5671,  0.5510,  0.5992, -0.1697,  0.6471,  0.5944,  0.7994,
         1.4300,  0.1175,  0.1942,  1.2138, -0.0842,  0.1078, -0.0863],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0020]], device='cuda:1')
Original likelihood: -216.43328857421875
Adjusted likelihood: -216.43328857421875
Likelihood residual: 0.0
Original likelihood: -228.09463500976562
Adjusted likelihood: -228.09463500976562
Likelihood residual: 0.0
{'index': 228.09463500976562, 'thumb_middle': 216.43328857421875}
Current yaw: tensor([-0.0840,  0.1192, -0.4513], device='cuda:1')
20 thumb_middle
tensor([ 0.0644,  0.5650,  0.5612,  0.6168, -0.2111,  0.6574,  0.5968,  0.7393,
         1.4827,  0.1366,  0.1888,  1.2553, -0.0840,  0.1192, -0.4513, -5.1119],
       device='cuda:1')
Solve time for step 1 9.033990903990343
Current ori: tensor([-0.0840,  0.1192, -0.4513], device='cuda:1')
Index force: tensor([0.5542, 0.6032, 0.6004, 0.5001], device='cuda:1')
tensor([ 0.0372,  0.5898,  0.5372,  0.5928, -0.2423,  0.6582,  0.5541,  0.7611,
         1.4232,  0.0937,  0.1858,  1.2372, -0.1003,  0.1493, -0.4964, -5.2738],
       device='cuda:1')
Solve time for step 2 3.5349256269983016
Current ori: tensor([-0.1003,  0.1493, -0.4964], device='cuda:1')
Index force: tensor([0.5471, 0.5898, 0.5904], device='cuda:1')
tensor([ 0.0136,  0.6215,  0.5791,  0.6136, -0.2456,  0.6576,  0.5477,  0.7567,
         1.4394,  0.0916,  0.1921,  1.2299, -0.1405,  0.1661, -0.5890, -5.3352],
       device='cuda:1')
Solve time for step 3 3.422241580032278
Current ori: tensor([-0.1405,  0.1661, -0.5890], device='cuda:1')
Index force: tensor([0.5775, 0.5829], device='cuda:1')
tensor([-0.0227,  0.6761,  0.6020,  0.6113, -0.2411,  0.6589,  0.5682,  0.7715,
         1.4692,  0.0993,  0.1818,  1.2246, -0.2824,  0.2718, -0.6360, -4.1563],
       device='cuda:1')
Solve time for step 4 3.292400265985634
Current ori: tensor([-0.2824,  0.2718, -0.6360], device='cuda:1')
Index force: tensor([0.5587], device='cuda:1')
Storing RECOVERY transition: reward=-0.3917 (scaled=-0.3917), steps=0
Reward stats updated: mean 0.0157 -> 0.0143, std: 0.0746
Collected 280 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.9064, Q2 Loss=0.9064, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3886
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=0.9796, Q2 Loss=0.9796, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2294
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=1.5643, Q2 Loss=1.5643, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4644
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=1.5091, Q2 Loss=1.5091, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1026
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.4672, Q2 Loss=1.4672, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8691

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.6%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (37.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009734
Q1 loss: 1.285300
Q2 loss: 1.285300
Current threshold: -149.5398
Global Scale Offset: 1405.3094
Reward stats: mean=0.0143, std=0.0746, count=280
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.2853, Q2 Loss: 1.2853, Entropy: 0.6929, Mean TD Error: 1.6108, Threshold: -149.5398
Original likelihood: -1585.01953125
Adjusted likelihood: -1585.01953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1538)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 18
Loaded trajectory sampler
Current yaw: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
Current yaw: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
1 turn
Sampling time 3.60477134300163
tensor([ 0.1183,  0.6192,  0.5609,  0.5335, -0.1112,  0.5225,  0.9087,  0.9025,
         1.1885,  0.3113,  0.2831,  1.2158, -0.0027,  0.0145, -0.0438,  0.1688],
       device='cuda:1')
Original likelihood: -97.15495300292969
Adjusted likelihood: -97.15495300292969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5149)
Solve time for step 1 13.888544802030083
Current ori: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
Middle force: tensor([1.4207, 0.4936, 0.5128, 0.5632, 0.5278, 0.5014, 0.5651, 0.4790, 0.5260,
        0.5911, 0.5523, 0.5074], device='cuda:1')
Thumb force: tensor([0.8286, 0.5142, 0.9901, 1.2873, 0.5425, 0.5647, 2.0539, 0.5279, 0.8418,
        0.6018, 0.5308, 0.5607], device='cuda:1')
Index force: tensor([0.8186, 0.9911, 0.5388, 0.5431, 0.5805, 0.7411, 0.5754, 0.7867, 0.6145,
        0.4977, 0.5635, 0.5404], device='cuda:1')
Storing NORMAL transition: reward=-0.0056 (scaled=-0.0056), steps=1
Reward stats updated: mean 0.0143 -> 0.0142, std: 0.0745
Collected 281 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.6943, Q2 Loss=0.6943, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4099
SAC Update 2/5: Actor Loss=-0.0135, Q1 Loss=1.5087, Q2 Loss=1.5087, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0858
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=1.1562, Q2 Loss=1.1562, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8772
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=0.8861, Q2 Loss=0.8861, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6159
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.3446, Q2 Loss=1.3446, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1174

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009901
Q1 loss: 1.117963
Q2 loss: 1.117963
Current threshold: -149.5396
Global Scale Offset: 1418.6674
Reward stats: mean=0.0142, std=0.0745, count=281
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.1180, Q2 Loss: 1.1180, Entropy: 0.6927, Mean TD Error: 1.0212, Threshold: -149.5396
tensor([ 0.0295,  0.5765,  0.5365,  0.5324, -0.1665,  0.5761,  0.8046,  0.7754,
         1.2928,  0.2818,  0.3231,  1.0494, -0.0210,  0.0588, -0.0417,  0.1944],
       device='cuda:1')
Original likelihood: -178.99868774414062
Adjusted likelihood: -178.99868774414062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4917)
State is out of distribution
Projection step: 0, Loss: 174.0714111328125
Projection step: 1, Loss: 171.43722534179688
Projection step: 2, Loss: 177.57077026367188
Projection step: 3, Loss: 168.35568237304688
Projection step: 4, Loss: 162.52993774414062
Projection step: 5, Loss: 159.2496337890625
Projection step: 6, Loss: 156.83575439453125
Projection step: 7, Loss: 150.94232177734375
Projection step: 8, Loss: 144.5100860595703
Projection step: 9, Loss: 139.70477294921875
Projection step: 10, Loss: 135.26881408691406
Projection step: 11, Loss: 132.01748657226562
Projection step: 12, Loss: 127.62084197998047
Projection step: 13, Loss: 126.27734375
Projection step: 14, Loss: 120.42317199707031
Projection step: 15, Loss: 116.32373809814453
Projection step: 16, Loss: 112.27379608154297
Projection step: 17, Loss: 108.07423400878906
Projection step: 18, Loss: 103.7281494140625
Final likelihood: tensor([-114.7016, -100.9018, -101.2765,  -96.2905, -106.0933,  -95.3621,
        -103.5733,  -98.4578, -104.4384, -100.7520, -110.4122, -104.7044,
        -105.9611, -106.1784, -108.2999, -102.2471])
Final projection likelihood: -103.7281
1 mode projection succeeded
New goal: tensor([ 0.0481,  0.5391,  0.5823,  0.5687, -0.1124,  0.5341,  0.8066,  0.8087,
         1.3188,  0.1923,  0.2121,  1.1499, -0.0271,  0.0422, -0.2806],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -131.89523315429688
Adjusted likelihood: -131.89523315429688
Likelihood residual: 0.0
Original likelihood: -130.75079345703125
Adjusted likelihood: -130.75079345703125
Likelihood residual: 0.0
{'index': 130.75079345703125, 'thumb_middle': 131.89523315429688}
Current yaw: tensor([-0.0210,  0.0588, -0.0417], device='cuda:1')
2 index
tensor([ 0.0295,  0.5765,  0.5365,  0.5324, -0.1665,  0.5761,  0.8046,  0.7754,
         1.2928,  0.2818,  0.3231,  1.0494, -0.0210,  0.0588, -0.0417,  0.1944],
       device='cuda:1')
Solve time for step 1 10.798391998047009
Current ori: tensor([-0.0210,  0.0588, -0.0417], device='cuda:1')
Middle force: tensor([0.5593, 0.5343, 0.5231, 0.5471], device='cuda:1')
Thumb force: tensor([0.5235, 0.5259, 0.5528, 0.5821], device='cuda:1')
tensor([ 0.0908,  0.4844,  0.5255,  0.5397, -0.1504,  0.5790,  0.8068,  0.7918,
         1.3499,  0.1964,  0.2610,  1.0784, -0.0235,  0.0471, -0.0738,  1.9896],
       device='cuda:1')
Solve time for step 2 4.039855167036876
Current ori: tensor([-0.0235,  0.0471, -0.0738], device='cuda:1')
Middle force: tensor([0.5326, 0.5206, 0.5430], device='cuda:1')
Thumb force: tensor([0.5213, 0.5483, 0.5765], device='cuda:1')
tensor([ 0.0937,  0.4819,  0.5284,  0.5431, -0.1419,  0.5772,  0.8149,  0.7963,
         1.3655,  0.1652,  0.2340,  1.1029, -0.0219,  0.0407, -0.0792,  2.8217],
       device='cuda:1')
Solve time for step 3 4.1697731540189125
Current ori: tensor([-0.0219,  0.0407, -0.0792], device='cuda:1')
Middle force: tensor([0.5030, 0.5668], device='cuda:1')
Thumb force: tensor([0.5590, 0.6115], device='cuda:1')
tensor([ 0.0945,  0.4802,  0.5314,  0.5434, -0.1335,  0.5704,  0.8249,  0.8136,
         1.3525,  0.1817,  0.2196,  1.1300, -0.0186,  0.0342, -0.0969,  3.1238],
       device='cuda:1')
Solve time for step 4 4.056437885970809
Current ori: tensor([-0.0186,  0.0342, -0.0969], device='cuda:1')
Middle force: tensor([0.5384], device='cuda:1')
Thumb force: tensor([0.5426], device='cuda:1')
Storing RECOVERY transition: reward=0.0562 (scaled=0.0562), steps=1
Reward stats updated: mean 0.0142 -> 0.0143, std: 0.0744
Collected 282 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6607, Q2 Loss=0.6607, Entropy=0.6929, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1987
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8953, Q2 Loss=0.8953, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2279
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=1.1080, Q2 Loss=1.1080, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9964
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.9764, Q2 Loss=0.9764, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7911
SAC Update 5/5: Actor Loss=-0.0069, Q1 Loss=0.6587, Q2 Loss=0.6587, Entropy=0.6913, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4523

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.06s (19.3%)
Q2 update: 0.06s (19.3%)
Actor update: 0.12s (41.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007784
Q1 loss: 0.859797
Q2 loss: 0.859797
Current threshold: -149.5394
Global Scale Offset: 1432.4881
Reward stats: mean=0.0143, std=0.0744, count=282
----------------------------------------------
SAC Update - Actor Loss: -0.0078, Q1 Loss: 0.8598, Q2 Loss: 0.8598, Entropy: 0.6926, Mean TD Error: 1.1333, Threshold: -149.5394
Original likelihood: -114.50471496582031
Adjusted likelihood: -114.50471496582031
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5097)
State is out of distribution
Projection step: 0, Loss: 114.02230834960938
Projection step: 1, Loss: 107.19036865234375
Projection step: 2, Loss: 105.30699157714844
Projection step: 3, Loss: 98.29257202148438
Final likelihood: tensor([-100.4753,  -95.1840,  -97.7362,  -94.6309, -103.2152,  -94.2543,
         -97.1465,  -97.7819, -100.2710,  -99.6556,  -95.9865,  -99.8367,
        -100.0716,  -99.2781, -104.1216,  -93.0358])
Final projection likelihood: -98.2926
1 mode projection succeeded
New goal: tensor([ 0.0496,  0.5399,  0.5823,  0.5564, -0.1233,  0.5672,  0.8139,  0.8132,
         1.3470,  0.1853,  0.1984,  1.1506, -0.0220,  0.0359, -0.0368],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -129.64581298828125
Adjusted likelihood: -129.64581298828125
Likelihood residual: 0.0
Original likelihood: -115.56378173828125
Adjusted likelihood: -115.56378173828125
Likelihood residual: 0.0
{'index': 115.56378173828125, 'thumb_middle': 129.64581298828125}
Current yaw: tensor([-0.0215,  0.0378, -0.0963], device='cuda:1')
3 index
tensor([ 0.0430,  0.5446,  0.5758,  0.5647, -0.1385,  0.5749,  0.8181,  0.8071,
         1.3519,  0.1913,  0.2159,  1.1383, -0.0215,  0.0378, -0.0963,  3.1417],
       device='cuda:1')
Solve time for step 1 10.331009162997361
Current ori: tensor([-0.0215,  0.0378, -0.0963], device='cuda:1')
Middle force: tensor([0.5114, 0.5725, 0.5319, 0.5945], device='cuda:1')
Thumb force: tensor([0.5132, 0.5745, 0.6284, 0.6035], device='cuda:1')
tensor([ 0.0943,  0.4836,  0.5317,  0.5366, -0.1412,  0.5726,  0.8235,  0.8194,
         1.3748,  0.1684,  0.1935,  1.1398, -0.0267,  0.0379, -0.1162,  3.1000],
       device='cuda:1')
Solve time for step 2 4.100634397997055
Current ori: tensor([-0.0267,  0.0379, -0.1162], device='cuda:1')
Middle force: tensor([0.5390, 0.5460, 0.5643], device='cuda:1')
Thumb force: tensor([0.5681, 0.5696, 0.5821], device='cuda:1')
tensor([ 0.0951,  0.4838,  0.5314,  0.5326, -0.1426,  0.5748,  0.8187,  0.8197,
         1.3787,  0.1738,  0.1853,  1.1388, -0.0305,  0.0395, -0.1354,  2.8602],
       device='cuda:1')
Solve time for step 3 3.983769159996882
Current ori: tensor([-0.0305,  0.0395, -0.1354], device='cuda:1')
Middle force: tensor([0.5481, 0.5324], device='cuda:1')
Thumb force: tensor([0.5115, 0.5417], device='cuda:1')
tensor([ 0.0921,  0.4823,  0.5319,  0.5308, -0.1443,  0.5750,  0.8177,  0.8188,
         1.3790,  0.1733,  0.1861,  1.1426, -0.0297,  0.0405, -0.1266,  2.4388],
       device='cuda:1')
Solve time for step 4 3.9465238520060666
Current ori: tensor([-0.0297,  0.0405, -0.1266], device='cuda:1')
Middle force: tensor([0.5087], device='cuda:1')
Thumb force: tensor([0.5334], device='cuda:1')
Storing RECOVERY transition: reward=0.1026 (scaled=0.1026), steps=1
Reward stats updated: mean 0.0143 -> 0.0147, std: 0.0744
Collected 283 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=1.0497, Q2 Loss=1.0497, Entropy=0.6928, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4462
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=1.0367, Q2 Loss=1.0367, Entropy=0.6921, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1237
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=0.9537, Q2 Loss=0.9537, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6521
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.7261, Q2 Loss=0.7261, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7803
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=1.9160, Q2 Loss=1.9160, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2904

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.06s (19.3%)
Q2 update: 0.06s (19.2%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009578
Q1 loss: 1.136436
Q2 loss: 1.136436
Current threshold: -149.5392
Global Scale Offset: 1445.6506
Reward stats: mean=0.0147, std=0.0744, count=283
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.1364, Q2 Loss: 1.1364, Entropy: 0.6928, Mean TD Error: 1.0585, Threshold: -149.5392
Original likelihood: -124.98678588867188
Adjusted likelihood: -124.98678588867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5068)
Current yaw: tensor([-0.0287,  0.0428, -0.1438], device='cuda:1')
4 turn
Sampling time 3.599125284992624
tensor([ 0.0403,  0.5467,  0.5764,  0.5523, -0.1481,  0.5675,  0.8231,  0.8273,
         1.3742,  0.1934,  0.1810,  1.1535, -0.0287,  0.0428, -0.1438,  2.3026],
       device='cuda:1')
Original likelihood: -121.34147644042969
Adjusted likelihood: -121.34147644042969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5078)
Solve time for step 1 14.293355125002563
Current ori: tensor([-0.0287,  0.0428, -0.1438], device='cuda:1')
Middle force: tensor([0.5029, 0.5101, 0.5602, 0.4939, 0.5163, 1.0266, 0.5766, 0.5405, 0.5551,
        1.0957, 0.5435, 0.5900], device='cuda:1')
Thumb force: tensor([0.5123, 0.5415, 0.8589, 0.6135, 0.8524, 0.9471, 0.5482, 0.5820, 1.0414,
        0.5732, 0.6425, 0.5290], device='cuda:1')
Index force: tensor([0.6576, 0.6787, 0.5926, 0.8064, 0.6529, 0.6867, 0.6020, 0.6034, 0.5453,
        0.5991, 0.6300, 0.5712], device='cuda:1')
Storing NORMAL transition: reward=0.1094 (scaled=0.1094), steps=1
Reward stats updated: mean 0.0147 -> 0.0150, std: 0.0745
Collected 284 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=0.8678, Q2 Loss=0.8678, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2515
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8558, Q2 Loss=0.8558, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0112
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=0.8988, Q2 Loss=0.8988, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4815
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=0.6456, Q2 Loss=0.6456, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7615
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=1.2770, Q2 Loss=1.2770, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0457

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (19.6%)
Actor update: 0.12s (42.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008935
Q1 loss: 0.909016
Q2 loss: 0.909016
Current threshold: -149.5394
Global Scale Offset: 1461.4382
Reward stats: mean=0.0150, std=0.0745, count=284
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9090, Q2 Loss: 0.9090, Entropy: 0.6927, Mean TD Error: 0.7103, Threshold: -149.5394
tensor([ 0.0547,  0.5211,  0.6177,  0.5662, -0.1377,  0.5551,  0.8136,  0.9199,
         1.3961,  0.1564,  0.1658,  1.1331, -0.0224,  0.0352, -0.2528,  2.4380],
       device='cuda:1')
Original likelihood: -110.49708557128906
Adjusted likelihood: -110.49708557128906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5106)
Solve time for step 2 5.6391687419964
Current ori: tensor([-0.0224,  0.0352, -0.2528], device='cuda:1')
Middle force: tensor([0.5090, 0.5636, 0.5027, 0.5143, 1.0113, 0.5746, 0.5390, 0.5534, 1.0830,
        0.5455, 0.5878], device='cuda:1')
Thumb force: tensor([0.5433, 0.8376, 0.6179, 0.8417, 0.9335, 0.5465, 0.5792, 1.0272, 0.5690,
        0.6315, 0.5278], device='cuda:1')
Index force: tensor([0.6724, 0.5894, 0.8255, 0.6558, 0.6808, 0.5991, 0.6005, 0.5440, 0.5959,
        0.6262, 0.5694], device='cuda:1')
Storing NORMAL transition: reward=-0.0469 (scaled=-0.0469), steps=1
Reward stats updated: mean 0.0150 -> 0.0148, std: 0.0745
Collected 285 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7017, Q2 Loss=0.7017, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3331
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.7923, Q2 Loss=1.7923, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8068
SAC Update 3/5: Actor Loss=-0.0133, Q1 Loss=1.8883, Q2 Loss=1.8883, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5983
SAC Update 4/5: Actor Loss=-0.0108, Q1 Loss=1.2203, Q2 Loss=1.2203, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0912
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=0.9586, Q2 Loss=0.9586, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8446

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.0%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (39.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009700
Q1 loss: 1.312228
Q2 loss: 1.312228
Current threshold: -149.5394
Global Scale Offset: 1479.9193
Reward stats: mean=0.0148, std=0.0745, count=285
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.3122, Q2 Loss: 1.3122, Entropy: 0.6926, Mean TD Error: 1.3348, Threshold: -149.5394
tensor([ 2.3791e-04,  4.6500e-01,  6.5360e-01,  5.3699e-01, -8.1590e-02,
         5.5843e-01,  8.0224e-01,  1.0489e+00,  1.3766e+00,  2.1872e-02,
         1.9950e-01,  1.1587e+00,  1.2943e-02, -7.8292e-03, -2.0409e-01,
         3.2058e+00], device='cuda:1')
Original likelihood: -125.0369873046875
Adjusted likelihood: -125.0369873046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5066)
State is out of distribution
Projection step: 0, Loss: 122.98970031738281
Projection step: 1, Loss: 122.68017578125
Projection step: 2, Loss: 117.10536193847656
Projection step: 3, Loss: 117.52400207519531
Projection step: 4, Loss: 114.70358276367188
Projection step: 5, Loss: 108.8952407836914
Projection step: 6, Loss: 110.86605834960938
Projection step: 7, Loss: 106.402099609375
Projection step: 8, Loss: 107.66231536865234
Projection step: 9, Loss: 98.90592193603516
Final likelihood: tensor([-106.3343,  -92.9855,  -94.6184,  -90.6267,  -89.1156, -106.1486,
        -106.9322,  -92.8450, -102.6565, -101.2378, -107.3455,  -99.3074,
         -99.1333, -105.7770,  -93.1265,  -94.3044])
Final projection likelihood: -98.9059
1 mode projection succeeded
New goal: tensor([ 0.0056,  0.4949,  0.6128,  0.5896, -0.0644,  0.5180,  0.8254,  0.9750,
         1.3750,  0.1263,  0.1812,  1.1924,  0.0129, -0.0054, -0.7999],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -114.96732330322266
Adjusted likelihood: -114.96732330322266
Likelihood residual: 0.0
Original likelihood: -132.20578002929688
Adjusted likelihood: -132.20578002929688
Likelihood residual: 0.0
{'index': 132.20578002929688, 'thumb_middle': 114.96732330322266}
Current yaw: tensor([ 0.0129, -0.0078, -0.2041], device='cuda:1')
5 thumb_middle
tensor([ 2.3791e-04,  4.6500e-01,  6.5360e-01,  5.3699e-01, -8.1590e-02,
         5.5843e-01,  8.0224e-01,  1.0489e+00,  1.3766e+00,  2.1872e-02,
         1.9950e-01,  1.1587e+00,  1.2943e-02, -7.8292e-03, -2.0409e-01,
         3.2058e+00], device='cuda:1')
Solve time for step 1 9.320796104962938
Current ori: tensor([ 0.0129, -0.0078, -0.2041], device='cuda:1')
Index force: tensor([0.5475, 0.5687, 0.5691, 0.5685], device='cuda:1')
tensor([-1.0277e-03,  4.7664e-01,  6.1622e-01,  5.7653e-01, -1.5136e-01,
         5.1088e-01,  7.7909e-01,  9.6588e-01,  1.3060e+00,  6.1666e-02,
         1.0505e-01,  1.1534e+00,  1.4542e-02, -5.6161e-03, -2.0352e-01,
         3.1704e+00], device='cuda:1')
Solve time for step 2 3.69161736901151
Current ori: tensor([ 0.0145, -0.0056, -0.2035], device='cuda:1')
Index force: tensor([0.5565, 0.5584, 0.5597], device='cuda:1')
tensor([-0.0201,  0.4860,  0.5900,  0.5730, -0.1694,  0.4969,  0.7876,  0.9787,
         1.3101,  0.0826,  0.0938,  1.1607,  0.0110,  0.0045, -0.2035,  3.1414],
       device='cuda:1')
Solve time for step 3 3.451701582991518
Current ori: tensor([ 0.0110,  0.0045, -0.2035], device='cuda:1')
Index force: tensor([0.5498, 0.5516], device='cuda:1')
tensor([-0.0056,  0.4737,  0.6102,  0.5899, -0.1555,  0.4997,  0.8059,  0.9380,
         1.3247,  0.0750,  0.0796,  1.1282,  0.0162, -0.0032, -0.2035,  3.1662],
       device='cuda:1')
Solve time for step 4 3.509629372972995
Current ori: tensor([ 0.0162, -0.0032, -0.2035], device='cuda:1')
Index force: tensor([0.5372], device='cuda:1')
Storing RECOVERY transition: reward=-0.0142 (scaled=-0.0071), steps=2
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0743
Collected 286 transitions for RL
SAC Update 1/5: Actor Loss=-0.0127, Q1 Loss=1.1546, Q2 Loss=1.1546, Entropy=0.6930, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1798
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=1.2861, Q2 Loss=1.2861, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2042
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=1.1340, Q2 Loss=1.1340, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3424
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=2.0254, Q2 Loss=2.0254, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2218
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=0.9178, Q2 Loss=0.9178, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3058

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (14.8%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.3%)
Actor update: 0.13s (41.4%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010894
Q1 loss: 1.303580
Q2 loss: 1.303580
Current threshold: -149.5391
Global Scale Offset: 1496.0467
Reward stats: mean=0.0147, std=0.0743, count=286
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.3036, Q2 Loss: 1.3036, Entropy: 0.6929, Mean TD Error: 1.0508, Threshold: -149.5391
Original likelihood: -105.6645278930664
Adjusted likelihood: -105.6645278930664
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5117)
State is out of distribution
Projection step: 0, Loss: 104.57462310791016
Final likelihood: tensor([ -92.5648,  -79.6680, -107.5599, -109.3356,  -93.7112, -105.2064,
        -100.3413, -111.0346,  -93.2195, -121.6644,  -91.8039, -122.3330,
        -113.4369, -121.3030, -103.3501, -106.6615])
Final projection likelihood: -104.5746
1 mode projection succeeded
New goal: tensor([-0.0175,  0.4647,  0.6115,  0.5931, -0.0955,  0.5635,  0.8172,  0.9665,
         1.3837,  0.1228,  0.1371,  1.1914,  0.0200,  0.0030, -0.1901],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0200,  0.0030, -0.1901], device='cuda:1')
6 turn
Sampling time 3.6260685439920053
tensor([-1.7471e-02,  4.6466e-01,  6.1148e-01,  5.9305e-01, -9.5544e-02,
         5.6355e-01,  8.1721e-01,  9.6653e-01,  1.3837e+00,  1.2279e-01,
         1.3715e-01,  1.1914e+00,  1.9993e-02,  3.0002e-03, -1.9009e-01,
         3.1542e+00], device='cuda:1')
Original likelihood: -95.78474426269531
Adjusted likelihood: -95.78474426269531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5143)
Solve time for step 1 13.980372007994447
Current ori: tensor([ 0.0200,  0.0030, -0.1901], device='cuda:1')
Middle force: tensor([0.5859, 0.5331, 1.4166, 1.2059, 0.7044, 0.5819, 0.6002, 0.7110, 0.5279,
        0.5561, 0.5892, 0.6097], device='cuda:1')
Thumb force: tensor([1.3778, 1.1689, 0.8492, 0.6601, 0.9190, 0.5638, 0.5449, 1.7582, 0.5564,
        0.5695, 0.5714, 0.5910], device='cuda:1')
Index force: tensor([0.6554, 0.5099, 0.7758, 1.0427, 0.7079, 0.6243, 0.5859, 0.5647, 0.7223,
        0.5849, 0.5799, 0.5909], device='cuda:1')
Storing NORMAL transition: reward=0.0025 (scaled=0.0025), steps=1
Reward stats updated: mean 0.0147 -> 0.0146, std: 0.0742
Collected 287 transitions for RL
SAC Update 1/5: Actor Loss=-0.0115, Q1 Loss=1.0732, Q2 Loss=1.0732, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5059
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=4.0904, Q2 Loss=4.0904, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4973
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.5765, Q2 Loss=1.5765, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7906
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=0.9329, Q2 Loss=0.9329, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5679
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.6317, Q2 Loss=0.6317, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1158

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010223
Q1 loss: 1.660954
Q2 loss: 1.660954
Current threshold: -149.5392
Global Scale Offset: 1508.5159
Reward stats: mean=0.0146, std=0.0742, count=287
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.6610, Q2 Loss: 1.6610, Entropy: 0.6930, Mean TD Error: 1.0955, Threshold: -149.5392
tensor([ 0.0734,  0.4516,  0.7175,  0.5851, -0.2087,  0.4956,  0.9218,  1.0617,
         1.4082,  0.1254,  0.2022,  1.1418,  0.0310,  0.0395, -0.1947,  1.7954],
       device='cuda:1')
Original likelihood: -222.42059326171875
Adjusted likelihood: -222.42059326171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4808)
Solve time for step 2 5.438459379016422
Current ori: tensor([ 0.0310,  0.0395, -0.1947], device='cuda:1')
Middle force: tensor([0.5594, 0.5087, 0.9608, 0.5460, 0.9485, 0.5761, 0.8165, 0.5281, 0.5214,
        1.0191, 0.7053], device='cuda:1')
Thumb force: tensor([0.6251, 0.5098, 1.8502, 0.7481, 1.0268, 1.1447, 1.1427, 0.6413, 0.8167,
        0.6299, 0.5779], device='cuda:1')
Index force: tensor([0.6048, 0.5563, 0.5159, 0.7826, 0.5634, 0.7198, 0.5437, 0.6732, 0.5358,
        0.6085, 0.7967], device='cuda:1')
Storing NORMAL transition: reward=-0.0098 (scaled=-0.0098), steps=1
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0741
Collected 288 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=1.3949, Q2 Loss=1.3949, Entropy=0.6929, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3091
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.7192, Q2 Loss=0.7192, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3642
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=1.2595, Q2 Loss=1.2595, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8754
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=0.8443, Q2 Loss=0.8443, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1425
SAC Update 5/5: Actor Loss=-0.0131, Q1 Loss=1.1946, Q2 Loss=1.1946, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1266

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (20.3%)
Actor update: 0.09s (37.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009338
Q1 loss: 1.082505
Q2 loss: 1.082505
Current threshold: -149.5394
Global Scale Offset: 1519.4822
Reward stats: mean=0.0146, std=0.0741, count=288
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.0825, Q2 Loss: 1.0825, Entropy: 0.6929, Mean TD Error: 1.1635, Threshold: -149.5394
tensor([ 0.1618,  0.5116,  0.6523,  0.6997, -0.2394,  0.4878,  0.9049,  1.0539,
         1.4166,  0.1453,  0.2345,  1.1136,  0.0298,  0.0624, -0.1870,  1.7633],
       device='cuda:1')
Original likelihood: -271.4574890136719
Adjusted likelihood: -271.4574890136719
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4681)
State is out of distribution
Projection step: 0, Loss: 275.4019775390625
Projection step: 1, Loss: 263.73284912109375
Projection step: 2, Loss: 258.00067138671875
Projection step: 3, Loss: 245.24755859375
Projection step: 4, Loss: 245.44142150878906
Projection step: 5, Loss: 222.94650268554688
Projection step: 6, Loss: 218.8419189453125
Projection step: 7, Loss: 218.36793518066406
Projection step: 8, Loss: 212.3643798828125
Projection step: 9, Loss: 201.94775390625
Projection step: 10, Loss: 188.43325805664062
Projection step: 11, Loss: 189.64422607421875
Projection step: 12, Loss: 188.72911071777344
Projection step: 13, Loss: 178.20883178710938
Projection step: 14, Loss: 196.68539428710938
Projection step: 15, Loss: 168.3079376220703
Projection step: 16, Loss: 164.67529296875
Projection step: 17, Loss: 160.47390747070312
Projection step: 18, Loss: 153.77008056640625
Projection step: 19, Loss: 159.84988403320312
Projection step: 20, Loss: 151.5251922607422
Projection step: 21, Loss: 142.49172973632812
Projection step: 22, Loss: 140.7515106201172
Projection step: 23, Loss: 137.74008178710938
Projection step: 24, Loss: 151.59298706054688
Final likelihood: tensor([-134.7685, -133.9725, -130.4495, -133.0477, -124.3496, -113.3135,
        -121.0294, -111.7343, -133.9765, -135.1165, -131.2418, -106.8578,
        -124.5446, -109.5190, -162.0113, -147.6056])
Final projection likelihood: -128.3461
1 mode projection succeeded
New goal: tensor([ 0.1092,  0.5398,  0.5778,  0.6198, -0.1297,  0.5445,  0.9101,  0.8363,
         1.3491,  0.2634,  0.2500,  1.1468,  0.0324,  0.0343,  0.1077],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -214.11666870117188
Adjusted likelihood: -214.11666870117188
Likelihood residual: 0.0
Original likelihood: -154.1663818359375
Adjusted likelihood: -154.1663818359375
Likelihood residual: 0.0
{'index': 154.1663818359375, 'thumb_middle': 214.11666870117188}
Current yaw: tensor([ 0.0298,  0.0624, -0.1870], device='cuda:1')
7 index
tensor([ 0.1618,  0.5116,  0.6523,  0.6997, -0.2394,  0.4878,  0.9049,  1.0539,
         1.4166,  0.1453,  0.2345,  1.1136,  0.0298,  0.0624, -0.1870,  1.7633],
       device='cuda:1')
Solve time for step 1 10.554266627994366
Current ori: tensor([ 0.0298,  0.0624, -0.1870], device='cuda:1')
Middle force: tensor([0.5664, 0.5374, 0.5693, 0.5796], device='cuda:1')
Thumb force: tensor([0.6023, 0.5103, 0.6090, 0.5512], device='cuda:1')
tensor([ 0.1522,  0.4935,  0.5483,  0.6113, -0.2098,  0.4927,  0.9569,  0.9448,
         1.3561,  0.2309,  0.2385,  1.0964,  0.0124,  0.0471, -0.1987,  1.7270],
       device='cuda:1')
Solve time for step 2 4.339411313994788
Current ori: tensor([ 0.0124,  0.0471, -0.1987], device='cuda:1')
Middle force: tensor([0.5920, 0.6262, 0.5005], device='cuda:1')
Thumb force: tensor([0.5078, 0.5499, 0.5268], device='cuda:1')
tensor([ 0.1505,  0.5022,  0.5382,  0.5983, -0.1807,  0.5219,  0.9552,  0.9028,
         1.3428,  0.2390,  0.2130,  1.0959, -0.0016,  0.0293, -0.2034,  1.4741],
       device='cuda:1')
Solve time for step 3 4.22399403702002
Current ori: tensor([-0.0016,  0.0293, -0.2034], device='cuda:1')
Middle force: tensor([0.5159, 0.5141], device='cuda:1')
Thumb force: tensor([0.5656, 0.5727], device='cuda:1')
tensor([ 0.1530,  0.5041,  0.5369,  0.5971, -0.1695,  0.5308,  0.9552,  0.8914,
         1.3421,  0.2343,  0.1963,  1.1079, -0.0047,  0.0220, -0.2008,  1.1996],
       device='cuda:1')
Solve time for step 4 4.01348521898035
Current ori: tensor([-0.0047,  0.0220, -0.2008], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5062], device='cuda:1')
Storing RECOVERY transition: reward=0.0186 (scaled=0.0093), steps=2
Reward stats updated: mean 0.0146 -> 0.0145, std: 0.0740
Collected 289 transitions for RL
SAC Update 1/5: Actor Loss=-0.0125, Q1 Loss=7.7545, Q2 Loss=7.7545, Entropy=0.6925, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1034
SAC Update 2/5: Actor Loss=-0.0124, Q1 Loss=1.9769, Q2 Loss=1.9769, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8487
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=0.9781, Q2 Loss=0.9781, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2927
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=0.8061, Q2 Loss=0.8061, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5848
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=1.1157, Q2 Loss=1.1157, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8792

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (39.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010276
Q1 loss: 2.526245
Q2 loss: 2.526245
Current threshold: -149.5398
Global Scale Offset: 1534.1354
Reward stats: mean=0.0145, std=0.0740, count=289
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 2.5262, Q2 Loss: 2.5262, Entropy: 0.6925, Mean TD Error: 2.1418, Threshold: -149.5398
Original likelihood: -143.32550048828125
Adjusted likelihood: -143.32550048828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5016)
Current yaw: tensor([-0.0047,  0.0265, -0.2018], device='cuda:1')
8 turn
Sampling time 3.5942807670217007
tensor([ 0.1016,  0.5611,  0.5800,  0.6196, -0.1773,  0.5274,  0.9573,  0.8917,
         1.3430,  0.2407,  0.1960,  1.1168, -0.0047,  0.0265, -0.2018,  1.1230],
       device='cuda:1')
Original likelihood: -148.1713409423828
Adjusted likelihood: -148.1713409423828
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5004)
State is out of distribution
Projection step: 0, Loss: 140.06048583984375
Projection step: 1, Loss: 130.61114501953125
Projection step: 2, Loss: 127.61629486083984
Projection step: 3, Loss: 119.63832092285156
Projection step: 4, Loss: 114.50949096679688
Projection step: 5, Loss: 106.73023223876953
Projection step: 6, Loss: 104.40830993652344
Final likelihood: tensor([ -94.3529,  -88.4656, -110.0789, -108.6382, -118.7832,  -97.9244,
        -105.7847, -103.8934,  -99.1587, -105.0059, -128.2202, -104.3215,
        -100.8428, -101.9696, -106.9941,  -96.0989])
Final projection likelihood: -104.4083
1 mode projection succeeded
New goal: tensor([ 0.0970,  0.5487,  0.5808,  0.6201, -0.1329,  0.5371,  0.9326,  0.8414,
         1.3258,  0.2482,  0.2003,  1.1305, -0.0049,  0.0225, -0.3430],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -116.05812072753906
Adjusted likelihood: -116.05812072753906
Likelihood residual: 0.0
Original likelihood: -119.42874145507812
Adjusted likelihood: -119.42874145507812
Likelihood residual: 0.0
{'index': 119.42874145507812, 'thumb_middle': 116.05812072753906}
Current yaw: tensor([-0.0047,  0.0265, -0.2018], device='cuda:1')
9 thumb_middle
tensor([ 0.1016,  0.5611,  0.5800,  0.6196, -0.1773,  0.5274,  0.9573,  0.8917,
         1.3430,  0.2407,  0.1960,  1.1168, -0.0047,  0.0265, -0.2018,  1.1230],
       device='cuda:1')
Solve time for step 1 9.260393035016023
Current ori: tensor([-0.0047,  0.0265, -0.2018], device='cuda:1')
Index force: tensor([0.5939, 0.5851, 0.5687, 0.6008], device='cuda:1')
tensor([ 0.0988,  0.5613,  0.5782,  0.6166, -0.2385,  0.5111,  0.8988,  0.8281,
         1.2877,  0.2257,  0.1319,  1.1035, -0.0046,  0.0284, -0.2018,  1.1074],
       device='cuda:1')
Solve time for step 2 3.9383341550128534
Current ori: tensor([-0.0046,  0.0284, -0.2018], device='cuda:1')
Index force: tensor([0.5781, 0.5640, 0.5953], device='cuda:1')
tensor([ 0.0971,  0.5544,  0.5824,  0.6244, -0.2404,  0.5183,  0.8972,  0.8193,
         1.2885,  0.2252,  0.1251,  1.1020, -0.0023,  0.0295, -0.2018,  1.1085],
       device='cuda:1')
Solve time for step 3 3.4943368160165846
Current ori: tensor([-0.0023,  0.0295, -0.2018], device='cuda:1')
Index force: tensor([0.5558, 0.5864], device='cuda:1')
tensor([ 1.0772e-01,  5.4720e-01,  5.9436e-01,  6.4092e-01, -2.3773e-01,
         5.1963e-01,  8.9965e-01,  8.1974e-01,  1.2859e+00,  2.2427e-01,
         1.2018e-01,  1.1005e+00,  5.9287e-04,  2.3953e-02, -2.0181e-01,
         1.1283e+00], device='cuda:1')
Solve time for step 4 3.3403609780361876
Current ori: tensor([ 0.0006,  0.0240, -0.2018], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0061), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0738
Collected 290 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7223, Q2 Loss=0.7223, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2813
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=2.1477, Q2 Loss=2.1477, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5691
SAC Update 3/5: Actor Loss=-0.0125, Q1 Loss=1.1788, Q2 Loss=1.1788, Entropy=0.6919, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6184
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=2.0281, Q2 Loss=2.0281, Entropy=0.6921, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4594
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.7567, Q2 Loss=0.7567, Entropy=0.6918, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2421

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.06s (20.6%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009316
Q1 loss: 1.366723
Q2 loss: 1.366723
Current threshold: -149.5404
Global Scale Offset: 1546.4657
Reward stats: mean=0.0145, std=0.0738, count=290
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.3667, Q2 Loss: 1.3667, Entropy: 0.6924, Mean TD Error: 1.4341, Threshold: -149.5404
Original likelihood: -142.43478393554688
Adjusted likelihood: -142.43478393554688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5018)
State is out of distribution
Projection step: 0, Loss: 134.7300262451172
Projection step: 1, Loss: 128.81781005859375
Projection step: 2, Loss: 116.15689086914062
Projection step: 3, Loss: 107.10821533203125
Projection step: 4, Loss: 102.29069519042969
Final likelihood: tensor([ -96.9089, -101.0888, -105.5499,  -86.1823,  -91.4046, -100.8102,
        -133.9042,  -96.0372, -109.7785, -109.1800, -113.8071,  -93.1121,
         -99.8763,  -98.1071, -106.6026,  -94.3013])
Final projection likelihood: -102.2907
1 mode projection succeeded
New goal: tensor([ 0.1053,  0.5491,  0.5872,  0.6276, -0.1398,  0.5711,  0.9240,  0.8158,
         1.3152,  0.2470,  0.2015,  1.1431, -0.0015,  0.0204, -0.2743],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -114.15444946289062
Adjusted likelihood: -114.15444946289062
Likelihood residual: 0.0
Original likelihood: -124.01132202148438
Adjusted likelihood: -124.01132202148438
Likelihood residual: 0.0
{'index': 124.01132202148438, 'thumb_middle': 114.15444946289062}
Current yaw: tensor([-0.0016,  0.0226, -0.2077], device='cuda:1')
10 thumb_middle
tensor([ 0.1082,  0.5573,  0.5855,  0.6316, -0.1725,  0.5614,  0.9362,  0.8432,
         1.3272,  0.2468,  0.1978,  1.1411, -0.0016,  0.0226, -0.2077,  1.1321],
       device='cuda:1')
Solve time for step 1 8.701189103012439
Current ori: tensor([-0.0016,  0.0226, -0.2077], device='cuda:1')
Index force: tensor([0.5872, 0.5840, 0.5687, 0.5820], device='cuda:1')
tensor([ 0.1065,  0.5581,  0.5821,  0.6326, -0.2409,  0.5372,  0.8888,  0.7910,
         1.2806,  0.2260,  0.1334,  1.1071, -0.0026,  0.0238, -0.2077,  1.1355],
       device='cuda:1')
Solve time for step 2 3.639467660977971
Current ori: tensor([-0.0026,  0.0238, -0.2077], device='cuda:1')
Index force: tensor([0.5720, 0.5588, 0.5725], device='cuda:1')
tensor([ 0.1043,  0.5553,  0.5841,  0.6330, -0.2456,  0.5370,  0.8959,  0.7944,
         1.2702,  0.2326,  0.1319,  1.1152, -0.0019,  0.0250, -0.2077,  1.1312],
       device='cuda:1')
Solve time for step 3 3.497872064996045
Current ori: tensor([-0.0019,  0.0250, -0.2077], device='cuda:1')
Index force: tensor([0.5492, 0.5633], device='cuda:1')
tensor([ 1.0121e-01,  5.4888e-01,  5.9043e-01,  6.3154e-01, -2.5142e-01,
         5.4916e-01,  8.8176e-01,  7.9678e-01,  1.2827e+00,  2.2474e-01,
         1.2013e-01,  1.1173e+00, -6.0395e-04,  2.6985e-02, -2.0769e-01,
         1.1278e+00], device='cuda:1')
Solve time for step 4 3.417214103974402
Current ori: tensor([-0.0006,  0.0270, -0.2077], device='cuda:1')
Index force: tensor([0.5506], device='cuda:1')
Storing RECOVERY transition: reward=0.0091 (scaled=0.0091), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0737
Collected 291 transitions for RL
SAC Update 1/5: Actor Loss=-0.0100, Q1 Loss=0.9454, Q2 Loss=0.9454, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5186
SAC Update 2/5: Actor Loss=-0.0069, Q1 Loss=0.6973, Q2 Loss=0.6973, Entropy=0.6920, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7154
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.7053, Q2 Loss=1.7053, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3300
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.1395, Q2 Loss=1.1395, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1326
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.8034, Q2 Loss=1.8034, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0756

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.4%)
Actor update: 0.12s (42.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010190
Q1 loss: 1.258180
Q2 loss: 1.258180
Current threshold: -149.5407
Global Scale Offset: 1560.0267
Reward stats: mean=0.0145, std=0.0737, count=291
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.2582, Q2 Loss: 1.2582, Entropy: 0.6927, Mean TD Error: 1.1545, Threshold: -149.5407
Original likelihood: -147.24807739257812
Adjusted likelihood: -147.24807739257812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5006)
Current yaw: tensor([ 0.0005,  0.0255, -0.2109], device='cuda:1')
11 turn
Sampling time 3.597945146029815
tensor([ 1.0353e-01,  5.4668e-01,  5.9090e-01,  6.4127e-01, -1.8335e-01,
         5.9551e-01,  9.1608e-01,  8.0116e-01,  1.3428e+00,  2.5230e-01,
         1.8170e-01,  1.1378e+00,  5.1439e-04,  2.5509e-02, -2.1087e-01,
         1.1485e+00], device='cuda:1')
Original likelihood: -140.55764770507812
Adjusted likelihood: -140.55764770507812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5023)
State is out of distribution
Projection step: 0, Loss: 143.79385375976562
Projection step: 1, Loss: 142.4443817138672
Projection step: 2, Loss: 131.77073669433594
Projection step: 3, Loss: 123.98918151855469
Projection step: 4, Loss: 117.17599487304688
Projection step: 5, Loss: 113.63871002197266
Projection step: 6, Loss: 111.40948486328125
Projection step: 7, Loss: 103.09696197509766
Final likelihood: tensor([ -83.8907, -130.7063, -112.2063, -111.8636, -117.9526, -102.4024,
        -106.6027, -106.1087,  -98.1745, -104.0840,  -96.7970, -100.2468,
        -103.2291,  -98.8138,  -93.8960,  -82.5769])
Final projection likelihood: -103.0970
1 mode projection succeeded
New goal: tensor([ 9.8659e-02,  5.4085e-01,  5.8974e-01,  6.3540e-01, -1.3139e-01,
         6.0679e-01,  8.9925e-01,  7.8171e-01,  1.3174e+00,  2.4986e-01,
         1.9549e-01,  1.1618e+00,  4.2976e-04,  2.0425e-02, -2.7905e-01],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0032]], device='cuda:1')
Original likelihood: -108.82395935058594
Adjusted likelihood: -108.82395935058594
Likelihood residual: 0.0
Original likelihood: -102.12158203125
Adjusted likelihood: -102.12158203125
Likelihood residual: 0.0
{'index': 102.12158203125, 'thumb_middle': 108.82395935058594}
Current yaw: tensor([ 0.0005,  0.0255, -0.2109], device='cuda:1')
12 index
tensor([ 1.0353e-01,  5.4668e-01,  5.9090e-01,  6.4127e-01, -1.8335e-01,
         5.9551e-01,  9.1608e-01,  8.0116e-01,  1.3428e+00,  2.5230e-01,
         1.8170e-01,  1.1378e+00,  5.1439e-04,  2.5509e-02, -2.1087e-01,
         1.1485e+00], device='cuda:1')
Solve time for step 1 10.422274764976464
Current ori: tensor([ 0.0005,  0.0255, -0.2109], device='cuda:1')
Middle force: tensor([0.5554, 0.5630, 0.5948, 0.5353], device='cuda:1')
Thumb force: tensor([0.5653, 0.5468, 0.5913, 0.5815], device='cuda:1')
tensor([ 0.1472,  0.4925,  0.5437,  0.6135, -0.1708,  0.6015,  0.9195,  0.8010,
         1.3326,  0.2644,  0.1668,  1.1461, -0.0027,  0.0161, -0.2292,  1.5453],
       device='cuda:1')
Solve time for step 2 4.15545993502019
Current ori: tensor([-0.0027,  0.0161, -0.2292], device='cuda:1')
Middle force: tensor([0.5586, 0.5900, 0.5327], device='cuda:1')
Thumb force: tensor([0.5440, 0.5876, 0.5771], device='cuda:1')
tensor([ 0.1462,  0.4925,  0.5412,  0.6103, -0.1725,  0.6031,  0.9152,  0.8033,
         1.3456,  0.2455,  0.1612,  1.1456, -0.0033,  0.0174, -0.2293,  1.7141],
       device='cuda:1')
Solve time for step 3 4.020104127004743
Current ori: tensor([-0.0033,  0.0174, -0.2293], device='cuda:1')
Middle force: tensor([0.5300, 0.5076], device='cuda:1')
Thumb force: tensor([0.5261, 0.5382], device='cuda:1')
tensor([ 0.1450,  0.4904,  0.5397,  0.6091, -0.1692,  0.6207,  0.9018,  0.7838,
         1.3450,  0.2493,  0.1627,  1.1218, -0.0131,  0.0155, -0.2342,  1.7517],
       device='cuda:1')
Solve time for step 4 3.9080778369680047
Current ori: tensor([-0.0131,  0.0155, -0.2342], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5144], device='cuda:1')
Storing RECOVERY transition: reward=0.0283 (scaled=0.0283), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0736
Collected 292 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.7999, Q2 Loss=0.7999, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7285
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.6425, Q2 Loss=1.6425, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4398
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.7539, Q2 Loss=0.7539, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7945
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=1.0063, Q2 Loss=1.0063, Entropy=0.6920, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2605
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.7968, Q2 Loss=0.7968, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8624

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009128
Q1 loss: 0.999883
Q2 loss: 0.999883
Current threshold: -149.5405
Global Scale Offset: 1573.7851
Reward stats: mean=0.0145, std=0.0736, count=292
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9999, Q2 Loss: 0.9999, Entropy: 0.6928, Mean TD Error: 1.0172, Threshold: -149.5405
Original likelihood: -147.85690307617188
Adjusted likelihood: -147.85690307617188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5004)
Current yaw: tensor([-0.0081,  0.0146, -0.2389], device='cuda:1')
13 turn
Sampling time 3.646268383017741
tensor([ 0.0951,  0.5479,  0.5857,  0.6332, -0.1687,  0.6105,  0.9108,  0.7994,
         1.3339,  0.2675,  0.1535,  1.1556, -0.0081,  0.0146, -0.2389,  1.7425],
       device='cuda:1')
Original likelihood: -126.0894546508789
Adjusted likelihood: -126.0894546508789
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5059)
Solve time for step 1 14.021247824013699
Current ori: tensor([-0.0081,  0.0146, -0.2389], device='cuda:1')
Middle force: tensor([1.1364, 1.5641, 0.4947, 0.5016, 0.5643, 0.5054, 0.6498, 0.5554, 0.6885,
        0.6015, 0.5145, 0.5729], device='cuda:1')
Thumb force: tensor([1.0235, 1.2087, 0.5904, 0.5829, 2.0086, 0.6007, 0.7171, 0.5867, 0.5570,
        0.5962, 0.6048, 1.1734], device='cuda:1')
Index force: tensor([1.3792, 0.5283, 0.8039, 0.6378, 0.6144, 0.5204, 0.5872, 0.5603, 0.5123,
        0.5963, 0.6008, 0.6193], device='cuda:1')
Storing NORMAL transition: reward=0.0155 (scaled=0.0155), steps=1
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0735
Collected 293 transitions for RL
SAC Update 1/5: Actor Loss=-0.0116, Q1 Loss=1.3270, Q2 Loss=1.3270, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0511
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=1.5761, Q2 Loss=1.5761, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6932
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.9846, Q2 Loss=0.9846, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6089
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=1.3166, Q2 Loss=1.3166, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9302
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.2732, Q2 Loss=1.2732, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0603

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.05s (18.4%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (42.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010554
Q1 loss: 1.295493
Q2 loss: 1.295493
Current threshold: -149.5400
Global Scale Offset: 1585.6585
Reward stats: mean=0.0145, std=0.0735, count=293
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.2955, Q2 Loss: 1.2955, Entropy: 0.6930, Mean TD Error: 1.2688, Threshold: -149.5400
tensor([ 0.0766,  0.6266,  0.4531,  0.6430, -0.2567,  0.6270,  0.9517,  0.9452,
         1.4165,  0.2542,  0.1290,  1.0051, -0.0247,  0.0236, -0.2552,  1.7159],
       device='cuda:1')
Original likelihood: -189.19305419921875
Adjusted likelihood: -189.19305419921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4900)
Solve time for step 2 5.636869847949129
Current ori: tensor([-0.0247,  0.0236, -0.2552], device='cuda:1')
Middle force: tensor([1.5606, 0.5031, 0.5016, 0.5586, 0.5076, 0.6564, 0.5601, 0.6733, 0.5982,
        0.5159, 0.5696], device='cuda:1')
Thumb force: tensor([1.1768, 0.5840, 0.5815, 1.9658, 0.5900, 0.7032, 0.5789, 0.5573, 0.5958,
        0.5954, 1.1593], device='cuda:1')
Index force: tensor([0.5270, 0.8125, 0.6220, 0.6057, 0.5132, 0.5828, 0.5557, 0.5119, 0.5915,
        0.5925, 0.6140], device='cuda:1')
Storing NORMAL transition: reward=0.2387 (scaled=0.2387), steps=1
Reward stats updated: mean 0.0145 -> 0.0153, std: 0.0745
Collected 294 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.0312, Q2 Loss=1.0312, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7184
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=0.8070, Q2 Loss=0.8070, Entropy=0.6870, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6348
SAC Update 3/5: Actor Loss=-0.0124, Q1 Loss=1.4206, Q2 Loss=1.4206, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1503
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=3.8746, Q2 Loss=3.8746, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3564
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=1.0566, Q2 Loss=1.0566, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8842

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.8%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010679
Q1 loss: 1.637979
Q2 loss: 1.637979
Current threshold: -149.5394
Global Scale Offset: 1586.1800
Reward stats: mean=0.0153, std=0.0745, count=294
----------------------------------------------
SAC Update - Actor Loss: -0.0107, Q1 Loss: 1.6380, Q2 Loss: 1.6380, Entropy: 0.6919, Mean TD Error: 1.3488, Threshold: -149.5394
tensor([ 0.1019,  0.5850,  0.5359,  0.6445, -0.2421,  0.5840,  1.0080,  1.0717,
         1.4097,  0.3003,  0.2049,  0.8348, -0.0155,  0.0097, -0.4935,  2.0035],
       device='cuda:1')
Original likelihood: -186.50289916992188
Adjusted likelihood: -186.50289916992188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4907)
Solve time for step 3 5.267283261986449
Current ori: tensor([-0.0155,  0.0097, -0.4935], device='cuda:1')
Middle force: tensor([0.5028, 0.5020, 0.5568, 0.5086, 0.6528, 0.5602, 0.6676, 0.5970, 0.5172,
        0.5681], device='cuda:1')
Thumb force: tensor([0.5800, 0.5648, 1.9150, 0.5787, 0.6955, 0.5745, 0.5539, 0.5904, 0.5851,
        1.1398], device='cuda:1')
Index force: tensor([0.7972, 0.6136, 0.6005, 0.5101, 0.5789, 0.5526, 0.5114, 0.5877, 0.5879,
        0.6104], device='cuda:1')
Storing NORMAL transition: reward=0.0691 (scaled=0.0691), steps=1
Reward stats updated: mean 0.0153 -> 0.0155, std: 0.0744
Collected 295 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=2.0714, Q2 Loss=2.0714, Entropy=0.6929, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9558
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8115, Q2 Loss=0.8115, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8850
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=0.6490, Q2 Loss=0.6490, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1340
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8054, Q2 Loss=0.8054, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8595
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=1.0083, Q2 Loss=1.0083, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2880

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008185
Q1 loss: 1.069118
Q2 loss: 1.069118
Current threshold: -149.5389
Global Scale Offset: 1590.0315
Reward stats: mean=0.0155, std=0.0744, count=295
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 1.0691, Q2 Loss: 1.0691, Entropy: 0.6929, Mean TD Error: 1.2245, Threshold: -149.5389
tensor([ 0.0794,  0.6010,  0.4640,  0.6992, -0.2556,  0.5846,  0.9806,  1.1287,
         1.4882,  0.2027,  0.2075,  0.7396, -0.0148,  0.0225, -0.5638,  2.0666],
       device='cuda:1')
Original likelihood: -214.14907836914062
Adjusted likelihood: -214.14907836914062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4838)
State is out of distribution
Projection step: 0, Loss: 220.80078125
Projection step: 1, Loss: 203.78839111328125
Projection step: 2, Loss: 205.79437255859375
Projection step: 3, Loss: 196.64108276367188
Projection step: 4, Loss: 195.5951690673828
Projection step: 5, Loss: 175.89410400390625
Projection step: 6, Loss: 181.66714477539062
Projection step: 7, Loss: 170.97811889648438
Projection step: 8, Loss: 160.45962524414062
Projection step: 9, Loss: 154.41168212890625
Projection step: 10, Loss: 155.3986358642578
Projection step: 11, Loss: 146.78952026367188
Projection step: 12, Loss: 134.8133544921875
Projection step: 13, Loss: 137.8462371826172
Projection step: 14, Loss: 126.44642639160156
Projection step: 15, Loss: 122.1448974609375
Projection step: 16, Loss: 124.14990234375
Projection step: 17, Loss: 133.5870819091797
Projection step: 18, Loss: 113.0738525390625
Projection step: 19, Loss: 115.06306457519531
Projection step: 20, Loss: 110.60498046875
Projection step: 21, Loss: 111.59527587890625
Projection step: 22, Loss: 106.28334045410156
Projection step: 23, Loss: 102.21372985839844
Final likelihood: tensor([-106.1830,  -97.9019,  -98.4939, -109.9467,  -92.8277,  -67.6147,
        -100.3408,  -86.1075,  -97.5815, -117.8601, -117.0079,  -99.7443,
        -112.4398,  -98.4078, -112.8773, -120.0849])
Final projection likelihood: -102.2137
1 mode projection succeeded
New goal: tensor([ 0.0883,  0.5660,  0.5050,  0.6545, -0.1063,  0.5439,  0.9001,  0.9121,
         1.4347,  0.2444,  0.1923,  0.9927, -0.0180,  0.0168, -1.1005],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0020]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -113.39701843261719
Adjusted likelihood: -113.39701843261719
Likelihood residual: 0.0
Original likelihood: -196.9853515625
Adjusted likelihood: -196.9853515625
Likelihood residual: 0.0
{'index': 196.9853515625, 'thumb_middle': 113.39701843261719}
Current yaw: tensor([-0.0148,  0.0225, -0.5638], device='cuda:1')
14 thumb_middle
tensor([ 0.0794,  0.6010,  0.4640,  0.6992, -0.2556,  0.5846,  0.9806,  1.1287,
         1.4882,  0.2027,  0.2075,  0.7396, -0.0148,  0.0225, -0.5638,  2.0666],
       device='cuda:1')
Solve time for step 1 8.789623217016924
Current ori: tensor([-0.0148,  0.0225, -0.5638], device='cuda:1')
Index force: tensor([0.5705, 0.5723, 0.5743, 0.5799], device='cuda:1')
tensor([ 0.0751,  0.5922,  0.4979,  0.6475, -0.2472,  0.5261,  0.8741,  0.9186,
         1.3730,  0.2095,  0.1197,  0.8929, -0.0169,  0.0253, -0.5615,  2.0308],
       device='cuda:1')
Solve time for step 2 3.5669219350093044
Current ori: tensor([-0.0169,  0.0253, -0.5615], device='cuda:1')
Index force: tensor([0.5591, 0.5625, 0.5676], device='cuda:1')
tensor([ 0.0759,  0.5910,  0.5016,  0.6448, -0.2382,  0.5369,  0.8543,  0.8907,
         1.3650,  0.2156,  0.0941,  0.9492, -0.0169,  0.0249, -0.5615,  2.0312],
       device='cuda:1')
Solve time for step 3 3.5495759359910153
Current ori: tensor([-0.0169,  0.0249, -0.5615], device='cuda:1')
Index force: tensor([0.5513, 0.5573], device='cuda:1')
tensor([ 0.0930,  0.5984,  0.4979,  0.6650, -0.2202,  0.5190,  0.8546,  0.9046,
         1.3647,  0.2026,  0.0864,  0.9438, -0.0168,  0.0149, -0.5615,  2.0600],
       device='cuda:1')
Solve time for step 4 3.454997325956356
Current ori: tensor([-0.0168,  0.0149, -0.5615], device='cuda:1')
Index force: tensor([0.5606], device='cuda:1')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0019), steps=3
Reward stats updated: mean 0.0155 -> 0.0154, std: 0.0743
Collected 296 transitions for RL
SAC Update 1/5: Actor Loss=-0.0129, Q1 Loss=1.3097, Q2 Loss=1.3097, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8571
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=1.0288, Q2 Loss=1.0288, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4359
SAC Update 3/5: Actor Loss=-0.0109, Q1 Loss=1.2416, Q2 Loss=1.2416, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0814
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.7453, Q2 Loss=0.7453, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2810
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.9021, Q2 Loss=0.9021, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6019

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009733
Q1 loss: 1.045506
Q2 loss: 1.045506
Current threshold: -149.5382
Global Scale Offset: 1596.1223
Reward stats: mean=0.0154, std=0.0743, count=296
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.0455, Q2 Loss: 1.0455, Entropy: 0.6930, Mean TD Error: 0.8515, Threshold: -149.5382
Original likelihood: -139.183349609375
Adjusted likelihood: -139.183349609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5026)
Current yaw: tensor([-0.0132,  0.0230, -0.5580], device='cuda:1')
15 turn
Sampling time 3.620824014011305
tensor([ 0.0795,  0.5886,  0.4902,  0.6807, -0.1708,  0.5750,  0.8837,  0.9224,
         1.4140,  0.2339,  0.1623,  0.9727, -0.0132,  0.0230, -0.5580,  2.0464],
       device='cuda:1')
Original likelihood: -133.84072875976562
Adjusted likelihood: -133.84072875976562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5039)
State is out of distribution
Projection step: 0, Loss: 136.17613220214844
Projection step: 1, Loss: 125.99740600585938
Projection step: 2, Loss: 122.62240600585938
Projection step: 3, Loss: 111.0516357421875
Projection step: 4, Loss: 107.72380065917969
Projection step: 5, Loss: 105.33320617675781
Projection step: 6, Loss: 99.821533203125
Final likelihood: tensor([ -88.7924, -108.0611,  -98.9734, -107.9289,  -94.3276,  -88.8766,
         -98.9461, -110.6828,  -93.0749,  -90.1969,  -94.5257,  -87.7255,
         -91.6207, -121.3289, -114.5147, -107.5682])
Final projection likelihood: -99.8215
1 mode projection succeeded
New goal: tensor([ 0.0826,  0.5671,  0.5054,  0.6750, -0.1338,  0.5620,  0.8996,  0.8682,
         1.3862,  0.2447,  0.1733,  1.0717, -0.0132,  0.0202, -0.8609],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -119.64320373535156
Adjusted likelihood: -119.64320373535156
Likelihood residual: 0.0
Original likelihood: -118.34927368164062
Adjusted likelihood: -118.34927368164062
Likelihood residual: 0.0
{'index': 118.34927368164062, 'thumb_middle': 119.64320373535156}
Current yaw: tensor([-0.0132,  0.0230, -0.5580], device='cuda:1')
16 index
tensor([ 0.0795,  0.5886,  0.4902,  0.6807, -0.1708,  0.5750,  0.8837,  0.9224,
         1.4140,  0.2339,  0.1623,  0.9727, -0.0132,  0.0230, -0.5580,  2.0464],
       device='cuda:1')
Solve time for step 1 10.80448636302026
Current ori: tensor([-0.0132,  0.0230, -0.5580], device='cuda:1')
Middle force: tensor([0.5991, 0.5910, 0.5238, 0.5764], device='cuda:1')
Thumb force: tensor([0.5116, 0.6267, 0.5325, 0.6054], device='cuda:1')
tensor([ 0.1220,  0.5218,  0.4580,  0.6541, -0.1563,  0.5600,  0.9257,  0.9071,
         1.4028,  0.2363,  0.1360,  1.0245, -0.0057,  0.0107, -0.5504,  1.6369],
       device='cuda:1')
Solve time for step 2 4.338839610980358
Current ori: tensor([-0.0057,  0.0107, -0.5504], device='cuda:1')
Middle force: tensor([0.5869, 0.5219, 0.5733], device='cuda:1')
Thumb force: tensor([0.6171, 0.5305, 0.6009], device='cuda:1')
tensor([ 0.1255,  0.5213,  0.4593,  0.6495, -0.1527,  0.5730,  0.9163,  0.8873,
         1.4098,  0.2267,  0.1341,  1.0041, -0.0140,  0.0097, -0.5528,  1.3807],
       device='cuda:1')
Solve time for step 3 3.957425841013901
Current ori: tensor([-0.0140,  0.0097, -0.5528], device='cuda:1')
Middle force: tensor([0.5188, 0.5679], device='cuda:1')
Thumb force: tensor([0.5257, 0.5927], device='cuda:1')
tensor([ 0.1253,  0.5208,  0.4586,  0.6510, -0.1556,  0.5656,  0.9315,  0.9008,
         1.4035,  0.2411,  0.1263,  1.0230, -0.0105,  0.0070, -0.5697,  1.2735],
       device='cuda:1')
Solve time for step 4 3.9924844540073536
Current ori: tensor([-0.0105,  0.0070, -0.5697], device='cuda:1')
Middle force: tensor([0.5177], device='cuda:1')
Thumb force: tensor([0.5956], device='cuda:1')
Storing RECOVERY transition: reward=-0.0019 (scaled=-0.0019), steps=0
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0742
Collected 297 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=1.2826, Q2 Loss=1.2826, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0800
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=2.2038, Q2 Loss=2.2038, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3191
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.8128, Q2 Loss=0.8128, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8263
SAC Update 4/5: Actor Loss=-0.0117, Q1 Loss=1.7492, Q2 Loss=1.7492, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7799
SAC Update 5/5: Actor Loss=-0.0089, Q1 Loss=0.9345, Q2 Loss=0.9345, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2525

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.04s (17.8%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009206
Q1 loss: 1.396573
Q2 loss: 1.396573
Current threshold: -149.5374
Global Scale Offset: 1605.6676
Reward stats: mean=0.0154, std=0.0742, count=297
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.3966, Q2 Loss: 1.3966, Entropy: 0.6928, Mean TD Error: 1.8516, Threshold: -149.5374
Original likelihood: -133.20338439941406
Adjusted likelihood: -133.20338439941406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5041)
Current yaw: tensor([-0.0123,  0.0016, -0.5557], device='cuda:1')
17 turn
Sampling time 3.7658304659998976
tensor([ 0.0755,  0.5793,  0.5025,  0.6734, -0.1473,  0.5754,  0.9279,  0.8910,
         1.3982,  0.2432,  0.1155,  1.0370, -0.0123,  0.0016, -0.5557,  1.2423],
       device='cuda:1')
Original likelihood: -132.13424682617188
Adjusted likelihood: -132.13424682617188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5043)
State is out of distribution
Projection step: 0, Loss: 130.49734497070312
Projection step: 1, Loss: 122.44670104980469
Projection step: 2, Loss: 114.49070739746094
Projection step: 3, Loss: 104.27110290527344
Final likelihood: tensor([-114.4613, -102.1296, -103.1838,  -97.6097, -109.2917, -105.0556,
        -114.3451,  -96.0803, -100.7081, -107.5575, -101.6687, -110.7970,
        -101.3456, -102.7362, -102.3081,  -99.0593])
Final projection likelihood: -104.2711
1 mode projection succeeded
New goal: tensor([ 0.0837,  0.5713,  0.5138,  0.6643, -0.1264,  0.5706,  0.9261,  0.8788,
         1.3892,  0.2482,  0.1402,  1.0583, -0.0113,  0.0040, -0.6351],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -134.6561279296875
Adjusted likelihood: -134.6561279296875
Likelihood residual: 0.0
Original likelihood: -144.20925903320312
Adjusted likelihood: -144.20925903320312
Likelihood residual: 0.0
{'index': 144.20925903320312, 'thumb_middle': 134.6561279296875}
Current yaw: tensor([-0.0123,  0.0016, -0.5557], device='cuda:1')
18 thumb_middle
tensor([ 0.0755,  0.5793,  0.5025,  0.6734, -0.1473,  0.5754,  0.9279,  0.8910,
         1.3982,  0.2432,  0.1155,  1.0370, -0.0123,  0.0016, -0.5557,  1.2423],
       device='cuda:1')
Solve time for step 1 9.037858890951611
Current ori: tensor([-0.0123,  0.0016, -0.5557], device='cuda:1')
Index force: tensor([0.5580, 0.5827, 0.5786, 0.5932], device='cuda:1')
tensor([ 0.0755,  0.5755,  0.5093,  0.6698, -0.2333,  0.5523,  0.8825,  0.8619,
         1.3369,  0.2108,  0.0636,  1.0347, -0.0116,  0.0019, -0.5556,  1.2434],
       device='cuda:1')
Solve time for step 2 3.644990174972918
Current ori: tensor([-0.0116,  0.0019, -0.5556], device='cuda:1')
Index force: tensor([0.5749, 0.5728, 0.5872], device='cuda:1')
tensor([ 0.0715,  0.5723,  0.5140,  0.6624, -0.2304,  0.5520,  0.8828,  0.8499,
         1.3397,  0.2386,  0.0499,  1.0259, -0.0116,  0.0041, -0.5556,  1.2364],
       device='cuda:1')
Solve time for step 3 3.4841775390086696
Current ori: tensor([-0.0116,  0.0041, -0.5556], device='cuda:1')
Index force: tensor([0.5671, 0.5823], device='cuda:1')
tensor([ 0.0691,  0.5767,  0.5118,  0.6504, -0.2392,  0.5634,  0.8807,  0.8483,
         1.3404,  0.2203,  0.0544,  1.0243, -0.0139,  0.0053, -0.5556,  1.2276],
       device='cuda:1')
Solve time for step 4 3.2349525679601356
Current ori: tensor([-0.0139,  0.0053, -0.5556], device='cuda:1')
Index force: tensor([0.5692], device='cuda:1')
Storing RECOVERY transition: reward=0.0062 (scaled=0.0062), steps=0
Reward stats updated: mean 0.0154 -> 0.0153, std: 0.0741
Collected 298 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=1.1164, Q2 Loss=1.1164, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8206
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.7549, Q2 Loss=0.7549, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4021
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=1.1792, Q2 Loss=1.1792, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6641
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=1.6785, Q2 Loss=1.6785, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0994
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=0.9779, Q2 Loss=0.9779, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9977

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (17.1%)
Actor update: 0.09s (39.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009706
Q1 loss: 1.141368
Q2 loss: 1.141368
Current threshold: -149.5364
Global Scale Offset: 1612.6649
Reward stats: mean=0.0153, std=0.0741, count=298
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.1414, Q2 Loss: 1.1414, Entropy: 0.6930, Mean TD Error: 1.1968, Threshold: -149.5364
Original likelihood: -145.2474365234375
Adjusted likelihood: -145.2474365234375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5011)
Current yaw: tensor([-0.0099,  0.0057, -0.5618], device='cuda:1')
19 turn
Sampling time 3.617377279966604
tensor([ 0.0686,  0.5692,  0.5114,  0.6708, -0.1722,  0.6044,  0.9239,  0.8725,
         1.3973,  0.2465,  0.1154,  1.0526, -0.0099,  0.0057, -0.5618,  1.2442],
       device='cuda:1')
Original likelihood: -138.720947265625
Adjusted likelihood: -138.720947265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5027)
Solve time for step 1 14.096290140005294
Current ori: tensor([-0.0099,  0.0057, -0.5618], device='cuda:1')
Middle force: tensor([0.5131, 1.1064, 0.5368, 0.4711, 0.4895, 0.5342, 1.0974, 0.5836, 1.0862,
        0.8513, 0.4825, 0.5633], device='cuda:1')
Thumb force: tensor([1.3183, 1.1844, 0.6194, 0.5394, 0.8445, 0.6544, 0.9887, 0.5047, 0.7962,
        0.5381, 0.5387, 0.5583], device='cuda:1')
Index force: tensor([0.7406, 0.5412, 0.5774, 0.7651, 0.6625, 0.5420, 1.2633, 0.6556, 0.5478,
        0.7667, 0.6637, 0.6449], device='cuda:1')
Storing NORMAL transition: reward=0.1097 (scaled=0.1097), steps=1
Reward stats updated: mean 0.0153 -> 0.0157, std: 0.0742
Collected 299 transitions for RL
SAC Update 1/5: Actor Loss=-0.0105, Q1 Loss=1.0509, Q2 Loss=1.0509, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0012
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.8771, Q2 Loss=0.8771, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7282
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.1557, Q2 Loss=1.1557, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6621
SAC Update 4/5: Actor Loss=-0.0104, Q1 Loss=0.9841, Q2 Loss=0.9841, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3042
SAC Update 5/5: Actor Loss=-0.0129, Q1 Loss=1.5380, Q2 Loss=1.5380, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2242

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (39.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010588
Q1 loss: 1.121155
Q2 loss: 1.121155
Current threshold: -149.5355
Global Scale Offset: 1618.0551
Reward stats: mean=0.0157, std=0.0742, count=299
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.1212, Q2 Loss: 1.1212, Entropy: 0.6928, Mean TD Error: 0.9840, Threshold: -149.5355
tensor([ 0.1510,  0.5677,  0.4832,  0.7485, -0.1816,  0.5842,  0.9618,  0.8280,
         1.4718,  0.1456,  0.1267,  0.9267, -0.0281,  0.0138, -0.6726,  0.6768],
       device='cuda:1')
Original likelihood: -182.67083740234375
Adjusted likelihood: -182.67083740234375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4918)
State is out of distribution
Projection step: 0, Loss: 179.468017578125
Projection step: 1, Loss: 163.8011474609375
Projection step: 2, Loss: 163.89205932617188
Projection step: 3, Loss: 153.2012176513672
Projection step: 4, Loss: 150.34713745117188
Projection step: 5, Loss: 153.32131958007812
Projection step: 6, Loss: 137.44549560546875
Projection step: 7, Loss: 137.60784912109375
Projection step: 8, Loss: 128.5926513671875
Projection step: 9, Loss: 130.57798767089844
Projection step: 10, Loss: 134.2799072265625
Projection step: 11, Loss: 118.77227783203125
Projection step: 12, Loss: 122.07841491699219
Projection step: 13, Loss: 114.39117431640625
Projection step: 14, Loss: 112.57025146484375
Projection step: 15, Loss: 120.701904296875
Projection step: 16, Loss: 114.62580871582031
Projection step: 17, Loss: 105.43254089355469
Projection step: 18, Loss: 111.65336608886719
Projection step: 19, Loss: 103.82386016845703
Final likelihood: tensor([-101.6684, -111.6956, -115.3567,  -85.2695,  -87.7621,  -90.6936,
        -109.7264, -124.7425,  -78.5660, -100.4885,  -93.9531, -123.5355,
        -108.9242, -111.8336, -116.3224, -100.6436])
Final projection likelihood: -103.8239
1 mode projection succeeded
New goal: tensor([ 0.1134,  0.5506,  0.5307,  0.7419, -0.0755,  0.6160,  0.8618,  0.7966,
         1.4366,  0.1910,  0.1665,  0.9981, -0.0284,  0.0082, -0.8135],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0068]], device='cuda:1')
Original likelihood: -153.36141967773438
Adjusted likelihood: -153.36141967773438
Likelihood residual: 0.0
{'index': 153.36141967773438, 'thumb_middle': inf}
Current yaw: tensor([-0.0281,  0.0138, -0.6726], device='cuda:1')
20 index
tensor([ 0.1510,  0.5677,  0.4832,  0.7485, -0.1816,  0.5842,  0.9618,  0.8280,
         1.4718,  0.1456,  0.1267,  0.9267, -0.0281,  0.0138, -0.6726,  0.6768],
       device='cuda:1')
Solve time for step 1 10.671234995010309
Current ori: tensor([-0.0281,  0.0138, -0.6726], device='cuda:1')
Middle force: tensor([0.5782, 0.5202, 0.5559, 0.5740], device='cuda:1')
Thumb force: tensor([0.6129, 0.6620, 0.6352, 0.5246], device='cuda:1')
tensor([ 0.1569,  0.5002,  0.4787,  0.7192, -0.1553,  0.6157,  0.9293,  0.8475,
         1.4467,  0.1739,  0.1021,  0.9526, -0.0328, -0.0060, -0.6663,  0.4059],
       device='cuda:1')
Solve time for step 2 4.154810535022989
Current ori: tensor([-0.0328, -0.0060, -0.6663], device='cuda:1')
Middle force: tensor([0.5158, 0.5506, 0.5682], device='cuda:1')
Thumb force: tensor([0.6587, 0.6311, 0.5233], device='cuda:1')
tensor([ 0.1614,  0.5062,  0.4786,  0.7103, -0.1441,  0.6262,  0.9238,  0.8485,
         1.4377,  0.1853,  0.0934,  0.9577, -0.0352, -0.0143, -0.6706,  0.3760],
       device='cuda:1')
Solve time for step 3 4.358295846031979
Current ori: tensor([-0.0352, -0.0143, -0.6706], device='cuda:1')
Middle force: tensor([0.5544, 0.5409], device='cuda:1')
Thumb force: tensor([0.5553, 0.5627], device='cuda:1')
tensor([ 0.1553,  0.5001,  0.4785,  0.7146, -0.1436,  0.6411,  0.9077,  0.8337,
         1.4446,  0.1754,  0.0953,  0.9357, -0.0433, -0.0135, -0.6689,  0.4757],
       device='cuda:1')
Solve time for step 4 3.93669190997025
Current ori: tensor([-0.0433, -0.0135, -0.6689], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5790], device='cuda:1')
Storing RECOVERY transition: reward=0.0063 (scaled=0.0063), steps=1
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0740
Collected 300 transitions for RL
SAC Update 1/5: Actor Loss=-0.0118, Q1 Loss=1.2398, Q2 Loss=1.2398, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9857
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=2.5033, Q2 Loss=2.5033, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7107
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=0.8601, Q2 Loss=0.8601, Entropy=0.6921, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2235
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.7789, Q2 Loss=1.7789, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2506
SAC Update 5/5: Actor Loss=-0.0104, Q1 Loss=3.8635, Q2 Loss=3.8635, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9591

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (21.1%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (37.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009968
Q1 loss: 2.049128
Q2 loss: 2.049128
Current threshold: -149.5345
Global Scale Offset: 1626.4533
Reward stats: mean=0.0156, std=0.0740, count=300
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 2.0491, Q2 Loss: 2.0491, Entropy: 0.6927, Mean TD Error: 2.2259, Threshold: -149.5345
Original likelihood: -140.685546875
Adjusted likelihood: -140.685546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5022)
State is out of distribution
Projection step: 0, Loss: 142.92626953125
Projection step: 1, Loss: 135.88035583496094
Projection step: 2, Loss: 132.51348876953125
Projection step: 3, Loss: 132.14328002929688
Projection step: 4, Loss: 127.68624114990234
Projection step: 5, Loss: 122.7611312866211
Projection step: 6, Loss: 120.82524108886719
Projection step: 7, Loss: 116.90682983398438
Projection step: 8, Loss: 114.34004211425781
Projection step: 9, Loss: 109.30992126464844
Projection step: 10, Loss: 105.24391174316406
Projection step: 11, Loss: 105.86353302001953
Projection step: 12, Loss: 94.96395874023438
Final likelihood: tensor([ -78.7538,  -95.0900, -102.5677,  -88.1384,  -79.1812,  -86.3060,
        -108.6888,  -90.7801,  -99.6485, -106.4706,  -87.2663,  -95.4324,
         -88.8220, -103.8816, -117.7533,  -90.6426])
Final projection likelihood: -94.9640
1 mode projection succeeded
New goal: tensor([ 0.1032,  0.5495,  0.5396,  0.7490, -0.0703,  0.6171,  0.9140,  0.8024,
         1.4081,  0.1861,  0.1200,  0.9585, -0.0371, -0.0087, -0.6655],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 19
Loaded trajectory sampler
Current yaw: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
Current yaw: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
1 turn
Sampling time 3.6675436189980246
tensor([ 0.1655,  0.6244,  0.5939,  0.5468, -0.1209,  0.5136,  0.9384,  0.9052,
         1.2636,  0.2501,  0.2269,  1.1844, -0.0027,  0.0145, -0.0438,  0.1688],
       device='cuda:1')
Original likelihood: -125.81549072265625
Adjusted likelihood: -125.81549072265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5058)
State is out of distribution
Projection step: 0, Loss: 121.02604675292969
Projection step: 1, Loss: 111.98892211914062
Projection step: 2, Loss: 106.53269958496094
Projection step: 3, Loss: 108.41883087158203
Projection step: 4, Loss: 99.83617401123047
Final likelihood: tensor([ -89.2178,  -86.9733, -113.9827,  -85.8277, -106.2556, -110.8392,
         -95.6911, -102.5432,  -95.6673, -104.9565, -117.7757, -115.8699,
        -106.6805, -109.1377,  -83.1023,  -72.8584])
Final projection likelihood: -99.8362
1 mode projection succeeded
New goal: tensor([ 0.1417,  0.6057,  0.5777,  0.5659, -0.1038,  0.5281,  0.9217,  0.8961,
         1.2716,  0.2784,  0.2254,  1.1578, -0.0017,  0.0145, -0.0754],
       device='cuda:1')
tensor([[0.0036]], device='cuda:1') tensor([[0.0015]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -151.99630737304688
Adjusted likelihood: -151.99630737304688
Likelihood residual: 0.0
Original likelihood: -118.40242004394531
Adjusted likelihood: -118.40242004394531
Likelihood residual: 0.0
{'index': 118.40242004394531, 'thumb_middle': 151.99630737304688}
Current yaw: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
2 index
tensor([ 0.1655,  0.6244,  0.5939,  0.5468, -0.1209,  0.5136,  0.9384,  0.9052,
         1.2636,  0.2501,  0.2269,  1.1844, -0.0027,  0.0145, -0.0438,  0.1688],
       device='cuda:1')
Solve time for step 1 10.37319800700061
Current ori: tensor([-0.0027,  0.0145, -0.0438], device='cuda:1')
Middle force: tensor([0.5686, 0.5474, 0.5509, 0.5817], device='cuda:1')
Thumb force: tensor([0.6026, 0.5299, 0.5662, 0.5857], device='cuda:1')
tensor([ 0.1977,  0.5525,  0.5330,  0.5404, -0.1343,  0.5283,  0.9325,  0.9092,
         1.2716,  0.2573,  0.2263,  1.1565, -0.0156,  0.0098, -0.0622,  1.2059],
       device='cuda:1')
Solve time for step 2 4.150792170024943
Current ori: tensor([-0.0156,  0.0098, -0.0622], device='cuda:1')
Middle force: tensor([0.5430, 0.5484, 0.5781], device='cuda:1')
Thumb force: tensor([0.5276, 0.5627, 0.5804], device='cuda:1')
tensor([ 0.1971,  0.5535,  0.5272,  0.5423, -0.1365,  0.5264,  0.9336,  0.9104,
         1.2728,  0.2579,  0.2306,  1.1489, -0.0159,  0.0112, -0.0684,  1.8229],
       device='cuda:1')
Solve time for step 3 4.059076773992274
Current ori: tensor([-0.0159,  0.0112, -0.0684], device='cuda:1')
Middle force: tensor([0.5009, 0.5682], device='cuda:1')
Thumb force: tensor([0.5854, 0.5685], device='cuda:1')
tensor([ 0.1978,  0.5533,  0.5275,  0.5421, -0.1286,  0.5270,  0.9365,  0.9161,
         1.2704,  0.2570,  0.2174,  1.1609, -0.0155,  0.0051, -0.0787,  2.1664],
       device='cuda:1')
Solve time for step 4 3.8517638799967244
Current ori: tensor([-0.0155,  0.0051, -0.0787], device='cuda:1')
Middle force: tensor([0.5668], device='cuda:1')
Thumb force: tensor([0.5585], device='cuda:1')
Storing RECOVERY transition: reward=0.0272 (scaled=0.0272), steps=0
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0739
Collected 301 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7332, Q2 Loss=0.7332, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2970
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=1.9305, Q2 Loss=1.9305, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9297
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.7230, Q2 Loss=0.7230, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2560
SAC Update 4/5: Actor Loss=-0.0115, Q1 Loss=1.9984, Q2 Loss=1.9984, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0435
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.8677, Q2 Loss=0.8677, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8735

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.2%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (40.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009443
Q1 loss: 1.250554
Q2 loss: 1.250554
Current threshold: -149.5340
Global Scale Offset: 1640.4502
Reward stats: mean=0.0157, std=0.0739, count=301
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.2506, Q2 Loss: 1.2506, Entropy: 0.6929, Mean TD Error: 1.0799, Threshold: -149.5340
Original likelihood: -128.91799926757812
Adjusted likelihood: -128.91799926757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5050)
Current yaw: tensor([-0.0162,  0.0133, -0.0713], device='cuda:1')
3 turn
Sampling time 3.741347021947149
tensor([ 0.1366,  0.6134,  0.5720,  0.5635, -0.1395,  0.5252,  0.9312,  0.9119,
         1.2792,  0.2517,  0.2313,  1.1448, -0.0162,  0.0133, -0.0713,  2.2266],
       device='cuda:1')
Original likelihood: -116.3416748046875
Adjusted likelihood: -116.3416748046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5081)
State is out of distribution
Projection step: 0, Loss: 124.55226135253906
Projection step: 1, Loss: 112.03948211669922
Projection step: 2, Loss: 100.10191345214844
Final likelihood: tensor([ -95.9382, -114.1463,  -74.9572, -124.2645, -100.1394,  -93.7411,
         -85.7607, -134.4747,  -79.3542, -101.8393, -117.9225,  -90.8055,
         -99.9507,  -84.6446,  -92.8236, -110.8680])
Final projection likelihood: -100.1019
1 mode projection succeeded
New goal: tensor([ 0.1290,  0.6049,  0.5691,  0.5568, -0.1254,  0.5315,  0.9291,  0.9084,
         1.2824,  0.2636,  0.2233,  1.1322, -0.0160,  0.0139, -0.0614],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -111.54651641845703
Adjusted likelihood: -111.54651641845703
Likelihood residual: 0.0
Original likelihood: -129.45355224609375
Adjusted likelihood: -129.45355224609375
Likelihood residual: 0.0
{'index': 129.45355224609375, 'thumb_middle': 111.54651641845703}
Current yaw: tensor([-0.0162,  0.0133, -0.0713], device='cuda:1')
4 thumb_middle
tensor([ 0.1366,  0.6134,  0.5720,  0.5635, -0.1395,  0.5252,  0.9312,  0.9119,
         1.2792,  0.2517,  0.2313,  1.1448, -0.0162,  0.0133, -0.0713,  2.2266],
       device='cuda:1')
Solve time for step 1 9.29878324904712
Current ori: tensor([-0.0162,  0.0133, -0.0713], device='cuda:1')
Index force: tensor([0.5872, 0.5805, 0.5719, 0.5729], device='cuda:1')
tensor([ 0.1343,  0.6156,  0.5714,  0.5532, -0.2316,  0.4933,  0.9013,  0.8979,
         1.2440,  0.2314,  0.1523,  1.1167, -0.0173,  0.0147, -0.0713,  2.2148],
       device='cuda:1')
Solve time for step 2 3.88079269498121
Current ori: tensor([-0.0173,  0.0147, -0.0713], device='cuda:1')
Index force: tensor([0.5704, 0.5636, 0.5648], device='cuda:1')
tensor([ 0.1396,  0.6120,  0.5818,  0.5546, -0.2322,  0.5125,  0.8988,  0.8805,
         1.2469,  0.2412,  0.1393,  1.0956, -0.0163,  0.0116, -0.0713,  2.2238],
       device='cuda:1')
Solve time for step 3 3.413633169955574
Current ori: tensor([-0.0163,  0.0116, -0.0713], device='cuda:1')
Index force: tensor([0.5525, 0.5548], device='cuda:1')
tensor([ 0.1376,  0.6042,  0.5814,  0.5719, -0.2301,  0.5136,  0.8831,  0.8889,
         1.2426,  0.2325,  0.1500,  1.0973, -0.0134,  0.0135, -0.0713,  2.2265],
       device='cuda:1')
Solve time for step 4 3.2972268370212987
Current ori: tensor([-0.0134,  0.0135, -0.0713], device='cuda:1')
Index force: tensor([0.5816], device='cuda:1')
Storing RECOVERY transition: reward=0.0073 (scaled=0.0073), steps=0
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0738
Collected 302 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=1.0148, Q2 Loss=1.0148, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2654
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.7360, Q2 Loss=0.7360, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2724
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.6687, Q2 Loss=0.6687, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4472
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=0.8118, Q2 Loss=0.8118, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8739
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.6601, Q2 Loss=1.6601, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6851

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (41.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008663
Q1 loss: 0.978301
Q2 loss: 0.978301
Current threshold: -149.5335
Global Scale Offset: 1655.1351
Reward stats: mean=0.0156, std=0.0738, count=302
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 0.9783, Q2 Loss: 0.9783, Entropy: 0.6929, Mean TD Error: 0.9088, Threshold: -149.5335
Original likelihood: -135.63079833984375
Adjusted likelihood: -135.63079833984375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5033)
State is out of distribution
Projection step: 0, Loss: 140.13885498046875
Projection step: 1, Loss: 128.78286743164062
Projection step: 2, Loss: 125.21658325195312
Projection step: 3, Loss: 116.1182861328125
Projection step: 4, Loss: 117.37135314941406
Projection step: 5, Loss: 115.58881378173828
Projection step: 6, Loss: 110.4305648803711
Projection step: 7, Loss: 102.92436218261719
Final likelihood: tensor([-105.5008, -116.7332,  -98.8775,  -94.8501, -104.0864,  -83.5601,
         -86.8113, -101.1439,  -91.6477, -127.8291, -120.8074,  -98.6430,
         -99.9871, -101.7510, -122.6535,  -91.9076])
Final projection likelihood: -102.9244
1 mode projection succeeded
New goal: tensor([ 0.1127,  0.5872,  0.5712,  0.5584, -0.1182,  0.5709,  0.9167,  0.8653,
         1.3144,  0.2768,  0.2062,  1.1227, -0.0150,  0.0166, -0.0568],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -122.955078125
Adjusted likelihood: -122.955078125
Likelihood residual: 0.0
Original likelihood: -123.57786560058594
Adjusted likelihood: -123.57786560058594
Likelihood residual: 0.0
{'index': 123.57786560058594, 'thumb_middle': 122.955078125}
Current yaw: tensor([-0.0154,  0.0162, -0.0786], device='cuda:1')
5 thumb_middle
tensor([ 0.1310,  0.6134,  0.5696,  0.5571, -0.1662,  0.5582,  0.9250,  0.9055,
         1.3114,  0.2620,  0.2005,  1.1255, -0.0154,  0.0162, -0.0786,  2.2190],
       device='cuda:1')
Solve time for step 1 9.180248804041184
Current ori: tensor([-0.0154,  0.0162, -0.0786], device='cuda:1')
Index force: tensor([0.5854, 0.5946, 0.5991, 0.5732], device='cuda:1')
tensor([ 0.1157,  0.6200,  0.5555,  0.5362, -0.2363,  0.5315,  0.8750,  0.8488,
         1.2693,  0.2548,  0.1313,  1.0927, -0.0193,  0.0251, -0.0786,  2.1928],
       device='cuda:1')
Solve time for step 2 3.5439833579584956
Current ori: tensor([-0.0193,  0.0251, -0.0786], device='cuda:1')
Index force: tensor([0.5844, 0.5907, 0.5667], device='cuda:1')
tensor([ 0.1144,  0.6210,  0.5533,  0.5352, -0.2395,  0.5359,  0.8733,  0.8405,
         1.2753,  0.2551,  0.1228,  1.0900, -0.0196,  0.0258, -0.0786,  2.1908],
       device='cuda:1')
Solve time for step 3 3.4465109939919785
Current ori: tensor([-0.0196,  0.0258, -0.0786], device='cuda:1')
Index force: tensor([0.5817, 0.5607], device='cuda:1')
tensor([ 0.1227,  0.6133,  0.5660,  0.5474, -0.2381,  0.5370,  0.8748,  0.8396,
         1.2758,  0.2546,  0.1181,  1.0856, -0.0171,  0.0215, -0.0786,  2.2061],
       device='cuda:1')
Solve time for step 4 3.4023735279915854
Current ori: tensor([-0.0171,  0.0215, -0.0786], device='cuda:1')
Index force: tensor([0.5479], device='cuda:1')
Storing RECOVERY transition: reward=0.0133 (scaled=0.0133), steps=0
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0737
Collected 303 transitions for RL
SAC Update 1/5: Actor Loss=-0.0070, Q1 Loss=0.8545, Q2 Loss=0.8545, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7933
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=0.9434, Q2 Loss=0.9434, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9689
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=4.3631, Q2 Loss=4.3631, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9028
SAC Update 4/5: Actor Loss=-0.0118, Q1 Loss=1.1212, Q2 Loss=1.1212, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4410
SAC Update 5/5: Actor Loss=-0.0133, Q1 Loss=1.3311, Q2 Loss=1.3311, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6944

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.1%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010571
Q1 loss: 1.722674
Q2 loss: 1.722674
Current threshold: -149.5332
Global Scale Offset: 1670.2532
Reward stats: mean=0.0156, std=0.0737, count=303
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.7227, Q2 Loss: 1.7227, Entropy: 0.6929, Mean TD Error: 1.7601, Threshold: -149.5332
Original likelihood: -145.62875366210938
Adjusted likelihood: -145.62875366210938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5009)
State is out of distribution
Projection step: 0, Loss: 140.2568359375
Projection step: 1, Loss: 132.3043975830078
Projection step: 2, Loss: 136.8891143798828
Projection step: 3, Loss: 125.48615264892578
Projection step: 4, Loss: 125.80996704101562
Projection step: 5, Loss: 113.67765808105469
Projection step: 6, Loss: 115.52760314941406
Projection step: 7, Loss: 111.26808166503906
Projection step: 8, Loss: 102.95044708251953
Final likelihood: tensor([ -87.0506, -104.9530,  -87.3798,  -97.7144, -133.6064, -100.0370,
         -98.6154, -128.4853, -100.7525, -117.3733, -101.6604, -117.1748,
         -99.8943,  -91.5018, -106.6527,  -74.3555])
Final projection likelihood: -102.9505
1 mode projection succeeded
New goal: tensor([ 0.1089,  0.5853,  0.5611,  0.5790, -0.1176,  0.5970,  0.9015,  0.8160,
         1.3371,  0.2854,  0.1984,  1.1323, -0.0148,  0.0186,  0.1807],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -116.16317749023438
Adjusted likelihood: -116.16317749023438
Likelihood residual: 0.0
Original likelihood: -130.11805725097656
Adjusted likelihood: -130.11805725097656
Likelihood residual: 0.0
{'index': 130.11805725097656, 'thumb_middle': 116.16317749023438}
Current yaw: tensor([-0.0151,  0.0192, -0.0847], device='cuda:1')
6 thumb_middle
tensor([ 0.1261,  0.6081,  0.5719,  0.5571, -0.1722,  0.5839,  0.9106,  0.8597,
         1.3356,  0.2776,  0.1720,  1.1162, -0.0151,  0.0192, -0.0847,  2.2293],
       device='cuda:1')
Solve time for step 1 9.04065050999634
Current ori: tensor([-0.0151,  0.0192, -0.0847], device='cuda:1')
Index force: tensor([0.5907, 0.5967, 0.5943, 0.5894], device='cuda:1')
tensor([ 0.1302,  0.6088,  0.5693,  0.5683, -0.2341,  0.5609,  0.8695,  0.8048,
         1.2842,  0.2736,  0.0934,  1.0956, -0.0147,  0.0176, -0.0847,  2.2278],
       device='cuda:1')
Solve time for step 2 3.7253778710146435
Current ori: tensor([-0.0147,  0.0176, -0.0847], device='cuda:1')
Index force: tensor([0.5850, 0.5841, 0.5803], device='cuda:1')
tensor([ 0.1213,  0.5937,  0.5738,  0.5817, -0.2401,  0.5678,  0.8593,  0.7999,
         1.2782,  0.2481,  0.1163,  1.0999, -0.0103,  0.0236, -0.0847,  2.2204],
       device='cuda:1')
Solve time for step 3 3.555099870020058
Current ori: tensor([-0.0103,  0.0236, -0.0847], device='cuda:1')
Index force: tensor([0.5725, 0.5703], device='cuda:1')
tensor([ 0.1223,  0.5912,  0.5681,  0.6015, -0.2361,  0.5702,  0.8571,  0.7811,
         1.2893,  0.2712,  0.0979,  1.0906, -0.0083,  0.0234, -0.0847,  2.2246],
       device='cuda:1')
Solve time for step 4 3.4723861509701237
Current ori: tensor([-0.0083,  0.0234, -0.0847], device='cuda:1')
Index force: tensor([0.5564], device='cuda:1')
Storing RECOVERY transition: reward=0.0271 (scaled=0.0271), steps=0
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0736
Collected 304 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.8046, Q2 Loss=0.8046, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7832
SAC Update 2/5: Actor Loss=-0.0094, Q1 Loss=0.9772, Q2 Loss=0.9772, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0598
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.8130, Q2 Loss=0.8130, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3146
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=0.8369, Q2 Loss=0.8369, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6932
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.5999, Q2 Loss=1.5999, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6410

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (20.1%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.1%)
Actor update: 0.08s (38.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008975
Q1 loss: 1.006333
Q2 loss: 1.006333
Current threshold: -149.5331
Global Scale Offset: 1682.0426
Reward stats: mean=0.0157, std=0.0736, count=304
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.0063, Q2 Loss: 1.0063, Entropy: 0.6930, Mean TD Error: 1.0984, Threshold: -149.5331
Original likelihood: -152.24850463867188
Adjusted likelihood: -152.24850463867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4994)
Current yaw: tensor([-0.0089,  0.0258, -0.0987], device='cuda:1')
7 turn
Sampling time 3.721580980985891
tensor([ 0.1162,  0.5919,  0.5714,  0.5809, -0.1839,  0.6074,  0.8930,  0.8117,
         1.3480,  0.2891,  0.1657,  1.1149, -0.0089,  0.0258, -0.0987,  2.2315],
       device='cuda:1')
Original likelihood: -140.7386016845703
Adjusted likelihood: -140.7386016845703
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5021)
State is out of distribution
Projection step: 0, Loss: 143.38185119628906
Projection step: 1, Loss: 140.41287231445312
Projection step: 2, Loss: 138.9673309326172
Projection step: 3, Loss: 127.70779418945312
Projection step: 4, Loss: 131.60137939453125
Projection step: 5, Loss: 123.39266204833984
Projection step: 6, Loss: 117.33377075195312
Projection step: 7, Loss: 114.414794921875
Projection step: 8, Loss: 108.71131896972656
Projection step: 9, Loss: 111.9444808959961
Projection step: 10, Loss: 104.363037109375
Final likelihood: tensor([-120.4265, -111.4173,  -98.7447, -110.6232,  -97.3341, -102.5882,
         -96.8691, -114.4753, -104.0439, -120.8561, -118.6681,  -90.1837,
         -85.5463,  -93.7645, -108.7849,  -95.4828])
Final projection likelihood: -104.3630
1 mode projection succeeded
New goal: tensor([ 0.1024,  0.5698,  0.5649,  0.6035, -0.1175,  0.6165,  0.8841,  0.7747,
         1.3348,  0.2870,  0.1967,  1.1574, -0.0089,  0.0209,  0.2383],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -245.05735778808594
Adjusted likelihood: -245.05735778808594
Likelihood residual: 0.0
Original likelihood: -125.47547149658203
Adjusted likelihood: -125.47547149658203
Likelihood residual: 0.0
{'index': 125.47547149658203, 'thumb_middle': 245.05735778808594}
Current yaw: tensor([-0.0089,  0.0258, -0.0987], device='cuda:1')
8 index
tensor([ 0.1162,  0.5919,  0.5714,  0.5809, -0.1839,  0.6074,  0.8930,  0.8117,
         1.3480,  0.2891,  0.1657,  1.1149, -0.0089,  0.0258, -0.0987,  2.2315],
       device='cuda:1')
Solve time for step 1 10.432010671996977
Current ori: tensor([-0.0089,  0.0258, -0.0987], device='cuda:1')
Middle force: tensor([0.5801, 0.5650, 0.5013, 0.5980], device='cuda:1')
Thumb force: tensor([0.5715, 0.5687, 0.5503, 0.5423], device='cuda:1')
tensor([ 0.1522,  0.5217,  0.5194,  0.5763, -0.1810,  0.6057,  0.9027,  0.8038,
         1.3518,  0.2822,  0.1592,  1.1140, -0.0101,  0.0232, -0.1079,  2.5993],
       device='cuda:1')
Solve time for step 2 4.345079681021161
Current ori: tensor([-0.0101,  0.0232, -0.1079], device='cuda:1')
Middle force: tensor([0.6033, 0.5296, 0.5202], device='cuda:1')
Thumb force: tensor([0.5477, 0.6198, 0.5853], device='cuda:1')
tensor([ 0.1534,  0.5198,  0.5182,  0.5778, -0.1673,  0.6224,  0.8928,  0.7883,
         1.3480,  0.2832,  0.1447,  1.1161, -0.0172,  0.0147, -0.1041,  2.6996],
       device='cuda:1')
Solve time for step 3 4.005336784990504
Current ori: tensor([-0.0172,  0.0147, -0.1041], device='cuda:1')
Middle force: tensor([0.5200, 0.5584], device='cuda:1')
Thumb force: tensor([0.5853, 0.5687], device='cuda:1')
tensor([ 0.1527,  0.5206,  0.5182,  0.5789, -0.1615,  0.6202,  0.8998,  0.7938,
         1.3473,  0.2811,  0.1342,  1.1255, -0.0161,  0.0100, -0.1159,  2.6631],
       device='cuda:1')
Solve time for step 4 4.00888430303894
Current ori: tensor([-0.0161,  0.0100, -0.1159], device='cuda:1')
Middle force: tensor([0.5073], device='cuda:1')
Thumb force: tensor([0.5151], device='cuda:1')
Storing RECOVERY transition: reward=0.0245 (scaled=0.0245), steps=0
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0734
Collected 305 transitions for RL
SAC Update 1/5: Actor Loss=-0.0111, Q1 Loss=4.7458, Q2 Loss=4.7458, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3028
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=4.7578, Q2 Loss=4.7578, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3028
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.4846, Q2 Loss=1.4846, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1160
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=3.5608, Q2 Loss=3.5608, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.8910
SAC Update 5/5: Actor Loss=-0.0091, Q1 Loss=2.0832, Q2 Loss=2.0832, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0003

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.3%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010834
Q1 loss: 3.326426
Q2 loss: 3.326426
Current threshold: -149.5331
Global Scale Offset: 1698.3207
Reward stats: mean=0.0157, std=0.0734, count=305
----------------------------------------------
SAC Update - Actor Loss: -0.0108, Q1 Loss: 3.3264, Q2 Loss: 3.3264, Entropy: 0.6928, Mean TD Error: 3.3226, Threshold: -149.5331
Original likelihood: -133.48812866210938
Adjusted likelihood: -133.48812866210938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5038)
Current yaw: tensor([-0.0159,  0.0159, -0.1230], device='cuda:1')
9 turn
Sampling time 3.630210541014094
tensor([ 0.0962,  0.5799,  0.5595,  0.6008, -0.1698,  0.6148,  0.9011,  0.7953,
         1.3456,  0.2945,  0.1406,  1.1253, -0.0159,  0.0159, -0.1230,  2.6274],
       device='cuda:1')
Original likelihood: -135.9717254638672
Adjusted likelihood: -135.9717254638672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5032)
Solve time for step 1 14.050611114013009
Current ori: tensor([-0.0159,  0.0159, -0.1230], device='cuda:1')
Middle force: tensor([0.6127, 0.7612, 0.5336, 1.4751, 0.5549, 0.4851, 0.6996, 0.4951, 0.5378,
        0.5490, 0.4838, 0.5629], device='cuda:1')
Thumb force: tensor([1.5809, 0.7068, 2.2303, 1.1039, 2.0228, 0.5017, 0.9365, 0.5748, 0.6019,
        0.9227, 0.6075, 1.3682], device='cuda:1')
Index force: tensor([0.9153, 0.7395, 0.5822, 0.8713, 0.7145, 0.7550, 0.5489, 0.7619, 0.6912,
        0.5330, 0.8064, 0.5998], device='cuda:1')
Storing NORMAL transition: reward=-0.0955 (scaled=-0.0955), steps=1
Reward stats updated: mean 0.0157 -> 0.0153, std: 0.0736
Collected 306 transitions for RL
SAC Update 1/5: Actor Loss=-0.0126, Q1 Loss=2.3703, Q2 Loss=2.3703, Entropy=0.6915, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1353
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.3578, Q2 Loss=1.3578, Entropy=0.6922, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3119
SAC Update 3/5: Actor Loss=-0.0098, Q1 Loss=2.4161, Q2 Loss=2.4161, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1117
SAC Update 4/5: Actor Loss=-0.0130, Q1 Loss=1.1837, Q2 Loss=1.1837, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1243
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8687, Q2 Loss=0.8687, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6190

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.6%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010310
Q1 loss: 1.639302
Q2 loss: 1.639302
Current threshold: -149.5332
Global Scale Offset: 1715.4508
Reward stats: mean=0.0153, std=0.0736, count=306
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.6393, Q2 Loss: 1.6393, Entropy: 0.6926, Mean TD Error: 2.0605, Threshold: -149.5332
tensor([ 0.0855,  0.5590,  0.5743,  0.6076, -0.1749,  0.6609,  0.8200,  0.8008,
         1.3304,  0.3077,  0.1406,  1.1832, -0.0110,  0.0228, -0.0275,  2.5194],
       device='cuda:1')
Original likelihood: -137.02267456054688
Adjusted likelihood: -137.02267456054688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5029)
Solve time for step 2 5.595105456013698
Current ori: tensor([-0.0110,  0.0228, -0.0275], device='cuda:1')
Middle force: tensor([0.7551, 0.5653, 1.5632, 0.6038, 0.5107, 0.6007, 0.5039, 0.5896, 0.5698,
        0.5072, 0.5675], device='cuda:1')
Thumb force: tensor([0.7869, 2.2066, 1.1205, 1.9697, 0.5036, 0.5006, 0.6440, 0.5194, 0.5986,
        0.6234, 0.6148], device='cuda:1')
Index force: tensor([0.7460, 0.5481, 0.9038, 0.6856, 0.7290, 0.5540, 0.6362, 0.5847, 0.6037,
        0.5928, 0.5647], device='cuda:1')
Storing NORMAL transition: reward=0.1528 (scaled=0.1528), steps=1
Reward stats updated: mean 0.0153 -> 0.0158, std: 0.0739
Collected 307 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.2622, Q2 Loss=1.2622, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6004
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=0.8075, Q2 Loss=0.8075, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6191
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.8652, Q2 Loss=0.8652, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8469
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.6848, Q2 Loss=0.6848, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1783
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.9198, Q2 Loss=0.9198, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5060

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.4%)
Q1 update: 0.06s (19.8%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008174
Q1 loss: 0.907891
Q2 loss: 0.907891
Current threshold: -149.5333
Global Scale Offset: 1726.3318
Reward stats: mean=0.0158, std=0.0739, count=307
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.9079, Q2 Loss: 0.9079, Entropy: 0.6929, Mean TD Error: 0.9501, Threshold: -149.5333
tensor([ 0.1296,  0.5769,  0.5582,  0.6733, -0.2044,  0.6129,  0.8874,  0.9653,
         1.3122,  0.3974,  0.1817,  1.0587, -0.0074,  0.0174, -0.1802,  2.5639],
       device='cuda:1')
Original likelihood: -166.45472717285156
Adjusted likelihood: -166.45472717285156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4961)
Solve time for step 3 5.209498701966368
Current ori: tensor([-0.0074,  0.0174, -0.1802], device='cuda:1')
Middle force: tensor([0.5645, 1.5724, 0.6127, 0.5043, 0.6007, 0.5033, 0.5890, 0.5656, 0.5070,
        0.5628], device='cuda:1')
Thumb force: tensor([2.1620, 1.1003, 1.9272, 0.5031, 0.5007, 0.6550, 0.5189, 0.6033, 0.6205,
        0.6207], device='cuda:1')
Index force: tensor([0.5451, 0.8997, 0.6717, 0.7920, 0.5523, 0.6298, 0.5823, 0.5968, 0.5903,
        0.5604], device='cuda:1')
Storing NORMAL transition: reward=0.1882 (scaled=0.1882), steps=1
Reward stats updated: mean 0.0158 -> 0.0163, std: 0.0744
Collected 308 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7366, Q2 Loss=0.7366, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2638
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=1.4788, Q2 Loss=1.4788, Entropy=0.6923, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3455
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=1.0229, Q2 Loss=1.0229, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6709
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.6916, Q2 Loss=0.6916, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4248
SAC Update 5/5: Actor Loss=-0.0089, Q1 Loss=1.6326, Q2 Loss=1.6326, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7005

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.6%)
Actor update: 0.09s (40.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008111
Q1 loss: 1.112484
Q2 loss: 1.112484
Current threshold: -149.5331
Global Scale Offset: 1732.4857
Reward stats: mean=0.0163, std=0.0744, count=308
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.1125, Q2 Loss: 1.1125, Entropy: 0.6929, Mean TD Error: 1.8811, Threshold: -149.5331
tensor([ 0.0674,  0.5286,  0.4932,  0.5833, -0.1762,  0.5697,  0.9981,  0.8333,
         1.3799,  0.3358,  0.1879,  0.8756, -0.0403,  0.0080, -0.3710,  2.6826],
       device='cuda:1')
Original likelihood: -158.06288146972656
Adjusted likelihood: -158.06288146972656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4980)
State is out of distribution
Projection step: 0, Loss: 153.427001953125
Projection step: 1, Loss: 147.72071838378906
Projection step: 2, Loss: 138.6684112548828
Projection step: 3, Loss: 124.60284423828125
Projection step: 4, Loss: 119.23091125488281
Projection step: 5, Loss: 108.35287475585938
Projection step: 6, Loss: 99.01129913330078
Final likelihood: tensor([ -98.3240,  -99.8858,  -94.5713, -109.7818, -104.1683,  -98.3433,
         -98.5460,  -98.9426,  -92.9516, -100.4068,  -88.6439, -104.2488,
         -94.8899,  -89.0802, -105.3500, -106.0465])
Final projection likelihood: -99.0113
1 mode projection succeeded
New goal: tensor([ 0.0721,  0.5415,  0.5211,  0.6475, -0.1231,  0.5648,  0.9870,  0.8069,
         1.3738,  0.3101,  0.1838,  0.9411, -0.0398,  0.0079, -0.3433],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0083]], device='cuda:1')
Original likelihood: -141.3404541015625
Adjusted likelihood: -141.3404541015625
Likelihood residual: 0.0
{'index': 141.3404541015625, 'thumb_middle': inf}
Current yaw: tensor([-0.0403,  0.0080, -0.3710], device='cuda:1')
10 index
tensor([ 0.0674,  0.5286,  0.4932,  0.5833, -0.1762,  0.5697,  0.9981,  0.8333,
         1.3799,  0.3358,  0.1879,  0.8756, -0.0403,  0.0080, -0.3710,  2.6826],
       device='cuda:1')
Solve time for step 1 10.552722182008438
Current ori: tensor([-0.0403,  0.0080, -0.3710], device='cuda:1')
Middle force: tensor([0.5401, 0.5377, 0.5454, 0.5903], device='cuda:1')
Thumb force: tensor([0.5322, 0.5916, 0.5802, 0.5638], device='cuda:1')
tensor([ 9.5701e-02,  4.9301e-01,  4.7900e-01,  6.1017e-01, -1.6710e-01,
         5.7319e-01,  1.0041e+00,  8.2699e-01,  1.3988e+00,  2.9424e-01,
         1.5646e-01,  8.9709e-01, -4.1218e-02,  5.7160e-04, -3.7116e-01,
         2.5215e+00], device='cuda:1')
Solve time for step 2 4.202422984002624
Current ori: tensor([-0.0412,  0.0006, -0.3712], device='cuda:1')
Middle force: tensor([0.5331, 0.5419, 0.5848], device='cuda:1')
Thumb force: tensor([0.5882, 0.5764, 0.5601], device='cuda:1')
tensor([ 0.0987,  0.4924,  0.4779,  0.6252, -0.1590,  0.5781,  1.0158,  0.8273,
         1.3651,  0.3442,  0.1572,  0.9163, -0.0400, -0.0094, -0.3676,  2.3742],
       device='cuda:1')
Solve time for step 3 3.956689301005099
Current ori: tensor([-0.0400, -0.0094, -0.3676], device='cuda:1')
Middle force: tensor([0.5133, 0.5328], device='cuda:1')
Thumb force: tensor([0.5659, 0.5000], device='cuda:1')
tensor([ 0.0985,  0.4942,  0.4786,  0.6237, -0.1484,  0.5918,  1.0077,  0.8166,
         1.3879,  0.3118,  0.1318,  0.9076, -0.0496, -0.0158, -0.3961,  2.3439],
       device='cuda:1')
Solve time for step 4 3.8642908839974552
Current ori: tensor([-0.0496, -0.0158, -0.3961], device='cuda:1')
Middle force: tensor([0.5627], device='cuda:1')
Thumb force: tensor([0.5350], device='cuda:1')
Storing RECOVERY transition: reward=0.0038 (scaled=0.0013), steps=3
Reward stats updated: mean 0.0163 -> 0.0163, std: 0.0743
Collected 309 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.0399, Q2 Loss=1.0399, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6712
SAC Update 2/5: Actor Loss=-0.0106, Q1 Loss=1.1055, Q2 Loss=1.1055, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7330
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=1.1493, Q2 Loss=1.1493, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1455
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=0.8924, Q2 Loss=0.8924, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8095
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.9511, Q2 Loss=0.9511, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8201

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.6%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009505
Q1 loss: 1.027633
Q2 loss: 1.027633
Current threshold: -149.5328
Global Scale Offset: 1738.3722
Reward stats: mean=0.0163, std=0.0743, count=309
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.0276, Q2 Loss: 1.0276, Entropy: 0.6929, Mean TD Error: 1.2359, Threshold: -149.5328
Original likelihood: -160.66860961914062
Adjusted likelihood: -160.66860961914062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4974)
Current yaw: tensor([-0.0463, -0.0177, -0.3763], device='cuda:1')
11 turn
Sampling time 3.6311914260149933
tensor([ 0.0525,  0.5546,  0.5214,  0.6471, -0.1541,  0.5975,  1.0126,  0.8194,
         1.3776,  0.3237,  0.1265,  0.9303, -0.0463, -0.0177, -0.3763,  2.3364],
       device='cuda:1')
Original likelihood: -205.74502563476562
Adjusted likelihood: -205.74502563476562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4871)
Solve time for step 1 13.923953416990116
Current ori: tensor([-0.0463, -0.0177, -0.3763], device='cuda:1')
Middle force: tensor([0.5412, 1.1148, 1.2450, 0.5418, 0.5828, 1.2803, 0.7346, 0.5898, 0.5908,
        0.5760, 0.6121, 0.5634], device='cuda:1')
Thumb force: tensor([0.5559, 0.9328, 1.5314, 0.7732, 0.6927, 1.1830, 1.1214, 0.5325, 1.4326,
        0.5403, 0.6684, 0.9424], device='cuda:1')
Index force: tensor([0.7087, 0.8899, 0.6275, 0.6213, 0.5646, 1.1026, 0.5666, 0.5539, 0.5588,
        0.5616, 0.6168, 0.6040], device='cuda:1')
Storing NORMAL transition: reward=-0.0006 (scaled=-0.0006), steps=1
Reward stats updated: mean 0.0163 -> 0.0162, std: 0.0742
Collected 310 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7156, Q2 Loss=0.7156, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7943
SAC Update 2/5: Actor Loss=-0.0107, Q1 Loss=1.9455, Q2 Loss=1.9455, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2660
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.6791, Q2 Loss=0.6791, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1474
SAC Update 4/5: Actor Loss=-0.0098, Q1 Loss=1.4977, Q2 Loss=1.4977, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1994
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=1.2211, Q2 Loss=1.2211, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9366

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.7%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008936
Q1 loss: 1.211814
Q2 loss: 1.211814
Current threshold: -149.5327
Global Scale Offset: 1745.2433
Reward stats: mean=0.0162, std=0.0742, count=310
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.2118, Q2 Loss: 1.2118, Entropy: 0.6931, Mean TD Error: 1.0687, Threshold: -149.5327
tensor([ 0.0361,  0.4589,  0.6461,  0.6238, -0.1532,  0.5681,  1.0590,  0.8156,
         1.3767,  0.3372,  0.1061,  0.9753, -0.0309, -0.0209, -0.3746,  2.1603],
       device='cuda:1')
Original likelihood: -193.18527221679688
Adjusted likelihood: -193.18527221679688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4900)
Solve time for step 2 5.452254558040295
Current ori: tensor([-0.0309, -0.0209, -0.3746], device='cuda:1')
Middle force: tensor([1.1122, 1.2351, 0.5444, 0.5829, 1.2860, 0.7281, 0.5932, 0.5889, 0.5769,
        0.6088, 0.5639], device='cuda:1')
Thumb force: tensor([0.9022, 1.5052, 0.7513, 0.6859, 1.1500, 1.1050, 0.5289, 1.4061, 0.5369,
        0.6611, 0.9255], device='cuda:1')
Index force: tensor([0.8733, 0.6151, 0.6101, 0.5585, 1.0724, 0.5632, 0.5469, 0.5556, 0.5579,
        0.6124, 0.5972], device='cuda:1')
Storing NORMAL transition: reward=0.0008 (scaled=0.0008), steps=1
Reward stats updated: mean 0.0162 -> 0.0162, std: 0.0741
Collected 311 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7255, Q2 Loss=0.7255, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2743
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.7527, Q2 Loss=0.7527, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2522
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.0618, Q2 Loss=1.0618, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7999
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.7169, Q2 Loss=0.7169, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7635
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8214, Q2 Loss=0.8214, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9161

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (19.8%)
Q2 update: 0.04s (20.0%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008174
Q1 loss: 0.815675
Q2 loss: 0.815675
Current threshold: -149.5326
Global Scale Offset: 1753.0753
Reward stats: mean=0.0162, std=0.0741, count=311
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.8157, Q2 Loss: 0.8157, Entropy: 0.6930, Mean TD Error: 0.8012, Threshold: -149.5326
tensor([ 0.0028,  0.4037,  0.6919,  0.6291, -0.1413,  0.4483,  1.0534,  0.6037,
         1.3824,  0.4096,  0.0730,  0.8794, -0.0221,  0.0063, -0.3746,  2.0589],
       device='cuda:1')
Original likelihood: -194.4645538330078
Adjusted likelihood: -194.4645538330078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4898)
Solve time for step 3 5.244736478023697
Current ori: tensor([-0.0221,  0.0063, -0.3746], device='cuda:1')
Middle force: tensor([1.1531, 0.5396, 0.5718, 1.2345, 0.7131, 0.5631, 0.5817, 0.5676, 0.6024,
        0.5560], device='cuda:1')
Thumb force: tensor([1.4934, 0.7400, 0.6805, 1.1291, 1.0987, 0.5283, 1.3883, 0.5379, 0.6558,
        0.9169], device='cuda:1')
Index force: tensor([0.6236, 0.6141, 0.5630, 1.0941, 0.5608, 0.5637, 0.5548, 0.5584, 0.6114,
        0.6002], device='cuda:1')
Storing NORMAL transition: reward=0.0373 (scaled=0.0373), steps=1
Reward stats updated: mean 0.0162 -> 0.0163, std: 0.0740
Collected 312 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=0.9964, Q2 Loss=0.9964, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1402
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.0272, Q2 Loss=1.0272, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7421
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.9271, Q2 Loss=0.9271, Entropy=0.6904, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8793
SAC Update 4/5: Actor Loss=-0.0123, Q1 Loss=1.1775, Q2 Loss=1.1775, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1617
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=1.0618, Q2 Loss=1.0618, Entropy=0.6904, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9396

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.5%)
Q1 update: 0.04s (17.5%)
Q2 update: 0.05s (20.4%)
Actor update: 0.11s (42.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010218
Q1 loss: 1.038008
Q2 loss: 1.038008
Current threshold: -149.5327
Global Scale Offset: 1765.3319
Reward stats: mean=0.0163, std=0.0740, count=312
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.0380, Q2 Loss: 1.0380, Entropy: 0.6919, Mean TD Error: 0.5726, Threshold: -149.5327
tensor([ 1.9319e-02,  2.8585e-01,  8.3818e-01,  6.5549e-01, -1.1854e-01,
         5.3062e-01,  1.0390e+00,  6.8051e-01,  1.4897e+00,  2.9669e-01,
         8.8209e-02,  8.4414e-01, -2.4988e-02,  5.1814e-04, -4.1211e-01,
         1.8562e+00], device='cuda:1')
Original likelihood: -168.81900024414062
Adjusted likelihood: -168.81900024414062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4956)
Solve time for step 4 4.938101251027547
Current ori: tensor([-0.0250,  0.0005, -0.4121], device='cuda:1')
Middle force: tensor([0.5407, 0.5712, 1.2375, 0.7053, 0.5657, 0.5784, 0.5652, 0.5994, 0.5539],
       device='cuda:1')
Thumb force: tensor([0.7257, 0.6781, 1.1083, 1.0886, 0.5273, 1.3709, 0.5373, 0.6504, 0.9079],
       device='cuda:1')
Index force: tensor([0.6053, 0.5578, 1.0602, 0.5575, 0.5568, 0.5519, 0.5561, 0.6083, 0.5955],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0199 (scaled=-0.0199), steps=1
Reward stats updated: mean 0.0163 -> 0.0161, std: 0.0739
Collected 313 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=1.2803, Q2 Loss=1.2803, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9131
SAC Update 2/5: Actor Loss=-0.0106, Q1 Loss=1.1267, Q2 Loss=1.1267, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9006
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=0.6631, Q2 Loss=0.6631, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2829
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=2.1753, Q2 Loss=2.1753, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3314
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.7188, Q2 Loss=0.7188, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2182

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (42.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009483
Q1 loss: 1.192829
Q2 loss: 1.192829
Current threshold: -149.5326
Global Scale Offset: 1781.8648
Reward stats: mean=0.0161, std=0.0739, count=313
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.1928, Q2 Loss: 1.1928, Entropy: 0.6930, Mean TD Error: 0.9292, Threshold: -149.5326
tensor([ 0.0569,  0.3150,  0.8255,  0.6690, -0.1037,  0.5687,  0.9574,  0.7465,
         1.4083,  0.4082,  0.1552,  0.8324, -0.0278, -0.0072, -0.3923,  1.7251],
       device='cuda:1')
Original likelihood: -149.30926513671875
Adjusted likelihood: -149.30926513671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5000)
Solve time for step 5 4.5499399559921585
Current ori: tensor([-0.0278, -0.0072, -0.3923], device='cuda:1')
Middle force: tensor([0.5676, 1.1984, 0.7004, 0.5545, 0.5751, 0.5609, 0.5948, 0.5505],
       device='cuda:1')
Thumb force: tensor([0.6714, 1.0982, 1.0732, 0.5273, 1.3493, 0.5373, 0.6456, 0.8972],
       device='cuda:1')
Index force: tensor([0.5551, 1.0624, 0.5558, 0.5617, 0.5507, 0.5551, 0.6064, 0.5942],
       device='cuda:1')
Storing NORMAL transition: reward=0.0455 (scaled=0.0455), steps=1
Reward stats updated: mean 0.0161 -> 0.0162, std: 0.0738
Collected 314 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.8547, Q2 Loss=0.8547, Entropy=0.6921, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1808
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.3744, Q2 Loss=1.3744, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6526
SAC Update 3/5: Actor Loss=-0.0139, Q1 Loss=3.5496, Q2 Loss=3.5496, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0404
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8085, Q2 Loss=0.8085, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8674
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=2.2766, Q2 Loss=2.2766, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3765

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (20.4%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009965
Q1 loss: 1.772775
Q2 loss: 1.772775
Current threshold: -149.5324
Global Scale Offset: 1796.5018
Reward stats: mean=0.0162, std=0.0738, count=314
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.7728, Q2 Loss: 1.7728, Entropy: 0.6928, Mean TD Error: 2.0236, Threshold: -149.5324
tensor([ 0.0020,  0.1978,  0.8427,  0.8552, -0.1363,  0.5054,  1.0036,  0.8170,
         1.4391,  0.3419,  0.2007,  0.7787, -0.0040,  0.0105, -0.4372,  1.7268],
       device='cuda:1')
Original likelihood: -343.742919921875
Adjusted likelihood: -343.742919921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4570)
State is out of distribution
Projection step: 0, Loss: 218.486328125
Projection step: 1, Loss: 272.98712158203125
Projection step: 2, Loss: 178.03158569335938
Projection step: 3, Loss: 192.802734375
Projection step: 4, Loss: 175.93386840820312
Projection step: 5, Loss: 172.78717041015625
Projection step: 6, Loss: 163.11415100097656
Projection step: 7, Loss: 164.35679626464844
Projection step: 8, Loss: 147.90579223632812
Projection step: 9, Loss: 148.95401000976562
Projection step: 10, Loss: 137.08346557617188
Projection step: 11, Loss: 125.12645721435547
Projection step: 12, Loss: 122.40927124023438
Projection step: 13, Loss: 112.10704040527344
Projection step: 14, Loss: 102.01953887939453
Final likelihood: tensor([-107.6910, -134.2069, -114.9856, -104.7100,  -95.7679, -120.5224,
         -82.9834, -125.1137,  -78.4056,  -86.4849,  -98.0183, -116.8799,
         -91.8423, -105.8163,  -92.6411,  -76.2433])
Final projection likelihood: -102.0195
1 mode projection succeeded
New goal: tensor([ 0.0339,  0.3521,  0.7228,  0.7813, -0.0960,  0.5100,  0.9479,  0.8517,
         1.3656,  0.2625,  0.2256,  0.8811, -0.0021,  0.0098, -0.4764],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -192.8427734375
Adjusted likelihood: -192.8427734375
Likelihood residual: 0.0
Original likelihood: -167.46600341796875
Adjusted likelihood: -167.46600341796875
Likelihood residual: 0.0
{'index': 167.46600341796875, 'thumb_middle': 192.8427734375}
Current yaw: tensor([-0.0040,  0.0105, -0.4372], device='cuda:1')
12 index
tensor([ 0.0020,  0.1978,  0.8427,  0.8552, -0.1363,  0.5054,  1.0036,  0.8170,
         1.4391,  0.3419,  0.2007,  0.7787, -0.0040,  0.0105, -0.4372,  1.7268],
       device='cuda:1')
Solve time for step 1 10.245410200965125
Current ori: tensor([-0.0040,  0.0105, -0.4372], device='cuda:1')
Middle force: tensor([0.5474, 0.5560, 0.5314, 0.5255], device='cuda:1')
Thumb force: tensor([0.5981, 0.6059, 0.6486, 0.5233], device='cuda:1')
tensor([ 0.0699,  0.2697,  0.6854,  0.7605, -0.1307,  0.5041,  0.9917,  0.8840,
         1.4486,  0.3109,  0.1610,  0.8505,  0.0093,  0.0023, -0.4336,  1.9479],
       device='cuda:1')
Solve time for step 2 4.270583812030964
Current ori: tensor([ 0.0093,  0.0023, -0.4336], device='cuda:1')
Middle force: tensor([0.5527, 0.5290, 0.5230], device='cuda:1')
Thumb force: tensor([0.5983, 0.6441, 0.5213], device='cuda:1')
tensor([ 7.3289e-02,  2.9018e-01,  6.6587e-01,  7.4604e-01, -1.3445e-01,
         5.2242e-01,  9.8556e-01,  8.7581e-01,  1.4555e+00,  3.0564e-01,
         1.5472e-01,  8.3417e-01,  1.8256e-03,  3.7561e-04, -4.5156e-01,
        -2.6680e+00], device='cuda:1')
Solve time for step 3 4.158389957039617
Current ori: tensor([ 1.8256e-03,  3.7561e-04, -4.5156e-01], device='cuda:1')
Middle force: tensor([0.5281, 0.5208], device='cuda:1')
Thumb force: tensor([0.6317, 0.5195], device='cuda:1')
tensor([ 0.0732,  0.2946,  0.6628,  0.7452, -0.1461,  0.5236,  0.9736,  0.8727,
         1.4629,  0.2950,  0.1591,  0.8380,  0.0047,  0.0089, -0.4346,  2.1206],
       device='cuda:1')
Solve time for step 4 3.869183407048695
Current ori: tensor([ 0.0047,  0.0089, -0.4346], device='cuda:1')
Middle force: tensor([0.5177], device='cuda:1')
Thumb force: tensor([0.5146], device='cuda:1')
Storing RECOVERY transition: reward=-0.0055 (scaled=-0.0011), steps=5
Reward stats updated: mean 0.0162 -> 0.0162, std: 0.0737
Collected 315 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=1.0050, Q2 Loss=1.0050, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8008
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=1.5656, Q2 Loss=1.5656, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6606
SAC Update 3/5: Actor Loss=-0.0133, Q1 Loss=1.2991, Q2 Loss=1.2991, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5394
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=1.6115, Q2 Loss=1.6115, Entropy=0.6905, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3051
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=1.6998, Q2 Loss=1.6998, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1219

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.6%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.8%)
Actor update: 0.09s (40.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011280
Q1 loss: 1.436195
Q2 loss: 1.436195
Current threshold: -149.5321
Global Scale Offset: 1814.1360
Reward stats: mean=0.0162, std=0.0737, count=315
----------------------------------------------
SAC Update - Actor Loss: -0.0113, Q1 Loss: 1.4362, Q2 Loss: 1.4362, Entropy: 0.6925, Mean TD Error: 1.2856, Threshold: -149.5321
Original likelihood: -164.1446533203125
Adjusted likelihood: -164.1446533203125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4968)
Current yaw: tensor([ 0.0042,  0.0023, -0.4316], device='cuda:1')
13 turn
Sampling time 3.5994687610073015
tensor([ 3.0301e-02,  3.5291e-01,  7.1206e-01,  7.7585e-01, -1.3645e-01,
         5.2921e-01,  9.7484e-01,  8.6940e-01,  1.4538e+00,  3.0623e-01,
         1.5202e-01,  8.4987e-01,  4.2012e-03,  2.2761e-03, -4.3162e-01,
         3.1890e+00], device='cuda:1')
Original likelihood: -144.35386657714844
Adjusted likelihood: -144.35386657714844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5011)
State is out of distribution
Projection step: 0, Loss: 150.291748046875
Projection step: 1, Loss: 148.7034149169922
Projection step: 2, Loss: 138.9812469482422
Projection step: 3, Loss: 137.23739624023438
Projection step: 4, Loss: 122.21038055419922
Projection step: 5, Loss: 127.19657135009766
Projection step: 6, Loss: 118.7092056274414
Projection step: 7, Loss: 121.0442886352539
Projection step: 8, Loss: 109.22612762451172
Projection step: 9, Loss: 111.8420181274414
Projection step: 10, Loss: 97.48603057861328
Final likelihood: tensor([-114.2379,  -93.6175, -105.1695, -140.5027,  -93.2236,  -89.7343,
         -92.1985,  -79.9875, -120.9693,  -69.8478,  -97.9411, -111.9445,
         -79.5502,  -83.4861,  -90.4784,  -96.8875])
Final projection likelihood: -97.4860
1 mode projection succeeded
New goal: tensor([ 0.0590,  0.4334,  0.6899,  0.7282, -0.0953,  0.5295,  0.9505,  0.8898,
         1.4008,  0.2841,  0.1847,  0.9392,  0.0018,  0.0062, -0.5950],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -118.50519561767578
Adjusted likelihood: -118.50519561767578
Likelihood residual: 0.0
Original likelihood: -138.57862854003906
Adjusted likelihood: -138.57862854003906
Likelihood residual: 0.0
{'index': 138.57862854003906, 'thumb_middle': 118.50519561767578}
Current yaw: tensor([ 0.0042,  0.0023, -0.4316], device='cuda:1')
14 thumb_middle
tensor([ 3.0301e-02,  3.5291e-01,  7.1206e-01,  7.7585e-01, -1.3645e-01,
         5.2921e-01,  9.7484e-01,  8.6940e-01,  1.4538e+00,  3.0623e-01,
         1.5202e-01,  8.4987e-01,  4.2012e-03,  2.2761e-03, -4.3162e-01,
         3.1890e+00], device='cuda:1')
Solve time for step 1 9.009125957032666
Current ori: tensor([ 0.0042,  0.0023, -0.4316], device='cuda:1')
Index force: tensor([0.5515, 0.5945, 0.5938, 0.5845], device='cuda:1')
tensor([ 2.7939e-02,  3.6304e-01,  6.9731e-01,  7.7430e-01, -2.0576e-01,
         4.8542e-01,  9.1705e-01,  8.6397e-01,  1.3677e+00,  2.6901e-01,
         1.0375e-01,  8.8829e-01,  2.7418e-03,  3.6886e-03, -4.3159e-01,
         3.2059e+00], device='cuda:1')
Solve time for step 2 3.6566464479546994
Current ori: tensor([ 0.0027,  0.0037, -0.4316], device='cuda:1')
Index force: tensor([0.5845, 0.5866, 0.5783], device='cuda:1')
tensor([ 3.3974e-02,  3.8517e-01,  6.8921e-01,  7.4094e-01, -2.1538e-01,
         5.2333e-01,  8.9617e-01,  8.7083e-01,  1.3601e+00,  2.6596e-01,
         8.3123e-02,  9.0484e-01, -6.1309e-03,  8.4912e-04, -4.3159e-01,
         3.2048e+00], device='cuda:1')
Solve time for step 3 3.603213800000958
Current ori: tensor([-0.0061,  0.0008, -0.4316], device='cuda:1')
Index force: tensor([0.5784, 0.5719], device='cuda:1')
tensor([ 0.0437,  0.3966,  0.6859,  0.7330, -0.1961,  0.5164,  0.8985,  0.8569,
         1.3461,  0.2722,  0.0929,  0.8938, -0.0098, -0.0045, -0.4316,  3.2078],
       device='cuda:1')
Solve time for step 4 3.6584147599642165
Current ori: tensor([-0.0098, -0.0045, -0.4316], device='cuda:1')
Index force: tensor([0.5588], device='cuda:1')
Storing RECOVERY transition: reward=0.0058 (scaled=0.0058), steps=0
Reward stats updated: mean 0.0162 -> 0.0161, std: 0.0735
Collected 316 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.7774, Q2 Loss=0.7774, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4981
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.9481, Q2 Loss=0.9481, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1926
SAC Update 3/5: Actor Loss=-0.0116, Q1 Loss=1.6577, Q2 Loss=1.6577, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6893
SAC Update 4/5: Actor Loss=-0.0095, Q1 Loss=2.4861, Q2 Loss=2.4861, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1928
SAC Update 5/5: Actor Loss=-0.0137, Q1 Loss=1.2857, Q2 Loss=1.2857, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4155

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.9%)
Target Q: 0.04s (14.0%)
Q1 update: 0.06s (21.4%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (41.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010044
Q1 loss: 1.431001
Q2 loss: 1.431001
Current threshold: -149.5320
Global Scale Offset: 1832.5879
Reward stats: mean=0.0161, std=0.0735, count=316
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.4310, Q2 Loss: 1.4310, Entropy: 0.6928, Mean TD Error: 1.7976, Threshold: -149.5320
Original likelihood: -146.90457153320312
Adjusted likelihood: -146.90457153320312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 149.23873901367188
Projection step: 1, Loss: 131.90447998046875
Projection step: 2, Loss: 122.38604736328125
Projection step: 3, Loss: 128.51620483398438
Projection step: 4, Loss: 116.81770324707031
Projection step: 5, Loss: 117.64820861816406
Projection step: 6, Loss: 115.67046356201172
Projection step: 7, Loss: 109.77003479003906
Projection step: 8, Loss: 101.34014129638672
Final likelihood: tensor([ -82.0178, -107.4948, -111.6483, -124.6398,  -79.6601, -110.7631,
        -105.4619,  -98.6934, -102.6661, -101.9262, -102.3981, -100.6593,
        -105.5310,  -76.8679,  -96.3905, -114.6240])
Final projection likelihood: -101.3401
1 mode projection succeeded
New goal: tensor([ 0.0503,  0.4197,  0.7062,  0.7047, -0.0977,  0.5386,  0.9177,  0.8870,
         1.3760,  0.2702,  0.1809,  0.9620, -0.0023,  0.0060, -0.4621],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -98.04342651367188
Adjusted likelihood: -98.04342651367188
Likelihood residual: 0.0
Original likelihood: -129.75396728515625
Adjusted likelihood: -129.75396728515625
Likelihood residual: 0.0
{'index': 129.75396728515625, 'thumb_middle': 98.04342651367188}
Current yaw: tensor([-0.0034,  0.0026, -0.4374], device='cuda:1')
15 thumb_middle
tensor([ 2.9897e-02,  3.8479e-01,  6.8428e-01,  7.4616e-01, -1.4426e-01,
         5.4277e-01,  9.5828e-01,  8.9546e-01,  1.4158e+00,  2.8096e-01,
         1.4998e-01,  9.4036e-01, -3.3749e-03,  2.6265e-03, -4.3740e-01,
         3.2452e+00], device='cuda:1')
Solve time for step 1 8.901425628981087
Current ori: tensor([-0.0034,  0.0026, -0.4374], device='cuda:1')
Index force: tensor([0.5336, 0.5851, 0.5831, 0.5771], device='cuda:1')
tensor([ 3.9550e-02,  4.0140e-01,  6.8975e-01,  7.0497e-01, -1.9241e-01,
         5.2853e-01,  8.7964e-01,  8.4775e-01,  1.3399e+00,  2.4048e-01,
         9.6236e-02,  9.2883e-01, -1.4914e-02,  5.4315e-04, -4.3738e-01,
         3.1872e+00], device='cuda:1')
Solve time for step 2 3.638945638027508
Current ori: tensor([-0.0149,  0.0005, -0.4374], device='cuda:1')
Index force: tensor([0.5767, 0.5762, 0.5705], device='cuda:1')
tensor([ 0.0305,  0.3917,  0.6912,  0.7132, -0.2136,  0.5196,  0.8927,  0.8574,
         1.3390,  0.2580,  0.0995,  0.9276, -0.0125,  0.0065, -0.4374,  3.1704],
       device='cuda:1')
Solve time for step 3 3.508167016960215
Current ori: tensor([-0.0125,  0.0065, -0.4374], device='cuda:1')
Index force: tensor([0.5617, 0.5582], device='cuda:1')
tensor([ 0.0479,  0.3819,  0.7136,  0.7236, -0.2048,  0.5301,  0.8861,  0.8635,
         1.3226,  0.2613,  0.1103,  0.9206, -0.0080, -0.0038, -0.4374,  3.2008],
       device='cuda:1')
Solve time for step 4 3.4016612310078926
Current ori: tensor([-0.0080, -0.0038, -0.4374], device='cuda:1')
Index force: tensor([0.5486], device='cuda:1')
Storing RECOVERY transition: reward=0.0096 (scaled=0.0096), steps=0
Reward stats updated: mean 0.0161 -> 0.0161, std: 0.0734
Collected 317 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=1.1424, Q2 Loss=1.1424, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4305
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8162, Q2 Loss=0.8162, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4967
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.9116, Q2 Loss=0.9116, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9504
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=1.0735, Q2 Loss=1.0735, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0962
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.8424, Q2 Loss=0.8424, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7741

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008941
Q1 loss: 0.957227
Q2 loss: 0.957227
Current threshold: -149.5315
Global Scale Offset: 1844.2833
Reward stats: mean=0.0161, std=0.0734, count=317
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9572, Q2 Loss: 0.9572, Entropy: 0.6930, Mean TD Error: 0.9496, Threshold: -149.5315
Original likelihood: -114.91741943359375
Adjusted likelihood: -114.91741943359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5075)
Current yaw: tensor([-0.0034, -0.0079, -0.4412], device='cuda:1')
16 turn
Sampling time 3.623316579964012
tensor([ 0.0410,  0.3836,  0.7043,  0.7255, -0.1241,  0.5727,  0.9265,  0.8821,
         1.3811,  0.2772,  0.1615,  0.9640, -0.0034, -0.0079, -0.4412,  3.2653],
       device='cuda:1')
Original likelihood: -107.22691345214844
Adjusted likelihood: -107.22691345214844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5091)
State is out of distribution
Projection step: 0, Loss: 110.86820983886719
Projection step: 1, Loss: 118.9452896118164
Projection step: 2, Loss: 104.03903198242188
Final likelihood: tensor([-140.2460,  -87.3532, -123.4213, -109.1656,  -87.9939, -105.0140,
        -137.1408, -100.1046,  -92.9026,  -85.9120, -140.2573, -105.2901,
         -81.9400,  -86.6608,  -90.5086,  -90.7137])
Final projection likelihood: -104.0390
1 mode projection succeeded
New goal: tensor([ 0.0427,  0.3961,  0.7125,  0.7258, -0.1099,  0.5748,  0.9069,  0.8723,
         1.3720,  0.2780,  0.1666,  0.9646, -0.0036, -0.0075, -0.3971],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -133.8221435546875
Adjusted likelihood: -133.8221435546875
Likelihood residual: 0.0
Original likelihood: -149.4175567626953
Adjusted likelihood: -149.4175567626953
Likelihood residual: 0.0
{'index': 149.4175567626953, 'thumb_middle': 133.8221435546875}
Current yaw: tensor([-0.0034, -0.0079, -0.4412], device='cuda:1')
17 thumb_middle
tensor([ 0.0410,  0.3836,  0.7043,  0.7255, -0.1241,  0.5727,  0.9265,  0.8821,
         1.3811,  0.2772,  0.1615,  0.9640, -0.0034, -0.0079, -0.4412,  3.2653],
       device='cuda:1')
Solve time for step 1 9.137841397023294
Current ori: tensor([-0.0034, -0.0079, -0.4412], device='cuda:1')
Index force: tensor([0.5519, 0.5035, 0.5957, 0.5884], device='cuda:1')
tensor([ 0.0576,  0.3544,  0.7298,  0.7841, -0.1973,  0.5575,  0.8847,  0.8594,
         1.3340,  0.2621,  0.0889,  0.9348,  0.0079, -0.0098, -0.4412,  3.2662],
       device='cuda:1')
Solve time for step 2 3.6586208129883744
Current ori: tensor([ 0.0079, -0.0098, -0.4412], device='cuda:1')
Index force: tensor([0.5030, 0.5838, 0.5772], device='cuda:1')
tensor([ 5.7632e-02,  3.6182e-01,  7.3070e-01,  7.6005e-01, -2.0836e-01,
         5.6013e-01,  8.7675e-01,  8.4224e-01,  1.3383e+00,  2.7119e-01,
         8.1257e-02,  9.4378e-01,  2.2887e-03, -9.3542e-03, -4.4124e-01,
         3.2434e+00], device='cuda:1')
Solve time for step 3 3.5234544170089066
Current ori: tensor([ 0.0023, -0.0094, -0.4412], device='cuda:1')
Index force: tensor([0.5734, 0.5693], device='cuda:1')
tensor([ 0.0482,  0.3847,  0.7068,  0.7312, -0.2095,  0.5620,  0.8682,  0.8396,
         1.3253,  0.2744,  0.0961,  0.9349, -0.0070, -0.0038, -0.4412,  3.2233],
       device='cuda:1')
Solve time for step 4 3.434795845998451
Current ori: tensor([-0.0070, -0.0038, -0.4412], device='cuda:1')
Index force: tensor([0.5403], device='cuda:1')
Storing RECOVERY transition: reward=0.0027 (scaled=0.0027), steps=0
Reward stats updated: mean 0.0161 -> 0.0161, std: 0.0733
Collected 318 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.0914, Q2 Loss=1.0914, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9620
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8229, Q2 Loss=0.8229, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4421
SAC Update 3/5: Actor Loss=-0.0128, Q1 Loss=1.7731, Q2 Loss=1.7731, Entropy=0.6907, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4342
SAC Update 4/5: Actor Loss=-0.0106, Q1 Loss=1.2162, Q2 Loss=1.2162, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0295
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.8029, Q2 Loss=0.8029, Entropy=0.6914, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4402

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009919
Q1 loss: 1.141300
Q2 loss: 1.141300
Current threshold: -149.5310
Global Scale Offset: 1858.2688
Reward stats: mean=0.0161, std=0.0733, count=318
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.1413, Q2 Loss: 1.1413, Entropy: 0.6921, Mean TD Error: 0.8616, Threshold: -149.5310
Original likelihood: -147.73342895507812
Adjusted likelihood: -147.73342895507812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5004)
Current yaw: tensor([-0.0028,  0.0026, -0.4439], device='cuda:1')
18 turn
Sampling time 3.6347310100100003
tensor([ 3.5965e-02,  3.7194e-01,  7.0985e-01,  7.3917e-01, -1.5255e-01,
         6.0164e-01,  9.0531e-01,  8.6279e-01,  1.3878e+00,  2.8936e-01,
         1.6184e-01,  9.6949e-01, -2.7788e-03,  2.6473e-03, -4.4393e-01,
         3.2320e+00], device='cuda:1')
Original likelihood: -145.5751953125
Adjusted likelihood: -145.5751953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5008)
State is out of distribution
Projection step: 0, Loss: 142.79287719726562
Projection step: 1, Loss: 134.76800537109375
Projection step: 2, Loss: 135.46139526367188
Projection step: 3, Loss: 131.8886260986328
Projection step: 4, Loss: 127.32160949707031
Projection step: 5, Loss: 116.61119079589844
Projection step: 6, Loss: 112.17259216308594
Projection step: 7, Loss: 109.0611343383789
Projection step: 8, Loss: 106.559326171875
Projection step: 9, Loss: 101.18936157226562
Final likelihood: tensor([ -90.4725,  -87.6995, -103.6064, -105.9203,  -84.4099, -127.4505,
        -108.8204, -101.7829, -107.2052, -110.2470, -108.1377,  -87.4773,
         -98.4256, -102.4112,  -95.4917,  -99.4715])
Final projection likelihood: -101.1894
1 mode projection succeeded
New goal: tensor([ 0.0566,  0.3991,  0.7357,  0.6943, -0.0998,  0.5910,  0.8593,  0.8638,
         1.3522,  0.2717,  0.1918,  1.0080, -0.0017,  0.0080, -0.4920],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -107.52835083007812
Adjusted likelihood: -107.52835083007812
Likelihood residual: 0.0
Original likelihood: -147.08428955078125
Adjusted likelihood: -147.08428955078125
Likelihood residual: 0.0
{'index': 147.08428955078125, 'thumb_middle': 107.52835083007812}
Current yaw: tensor([-0.0028,  0.0026, -0.4439], device='cuda:1')
19 thumb_middle
tensor([ 3.5965e-02,  3.7194e-01,  7.0985e-01,  7.3917e-01, -1.5255e-01,
         6.0164e-01,  9.0531e-01,  8.6279e-01,  1.3878e+00,  2.8936e-01,
         1.6184e-01,  9.6949e-01, -2.7788e-03,  2.6473e-03, -4.4393e-01,
         3.2320e+00], device='cuda:1')
Solve time for step 1 9.008380190993194
Current ori: tensor([-0.0028,  0.0026, -0.4439], device='cuda:1')
Index force: tensor([0.5707, 0.5711, 0.5899, 0.5016], device='cuda:1')
tensor([ 0.0515,  0.3769,  0.7308,  0.7082, -0.1859,  0.5702,  0.8212,  0.8530,
         1.2992,  0.2587,  0.1139,  0.9694, -0.0075, -0.0054, -0.4439,  3.2212],
       device='cuda:1')
Solve time for step 2 3.608496203960385
Current ori: tensor([-0.0075, -0.0054, -0.4439], device='cuda:1')
Index force: tensor([0.5662, 0.5655, 0.5814], device='cuda:1')
tensor([ 0.0528,  0.3703,  0.7377,  0.7145, -0.1942,  0.5785,  0.8228,  0.8495,
         1.3044,  0.2620,  0.1014,  0.9721, -0.0048, -0.0062, -0.4439,  3.2305],
       device='cuda:1')
Solve time for step 3 3.5224127279943787
Current ori: tensor([-0.0048, -0.0062, -0.4439], device='cuda:1')
Index force: tensor([0.5553, 0.5718], device='cuda:1')
tensor([ 4.5866e-02,  3.7224e-01,  7.3372e-01,  7.0503e-01, -2.0342e-01,
         5.8127e-01,  8.2308e-01,  8.4863e-01,  1.3047e+00,  2.5165e-01,
         1.0237e-01,  9.8303e-01, -6.8824e-03, -2.1748e-03, -4.4391e-01,
         3.2146e+00], device='cuda:1')
Solve time for step 4 3.3797509460127912
Current ori: tensor([-0.0069, -0.0022, -0.4439], device='cuda:1')
Index force: tensor([0.5563], device='cuda:1')
Storing RECOVERY transition: reward=-0.0006 (scaled=-0.0006), steps=0
Reward stats updated: mean 0.0161 -> 0.0160, std: 0.0732
Collected 319 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.8044, Q2 Loss=0.8044, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2958
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.8604, Q2 Loss=0.8604, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8934
SAC Update 3/5: Actor Loss=-0.0113, Q1 Loss=2.6861, Q2 Loss=2.6861, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7543
SAC Update 4/5: Actor Loss=-0.0120, Q1 Loss=1.9446, Q2 Loss=1.9446, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9077
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=1.0163, Q2 Loss=1.0163, Entropy=0.6922, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2958

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009751
Q1 loss: 1.462367
Q2 loss: 1.462367
Current threshold: -149.5308
Global Scale Offset: 1880.9573
Reward stats: mean=0.0160, std=0.0732, count=319
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.4624, Q2 Loss: 1.4624, Entropy: 0.6926, Mean TD Error: 1.4294, Threshold: -149.5308
Original likelihood: -136.92823791503906
Adjusted likelihood: -136.92823791503906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5027)
Current yaw: tensor([-0.0012,  0.0071, -0.4434], device='cuda:1')
20 turn
Sampling time 3.6361733049852774
tensor([ 2.8284e-02,  3.5664e-01,  7.3249e-01,  7.2070e-01, -1.4750e-01,
         6.1653e-01,  8.6120e-01,  8.5938e-01,  1.3748e+00,  2.5504e-01,
         1.7066e-01,  1.0067e+00, -1.2087e-03,  7.0638e-03, -4.4337e-01,
         3.2049e+00], device='cuda:1')
Original likelihood: -137.3386688232422
Adjusted likelihood: -137.3386688232422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5026)
Solve time for step 1 14.264310658967588
Current ori: tensor([-0.0012,  0.0071, -0.4434], device='cuda:1')
Middle force: tensor([1.5861, 0.9550, 1.3108, 1.8237, 0.5029, 1.0667, 0.5410, 0.5431, 0.5862,
        0.5714, 0.5366, 0.5761], device='cuda:1')
Thumb force: tensor([2.0283, 0.9426, 1.0633, 4.0751, 0.8352, 1.0699, 1.0900, 0.5402, 0.5749,
        0.6018, 0.5762, 0.5798], device='cuda:1')
Index force: tensor([1.3012, 0.5770, 0.5346, 1.0950, 0.7954, 1.1137, 0.6215, 0.5870, 0.6064,
        0.6855, 0.5503, 0.5720], device='cuda:1')
Storing NORMAL transition: reward=0.3049 (scaled=0.3049), steps=1
Reward stats updated: mean 0.0160 -> 0.0169, std: 0.0748
Collected 320 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8050, Q2 Loss=0.8050, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6316
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=0.8659, Q2 Loss=0.8659, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6476
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=1.2940, Q2 Loss=1.2940, Entropy=0.6924, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2514
SAC Update 4/5: Actor Loss=-0.0109, Q1 Loss=3.4520, Q2 Loss=3.4520, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5653
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=1.4232, Q2 Loss=1.4232, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1301

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.4%)
Q1 update: 0.05s (20.9%)
Q2 update: 0.05s (20.1%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008917
Q1 loss: 1.568016
Q2 loss: 1.568016
Current threshold: -149.5307
Global Scale Offset: 1906.8600
Reward stats: mean=0.0169, std=0.0748, count=320
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.5680, Q2 Loss: 1.5680, Entropy: 0.6928, Mean TD Error: 1.8452, Threshold: -149.5307
tensor([ 0.1125,  0.3546,  0.7909,  0.5738, -0.0709,  0.4629,  1.0042,  1.1129,
         1.4188,  0.1559,  0.3318,  0.6980,  0.0709, -0.0409, -0.7641,  4.6978],
       device='cuda:1')
Original likelihood: -208.9466552734375
Adjusted likelihood: -208.9466552734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4876)
State is out of distribution
Projection step: 0, Loss: 210.39593505859375
Projection step: 1, Loss: 209.1513671875
Projection step: 2, Loss: 197.31895446777344
Projection step: 3, Loss: 195.3282470703125
Projection step: 4, Loss: 198.82275390625
Projection step: 5, Loss: 193.35986328125
Projection step: 6, Loss: 180.562744140625
Projection step: 7, Loss: 176.32135009765625
Projection step: 8, Loss: 175.25819396972656
Projection step: 9, Loss: 177.06549072265625
Projection step: 10, Loss: 177.7124786376953
Projection step: 11, Loss: 191.35635375976562
Projection step: 12, Loss: 171.62786865234375
Projection step: 13, Loss: 181.0637664794922
Projection step: 14, Loss: 161.87075805664062
Projection step: 15, Loss: 172.34471130371094
Projection step: 16, Loss: 171.61788940429688
Projection step: 17, Loss: 182.5445556640625
Projection step: 18, Loss: 167.39804077148438
Projection step: 19, Loss: 167.47222900390625
Projection step: 20, Loss: 168.87423706054688
Projection step: 21, Loss: 164.64491271972656
Projection step: 22, Loss: 153.9218292236328
Projection step: 23, Loss: 162.69131469726562
Projection step: 24, Loss: 162.28640747070312
Final likelihood: tensor([-138.7612, -161.3503, -171.2978, -163.0667, -174.0346, -172.8847,
        -178.4575, -176.7560, -179.5585, -137.5241, -162.5641, -149.7235,
        -145.3373, -147.0003, -164.1223, -157.6414])
Final projection likelihood: -161.2550
1 mode projection failed, trying anyway
New goal: tensor([ 0.0897,  0.4352,  0.6817,  0.6868, -0.0377,  0.4607,  0.9031,  0.9853,
         1.4061,  0.1013,  0.2723,  0.9184,  0.0649, -0.0308, -1.6298],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 20
Loaded trajectory sampler
Current yaw: tensor([-0.0029,  0.0146, -0.0437], device='cuda:1')
Current yaw: tensor([-0.0029,  0.0146, -0.0437], device='cuda:1')
1 turn
Sampling time 3.6020930929807946
tensor([ 0.1456,  0.6107,  0.5902,  0.5522, -0.1199,  0.5017,  0.9350,  0.9375,
         1.2472,  0.2851,  0.2594,  1.1242, -0.0029,  0.0146, -0.0437,  0.1428],
       device='cuda:1')
Original likelihood: -99.27002716064453
Adjusted likelihood: -99.27002716064453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5105)
State is out of distribution
Projection step: 0, Loss: 100.29678344726562
Final likelihood: tensor([ -86.6866,  -93.6031,  -95.3371,  -85.0424,  -93.6577, -100.4109,
        -123.4993, -111.5547,  -83.9728,  -96.2359,  -92.1083, -110.9657,
        -138.0834, -100.4065,  -97.1215,  -96.0627])
Final projection likelihood: -100.2968
1 mode projection succeeded
New goal: tensor([ 0.1456,  0.6107,  0.5902,  0.5522, -0.1199,  0.5017,  0.9350,  0.9375,
         1.2472,  0.2851,  0.2594,  1.1242, -0.0029,  0.0146, -0.0437],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0029,  0.0146, -0.0437], device='cuda:1')
2 turn
Sampling time 3.8234449150040746
tensor([ 0.1456,  0.6107,  0.5902,  0.5522, -0.1199,  0.5017,  0.9350,  0.9375,
         1.2472,  0.2851,  0.2594,  1.1242, -0.0029,  0.0146, -0.0437,  0.1428],
       device='cuda:1')
Original likelihood: -99.49513244628906
Adjusted likelihood: -99.49513244628906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5105)
Solve time for step 1 14.121586474997457
Current ori: tensor([-0.0029,  0.0146, -0.0437], device='cuda:1')
Middle force: tensor([0.7017, 1.9269, 0.7157, 0.5583, 0.8824, 0.5687, 0.5805, 0.5477, 0.4989,
        0.5757, 0.5137, 0.5377], device='cuda:1')
Thumb force: tensor([0.6487, 1.7866, 1.8660, 1.5498, 1.0489, 0.7447, 0.5120, 0.5173, 0.6035,
        1.2706, 0.5361, 0.8936], device='cuda:1')
Index force: tensor([0.7065, 1.3024, 0.5726, 0.5027, 1.3251, 0.6001, 0.5014, 0.6116, 0.6573,
        0.6053, 0.5757, 0.5335], device='cuda:1')
Storing NORMAL transition: reward=0.0085 (scaled=0.0085), steps=1
Reward stats updated: mean 0.0169 -> 0.0169, std: 0.0747
Collected 321 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=2.1083, Q2 Loss=2.1083, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5689
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=1.5210, Q2 Loss=1.5210, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3573
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=1.1604, Q2 Loss=1.1604, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1511
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=1.3281, Q2 Loss=1.3281, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2046
SAC Update 5/5: Actor Loss=-0.0128, Q1 Loss=1.3647, Q2 Loss=1.3647, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8737

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010976
Q1 loss: 1.496505
Q2 loss: 1.496505
Current threshold: -149.5307
Global Scale Offset: 1930.6138
Reward stats: mean=0.0169, std=0.0747, count=321
----------------------------------------------
SAC Update - Actor Loss: -0.0110, Q1 Loss: 1.4965, Q2 Loss: 1.4965, Entropy: 0.6930, Mean TD Error: 1.4311, Threshold: -149.5307
tensor([ 0.1289,  0.6682,  0.5680,  0.3617, -0.0384,  0.3300,  1.0107,  1.1952,
         1.1826,  0.2494,  0.3649,  1.0612, -0.0140,  0.0090, -0.0522, -0.2146],
       device='cuda:1')
Original likelihood: -187.44842529296875
Adjusted likelihood: -187.44842529296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4922)
State is out of distribution
Projection step: 0, Loss: 186.6431884765625
Projection step: 1, Loss: 169.24545288085938
Projection step: 2, Loss: 154.04452514648438
Projection step: 3, Loss: 143.53082275390625
Projection step: 4, Loss: 130.55979919433594
Projection step: 5, Loss: 116.92960357666016
Projection step: 6, Loss: 117.91413879394531
Projection step: 7, Loss: 111.37933349609375
Projection step: 8, Loss: 105.08584594726562
Projection step: 9, Loss: 102.30189514160156
Final likelihood: tensor([-121.5929,  -85.8973,  -92.0725,  -86.6372, -101.8602, -102.7537,
        -105.0501,  -91.1889, -142.9662,  -88.3683,  -92.3668, -130.6288,
         -97.4879,  -90.2910,  -96.7857, -110.8828])
Final projection likelihood: -102.3019
1 mode projection succeeded
New goal: tensor([ 0.1068,  0.6459,  0.5352,  0.4582, -0.0681,  0.3731,  0.8169,  1.1387,
         1.2234,  0.3349,  0.2481,  1.0877, -0.0133,  0.0112, -0.4602],
       device='cuda:1')
tensor([[0.0045]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -133.56227111816406
Adjusted likelihood: -133.56227111816406
Likelihood residual: 0.0
Original likelihood: -212.23577880859375
Adjusted likelihood: -212.23577880859375
Likelihood residual: 0.0
{'index': 212.23577880859375, 'thumb_middle': 133.56227111816406}
Current yaw: tensor([-0.0140,  0.0090, -0.0522], device='cuda:1')
3 thumb_middle
tensor([ 0.1289,  0.6682,  0.5680,  0.3617, -0.0384,  0.3300,  1.0107,  1.1952,
         1.1826,  0.2494,  0.3649,  1.0612, -0.0140,  0.0090, -0.0522, -0.2146],
       device='cuda:1')
Solve time for step 1 9.081095363013446
Current ori: tensor([-0.0140,  0.0090, -0.0522], device='cuda:1')
Index force: tensor([0.5857, 0.5855, 0.5740, 0.5032], device='cuda:1')
tensor([ 0.1215,  0.6508,  0.5522,  0.4607, -0.1256,  0.3490,  0.8317,  1.1392,
         1.1940,  0.3074,  0.2080,  1.0592, -0.0039,  0.0131, -0.0522, -0.1858],
       device='cuda:1')
Solve time for step 2 3.608793075021822
Current ori: tensor([-0.0039,  0.0131, -0.0522], device='cuda:1')
Index force: tensor([0.5826, 0.5818, 0.5954], device='cuda:1')
tensor([ 0.1058,  0.6539,  0.5354,  0.4455, -0.1426,  0.3536,  0.8267,  1.1217,
         1.2141,  0.3122,  0.1904,  1.0577, -0.0054,  0.0223, -0.0522, -0.2154],
       device='cuda:1')
Solve time for step 3 3.3671816760324873
Current ori: tensor([-0.0054,  0.0223, -0.0522], device='cuda:1')
Index force: tensor([0.5699, 0.5838], device='cuda:1')
tensor([ 0.1233,  0.6677,  0.5303,  0.4538, -0.1321,  0.3792,  0.8057,  1.1360,
         1.1969,  0.3195,  0.1821,  1.0741, -0.0079,  0.0118, -0.0522, -0.1912],
       device='cuda:1')
Solve time for step 4 3.2629661969840527
Current ori: tensor([-0.0079,  0.0118, -0.0522], device='cuda:1')
Index force: tensor([0.5674], device='cuda:1')
Storing RECOVERY transition: reward=0.0021 (scaled=0.0021), steps=1
Reward stats updated: mean 0.0169 -> 0.0169, std: 0.0746
Collected 322 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=1.0866, Q2 Loss=1.0866, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3263
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=1.2897, Q2 Loss=1.2897, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4615
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.8266, Q2 Loss=0.8266, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3994
SAC Update 4/5: Actor Loss=-0.0095, Q1 Loss=0.8868, Q2 Loss=0.8868, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1688
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=1.0189, Q2 Loss=1.0189, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9541

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009286
Q1 loss: 1.021714
Q2 loss: 1.021714
Current threshold: -149.5306
Global Scale Offset: 1950.7688
Reward stats: mean=0.0169, std=0.0746, count=322
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.0217, Q2 Loss: 1.0217, Entropy: 0.6930, Mean TD Error: 0.8620, Threshold: -149.5306
Original likelihood: -125.08030700683594
Adjusted likelihood: -125.08030700683594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5050)
State is out of distribution
Projection step: 0, Loss: 112.41864013671875
Projection step: 1, Loss: 94.45645141601562
Final likelihood: tensor([ -89.2096,  -64.3530,  -96.6421,  -93.1712,  -95.1249, -113.6678,
         -83.1001, -100.7613,  -96.6347,  -93.3474, -100.0658,  -75.8631,
        -108.9995, -115.7419,  -95.0097,  -89.6113])
Final projection likelihood: -94.4565
1 mode projection succeeded
New goal: tensor([ 9.7574e-02,  6.3591e-01,  5.3545e-01,  4.7919e-01, -8.6423e-02,
         4.2299e-01,  8.4238e-01,  1.1279e+00,  1.2738e+00,  3.4315e-01,
         2.4335e-01,  1.1000e+00, -1.2414e-03,  2.2420e-02, -1.1416e-01],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -141.46734619140625
Adjusted likelihood: -141.46734619140625
Likelihood residual: 0.0
Original likelihood: -104.05216979980469
Adjusted likelihood: -104.05216979980469
Likelihood residual: 0.0
{'index': 104.05216979980469, 'thumb_middle': 141.46734619140625}
Current yaw: tensor([-0.0011,  0.0240, -0.0546], device='cuda:1')
4 index
tensor([ 1.0055e-01,  6.4033e-01,  5.4241e-01,  4.6987e-01, -8.6317e-02,
         4.2371e-01,  8.5046e-01,  1.1387e+00,  1.2743e+00,  3.4055e-01,
         2.4568e-01,  1.0951e+00, -1.1039e-03,  2.3992e-02, -5.4581e-02,
        -1.6497e-01], device='cuda:1')
Solve time for step 1 10.315151813963894
Current ori: tensor([-0.0011,  0.0240, -0.0546], device='cuda:1')
Middle force: tensor([0.5365, 0.6010, 0.5176, 0.5814], device='cuda:1')
Thumb force: tensor([0.5643, 0.5392, 0.5472, 0.5907], device='cuda:1')
tensor([ 0.1484,  0.5692,  0.4872,  0.4589, -0.0909,  0.4243,  0.8493,  1.1378,
         1.2924,  0.3349,  0.2361,  1.0818, -0.0056,  0.0273, -0.0802,  1.7718],
       device='cuda:1')
Solve time for step 2 4.189782202010974
Current ori: tensor([-0.0056,  0.0273, -0.0802], device='cuda:1')
Middle force: tensor([0.5970, 0.5159, 0.5779], device='cuda:1')
Thumb force: tensor([0.5353, 0.5455, 0.5875], device='cuda:1')
tensor([ 0.1498,  0.5694,  0.4845,  0.4611, -0.0908,  0.4187,  0.8549,  1.1449,
         1.2957,  0.3356,  0.2259,  1.0978, -0.0041,  0.0275, -0.0953,  2.8682],
       device='cuda:1')
Solve time for step 3 4.096357128990348
Current ori: tensor([-0.0041,  0.0275, -0.0953], device='cuda:1')
Middle force: tensor([0.5022, 0.5403], device='cuda:1')
Thumb force: tensor([0.5262, 0.5645], device='cuda:1')
tensor([ 0.1467,  0.5689,  0.4817,  0.4599, -0.1008,  0.4240,  0.8436,  1.1322,
         1.2946,  0.3428,  0.2430,  1.0762, -0.0082,  0.0341, -0.0819,  3.3976],
       device='cuda:1')
Solve time for step 4 3.840360500034876
Current ori: tensor([-0.0082,  0.0341, -0.0819], device='cuda:1')
Middle force: tensor([0.5361], device='cuda:1')
Thumb force: tensor([0.5549], device='cuda:1')
Storing RECOVERY transition: reward=0.0476 (scaled=0.0476), steps=1
Reward stats updated: mean 0.0169 -> 0.0170, std: 0.0745
Collected 323 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.8599, Q2 Loss=0.8599, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4849
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.4876, Q2 Loss=1.4876, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1672
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.8497, Q2 Loss=0.8497, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0162
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8670, Q2 Loss=0.8670, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3172
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=3.0665, Q2 Loss=3.0665, Entropy=0.6921, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4262

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.3%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.1%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008788
Q1 loss: 1.426160
Q2 loss: 1.426160
Current threshold: -149.5305
Global Scale Offset: 1971.0270
Reward stats: mean=0.0170, std=0.0745, count=323
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.4262, Q2 Loss: 1.4262, Entropy: 0.6928, Mean TD Error: 1.6823, Threshold: -149.5305
Original likelihood: -119.43302154541016
Adjusted likelihood: -119.43302154541016
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5061)
State is out of distribution
Projection step: 0, Loss: 123.19581604003906
Projection step: 1, Loss: 116.14666748046875
Projection step: 2, Loss: 112.66627502441406
Projection step: 3, Loss: 99.55804443359375
Final likelihood: tensor([-102.7703, -101.8451,  -83.3777,  -76.7815,  -89.6376, -104.8025,
         -92.2613, -115.2405,  -96.4910,  -88.0583, -113.5009, -116.3071,
         -96.3178,  -88.6012,  -96.5555, -130.3802])
Final projection likelihood: -99.5580
1 mode projection succeeded
New goal: tensor([ 0.0838,  0.6304,  0.5193,  0.4974, -0.0954,  0.4261,  0.8302,  1.1014,
         1.3036,  0.3304,  0.2118,  1.1123, -0.0106,  0.0270, -0.3505],
       device='cuda:1')
tensor([[0.0019]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -152.38760375976562
Adjusted likelihood: -152.38760375976562
Likelihood residual: 0.0
Original likelihood: -129.74990844726562
Adjusted likelihood: -129.74990844726562
Likelihood residual: 0.0
{'index': 129.74990844726562, 'thumb_middle': 152.38760375976562}
Current yaw: tensor([-0.0096,  0.0317, -0.1007], device='cuda:1')
5 index
tensor([ 0.0916,  0.6379,  0.5312,  0.4785, -0.0959,  0.4239,  0.8475,  1.1332,
         1.3097,  0.3284,  0.2159,  1.0978, -0.0096,  0.0317, -0.1007,  3.5299],
       device='cuda:1')
Solve time for step 1 10.380615115049295
Current ori: tensor([-0.0096,  0.0317, -0.1007], device='cuda:1')
Middle force: tensor([0.5246, 0.5477, 0.5012, 0.5170], device='cuda:1')
Thumb force: tensor([0.5119, 0.5567, 0.5747, 0.5582], device='cuda:1')
tensor([ 0.1371,  0.5656,  0.4723,  0.4718, -0.0919,  0.4343,  0.8411,  1.1182,
         1.3292,  0.3042,  0.2045,  1.0786, -0.0174,  0.0308, -0.1149,  3.9613],
       device='cuda:1')
Solve time for step 2 4.4369914589915425
Current ori: tensor([-0.0174,  0.0308, -0.1149], device='cuda:1')
Middle force: tensor([0.5455, 0.5008, 0.5152], device='cuda:1')
Thumb force: tensor([0.5516, 0.5717, 0.5559], device='cuda:1')
tensor([ 0.1350,  0.5652,  0.4670,  0.4766, -0.0911,  0.4270,  0.8500,  1.1237,
         1.3331,  0.2942,  0.1946,  1.1000, -0.0128,  0.0295, -0.1083,  4.1949],
       device='cuda:1')
Solve time for step 3 4.1086395279853605
Current ori: tensor([-0.0128,  0.0295, -0.1083], device='cuda:1')
Middle force: tensor([0.5007, 0.5135], device='cuda:1')
Thumb force: tensor([0.5647, 0.5528], device='cuda:1')
tensor([ 0.1354,  0.5655,  0.4656,  0.4746, -0.0855,  0.4312,  0.8490,  1.1228,
         1.3186,  0.3177,  0.1989,  1.0943, -0.0152,  0.0266, -0.1205,  4.3851],
       device='cuda:1')
Solve time for step 4 4.125377060030587
Current ori: tensor([-0.0152,  0.0266, -0.1205], device='cuda:1')
Middle force: tensor([0.5113], device='cuda:1')
Thumb force: tensor([0.5601], device='cuda:1')
Storing RECOVERY transition: reward=0.0647 (scaled=0.0647), steps=1
Reward stats updated: mean 0.0170 -> 0.0171, std: 0.0745
Collected 324 transitions for RL
SAC Update 1/5: Actor Loss=-0.0112, Q1 Loss=1.1519, Q2 Loss=1.1519, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7388
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=1.3263, Q2 Loss=1.3263, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9136
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.7781, Q2 Loss=0.7781, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4694
SAC Update 4/5: Actor Loss=-0.0123, Q1 Loss=1.2122, Q2 Loss=1.2122, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6188
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=2.3112, Q2 Loss=2.3112, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7762

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (18.0%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010821
Q1 loss: 1.355934
Q2 loss: 1.355934
Current threshold: -149.5303
Global Scale Offset: 1992.4379
Reward stats: mean=0.0171, std=0.0745, count=324
----------------------------------------------
SAC Update - Actor Loss: -0.0108, Q1 Loss: 1.3559, Q2 Loss: 1.3559, Entropy: 0.6931, Mean TD Error: 1.1034, Threshold: -149.5303
Original likelihood: -78.13275146484375
Adjusted likelihood: -78.13275146484375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5143)
State is out of distribution
Projection step: 0, Loss: 86.45257568359375
Final likelihood: tensor([ -87.4751,  -79.8190,  -91.7480,  -67.8926,  -76.0161,  -81.1924,
        -122.5456,  -78.3347,  -90.3723, -125.3423,  -77.8551,  -68.7124,
         -75.0831,  -70.7457, -118.7087,  -71.3981])
Final projection likelihood: -86.4526
1 mode projection succeeded
New goal: tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0173,  0.0227, -0.1175], device='cuda:1')
6 turn
Sampling time 3.600636016984936
tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175,  4.4423],
       device='cuda:1')
Original likelihood: -89.3846435546875
Adjusted likelihood: -89.3846435546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5120)
State is out of distribution
Projection step: 0, Loss: 89.81022644042969
Final likelihood: tensor([ -86.1998,  -79.5110,  -76.6353,  -99.9841,  -71.1248,  -92.2473,
         -82.8446, -120.3390, -111.3238, -121.3652, -104.6850,  -61.9358,
         -71.6112,  -92.6149,  -72.3255,  -92.2163])
Final projection likelihood: -89.8102
1 mode projection succeeded
New goal: tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0173,  0.0227, -0.1175], device='cuda:1')
7 turn
Sampling time 3.6103171979775652
tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175,  4.4423],
       device='cuda:1')
Original likelihood: -84.57627868652344
Adjusted likelihood: -84.57627868652344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5130)
State is out of distribution
Projection step: 0, Loss: 88.11906433105469
Final likelihood: tensor([ -84.4690,  -96.8976,  -66.9764,  -93.3342,  -86.2722,  -69.9163,
         -79.2064,  -78.7346, -114.9028,  -84.9433,  -80.3458, -106.2942,
        -103.8947,  -84.9056,  -81.9009,  -96.9109])
Final projection likelihood: -88.1191
1 mode projection succeeded
New goal: tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0173,  0.0227, -0.1175], device='cuda:1')
8 turn
Sampling time 3.7300589959486388
tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175,  4.4423],
       device='cuda:1')
Original likelihood: -84.32337951660156
Adjusted likelihood: -84.32337951660156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5130)
State is out of distribution
Projection step: 0, Loss: 87.94639587402344
Final likelihood: tensor([ -72.3885, -126.0804,  -71.8761,  -82.6182,  -79.1979,  -91.4712,
         -81.5543, -133.1028, -111.6524,  -94.4059,  -75.5457,  -70.5578,
         -71.1338,  -76.9009,  -80.6738,  -87.9828])
Final projection likelihood: -87.9464
1 mode projection succeeded
New goal: tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0173,  0.0227, -0.1175], device='cuda:1')
9 turn
Sampling time 3.5902980290120468
tensor([ 0.0833,  0.6365,  0.5160,  0.4974, -0.0790,  0.4377,  0.8481,  1.1158,
         1.3180,  0.3164,  0.1880,  1.1038, -0.0173,  0.0227, -0.1175,  4.4423],
       device='cuda:1')
Original likelihood: -78.61923217773438
Adjusted likelihood: -78.61923217773438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5142)
Solve time for step 1 13.87646992696682
Current ori: tensor([-0.0173,  0.0227, -0.1175], device='cuda:1')
Middle force: tensor([0.9788, 0.5646, 0.5181, 0.8573, 0.5272, 0.8123, 1.0111, 0.5065, 0.5343,
        0.5144, 0.5544, 0.6048], device='cuda:1')
Thumb force: tensor([0.5689, 0.8034, 0.5263, 0.9222, 0.7183, 0.5700, 0.8011, 0.6718, 0.7027,
        0.8224, 0.6023, 0.5946], device='cuda:1')
Index force: tensor([0.5232, 0.5591, 1.2183, 0.9283, 0.6465, 0.5473, 0.5679, 0.6905, 0.5984,
        0.5414, 0.6026, 0.5762], device='cuda:1')
Storing NORMAL transition: reward=-0.0408 (scaled=-0.0408), steps=1
Reward stats updated: mean 0.0171 -> 0.0169, std: 0.0744
Collected 325 transitions for RL
SAC Update 1/5: Actor Loss=-0.0112, Q1 Loss=1.0768, Q2 Loss=1.0768, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3195
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8169, Q2 Loss=0.8169, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7253
SAC Update 3/5: Actor Loss=-0.0114, Q1 Loss=1.2559, Q2 Loss=1.2559, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9295
SAC Update 4/5: Actor Loss=-0.0114, Q1 Loss=1.0728, Q2 Loss=1.0728, Entropy=0.6925, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6000
SAC Update 5/5: Actor Loss=-0.0109, Q1 Loss=1.0445, Q2 Loss=1.0445, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3874

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (39.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010561
Q1 loss: 1.053384
Q2 loss: 1.053384
Current threshold: -149.5301
Global Scale Offset: 2012.5843
Reward stats: mean=0.0169, std=0.0744, count=325
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.0534, Q2 Loss: 1.0534, Entropy: 0.6928, Mean TD Error: 0.5923, Threshold: -149.5301
tensor([ 0.0736,  0.6000,  0.5674,  0.4872, -0.2220,  0.4389,  0.8546,  1.0901,
         1.4204,  0.0957,  0.1944,  1.0668, -0.0100,  0.0292, -0.0768,  4.3757],
       device='cuda:1')
Original likelihood: -181.3988800048828
Adjusted likelihood: -181.3988800048828
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4937)
State is out of distribution
Projection step: 0, Loss: 185.0670166015625
Projection step: 1, Loss: 183.18661499023438
Projection step: 2, Loss: 174.36526489257812
Projection step: 3, Loss: 161.81423950195312
Projection step: 4, Loss: 155.2833251953125
Projection step: 5, Loss: 146.09463500976562
Projection step: 6, Loss: 149.53179931640625
Projection step: 7, Loss: 136.48727416992188
Projection step: 8, Loss: 139.66189575195312
Projection step: 9, Loss: 123.10549926757812
Projection step: 10, Loss: 108.33790588378906
Projection step: 11, Loss: 117.67447662353516
Projection step: 12, Loss: 98.89321899414062
Final likelihood: tensor([ -82.9217,  -87.6457, -107.1670,  -99.6973,  -89.8892, -109.7640,
        -105.3283, -110.4255, -101.5099, -114.5533,  -89.1103, -107.3343,
         -98.0513,  -87.0223, -108.4131,  -83.4584])
Final projection likelihood: -98.8932
1 mode projection succeeded
New goal: tensor([ 0.0533,  0.6221,  0.4758,  0.5227, -0.1345,  0.4600,  0.8259,  1.0241,
         1.3787,  0.1242,  0.1789,  1.1182, -0.0128,  0.0256, -0.2999],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0111]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -123.1257095336914
Adjusted likelihood: -123.1257095336914
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 123.1257095336914}
Current yaw: tensor([-0.0100,  0.0292, -0.0768], device='cuda:1')
10 thumb_middle
tensor([ 0.0736,  0.6000,  0.5674,  0.4872, -0.2220,  0.4389,  0.8546,  1.0901,
         1.4204,  0.0957,  0.1944,  1.0668, -0.0100,  0.0292, -0.0768,  4.3757],
       device='cuda:1')
Solve time for step 1 9.111676487955265
Current ori: tensor([-0.0100,  0.0292, -0.0768], device='cuda:1')
Index force: tensor([0.5792, 0.5882, 0.5923, 0.5979], device='cuda:1')
tensor([ 0.0680,  0.6170,  0.5171,  0.5275, -0.2166,  0.4457,  0.8028,  1.0353,
         1.3516,  0.0920,  0.1270,  1.0847, -0.0106,  0.0321, -0.0767,  4.3852],
       device='cuda:1')
Solve time for step 2 3.7092462810105644
Current ori: tensor([-0.0106,  0.0321, -0.0767], device='cuda:1')
Index force: tensor([0.5793, 0.5847, 0.5899], device='cuda:1')
tensor([ 0.0728,  0.6423,  0.4844,  0.5292, -0.2085,  0.4623,  0.8076,  1.0127,
         1.3414,  0.1051,  0.1066,  1.0995, -0.0159,  0.0288, -0.0767,  4.3868],
       device='cuda:1')
Solve time for step 3 3.5171310160076246
Current ori: tensor([-0.0159,  0.0288, -0.0767], device='cuda:1')
Index force: tensor([0.5699, 0.5756], device='cuda:1')
tensor([ 0.0575,  0.6285,  0.4889,  0.5316, -0.2210,  0.4591,  0.8068,  1.0118,
         1.3488,  0.0998,  0.1208,  1.0874, -0.0125,  0.0378, -0.0767,  4.3695],
       device='cuda:1')
Solve time for step 4 3.5764790319954045
Current ori: tensor([-0.0125,  0.0378, -0.0767], device='cuda:1')
Index force: tensor([0.5709], device='cuda:1')
Storing RECOVERY transition: reward=-0.0000 (scaled=-0.0000), steps=1
Reward stats updated: mean 0.0169 -> 0.0169, std: 0.0743
Collected 326 transitions for RL
SAC Update 1/5: Actor Loss=-0.0091, Q1 Loss=1.3268, Q2 Loss=1.3268, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9893
SAC Update 2/5: Actor Loss=-0.0125, Q1 Loss=1.2159, Q2 Loss=1.2159, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4453
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=1.2370, Q2 Loss=1.2370, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5261
SAC Update 4/5: Actor Loss=-0.0135, Q1 Loss=1.5461, Q2 Loss=1.5461, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1274
SAC Update 5/5: Actor Loss=-0.0139, Q1 Loss=1.3087, Q2 Loss=1.3087, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4112

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (42.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011407
Q1 loss: 1.326897
Q2 loss: 1.326897
Current threshold: -149.5297
Global Scale Offset: 2027.2836
Reward stats: mean=0.0169, std=0.0743, count=326
----------------------------------------------
SAC Update - Actor Loss: -0.0114, Q1 Loss: 1.3269, Q2 Loss: 1.3269, Entropy: 0.6931, Mean TD Error: 1.2999, Threshold: -149.5297
Original likelihood: -158.1898956298828
Adjusted likelihood: -158.1898956298828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4983)
Current yaw: tensor([-0.0118,  0.0451, -0.0778], device='cuda:1')
11 turn
Sampling time 3.687485452974215
tensor([ 0.0434,  0.6281,  0.4789,  0.5236, -0.1603,  0.4993,  0.8367,  1.0248,
         1.4282,  0.1361,  0.1660,  1.1109, -0.0118,  0.0451, -0.0778,  4.3707],
       device='cuda:1')
Original likelihood: -158.01156616210938
Adjusted likelihood: -158.01156616210938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4983)
Solve time for step 1 14.257811507035512
Current ori: tensor([-0.0118,  0.0451, -0.0778], device='cuda:1')
Middle force: tensor([0.5759, 0.6095, 1.2325, 1.2724, 1.8579, 0.5872, 0.5473, 0.5378, 0.5205,
        0.5224, 0.5307, 0.5414], device='cuda:1')
Thumb force: tensor([0.6014, 1.2932, 0.5632, 1.1837, 1.1563, 0.5826, 1.0610, 0.6004, 0.5848,
        0.7522, 0.5872, 0.5699], device='cuda:1')
Index force: tensor([0.5639, 1.0023, 0.7950, 0.7725, 0.7503, 0.5369, 0.5402, 0.5741, 0.5521,
        0.5486, 0.6063, 0.5682], device='cuda:1')
Storing NORMAL transition: reward=0.1086 (scaled=0.1086), steps=1
Reward stats updated: mean 0.0169 -> 0.0172, std: 0.0744
Collected 327 transitions for RL
SAC Update 1/5: Actor Loss=-0.0122, Q1 Loss=1.1385, Q2 Loss=1.1385, Entropy=0.6926, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4146
SAC Update 2/5: Actor Loss=-0.0103, Q1 Loss=0.9943, Q2 Loss=0.9943, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4842
SAC Update 3/5: Actor Loss=-0.0130, Q1 Loss=2.1310, Q2 Loss=2.1310, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9434
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=4.0502, Q2 Loss=4.0502, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9911
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.7772, Q2 Loss=0.7772, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8287

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.2%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.7%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011129
Q1 loss: 1.818253
Q2 loss: 1.818253
Current threshold: -149.5292
Global Scale Offset: 2038.2450
Reward stats: mean=0.0172, std=0.0744, count=327
----------------------------------------------
SAC Update - Actor Loss: -0.0111, Q1 Loss: 1.8183, Q2 Loss: 1.8183, Entropy: 0.6929, Mean TD Error: 1.3324, Threshold: -149.5292
tensor([ 0.0414,  0.6334,  0.4557,  0.5524, -0.1674,  0.4650,  0.8768,  1.0399,
         1.4277,  0.1539,  0.2042,  1.0131, -0.0131,  0.0493, -0.1874,  4.4279],
       device='cuda:1')
Original likelihood: -165.63397216796875
Adjusted likelihood: -165.63397216796875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4969)
State is out of distribution
Projection step: 0, Loss: 168.31625366210938
Projection step: 1, Loss: 156.02825927734375
Projection step: 2, Loss: 148.023193359375
Projection step: 3, Loss: 140.10867309570312
Projection step: 4, Loss: 130.60556030273438
Projection step: 5, Loss: 125.50452423095703
Projection step: 6, Loss: 117.78052520751953
Projection step: 7, Loss: 111.45071411132812
Projection step: 8, Loss: 104.56938171386719
Final likelihood: tensor([-105.7309, -108.0094, -112.8062, -106.4928,  -96.9482, -100.4903,
         -99.5661, -101.3853, -102.0286, -103.6767, -108.2108, -108.0212,
        -104.7161, -108.9718, -106.2205,  -99.8353])
Final projection likelihood: -104.5694
1 mode projection succeeded
New goal: tensor([ 0.0297,  0.6351,  0.4306,  0.5677, -0.1508,  0.4585,  0.8634,  0.9601,
         1.3807,  0.1387,  0.1852,  1.1316, -0.0184,  0.0401, -0.6009],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -144.92613220214844
Adjusted likelihood: -144.92613220214844
Likelihood residual: 0.0
Original likelihood: -124.0803451538086
Adjusted likelihood: -124.0803451538086
Likelihood residual: 0.0
{'index': 124.0803451538086, 'thumb_middle': 144.92613220214844}
Current yaw: tensor([-0.0131,  0.0493, -0.1874], device='cuda:1')
12 index
tensor([ 0.0414,  0.6334,  0.4557,  0.5524, -0.1674,  0.4650,  0.8768,  1.0399,
         1.4277,  0.1539,  0.2042,  1.0131, -0.0131,  0.0493, -0.1874,  4.4279],
       device='cuda:1')
Solve time for step 1 10.887598591041751
Current ori: tensor([-0.0131,  0.0493, -0.1874], device='cuda:1')
Middle force: tensor([0.5905, 0.6040, 0.5094, 0.5053], device='cuda:1')
Thumb force: tensor([0.5368, 0.5995, 0.5137, 0.5934], device='cuda:1')
tensor([ 0.0799,  0.5757,  0.3810,  0.5413, -0.1418,  0.4702,  0.9017,  1.0062,
         1.4469,  0.0996,  0.1553,  1.0561, -0.0164,  0.0328, -0.1771,  5.1925],
       device='cuda:1')
Solve time for step 2 4.186413682997227
Current ori: tensor([-0.0164,  0.0328, -0.1771], device='cuda:1')
Middle force: tensor([0.5980, 0.5079, 0.5044], device='cuda:1')
Thumb force: tensor([0.5919, 0.5126, 0.5882], device='cuda:1')
tensor([ 0.0814,  0.5727,  0.3826,  0.5424, -0.1357,  0.4746,  0.9058,  0.9984,
         1.4278,  0.1340,  0.1568,  1.0480, -0.0214,  0.0291, -0.1922,  5.8434],
       device='cuda:1')
Solve time for step 3 4.158463342988398
Current ori: tensor([-0.0214,  0.0291, -0.1922], device='cuda:1')
Middle force: tensor([0.5003, 0.5496], device='cuda:1')
Thumb force: tensor([0.5323, 0.5288], device='cuda:1')
tensor([ 0.0814,  0.5735,  0.3815,  0.5417, -0.1331,  0.4673,  0.9138,  1.0103,
         1.4180,  0.1467,  0.1487,  1.0778, -0.0156,  0.0264, -0.1875, -6.1670],
       device='cuda:1')
Solve time for step 4 4.201838781998958
Current ori: tensor([-0.0156,  0.0264, -0.1875], device='cuda:1')
Middle force: tensor([0.5262], device='cuda:1')
Thumb force: tensor([0.6182], device='cuda:1')
Storing RECOVERY transition: reward=-0.0068 (scaled=-0.0068), steps=1
Reward stats updated: mean 0.0172 -> 0.0171, std: 0.0743
Collected 328 transitions for RL
SAC Update 1/5: Actor Loss=-0.0133, Q1 Loss=1.3140, Q2 Loss=1.3140, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6831
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=4.5220, Q2 Loss=4.5220, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.2547
SAC Update 3/5: Actor Loss=-0.0134, Q1 Loss=1.6733, Q2 Loss=1.6733, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3451
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=1.2063, Q2 Loss=1.2063, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1472
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=2.0038, Q2 Loss=2.0038, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5945

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.7%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.012157
Q1 loss: 2.143865
Q2 loss: 2.143865
Current threshold: -149.5289
Global Scale Offset: 2050.0299
Reward stats: mean=0.0171, std=0.0743, count=328
----------------------------------------------
SAC Update - Actor Loss: -0.0122, Q1 Loss: 2.1439, Q2 Loss: 2.1439, Entropy: 0.6929, Mean TD Error: 1.6049, Threshold: -149.5289
Original likelihood: -106.51666259765625
Adjusted likelihood: -106.51666259765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5084)
Current yaw: tensor([-0.0153,  0.0328, -0.1790], device='cuda:1')
13 turn
Sampling time 3.602315933967475
tensor([ 0.0239,  0.6388,  0.4249,  0.5642, -0.1425,  0.4654,  0.9101,  1.0064,
         1.4244,  0.1421,  0.1579,  1.0698, -0.0153,  0.0328, -0.1790, -5.9966],
       device='cuda:1')
Original likelihood: -107.8784408569336
Adjusted likelihood: -107.8784408569336
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5081)
State is out of distribution
Projection step: 0, Loss: 105.44026184082031
Projection step: 1, Loss: 101.92980194091797
Final likelihood: tensor([ -99.9408, -100.8680, -108.7004,  -95.8827,  -99.8199, -101.3227,
        -105.2422, -107.4066, -104.7824, -102.5550, -105.0342, -106.5443,
        -100.3125,  -99.9273, -100.9632,  -91.5748])
Final projection likelihood: -101.9298
1 mode projection succeeded
New goal: tensor([ 0.0262,  0.6386,  0.4235,  0.5669, -0.1408,  0.4626,  0.9011,  0.9961,
         1.4175,  0.1436,  0.1612,  1.0800, -0.0156,  0.0319, -0.1475],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -117.34249877929688
Adjusted likelihood: -117.34249877929688
Likelihood residual: 0.0
Original likelihood: -115.9102783203125
Adjusted likelihood: -115.9102783203125
Likelihood residual: 0.0
{'index': 115.9102783203125, 'thumb_middle': 117.34249877929688}
Current yaw: tensor([-0.0153,  0.0328, -0.1790], device='cuda:1')
14 index
tensor([ 0.0239,  0.6388,  0.4249,  0.5642, -0.1425,  0.4654,  0.9101,  1.0064,
         1.4244,  0.1421,  0.1579,  1.0698, -0.0153,  0.0328, -0.1790, -5.9966],
       device='cuda:1')
Solve time for step 1 10.636859307996929
Current ori: tensor([-0.0153,  0.0328, -0.1790], device='cuda:1')
Middle force: tensor([0.5192, 0.5940, 0.5814, 0.5866], device='cuda:1')
Thumb force: tensor([0.5843, 0.5964, 0.5527, 0.6099], device='cuda:1')
tensor([ 0.0725,  0.5749,  0.3752,  0.5423, -0.1442,  0.4620,  0.9119,  1.0119,
         1.4328,  0.1275,  0.1539,  1.0747, -0.0135,  0.0335, -0.1800, -6.0365],
       device='cuda:1')
Solve time for step 2 4.287045628996566
Current ori: tensor([-0.0135,  0.0335, -0.1800], device='cuda:1')
Middle force: tensor([0.5884, 0.5780, 0.5821], device='cuda:1')
Thumb force: tensor([0.5922, 0.5500, 0.6053], device='cuda:1')
tensor([ 0.0737,  0.5767,  0.3713,  0.5418, -0.1471,  0.4607,  0.9127,  1.0101,
         1.4320,  0.1312,  0.1585,  1.0698, -0.0137,  0.0353, -0.1800, -5.9524],
       device='cuda:1')
Solve time for step 3 4.26813530101208
Current ori: tensor([-0.0137,  0.0353, -0.1800], device='cuda:1')
Middle force: tensor([0.5225, 0.5129], device='cuda:1')
Thumb force: tensor([0.5295, 0.5634], device='cuda:1')
tensor([ 0.0731,  0.5760,  0.3705,  0.5419, -0.1457,  0.4641,  0.9099,  1.0088,
         1.4262,  0.1457,  0.1571,  1.0668, -0.0171,  0.0350, -0.1921, -5.7855],
       device='cuda:1')
Solve time for step 4 3.9653382130200043
Current ori: tensor([-0.0171,  0.0350, -0.1921], device='cuda:1')
Middle force: tensor([0.5149], device='cuda:1')
Thumb force: tensor([0.5032], device='cuda:1')
Storing RECOVERY transition: reward=0.0058 (scaled=0.0058), steps=0
Reward stats updated: mean 0.0171 -> 0.0170, std: 0.0742
Collected 329 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.9791, Q2 Loss=0.9791, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6902
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8477, Q2 Loss=0.8477, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4590
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.8577, Q2 Loss=0.8577, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5882
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=5.9465, Q2 Loss=5.9465, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1603
SAC Update 5/5: Actor Loss=-0.0091, Q1 Loss=0.8964, Q2 Loss=0.8964, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6017

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (38.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009490
Q1 loss: 1.905494
Q2 loss: 1.905494
Current threshold: -149.5288
Global Scale Offset: 2065.6141
Reward stats: mean=0.0170, std=0.0742, count=329
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.9055, Q2 Loss: 1.9055, Entropy: 0.6930, Mean TD Error: 1.0999, Threshold: -149.5288
Original likelihood: -99.02824401855469
Adjusted likelihood: -99.02824401855469
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5097)
State is out of distribution
Projection step: 0, Loss: 100.48937225341797
Final likelihood: tensor([ -97.9438, -101.4574, -100.7542,  -96.0431,  -96.0677, -104.2666,
        -107.0246,  -96.9525,  -97.0909,  -99.8874, -102.1046, -105.5118,
         -95.0628,  -99.7773, -102.2976, -105.5876])
Final projection likelihood: -100.4894
1 mode projection succeeded
New goal: tensor([ 0.0242,  0.6428,  0.4172,  0.5648, -0.1365,  0.4740,  0.9059,  0.9984,
         1.4287,  0.1347,  0.1443,  1.0742, -0.0203,  0.0296, -0.1848],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0203,  0.0296, -0.1848], device='cuda:1')
15 turn
Sampling time 3.6348378900438547
tensor([ 0.0242,  0.6428,  0.4172,  0.5648, -0.1365,  0.4740,  0.9059,  0.9984,
         1.4287,  0.1347,  0.1443,  1.0742, -0.0203,  0.0296, -0.1848, -5.7305],
       device='cuda:1')
Original likelihood: -98.91324615478516
Adjusted likelihood: -98.91324615478516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5098)
Solve time for step 1 14.583142883959226
Current ori: tensor([-0.0203,  0.0296, -0.1848], device='cuda:1')
Middle force: tensor([0.5735, 0.6803, 1.3197, 1.3498, 1.9440, 0.5834, 0.5704, 0.5347, 1.0890,
        0.6343, 0.5386, 0.5249], device='cuda:1')
Thumb force: tensor([0.6017, 1.3040, 0.5516, 1.2058, 1.1843, 0.6051, 1.1012, 0.6109, 1.6355,
        0.5709, 0.6058, 0.5887], device='cuda:1')
Index force: tensor([0.6140, 1.0270, 0.8016, 0.7889, 0.7722, 0.5523, 0.5492, 0.6291, 0.5932,
        0.6042, 0.6690, 0.5540], device='cuda:1')
Storing NORMAL transition: reward=-0.0063 (scaled=-0.0063), steps=1
Reward stats updated: mean 0.0170 -> 0.0170, std: 0.0741
Collected 330 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=0.9812, Q2 Loss=0.9812, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6873
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=0.8793, Q2 Loss=0.8793, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4970
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8724, Q2 Loss=0.8724, Entropy=0.6917, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8083
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.3095, Q2 Loss=1.3095, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5662
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8538, Q2 Loss=0.8538, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2188

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (19.4%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008713
Q1 loss: 0.979226
Q2 loss: 0.979226
Current threshold: -149.5286
Global Scale Offset: 2086.1070
Reward stats: mean=0.0170, std=0.0741, count=330
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 0.9792, Q2 Loss: 0.9792, Entropy: 0.6928, Mean TD Error: 0.9555, Threshold: -149.5286
tensor([ 0.1478,  0.6517,  0.5077,  0.5566, -0.2541,  0.5596,  0.8841,  0.8952,
         1.4973,  0.1022,  0.1423,  0.9145, -0.0513,  0.0756, -0.1852, -6.0906],
       device='cuda:1')
Original likelihood: -216.49200439453125
Adjusted likelihood: -216.49200439453125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4872)
State is out of distribution
Projection step: 0, Loss: 207.07061767578125
Projection step: 1, Loss: 201.2812957763672
Projection step: 2, Loss: 200.043701171875
Projection step: 3, Loss: 193.1825408935547
Projection step: 4, Loss: 196.30422973632812
Projection step: 5, Loss: 198.2906951904297
Projection step: 6, Loss: 186.89569091796875
Projection step: 7, Loss: 184.78472900390625
Projection step: 8, Loss: 192.91036987304688
Projection step: 9, Loss: 197.12725830078125
Projection step: 10, Loss: 184.73455810546875
Projection step: 11, Loss: 174.16912841796875
Projection step: 12, Loss: 181.52285766601562
Projection step: 13, Loss: 190.35006713867188
Projection step: 14, Loss: 183.81076049804688
Projection step: 15, Loss: 192.89132690429688
Projection step: 16, Loss: 188.79962158203125
Projection step: 17, Loss: 180.82229614257812
Projection step: 18, Loss: 175.58212280273438
Projection step: 19, Loss: 184.11941528320312
Projection step: 20, Loss: 185.54879760742188
Projection step: 21, Loss: 170.6167755126953
Projection step: 22, Loss: 181.47300720214844
Projection step: 23, Loss: 174.72708129882812
Projection step: 24, Loss: 181.53001403808594
Final likelihood: tensor([-143.8585, -188.4145, -178.2989, -168.0358, -165.5185, -181.0885,
        -154.3915, -175.4106, -193.8520, -160.2306, -200.6197, -163.2367,
        -148.3267, -151.0967, -165.1520, -204.8459])
Final projection likelihood: -171.3986
1 mode projection failed, trying anyway
New goal: tensor([ 0.1057,  0.6341,  0.4203,  0.6518, -0.1927,  0.5351,  0.8322,  0.8856,
         1.4494,  0.0746,  0.1529,  1.0790, -0.0541,  0.0592,  0.8544],
       device='cuda:1')
tensor([[0.0066]], device='cuda:1') tensor([[0.0034]], device='cuda:1') tensor([[0.0032]], device='cuda:1')
Original likelihood: -176.90225219726562
Adjusted likelihood: -176.90225219726562
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 176.90225219726562}
Current yaw: tensor([-0.0513,  0.0756, -0.1852], device='cuda:1')
16 thumb_middle
tensor([ 0.1478,  0.6517,  0.5077,  0.5566, -0.2541,  0.5596,  0.8841,  0.8952,
         1.4973,  0.1022,  0.1423,  0.9145, -0.0513,  0.0756, -0.1852, -6.0906],
       device='cuda:1')
Solve time for step 1 8.83387708402006
Current ori: tensor([-0.0513,  0.0756, -0.1852], device='cuda:1')
Index force: tensor([0.5850, 0.6022, 0.5889, 0.5870], device='cuda:1')
tensor([ 0.1125,  0.7244,  0.4741,  0.6448, -0.2819,  0.5486,  0.8301,  0.8743,
         1.4363,  0.0596,  0.1067,  1.0403, -0.1064,  0.1366, -0.2085, -5.7465],
       device='cuda:1')
Solve time for step 2 3.5454948879778385
Current ori: tensor([-0.1064,  0.1366, -0.2085], device='cuda:1')
Index force: tensor([0.5593, 0.5595, 0.5689], device='cuda:1')
tensor([ 0.0740,  0.7602,  0.5125,  0.6815, -0.2948,  0.5478,  0.8178,  0.8697,
         1.4692,  0.0567,  0.1248,  1.0673, -0.2145,  0.2360, -0.2488, -4.8262],
       device='cuda:1')
Solve time for step 3 3.3886483490350656
Current ori: tensor([-0.2145,  0.2360, -0.2488], device='cuda:1')
Index force: tensor([0.5324, 0.5481], device='cuda:1')
tensor([-0.0121,  0.8192,  0.5395,  0.6935, -0.2901,  0.5538,  0.8215,  0.8785,
         1.4865,  0.0773,  0.1422,  1.0691, -0.5033,  0.5570, -0.2488, -4.5517],
       device='cuda:1')
Solve time for step 4 3.3089917289908044
Current ori: tensor([-0.5033,  0.5570, -0.2488], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-0.9429 (scaled=-0.9429), steps=1
Reward stats updated: mean 0.0170 -> 0.0141, std: 0.0908
Collected 331 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7563, Q2 Loss=0.7563, Entropy=0.6924, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4006
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.7688, Q2 Loss=0.7688, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6452
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=0.9983, Q2 Loss=0.9983, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4186
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=1.4740, Q2 Loss=1.4740, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0020
SAC Update 5/5: Actor Loss=-0.0132, Q1 Loss=17.1006, Q2 Loss=17.1006, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.7854

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010477
Q1 loss: 4.219590
Q2 loss: 4.219590
Current threshold: -149.5286
Global Scale Offset: 2106.7762
Reward stats: mean=0.0141, std=0.0908, count=331
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 4.2196, Q2 Loss: 4.2196, Entropy: 0.6928, Mean TD Error: 2.0504, Threshold: -149.5286
Original likelihood: -2031.344482421875
Adjusted likelihood: -2031.344482421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1860)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 21
Loaded trajectory sampler
Current yaw: tensor([-0.0022,  0.0146, -0.0304], device='cuda:1')
Current yaw: tensor([-0.0022,  0.0146, -0.0304], device='cuda:1')
1 turn
Sampling time 3.6021887449896894
tensor([ 0.1594,  0.6012,  0.5708,  0.6438, -0.1455,  0.5719,  0.9031,  0.8943,
         1.2436,  0.2609,  0.2629,  1.1500, -0.0022,  0.0146, -0.0304,  0.0445],
       device='cuda:1')
Original likelihood: -140.59228515625
Adjusted likelihood: -140.59228515625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Solve time for step 1 14.112391642993316
Current ori: tensor([-0.0022,  0.0146, -0.0304], device='cuda:1')
Middle force: tensor([1.4029, 0.5266, 1.3045, 0.6560, 0.5332, 0.9723, 0.4994, 0.7864, 0.6337,
        0.5195, 0.4894, 0.5383], device='cuda:1')
Thumb force: tensor([0.9147, 0.7170, 0.5573, 0.7170, 0.6107, 1.7048, 0.5327, 0.5610, 0.6825,
        0.5837, 1.0657, 0.5978], device='cuda:1')
Index force: tensor([0.5384, 1.3264, 0.5243, 0.6375, 0.5968, 1.1509, 0.5509, 0.7862, 0.5489,
        0.6664, 0.6229, 0.6258], device='cuda:1')
Storing NORMAL transition: reward=-0.0288 (scaled=-0.0288), steps=1
Reward stats updated: mean 0.0141 -> 0.0139, std: 0.0907
Collected 332 transitions for RL
SAC Update 1/5: Actor Loss=-0.0124, Q1 Loss=4.8889, Q2 Loss=4.8889, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1351
SAC Update 2/5: Actor Loss=-0.0124, Q1 Loss=1.3567, Q2 Loss=1.3567, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8947
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=0.9137, Q2 Loss=0.9137, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4302
SAC Update 4/5: Actor Loss=-0.0105, Q1 Loss=1.0144, Q2 Loss=1.0144, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6511
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=1.1092, Q2 Loss=1.1092, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6320

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (42.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010496
Q1 loss: 1.856597
Q2 loss: 1.856597
Current threshold: -149.5286
Global Scale Offset: 2125.3338
Reward stats: mean=0.0139, std=0.0907, count=332
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.8566, Q2 Loss: 1.8566, Entropy: 0.6930, Mean TD Error: 1.7486, Threshold: -149.5286
tensor([ 0.0594,  0.5173,  0.6467,  0.5220, -0.2267,  0.7391,  0.6788,  0.7490,
         1.3487,  0.1816,  0.2078,  1.1446,  0.0111,  0.0714, -0.0062, -0.1326],
       device='cuda:1')
Original likelihood: -255.2253875732422
Adjusted likelihood: -255.2253875732422
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4802)
State is out of distribution
Projection step: 0, Loss: 251.1455841064453
Projection step: 1, Loss: 255.44647216796875
Projection step: 2, Loss: 241.3831787109375
Projection step: 3, Loss: 241.28033447265625
Projection step: 4, Loss: 232.5838623046875
Projection step: 5, Loss: 226.4439697265625
Projection step: 6, Loss: 221.423095703125
Projection step: 7, Loss: 220.98812866210938
Projection step: 8, Loss: 209.47402954101562
Projection step: 9, Loss: 217.7283477783203
Projection step: 10, Loss: 208.35647583007812
Projection step: 11, Loss: 206.12881469726562
Projection step: 12, Loss: 214.5001983642578
Projection step: 13, Loss: 207.34442138671875
Projection step: 14, Loss: 202.59898376464844
Projection step: 15, Loss: 205.42535400390625
Projection step: 16, Loss: 201.90118408203125
Projection step: 17, Loss: 193.60670471191406
Projection step: 18, Loss: 188.62753295898438
Projection step: 19, Loss: 195.70440673828125
Projection step: 20, Loss: 189.14834594726562
Projection step: 21, Loss: 177.26446533203125
Projection step: 22, Loss: 188.98046875
Projection step: 23, Loss: 179.1699676513672
Projection step: 24, Loss: 170.58682250976562
Final likelihood: tensor([-153.5895, -192.4680, -188.1570, -178.1504, -182.7630, -194.4836,
        -158.2200, -154.1129, -158.3701, -165.6351, -164.6103, -183.2787,
        -192.9703, -148.0793, -172.9942, -150.0267])
Final projection likelihood: -171.1193
1 mode projection failed, trying anyway
New goal: tensor([ 0.0630,  0.5522,  0.6162,  0.5438, -0.1835,  0.6837,  0.7257,  0.7401,
         1.3081,  0.1961,  0.2004,  1.2960,  0.0038,  0.0467, -0.7007],
       device='cuda:1')
tensor([[0.0086]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -205.4600830078125
Adjusted likelihood: -205.4600830078125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 205.4600830078125}
Current yaw: tensor([ 0.0111,  0.0714, -0.0062], device='cuda:1')
2 thumb_middle
tensor([ 0.0594,  0.5173,  0.6467,  0.5220, -0.2267,  0.7391,  0.6788,  0.7490,
         1.3487,  0.1816,  0.2078,  1.1446,  0.0111,  0.0714, -0.0062, -0.1326],
       device='cuda:1')
Solve time for step 1 9.235497109999415
Current ori: tensor([ 0.0111,  0.0714, -0.0062], device='cuda:1')
Index force: tensor([0.5762, 0.5773, 0.5740, 0.5800], device='cuda:1')
tensor([ 0.0636,  0.5571,  0.5918,  0.5299, -0.2527,  0.6960,  0.6939,  0.7232,
         1.2936,  0.1745,  0.1554,  1.2576,  0.0026,  0.0688, -0.0062, -0.1374],
       device='cuda:1')
Solve time for step 2 3.7043376190122217
Current ori: tensor([ 0.0026,  0.0688, -0.0062], device='cuda:1')
Index force: tensor([0.5686, 0.5677, 0.5745], device='cuda:1')
tensor([ 7.9183e-02,  5.5829e-01,  6.0755e-01,  5.2464e-01, -2.5263e-01,
         7.0778e-01,  7.0264e-01,  7.0555e-01,  1.2940e+00,  1.6609e-01,
         1.3197e-01,  1.2766e+00,  9.8219e-04,  5.9998e-02, -6.1994e-03,
        -1.1711e-01], device='cuda:1')
Solve time for step 3 3.3732473839772865
Current ori: tensor([ 0.0010,  0.0600, -0.0062], device='cuda:1')
Index force: tensor([0.5561, 0.5625], device='cuda:1')
tensor([ 0.0820,  0.5585,  0.5951,  0.5538, -0.2519,  0.7009,  0.7029,  0.7254,
         1.2845,  0.1653,  0.1412,  1.2903,  0.0028,  0.0588, -0.0062, -0.1058],
       device='cuda:1')
Solve time for step 4 3.2835379419848323
Current ori: tensor([ 0.0028,  0.0588, -0.0062], device='cuda:1')
Index force: tensor([0.5859], device='cuda:1')
Storing RECOVERY transition: reward=0.0130 (scaled=0.0130), steps=1
Reward stats updated: mean 0.0139 -> 0.0139, std: 0.0905
Collected 333 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.9878, Q2 Loss=0.9878, Entropy=0.6924, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0903
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=1.3137, Q2 Loss=1.3137, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9706
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.1779, Q2 Loss=1.1779, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2045
SAC Update 4/5: Actor Loss=-0.0119, Q1 Loss=1.1644, Q2 Loss=1.1644, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3900
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.0546, Q2 Loss=1.0546, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5404

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009651
Q1 loss: 1.139677
Q2 loss: 1.139677
Current threshold: -149.5286
Global Scale Offset: 2141.0781
Reward stats: mean=0.0139, std=0.0905, count=333
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.1397, Q2 Loss: 1.1397, Entropy: 0.6929, Mean TD Error: 1.2392, Threshold: -149.5286
Original likelihood: -220.00021362304688
Adjusted likelihood: -220.00021362304688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4869)
State is out of distribution
Projection step: 0, Loss: 217.71151733398438
Projection step: 1, Loss: 215.1814422607422
Projection step: 2, Loss: 194.47254943847656
Projection step: 3, Loss: 201.2791748046875
Projection step: 4, Loss: 199.2367706298828
Projection step: 5, Loss: 204.29737854003906
Projection step: 6, Loss: 214.13906860351562
Projection step: 7, Loss: 197.78515625
Projection step: 8, Loss: 185.5721893310547
Projection step: 9, Loss: 179.41354370117188
Projection step: 10, Loss: 181.47518920898438
Projection step: 11, Loss: 184.34194946289062
Projection step: 12, Loss: 179.85958862304688
Projection step: 13, Loss: 170.31903076171875
Projection step: 14, Loss: 170.55184936523438
Projection step: 15, Loss: 170.32510375976562
Projection step: 16, Loss: 167.86178588867188
Projection step: 17, Loss: 169.16241455078125
Projection step: 18, Loss: 165.68807983398438
Projection step: 19, Loss: 156.84255981445312
Projection step: 20, Loss: 159.93417358398438
Projection step: 21, Loss: 149.97039794921875
Projection step: 22, Loss: 149.9272918701172
Projection step: 23, Loss: 142.1331787109375
Projection step: 24, Loss: 144.94532775878906
Final likelihood: tensor([-177.1534, -141.3726, -130.4249, -156.5260, -134.0505, -153.6491,
        -140.9507, -130.5040, -138.0066, -142.0109, -142.4021, -173.3092,
        -144.1783, -136.1371, -167.1559, -139.6091])
Final projection likelihood: -146.7150
1 mode projection succeeded
New goal: tensor([ 0.0720,  0.5523,  0.5853,  0.5824, -0.1498,  0.6867,  0.7706,  0.7352,
         1.3211,  0.1893,  0.1716,  1.3124, -0.0097,  0.0346, -0.2918],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -193.22213745117188
Adjusted likelihood: -193.22213745117188
Likelihood residual: 0.0
Original likelihood: -154.60324096679688
Adjusted likelihood: -154.60324096679688
Likelihood residual: 0.0
{'index': 154.60324096679688, 'thumb_middle': 193.22213745117188}
Current yaw: tensor([ 0.0019,  0.0586, -0.0177], device='cuda:1')
3 index
tensor([ 0.0798,  0.5549,  0.6121,  0.5263, -0.2168,  0.7290,  0.7310,  0.7407,
         1.3503,  0.2118,  0.1939,  1.2902,  0.0019,  0.0586, -0.0177, -0.0710],
       device='cuda:1')
Solve time for step 1 10.541229752998333
Current ori: tensor([ 0.0019,  0.0586, -0.0177], device='cuda:1')
Middle force: tensor([0.5677, 0.5195, 0.5728, 0.5118], device='cuda:1')
Thumb force: tensor([0.5566, 0.6242, 0.5655, 0.5384], device='cuda:1')
tensor([ 1.2099e-01,  4.9660e-01,  5.3742e-01,  5.4673e-01, -2.0703e-01,
         7.2163e-01,  7.5646e-01,  7.3075e-01,  1.3580e+00,  1.9418e-01,
         1.7354e-01,  1.2912e+00, -3.9324e-04,  5.0279e-02, -4.7212e-02,
         3.5913e-01], device='cuda:1')
Solve time for step 2 4.17935132997809
Current ori: tensor([-0.0004,  0.0503, -0.0472], device='cuda:1')
Middle force: tensor([0.5157, 0.5684, 0.5103], device='cuda:1')
Thumb force: tensor([0.6198, 0.5613, 0.5351], device='cuda:1')
tensor([ 0.1188,  0.4968,  0.5322,  0.5548, -0.2014,  0.7176,  0.7693,  0.7273,
         1.3539,  0.1942,  0.1642,  1.3078,  0.0020,  0.0456, -0.0435,  0.6101],
       device='cuda:1')
Solve time for step 3 3.984187881986145
Current ori: tensor([ 0.0020,  0.0456, -0.0435], device='cuda:1')
Middle force: tensor([0.5666, 0.5548], device='cuda:1')
Thumb force: tensor([0.5728, 0.5140], device='cuda:1')
tensor([ 1.2019e-01,  4.9565e-01,  5.3367e-01,  5.5957e-01, -1.9746e-01,
         7.2087e-01,  7.6856e-01,  7.2318e-01,  1.3514e+00,  1.9533e-01,
         1.6034e-01,  1.3107e+00,  8.5661e-04,  4.2999e-02, -4.0238e-02,
         6.9556e-01], device='cuda:1')
Solve time for step 4 3.823909435013775
Current ori: tensor([ 0.0009,  0.0430, -0.0402], device='cuda:1')
Middle force: tensor([0.5293], device='cuda:1')
Thumb force: tensor([0.5183], device='cuda:1')
Storing RECOVERY transition: reward=0.0269 (scaled=0.0269), steps=1
Reward stats updated: mean 0.0139 -> 0.0140, std: 0.0904
Collected 334 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.9574, Q2 Loss=0.9574, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7361
SAC Update 2/5: Actor Loss=-0.0096, Q1 Loss=1.0524, Q2 Loss=1.0524, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1260
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.7812, Q2 Loss=0.7812, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1433
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.9327, Q2 Loss=0.9327, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3225
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.7840, Q2 Loss=0.7840, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4105

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008185
Q1 loss: 0.901526
Q2 loss: 0.901526
Current threshold: -149.5284
Global Scale Offset: 2155.6512
Reward stats: mean=0.0140, std=0.0904, count=334
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.9015, Q2 Loss: 0.9015, Entropy: 0.6929, Mean TD Error: 1.1477, Threshold: -149.5284
Original likelihood: -179.71238708496094
Adjusted likelihood: -179.71238708496094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4944)
Current yaw: tensor([-0.0041,  0.0401, -0.0299], device='cuda:1')
4 turn
Sampling time 3.7647760969703086
tensor([ 0.0727,  0.5568,  0.5783,  0.5799, -0.1911,  0.7344,  0.7556,  0.7101,
         1.3452,  0.2028,  0.1589,  1.3060, -0.0041,  0.0401, -0.0299,  0.6880],
       device='cuda:1')
Original likelihood: -170.50350952148438
Adjusted likelihood: -170.50350952148438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4961)
State is out of distribution
Projection step: 0, Loss: 172.91513061523438
Projection step: 1, Loss: 167.70376586914062
Projection step: 2, Loss: 165.01336669921875
Projection step: 3, Loss: 165.45574951171875
Projection step: 4, Loss: 158.58270263671875
Projection step: 5, Loss: 159.71279907226562
Projection step: 6, Loss: 158.23593139648438
Projection step: 7, Loss: 160.21206665039062
Projection step: 8, Loss: 146.7505645751953
Projection step: 9, Loss: 151.4736328125
Projection step: 10, Loss: 142.77532958984375
Projection step: 11, Loss: 140.69393920898438
Projection step: 12, Loss: 138.0869140625
Projection step: 13, Loss: 135.98928833007812
Projection step: 14, Loss: 132.2091827392578
Projection step: 15, Loss: 139.287109375
Projection step: 16, Loss: 132.1366424560547
Projection step: 17, Loss: 126.40214538574219
Projection step: 18, Loss: 120.72614288330078
Projection step: 19, Loss: 121.71531677246094
Projection step: 20, Loss: 123.54527282714844
Projection step: 21, Loss: 118.3429183959961
Projection step: 22, Loss: 109.5867691040039
Projection step: 23, Loss: 113.37135314941406
Projection step: 24, Loss: 109.41072082519531
Final likelihood: tensor([-121.6659, -105.2484,  -96.7064, -103.6212, -102.6865, -117.1508,
        -118.5908,  -95.1548,  -98.9753,  -92.8844, -101.1182, -117.9339,
        -102.8191, -114.2859,  -96.9151, -102.1528])
Final projection likelihood: -105.4943
1 mode projection succeeded
New goal: tensor([ 0.0801,  0.5641,  0.5533,  0.6113, -0.1096,  0.6557,  0.8080,  0.7433,
         1.3117,  0.2396,  0.1816,  1.2615, -0.0067,  0.0210, -2.2052],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -106.01495361328125
Adjusted likelihood: -106.01495361328125
Likelihood residual: 0.0
Original likelihood: -138.0406036376953
Adjusted likelihood: -138.0406036376953
Likelihood residual: 0.0
{'index': 138.0406036376953, 'thumb_middle': 106.01495361328125}
Current yaw: tensor([-0.0041,  0.0401, -0.0299], device='cuda:1')
5 thumb_middle
tensor([ 0.0727,  0.5568,  0.5783,  0.5799, -0.1911,  0.7344,  0.7556,  0.7101,
         1.3452,  0.2028,  0.1589,  1.3060, -0.0041,  0.0401, -0.0299,  0.6880],
       device='cuda:1')
Solve time for step 1 9.155514863028657
Current ori: tensor([-0.0041,  0.0401, -0.0299], device='cuda:1')
Index force: tensor([0.5430, 0.4999, 0.5997, 0.5012], device='cuda:1')
tensor([ 0.0675,  0.5627,  0.5432,  0.6223, -0.2356,  0.6512,  0.7576,  0.7108,
         1.2801,  0.2078,  0.1133,  1.2477, -0.0014,  0.0439, -0.0299,  0.6789],
       device='cuda:1')
Solve time for step 2 3.6222984609776177
Current ori: tensor([-0.0014,  0.0439, -0.0299], device='cuda:1')
Index force: tensor([0.5000, 0.5790, 0.5675], device='cuda:1')
tensor([ 0.0667,  0.5646,  0.5485,  0.6050, -0.2319,  0.6352,  0.7621,  0.7234,
         1.2831,  0.2145,  0.1063,  1.2343, -0.0032,  0.0442, -0.0299,  0.6731],
       device='cuda:1')
Solve time for step 3 3.4796384930377826
Current ori: tensor([-0.0032,  0.0442, -0.0299], device='cuda:1')
Index force: tensor([0.5711, 0.5613], device='cuda:1')
tensor([ 0.0860,  0.5772,  0.5447,  0.6159, -0.2329,  0.6463,  0.7763,  0.7158,
         1.2668,  0.2155,  0.1049,  1.2253, -0.0057,  0.0329, -0.0299,  0.7021],
       device='cuda:1')
Solve time for step 4 3.330460580997169
Current ori: tensor([-0.0057,  0.0329, -0.0299], device='cuda:1')
Index force: tensor([0.5478], device='cuda:1')
Storing RECOVERY transition: reward=0.0042 (scaled=0.0042), steps=0
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0903
Collected 335 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.8471, Q2 Loss=0.8471, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4618
SAC Update 2/5: Actor Loss=-0.0128, Q1 Loss=1.3506, Q2 Loss=1.3506, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6354
SAC Update 3/5: Actor Loss=-0.0113, Q1 Loss=1.1434, Q2 Loss=1.1434, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5820
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=0.8359, Q2 Loss=0.8359, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0503
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.8039, Q2 Loss=0.8039, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0404

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.04s (17.0%)
Q2 update: 0.05s (20.0%)
Actor update: 0.10s (43.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009758
Q1 loss: 0.996176
Q2 loss: 0.996176
Current threshold: -149.5282
Global Scale Offset: 2169.9615
Reward stats: mean=0.0140, std=0.0903, count=335
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 0.9962, Q2 Loss: 0.9962, Entropy: 0.6931, Mean TD Error: 0.5540, Threshold: -149.5282
Original likelihood: -142.80523681640625
Adjusted likelihood: -142.80523681640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5012)
State is out of distribution
Projection step: 0, Loss: 145.87860107421875
Projection step: 1, Loss: 138.98753356933594
Projection step: 2, Loss: 146.21946716308594
Projection step: 3, Loss: 147.0350341796875
Projection step: 4, Loss: 142.0005340576172
Projection step: 5, Loss: 132.36041259765625
Projection step: 6, Loss: 126.21757507324219
Projection step: 7, Loss: 126.59199523925781
Projection step: 8, Loss: 119.19236755371094
Projection step: 9, Loss: 111.62657928466797
Projection step: 10, Loss: 112.68226623535156
Projection step: 11, Loss: 111.38789367675781
Projection step: 12, Loss: 112.74093627929688
Projection step: 13, Loss: 106.20086669921875
Projection step: 14, Loss: 107.31953430175781
Projection step: 15, Loss: 96.96018981933594
Final likelihood: tensor([-101.7501,  -90.1007,  -98.4530, -108.4478,  -86.4142,  -94.7251,
         -91.5298, -113.6454,  -90.6982, -125.9298, -106.9543,  -93.0211,
         -87.4768,  -83.1797,  -99.7304,  -79.3065])
Final projection likelihood: -96.9602
1 mode projection succeeded
New goal: tensor([ 0.0824,  0.5626,  0.5579,  0.6120, -0.1096,  0.6456,  0.8224,  0.7500,
         1.3091,  0.2523,  0.1893,  1.2377, -0.0042,  0.0205, -0.1051],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -110.266845703125
Adjusted likelihood: -110.266845703125
Likelihood residual: 0.0
Original likelihood: -118.38259887695312
Adjusted likelihood: -118.38259887695312
Likelihood residual: 0.0
{'index': 118.38259887695312, 'thumb_middle': 110.266845703125}
Current yaw: tensor([-0.0042,  0.0318, -0.0335], device='cuda:1')
6 thumb_middle
tensor([ 0.0875,  0.5699,  0.5593,  0.6101, -0.1729,  0.6760,  0.8076,  0.7366,
         1.3405,  0.2378,  0.1488,  1.2486, -0.0042,  0.0318, -0.0335,  0.7179],
       device='cuda:1')
Solve time for step 1 8.899232138996013
Current ori: tensor([-0.0042,  0.0318, -0.0335], device='cuda:1')
Index force: tensor([0.6005, 0.5832, 0.6041, 0.6061], device='cuda:1')
tensor([ 0.0886,  0.5692,  0.5612,  0.6103, -0.2205,  0.6279,  0.7804,  0.7245,
         1.2677,  0.2226,  0.1079,  1.2109, -0.0044,  0.0315, -0.0335,  0.7097],
       device='cuda:1')
Solve time for step 2 3.5611272329697385
Current ori: tensor([-0.0044,  0.0315, -0.0335], device='cuda:1')
Index force: tensor([0.5746, 0.5956, 0.5974], device='cuda:1')
tensor([ 0.0873,  0.5835,  0.5462,  0.5987, -0.2214,  0.6290,  0.7818,  0.7223,
         1.2676,  0.2250,  0.1036,  1.2059, -0.0085,  0.0317, -0.0335,  0.7027],
       device='cuda:1')
Solve time for step 3 3.523848604003433
Current ori: tensor([-0.0085,  0.0317, -0.0335], device='cuda:1')
Index force: tensor([0.5852, 0.5880], device='cuda:1')
tensor([ 0.0832,  0.5680,  0.5564,  0.6126, -0.2228,  0.6262,  0.7830,  0.7223,
         1.2686,  0.2253,  0.1075,  1.2081, -0.0038,  0.0347, -0.0335,  0.7025],
       device='cuda:1')
Solve time for step 4 3.2681090300320648
Current ori: tensor([-0.0038,  0.0347, -0.0335], device='cuda:1')
Index force: tensor([0.5989], device='cuda:1')
Storing RECOVERY transition: reward=0.0112 (scaled=0.0112), steps=0
Reward stats updated: mean 0.0140 -> 0.0139, std: 0.0901
Collected 336 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8051, Q2 Loss=0.8051, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3607
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=3.5597, Q2 Loss=3.5597, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5052
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=1.7199, Q2 Loss=1.7199, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5592
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=0.8647, Q2 Loss=0.8647, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0411
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=1.1031, Q2 Loss=1.1031, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8354

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (39.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009371
Q1 loss: 1.610517
Q2 loss: 1.610517
Current threshold: -149.5280
Global Scale Offset: 2183.6296
Reward stats: mean=0.0139, std=0.0901, count=336
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.6105, Q2 Loss: 1.6105, Entropy: 0.6929, Mean TD Error: 1.4603, Threshold: -149.5280
Original likelihood: -147.22268676757812
Adjusted likelihood: -147.22268676757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5004)
Current yaw: tensor([-0.0067,  0.0326, -0.0406], device='cuda:1')
7 turn
Sampling time 3.797024294966832
tensor([ 0.0855,  0.5800,  0.5478,  0.6016, -0.1681,  0.6611,  0.8122,  0.7409,
         1.3334,  0.2518,  0.1591,  1.2312, -0.0067,  0.0326, -0.0406,  0.7191],
       device='cuda:1')
Original likelihood: -135.7513427734375
Adjusted likelihood: -135.7513427734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5025)
State is out of distribution
Projection step: 0, Loss: 165.76943969726562
Projection step: 1, Loss: 152.58538818359375
Projection step: 2, Loss: 156.7076416015625
Projection step: 3, Loss: 136.08737182617188
Projection step: 4, Loss: 133.53668212890625
Projection step: 5, Loss: 134.3875274658203
Projection step: 6, Loss: 125.93760681152344
Projection step: 7, Loss: 124.54386901855469
Projection step: 8, Loss: 121.33856201171875
Projection step: 9, Loss: 121.56644439697266
Projection step: 10, Loss: 124.62361907958984
Projection step: 11, Loss: 119.82946014404297
Projection step: 12, Loss: 110.22048950195312
Projection step: 13, Loss: 108.26817321777344
Projection step: 14, Loss: 107.60089874267578
Projection step: 15, Loss: 101.74014282226562
Final likelihood: tensor([ -94.8579, -118.2050, -106.9333,  -92.3844, -111.9704, -111.9905,
        -107.2393, -112.4068, -109.8678,  -89.2640,  -92.0657,  -96.4368,
         -97.4419,  -91.2281, -101.1137,  -94.4367])
Final projection likelihood: -101.7401
1 mode projection succeeded
New goal: tensor([ 0.0811,  0.5655,  0.5584,  0.6055, -0.1038,  0.6362,  0.8203,  0.7465,
         1.3134,  0.2569,  0.1821,  1.2270, -0.0077,  0.0210, -0.2449],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -115.32490539550781
Adjusted likelihood: -115.32490539550781
Likelihood residual: 0.0
Original likelihood: -123.98237609863281
Adjusted likelihood: -123.98237609863281
Likelihood residual: 0.0
{'index': 123.98237609863281, 'thumb_middle': 115.32490539550781}
Current yaw: tensor([-0.0067,  0.0326, -0.0406], device='cuda:1')
8 thumb_middle
tensor([ 0.0855,  0.5800,  0.5478,  0.6016, -0.1681,  0.6611,  0.8122,  0.7409,
         1.3334,  0.2518,  0.1591,  1.2312, -0.0067,  0.0326, -0.0406,  0.7191],
       device='cuda:1')
Solve time for step 1 9.052603624993935
Current ori: tensor([-0.0067,  0.0326, -0.0406], device='cuda:1')
Index force: tensor([0.5777, 0.5969, 0.5667, 0.5940], device='cuda:1')
tensor([ 0.0811,  0.5870,  0.5393,  0.5908, -0.2162,  0.6141,  0.7804,  0.7250,
         1.2835,  0.2414,  0.0926,  1.1893, -0.0098,  0.0351, -0.0406,  0.6981],
       device='cuda:1')
Solve time for step 2 3.7522954929736443
Current ori: tensor([-0.0098,  0.0351, -0.0406], device='cuda:1')
Index force: tensor([0.5864, 0.5581, 0.5858], device='cuda:1')
tensor([ 0.0841,  0.5639,  0.5618,  0.6146, -0.2216,  0.6190,  0.7841,  0.7279,
         1.2757,  0.2293,  0.1039,  1.1927, -0.0028,  0.0343, -0.0406,  0.7119],
       device='cuda:1')
Solve time for step 3 3.499009136983659
Current ori: tensor([-0.0028,  0.0343, -0.0406], device='cuda:1')
Index force: tensor([0.5484, 0.5760], device='cuda:1')
tensor([ 0.0973,  0.5628,  0.5683,  0.6303, -0.2120,  0.6168,  0.7788,  0.7228,
         1.2644,  0.2349,  0.0983,  1.2023, -0.0014,  0.0270, -0.0406,  0.7345],
       device='cuda:1')
Solve time for step 4 3.3698213049792685
Current ori: tensor([-0.0014,  0.0270, -0.0406], device='cuda:1')
Index force: tensor([0.5660], device='cuda:1')
Storing RECOVERY transition: reward=0.0007 (scaled=0.0007), steps=0
Reward stats updated: mean 0.0139 -> 0.0139, std: 0.0900
Collected 337 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.0910, Q2 Loss=1.0910, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7298
SAC Update 2/5: Actor Loss=-0.0095, Q1 Loss=1.5333, Q2 Loss=1.5333, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3997
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=0.8925, Q2 Loss=0.8925, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3672
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=1.2398, Q2 Loss=1.2398, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3804
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8688, Q2 Loss=0.8688, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5178

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (18.6%)
Actor update: 0.11s (39.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008857
Q1 loss: 1.125056
Q2 loss: 1.125056
Current threshold: -149.5278
Global Scale Offset: 2195.1641
Reward stats: mean=0.0139, std=0.0900, count=337
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.1251, Q2 Loss: 1.1251, Entropy: 0.6931, Mean TD Error: 1.6790, Threshold: -149.5278
Original likelihood: -150.84429931640625
Adjusted likelihood: -150.84429931640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4998)
State is out of distribution
Projection step: 0, Loss: 156.208740234375
Projection step: 1, Loss: 150.99485778808594
Projection step: 2, Loss: 134.31646728515625
Projection step: 3, Loss: 137.11993408203125
Projection step: 4, Loss: 139.8145751953125
Projection step: 5, Loss: 132.90994262695312
Projection step: 6, Loss: 122.42914581298828
Projection step: 7, Loss: 122.45024871826172
Projection step: 8, Loss: 116.11318969726562
Projection step: 9, Loss: 108.9273681640625
Projection step: 10, Loss: 109.25745391845703
Projection step: 11, Loss: 105.62742614746094
Projection step: 12, Loss: 98.21940612792969
Final likelihood: tensor([ -81.1217, -115.2943,  -98.5163,  -81.1884,  -74.4484, -111.5698,
         -92.0004, -117.7363,  -75.7032,  -72.9486, -128.4211,  -78.9864,
         -87.6578, -145.6102, -116.2746,  -94.0329])
Final projection likelihood: -98.2194
1 mode projection succeeded
New goal: tensor([ 0.0800,  0.5611,  0.5707,  0.5983, -0.1167,  0.6229,  0.8148,  0.7759,
         1.3055,  0.2770,  0.1763,  1.2228, -0.0022,  0.0230,  0.0349],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -170.86415100097656
Adjusted likelihood: -170.86415100097656
Likelihood residual: 0.0
Original likelihood: -121.05860137939453
Adjusted likelihood: -121.05860137939453
Likelihood residual: 0.0
{'index': 121.05860137939453, 'thumb_middle': 170.86415100097656}
Current yaw: tensor([-0.0008,  0.0355, -0.0415], device='cuda:1')
9 index
tensor([ 8.1463e-02,  5.6255e-01,  5.5570e-01,  6.2544e-01, -1.6030e-01,
         6.4261e-01,  8.1738e-01,  7.3621e-01,  1.3386e+00,  2.5940e-01,
         1.5599e-01,  1.2297e+00, -8.2664e-04,  3.5518e-02, -4.1508e-02,
         7.2439e-01], device='cuda:1')
Solve time for step 1 10.622131446027197
Current ori: tensor([-0.0008,  0.0355, -0.0415], device='cuda:1')
Middle force: tensor([0.6026, 0.5728, 0.5897, 0.5936], device='cuda:1')
Thumb force: tensor([0.5824, 0.5227, 0.6108, 0.5947], device='cuda:1')
tensor([ 0.1251,  0.5054,  0.5187,  0.5802, -0.1663,  0.6331,  0.8160,  0.7711,
         1.3330,  0.2704,  0.1681,  1.2178,  0.0024,  0.0369, -0.0660,  1.0515],
       device='cuda:1')
Solve time for step 2 4.283257125003729
Current ori: tensor([ 0.0024,  0.0369, -0.0660], device='cuda:1')
Middle force: tensor([0.5029, 0.5554, 0.5750], device='cuda:1')
Thumb force: tensor([0.5611, 0.5098, 0.5790], device='cuda:1')
tensor([ 0.1279,  0.5067,  0.5191,  0.5758, -0.1574,  0.6296,  0.8239,  0.7834,
         1.3270,  0.2739,  0.1554,  1.2320,  0.0041,  0.0293, -0.0812,  1.1477],
       device='cuda:1')
Solve time for step 3 4.183455016987864
Current ori: tensor([ 0.0041,  0.0293, -0.0812], device='cuda:1')
Middle force: tensor([0.5688, 0.5255], device='cuda:1')
Thumb force: tensor([0.5864, 0.5151], device='cuda:1')
tensor([ 1.2607e-01,  5.0523e-01,  5.2064e-01,  5.7393e-01, -1.5479e-01,
         6.3721e-01,  8.1715e-01,  7.7436e-01,  1.3226e+00,  2.8162e-01,
         1.5826e-01,  1.2230e+00,  3.6497e-04,  2.8283e-02, -8.2562e-02,
         1.0808e+00], device='cuda:1')
Solve time for step 4 3.927947074000258
Current ori: tensor([ 0.0004,  0.0283, -0.0826], device='cuda:1')
Middle force: tensor([0.5831], device='cuda:1')
Thumb force: tensor([0.5808], device='cuda:1')
Storing RECOVERY transition: reward=0.0278 (scaled=0.0278), steps=0
Reward stats updated: mean 0.0139 -> 0.0140, std: 0.0899
Collected 338 transitions for RL
SAC Update 1/5: Actor Loss=-0.0121, Q1 Loss=1.4566, Q2 Loss=1.4566, Entropy=0.6914, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0696
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.1897, Q2 Loss=1.1897, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7058
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=1.8980, Q2 Loss=1.8980, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5872
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7019, Q2 Loss=0.7019, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1927
SAC Update 5/5: Actor Loss=-0.0135, Q1 Loss=1.3376, Q2 Loss=1.3376, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4387

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010165
Q1 loss: 1.316762
Q2 loss: 1.316762
Current threshold: -149.5275
Global Scale Offset: 2209.9686
Reward stats: mean=0.0140, std=0.0899, count=338
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.3168, Q2 Loss: 1.3168, Entropy: 0.6926, Mean TD Error: 1.3988, Threshold: -149.5275
Original likelihood: -130.48072814941406
Adjusted likelihood: -130.48072814941406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5034)
State is out of distribution
Projection step: 0, Loss: 128.34930419921875
Projection step: 1, Loss: 116.23294830322266
Projection step: 2, Loss: 108.30630493164062
Projection step: 3, Loss: 115.11909484863281
Projection step: 4, Loss: 107.95197296142578
Projection step: 5, Loss: 112.07850646972656
Projection step: 6, Loss: 104.08763122558594
Final likelihood: tensor([-120.1863, -107.7929,  -96.7664, -108.9715, -131.0874, -123.7568,
         -77.9244, -102.0448, -107.6384,  -86.5251, -129.4221, -116.4369,
         -94.0719,  -80.5102, -100.4743,  -81.7927])
Final projection likelihood: -104.0876
1 mode projection succeeded
New goal: tensor([ 0.0828,  0.5667,  0.5694,  0.5925, -0.1213,  0.6377,  0.8108,  0.7692,
         1.3042,  0.2787,  0.1683,  1.2212, -0.0052,  0.0211,  0.0226],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -144.43557739257812
Adjusted likelihood: -144.43557739257812
Likelihood residual: 0.0
Original likelihood: -108.7574462890625
Adjusted likelihood: -108.7574462890625
Likelihood residual: 0.0
{'index': 108.7574462890625, 'thumb_middle': 144.43557739257812}
Current yaw: tensor([-0.0057,  0.0245, -0.0680], device='cuda:1')
10 index
tensor([ 0.0785,  0.5674,  0.5627,  0.5940, -0.1453,  0.6573,  0.7996,  0.7508,
         1.3206,  0.2822,  0.1523,  1.2196, -0.0057,  0.0245, -0.0680,  1.0270],
       device='cuda:1')
Solve time for step 1 10.537426564027555
Current ori: tensor([-0.0057,  0.0245, -0.0680], device='cuda:1')
Middle force: tensor([0.5091, 0.5240, 0.5189, 0.5901], device='cuda:1')
Thumb force: tensor([0.6242, 0.5825, 0.5499, 0.5319], device='cuda:1')
tensor([ 0.1300,  0.5087,  0.5186,  0.5689, -0.1566,  0.6567,  0.8040,  0.7581,
         1.3280,  0.2861,  0.1512,  1.2010, -0.0141,  0.0272, -0.0888,  1.5452],
       device='cuda:1')
Solve time for step 2 4.172032418020535
Current ori: tensor([-0.0141,  0.0272, -0.0888], device='cuda:1')
Middle force: tensor([0.5221, 0.5167, 0.5844], device='cuda:1')
Thumb force: tensor([0.5723, 0.5458, 0.5288], device='cuda:1')
tensor([ 0.1337,  0.5109,  0.5192,  0.5668, -0.1522,  0.6446,  0.8188,  0.7772,
         1.3315,  0.2766,  0.1369,  1.2199, -0.0091,  0.0224, -0.1044,  1.7678],
       device='cuda:1')
Solve time for step 3 3.92412187095033
Current ori: tensor([-0.0091,  0.0224, -0.1044], device='cuda:1')
Middle force: tensor([0.5704, 0.5898], device='cuda:1')
Thumb force: tensor([0.6055, 0.5598], device='cuda:1')
tensor([ 0.1329,  0.5106,  0.5178,  0.5675, -0.1499,  0.6459,  0.8190,  0.7780,
         1.3255,  0.2837,  0.1374,  1.2217, -0.0090,  0.0206, -0.1038,  1.7905],
       device='cuda:1')
Solve time for step 4 4.016603696043603
Current ori: tensor([-0.0090,  0.0206, -0.1038], device='cuda:1')
Middle force: tensor([0.5648], device='cuda:1')
Thumb force: tensor([0.5361], device='cuda:1')
Storing RECOVERY transition: reward=0.0454 (scaled=0.0454), steps=0
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0898
Collected 339 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.8235, Q2 Loss=0.8235, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9685
SAC Update 2/5: Actor Loss=-0.0116, Q1 Loss=1.1917, Q2 Loss=1.1917, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7305
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.7307, Q2 Loss=0.7307, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3550
SAC Update 4/5: Actor Loss=-0.0129, Q1 Loss=1.3161, Q2 Loss=1.3161, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5180
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8521, Q2 Loss=0.8521, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4381

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009551
Q1 loss: 0.982822
Q2 loss: 0.982822
Current threshold: -149.5274
Global Scale Offset: 2220.9711
Reward stats: mean=0.0140, std=0.0898, count=339
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 0.9828, Q2 Loss: 0.9828, Entropy: 0.6931, Mean TD Error: 0.8020, Threshold: -149.5274
Original likelihood: -126.91015625
Adjusted likelihood: -126.91015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5041)
State is out of distribution
Projection step: 0, Loss: 124.344482421875
Projection step: 1, Loss: 112.41179656982422
Projection step: 2, Loss: 121.92835235595703
Projection step: 3, Loss: 113.06464385986328
Projection step: 4, Loss: 106.4635009765625
Projection step: 5, Loss: 111.58720397949219
Projection step: 6, Loss: 111.9393310546875
Projection step: 7, Loss: 112.42566680908203
Projection step: 8, Loss: 106.11046600341797
Projection step: 9, Loss: 95.59154510498047
Final likelihood: tensor([ -90.9753,  -90.6333,  -86.8058, -100.9886,  -92.2074,  -86.5581,
         -86.2631, -123.8451, -121.6844,  -95.5025,  -80.1725,  -94.1874,
         -98.2456,  -82.7044, -118.0892,  -80.6019])
Final projection likelihood: -95.5915
1 mode projection succeeded
New goal: tensor([ 0.0861,  0.5665,  0.5752,  0.5929, -0.1071,  0.6274,  0.8215,  0.7717,
         1.3057,  0.2797,  0.1696,  1.2129, -0.0084,  0.0187, -0.0542],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -115.46009826660156
Adjusted likelihood: -115.46009826660156
Likelihood residual: 0.0
Original likelihood: -114.25582885742188
Adjusted likelihood: -114.25582885742188
Likelihood residual: 0.0
{'index': 114.25582885742188, 'thumb_middle': 115.46009826660156}
Current yaw: tensor([-0.0097,  0.0206, -0.0855], device='cuda:1')
11 index
tensor([ 0.0801,  0.5710,  0.5621,  0.5888, -0.1483,  0.6528,  0.8121,  0.7690,
         1.3242,  0.2835,  0.1350,  1.2280, -0.0097,  0.0206, -0.0855,  1.7483],
       device='cuda:1')
Solve time for step 1 10.643147281953134
Current ori: tensor([-0.0097,  0.0206, -0.0855], device='cuda:1')
Middle force: tensor([0.5310, 0.5661, 0.5194, 0.5590], device='cuda:1')
Thumb force: tensor([0.5984, 0.5673, 0.5616, 0.5747], device='cuda:1')
tensor([ 0.1339,  0.5093,  0.5219,  0.5658, -0.1537,  0.6415,  0.8244,  0.7735,
         1.3277,  0.2835,  0.1462,  1.2067, -0.0098,  0.0232, -0.1127,  1.7440],
       device='cuda:1')
Solve time for step 2 4.257332569977734
Current ori: tensor([-0.0098,  0.0232, -0.1127], device='cuda:1')
Middle force: tensor([0.5591, 0.5172, 0.5556], device='cuda:1')
Thumb force: tensor([0.5614, 0.5559, 0.5688], device='cuda:1')
tensor([ 0.1369,  0.5082,  0.5244,  0.5680, -0.1622,  0.6389,  0.8218,  0.7709,
         1.3500,  0.2552,  0.1443,  1.2014, -0.0098,  0.0298, -0.1096,  1.6072],
       device='cuda:1')
Solve time for step 3 4.073985255032312
Current ori: tensor([-0.0098,  0.0298, -0.1096], device='cuda:1')
Middle force: tensor([0.5177, 0.5000], device='cuda:1')
Thumb force: tensor([0.5489, 0.5918], device='cuda:1')
tensor([ 0.1379,  0.5048,  0.5275,  0.5744, -0.1602,  0.6364,  0.8280,  0.7706,
         1.3343,  0.2900,  0.1460,  1.1983, -0.0127,  0.0278, -0.1367,  1.4334],
       device='cuda:1')
Solve time for step 4 3.972876875952352
Current ori: tensor([-0.0127,  0.0278, -0.1367], device='cuda:1')
Middle force: tensor([0.5326], device='cuda:1')
Thumb force: tensor([0.5750], device='cuda:1')
Storing RECOVERY transition: reward=0.0794 (scaled=0.0794), steps=0
Reward stats updated: mean 0.0140 -> 0.0142, std: 0.0897
Collected 340 transitions for RL
SAC Update 1/5: Actor Loss=-0.0098, Q1 Loss=1.1684, Q2 Loss=1.1684, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1781
SAC Update 2/5: Actor Loss=-0.0109, Q1 Loss=1.6011, Q2 Loss=1.6011, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8534
SAC Update 3/5: Actor Loss=-0.0116, Q1 Loss=1.1638, Q2 Loss=1.1638, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6181
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=1.4237, Q2 Loss=1.4237, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6767
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8261, Q2 Loss=0.8261, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8674

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (43.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010059
Q1 loss: 1.236604
Q2 loss: 1.236604
Current threshold: -149.5274
Global Scale Offset: 2234.4956
Reward stats: mean=0.0142, std=0.0897, count=340
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.2366, Q2 Loss: 1.2366, Entropy: 0.6929, Mean TD Error: 1.2387, Threshold: -149.5274
Original likelihood: -137.86024475097656
Adjusted likelihood: -137.86024475097656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5021)
State is out of distribution
Projection step: 0, Loss: 134.28045654296875
Projection step: 1, Loss: 133.72882080078125
Projection step: 2, Loss: 123.49310302734375
Projection step: 3, Loss: 125.53428649902344
Projection step: 4, Loss: 127.33871459960938
Projection step: 5, Loss: 116.51531219482422
Projection step: 6, Loss: 114.29078674316406
Projection step: 7, Loss: 117.70361328125
Projection step: 8, Loss: 113.89443969726562
Projection step: 9, Loss: 107.60063171386719
Projection step: 10, Loss: 106.96818542480469
Projection step: 11, Loss: 101.86847686767578
Final likelihood: tensor([-100.6221,  -98.1576, -103.1117, -103.4549, -109.2413, -115.2396,
        -121.6776,  -97.1622,  -98.7847,  -85.9018,  -99.1916, -117.2530,
         -93.1686,  -83.3229,  -88.7730, -114.8330])
Final projection likelihood: -101.8685
1 mode projection succeeded
New goal: tensor([ 0.0870,  0.5615,  0.5721,  0.6065, -0.1014,  0.6262,  0.8224,  0.7560,
         1.3180,  0.2707,  0.1734,  1.1934, -0.0162,  0.0209,  0.1854],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -114.86405944824219
Adjusted likelihood: -114.86405944824219
Likelihood residual: 0.0
Original likelihood: -121.961669921875
Adjusted likelihood: -121.961669921875
Likelihood residual: 0.0
{'index': 121.961669921875, 'thumb_middle': 114.86405944824219}
Current yaw: tensor([-0.0167,  0.0235, -0.1199], device='cuda:1')
12 thumb_middle
tensor([ 0.0867,  0.5687,  0.5702,  0.5912, -0.1521,  0.6526,  0.8134,  0.7576,
         1.3315,  0.2897,  0.1366,  1.2055, -0.0167,  0.0235, -0.1199,  1.3472],
       device='cuda:1')
Solve time for step 1 8.885826951009221
Current ori: tensor([-0.0167,  0.0235, -0.1199], device='cuda:1')
Index force: tensor([0.5609, 0.5949, 0.5814, 0.5825], device='cuda:1')
tensor([ 0.0851,  0.5652,  0.5729,  0.5917, -0.2084,  0.6129,  0.7709,  0.7307,
         1.2743,  0.2429,  0.0979,  1.1738, -0.0156,  0.0248, -0.1199,  1.3413],
       device='cuda:1')
Solve time for step 2 3.5608204310410656
Current ori: tensor([-0.0156,  0.0248, -0.1199], device='cuda:1')
Index force: tensor([0.5842, 0.5726, 0.5744], device='cuda:1')
tensor([ 0.0889,  0.5679,  0.5659,  0.6065, -0.2069,  0.6020,  0.7829,  0.7447,
         1.2758,  0.2429,  0.0851,  1.1682, -0.0150,  0.0225, -0.1199,  1.3500],
       device='cuda:1')
Solve time for step 3 3.441882254963275
Current ori: tensor([-0.0150,  0.0225, -0.1199], device='cuda:1')
Index force: tensor([0.5632, 0.5664], device='cuda:1')
tensor([ 0.0992,  0.5732,  0.5745,  0.5952, -0.2088,  0.6058,  0.7994,  0.7312,
         1.2734,  0.2300,  0.0876,  1.1524, -0.0172,  0.0162, -0.1199,  1.3608],
       device='cuda:1')
Solve time for step 4 3.3905853639589623
Current ori: tensor([-0.0172,  0.0162, -0.1199], device='cuda:1')
Index force: tensor([0.5531], device='cuda:1')
Storing RECOVERY transition: reward=0.0789 (scaled=0.0789), steps=0
Reward stats updated: mean 0.0142 -> 0.0144, std: 0.0896
Collected 341 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=0.9791, Q2 Loss=0.9791, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8705
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=0.7515, Q2 Loss=0.7515, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1924
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=0.9536, Q2 Loss=0.9536, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7219
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8521, Q2 Loss=0.8521, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2380
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=1.1574, Q2 Loss=1.1574, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6960

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (18.0%)
Actor update: 0.10s (42.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008295
Q1 loss: 0.938736
Q2 loss: 0.938736
Current threshold: -149.5273
Global Scale Offset: 2251.9457
Reward stats: mean=0.0144, std=0.0896, count=341
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 0.9387, Q2 Loss: 0.9387, Entropy: 0.6930, Mean TD Error: 1.1438, Threshold: -149.5273
Original likelihood: -125.5197525024414
Adjusted likelihood: -125.5197525024414
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5043)
Current yaw: tensor([-0.0135,  0.0198, -0.1191], device='cuda:1')
13 turn
Sampling time 3.627087800996378
tensor([ 0.0935,  0.5626,  0.5757,  0.6105, -0.1455,  0.6488,  0.8191,  0.7589,
         1.3299,  0.2758,  0.1462,  1.1920, -0.0135,  0.0198, -0.1191,  1.3598],
       device='cuda:1')
Original likelihood: -126.38469696044922
Adjusted likelihood: -126.38469696044922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5041)
State is out of distribution
Projection step: 0, Loss: 122.37611389160156
Projection step: 1, Loss: 118.35913848876953
Projection step: 2, Loss: 119.07244873046875
Projection step: 3, Loss: 106.10487365722656
Projection step: 4, Loss: 113.70621490478516
Projection step: 5, Loss: 109.51752471923828
Projection step: 6, Loss: 102.28303527832031
Final likelihood: tensor([-112.6123, -101.0858,  -98.8999,  -98.8580, -100.6758, -101.3715,
        -100.2769, -112.9369, -105.2490, -103.1616, -100.4103,  -92.5832,
         -94.0868, -109.3621, -103.0425, -101.9160])
Final projection likelihood: -102.2830
1 mode projection succeeded
New goal: tensor([ 0.0972,  0.5643,  0.5824,  0.6046, -0.1158,  0.6357,  0.8284,  0.7610,
         1.3156,  0.2698,  0.1698,  1.1881, -0.0129,  0.0194, -0.0942],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -123.10362243652344
Adjusted likelihood: -123.10362243652344
Likelihood residual: 0.0
Original likelihood: -110.7502670288086
Adjusted likelihood: -110.7502670288086
Likelihood residual: 0.0
{'index': 110.7502670288086, 'thumb_middle': 123.10362243652344}
Current yaw: tensor([-0.0135,  0.0198, -0.1191], device='cuda:1')
14 index
tensor([ 0.0935,  0.5626,  0.5757,  0.6105, -0.1455,  0.6488,  0.8191,  0.7589,
         1.3299,  0.2758,  0.1462,  1.1920, -0.0135,  0.0198, -0.1191,  1.3598],
       device='cuda:1')
Solve time for step 1 10.241390097013209
Current ori: tensor([-0.0135,  0.0198, -0.1191], device='cuda:1')
Middle force: tensor([0.5419, 0.5731, 0.5579, 0.5001], device='cuda:1')
Thumb force: tensor([0.5754, 0.5221, 0.5917, 0.5713], device='cuda:1')
tensor([ 0.1463,  0.5058,  0.5309,  0.5799, -0.1515,  0.6403,  0.8276,  0.7633,
         1.3338,  0.2751,  0.1551,  1.1762, -0.0131,  0.0229, -0.1362,  1.0586],
       device='cuda:1')
Solve time for step 2 4.308716989995446
Current ori: tensor([-0.0131,  0.0229, -0.1362], device='cuda:1')
Middle force: tensor([0.5668, 0.5558, 0.5000], device='cuda:1')
Thumb force: tensor([0.5206, 0.5888, 0.5683], device='cuda:1')
tensor([ 0.1488,  0.5074,  0.5289,  0.5790, -0.1497,  0.6533,  0.8156,  0.7474,
         1.3321,  0.2807,  0.1589,  1.1587, -0.0198,  0.0226, -0.1368,  0.8611],
       device='cuda:1')
Solve time for step 3 4.029892839957029
Current ori: tensor([-0.0198,  0.0226, -0.1368], device='cuda:1')
Middle force: tensor([0.5526, 0.5000], device='cuda:1')
Thumb force: tensor([0.5792, 0.5630], device='cuda:1')
tensor([ 0.1478,  0.5056,  0.5305,  0.5785, -0.1536,  0.6470,  0.8197,  0.7553,
         1.3705,  0.2276,  0.1290,  1.1750, -0.0199,  0.0247, -0.1543,  0.8021],
       device='cuda:1')
Solve time for step 4 3.8701984750223346
Current ori: tensor([-0.0199,  0.0247, -0.1543], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5552], device='cuda:1')
Storing RECOVERY transition: reward=0.0332 (scaled=0.0332), steps=0
Reward stats updated: mean 0.0144 -> 0.0145, std: 0.0895
Collected 342 transitions for RL
SAC Update 1/5: Actor Loss=-0.0091, Q1 Loss=1.5012, Q2 Loss=1.5012, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2905
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=4.2806, Q2 Loss=4.2806, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0212
SAC Update 3/5: Actor Loss=-0.0135, Q1 Loss=1.5131, Q2 Loss=1.5131, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0267
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=1.5869, Q2 Loss=1.5869, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6188
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=1.0875, Q2 Loss=1.0875, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5062

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (37.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009740
Q1 loss: 1.993856
Q2 loss: 1.993856
Current threshold: -149.5271
Global Scale Offset: 2269.0936
Reward stats: mean=0.0145, std=0.0895, count=342
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.9939, Q2 Loss: 1.9939, Entropy: 0.6930, Mean TD Error: 2.4927, Threshold: -149.5271
Original likelihood: -136.5449676513672
Adjusted likelihood: -136.5449676513672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5023)
Current yaw: tensor([-0.0197,  0.0227, -0.1527], device='cuda:1')
15 turn
Sampling time 3.8492020909907296
tensor([ 0.0957,  0.5682,  0.5747,  0.6007, -0.1506,  0.6477,  0.8213,  0.7538,
         1.3370,  0.2813,  0.1394,  1.1859, -0.0197,  0.0227, -0.1527,  0.7970],
       device='cuda:1')
Original likelihood: -134.64694213867188
Adjusted likelihood: -134.64694213867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5026)
Solve time for step 1 14.34432094899239
Current ori: tensor([-0.0197,  0.0227, -0.1527], device='cuda:1')
Middle force: tensor([0.9028, 1.2414, 0.9060, 0.7965, 1.0487, 1.4144, 1.2749, 0.6538, 0.4420,
        0.4523, 0.5687, 0.4645], device='cuda:1')
Thumb force: tensor([0.7437, 2.2054, 0.5355, 2.1450, 1.0752, 0.6953, 0.7090, 0.6335, 0.7865,
        0.5290, 0.6652, 0.5262], device='cuda:1')
Index force: tensor([0.5654, 1.1809, 0.5147, 1.2179, 0.9711, 0.6476, 0.8321, 0.7982, 0.6042,
        0.6299, 0.5024, 0.5465], device='cuda:1')
Storing NORMAL transition: reward=0.2696 (scaled=0.2696), steps=1
Reward stats updated: mean 0.0145 -> 0.0152, std: 0.0904
Collected 343 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.4098, Q2 Loss=1.4098, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7191
SAC Update 2/5: Actor Loss=-0.0115, Q1 Loss=1.3017, Q2 Loss=1.3017, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9297
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=0.9053, Q2 Loss=0.9053, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4018
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=0.8636, Q2 Loss=0.8636, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6538
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.6916, Q2 Loss=0.6916, Entropy=0.6915, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6727

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009326
Q1 loss: 1.034384
Q2 loss: 1.034384
Current threshold: -149.5267
Global Scale Offset: 2286.4331
Reward stats: mean=0.0152, std=0.0904, count=343
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.0344, Q2 Loss: 1.0344, Entropy: 0.6927, Mean TD Error: 0.8754, Threshold: -149.5267
tensor([ 0.0474,  0.5739,  0.5489,  0.5388, -0.1104,  0.5492,  1.0014,  0.7648,
         1.3520,  0.2591,  0.1316,  1.0522, -0.0243, -0.0109, -0.4228,  1.9367],
       device='cuda:1')
Original likelihood: -94.42352294921875
Adjusted likelihood: -94.42352294921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5096)
State is out of distribution
Projection step: 0, Loss: 95.56266021728516
Final likelihood: tensor([ -90.3157,  -90.8489,  -98.3201, -105.0033,  -87.0485,  -87.4678,
         -90.8624,  -98.1493,  -95.2216, -104.6526, -105.9718,  -95.2213,
         -93.7260,  -98.4550,  -91.9704,  -95.7677])
Final projection likelihood: -95.5627
1 mode projection succeeded
New goal: tensor([ 0.0474,  0.5739,  0.5489,  0.5388, -0.1104,  0.5492,  1.0014,  0.7648,
         1.3520,  0.2591,  0.1316,  1.0522, -0.0243, -0.0109, -0.4228],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0243, -0.0109, -0.4228], device='cuda:1')
16 turn
Sampling time 3.6249949039774947
tensor([ 0.0474,  0.5739,  0.5489,  0.5388, -0.1104,  0.5492,  1.0014,  0.7648,
         1.3520,  0.2591,  0.1316,  1.0522, -0.0243, -0.0109, -0.4228,  1.9367],
       device='cuda:1')
Original likelihood: -92.95120239257812
Adjusted likelihood: -92.95120239257812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5099)
State is out of distribution
Projection step: 0, Loss: 95.7813491821289
Final likelihood: tensor([-104.4599, -102.4591,  -96.0209,  -92.6984,  -90.2497, -102.4847,
         -88.6996,  -92.1214,  -87.5008,  -89.0828,  -88.3591, -114.1878,
         -97.8381,  -87.8508,  -98.7528,  -99.7354])
Final projection likelihood: -95.7813
1 mode projection succeeded
New goal: tensor([ 0.0474,  0.5739,  0.5489,  0.5388, -0.1104,  0.5492,  1.0014,  0.7648,
         1.3520,  0.2591,  0.1316,  1.0522, -0.0243, -0.0109, -0.4228],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0243, -0.0109, -0.4228], device='cuda:1')
17 turn
Sampling time 3.63152470899513
tensor([ 0.0474,  0.5739,  0.5489,  0.5388, -0.1104,  0.5492,  1.0014,  0.7648,
         1.3520,  0.2591,  0.1316,  1.0522, -0.0243, -0.0109, -0.4228,  1.9367],
       device='cuda:1')
Original likelihood: -97.77708435058594
Adjusted likelihood: -97.77708435058594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5090)
Solve time for step 1 14.20103769999696
Current ori: tensor([-0.0243, -0.0109, -0.4228], device='cuda:1')
Middle force: tensor([1.1489, 1.7757, 0.8202, 0.6259, 0.6194, 0.6251, 0.8620, 0.5818, 0.5116,
        0.5885, 1.1407, 0.5756], device='cuda:1')
Thumb force: tensor([0.9078, 0.6515, 0.5797, 1.4646, 0.5734, 0.5102, 0.5865, 0.9429, 0.5633,
        1.0590, 1.2073, 0.7979], device='cuda:1')
Index force: tensor([1.5664, 1.6430, 0.9092, 0.5526, 0.6484, 0.5236, 0.5501, 0.6066, 0.5119,
        0.5328, 0.5455, 0.6240], device='cuda:1')
Storing NORMAL transition: reward=0.1105 (scaled=0.1105), steps=1
Reward stats updated: mean 0.0152 -> 0.0155, std: 0.0905
Collected 344 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8019, Q2 Loss=0.8019, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0865
SAC Update 2/5: Actor Loss=-0.0072, Q1 Loss=0.6981, Q2 Loss=0.6981, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4347
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.3209, Q2 Loss=1.3209, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3237
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8414, Q2 Loss=0.8414, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7654
SAC Update 5/5: Actor Loss=-0.0109, Q1 Loss=1.1840, Q2 Loss=1.1840, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8579

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.4%)
Q1 update: 0.06s (21.1%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (41.3%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009523
Q1 loss: 0.969265
Q2 loss: 0.969265
Current threshold: -149.5263
Global Scale Offset: 2303.7538
Reward stats: mean=0.0155, std=0.0905, count=344
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 0.9693, Q2 Loss: 0.9693, Entropy: 0.6930, Mean TD Error: 0.4936, Threshold: -149.5263
tensor([ 3.7502e-02,  5.9973e-01,  5.3200e-01,  4.4537e-01, -1.2305e-01,
         5.4721e-01,  9.8885e-01,  7.7435e-01,  1.4064e+00,  1.9898e-01,
         1.6722e-01,  9.0689e-01, -4.2317e-02,  9.9084e-04, -5.3480e-01,
         1.9344e+00], device='cuda:1')
Original likelihood: -107.28672790527344
Adjusted likelihood: -107.28672790527344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5073)
State is out of distribution
Projection step: 0, Loss: 109.60794830322266
Projection step: 1, Loss: 102.03628540039062
Final likelihood: tensor([-105.3859, -102.6797, -102.2029, -100.5862, -102.8843, -101.7950,
        -101.1583,  -98.9417, -105.6103,  -99.3985, -100.3976, -101.2047,
        -102.9001, -107.8194,  -95.3777, -104.2383])
Final projection likelihood: -102.0363
1 mode projection succeeded
New goal: tensor([ 3.7092e-02,  6.0120e-01,  5.3405e-01,  4.5125e-01, -1.1700e-01,
         5.4965e-01,  9.8140e-01,  7.7099e-01,  1.4047e+00,  1.9770e-01,
         1.7701e-01,  9.0579e-01, -4.2178e-02,  1.0114e-03, -5.1587e-01],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -123.00028228759766
Adjusted likelihood: -123.00028228759766
Likelihood residual: 0.0
Original likelihood: -105.48077392578125
Adjusted likelihood: -105.48077392578125
Likelihood residual: 0.0
{'index': 105.48077392578125, 'thumb_middle': 123.00028228759766}
Current yaw: tensor([-0.0423,  0.0010, -0.5348], device='cuda:1')
18 index
tensor([ 3.7502e-02,  5.9973e-01,  5.3200e-01,  4.4537e-01, -1.2305e-01,
         5.4721e-01,  9.8885e-01,  7.7435e-01,  1.4064e+00,  1.9898e-01,
         1.6722e-01,  9.0689e-01, -4.2317e-02,  9.9084e-04, -5.3480e-01,
         1.9344e+00], device='cuda:1')
Solve time for step 1 10.669140899961349
Current ori: tensor([-0.0423,  0.0010, -0.5348], device='cuda:1')
Middle force: tensor([0.5277, 0.5392, 0.5565, 0.5268], device='cuda:1')
Thumb force: tensor([0.5244, 0.5407, 0.6272, 0.5292], device='cuda:1')
tensor([ 0.0690,  0.5365,  0.4814,  0.4278, -0.1152,  0.5544,  0.9845,  0.7763,
         1.4090,  0.1904,  0.1584,  0.9042, -0.0452, -0.0047, -0.5483,  1.9208],
       device='cuda:1')
Solve time for step 2 4.642785468022339
Current ori: tensor([-0.0452, -0.0047, -0.5483], device='cuda:1')
Middle force: tensor([0.5005, 0.5018, 0.5694], device='cuda:1')
Thumb force: tensor([0.5564, 0.5903, 0.5740], device='cuda:1')
tensor([ 0.0667,  0.5365,  0.4803,  0.4254, -0.1125,  0.5521,  0.9881,  0.7809,
         1.4086,  0.1978,  0.1444,  0.9215, -0.0467, -0.0065, -0.5719,  2.0671],
       device='cuda:1')
Solve time for step 3 4.148507890000474
Current ori: tensor([-0.0467, -0.0065, -0.5719], device='cuda:1')
Middle force: tensor([0.5357, 0.5309], device='cuda:1')
Thumb force: tensor([0.5359, 0.6044], device='cuda:1')
tensor([ 0.0645,  0.5371,  0.4802,  0.4245, -0.1057,  0.5694,  0.9766,  0.7637,
         1.4069,  0.1955,  0.1343,  0.9263, -0.0517, -0.0111, -0.5554,  2.2561],
       device='cuda:1')
Solve time for step 4 4.154574212036096
Current ori: tensor([-0.0517, -0.0111, -0.5554], device='cuda:1')
Middle force: tensor([0.5540], device='cuda:1')
Thumb force: tensor([0.5879], device='cuda:1')
Storing RECOVERY transition: reward=0.0109 (scaled=0.0109), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0903
Collected 345 transitions for RL
SAC Update 1/5: Actor Loss=-0.0091, Q1 Loss=1.2449, Q2 Loss=1.2449, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1333
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8225, Q2 Loss=0.8225, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3030
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.9833, Q2 Loss=0.9833, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3397
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.6943, Q2 Loss=0.6943, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6382
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=1.5928, Q2 Loss=1.5928, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2684

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.3%)
Q1 update: 0.06s (20.3%)
Q2 update: 0.06s (20.4%)
Actor update: 0.12s (41.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008130
Q1 loss: 1.067554
Q2 loss: 1.067554
Current threshold: -149.5261
Global Scale Offset: 2322.9495
Reward stats: mean=0.0155, std=0.0903, count=345
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.0676, Q2 Loss: 1.0676, Entropy: 0.6930, Mean TD Error: 1.3365, Threshold: -149.5261
Original likelihood: -114.13424682617188
Adjusted likelihood: -114.13424682617188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5061)
State is out of distribution
Projection step: 0, Loss: 117.28588104248047
Projection step: 1, Loss: 110.83476257324219
Projection step: 2, Loss: 105.228759765625
Projection step: 3, Loss: 99.51573944091797
Final likelihood: tensor([-100.8189,  -98.5750,  -96.3607, -103.2731,  -97.9059, -101.7146,
         -92.3810, -100.6819,  -97.1158, -101.0901, -105.1215, -103.5869,
         -99.1192,  -98.1668,  -97.2918,  -99.0485])
Final projection likelihood: -99.5157
1 mode projection succeeded
New goal: tensor([ 0.0305,  0.5996,  0.5424,  0.4531, -0.0958,  0.5732,  0.9531,  0.7471,
         1.4088,  0.1836,  0.1677,  0.8976, -0.0540, -0.0065, -0.5960],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -121.32000732421875
Adjusted likelihood: -121.32000732421875
Likelihood residual: 0.0
Original likelihood: -115.84452819824219
Adjusted likelihood: -115.84452819824219
Likelihood residual: 0.0
{'index': 115.84452819824219, 'thumb_middle': 121.32000732421875}
Current yaw: tensor([-0.0540, -0.0085, -0.5472], device='cuda:1')
19 index
tensor([ 0.0269,  0.5995,  0.5223,  0.4463, -0.1085,  0.5743,  0.9704,  0.7558,
         1.4112,  0.1896,  0.1363,  0.9203, -0.0540, -0.0085, -0.5472,  2.3030],
       device='cuda:1')
Solve time for step 1 10.65961360995425
Current ori: tensor([-0.0540, -0.0085, -0.5472], device='cuda:1')
Middle force: tensor([0.5574, 0.6016, 0.5316, 0.5398], device='cuda:1')
Thumb force: tensor([0.5297, 0.5876, 0.5009, 0.6609], device='cuda:1')
tensor([ 0.0540,  0.5317,  0.4856,  0.4252, -0.1123,  0.5845,  0.9647,  0.7573,
         1.4154,  0.1832,  0.1364,  0.9071, -0.0590, -0.0090, -0.5484,  2.3148],
       device='cuda:1')
Solve time for step 2 4.2897644869517535
Current ori: tensor([-0.0590, -0.0090, -0.5484], device='cuda:1')
Middle force: tensor([0.5018, 0.5008, 0.5422], device='cuda:1')
Thumb force: tensor([0.5031, 0.5099, 0.5701], device='cuda:1')
tensor([ 0.0541,  0.5331,  0.4864,  0.4229, -0.1176,  0.5955,  0.9603,  0.7470,
         1.4291,  0.1606,  0.1372,  0.8828, -0.0667, -0.0077, -0.5531,  2.4103],
       device='cuda:1')
Solve time for step 3 4.04069365299074
Current ori: tensor([-0.0667, -0.0077, -0.5531], device='cuda:1')
Middle force: tensor([0.5006, 0.5378], device='cuda:1')
Thumb force: tensor([0.5075, 0.5662], device='cuda:1')
tensor([ 0.0535,  0.5343,  0.4847,  0.4257, -0.1077,  0.5906,  0.9686,  0.7635,
         1.4148,  0.1909,  0.1186,  0.9126, -0.0662, -0.0154, -0.5903,  2.5622],
       device='cuda:1')
Solve time for step 4 3.990846121974755
Current ori: tensor([-0.0662, -0.0154, -0.5903], device='cuda:1')
Middle force: tensor([0.5203], device='cuda:1')
Thumb force: tensor([0.5001], device='cuda:1')
Storing RECOVERY transition: reward=0.0376 (scaled=0.0376), steps=1
Reward stats updated: mean 0.0155 -> 0.0156, std: 0.0902
Collected 346 transitions for RL
SAC Update 1/5: Actor Loss=-0.0135, Q1 Loss=1.7009, Q2 Loss=1.7009, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3227
SAC Update 2/5: Actor Loss=-0.0133, Q1 Loss=1.2788, Q2 Loss=1.2788, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2505
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=1.1501, Q2 Loss=1.1501, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8600
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=0.9394, Q2 Loss=0.9394, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3425
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=1.1755, Q2 Loss=1.1755, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6553

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (19.7%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011698
Q1 loss: 1.248940
Q2 loss: 1.248940
Current threshold: -149.5259
Global Scale Offset: 2341.0430
Reward stats: mean=0.0156, std=0.0902, count=346
----------------------------------------------
SAC Update - Actor Loss: -0.0117, Q1 Loss: 1.2489, Q2 Loss: 1.2489, Entropy: 0.6930, Mean TD Error: 0.6862, Threshold: -149.5259
Original likelihood: -140.1062469482422
Adjusted likelihood: -140.1062469482422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5016)
Current yaw: tensor([-0.0685, -0.0149, -0.5768], device='cuda:1')
20 turn
Sampling time 3.768842237011995
tensor([ 0.0199,  0.5940,  0.5252,  0.4463, -0.1155,  0.6036,  0.9660,  0.7538,
         1.4165,  0.1867,  0.1165,  0.9131, -0.0685, -0.0149, -0.5768,  2.5747],
       device='cuda:1')
Original likelihood: -144.15609741210938
Adjusted likelihood: -144.15609741210938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Solve time for step 1 14.474984942004085
Current ori: tensor([-0.0685, -0.0149, -0.5768], device='cuda:1')
Middle force: tensor([1.1684, 1.8005, 0.8496, 0.5908, 0.6539, 0.6406, 0.6014, 0.5300, 0.5664,
        0.5479, 0.5607, 0.5662], device='cuda:1')
Thumb force: tensor([0.8722, 0.5566, 0.5454, 1.5541, 0.5292, 0.5058, 0.8425, 0.4372, 0.5461,
        0.5056, 0.6840, 0.9083], device='cuda:1')
Index force: tensor([1.5468, 1.5992, 0.8858, 0.5005, 0.6329, 0.5151, 0.4567, 0.5680, 0.5239,
        0.5086, 0.5503, 0.5136], device='cuda:1')
Storing NORMAL transition: reward=-0.0485 (scaled=-0.0485), steps=1
Reward stats updated: mean 0.0156 -> 0.0154, std: 0.0901
Collected 347 transitions for RL
SAC Update 1/5: Actor Loss=-0.0129, Q1 Loss=1.5264, Q2 Loss=1.5264, Entropy=0.6916, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0238
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.7899, Q2 Loss=0.7899, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5426
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=1.4271, Q2 Loss=1.4271, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5380
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=0.6920, Q2 Loss=0.6920, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1123
SAC Update 5/5: Actor Loss=-0.0133, Q1 Loss=1.6991, Q2 Loss=1.6991, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3607

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.8%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.05s (19.8%)
Actor update: 0.10s (42.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009922
Q1 loss: 1.226899
Q2 loss: 1.226899
Current threshold: -149.5260
Global Scale Offset: 2365.6431
Reward stats: mean=0.0154, std=0.0901, count=347
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.2269, Q2 Loss: 1.2269, Entropy: 0.6926, Mean TD Error: 1.1155, Threshold: -149.5260
tensor([-0.0460,  0.6079,  0.5675,  0.3671, -0.0931,  0.7285,  0.8346,  0.8261,
         1.3363,  0.1706,  0.1585,  0.8849, -0.1026, -0.0521, -0.5353,  2.8941],
       device='cuda:1')
Original likelihood: -224.89532470703125
Adjusted likelihood: -224.89532470703125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4873)
State is out of distribution
Projection step: 0, Loss: 225.291015625
Projection step: 1, Loss: 216.90414428710938
Projection step: 2, Loss: 209.03330993652344
Projection step: 3, Loss: 207.65086364746094
Projection step: 4, Loss: 196.5946502685547
Projection step: 5, Loss: 195.18978881835938
Projection step: 6, Loss: 190.1521453857422
Projection step: 7, Loss: 183.3663330078125
Projection step: 8, Loss: 179.42605590820312
Projection step: 9, Loss: 176.88670349121094
Projection step: 10, Loss: 174.98785400390625
Projection step: 11, Loss: 173.0281219482422
Projection step: 12, Loss: 168.06597900390625
Projection step: 13, Loss: 167.2340087890625
Projection step: 14, Loss: 164.4269561767578
Projection step: 15, Loss: 161.23960876464844
Projection step: 16, Loss: 158.92933654785156
Projection step: 17, Loss: 158.06201171875
Projection step: 18, Loss: 153.0341796875
Projection step: 19, Loss: 154.3783416748047
Projection step: 20, Loss: 151.74957275390625
Projection step: 21, Loss: 150.7801971435547
Projection step: 22, Loss: 148.53733825683594
Projection step: 23, Loss: 145.506103515625
Projection step: 24, Loss: 143.0631103515625
Final likelihood: tensor([-147.0762, -137.8581, -141.6742, -139.0822, -135.1364, -141.0308,
        -145.6219, -145.2205, -144.1422, -150.5146, -143.6456, -142.5280,
        -146.5562, -148.8920, -145.4984, -139.3519])
Final projection likelihood: -143.3643
1 mode projection succeeded
New goal: tensor([ 0.0117,  0.5320,  0.5646,  0.4518, -0.0399,  0.6244,  0.7590,  0.9430,
         1.3770,  0.2296,  0.1461,  0.8589, -0.0978, -0.0364, -0.3862],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 22
Loaded trajectory sampler
Current yaw: tensor([-0.0014,  0.0146, -0.0302], device='cuda:1')
Current yaw: tensor([-0.0014,  0.0146, -0.0302], device='cuda:1')
1 turn
Sampling time 3.645438171981368
tensor([ 0.1680,  0.6126,  0.5699,  0.6312, -0.1042,  0.5367,  0.8819,  0.8942,
         1.2220,  0.3316,  0.2673,  1.1272, -0.0014,  0.0146, -0.0302, -0.0457],
       device='cuda:1')
Original likelihood: -100.61927795410156
Adjusted likelihood: -100.61927795410156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5082)
Solve time for step 1 14.125054831965826
Current ori: tensor([-0.0014,  0.0146, -0.0302], device='cuda:1')
Middle force: tensor([0.5329, 0.6199, 0.5439, 0.5065, 0.7814, 1.1320, 0.5809, 0.5609, 0.5033,
        0.5173, 0.5902, 0.4910], device='cuda:1')
Thumb force: tensor([0.8640, 0.7714, 1.6379, 2.5813, 0.8863, 1.7882, 0.6248, 0.6841, 0.5756,
        1.7642, 0.6031, 0.5474], device='cuda:1')
Index force: tensor([0.5409, 0.8748, 0.6004, 0.6132, 0.5924, 0.5953, 0.5940, 0.5254, 0.4940,
        0.8325, 0.7091, 0.7412], device='cuda:1')
Storing NORMAL transition: reward=0.0224 (scaled=0.0224), steps=1
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0900
Collected 348 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.6931, Q2 Loss=1.6931, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4905
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=1.6966, Q2 Loss=1.6966, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6486
SAC Update 3/5: Actor Loss=-0.0124, Q1 Loss=1.3055, Q2 Loss=1.3055, Entropy=0.6923, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5543
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.2442, Q2 Loss=1.2442, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9661
SAC Update 5/5: Actor Loss=-0.0082, Q1 Loss=0.8373, Q2 Loss=0.8373, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7015

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.9%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (42.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010222
Q1 loss: 1.355352
Q2 loss: 1.355352
Current threshold: -149.5258
Global Scale Offset: 2393.6813
Reward stats: mean=0.0154, std=0.0900, count=348
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.3554, Q2 Loss: 1.3554, Entropy: 0.6929, Mean TD Error: 1.2722, Threshold: -149.5258
tensor([ 0.1555,  0.6323,  0.5416,  0.5905, -0.1396,  0.3538,  0.9814,  0.9592,
         1.3412,  0.3360,  0.2002,  1.0962, -0.0053,  0.0484, -0.0547, -0.7675],
       device='cuda:1')
Original likelihood: -201.388916015625
Adjusted likelihood: -201.388916015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4914)
Solve time for step 2 5.446542511985172
Current ori: tensor([-0.0053,  0.0484, -0.0547], device='cuda:1')
Middle force: tensor([0.5977, 0.5420, 0.5059, 0.7651, 1.1068, 0.5705, 0.5503, 0.5026, 0.5109,
        0.5759, 0.5017], device='cuda:1')
Thumb force: tensor([0.8167, 1.6064, 2.5368, 0.8799, 1.7654, 0.6518, 0.7240, 0.5816, 1.7695,
        0.6384, 0.5367], device='cuda:1')
Index force: tensor([0.8229, 0.5975, 0.6016, 0.5915, 0.5887, 0.5765, 0.5174, 0.5040, 0.8241,
        0.6701, 0.7979], device='cuda:1')
Storing NORMAL transition: reward=0.1063 (scaled=0.1063), steps=1
Reward stats updated: mean 0.0154 -> 0.0156, std: 0.0900
Collected 349 transitions for RL
SAC Update 1/5: Actor Loss=-0.0105, Q1 Loss=1.0113, Q2 Loss=1.0113, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1916
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8507, Q2 Loss=0.8507, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0845
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.2773, Q2 Loss=1.2773, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9436
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=0.9249, Q2 Loss=0.9249, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5828
SAC Update 5/5: Actor Loss=-0.0115, Q1 Loss=1.1428, Q2 Loss=1.1428, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4485

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010251
Q1 loss: 1.041426
Q2 loss: 1.041426
Current threshold: -149.5257
Global Scale Offset: 2416.2673
Reward stats: mean=0.0156, std=0.0900, count=349
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.0414, Q2 Loss: 1.0414, Entropy: 0.6931, Mean TD Error: 0.6502, Threshold: -149.5257
tensor([ 0.2288,  0.5707,  0.5098,  0.4569, -0.1428,  0.3468,  1.0341,  1.0457,
         1.4085,  0.3005,  0.1118,  1.1303, -0.0287,  0.0567, -0.1638, -0.8243],
       device='cuda:1')
Original likelihood: -194.768798828125
Adjusted likelihood: -194.768798828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4925)
Solve time for step 3 5.242644638987258
Current ori: tensor([-0.0287,  0.0567, -0.1638], device='cuda:1')
Middle force: tensor([1.1731, 0.5554, 1.1067, 0.6133, 0.5294, 0.5133, 0.5003, 0.5621, 0.5532,
        0.5020], device='cuda:1')
Thumb force: tensor([0.7466, 1.0031, 0.9877, 0.6503, 0.5197, 0.9927, 0.5301, 0.5732, 0.5911,
        0.6506], device='cuda:1')
Index force: tensor([0.5400, 0.5570, 0.7820, 0.5077, 0.9870, 0.8557, 0.5468, 0.5492, 0.5773,
        0.6224], device='cuda:1')
Storing NORMAL transition: reward=0.0365 (scaled=0.0365), steps=1
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0899
Collected 350 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=1.3010, Q2 Loss=1.3010, Entropy=0.6930, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3962
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=2.7324, Q2 Loss=2.7324, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3016
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=0.9772, Q2 Loss=0.9772, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7681
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.7798, Q2 Loss=0.7798, Entropy=0.6925, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2276
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.7944, Q2 Loss=0.7944, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6794

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (41.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008286
Q1 loss: 1.316982
Q2 loss: 1.316982
Current threshold: -149.5258
Global Scale Offset: 2436.1821
Reward stats: mean=0.0157, std=0.0899, count=350
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.3170, Q2 Loss: 1.3170, Entropy: 0.6929, Mean TD Error: 1.8746, Threshold: -149.5258
tensor([ 0.1660,  0.6266,  0.5716,  0.5704, -0.1126,  0.4097,  0.9623,  1.0784,
         1.3884,  0.3393,  0.0915,  1.1191, -0.0514,  0.0421, -0.2013, -0.6431],
       device='cuda:1')
Original likelihood: -168.15855407714844
Adjusted likelihood: -168.15855407714844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4970)
State is out of distribution
Projection step: 0, Loss: 156.00515747070312
Projection step: 1, Loss: 164.57778930664062
Projection step: 2, Loss: 147.85122680664062
Projection step: 3, Loss: 153.3768768310547
Projection step: 4, Loss: 140.96493530273438
Projection step: 5, Loss: 145.07669067382812
Projection step: 6, Loss: 145.92633056640625
Projection step: 7, Loss: 143.411376953125
Projection step: 8, Loss: 139.85888671875
Projection step: 9, Loss: 144.2571563720703
Projection step: 10, Loss: 142.28530883789062
Projection step: 11, Loss: 133.77078247070312
Projection step: 12, Loss: 129.9278564453125
Projection step: 13, Loss: 128.6428985595703
Projection step: 14, Loss: 119.32522583007812
Projection step: 15, Loss: 133.5099334716797
Projection step: 16, Loss: 124.0377197265625
Projection step: 17, Loss: 114.39169311523438
Projection step: 18, Loss: 122.22036743164062
Projection step: 19, Loss: 119.6141128540039
Projection step: 20, Loss: 115.67062377929688
Projection step: 21, Loss: 114.54359436035156
Projection step: 22, Loss: 116.41472625732422
Projection step: 23, Loss: 105.744140625
Projection step: 24, Loss: 107.46405029296875
Final likelihood: tensor([-119.4401,  -82.3054, -114.5399,  -81.8737, -112.0453,  -81.0196,
         -83.8026,  -81.4405, -116.8384, -104.5498,  -96.4810, -109.3555,
         -84.0505, -109.6738, -115.8525, -111.5189])
Final projection likelihood: -100.2992
1 mode projection succeeded
New goal: tensor([ 0.0947,  0.6286,  0.4589,  0.5997, -0.0734,  0.4405,  0.7915,  1.0139,
         1.3594,  0.3083,  0.0960,  1.1026, -0.0544,  0.0241, -1.9504],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -168.30722045898438
Adjusted likelihood: -168.30722045898438
Likelihood residual: 0.0
Original likelihood: -108.54409790039062
Adjusted likelihood: -108.54409790039062
Likelihood residual: 0.0
{'index': 108.54409790039062, 'thumb_middle': 168.30722045898438}
Current yaw: tensor([-0.0514,  0.0421, -0.2013], device='cuda:1')
2 index
tensor([ 0.1660,  0.6266,  0.5716,  0.5704, -0.1126,  0.4097,  0.9623,  1.0784,
         1.3884,  0.3393,  0.0915,  1.1191, -0.0514,  0.0421, -0.2013, -0.6431],
       device='cuda:1')
Solve time for step 1 10.64046301797498
Current ori: tensor([-0.0514,  0.0421, -0.2013], device='cuda:1')
Middle force: tensor([0.5498, 0.5794, 0.5453, 0.5192], device='cuda:1')
Thumb force: tensor([0.5378, 0.6116, 0.6219, 0.5432], device='cuda:1')
tensor([ 0.1425,  0.5749,  0.4336,  0.5697, -0.1038,  0.4664,  0.8903,  1.0758,
         1.3953,  0.3324,  0.0884,  1.0802, -0.0716,  0.0386, -0.1974, -0.0434],
       device='cuda:1')
Solve time for step 2 4.169043775007594
Current ori: tensor([-0.0716,  0.0386, -0.1974], device='cuda:1')
Middle force: tensor([0.5752, 0.5418, 0.5168], device='cuda:1')
Thumb force: tensor([0.6015, 0.6176, 0.5412], device='cuda:1')
tensor([ 0.1320,  0.5763,  0.4186,  0.5758, -0.0866,  0.4929,  0.8706,  1.0675,
         1.4053,  0.3089,  0.0611,  1.0844, -0.0807,  0.0278, -0.2003,  0.7344],
       device='cuda:1')
Solve time for step 3 4.045483549009077
Current ori: tensor([-0.0807,  0.0278, -0.2003], device='cuda:1')
Middle force: tensor([0.5479, 0.5001], device='cuda:1')
Thumb force: tensor([0.5229, 0.5368], device='cuda:1')
tensor([ 0.1300,  0.5779,  0.4152,  0.5762, -0.0914,  0.5068,  0.8654,  1.0672,
         1.4050,  0.3305,  0.0583,  1.0820, -0.1025,  0.0349, -0.2122,  1.5821],
       device='cuda:1')
Solve time for step 4 3.9145323719712906
Current ori: tensor([-0.1025,  0.0349, -0.2122], device='cuda:1')
Middle force: tensor([0.5573], device='cuda:1')
Thumb force: tensor([0.5580], device='cuda:1')
Storing RECOVERY transition: reward=0.0015 (scaled=0.0005), steps=3
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0898
Collected 351 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=1.1829, Q2 Loss=1.1829, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0075
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8495, Q2 Loss=0.8495, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9578
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.8240, Q2 Loss=0.8240, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9493
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=0.8493, Q2 Loss=0.8493, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2177
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.7472, Q2 Loss=0.7472, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7024

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008165
Q1 loss: 0.890548
Q2 loss: 0.890548
Current threshold: -149.5258
Global Scale Offset: 2450.4171
Reward stats: mean=0.0157, std=0.0898, count=351
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.8905, Q2 Loss: 0.8905, Entropy: 0.6930, Mean TD Error: 0.9669, Threshold: -149.5258
Original likelihood: -129.86129760742188
Adjusted likelihood: -129.86129760742188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5032)
State is out of distribution
Projection step: 0, Loss: 139.0029754638672
Projection step: 1, Loss: 135.55958557128906
Projection step: 2, Loss: 139.98245239257812
Projection step: 3, Loss: 128.43898010253906
Projection step: 4, Loss: 128.2581329345703
Projection step: 5, Loss: 120.42521667480469
Projection step: 6, Loss: 122.27271270751953
Projection step: 7, Loss: 122.65156555175781
Projection step: 8, Loss: 119.12477111816406
Projection step: 9, Loss: 117.00971221923828
Projection step: 10, Loss: 116.8741455078125
Projection step: 11, Loss: 117.89417266845703
Projection step: 12, Loss: 111.77345275878906
Projection step: 13, Loss: 113.78670501708984
Projection step: 14, Loss: 112.4066162109375
Projection step: 15, Loss: 112.77595520019531
Projection step: 16, Loss: 114.76751708984375
Projection step: 17, Loss: 108.37117004394531
Projection step: 18, Loss: 109.08903503417969
Projection step: 19, Loss: 106.60319519042969
Projection step: 20, Loss: 111.09504699707031
Projection step: 21, Loss: 107.84866333007812
Projection step: 22, Loss: 105.90037536621094
Projection step: 23, Loss: 106.43263244628906
Projection step: 24, Loss: 103.49250030517578
Final likelihood: tensor([-110.0011, -104.3357,  -93.2200, -108.3737, -103.4758, -100.0648,
        -109.1347, -100.9853, -106.3234, -100.8234, -107.6632, -102.7641,
         -97.9973,  -97.2050, -103.4660, -110.0467])
Final projection likelihood: -103.4925
1 mode projection succeeded
New goal: tensor([ 0.0750,  0.6492,  0.3922,  0.6050, -0.0550,  0.4756,  0.7907,  1.0005,
         1.3810,  0.3027,  0.1194,  0.9834, -0.0980,  0.0226, -0.7362],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -155.68153381347656
Adjusted likelihood: -155.68153381347656
Likelihood residual: 0.0
Original likelihood: -181.04556274414062
Adjusted likelihood: -181.04556274414062
Likelihood residual: 0.0
{'index': 181.04556274414062, 'thumb_middle': 155.68153381347656}
Current yaw: tensor([-0.1048,  0.0339, -0.2140], device='cuda:1')
3 thumb_middle
tensor([ 0.0783,  0.6351,  0.4521,  0.5953, -0.0896,  0.5112,  0.8630,  1.0617,
         1.4083,  0.3231,  0.0476,  1.0968, -0.1048,  0.0339, -0.2140,  1.8432],
       device='cuda:1')
Solve time for step 1 8.829887388972566
Current ori: tensor([-0.1048,  0.0339, -0.2140], device='cuda:1')
Index force: tensor([0.5735, 0.5000, 0.4998, 0.5970], device='cuda:1')
tensor([ 0.0633,  0.6278,  0.4076,  0.6772, -0.1521,  0.4527,  0.7767,  1.0000,
         1.3580,  0.2942,  0.0551,  0.9846, -0.0929,  0.0552, -0.2140,  1.7406],
       device='cuda:1')
Solve time for step 2 3.548660997999832
Current ori: tensor([-0.0929,  0.0552, -0.2140], device='cuda:1')
Index force: tensor([0.5000, 0.5001, 0.5940], device='cuda:1')
tensor([ 0.0598,  0.6217,  0.4050,  0.6876, -0.1709,  0.4429,  0.7615,  0.9873,
         1.3713,  0.2919,  0.0660,  0.9708, -0.0918,  0.0775, -0.2140,  1.5016],
       device='cuda:1')
Solve time for step 3 3.3872340279631317
Current ori: tensor([-0.0918,  0.0775, -0.2140], device='cuda:1')
Index force: tensor([0.5001, 0.5881], device='cuda:1')
tensor([ 0.0547,  0.6336,  0.4034,  0.6518, -0.1878,  0.4324,  0.7529,  0.9842,
         1.3797,  0.2951,  0.0770,  0.9725, -0.0990,  0.1023, -0.2140,  1.4068],
       device='cuda:1')
Solve time for step 4 3.4378587739774957
Current ori: tensor([-0.0990,  0.1023, -0.2140], device='cuda:1')
Index force: tensor([0.5766], device='cuda:1')
Storing RECOVERY transition: reward=-0.0492 (scaled=-0.0164), steps=3
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0896
Collected 352 transitions for RL
SAC Update 1/5: Actor Loss=-0.0096, Q1 Loss=1.9294, Q2 Loss=1.9294, Entropy=0.6928, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6193
SAC Update 2/5: Actor Loss=-0.0070, Q1 Loss=0.6956, Q2 Loss=0.6956, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7891
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=4.0488, Q2 Loss=4.0488, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7339
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.7529, Q2 Loss=0.7529, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5192
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.7930, Q2 Loss=0.7930, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0927

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (21.1%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (17.6%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008459
Q1 loss: 1.643955
Q2 loss: 1.643955
Current threshold: -149.5258
Global Scale Offset: 2466.6207
Reward stats: mean=0.0156, std=0.0896, count=352
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 1.6440, Q2 Loss: 1.6440, Entropy: 0.6930, Mean TD Error: 1.7508, Threshold: -149.5258
Original likelihood: -607.1707763671875
Adjusted likelihood: -607.1707763671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4264)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 23
Loaded trajectory sampler
Current yaw: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
Current yaw: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
1 turn
Sampling time 3.831402424024418
tensor([ 0.1271,  0.5515,  0.6266,  0.6044, -0.1170,  0.5489,  0.8790,  0.9065,
         1.2371,  0.2984,  0.2335,  1.1962, -0.0024,  0.0146, -0.0302, -0.0180],
       device='cuda:1')
Original likelihood: -93.14624786376953
Adjusted likelihood: -93.14624786376953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5091)
State is out of distribution
Projection step: 0, Loss: 94.74159240722656
Final likelihood: tensor([ -85.9128,  -94.0783,  -97.1878, -109.9791,  -99.9990,  -56.6789,
         -92.5898,  -96.4146,  -98.6553,  -93.0064, -136.2148,  -86.1502,
        -114.0231,  -80.8974,  -77.4027,  -96.6754])
Final projection likelihood: -94.7416
1 mode projection succeeded
New goal: tensor([ 0.1271,  0.5515,  0.6266,  0.6044, -0.1170,  0.5489,  0.8790,  0.9065,
         1.2371,  0.2984,  0.2335,  1.1962, -0.0024,  0.0146, -0.0302],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
2 turn
Sampling time 3.573237888980657
tensor([ 0.1271,  0.5515,  0.6266,  0.6044, -0.1170,  0.5489,  0.8790,  0.9065,
         1.2371,  0.2984,  0.2335,  1.1962, -0.0024,  0.0146, -0.0302, -0.0180],
       device='cuda:1')
Original likelihood: -101.84890747070312
Adjusted likelihood: -101.84890747070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5077)
Solve time for step 1 13.823662948969286
Current ori: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
Middle force: tensor([0.5597, 0.6022, 0.5036, 2.2400, 1.1787, 0.5035, 0.6511, 0.5093, 0.5450,
        0.6059, 0.6121, 0.5493], device='cuda:1')
Thumb force: tensor([0.5844, 0.7284, 1.3432, 1.7439, 1.2092, 0.5824, 0.9209, 0.6200, 1.2547,
        0.5750, 0.5992, 0.6471], device='cuda:1')
Index force: tensor([0.5789, 0.5391, 0.5607, 1.1671, 0.5118, 0.5523, 0.9570, 0.8019, 0.5451,
        0.5181, 0.6203, 0.6596], device='cuda:1')
Storing NORMAL transition: reward=0.0416 (scaled=0.0416), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0895
Collected 353 transitions for RL
SAC Update 1/5: Actor Loss=-0.0115, Q1 Loss=2.0696, Q2 Loss=2.0696, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2806
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=2.9146, Q2 Loss=2.9146, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8834
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=0.8885, Q2 Loss=0.8885, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4233
SAC Update 4/5: Actor Loss=-0.0106, Q1 Loss=2.7909, Q2 Loss=2.7909, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2907
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.9011, Q2 Loss=0.9011, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4432

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (39.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010357
Q1 loss: 1.912960
Q2 loss: 1.912960
Current threshold: -149.5260
Global Scale Offset: 2481.7575
Reward stats: mean=0.0156, std=0.0895, count=353
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.9130, Q2 Loss: 1.9130, Entropy: 0.6931, Mean TD Error: 2.0642, Threshold: -149.5260
tensor([ 0.1273,  0.5755,  0.6191,  0.5558, -0.1249,  0.5519,  0.8802,  0.9191,
         1.2819,  0.2619,  0.2281,  1.1227, -0.0118,  0.0093, -0.0718,  0.0798],
       device='cuda:1')
Original likelihood: -117.24201202392578
Adjusted likelihood: -117.24201202392578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5052)
State is out of distribution
Projection step: 0, Loss: 117.92816162109375
Projection step: 1, Loss: 108.68006896972656
Projection step: 2, Loss: 89.85838317871094
Final likelihood: tensor([ -84.0345,  -91.9153,  -95.5693, -100.3495,  -68.6714, -109.0564,
         -74.7174, -104.9364, -100.0601,  -62.0668, -103.4403,  -59.2482,
         -63.8123, -109.3580, -130.7876,  -79.7106])
Final projection likelihood: -89.8584
1 mode projection succeeded
New goal: tensor([ 0.1204,  0.5689,  0.6165,  0.5559, -0.1114,  0.5543,  0.8924,  0.9097,
         1.2857,  0.2777,  0.2247,  1.1177, -0.0113,  0.0104, -0.1394],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -100.93464660644531
Adjusted likelihood: -100.93464660644531
Likelihood residual: 0.0
Original likelihood: -100.14093780517578
Adjusted likelihood: -100.14093780517578
Likelihood residual: 0.0
{'index': 100.14093780517578, 'thumb_middle': 100.93464660644531}
Current yaw: tensor([-0.0118,  0.0093, -0.0718], device='cuda:1')
3 index
tensor([ 0.1273,  0.5755,  0.6191,  0.5558, -0.1249,  0.5519,  0.8802,  0.9191,
         1.2819,  0.2619,  0.2281,  1.1227, -0.0118,  0.0093, -0.0718,  0.0798],
       device='cuda:1')
Solve time for step 1 10.499853597022593
Current ori: tensor([-0.0118,  0.0093, -0.0718], device='cuda:1')
Middle force: tensor([0.5893, 0.5265, 0.5616, 0.6136], device='cuda:1')
Thumb force: tensor([0.5518, 0.6349, 0.5645, 0.5652], device='cuda:1')
tensor([ 0.1722,  0.5148,  0.5665,  0.5320, -0.1215,  0.5463,  0.8922,  0.9160,
         1.2865,  0.2572,  0.2260,  1.1116, -0.0132,  0.0070, -0.0967,  0.3244],
       device='cuda:1')
Solve time for step 2 4.2807910540141165
Current ori: tensor([-0.0132,  0.0070, -0.0967], device='cuda:1')
Middle force: tensor([0.5457, 0.5295, 0.5606], device='cuda:1')
Thumb force: tensor([0.6082, 0.5426, 0.5684], device='cuda:1')
tensor([ 0.1738,  0.5150,  0.5656,  0.5312, -0.1161,  0.5455,  0.8971,  0.9197,
         1.2864,  0.2539,  0.2148,  1.1235, -0.0121,  0.0028, -0.1039,  0.5329],
       device='cuda:1')
Solve time for step 3 4.218352705996949
Current ori: tensor([-0.0121,  0.0028, -0.1039], device='cuda:1')
Middle force: tensor([0.5340, 0.5387], device='cuda:1')
Thumb force: tensor([0.5400, 0.5826], device='cuda:1')
tensor([ 0.1712,  0.5129,  0.5664,  0.5278, -0.1192,  0.5548,  0.8889,  0.9080,
         1.2925,  0.2476,  0.2166,  1.1143, -0.0158,  0.0047, -0.0948,  0.7117],
       device='cuda:1')
Solve time for step 4 4.029481083969586
Current ori: tensor([-0.0158,  0.0047, -0.0948], device='cuda:1')
Middle force: tensor([0.5011], device='cuda:1')
Thumb force: tensor([0.5405], device='cuda:1')
Storing RECOVERY transition: reward=0.0261 (scaled=0.0261), steps=1
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0894
Collected 354 transitions for RL
SAC Update 1/5: Actor Loss=-0.0139, Q1 Loss=2.7347, Q2 Loss=2.7347, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5174
SAC Update 2/5: Actor Loss=-0.0115, Q1 Loss=1.0979, Q2 Loss=1.0979, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2121
SAC Update 3/5: Actor Loss=-0.0122, Q1 Loss=1.4464, Q2 Loss=1.4464, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1610
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=1.5078, Q2 Loss=1.5078, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2654
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=3.0008, Q2 Loss=3.0008, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8383

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010916
Q1 loss: 1.957529
Q2 loss: 1.957529
Current threshold: -149.5261
Global Scale Offset: 2493.4800
Reward stats: mean=0.0157, std=0.0894, count=354
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.9575, Q2 Loss: 1.9575, Entropy: 0.6931, Mean TD Error: 2.1988, Threshold: -149.5261
Original likelihood: -123.13583374023438
Adjusted likelihood: -123.13583374023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5042)
State is out of distribution
Projection step: 0, Loss: 102.63218688964844
Final likelihood: tensor([-132.8407,  -83.2345, -135.6405, -129.5135,  -92.2222,  -78.8163,
        -114.5261,  -83.2453,  -88.6952, -131.7431, -127.0520,  -80.8210,
         -82.5964, -116.8271,  -83.4600,  -80.8811])
Final projection likelihood: -102.6322
1 mode projection succeeded
New goal: tensor([ 0.1177,  0.5760,  0.6112,  0.5519, -0.1176,  0.5581,  0.8860,  0.9054,
         1.2854,  0.2603,  0.2176,  1.1135, -0.0176,  0.0040, -0.0980],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0176,  0.0040, -0.0980], device='cuda:1')
4 turn
Sampling time 3.767994062975049
tensor([ 0.1177,  0.5760,  0.6112,  0.5519, -0.1176,  0.5581,  0.8860,  0.9054,
         1.2854,  0.2603,  0.2176,  1.1135, -0.0176,  0.0040, -0.0980,  0.7713],
       device='cuda:1')
Original likelihood: -102.43898010253906
Adjusted likelihood: -102.43898010253906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5075)
State is out of distribution
Projection step: 0, Loss: 105.78633117675781
Projection step: 1, Loss: 92.92623901367188
Final likelihood: tensor([-108.4835,  -71.4435,  -78.8676,  -77.4322,  -80.8278, -135.2907,
         -82.4234,  -74.7027, -118.8316,  -78.8108, -107.9496, -107.8359,
        -131.5112,  -81.4423,  -76.5823,  -74.3846])
Final projection likelihood: -92.9262
1 mode projection succeeded
New goal: tensor([ 0.1157,  0.5735,  0.6090,  0.5464, -0.1103,  0.5597,  0.8878,  0.9018,
         1.2872,  0.2670,  0.2150,  1.1127, -0.0175,  0.0048, -0.0902],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -110.31867218017578
Adjusted likelihood: -110.31867218017578
Likelihood residual: 0.0
Original likelihood: -123.48615264892578
Adjusted likelihood: -123.48615264892578
Likelihood residual: 0.0
{'index': 123.48615264892578, 'thumb_middle': 110.31867218017578}
Current yaw: tensor([-0.0176,  0.0040, -0.0980], device='cuda:1')
5 thumb_middle
tensor([ 0.1177,  0.5760,  0.6112,  0.5519, -0.1176,  0.5581,  0.8860,  0.9054,
         1.2854,  0.2603,  0.2176,  1.1135, -0.0176,  0.0040, -0.0980,  0.7713],
       device='cuda:1')
Solve time for step 1 8.665554900013376
Current ori: tensor([-0.0176,  0.0040, -0.0980], device='cuda:1')
Index force: tensor([0.5645, 0.5801, 0.5924, 0.5861], device='cuda:1')
tensor([ 0.1073,  0.5817,  0.5944,  0.5495, -0.2116,  0.5331,  0.8533,  0.8827,
         1.2483,  0.2375,  0.1460,  1.0751, -0.0192,  0.0100, -0.0980,  0.7547],
       device='cuda:1')
Solve time for step 2 3.570325380016584
Current ori: tensor([-0.0192,  0.0100, -0.0980], device='cuda:1')
Index force: tensor([0.5681, 0.5808, 0.5747], device='cuda:1')
tensor([ 0.1101,  0.5845,  0.5978,  0.5410, -0.2119,  0.5342,  0.8487,  0.8863,
         1.2491,  0.2603,  0.1278,  1.0791, -0.0205,  0.0081, -0.0980,  0.7555],
       device='cuda:1')
Solve time for step 3 3.5350791919627227
Current ori: tensor([-0.0205,  0.0081, -0.0980], device='cuda:1')
Index force: tensor([0.5696, 0.5648], device='cuda:1')
tensor([ 0.1096,  0.5824,  0.5978,  0.5453, -0.2143,  0.5442,  0.8481,  0.8608,
         1.2534,  0.2465,  0.1320,  1.0718, -0.0197,  0.0085, -0.0980,  0.7565],
       device='cuda:1')
Solve time for step 4 3.4321625889861025
Current ori: tensor([-0.0197,  0.0085, -0.0980], device='cuda:1')
Index force: tensor([0.5490], device='cuda:1')
Storing RECOVERY transition: reward=0.0117 (scaled=0.0117), steps=0
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0893
Collected 355 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=1.0586, Q2 Loss=1.0586, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6543
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.1299, Q2 Loss=1.1299, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1437
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.7791, Q2 Loss=0.7791, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4366
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=1.0985, Q2 Loss=1.0985, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5048
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.9059, Q2 Loss=0.9059, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9921

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.0%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (19.0%)
Actor update: 0.10s (43.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009076
Q1 loss: 0.994402
Q2 loss: 0.994402
Current threshold: -149.5260
Global Scale Offset: 2507.6928
Reward stats: mean=0.0157, std=0.0893, count=355
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9944, Q2 Loss: 0.9944, Entropy: 0.6930, Mean TD Error: 0.9463, Threshold: -149.5260
Original likelihood: -148.00534057617188
Adjusted likelihood: -148.00534057617188
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5002)
State is out of distribution
Projection step: 0, Loss: 127.638427734375
Projection step: 1, Loss: 115.3197250366211
Projection step: 2, Loss: 116.87320709228516
Projection step: 3, Loss: 112.39835357666016
Projection step: 4, Loss: 111.01741027832031
Projection step: 5, Loss: 104.0376968383789
Final likelihood: tensor([ -93.1474,  -90.5811, -131.7959,  -92.8322, -105.0207, -108.5312,
        -123.7487, -114.7041,  -82.0324,  -78.6387,  -92.1006, -113.0627,
         -91.0111, -113.7391, -137.5943,  -96.0628])
Final projection likelihood: -104.0377
1 mode projection succeeded
New goal: tensor([ 0.1016,  0.5583,  0.6164,  0.5422, -0.1217,  0.5798,  0.9009,  0.8662,
         1.3138,  0.2805,  0.1972,  1.1106, -0.0156,  0.0145, -0.1328],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -121.84773254394531
Adjusted likelihood: -121.84773254394531
Likelihood residual: 0.0
Original likelihood: -120.60367584228516
Adjusted likelihood: -120.60367584228516
Likelihood residual: 0.0
{'index': 120.60367584228516, 'thumb_middle': 121.84773254394531}
Current yaw: tensor([-0.0161,  0.0126, -0.1098], device='cuda:1')
6 index
tensor([ 0.1033,  0.5657,  0.6167,  0.5405, -0.1588,  0.5792,  0.8972,  0.9045,
         1.3206,  0.2708,  0.1855,  1.1106, -0.0161,  0.0126, -0.1098,  0.7530],
       device='cuda:1')
Solve time for step 1 10.614335391030181
Current ori: tensor([-0.0161,  0.0126, -0.1098], device='cuda:1')
Middle force: tensor([0.5745, 0.5182, 0.5705, 0.5114], device='cuda:1')
Thumb force: tensor([0.5499, 0.6419, 0.6015, 0.6041], device='cuda:1')
tensor([ 0.1530,  0.5031,  0.5674,  0.5181, -0.1706,  0.5890,  0.9168,  0.8873,
         1.3217,  0.2797,  0.1772,  1.0970, -0.0301,  0.0117, -0.1225,  1.3696],
       device='cuda:1')
Solve time for step 2 4.432896715006791
Current ori: tensor([-0.0301,  0.0117, -0.1225], device='cuda:1')
Middle force: tensor([0.5737, 0.5059, 0.5165], device='cuda:1')
Thumb force: tensor([0.5369, 0.5451, 0.6021], device='cuda:1')
tensor([ 0.1533,  0.5020,  0.5654,  0.5175, -0.1757,  0.5889,  0.9151,  0.8810,
         1.3301,  0.2704,  0.1811,  1.0909, -0.0309,  0.0160, -0.1160,  1.7701],
       device='cuda:1')
Solve time for step 3 4.227820985019207
Current ori: tensor([-0.0309,  0.0160, -0.1160], device='cuda:1')
Middle force: tensor([0.5629, 0.5077], device='cuda:1')
Thumb force: tensor([0.5845, 0.5922], device='cuda:1')
tensor([ 0.1518,  0.5004,  0.5644,  0.5189, -0.1669,  0.5910,  0.9186,  0.8831,
         1.3293,  0.2670,  0.1660,  1.1021, -0.0316,  0.0092, -0.1271,  1.9955],
       device='cuda:1')
Solve time for step 4 3.8397526619955897
Current ori: tensor([-0.0316,  0.0092, -0.1271], device='cuda:1')
Middle force: tensor([0.5008], device='cuda:1')
Thumb force: tensor([0.5908], device='cuda:1')
Storing RECOVERY transition: reward=0.0276 (scaled=0.0276), steps=0
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0892
Collected 356 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=3.2278, Q2 Loss=3.2278, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8158
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=0.8304, Q2 Loss=0.8304, Entropy=0.6907, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7644
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.2047, Q2 Loss=1.2047, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0565
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=1.0311, Q2 Loss=1.0311, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8573
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8034, Q2 Loss=0.8034, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4276

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.1%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (42.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008946
Q1 loss: 1.419481
Q2 loss: 1.419481
Current threshold: -149.5257
Global Scale Offset: 2510.4069
Reward stats: mean=0.0157, std=0.0892, count=356
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.4195, Q2 Loss: 1.4195, Entropy: 0.6926, Mean TD Error: 1.7843, Threshold: -149.5257
Original likelihood: -137.77963256835938
Adjusted likelihood: -137.77963256835938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5019)
State is out of distribution
Projection step: 0, Loss: 122.08638000488281
Projection step: 1, Loss: 113.81489562988281
Projection step: 2, Loss: 117.76748657226562
Projection step: 3, Loss: 117.202880859375
Projection step: 4, Loss: 116.6628646850586
Projection step: 5, Loss: 118.99313354492188
Projection step: 6, Loss: 110.46080017089844
Projection step: 7, Loss: 108.68771362304688
Projection step: 8, Loss: 110.63284301757812
Projection step: 9, Loss: 100.25163269042969
Final likelihood: tensor([-108.4766,  -87.9241,  -88.6462, -104.1674, -104.4482,  -93.5622,
         -96.6514,  -98.1418,  -89.5007,  -99.9454,  -95.1371, -156.9601,
        -102.9318,  -91.7427,  -97.4940,  -88.2964])
Final projection likelihood: -100.2516
1 mode projection succeeded
New goal: tensor([ 0.0892,  0.5565,  0.5836,  0.5855, -0.1101,  0.5867,  0.9157,  0.8302,
         1.3310,  0.2711,  0.1746,  1.1232, -0.0333,  0.0107, -0.0519],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -119.06461334228516
Adjusted likelihood: -119.06461334228516
Likelihood residual: 0.0
Original likelihood: -122.26280212402344
Adjusted likelihood: -122.26280212402344
Likelihood residual: 0.0
{'index': 122.26280212402344, 'thumb_middle': 119.06461334228516}
Current yaw: tensor([-0.0337,  0.0087, -0.1264], device='cuda:1')
7 thumb_middle
tensor([ 0.0985,  0.5674,  0.6100,  0.5391, -0.1656,  0.5951,  0.9154,  0.8784,
         1.3274,  0.2718,  0.1617,  1.1084, -0.0337,  0.0087, -0.1264,  2.0231],
       device='cuda:1')
Solve time for step 1 8.845170939981472
Current ori: tensor([-0.0337,  0.0087, -0.1264], device='cuda:1')
Index force: tensor([0.5824, 0.5028, 0.5983, 0.5970], device='cuda:1')
tensor([ 1.1358e-01,  5.3827e-01,  6.1162e-01,  6.4349e-01, -2.1179e-01,
         5.4949e-01,  8.7671e-01,  8.1550e-01,  1.2791e+00,  2.5997e-01,
         8.5201e-02,  1.0869e+00, -1.7832e-02,  1.4868e-03, -1.2648e-01,
         2.0811e+00], device='cuda:1')
Solve time for step 2 3.7199446799932048
Current ori: tensor([-0.0178,  0.0015, -0.1265], device='cuda:1')
Index force: tensor([0.5026, 0.5917, 0.5920], device='cuda:1')
tensor([ 0.1108,  0.5489,  0.6034,  0.6247, -0.2196,  0.5529,  0.8754,  0.8177,
         1.2911,  0.2483,  0.0738,  1.0821, -0.0220,  0.0028, -0.1265,  2.0679],
       device='cuda:1')
Solve time for step 3 3.502187645994127
Current ori: tensor([-0.0220,  0.0028, -0.1265], device='cuda:1')
Index force: tensor([0.5840, 0.5870], device='cuda:1')
tensor([ 0.0910,  0.5715,  0.5782,  0.5763, -0.2343,  0.5676,  0.8735,  0.7989,
         1.2788,  0.2511,  0.0948,  1.0806, -0.0317,  0.0138, -0.1265,  2.0190],
       device='cuda:1')
Solve time for step 4 3.5068012929987162
Current ori: tensor([-0.0317,  0.0138, -0.1265], device='cuda:1')
Index force: tensor([0.5733], device='cuda:1')
Storing RECOVERY transition: reward=0.0370 (scaled=0.0370), steps=0
Reward stats updated: mean 0.0157 -> 0.0158, std: 0.0890
Collected 357 transitions for RL
SAC Update 1/5: Actor Loss=-0.0128, Q1 Loss=1.2491, Q2 Loss=1.2491, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1384
SAC Update 2/5: Actor Loss=-0.0096, Q1 Loss=0.9669, Q2 Loss=0.9669, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4068
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=2.6696, Q2 Loss=2.6696, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4787
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=1.5699, Q2 Loss=1.5699, Entropy=0.6917, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7544
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.8298, Q2 Loss=0.8298, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6976

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.0%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.0%)
Actor update: 0.12s (42.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010111
Q1 loss: 1.457069
Q2 loss: 1.457069
Current threshold: -149.5257
Global Scale Offset: 2523.2388
Reward stats: mean=0.0158, std=0.0890, count=357
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.4571, Q2 Loss: 1.4571, Entropy: 0.6926, Mean TD Error: 1.2952, Threshold: -149.5257
Original likelihood: -125.1965103149414
Adjusted likelihood: -125.1965103149414
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5038)
Current yaw: tensor([-0.0266,  0.0050, -0.1354], device='cuda:1')
8 turn
Sampling time 3.594843962986488
tensor([ 0.1052,  0.5612,  0.5915,  0.6056, -0.1518,  0.6047,  0.9122,  0.8276,
         1.3449,  0.2688,  0.1309,  1.1198, -0.0266,  0.0050, -0.1354,  2.0631],
       device='cuda:1')
Original likelihood: -131.10260009765625
Adjusted likelihood: -131.10260009765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5029)
State is out of distribution
Projection step: 0, Loss: 117.53829193115234
Projection step: 1, Loss: 129.34817504882812
Projection step: 2, Loss: 124.37665557861328
Projection step: 3, Loss: 119.14253997802734
Projection step: 4, Loss: 112.95948791503906
Projection step: 5, Loss: 118.38333892822266
Projection step: 6, Loss: 114.45628356933594
Projection step: 7, Loss: 113.29315185546875
Projection step: 8, Loss: 108.9637451171875
Projection step: 9, Loss: 107.19097900390625
Projection step: 10, Loss: 105.80770874023438
Projection step: 11, Loss: 106.11795043945312
Projection step: 12, Loss: 96.53730773925781
Final likelihood: tensor([ -94.1379,  -98.2977,  -78.7277,  -91.4131, -118.0657,  -73.8222,
        -101.7144,  -91.8865,  -92.6208, -100.4315,  -93.3391, -123.9543,
        -102.2543,  -95.4630,  -89.3719,  -99.0967])
Final projection likelihood: -96.5373
1 mode projection succeeded
New goal: tensor([ 0.0966,  0.5496,  0.5920,  0.6228, -0.0856,  0.5971,  0.8839,  0.8044,
         1.3405,  0.2645,  0.1752,  1.0906, -0.0261,  0.0085,  0.2453],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -103.523193359375
Adjusted likelihood: -103.523193359375
Likelihood residual: 0.0
Original likelihood: -134.7401885986328
Adjusted likelihood: -134.7401885986328
Likelihood residual: 0.0
{'index': 134.7401885986328, 'thumb_middle': 103.523193359375}
Current yaw: tensor([-0.0266,  0.0050, -0.1354], device='cuda:1')
9 thumb_middle
tensor([ 0.1052,  0.5612,  0.5915,  0.6056, -0.1518,  0.6047,  0.9122,  0.8276,
         1.3449,  0.2688,  0.1309,  1.1198, -0.0266,  0.0050, -0.1354,  2.0631],
       device='cuda:1')
Solve time for step 1 9.109860441996716
Current ori: tensor([-0.0266,  0.0050, -0.1354], device='cuda:1')
Index force: tensor([0.5921, 0.5916, 0.6000, 0.5890], device='cuda:1')
tensor([ 0.1030,  0.5592,  0.5852,  0.6178, -0.2109,  0.5651,  0.8508,  0.7943,
         1.2840,  0.2387,  0.0985,  1.0767, -0.0252,  0.0072, -0.1354,  2.0607],
       device='cuda:1')
Solve time for step 2 3.6465101839858107
Current ori: tensor([-0.0252,  0.0072, -0.1354], device='cuda:1')
Index force: tensor([0.5850, 0.5947, 0.5837], device='cuda:1')
tensor([ 0.0949,  0.5547,  0.5871,  0.6114, -0.2107,  0.5738,  0.8309,  0.7891,
         1.3070,  0.2397,  0.0783,  1.0562, -0.0248,  0.0120, -0.1354,  2.0486],
       device='cuda:1')
Solve time for step 3 3.495032252976671
Current ori: tensor([-0.0248,  0.0120, -0.1354], device='cuda:1')
Index force: tensor([0.5857, 0.5768], device='cuda:1')
tensor([ 0.0986,  0.5635,  0.5742,  0.6204, -0.2040,  0.5697,  0.8362,  0.7795,
         1.2934,  0.2522,  0.0860,  1.0554, -0.0260,  0.0097, -0.1354,  2.0545],
       device='cuda:1')
Solve time for step 4 3.593404772982467
Current ori: tensor([-0.0260,  0.0097, -0.1354], device='cuda:1')
Index force: tensor([0.5611], device='cuda:1')
Storing RECOVERY transition: reward=0.0004 (scaled=0.0004), steps=0
Reward stats updated: mean 0.0158 -> 0.0157, std: 0.0889
Collected 358 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.8930, Q2 Loss=0.8930, Entropy=0.6927, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7301
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=0.7740, Q2 Loss=0.7740, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3862
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=0.9639, Q2 Loss=0.9639, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1364
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.7078, Q2 Loss=0.7078, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1773
SAC Update 5/5: Actor Loss=-0.0111, Q1 Loss=2.4762, Q2 Loss=2.4762, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9036

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (38.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008694
Q1 loss: 1.162980
Q2 loss: 1.162980
Current threshold: -149.5259
Global Scale Offset: 2543.7566
Reward stats: mean=0.0157, std=0.0889, count=358
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.1630, Q2 Loss: 1.1630, Entropy: 0.6930, Mean TD Error: 1.0667, Threshold: -149.5259
Original likelihood: -118.23231506347656
Adjusted likelihood: -118.23231506347656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5049)
Current yaw: tensor([-0.0184,  0.0119, -0.1356], device='cuda:1')
10 turn
Sampling time 3.620854073029477
tensor([ 0.0950,  0.5368,  0.5987,  0.6373, -0.1434,  0.6065,  0.8803,  0.7962,
         1.3619,  0.2621,  0.1443,  1.0838, -0.0184,  0.0119, -0.1356,  2.0644],
       device='cuda:1')
Original likelihood: -120.4068374633789
Adjusted likelihood: -120.4068374633789
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5046)
Solve time for step 1 14.066093590983655
Current ori: tensor([-0.0184,  0.0119, -0.1356], device='cuda:1')
Middle force: tensor([0.5817, 1.7466, 2.2111, 0.5572, 0.8028, 0.5744, 0.5101, 0.7887, 0.5001,
        0.5340, 0.5339, 0.4978], device='cuda:1')
Thumb force: tensor([0.9390, 1.6129, 0.7156, 0.6096, 0.5069, 1.1665, 1.3739, 1.5885, 0.5056,
        0.5538, 0.6157, 0.5787], device='cuda:1')
Index force: tensor([0.5578, 0.8336, 0.5933, 0.6329, 0.5321, 0.9218, 0.5296, 0.5733, 0.6128,
        0.5486, 0.6427, 0.7717], device='cuda:1')
Storing NORMAL transition: reward=0.0004 (scaled=0.0004), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0888
Collected 359 transitions for RL
SAC Update 1/5: Actor Loss=-0.0115, Q1 Loss=1.1579, Q2 Loss=1.1579, Entropy=0.6930, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5090
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.7702, Q2 Loss=0.7702, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3299
SAC Update 3/5: Actor Loss=-0.0123, Q1 Loss=1.3556, Q2 Loss=1.3556, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9318
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8543, Q2 Loss=0.8543, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3435
SAC Update 5/5: Actor Loss=-0.0109, Q1 Loss=1.2009, Q2 Loss=1.2009, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9051

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.4%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010037
Q1 loss: 1.067800
Q2 loss: 1.067800
Current threshold: -149.5260
Global Scale Offset: 2561.7418
Reward stats: mean=0.0157, std=0.0888, count=359
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.0678, Q2 Loss: 1.0678, Entropy: 0.6931, Mean TD Error: 0.8039, Threshold: -149.5260
tensor([ 1.4006e-01,  5.1605e-01,  6.0475e-01,  7.6911e-01, -2.9322e-01,
         5.8570e-01,  9.0355e-01,  8.6688e-01,  1.3020e+00,  3.5993e-01,
         1.3070e-01,  1.0439e+00, -1.2321e-03, -9.4170e-03, -1.3559e-01,
         2.1287e+00], device='cuda:1')
Original likelihood: -290.12054443359375
Adjusted likelihood: -290.12054443359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4781)
State is out of distribution
Projection step: 0, Loss: 285.0245056152344
Projection step: 1, Loss: 266.9201354980469
Projection step: 2, Loss: 257.3528747558594
Projection step: 3, Loss: 238.94598388671875
Projection step: 4, Loss: 221.71856689453125
Projection step: 5, Loss: 209.88543701171875
Projection step: 6, Loss: 200.74143981933594
Projection step: 7, Loss: 187.95562744140625
Projection step: 8, Loss: 175.35641479492188
Projection step: 9, Loss: 169.15386962890625
Projection step: 10, Loss: 169.20999145507812
Projection step: 11, Loss: 163.39785766601562
Projection step: 12, Loss: 154.33177185058594
Projection step: 13, Loss: 144.99566650390625
Projection step: 14, Loss: 137.1972198486328
Projection step: 15, Loss: 126.16514587402344
Projection step: 16, Loss: 119.45832824707031
Projection step: 17, Loss: 118.98211669921875
Projection step: 18, Loss: 119.35795593261719
Projection step: 19, Loss: 105.56189727783203
Projection step: 20, Loss: 102.9427261352539
Final likelihood: tensor([-103.8917, -107.9207, -106.5689,  -86.4597, -107.5234, -102.9628,
         -92.6690, -115.4170, -102.1293, -106.0742, -103.3429,  -85.6366,
         -99.1053, -107.2139, -118.1006, -102.0676])
Final projection likelihood: -102.9427
1 mode projection succeeded
New goal: tensor([ 0.1222,  0.4912,  0.6130,  0.7744, -0.1182,  0.6221,  0.9750,  0.8595,
         1.3216,  0.3178,  0.1763,  1.0104, -0.0014,  0.0056,  0.0405],
       device='cuda:1')
tensor([[0.0068]], device='cuda:1') tensor([[0.0152]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -132.42330932617188
Adjusted likelihood: -132.42330932617188
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 132.42330932617188}
Current yaw: tensor([-0.0012, -0.0094, -0.1356], device='cuda:1')
11 thumb_middle
tensor([ 1.4006e-01,  5.1605e-01,  6.0475e-01,  7.6911e-01, -2.9322e-01,
         5.8570e-01,  9.0355e-01,  8.6688e-01,  1.3020e+00,  3.5993e-01,
         1.3070e-01,  1.0439e+00, -1.2321e-03, -9.4170e-03, -1.3559e-01,
         2.1287e+00], device='cuda:1')
Solve time for step 1 8.793209732044488
Current ori: tensor([-0.0012, -0.0094, -0.1356], device='cuda:1')
Index force: tensor([0.5981, 0.5948, 0.5893, 0.5866], device='cuda:1')
tensor([ 1.3916e-01,  5.0832e-01,  6.1393e-01,  7.7025e-01, -2.5900e-01,
         5.7870e-01,  9.1688e-01,  8.3454e-01,  1.2885e+00,  3.3441e-01,
         1.0068e-01,  9.8894e-01,  7.0716e-04, -8.7127e-03, -1.3559e-01,
         2.1307e+00], device='cuda:1')
Solve time for step 2 3.678130927029997
Current ori: tensor([ 0.0007, -0.0087, -0.1356], device='cuda:1')
Index force: tensor([0.5832, 0.5802, 0.5789], device='cuda:1')
tensor([ 1.3253e-01,  5.0570e-01,  6.0652e-01,  7.8007e-01, -2.5030e-01,
         5.8269e-01,  9.0997e-01,  8.2142e-01,  1.2914e+00,  3.1176e-01,
         1.0815e-01,  9.7594e-01,  2.0300e-03, -4.8668e-03, -1.3559e-01,
         2.1270e+00], device='cuda:1')
Solve time for step 3 3.5793826549779624
Current ori: tensor([ 0.0020, -0.0049, -0.1356], device='cuda:1')
Index force: tensor([0.5718, 0.5729], device='cuda:1')
tensor([ 0.1207,  0.4879,  0.6149,  0.7881, -0.2586,  0.5734,  0.9152,  0.8222,
         1.3116,  0.2980,  0.0993,  0.9799,  0.0066,  0.0024, -0.1356,  2.1218],
       device='cuda:1')
Solve time for step 4 3.415732808993198
Current ori: tensor([ 0.0066,  0.0024, -0.1356], device='cuda:1')
Index force: tensor([0.5608], device='cuda:1')
Storing RECOVERY transition: reward=0.0159 (scaled=0.0159), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0887
Collected 360 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7337, Q2 Loss=0.7337, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2420
SAC Update 2/5: Actor Loss=-0.0114, Q1 Loss=1.1818, Q2 Loss=1.1818, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7212
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=1.6650, Q2 Loss=1.6650, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4956
SAC Update 4/5: Actor Loss=-0.0107, Q1 Loss=1.2964, Q2 Loss=1.2964, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2571
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8282, Q2 Loss=0.8282, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2451

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.7%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009371
Q1 loss: 1.141028
Q2 loss: 1.141028
Current threshold: -149.5261
Global Scale Offset: 2575.5408
Reward stats: mean=0.0157, std=0.0887, count=360
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.1410, Q2 Loss: 1.1410, Entropy: 0.6931, Mean TD Error: 1.1922, Threshold: -149.5261
Original likelihood: -178.684814453125
Adjusted likelihood: -178.684814453125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4955)
State is out of distribution
Projection step: 0, Loss: 171.33639526367188
Projection step: 1, Loss: 156.24002075195312
Projection step: 2, Loss: 159.18736267089844
Projection step: 3, Loss: 154.75375366210938
Projection step: 4, Loss: 144.299560546875
Projection step: 5, Loss: 132.15109252929688
Projection step: 6, Loss: 130.77593994140625
Projection step: 7, Loss: 128.47836303710938
Projection step: 8, Loss: 119.62735748291016
Projection step: 9, Loss: 119.4833984375
Projection step: 10, Loss: 118.95639038085938
Projection step: 11, Loss: 115.99847412109375
Projection step: 12, Loss: 109.28147888183594
Projection step: 13, Loss: 100.66764831542969
Final likelihood: tensor([-111.6318,  -91.3885,  -98.8027, -108.9251,  -91.4914, -107.1976,
         -96.9809,  -90.6890,  -91.6287,  -99.2049, -100.0208, -101.0453,
         -99.8053, -115.3601, -101.0927, -105.4174])
Final projection likelihood: -100.6676
1 mode projection succeeded
New goal: tensor([ 0.1337,  0.4831,  0.6168,  0.7931, -0.0956,  0.5943,  0.9717,  0.8674,
         1.3619,  0.3154,  0.1780,  1.0229,  0.0055,  0.0046, -0.0783],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -117.72016906738281
Adjusted likelihood: -117.72016906738281
Likelihood residual: 0.0
Original likelihood: -162.50086975097656
Adjusted likelihood: -162.50086975097656
Likelihood residual: 0.0
{'index': 162.50086975097656, 'thumb_middle': 117.72016906738281}
Current yaw: tensor([ 0.0091, -0.0053, -0.1516], device='cuda:1')
12 thumb_middle
tensor([ 0.1330,  0.4845,  0.6268,  0.7983, -0.1836,  0.6213,  0.9577,  0.8578,
         1.3631,  0.3078,  0.1548,  1.0181,  0.0091, -0.0053, -0.1516,  2.1544],
       device='cuda:1')
Solve time for step 1 9.12535178597318
Current ori: tensor([ 0.0091, -0.0053, -0.1516], device='cuda:1')
Index force: tensor([0.5808, 0.5928, 0.5928, 0.5856], device='cuda:1')
tensor([ 0.1285,  0.4942,  0.6165,  0.7834, -0.2273,  0.5492,  0.9144,  0.8310,
         1.3082,  0.3010,  0.0974,  0.9803,  0.0050, -0.0022, -0.1515,  2.1437],
       device='cuda:1')
Solve time for step 2 3.541638075024821
Current ori: tensor([ 0.0050, -0.0022, -0.1515], device='cuda:1')
Index force: tensor([0.5833, 0.5838, 0.5775], device='cuda:1')
tensor([ 0.1308,  0.5053,  0.6031,  0.7846, -0.2247,  0.5512,  0.9048,  0.8353,
         1.3217,  0.3102,  0.0797,  0.9698,  0.0025, -0.0038, -0.1515,  2.1430],
       device='cuda:1')
Solve time for step 3 3.46914978598943
Current ori: tensor([ 0.0025, -0.0038, -0.1515], device='cuda:1')
Index force: tensor([0.5708, 0.5661], device='cuda:1')
tensor([ 0.1350,  0.4797,  0.6333,  0.8021, -0.2275,  0.5517,  0.9131,  0.8293,
         1.3150,  0.2980,  0.0833,  0.9874,  0.0107, -0.0053, -0.1515,  2.1627],
       device='cuda:1')
Solve time for step 4 3.4342737440019846
Current ori: tensor([ 0.0107, -0.0053, -0.1515], device='cuda:1')
Index force: tensor([0.5428], device='cuda:1')
Storing RECOVERY transition: reward=0.0214 (scaled=0.0214), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0886
Collected 361 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=1.7413, Q2 Loss=1.7413, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4396
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.8591, Q2 Loss=0.8591, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6352
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.8843, Q2 Loss=0.8843, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0142
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=2.6398, Q2 Loss=2.6398, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9508
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=0.9380, Q2 Loss=0.9380, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3830

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.6%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.7%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009024
Q1 loss: 1.412492
Q2 loss: 1.412492
Current threshold: -149.5261
Global Scale Offset: 2587.9179
Reward stats: mean=0.0157, std=0.0886, count=361
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.4125, Q2 Loss: 1.4125, Entropy: 0.6931, Mean TD Error: 1.2846, Threshold: -149.5261
Original likelihood: -148.61480712890625
Adjusted likelihood: -148.61480712890625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5001)
State is out of distribution
Projection step: 0, Loss: 145.60867309570312
Projection step: 1, Loss: 139.03060913085938
Projection step: 2, Loss: 137.90542602539062
Projection step: 3, Loss: 124.20723724365234
Projection step: 4, Loss: 117.9759750366211
Projection step: 5, Loss: 109.7808837890625
Projection step: 6, Loss: 106.4384765625
Projection step: 7, Loss: 105.01101684570312
Projection step: 8, Loss: 102.60820007324219
Final likelihood: tensor([-110.8521,  -99.4736, -106.8696, -103.2875, -110.8939, -112.6626,
         -98.6248,  -93.0999, -109.8085,  -99.9690, -104.0321,  -96.5255,
        -103.1162,  -96.3394,  -97.1359,  -99.0406])
Final projection likelihood: -102.6082
1 mode projection succeeded
New goal: tensor([ 0.1212,  0.4819,  0.6075,  0.7854, -0.1098,  0.5864,  0.9570,  0.8801,
         1.3812,  0.3366,  0.1689,  1.0195,  0.0101,  0.0095, -0.1528],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -157.284423828125
Adjusted likelihood: -157.284423828125
Likelihood residual: 0.0
Original likelihood: -133.225830078125
Adjusted likelihood: -133.225830078125
Likelihood residual: 0.0
{'index': 133.225830078125, 'thumb_middle': 157.284423828125}
Current yaw: tensor([ 0.0123,  0.0048, -0.1570], device='cuda:1')
13 index
tensor([ 0.1164,  0.4709,  0.6261,  0.8038, -0.1720,  0.5970,  0.9354,  0.8624,
         1.3907,  0.3183,  0.1384,  1.0188,  0.0123,  0.0048, -0.1570,  2.1388],
       device='cuda:1')
Solve time for step 1 10.58510569500504
Current ori: tensor([ 0.0123,  0.0048, -0.1570], device='cuda:1')
Middle force: tensor([0.5070, 0.5518, 0.5224, 0.5361], device='cuda:1')
Thumb force: tensor([0.5702, 0.5665, 0.6158, 0.5083], device='cuda:1')
tensor([ 0.1611,  0.4338,  0.5654,  0.7636, -0.1791,  0.5798,  0.9553,  0.8828,
         1.3888,  0.3239,  0.1464,  1.0199,  0.0188,  0.0066, -0.1739,  1.8907],
       device='cuda:1')
Solve time for step 2 4.262147923000157
Current ori: tensor([ 0.0188,  0.0066, -0.1739], device='cuda:1')
Middle force: tensor([0.5492, 0.5204, 0.5338], device='cuda:1')
Thumb force: tensor([0.5617, 0.6121, 0.5078], device='cuda:1')
tensor([ 1.6487e-01,  4.3902e-01,  5.6350e-01,  7.5912e-01, -1.6762e-01,
         5.9276e-01,  9.4916e-01,  8.7051e-01,  1.3864e+00,  3.2544e-01,
         1.3876e-01,  1.0140e+00,  1.2998e-02, -4.0355e-04, -1.7914e-01,
         1.6864e+00], device='cuda:1')
Solve time for step 3 4.166343684017193
Current ori: tensor([ 0.0130, -0.0004, -0.1791], device='cuda:1')
Middle force: tensor([0.5483, 0.5002], device='cuda:1')
Thumb force: tensor([0.5604, 0.5120], device='cuda:1')
tensor([ 0.1661,  0.4374,  0.5641,  0.7587, -0.1716,  0.6112,  0.9477,  0.8601,
         1.3912,  0.3227,  0.1261,  1.0083,  0.0045, -0.0036, -0.1827,  1.5466],
       device='cuda:1')
Solve time for step 4 3.9272460900247097
Current ori: tensor([ 0.0045, -0.0036, -0.1827], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5096], device='cuda:1')
Storing RECOVERY transition: reward=0.0535 (scaled=0.0535), steps=1
Reward stats updated: mean 0.0157 -> 0.0158, std: 0.0885
Collected 362 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=1.1119, Q2 Loss=1.1119, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8577
SAC Update 2/5: Actor Loss=-0.0104, Q1 Loss=1.2755, Q2 Loss=1.2755, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3113
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=1.0316, Q2 Loss=1.0316, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7487
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=1.0606, Q2 Loss=1.0606, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2652
SAC Update 5/5: Actor Loss=-0.0124, Q1 Loss=1.2537, Q2 Loss=1.2537, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3644

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010135
Q1 loss: 1.146654
Q2 loss: 1.146654
Current threshold: -149.5259
Global Scale Offset: 2600.7870
Reward stats: mean=0.0158, std=0.0885, count=362
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.1467, Q2 Loss: 1.1467, Entropy: 0.6930, Mean TD Error: 0.9095, Threshold: -149.5259
Original likelihood: -150.14898681640625
Adjusted likelihood: -150.14898681640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4999)
Current yaw: tensor([ 0.0079, -0.0033, -0.1891], device='cuda:1')
14 turn
Sampling time 3.825671995000448
tensor([ 0.1162,  0.4927,  0.6057,  0.7846, -0.1727,  0.6041,  0.9533,  0.8724,
         1.3835,  0.3425,  0.1203,  1.0306,  0.0079, -0.0033, -0.1891,  1.5362],
       device='cuda:1')
Original likelihood: -152.06959533691406
Adjusted likelihood: -152.06959533691406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4996)
Solve time for step 1 14.186568028002512
Current ori: tensor([ 0.0079, -0.0033, -0.1891], device='cuda:1')
Middle force: tensor([1.2775, 0.5173, 0.5084, 0.5124, 0.5990, 0.6167, 1.1024, 0.8119, 0.8051,
        0.6004, 0.5037, 0.5515], device='cuda:1')
Thumb force: tensor([1.8900, 1.9968, 1.4139, 0.5748, 1.1240, 0.7938, 1.4701, 0.5832, 0.7202,
        0.6905, 0.5696, 0.8762], device='cuda:1')
Index force: tensor([0.5673, 0.8356, 0.7079, 0.6643, 0.5645, 0.5525, 0.5903, 0.5212, 0.5769,
        0.5714, 0.5042, 0.5308], device='cuda:1')
Storing NORMAL transition: reward=-0.0698 (scaled=-0.0698), steps=1
Reward stats updated: mean 0.0158 -> 0.0156, std: 0.0884
Collected 363 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.6998, Q2 Loss=0.6998, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5587
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=2.1518, Q2 Loss=2.1518, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0068
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=1.0876, Q2 Loss=1.0876, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5278
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8387, Q2 Loss=0.8387, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6381
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.7670, Q2 Loss=0.7670, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5507

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.05s (18.8%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008609
Q1 loss: 1.108995
Q2 loss: 1.108995
Current threshold: -149.5257
Global Scale Offset: 2617.9872
Reward stats: mean=0.0156, std=0.0884, count=363
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1090, Q2 Loss: 1.1090, Entropy: 0.6930, Mean TD Error: 1.0564, Threshold: -149.5257
tensor([-0.0186,  0.4657,  0.4993,  0.8333, -0.2390,  0.6338,  0.7861,  0.9291,
         1.4666,  0.2537,  0.2241,  0.8686,  0.0142,  0.0599, -0.1224,  0.9312],
       device='cuda:1')
Original likelihood: -268.975341796875
Adjusted likelihood: -268.975341796875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4818)
Solve time for step 2 5.542568098986521
Current ori: tensor([ 0.0142,  0.0599, -0.1224], device='cuda:1')
Middle force: tensor([0.6475, 1.5921, 0.7835, 0.5443, 0.5134, 0.6183, 0.7099, 0.5122, 0.6030,
        0.5178, 0.5026], device='cuda:1')
Thumb force: tensor([0.9409, 0.5740, 1.1966, 0.9794, 0.5493, 0.5583, 0.5763, 0.5830, 0.5963,
        0.5711, 0.5927], device='cuda:1')
Index force: tensor([0.6105, 0.6538, 0.5447, 0.6855, 0.5637, 0.5276, 0.5575, 0.7646, 0.6097,
        0.6437, 0.8131], device='cuda:1')
Storing NORMAL transition: reward=0.0275 (scaled=0.0275), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0883
Collected 364 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.9857, Q2 Loss=0.9857, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4201
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8756, Q2 Loss=0.8756, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0003
SAC Update 3/5: Actor Loss=-0.0087, Q1 Loss=1.0493, Q2 Loss=1.0493, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4807
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=2.1343, Q2 Loss=2.1343, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6377
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=0.9318, Q2 Loss=0.9318, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8162

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (20.4%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008276
Q1 loss: 1.195323
Q2 loss: 1.195323
Current threshold: -149.5255
Global Scale Offset: 2632.9840
Reward stats: mean=0.0156, std=0.0883, count=364
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.1953, Q2 Loss: 1.1953, Entropy: 0.6931, Mean TD Error: 2.2710, Threshold: -149.5255
tensor([-0.0328,  0.3939,  0.5925,  0.8217, -0.2510,  0.5946,  0.8151,  0.9934,
         1.4184,  0.3710,  0.3239,  0.7442,  0.0310,  0.0620, -0.1510,  0.7982],
       device='cuda:1')
Original likelihood: -193.86264038085938
Adjusted likelihood: -193.86264038085938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4933)
Solve time for step 3 5.097868706972804
Current ori: tensor([ 0.0310,  0.0620, -0.1510], device='cuda:1')
Middle force: tensor([0.5055, 0.5093, 0.5976, 0.6229, 1.0719, 0.7976, 0.7948, 0.5966, 0.5037,
        0.5467], device='cuda:1')
Thumb force: tensor([1.3560, 0.5549, 1.0760, 0.7637, 1.4184, 0.5737, 0.6993, 0.6737, 0.5621,
        0.8641], device='cuda:1')
Index force: tensor([0.7431, 0.7122, 0.5692, 0.5435, 0.5943, 0.5194, 0.5702, 0.5635, 0.5025,
        0.5261], device='cuda:1')
Storing NORMAL transition: reward=-0.1106 (scaled=-0.1106), steps=1
Reward stats updated: mean 0.0156 -> 0.0152, std: 0.0885
Collected 365 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.8640, Q2 Loss=0.8640, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6025
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8239, Q2 Loss=0.8239, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6135
SAC Update 3/5: Actor Loss=-0.0132, Q1 Loss=1.5182, Q2 Loss=1.5182, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0791
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=1.1059, Q2 Loss=1.1059, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8995
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=1.4004, Q2 Loss=1.4004, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5579

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009721
Q1 loss: 1.142482
Q2 loss: 1.142482
Current threshold: -149.5253
Global Scale Offset: 2647.5539
Reward stats: mean=0.0152, std=0.0885, count=365
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.1425, Q2 Loss: 1.1425, Entropy: 0.6931, Mean TD Error: 1.1505, Threshold: -149.5253
tensor([-0.1130,  0.3475,  0.6210,  0.7759, -0.2929,  0.6258,  0.7241,  1.0259,
         1.3221,  0.4838,  0.4064,  0.8166,  0.0439,  0.0934, -0.0440,  0.5904],
       device='cuda:1')
Original likelihood: -138.08253479003906
Adjusted likelihood: -138.08253479003906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Solve time for step 4 4.878931123006623
Current ori: tensor([ 0.0439,  0.0934, -0.0440], device='cuda:1')
Middle force: tensor([0.5082, 0.5969, 0.6253, 1.0731, 0.7967, 0.7888, 0.5993, 0.5046, 0.5470],
       device='cuda:1')
Thumb force: tensor([0.5471, 1.0536, 0.7505, 1.3833, 0.5688, 0.6876, 0.6636, 0.5580, 0.8471],
       device='cuda:1')
Index force: tensor([0.7533, 0.5817, 0.5434, 0.6085, 0.5193, 0.5714, 0.5595, 0.5014, 0.5242],
       device='cuda:1')
Storing NORMAL transition: reward=0.2439 (scaled=0.2439), steps=1
Reward stats updated: mean 0.0152 -> 0.0159, std: 0.0891
Collected 366 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7164, Q2 Loss=0.7164, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1235
SAC Update 2/5: Actor Loss=-0.0124, Q1 Loss=1.2166, Q2 Loss=1.2166, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3958
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=1.4195, Q2 Loss=1.4195, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3847
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=1.0803, Q2 Loss=1.0803, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1411
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.8060, Q2 Loss=0.8060, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0057

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.8%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009377
Q1 loss: 1.047744
Q2 loss: 1.047744
Current threshold: -149.5253
Global Scale Offset: 2662.6920
Reward stats: mean=0.0159, std=0.0891, count=366
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.0477, Q2 Loss: 1.0477, Entropy: 0.6930, Mean TD Error: 1.0102, Threshold: -149.5253
tensor([-0.0786,  0.4666,  0.4939,  0.7426, -0.2698,  0.5753,  0.7762,  1.1783,
         1.4145,  0.4254,  0.2183,  0.9254,  0.0261,  0.0668, -0.2860,  0.6459],
       device='cuda:1')
Original likelihood: -266.57568359375
Adjusted likelihood: -266.57568359375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4825)
Solve time for step 5 4.712930170004256
Current ori: tensor([ 0.0261,  0.0668, -0.2860], device='cuda:1')
Middle force: tensor([0.5958, 0.6317, 1.0563, 0.7868, 0.8009, 0.6026, 0.5034, 0.5458],
       device='cuda:1')
Thumb force: tensor([1.0221, 0.7307, 1.3624, 0.5695, 0.6629, 0.6495, 0.5567, 0.8376],
       device='cuda:1')
Index force: tensor([0.5809, 0.5427, 0.6076, 0.5172, 0.5666, 0.5563, 0.5012, 0.5219],
       device='cuda:1')
Storing NORMAL transition: reward=0.0333 (scaled=0.0333), steps=1
Reward stats updated: mean 0.0159 -> 0.0159, std: 0.0890
Collected 367 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=0.8613, Q2 Loss=0.8613, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6509
SAC Update 2/5: Actor Loss=-0.0094, Q1 Loss=0.9570, Q2 Loss=0.9570, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6244
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7119, Q2 Loss=0.7119, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1218
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.9160, Q2 Loss=0.9160, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3810
SAC Update 5/5: Actor Loss=-0.0126, Q1 Loss=1.2128, Q2 Loss=1.2128, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2478

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.6%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.06s (20.9%)
Actor update: 0.11s (40.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009256
Q1 loss: 0.931796
Q2 loss: 0.931796
Current threshold: -149.5251
Global Scale Offset: 2671.2244
Reward stats: mean=0.0159, std=0.0890, count=367
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 0.9318, Q2 Loss: 0.9318, Entropy: 0.6930, Mean TD Error: 0.6052, Threshold: -149.5251
tensor([-0.0498,  0.4719,  0.5034,  0.7510, -0.2553,  0.5607,  0.8210,  1.1551,
         1.4420,  0.3774,  0.1971,  0.9006,  0.0252,  0.0542, -0.3178,  0.7735],
       device='cuda:1')
Original likelihood: -267.821044921875
Adjusted likelihood: -267.821044921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4823)
Solve time for step 6 4.663667720044032
Current ori: tensor([ 0.0252,  0.0542, -0.3178], device='cuda:1')
Middle force: tensor([0.6255, 1.0441, 0.7801, 0.7932, 0.5995, 0.5028, 0.5429],
       device='cuda:1')
Thumb force: tensor([0.7221, 1.3389, 0.5679, 0.6550, 0.6436, 0.5549, 0.8317],
       device='cuda:1')
Index force: tensor([0.5418, 0.6105, 0.5161, 0.5631, 0.5536, 0.5009, 0.5202],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0090 (scaled=-0.0090), steps=1
Reward stats updated: mean 0.0159 -> 0.0158, std: 0.0889
Collected 368 transitions for RL
SAC Update 1/5: Actor Loss=-0.0136, Q1 Loss=1.2843, Q2 Loss=1.2843, Entropy=0.6929, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2948
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=1.3312, Q2 Loss=1.3312, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1040
SAC Update 3/5: Actor Loss=-0.0114, Q1 Loss=1.0954, Q2 Loss=1.0954, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4042
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=0.9350, Q2 Loss=0.9350, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4066
SAC Update 5/5: Actor Loss=-0.0111, Q1 Loss=1.0734, Q2 Loss=1.0734, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4312

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010715
Q1 loss: 1.143868
Q2 loss: 1.143868
Current threshold: -149.5249
Global Scale Offset: 2670.6350
Reward stats: mean=0.0158, std=0.0889, count=368
----------------------------------------------
SAC Update - Actor Loss: -0.0107, Q1 Loss: 1.1439, Q2 Loss: 1.1439, Entropy: 0.6930, Mean TD Error: 0.7282, Threshold: -149.5249
tensor([ 0.0020,  0.4154,  0.5554,  0.8937, -0.2772,  0.4857,  0.9247,  1.0497,
         1.4461,  0.5080,  0.1956,  0.8926,  0.0344,  0.0763, -0.3129,  0.0192],
       device='cuda:1')
Original likelihood: -186.1392822265625
Adjusted likelihood: -186.1392822265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4945)
State is out of distribution
Projection step: 0, Loss: 222.7195587158203
Projection step: 1, Loss: 221.0755615234375
Projection step: 2, Loss: 200.2178955078125
Projection step: 3, Loss: 208.10484313964844
Projection step: 4, Loss: 206.24078369140625
Projection step: 5, Loss: 202.9275665283203
Projection step: 6, Loss: 215.73153686523438
Projection step: 7, Loss: 192.48109436035156
Projection step: 8, Loss: 188.11932373046875
Projection step: 9, Loss: 175.57666015625
Projection step: 10, Loss: 170.4352264404297
Projection step: 11, Loss: 167.60409545898438
Projection step: 12, Loss: 161.52346801757812
Projection step: 13, Loss: 153.80349731445312
Projection step: 14, Loss: 151.60154724121094
Projection step: 15, Loss: 146.47044372558594
Projection step: 16, Loss: 141.10888671875
Projection step: 17, Loss: 140.01629638671875
Projection step: 18, Loss: 134.91293334960938
Projection step: 19, Loss: 129.01705932617188
Projection step: 20, Loss: 125.48330688476562
Projection step: 21, Loss: 120.91419982910156
Projection step: 22, Loss: 120.43800354003906
Projection step: 23, Loss: 118.01294708251953
Projection step: 24, Loss: 116.18669128417969
Final likelihood: tensor([-115.3168, -105.1627, -114.4825, -118.8651, -116.8972, -108.9237,
        -109.4300, -112.4995, -115.2853, -113.2172, -110.1865, -125.4589,
        -118.8556, -115.7915, -122.9551, -116.9270])
Final projection likelihood: -115.0159
1 mode projection succeeded
New goal: tensor([-0.0394,  0.3934,  0.3127,  1.1542, -0.1813,  0.5632,  0.7129,  1.2319,
         1.5222,  0.5164,  0.1908,  1.0349,  0.0366,  0.0815, -0.3855],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -142.6881866455078
Adjusted likelihood: -142.6881866455078
Likelihood residual: 0.0
Original likelihood: -167.4224395751953
Adjusted likelihood: -167.4224395751953
Likelihood residual: 0.0
{'index': 167.4224395751953, 'thumb_middle': 142.6881866455078}
Current yaw: tensor([ 0.0344,  0.0763, -0.3129], device='cuda:1')
15 thumb_middle
tensor([ 0.0020,  0.4154,  0.5554,  0.8937, -0.2772,  0.4857,  0.9247,  1.0497,
         1.4461,  0.5080,  0.1956,  0.8926,  0.0344,  0.0763, -0.3129,  0.0192],
       device='cuda:1')
Solve time for step 1 8.923255554982461
Current ori: tensor([ 0.0344,  0.0763, -0.3129], device='cuda:1')
Index force: tensor([0.5763, 0.5738, 0.5833, 0.5654], device='cuda:1')
tensor([-0.0227,  0.4342,  0.3846,  1.1324, -0.3163,  0.5410,  0.7177,  1.1699,
         1.4277,  0.4989,  0.0849,  0.9547,  0.0591,  0.0880, -0.3129,  0.0344],
       device='cuda:1')
Solve time for step 2 3.5624414079939015
Current ori: tensor([ 0.0591,  0.0880, -0.3129], device='cuda:1')
Index force: tensor([0.5612, 0.5733, 0.5568], device='cuda:1')
tensor([-0.0100,  0.4462,  0.3605,  1.1636, -0.3124,  0.5576,  0.6947,  1.1932,
         1.4286,  0.4966,  0.0700,  0.9632,  0.0593,  0.0822, -0.3129,  0.0554],
       device='cuda:1')
Solve time for step 3 3.4281186209991574
Current ori: tensor([ 0.0593,  0.0822, -0.3129], device='cuda:1')
Index force: tensor([0.5505, 0.5725], device='cuda:1')
tensor([ 0.0017,  0.4413,  0.3658,  1.1835, -0.3087,  0.5598,  0.6884,  1.2091,
         1.4347,  0.4943,  0.0623,  0.9575,  0.0622,  0.0767, -0.3129,  0.0754],
       device='cuda:1')
Solve time for step 4 3.6245041280053556
Current ori: tensor([ 0.0622,  0.0767, -0.3129], device='cuda:1')
Index force: tensor([0.5535], device='cuda:1')
Storing RECOVERY transition: reward=-0.0261 (scaled=-0.0043), steps=6
Reward stats updated: mean 0.0158 -> 0.0158, std: 0.0888
Collected 369 transitions for RL
SAC Update 1/5: Actor Loss=-0.0100, Q1 Loss=1.1167, Q2 Loss=1.1167, Entropy=0.6918, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8410
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.7301, Q2 Loss=0.7301, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2449
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.0610, Q2 Loss=1.0610, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5435
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=1.0662, Q2 Loss=1.0662, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4020
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=0.9036, Q2 Loss=0.9036, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6352

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.06s (19.5%)
Actor update: 0.12s (40.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009135
Q1 loss: 0.975532
Q2 loss: 0.975532
Current threshold: -149.5249
Global Scale Offset: 2679.7269
Reward stats: mean=0.0158, std=0.0888, count=369
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9755, Q2 Loss: 0.9755, Entropy: 0.6927, Mean TD Error: 0.7333, Threshold: -149.5249
Original likelihood: -191.93435668945312
Adjusted likelihood: -191.93435668945312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4937)
State is out of distribution
Projection step: 0, Loss: 191.99163818359375
Projection step: 1, Loss: 186.62973022460938
Projection step: 2, Loss: 168.23715209960938
Projection step: 3, Loss: 162.403564453125
Projection step: 4, Loss: 154.10098266601562
Projection step: 5, Loss: 143.08860778808594
Projection step: 6, Loss: 136.71546936035156
Projection step: 7, Loss: 134.87876892089844
Projection step: 8, Loss: 131.05520629882812
Projection step: 9, Loss: 125.227783203125
Projection step: 10, Loss: 124.953369140625
Projection step: 11, Loss: 122.90913391113281
Projection step: 12, Loss: 123.29264831542969
Projection step: 13, Loss: 123.48228454589844
Projection step: 14, Loss: 119.26118469238281
Projection step: 15, Loss: 120.0440902709961
Projection step: 16, Loss: 116.97936248779297
Projection step: 17, Loss: 116.83984375
Projection step: 18, Loss: 116.23040771484375
Projection step: 19, Loss: 113.13337707519531
Projection step: 20, Loss: 115.73856353759766
Projection step: 21, Loss: 114.81240844726562
Projection step: 22, Loss: 115.3199462890625
Projection step: 23, Loss: 108.62962341308594
Projection step: 24, Loss: 112.8927993774414
Final likelihood: tensor([-110.2349, -119.5738, -105.9925, -109.3417, -117.1922, -117.8281,
        -118.3310, -130.7133, -116.8987, -114.9771, -112.4828, -107.0083,
        -114.0526, -115.4079, -116.1672, -116.3262])
Final projection likelihood: -115.1580
1 mode projection succeeded
New goal: tensor([-0.0587,  0.4064,  0.2459,  1.2462, -0.1851,  0.5851,  0.6675,  1.2420,
         1.5356,  0.4920,  0.1952,  0.9976,  0.0610,  0.0903,  0.3336],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -138.69842529296875
Adjusted likelihood: -138.69842529296875
Likelihood residual: 0.0
Original likelihood: -156.989013671875
Adjusted likelihood: -156.989013671875
Likelihood residual: 0.0
{'index': 156.989013671875, 'thumb_middle': 138.69842529296875}
Current yaw: tensor([ 0.0661,  0.0881, -0.2924], device='cuda:1')
16 thumb_middle
tensor([-0.0236,  0.4344,  0.3531,  1.1878, -0.2856,  0.5850,  0.6879,  1.2008,
         1.4902,  0.5169,  0.1185,  1.0043,  0.0661,  0.0881, -0.2924,  0.0091],
       device='cuda:1')
Solve time for step 1 9.240266919950955
Current ori: tensor([ 0.0661,  0.0881, -0.2924], device='cuda:1')
Index force: tensor([0.5715, 0.5977, 0.5927, 0.5608], device='cuda:1')
tensor([-0.0351,  0.4496,  0.2893,  1.2479, -0.3116,  0.5765,  0.6417,  1.2067,
         1.4489,  0.4658,  0.0871,  0.9433,  0.0715,  0.0936, -0.2919,  0.0193],
       device='cuda:1')
Solve time for step 2 3.5456543870386668
Current ori: tensor([ 0.0715,  0.0936, -0.2919], device='cuda:1')
Index force: tensor([0.5880, 0.5852, 0.5563], device='cuda:1')
tensor([-0.0332,  0.4415,  0.2891,  1.2716, -0.3101,  0.5829,  0.6456,  1.2033,
         1.4468,  0.4817,  0.0810,  0.9510,  0.0762,  0.0933, -0.2919,  0.0419],
       device='cuda:1')
Solve time for step 3 3.5462999470182694
Current ori: tensor([ 0.0762,  0.0933, -0.2919], device='cuda:1')
Index force: tensor([0.5780, 0.5660], device='cuda:1')
tensor([-0.0207,  0.4451,  0.2986,  1.2628, -0.3110,  0.5996,  0.6281,  1.1917,
         1.4512,  0.4797,  0.0719,  0.9431,  0.0732,  0.0876, -0.2919,  0.0542],
       device='cuda:1')
Solve time for step 4 3.3423289170023054
Current ori: tensor([ 0.0732,  0.0876, -0.2919], device='cuda:1')
Index force: tensor([0.5541], device='cuda:1')
Storing RECOVERY transition: reward=-0.0736 (scaled=-0.0123), steps=6
Reward stats updated: mean 0.0158 -> 0.0157, std: 0.0887
Collected 370 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.6955, Q2 Loss=0.6955, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2140
SAC Update 2/5: Actor Loss=-0.0080, Q1 Loss=0.9057, Q2 Loss=0.9057, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3775
SAC Update 3/5: Actor Loss=-0.0127, Q1 Loss=1.3012, Q2 Loss=1.3012, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5235
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=5.7014, Q2 Loss=5.7014, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.5671
SAC Update 5/5: Actor Loss=-0.0116, Q1 Loss=1.5290, Q2 Loss=1.5290, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5435

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.5%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009683
Q1 loss: 2.026544
Q2 loss: 2.026544
Current threshold: -149.5248
Global Scale Offset: 2695.0904
Reward stats: mean=0.0157, std=0.0887, count=370
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 2.0265, Q2 Loss: 2.0265, Entropy: 0.6929, Mean TD Error: 2.0451, Threshold: -149.5248
Original likelihood: -194.53439331054688
Adjusted likelihood: -194.53439331054688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4933)
State is out of distribution
Projection step: 0, Loss: 192.65689086914062
Projection step: 1, Loss: 177.34957885742188
Projection step: 2, Loss: 167.33328247070312
Projection step: 3, Loss: 160.61343383789062
Projection step: 4, Loss: 151.37924194335938
Projection step: 5, Loss: 150.10726928710938
Projection step: 6, Loss: 148.95953369140625
Projection step: 7, Loss: 146.53463745117188
Projection step: 8, Loss: 139.8795623779297
Projection step: 9, Loss: 137.71392822265625
Projection step: 10, Loss: 135.94700622558594
Projection step: 11, Loss: 134.18362426757812
Projection step: 12, Loss: 133.15811157226562
Projection step: 13, Loss: 130.32643127441406
Projection step: 14, Loss: 128.45416259765625
Projection step: 15, Loss: 129.02081298828125
Projection step: 16, Loss: 126.0101089477539
Projection step: 17, Loss: 125.36328887939453
Projection step: 18, Loss: 128.66522216796875
Projection step: 19, Loss: 124.76278686523438
Projection step: 20, Loss: 126.59883880615234
Projection step: 21, Loss: 125.80213165283203
Projection step: 22, Loss: 123.39746856689453
Projection step: 23, Loss: 124.8014907836914
Projection step: 24, Loss: 117.66180419921875
Final likelihood: tensor([-126.8757, -131.7811, -126.9670, -113.5725, -127.3357, -109.9283,
        -110.9003, -111.2670, -118.7303, -125.2661, -115.9830, -120.8094,
        -120.6646, -106.7981, -113.6384, -122.1672])
Final projection likelihood: -118.9178
1 mode projection succeeded
New goal: tensor([-0.0722,  0.4205,  0.2322,  1.2402, -0.1860,  0.5795,  0.6610,  1.2386,
         1.5237,  0.4643,  0.2108,  1.0135,  0.0756,  0.0908,  0.4608],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -138.93490600585938
Adjusted likelihood: -138.93490600585938
Likelihood residual: 0.0
Original likelihood: -172.632568359375
Adjusted likelihood: -172.632568359375
Likelihood residual: 0.0
{'index': 172.632568359375, 'thumb_middle': 138.93490600585938}
Current yaw: tensor([ 0.0830,  0.0913, -0.2467], device='cuda:1')
17 thumb_middle
tensor([-0.0498,  0.4384,  0.2765,  1.2792, -0.2813,  0.6157,  0.6439,  1.1838,
         1.4999,  0.4875,  0.1432,  0.9800,  0.0830,  0.0913, -0.2467, -0.2048],
       device='cuda:1')
Solve time for step 1 9.177026139048394
Current ori: tensor([ 0.0830,  0.0913, -0.2467], device='cuda:1')
Index force: tensor([0.5936, 0.5959, 0.6080, 0.5676], device='cuda:1')
tensor([-0.0596,  0.4366,  0.2724,  1.2770, -0.3074,  0.5943,  0.6154,  1.1915,
         1.4482,  0.4506,  0.1019,  0.9570,  0.0838,  0.0974, -0.2471, -0.1579],
       device='cuda:1')
Solve time for step 2 3.59302246599691
Current ori: tensor([ 0.0838,  0.0974, -0.2471], device='cuda:1')
Index force: tensor([0.5866, 0.6001, 0.5616], device='cuda:1')
tensor([-0.0489,  0.4541,  0.2632,  1.2636, -0.3013,  0.5957,  0.6243,  1.1942,
         1.4415,  0.4474,  0.0957,  0.9529,  0.0769,  0.0930, -0.2471, -0.1491],
       device='cuda:1')
Solve time for step 3 3.382056877017021
Current ori: tensor([ 0.0769,  0.0930, -0.2471], device='cuda:1')
Index force: tensor([0.5902, 0.5558], device='cuda:1')
tensor([-0.0465,  0.4517,  0.2649,  1.2701, -0.3009,  0.5963,  0.6266,  1.1958,
         1.4450,  0.4445,  0.0897,  0.9530,  0.0782,  0.0918, -0.2471, -0.1446],
       device='cuda:1')
Solve time for step 4 3.132973695988767
Current ori: tensor([ 0.0782,  0.0918, -0.2471], device='cuda:1')
Index force: tensor([0.5419], device='cuda:1')
Storing RECOVERY transition: reward=-0.0834 (scaled=-0.0139), steps=6
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0886
Collected 371 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7291, Q2 Loss=0.7291, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3531
SAC Update 2/5: Actor Loss=-0.0096, Q1 Loss=1.7648, Q2 Loss=1.7648, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4779
SAC Update 3/5: Actor Loss=-0.0127, Q1 Loss=1.2430, Q2 Loss=1.2430, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4903
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.7773, Q2 Loss=0.7773, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5648
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=0.9368, Q2 Loss=0.9368, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7858

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.06s (19.4%)
Q2 update: 0.06s (20.1%)
Actor update: 0.11s (39.7%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009372
Q1 loss: 1.090208
Q2 loss: 1.090208
Current threshold: -149.5245
Global Scale Offset: 2709.9608
Reward stats: mean=0.0156, std=0.0886, count=371
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.0902, Q2 Loss: 1.0902, Entropy: 0.6931, Mean TD Error: 0.9344, Threshold: -149.5245
Original likelihood: -184.58444213867188
Adjusted likelihood: -184.58444213867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4948)
Current yaw: tensor([ 0.0853,  0.0862, -0.2360], device='cuda:1')
18 turn
Sampling time 3.6022945899749175
tensor([-0.0584,  0.4391,  0.2688,  1.2790, -0.2725,  0.6012,  0.6413,  1.2178,
         1.4995,  0.4562,  0.1439,  0.9897,  0.0853,  0.0862, -0.2360, -0.4047],
       device='cuda:1')
Original likelihood: -186.86773681640625
Adjusted likelihood: -186.86773681640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4945)
Solve time for step 1 14.167686911008786
Current ori: tensor([ 0.0853,  0.0862, -0.2360], device='cuda:1')
Middle force: tensor([0.8166, 0.7166, 0.8572, 0.6073, 0.5154, 0.5019, 0.4907, 0.6903, 1.1540,
        0.5800, 0.5060, 0.5661], device='cuda:1')
Thumb force: tensor([2.3833, 0.5189, 1.4268, 1.2739, 0.5736, 0.5978, 1.2297, 0.7411, 1.3817,
        0.6068, 1.1348, 0.6246], device='cuda:1')
Index force: tensor([0.8453, 0.6942, 0.5678, 0.5756, 0.8367, 0.5462, 0.5997, 0.5340, 0.5802,
        0.5755, 0.5460, 0.6081], device='cuda:1')
Storing NORMAL transition: reward=0.0125 (scaled=0.0125), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0885
Collected 372 transitions for RL
SAC Update 1/5: Actor Loss=-0.0105, Q1 Loss=1.0085, Q2 Loss=1.0085, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1856
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=3.5886, Q2 Loss=3.5886, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0344
SAC Update 3/5: Actor Loss=-0.0109, Q1 Loss=1.1341, Q2 Loss=1.1341, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7536
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.7703, Q2 Loss=0.7703, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6308
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.0085, Q2 Loss=1.0085, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7485

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.05s (19.5%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009428
Q1 loss: 1.502007
Q2 loss: 1.502007
Current threshold: -149.5242
Global Scale Offset: 2720.8647
Reward stats: mean=0.0156, std=0.0885, count=372
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.5020, Q2 Loss: 1.5020, Entropy: 0.6931, Mean TD Error: 1.6706, Threshold: -149.5242
tensor([-0.0467,  0.4574,  0.2632,  1.2571, -0.2953,  0.6629,  0.5720,  1.2524,
         1.5000,  0.5046,  0.1089,  1.0220,  0.0759,  0.0902, -0.2480, -0.2759],
       device='cuda:1')
Original likelihood: -198.80247497558594
Adjusted likelihood: -198.80247497558594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4928)
Solve time for step 2 5.56065405200934
Current ori: tensor([ 0.0759,  0.0902, -0.2480], device='cuda:1')
Middle force: tensor([0.7613, 0.8891, 0.6325, 0.5080, 0.5029, 0.5063, 1.2722, 0.7199, 0.5422,
        0.4999, 0.5139], device='cuda:1')
Thumb force: tensor([0.5320, 1.4509, 1.2593, 0.5328, 0.5534, 1.1399, 0.5759, 0.5707, 0.5575,
        0.7269, 0.5496], device='cuda:1')
Index force: tensor([0.7809, 0.6030, 0.6183, 0.8718, 0.5875, 0.5818, 0.7361, 0.6103, 0.5904,
        0.5876, 0.5091], device='cuda:1')
Storing NORMAL transition: reward=-0.0208 (scaled=-0.0208), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0884
Collected 373 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.8620, Q2 Loss=0.8620, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4315
SAC Update 2/5: Actor Loss=-0.0110, Q1 Loss=1.8392, Q2 Loss=1.8392, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1572
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.7222, Q2 Loss=0.7222, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2735
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=2.7511, Q2 Loss=2.7511, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8310
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.8216, Q2 Loss=0.8216, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4028

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.3%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008599
Q1 loss: 1.399244
Q2 loss: 1.399244
Current threshold: -149.5239
Global Scale Offset: 2730.8128
Reward stats: mean=0.0155, std=0.0884, count=373
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.3992, Q2 Loss: 1.3992, Entropy: 0.6931, Mean TD Error: 1.8192, Threshold: -149.5239
tensor([-0.1606,  0.4882,  0.1550,  1.2122, -0.1832,  0.6547,  0.6735,  1.4042,
         1.5000,  0.4777,  0.0988,  0.8916,  0.1475,  0.0046, -0.2342, -0.1478],
       device='cuda:1')
Original likelihood: -222.96009826660156
Adjusted likelihood: -222.96009826660156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4893)
State is out of distribution
Projection step: 0, Loss: 220.56610107421875
Projection step: 1, Loss: 210.5159454345703
Projection step: 2, Loss: 185.9409942626953
Projection step: 3, Loss: 189.7756805419922
Projection step: 4, Loss: 216.43310546875
Projection step: 5, Loss: 209.157470703125
Projection step: 6, Loss: 186.394287109375
Projection step: 7, Loss: 185.18508911132812
Projection step: 8, Loss: 196.61166381835938
Projection step: 9, Loss: 174.5473175048828
Projection step: 10, Loss: 167.8118133544922
Projection step: 11, Loss: 183.85638427734375
Projection step: 12, Loss: 166.48251342773438
Projection step: 13, Loss: 182.9154052734375
Projection step: 14, Loss: 183.39010620117188
Projection step: 15, Loss: 192.5208740234375
Projection step: 16, Loss: 196.81422424316406
Projection step: 17, Loss: 208.88754272460938
Projection step: 18, Loss: 179.5145721435547
Projection step: 19, Loss: 191.56475830078125
Projection step: 20, Loss: 165.87759399414062
Projection step: 21, Loss: 185.26492309570312
Projection step: 22, Loss: 180.39910888671875
Projection step: 23, Loss: 154.53195190429688
Projection step: 24, Loss: 163.1475830078125
Final likelihood: tensor([-193.9570, -173.4894, -205.9303, -165.5297, -226.0857, -114.4839,
        -116.2571,  -86.3043, -203.2256, -223.6722, -170.7363, -224.3019,
        -203.9049, -223.5609, -204.6614, -225.0522])
Final projection likelihood: -185.0721
1 mode projection failed, trying anyway
New goal: tensor([-0.1495,  0.4553,  0.2176,  1.2611, -0.1151,  0.5678,  0.5448,  1.2712,
         1.4811,  0.2878,  0.0997,  1.0012,  0.1418,  0.0145, -0.3784],
       device='cuda:1')
tensor([[0.0092]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0048]], device='cuda:1')
Original likelihood: -152.81524658203125
Adjusted likelihood: -152.81524658203125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 152.81524658203125}
Current yaw: tensor([ 0.1475,  0.0046, -0.2342], device='cuda:1')
19 thumb_middle
tensor([-0.1606,  0.4882,  0.1550,  1.2122, -0.1832,  0.6547,  0.6735,  1.4042,
         1.5000,  0.4777,  0.0988,  0.8916,  0.1475,  0.0046, -0.2342, -0.1478],
       device='cuda:1')
Solve time for step 1 8.834140504011884
Current ori: tensor([ 0.1475,  0.0046, -0.2342], device='cuda:1')
Index force: tensor([0.5982, 0.5809, 0.5847, 0.5552], device='cuda:1')
tensor([-1.9370e-01,  4.9530e-01,  2.0665e-01,  1.2417e+00, -1.8685e-01,
         5.8669e-01,  5.4023e-01,  1.2703e+00,  1.4866e+00,  2.9711e-01,
         6.0108e-02,  9.6822e-01,  2.4329e-01, -1.3007e-02, -2.3435e-01,
        -6.7849e-04], device='cuda:1')
Solve time for step 2 3.5785500690108165
Current ori: tensor([ 0.2433, -0.0130, -0.2343], device='cuda:1')
Index force: tensor([0.5767, 0.5770, 0.5496], device='cuda:1')
tensor([-0.1451,  0.5273,  0.3512,  1.3821, -0.1161,  0.6229,  0.5891,  1.3034,
         1.4999,  0.2980,  0.0767,  1.0016,  0.2386, -0.0217, -0.2550, -0.0504],
       device='cuda:1')
Solve time for step 3 3.5127125769504346
Current ori: tensor([ 0.2386, -0.0217, -0.2550], device='cuda:1')
Index force: tensor([0.5002, 0.5013], device='cuda:1')
tensor([-0.1351,  0.5593,  0.3308,  1.2344, -0.0679,  0.6232,  0.6075,  1.2962,
         1.4948,  0.2856,  0.0870,  1.0130,  0.2316, -0.0376, -0.2529,  0.1469],
       device='cuda:1')
Solve time for step 4 3.3159447780344635
Current ori: tensor([ 0.2316, -0.0376, -0.2529], device='cuda:1')
Index force: tensor([0.5009], device='cuda:1')
Storing RECOVERY transition: reward=-0.0206 (scaled=-0.0103), steps=2
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0882
Collected 374 transitions for RL
SAC Update 1/5: Actor Loss=-0.0129, Q1 Loss=1.4491, Q2 Loss=1.4491, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9907
SAC Update 2/5: Actor Loss=-0.0129, Q1 Loss=1.2503, Q2 Loss=1.2503, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1206
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=1.1605, Q2 Loss=1.1605, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4329
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.2048, Q2 Loss=1.2048, Entropy=0.6919, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9018
SAC Update 5/5: Actor Loss=-0.0127, Q1 Loss=1.2933, Q2 Loss=1.2933, Entropy=0.6927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4500

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.012271
Q1 loss: 1.271605
Q2 loss: 1.271605
Current threshold: -149.5237
Global Scale Offset: 2743.4487
Reward stats: mean=0.0155, std=0.0882, count=374
----------------------------------------------
SAC Update - Actor Loss: -0.0123, Q1 Loss: 1.2716, Q2 Loss: 1.2716, Entropy: 0.6928, Mean TD Error: 0.5792, Threshold: -149.5237
Original likelihood: -241.47975158691406
Adjusted likelihood: -241.47975158691406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4866)
Current yaw: tensor([ 0.2273, -0.0640, -0.2448], device='cuda:1')
20 turn
Sampling time 3.648411303991452
tensor([-0.1431,  0.5800,  0.2248,  1.2367,  0.0649,  0.7003,  0.7036,  1.3809,
         1.5000,  0.2980,  0.1793,  1.0734,  0.2273, -0.0640, -0.2448,  0.4057],
       device='cuda:1')
Original likelihood: -263.122802734375
Adjusted likelihood: -263.122802734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4835)
Solve time for step 1 14.236519024008885
Current ori: tensor([ 0.2273, -0.0640, -0.2448], device='cuda:1')
Middle force: tensor([1.6877, 1.0233, 0.7416, 0.3881, 0.5019, 1.0162, 0.4183, 0.9087, 0.6304,
        0.8843, 0.9776, 1.1585], device='cuda:1')
Thumb force: tensor([0.6023, 0.5720, 0.8663, 0.8392, 1.2130, 0.8582, 0.7332, 1.7880, 0.9586,
        1.0279, 0.5023, 1.3513], device='cuda:1')
Index force: tensor([1.4339, 1.0791, 0.5159, 0.5006, 0.5071, 0.4663, 0.4705, 0.5002, 0.5030,
        0.5219, 0.4411, 0.4680], device='cuda:1')
Storing NORMAL transition: reward=-0.0346 (scaled=-0.0346), steps=1
Reward stats updated: mean 0.0155 -> 0.0153, std: 0.0882
Collected 375 transitions for RL
SAC Update 1/5: Actor Loss=-0.0124, Q1 Loss=1.3579, Q2 Loss=1.3579, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9281
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=0.9436, Q2 Loss=0.9436, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7421
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.7857, Q2 Loss=0.7857, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3236
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.8438, Q2 Loss=0.8438, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3514
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.7968, Q2 Loss=0.7968, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6147

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.7%)
Actor update: 0.10s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008951
Q1 loss: 0.945571
Q2 loss: 0.945571
Current threshold: -149.5235
Global Scale Offset: 2759.5982
Reward stats: mean=0.0153, std=0.0882, count=375
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 0.9456, Q2 Loss: 0.9456, Entropy: 0.6930, Mean TD Error: 0.9920, Threshold: -149.5235
tensor([-0.1531,  0.6395,  0.2197,  1.0303,  0.0092,  0.4606,  1.0390,  1.1648,
         1.4806,  0.4084, -0.0069,  1.1173,  0.2176, -0.0865, -0.2062,  0.5393],
       device='cuda:1')
Original likelihood: -194.3078155517578
Adjusted likelihood: -194.3078155517578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4935)
State is out of distribution
Projection step: 0, Loss: 234.58065795898438
Projection step: 1, Loss: 240.1919403076172
Projection step: 2, Loss: 206.7357177734375
Projection step: 3, Loss: 223.5619354248047
Projection step: 4, Loss: 225.09072875976562
Projection step: 5, Loss: 234.0938720703125
Projection step: 6, Loss: 211.5400390625
Projection step: 7, Loss: 239.87954711914062
Projection step: 8, Loss: 229.27976989746094
Projection step: 9, Loss: 226.8567657470703
Projection step: 10, Loss: 231.7697296142578
Projection step: 11, Loss: 219.10104370117188
Projection step: 12, Loss: 220.23638916015625
Projection step: 13, Loss: 208.98065185546875
Projection step: 14, Loss: 217.46041870117188
Projection step: 15, Loss: 208.60047912597656
Projection step: 16, Loss: 243.63661193847656
Projection step: 17, Loss: 202.7903289794922
Projection step: 18, Loss: 220.22999572753906
Projection step: 19, Loss: 214.7108612060547
Projection step: 20, Loss: 203.99391174316406
Projection step: 21, Loss: 230.22067260742188
Projection step: 22, Loss: 202.98153686523438
Projection step: 23, Loss: 239.95419311523438
Projection step: 24, Loss: 220.05648803710938
Final likelihood: tensor([-180.4121, -200.3312, -170.4200, -245.3507, -222.8756, -206.3705,
        -307.4636, -268.0434, -177.1445, -182.2934, -181.4116, -183.0995,
        -178.5274, -181.5119, -257.9778, -188.4643])
Final projection likelihood: -208.2311
1 mode projection failed, trying anyway
New goal: tensor([-0.1043,  0.5896,  0.2849,  1.0388,  0.0415,  0.4646,  1.0151,  1.0774,
         1.4128,  0.4185,  0.0721,  1.1642,  0.2082, -0.0815,  0.1438],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 24
Loaded trajectory sampler
Current yaw: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
Current yaw: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
1 turn
Sampling time 3.6418680520146154
tensor([ 0.1545,  0.5737,  0.6105,  0.6303, -0.1181,  0.5273,  0.9451,  0.8433,
         1.2278,  0.2957,  0.2758,  1.1234, -0.0024,  0.0146, -0.0302, -0.0180],
       device='cuda:1')
Original likelihood: -123.70217895507812
Adjusted likelihood: -123.70217895507812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5037)
Solve time for step 1 14.295391759020276
Current ori: tensor([-0.0024,  0.0146, -0.0302], device='cuda:1')
Middle force: tensor([1.4248, 1.4215, 1.2440, 0.5302, 0.5439, 1.1432, 1.5972, 0.6833, 0.5992,
        0.4921, 0.5636, 0.5963], device='cuda:1')
Thumb force: tensor([1.7481, 1.1990, 2.1902, 0.6509, 0.5585, 0.5490, 0.6029, 0.5371, 0.5952,
        0.6374, 0.5969, 0.5875], device='cuda:1')
Index force: tensor([0.9657, 0.6339, 0.5635, 0.5823, 0.6734, 0.6125, 0.5045, 0.7087, 0.5520,
        0.7456, 0.6018, 0.6488], device='cuda:1')
Storing NORMAL transition: reward=-0.1116 (scaled=-0.1116), steps=1
Reward stats updated: mean 0.0153 -> 0.0150, std: 0.0883
Collected 376 transitions for RL
SAC Update 1/5: Actor Loss=-0.0098, Q1 Loss=1.2549, Q2 Loss=1.2549, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5474
SAC Update 2/5: Actor Loss=-0.0096, Q1 Loss=0.9457, Q2 Loss=0.9457, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5039
SAC Update 3/5: Actor Loss=-0.0134, Q1 Loss=1.2756, Q2 Loss=1.2756, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1190
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=0.9096, Q2 Loss=0.9096, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2086
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8979, Q2 Loss=0.8979, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6357

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (41.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010027
Q1 loss: 1.056731
Q2 loss: 1.056731
Current threshold: -149.5235
Global Scale Offset: 2771.6423
Reward stats: mean=0.0150, std=0.0883, count=376
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.0567, Q2 Loss: 1.0567, Entropy: 0.6930, Mean TD Error: 0.6029, Threshold: -149.5235
tensor([ 0.1026,  0.6166,  0.5428,  0.5410, -0.1462,  0.5612,  0.8252,  0.9178,
         1.2585,  0.1895,  0.3465,  1.1679,  0.0051,  0.0310,  0.0809, -0.3983],
       device='cuda:1')
Original likelihood: -161.1905517578125
Adjusted likelihood: -161.1905517578125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4983)
Solve time for step 2 5.5005673979758285
Current ori: tensor([0.0051, 0.0310, 0.0809], device='cuda:1')
Middle force: tensor([0.5778, 1.2106, 0.5696, 1.1585, 0.6443, 0.5379, 0.5288, 0.5127, 0.8658,
        0.6944, 0.5414], device='cuda:1')
Thumb force: tensor([0.8814, 0.7787, 1.0377, 0.9954, 0.6398, 0.5195, 0.8426, 0.5319, 0.5273,
        0.6930, 0.6180], device='cuda:1')
Index force: tensor([0.6040, 0.5486, 0.5705, 0.8048, 0.5348, 1.0205, 0.9519, 0.5641, 0.5923,
        0.7537, 0.5860], device='cuda:1')
Storing NORMAL transition: reward=0.1468 (scaled=0.1468), steps=1
Reward stats updated: mean 0.0150 -> 0.0153, std: 0.0884
Collected 377 transitions for RL
SAC Update 1/5: Actor Loss=-0.0131, Q1 Loss=1.3002, Q2 Loss=1.3002, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5663
SAC Update 2/5: Actor Loss=-0.0136, Q1 Loss=2.6320, Q2 Loss=2.6320, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4684
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.8609, Q2 Loss=0.8609, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2994
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.9154, Q2 Loss=0.9154, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1795
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=1.1699, Q2 Loss=1.1699, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9810

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.0%)
Q1 update: 0.06s (19.3%)
Q2 update: 0.06s (19.6%)
Actor update: 0.13s (43.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010337
Q1 loss: 1.375679
Q2 loss: 1.375679
Current threshold: -149.5232
Global Scale Offset: 2782.1481
Reward stats: mean=0.0153, std=0.0884, count=377
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.3757, Q2 Loss: 1.3757, Entropy: 0.6931, Mean TD Error: 1.2989, Threshold: -149.5232
tensor([ 0.1004,  0.6453,  0.5014,  0.5401, -0.1490,  0.5296,  0.8401,  0.9929,
         1.2561,  0.2081,  0.3578,  1.0830, -0.0041,  0.0309, -0.0661, -0.2199],
       device='cuda:1')
Original likelihood: -151.59512329101562
Adjusted likelihood: -151.59512329101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4997)
Solve time for step 3 5.232662067981437
Current ori: tensor([-0.0041,  0.0309, -0.0661], device='cuda:1')
Middle force: tensor([1.1907, 0.5655, 1.1430, 0.6399, 0.5359, 0.5216, 0.5118, 0.8542, 0.6888,
        0.5388], device='cuda:1')
Thumb force: tensor([0.7666, 1.0215, 0.9782, 0.6354, 0.5173, 0.8456, 0.5286, 0.5253, 0.6832,
        0.6133], device='cuda:1')
Index force: tensor([0.5435, 0.5654, 0.7910, 0.5320, 1.0030, 0.9473, 0.5619, 0.5879, 0.7466,
        0.5828], device='cuda:1')
Storing NORMAL transition: reward=0.0171 (scaled=0.0171), steps=1
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0883
Collected 378 transitions for RL
SAC Update 1/5: Actor Loss=-0.0091, Q1 Loss=0.9211, Q2 Loss=0.9211, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6306
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=1.0079, Q2 Loss=1.0079, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4177
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.0421, Q2 Loss=1.0421, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6262
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.7582, Q2 Loss=0.7582, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4610
SAC Update 5/5: Actor Loss=-0.0098, Q1 Loss=1.0032, Q2 Loss=1.0032, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6891

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.6%)
Q1 update: 0.04s (19.9%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008873
Q1 loss: 0.946500
Q2 loss: 0.946500
Current threshold: -149.5232
Global Scale Offset: 2796.4467
Reward stats: mean=0.0153, std=0.0883, count=378
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9465, Q2 Loss: 0.9465, Entropy: 0.6931, Mean TD Error: 0.9649, Threshold: -149.5232
tensor([ 0.0849,  0.6828,  0.3930,  0.6151, -0.1472,  0.5134,  0.8408,  0.9847,
         1.2296,  0.2793,  0.3538,  1.0845, -0.0056,  0.0371, -0.0837, -0.1904],
       device='cuda:1')
Original likelihood: -170.80477905273438
Adjusted likelihood: -170.80477905273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4970)
Solve time for step 4 5.024711548991036
Current ori: tensor([-0.0056,  0.0371, -0.0837], device='cuda:1')
Middle force: tensor([1.7579, 0.5599, 1.2875, 0.5068, 1.0807, 0.5904, 0.5310, 0.5065, 0.6022],
       device='cuda:1')
Thumb force: tensor([1.3924, 0.5450, 0.7934, 0.5810, 1.2408, 1.8326, 0.5606, 0.5851, 0.5558],
       device='cuda:1')
Index force: tensor([0.5251, 0.5674, 0.6266, 0.7226, 0.5889, 0.5557, 0.5343, 0.7315, 0.5914],
       device='cuda:1')
Storing NORMAL transition: reward=0.2442 (scaled=0.2442), steps=1
Reward stats updated: mean 0.0153 -> 0.0159, std: 0.0890
Collected 379 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=1.0602, Q2 Loss=1.0602, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8505
SAC Update 2/5: Actor Loss=-0.0133, Q1 Loss=1.4266, Q2 Loss=1.4266, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7681
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.2956, Q2 Loss=1.2956, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9538
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=1.0541, Q2 Loss=1.0541, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6533
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.9531, Q2 Loss=0.9531, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2833

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.06s (20.6%)
Actor update: 0.11s (41.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009959
Q1 loss: 1.157921
Q2 loss: 1.157921
Current threshold: -149.5229
Global Scale Offset: 2812.3888
Reward stats: mean=0.0159, std=0.0890, count=379
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.1579, Q2 Loss: 1.1579, Entropy: 0.6931, Mean TD Error: 1.3018, Threshold: -149.5229
tensor([-0.0143,  0.6338,  0.3654,  0.6224, -0.1406,  0.4868,  0.8541,  1.1018,
         1.3090,  0.2707,  0.3430,  0.8635, -0.0260,  0.0329, -0.3303,  0.3087],
       device='cuda:1')
Original likelihood: -138.75137329101562
Adjusted likelihood: -138.75137329101562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5015)
State is out of distribution
Projection step: 0, Loss: 141.96771240234375
Projection step: 1, Loss: 148.24545288085938
Projection step: 2, Loss: 145.18325805664062
Projection step: 3, Loss: 146.37551879882812
Projection step: 4, Loss: 131.27560424804688
Projection step: 5, Loss: 128.10284423828125
Projection step: 6, Loss: 122.80944061279297
Projection step: 7, Loss: 131.1612548828125
Projection step: 8, Loss: 124.17788696289062
Projection step: 9, Loss: 121.52843475341797
Projection step: 10, Loss: 114.20904541015625
Projection step: 11, Loss: 114.85044860839844
Projection step: 12, Loss: 103.77963256835938
Final likelihood: tensor([ -98.3476,  -94.8632, -122.1491,  -99.1133,  -94.7455, -105.8983,
        -113.9946,  -91.2327, -103.8890,  -96.5128, -107.4012, -110.9611,
        -112.1924, -117.7898,  -94.8215,  -96.5621])
Final projection likelihood: -103.7796
1 mode projection succeeded
New goal: tensor([ 0.0062,  0.6030,  0.3644,  0.6723, -0.0876,  0.4576,  0.8155,  1.0259,
         1.3340,  0.2261,  0.2729,  0.9029, -0.0306,  0.0213, -0.4965],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -132.40603637695312
Adjusted likelihood: -132.40603637695312
Likelihood residual: 0.0
Original likelihood: -125.42520141601562
Adjusted likelihood: -125.42520141601562
Likelihood residual: 0.0
{'index': 125.42520141601562, 'thumb_middle': 132.40603637695312}
Current yaw: tensor([-0.0260,  0.0329, -0.3303], device='cuda:1')
2 index
tensor([-0.0143,  0.6338,  0.3654,  0.6224, -0.1406,  0.4868,  0.8541,  1.1018,
         1.3090,  0.2707,  0.3430,  0.8635, -0.0260,  0.0329, -0.3303,  0.3087],
       device='cuda:1')
Solve time for step 1 10.573226315958891
Current ori: tensor([-0.0260,  0.0329, -0.3303], device='cuda:1')
Middle force: tensor([0.5454, 0.5737, 0.5024, 0.5421], device='cuda:1')
Thumb force: tensor([0.5533, 0.5199, 0.5601, 0.5681], device='cuda:1')
tensor([ 0.0296,  0.5552,  0.3209,  0.6413, -0.1282,  0.5025,  0.8584,  1.0579,
         1.3488,  0.2107,  0.3088,  0.8474, -0.0402,  0.0272, -0.3460, -0.3550],
       device='cuda:1')
Solve time for step 2 4.23989317700034
Current ori: tensor([-0.0402,  0.0272, -0.3460], device='cuda:1')
Middle force: tensor([0.5707, 0.5020, 0.5404], device='cuda:1')
Thumb force: tensor([0.5174, 0.5572, 0.5655], device='cuda:1')
tensor([ 0.0329,  0.5541,  0.3218,  0.6464, -0.1226,  0.5048,  0.8657,  1.0628,
         1.3649,  0.1856,  0.2721,  0.8888, -0.0425,  0.0228, -0.3626, -0.5235],
       device='cuda:1')
Solve time for step 3 3.9575740640284494
Current ori: tensor([-0.0425,  0.0228, -0.3626], device='cuda:1')
Middle force: tensor([0.5017, 0.5377], device='cuda:1')
Thumb force: tensor([0.5498, 0.5618], device='cuda:1')
tensor([ 0.0295,  0.5538,  0.3199,  0.6477, -0.1202,  0.5195,  0.8552,  1.0385,
         1.3477,  0.2201,  0.2752,  0.8878, -0.0524,  0.0229, -0.3640, -0.4306],
       device='cuda:1')
Solve time for step 4 4.063459129014518
Current ori: tensor([-0.0524,  0.0229, -0.3640], device='cuda:1')
Middle force: tensor([0.5350], device='cuda:1')
Thumb force: tensor([0.5520], device='cuda:1')
Storing RECOVERY transition: reward=0.0322 (scaled=0.0081), steps=4
Reward stats updated: mean 0.0159 -> 0.0159, std: 0.0889
Collected 380 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=1.0558, Q2 Loss=1.0558, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0954
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.6934, Q2 Loss=0.6934, Entropy=0.6931, Time=0.28sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1252
SAC Update 3/5: Actor Loss=-0.0115, Q1 Loss=1.5201, Q2 Loss=1.5201, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5380
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=1.0486, Q2 Loss=1.0486, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5559
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=1.9177, Q2 Loss=1.9177, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5989

------ SAC Update Summary (5 iterations) ------
Total time: 0.49s, Avg iteration: 0.10s
Sampling: 0.00s (0.3%)
Target Q: 0.04s (9.0%)
Q1 update: 0.05s (10.6%)
Q2 update: 0.05s (10.4%)
Actor update: 0.33s (68.2%)
Target update: 0.00s (0.7%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008505
Q1 loss: 1.247129
Q2 loss: 1.247129
Current threshold: -149.5226
Global Scale Offset: 2829.8236
Reward stats: mean=0.0159, std=0.0889, count=380
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 1.2471, Q2 Loss: 1.2471, Entropy: 0.6931, Mean TD Error: 2.1827, Threshold: -149.5226
Original likelihood: -113.0024642944336
Adjusted likelihood: -113.0024642944336
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5051)
State is out of distribution
Projection step: 0, Loss: 114.22267150878906
Projection step: 1, Loss: 105.40314483642578
Projection step: 2, Loss: 97.08883666992188
Final likelihood: tensor([ -99.3368,  -97.3280,  -94.6580,  -97.2512,  -95.2125,  -90.7010,
         -98.1195,  -93.4863,  -98.0019, -102.4456,  -98.8805,  -96.4721,
         -98.8219,  -94.2735,  -96.2111, -102.2213])
Final projection likelihood: -97.0888
1 mode projection succeeded
New goal: tensor([-0.0053,  0.6145,  0.3577,  0.6787, -0.1028,  0.5099,  0.8432,  1.0177,
         1.3685,  0.1788,  0.2359,  0.9164, -0.0569,  0.0189, -0.3000],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -122.03173828125
Adjusted likelihood: -122.03173828125
Likelihood residual: 0.0
Original likelihood: -116.47120666503906
Adjusted likelihood: -116.47120666503906
Likelihood residual: 0.0
{'index': 116.47120666503906, 'thumb_middle': 122.03173828125}
Current yaw: tensor([-0.0568,  0.0197, -0.3681], device='cuda:1')
3 index
tensor([-0.0098,  0.6165,  0.3632,  0.6718, -0.1146,  0.5288,  0.8491,  1.0314,
         1.3628,  0.1947,  0.2516,  0.9048, -0.0568,  0.0197, -0.3681, -0.3696],
       device='cuda:1')
Solve time for step 1 11.069929543009493
Current ori: tensor([-0.0568,  0.0197, -0.3681], device='cuda:1')
Middle force: tensor([0.5416, 0.5040, 0.5703, 0.5002], device='cuda:1')
Thumb force: tensor([0.5657, 0.5015, 0.5373, 0.5923], device='cuda:1')
tensor([ 0.0185,  0.5584,  0.3141,  0.6512, -0.1013,  0.5379,  0.8504,  1.0153,
         1.3800,  0.1815,  0.2173,  0.9141, -0.0748,  0.0178, -0.4072, -0.2312],
       device='cuda:1')
Solve time for step 2 4.06765332899522
Current ori: tensor([-0.0748,  0.0178, -0.4072], device='cuda:1')
Middle force: tensor([0.5035, 0.5664, 0.5001], device='cuda:1')
Thumb force: tensor([0.5012, 0.5355, 0.5904], device='cuda:1')
tensor([ 0.0171,  0.5608,  0.3097,  0.6508, -0.1136,  0.5467,  0.8443,  1.0121,
         1.3954,  0.1803,  0.2102,  0.9275, -0.0974,  0.0323, -0.4187,  0.1776],
       device='cuda:1')
Solve time for step 3 4.077383448020555
Current ori: tensor([-0.0974,  0.0323, -0.4187], device='cuda:1')
Middle force: tensor([0.5522, 0.5699], device='cuda:1')
Thumb force: tensor([0.5425, 0.5852], device='cuda:1')
tensor([ 0.0132,  0.5630,  0.3100,  0.6501, -0.1110,  0.5494,  0.8427,  1.0071,
         1.3847,  0.1944,  0.2036,  0.9538, -0.0962,  0.0298, -0.4100,  0.9095],
       device='cuda:1')
Solve time for step 4 4.116870124998968
Current ori: tensor([-0.0962,  0.0298, -0.4100], device='cuda:1')
Middle force: tensor([0.5000], device='cuda:1')
Thumb force: tensor([0.5773], device='cuda:1')
Storing RECOVERY transition: reward=0.0576 (scaled=0.0144), steps=4
Reward stats updated: mean 0.0159 -> 0.0159, std: 0.0887
Collected 381 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.2127, Q2 Loss=1.2127, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5919
SAC Update 2/5: Actor Loss=-0.0128, Q1 Loss=1.5265, Q2 Loss=1.5265, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1857
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=4.1090, Q2 Loss=4.1090, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7425
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=1.0659, Q2 Loss=1.0659, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8398
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=0.9792, Q2 Loss=0.9792, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6758

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010495
Q1 loss: 1.778656
Q2 loss: 1.778656
Current threshold: -149.5222
Global Scale Offset: 2849.1573
Reward stats: mean=0.0159, std=0.0887, count=381
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.7787, Q2 Loss: 1.7787, Entropy: 0.6931, Mean TD Error: 1.4071, Threshold: -149.5222
Original likelihood: -171.72976684570312
Adjusted likelihood: -171.72976684570312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4969)
State is out of distribution
Projection step: 0, Loss: 174.70571899414062
Projection step: 1, Loss: 195.67037963867188
Projection step: 2, Loss: 174.1481475830078
Projection step: 3, Loss: 170.2191619873047
Projection step: 4, Loss: 180.82083129882812
Projection step: 5, Loss: 173.6602020263672
Projection step: 6, Loss: 169.51895141601562
Projection step: 7, Loss: 173.11642456054688
Projection step: 8, Loss: 164.0928192138672
Projection step: 9, Loss: 157.0252685546875
Projection step: 10, Loss: 172.5524444580078
Projection step: 11, Loss: 181.1287384033203
Projection step: 12, Loss: 164.30221557617188
Projection step: 13, Loss: 166.01910400390625
Projection step: 14, Loss: 149.59222412109375
Projection step: 15, Loss: 153.35552978515625
Projection step: 16, Loss: 147.10781860351562
Projection step: 17, Loss: 162.7069854736328
Projection step: 18, Loss: 139.2528839111328
Projection step: 19, Loss: 151.32945251464844
Projection step: 20, Loss: 162.70492553710938
Projection step: 21, Loss: 173.00875854492188
Projection step: 22, Loss: 152.25677490234375
Projection step: 23, Loss: 152.56036376953125
Projection step: 24, Loss: 171.60382080078125
Final likelihood: tensor([-172.3260, -163.0565, -138.5939, -167.5598, -158.6382, -155.7524,
        -155.8203, -158.6473, -132.2752, -160.4341, -123.4870, -152.3585,
        -131.6381, -121.9640, -129.8254, -127.8698])
Final projection likelihood: -146.8904
1 mode projection succeeded
New goal: tensor([ 0.0225,  0.6265,  0.3378,  0.6813, -0.0575,  0.4995,  0.7581,  0.9763,
         1.3718,  0.2512,  0.1870,  0.9163, -0.1118,  0.0277, -0.1606],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -193.5557861328125
Adjusted likelihood: -193.5557861328125
Likelihood residual: 0.0
Original likelihood: -206.4664306640625
Adjusted likelihood: -206.4664306640625
Likelihood residual: 0.0
{'index': 206.4664306640625, 'thumb_middle': 193.5557861328125}
Current yaw: tensor([-0.1178,  0.0404, -0.4384], device='cuda:1')
4 thumb_middle
tensor([-0.0243,  0.6190,  0.3485,  0.6737, -0.1122,  0.5530,  0.8389,  1.0027,
         1.3953,  0.1981,  0.1899,  0.9735, -0.1178,  0.0404, -0.4384,  1.0262],
       device='cuda:1')
Solve time for step 1 9.294818987953477
Current ori: tensor([-0.1178,  0.0404, -0.4384], device='cuda:1')
Index force: tensor([0.5348, 0.5891, 0.5845, 0.6041], device='cuda:1')
tensor([-0.0358,  0.6521,  0.3530,  0.6806, -0.1546,  0.4999,  0.7413,  0.9602,
         1.3390,  0.2194,  0.1412,  0.9203, -0.2844,  0.1061, -0.4384,  0.5966],
       device='cuda:1')
Solve time for step 2 3.7173640379915014
Current ori: tensor([-0.2844,  0.1061, -0.4384], device='cuda:1')
Index force: tensor([0.5846, 0.5853, 0.5791], device='cuda:1')
tensor([-0.0717,  0.7434,  0.4031,  0.7048, -0.1328,  0.5257,  0.7546,  0.9565,
         1.3687,  0.2249,  0.1584,  0.9131, -0.6909,  0.2436, -0.4384,  1.8308],
       device='cuda:1')
Solve time for step 3 3.5519661869620904
Current ori: tensor([-0.6909,  0.2436, -0.4384], device='cuda:1')
Index force: tensor([0.6256, 0.5000], device='cuda:1')
tensor([-0.3345,  0.9387,  0.5688,  0.8245, -0.1762,  0.5733,  0.7360,  0.9321,
         1.4426,  0.2645,  0.1899,  0.9262, -1.4340,  0.3873, -0.4383,  2.8278],
       device='cuda:1')
Solve time for step 4 3.2861996379797347
Current ori: tensor([-1.4340,  0.3873, -0.4383], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-1.7854 (scaled=-0.4463), steps=4
Reward stats updated: mean 0.0159 -> 0.0147, std: 0.0917
Collected 382 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.7745, Q2 Loss=0.7745, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3210
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=0.9873, Q2 Loss=0.9873, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6203
SAC Update 3/5: Actor Loss=-0.0122, Q1 Loss=1.1665, Q2 Loss=1.1665, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2337
SAC Update 4/5: Actor Loss=-0.0115, Q1 Loss=1.3854, Q2 Loss=1.3854, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2264
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=0.8916, Q2 Loss=0.8916, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4431

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (17.8%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (41.0%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010024
Q1 loss: 1.041082
Q2 loss: 1.041082
Current threshold: -149.5218
Global Scale Offset: 2866.7250
Reward stats: mean=0.0147, std=0.0917, count=382
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.0411, Q2 Loss: 1.0411, Entropy: 0.6930, Mean TD Error: 0.5689, Threshold: -149.5218
Original likelihood: -2634.5205078125
Adjusted likelihood: -2634.5205078125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1931)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 25
Loaded trajectory sampler
Current yaw: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
Current yaw: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
1 turn
Sampling time 3.6541919019655325
tensor([ 1.4706e-01,  5.8385e-01,  6.1052e-01,  5.8761e-01, -1.0815e-01,
         5.1628e-01,  8.9838e-01,  9.3001e-01,  1.2386e+00,  2.5202e-01,
         2.4139e-01,  1.2330e+00, -6.7404e-04,  1.3941e-02, -3.5587e-02,
         4.5237e-01], device='cuda:1')
Original likelihood: -114.22747802734375
Adjusted likelihood: -114.22747802734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5049)
Solve time for step 1 13.924277887970675
Current ori: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
Middle force: tensor([1.1304, 1.6767, 0.8166, 0.5138, 0.5699, 0.9305, 1.1492, 0.5072, 0.6896,
        0.5087, 0.5004, 0.5562], device='cuda:1')
Thumb force: tensor([0.9094, 1.5159, 0.5768, 0.5505, 0.5332, 1.2562, 0.6699, 0.5610, 0.6026,
        0.5932, 0.8745, 0.6210], device='cuda:1')
Index force: tensor([0.9351, 1.8542, 0.5615, 0.5886, 0.5915, 0.8269, 0.5473, 0.5744, 0.5988,
        0.6867, 0.7089, 0.5475], device='cuda:1')
Storing NORMAL transition: reward=0.0005 (scaled=0.0005), steps=1
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0916
Collected 383 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=1.2397, Q2 Loss=1.2397, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7130
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8539, Q2 Loss=0.8539, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0722
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=2.4245, Q2 Loss=2.4245, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5237
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.7168, Q2 Loss=0.7168, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2273
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=3.9941, Q2 Loss=3.9941, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9676

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (19.5%)
Q2 update: 0.06s (20.4%)
Actor update: 0.11s (39.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008775
Q1 loss: 1.845795
Q2 loss: 1.845795
Current threshold: -149.5215
Global Scale Offset: 2885.0736
Reward stats: mean=0.0147, std=0.0916, count=383
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.8458, Q2 Loss: 1.8458, Entropy: 0.6931, Mean TD Error: 2.7008, Threshold: -149.5215
tensor([ 0.1930,  0.7191,  0.5325,  0.4394, -0.1532,  0.5823,  0.9398,  0.8320,
         1.2262,  0.2281,  0.2437,  1.1274, -0.0372, -0.0213, -0.0377,  0.4416],
       device='cuda:1')
Original likelihood: -234.16346740722656
Adjusted likelihood: -234.16346740722656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4883)
State is out of distribution
Projection step: 0, Loss: 220.74057006835938
Projection step: 1, Loss: 211.69674682617188
Projection step: 2, Loss: 215.99046325683594
Projection step: 3, Loss: 201.78707885742188
Projection step: 4, Loss: 193.37806701660156
Projection step: 5, Loss: 176.86700439453125
Projection step: 6, Loss: 169.19021606445312
Projection step: 7, Loss: 162.1756134033203
Projection step: 8, Loss: 153.21719360351562
Projection step: 9, Loss: 145.47726440429688
Projection step: 10, Loss: 135.1855926513672
Projection step: 11, Loss: 132.00897216796875
Projection step: 12, Loss: 129.03424072265625
Projection step: 13, Loss: 126.1165771484375
Projection step: 14, Loss: 124.10130310058594
Projection step: 15, Loss: 118.90985107421875
Projection step: 16, Loss: 112.66556549072266
Projection step: 17, Loss: 105.89744567871094
Projection step: 18, Loss: 100.06597137451172
Final likelihood: tensor([ -89.8440, -124.7182,  -96.3340,  -98.5894,  -87.9398, -101.8124,
         -96.0943, -103.1376, -123.5583,  -99.8572,  -92.0124,  -97.8516,
         -97.1001, -103.8326,  -93.2867,  -95.0870])
Final projection likelihood: -100.0660
1 mode projection succeeded
New goal: tensor([ 0.1313,  0.6798,  0.4770,  0.5014, -0.0771,  0.5690,  0.9289,  0.8487,
         1.3170,  0.2750,  0.1650,  1.0930, -0.0358, -0.0123, -2.5799],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0067]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -136.7371063232422
Adjusted likelihood: -136.7371063232422
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 136.7371063232422}
Current yaw: tensor([-0.0372, -0.0213, -0.0377], device='cuda:1')
2 thumb_middle
tensor([ 0.1930,  0.7191,  0.5325,  0.4394, -0.1532,  0.5823,  0.9398,  0.8320,
         1.2262,  0.2281,  0.2437,  1.1274, -0.0372, -0.0213, -0.0377,  0.4416],
       device='cuda:1')
Solve time for step 1 8.914900820993353
Current ori: tensor([-0.0372, -0.0213, -0.0377], device='cuda:1')
Index force: tensor([0.5660, 0.6017, 0.6017, 0.5996], device='cuda:1')
tensor([ 0.1510,  0.7123,  0.4804,  0.4727, -0.2001,  0.5276,  0.8880,  0.8222,
         1.2670,  0.2506,  0.1065,  1.0686, -0.0342,  0.0051, -0.0379,  0.3936],
       device='cuda:1')
Solve time for step 2 3.582668489019852
Current ori: tensor([-0.0342,  0.0051, -0.0379], device='cuda:1')
Index force: tensor([0.5931, 0.5955, 0.5941], device='cuda:1')
tensor([ 0.1451,  0.7130,  0.4712,  0.4759, -0.2065,  0.5289,  0.8844,  0.8222,
         1.2832,  0.2543,  0.0892,  1.0623, -0.0341,  0.0089, -0.0379,  0.3860],
       device='cuda:1')
Solve time for step 3 3.5176434249733575
Current ori: tensor([-0.0341,  0.0089, -0.0379], device='cuda:1')
Index force: tensor([0.5878, 0.5888], device='cuda:1')
tensor([ 0.1645,  0.7167,  0.4822,  0.4933, -0.1980,  0.5365,  0.8884,  0.8253,
         1.2804,  0.2557,  0.0788,  1.0564, -0.0336, -0.0038, -0.0379,  0.4178],
       device='cuda:1')
Solve time for step 4 3.392538360960316
Current ori: tensor([-0.0336, -0.0038, -0.0379], device='cuda:1')
Index force: tensor([0.5738], device='cuda:1')
Storing RECOVERY transition: reward=0.0080 (scaled=0.0080), steps=1
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0915
Collected 384 transitions for RL
SAC Update 1/5: Actor Loss=-0.0119, Q1 Loss=1.2652, Q2 Loss=1.2652, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8403
SAC Update 2/5: Actor Loss=-0.0129, Q1 Loss=1.8148, Q2 Loss=1.8148, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6712
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.7657, Q2 Loss=0.7657, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6035
SAC Update 4/5: Actor Loss=-0.0134, Q1 Loss=1.5715, Q2 Loss=1.5715, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1480
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=0.9399, Q2 Loss=0.9399, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3575

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011175
Q1 loss: 1.271427
Q2 loss: 1.271427
Current threshold: -149.5212
Global Scale Offset: 2897.1366
Reward stats: mean=0.0147, std=0.0915, count=384
----------------------------------------------
SAC Update - Actor Loss: -0.0112, Q1 Loss: 1.2714, Q2 Loss: 1.2714, Entropy: 0.6931, Mean TD Error: 0.9241, Threshold: -149.5212
Original likelihood: -194.38748168945312
Adjusted likelihood: -194.38748168945312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4938)
Current yaw: tensor([-0.0314, -0.0104, -0.0450], device='cuda:1')
3 turn
Sampling time 3.6982123549678363
tensor([ 0.1745,  0.7120,  0.4955,  0.5109, -0.1225,  0.5895,  0.9285,  0.8438,
         1.3369,  0.2744,  0.1265,  1.0855, -0.0314, -0.0104, -0.0450,  0.4450],
       device='cuda:1')
Original likelihood: -166.4791259765625
Adjusted likelihood: -166.4791259765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4977)
State is out of distribution
Projection step: 0, Loss: 156.56832885742188
Projection step: 1, Loss: 169.95462036132812
Projection step: 2, Loss: 148.74298095703125
Projection step: 3, Loss: 168.70387268066406
Projection step: 4, Loss: 147.6793212890625
Projection step: 5, Loss: 140.57383728027344
Projection step: 6, Loss: 127.67975616455078
Projection step: 7, Loss: 138.85479736328125
Projection step: 8, Loss: 126.48372650146484
Projection step: 9, Loss: 127.11799621582031
Projection step: 10, Loss: 124.23207092285156
Projection step: 11, Loss: 121.18609619140625
Projection step: 12, Loss: 126.03166961669922
Projection step: 13, Loss: 116.01109313964844
Projection step: 14, Loss: 118.5556411743164
Projection step: 15, Loss: 116.82717895507812
Projection step: 16, Loss: 109.85877990722656
Projection step: 17, Loss: 101.91051483154297
Final likelihood: tensor([-125.1670,  -70.4294, -121.6313, -112.9507, -110.9613, -105.2210,
        -110.7460,  -68.2560, -117.2809,  -71.3436, -103.4688,  -72.3112,
        -118.3492, -104.7367, -107.1805, -110.5347])
Final projection likelihood: -101.9105
1 mode projection succeeded
New goal: tensor([ 0.1116,  0.6572,  0.4696,  0.5363, -0.0737,  0.5895,  0.9048,  0.8184,
         1.3562,  0.3035,  0.1595,  1.0602, -0.0300, -0.0030, -2.6093],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -140.93943786621094
Adjusted likelihood: -140.93943786621094
Likelihood residual: 0.0
Original likelihood: -118.65736389160156
Adjusted likelihood: -118.65736389160156
Likelihood residual: 0.0
{'index': 118.65736389160156, 'thumb_middle': 140.93943786621094}
Current yaw: tensor([-0.0314, -0.0104, -0.0450], device='cuda:1')
4 index
tensor([ 0.1745,  0.7120,  0.4955,  0.5109, -0.1225,  0.5895,  0.9285,  0.8438,
         1.3369,  0.2744,  0.1265,  1.0855, -0.0314, -0.0104, -0.0450,  0.4450],
       device='cuda:1')
Solve time for step 1 10.53878793399781
Current ori: tensor([-0.0314, -0.0104, -0.0450], device='cuda:1')
Middle force: tensor([0.5788, 0.5054, 0.5058, 0.5498], device='cuda:1')
Thumb force: tensor([0.5342, 0.5484, 0.6104, 0.6135], device='cuda:1')
tensor([ 0.1714,  0.6103,  0.4301,  0.5110, -0.1310,  0.5953,  0.9160,  0.8318,
         1.3433,  0.2758,  0.1456,  1.0462, -0.0389, -0.0026, -0.0527,  1.1221],
       device='cuda:1')
Solve time for step 2 4.128301226999611
Current ori: tensor([-0.0389, -0.0026, -0.0527], device='cuda:1')
Middle force: tensor([0.5048, 0.5051, 0.5466], device='cuda:1')
Thumb force: tensor([0.5420, 0.6052, 0.6071], device='cuda:1')
tensor([ 0.1643,  0.6070,  0.4240,  0.5123, -0.1265,  0.5889,  0.9270,  0.8400,
         1.3375,  0.2807,  0.1380,  1.0624, -0.0350, -0.0070, -0.0604,  1.6916],
       device='cuda:1')
Solve time for step 3 4.190476839954499
Current ori: tensor([-0.0350, -0.0070, -0.0604], device='cuda:1')
Middle force: tensor([0.5744, 0.5523], device='cuda:1')
Thumb force: tensor([0.5200, 0.5525], device='cuda:1')
tensor([ 0.1628,  0.6064,  0.4229,  0.5128, -0.1298,  0.6036,  0.9216,  0.8319,
         1.3411,  0.2750,  0.1337,  1.0547, -0.0406, -0.0087, -0.0546,  2.1085],
       device='cuda:1')
Solve time for step 4 4.034604870015755
Current ori: tensor([-0.0406, -0.0087, -0.0546], device='cuda:1')
Middle force: tensor([0.5410], device='cuda:1')
Thumb force: tensor([0.5921], device='cuda:1')
Storing RECOVERY transition: reward=0.0036 (scaled=0.0036), steps=0
Reward stats updated: mean 0.0147 -> 0.0146, std: 0.0914
Collected 385 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=1.3872, Q2 Loss=1.3872, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0037
SAC Update 2/5: Actor Loss=-0.0095, Q1 Loss=1.2495, Q2 Loss=1.2495, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5148
SAC Update 3/5: Actor Loss=-0.0122, Q1 Loss=1.4447, Q2 Loss=1.4447, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1526
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=0.8824, Q2 Loss=0.8824, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8048
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.8233, Q2 Loss=0.8233, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2435

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.7%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.05s (19.9%)
Actor update: 0.11s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009384
Q1 loss: 1.157404
Q2 loss: 1.157404
Current threshold: -149.5210
Global Scale Offset: 2913.1226
Reward stats: mean=0.0146, std=0.0914, count=385
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.1574, Q2 Loss: 1.1574, Entropy: 0.6930, Mean TD Error: 1.5439, Threshold: -149.5210
Original likelihood: -118.64539337158203
Adjusted likelihood: -118.64539337158203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5042)
State is out of distribution
Projection step: 0, Loss: 123.85646057128906
Projection step: 1, Loss: 105.32601928710938
Projection step: 2, Loss: 109.34363555908203
Projection step: 3, Loss: 97.05909729003906
Final likelihood: tensor([ -94.9012,  -89.7576,  -95.7587,  -94.0899,  -95.8437,  -91.6288,
         -95.1219,  -97.5351,  -97.5244, -107.5024, -107.3964,  -88.2543,
         -94.0746, -102.6010, -102.6124,  -98.3435])
Final projection likelihood: -97.0591
1 mode projection succeeded
New goal: tensor([ 9.9976e-02,  6.5529e-01,  4.6613e-01,  5.3235e-01, -1.1889e-01,
         5.9750e-01,  9.2418e-01,  8.2238e-01,  1.3530e+00,  2.6804e-01,
         1.5449e-01,  1.0744e+00, -4.0930e-02,  6.6660e-04,  1.1008e-01],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -104.72305297851562
Adjusted likelihood: -104.72305297851562
Likelihood residual: 0.0
Original likelihood: -102.08854675292969
Adjusted likelihood: -102.08854675292969
Likelihood residual: 0.0
{'index': 102.08854675292969, 'thumb_middle': 104.72305297851562}
Current yaw: tensor([-0.0413, -0.0012, -0.0492], device='cuda:1')
5 index
tensor([ 1.0150e-01,  6.6635e-01,  4.6748e-01,  5.3566e-01, -1.4005e-01,
         6.0172e-01,  9.1811e-01,  8.3073e-01,  1.3484e+00,  2.6966e-01,
         1.4544e-01,  1.0408e+00, -4.1313e-02, -1.2255e-03, -4.9225e-02,
         2.1994e+00], device='cuda:1')
Solve time for step 1 10.603589835052844
Current ori: tensor([-0.0413, -0.0012, -0.0492], device='cuda:1')
Middle force: tensor([0.5909, 0.5862, 0.5054, 0.5124], device='cuda:1')
Thumb force: tensor([0.5794, 0.5310, 0.5016, 0.5156], device='cuda:1')
tensor([ 0.1502,  0.6011,  0.4202,  0.5125, -0.1388,  0.5949,  0.9281,  0.8345,
         1.3542,  0.2567,  0.1364,  1.0535, -0.0380, -0.0028, -0.0526,  2.5054],
       device='cuda:1')
Solve time for step 2 4.24340175796533
Current ori: tensor([-0.0380, -0.0028, -0.0526], device='cuda:1')
Middle force: tensor([0.5010, 0.5536, 0.5348], device='cuda:1')
Thumb force: tensor([0.5270, 0.6205, 0.6239], device='cuda:1')
tensor([ 0.1498,  0.6012,  0.4193,  0.5111, -0.1255,  0.6042,  0.9290,  0.8270,
         1.3541,  0.2516,  0.1160,  1.0618, -0.0423, -0.0126, -0.0652,  2.6224],
       device='cuda:1')
Solve time for step 3 4.084616247972008
Current ori: tensor([-0.0423, -0.0126, -0.0652], device='cuda:1')
Middle force: tensor([0.5565, 0.5246], device='cuda:1')
Thumb force: tensor([0.5254, 0.5291], device='cuda:1')
tensor([ 0.1467,  0.5996,  0.4184,  0.5099, -0.1356,  0.6090,  0.9326,  0.8313,
         1.3521,  0.2553,  0.1205,  1.0640, -0.0412, -0.0104, -0.0543,  2.5879],
       device='cuda:1')
Solve time for step 4 4.104308190988377
Current ori: tensor([-0.0412, -0.0104, -0.0543], device='cuda:1')
Middle force: tensor([0.5156], device='cuda:1')
Thumb force: tensor([0.5628], device='cuda:1')
Storing RECOVERY transition: reward=0.0078 (scaled=0.0078), steps=0
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0913
Collected 386 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=1.3271, Q2 Loss=1.3271, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9337
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.4055, Q2 Loss=1.4055, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9628
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.0000, Q2 Loss=1.0000, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2972
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=1.4760, Q2 Loss=1.4760, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1630
SAC Update 5/5: Actor Loss=-0.0069, Q1 Loss=0.6756, Q2 Loss=0.6756, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0896

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.3%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.0%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009407
Q1 loss: 1.176832
Q2 loss: 1.176832
Current threshold: -149.5209
Global Scale Offset: 2930.3125
Reward stats: mean=0.0146, std=0.0913, count=386
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.1768, Q2 Loss: 1.1768, Entropy: 0.6931, Mean TD Error: 1.0892, Threshold: -149.5209
Original likelihood: -125.59431457519531
Adjusted likelihood: -125.59431457519531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5033)
Current yaw: tensor([-0.0415, -0.0046, -0.0535], device='cuda:1')
6 turn
Sampling time 3.7114897459978238
tensor([ 0.0922,  0.6616,  0.4651,  0.5320, -0.1436,  0.6047,  0.9320,  0.8282,
         1.3567,  0.2533,  0.1308,  1.0517, -0.0415, -0.0046, -0.0535,  2.5630],
       device='cuda:1')
Original likelihood: -132.1175537109375
Adjusted likelihood: -132.1175537109375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5024)
State is out of distribution
Projection step: 0, Loss: 129.642333984375
Projection step: 1, Loss: 117.31664276123047
Projection step: 2, Loss: 106.6456527709961
Projection step: 3, Loss: 101.40251922607422
Final likelihood: tensor([-101.1315, -102.1527, -101.6036,  -99.4794, -104.6996,  -95.5880,
         -96.0532,  -90.2353, -122.6330,  -94.5360, -106.6688,  -99.0016,
        -102.0459, -103.8758, -103.5947,  -99.1412])
Final projection likelihood: -101.4025
1 mode projection succeeded
New goal: tensor([ 0.0919,  0.6523,  0.4613,  0.5289, -0.1183,  0.6032,  0.9343,  0.8159,
         1.3612,  0.2501,  0.1447,  1.0818, -0.0411, -0.0025,  0.1300],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -119.97217559814453
Adjusted likelihood: -119.97217559814453
Likelihood residual: 0.0
Original likelihood: -130.16824340820312
Adjusted likelihood: -130.16824340820312
Likelihood residual: 0.0
{'index': 130.16824340820312, 'thumb_middle': 119.97217559814453}
Current yaw: tensor([-0.0415, -0.0046, -0.0535], device='cuda:1')
7 thumb_middle
tensor([ 0.0922,  0.6616,  0.4651,  0.5320, -0.1436,  0.6047,  0.9320,  0.8282,
         1.3567,  0.2533,  0.1308,  1.0517, -0.0415, -0.0046, -0.0535,  2.5630],
       device='cuda:1')
Solve time for step 1 9.172460542002227
Current ori: tensor([-0.0415, -0.0046, -0.0535], device='cuda:1')
Index force: tensor([0.5817, 0.5926, 0.5938, 0.5575], device='cuda:1')
tensor([ 0.0897,  0.6577,  0.4706,  0.5273, -0.2205,  0.5781,  0.8965,  0.7910,
         1.3164,  0.2337,  0.0559,  1.0258, -0.0410, -0.0030, -0.0536,  2.5612],
       device='cuda:1')
Solve time for step 2 3.62579933705274
Current ori: tensor([-0.0410, -0.0030, -0.0536], device='cuda:1')
Index force: tensor([0.5847, 0.5876, 0.5528], device='cuda:1')
tensor([ 0.0795,  0.6656,  0.4509,  0.5160, -0.2235,  0.5759,  0.8889,  0.7787,
         1.3219,  0.2310,  0.0420,  1.0482, -0.0437,  0.0038, -0.0536,  2.5413],
       device='cuda:1')
Solve time for step 3 3.456313741975464
Current ori: tensor([-0.0437,  0.0038, -0.0536], device='cuda:1')
Index force: tensor([0.5777, 0.5458], device='cuda:1')
tensor([ 0.0907,  0.6534,  0.4747,  0.5379, -0.2321,  0.5753,  0.9057,  0.8046,
         1.3210,  0.2207,  0.0385,  1.0512, -0.0392, -0.0039, -0.0536,  2.5668],
       device='cuda:1')
Solve time for step 4 3.3720017539453693
Current ori: tensor([-0.0392, -0.0039, -0.0536], device='cuda:1')
Index force: tensor([0.5337], device='cuda:1')
Storing RECOVERY transition: reward=0.0047 (scaled=0.0047), steps=0
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0911
Collected 387 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=2.6223, Q2 Loss=2.6223, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6299
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.0553, Q2 Loss=1.0553, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1279
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.2581, Q2 Loss=1.2581, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8567
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=0.8740, Q2 Loss=0.8740, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7613
SAC Update 5/5: Actor Loss=-0.0136, Q1 Loss=1.5438, Q2 Loss=1.5438, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0400

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.2%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.04s (19.0%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010193
Q1 loss: 1.470703
Q2 loss: 1.470703
Current threshold: -149.5209
Global Scale Offset: 2947.8276
Reward stats: mean=0.0146, std=0.0911, count=387
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.4707, Q2 Loss: 1.4707, Entropy: 0.6931, Mean TD Error: 1.8832, Threshold: -149.5209
Original likelihood: -142.50643920898438
Adjusted likelihood: -142.50643920898438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Current yaw: tensor([-0.0421, -0.0043, -0.0583], device='cuda:1')
8 turn
Sampling time 3.6897391569800675
tensor([ 0.0914,  0.6657,  0.4582,  0.5313, -0.1623,  0.6294,  0.9348,  0.8130,
         1.3715,  0.2442,  0.1067,  1.0684, -0.0421, -0.0043, -0.0583,  2.5694],
       device='cuda:1')
Original likelihood: -134.83419799804688
Adjusted likelihood: -134.83419799804688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5020)
Solve time for step 1 13.910083649971057
Current ori: tensor([-0.0421, -0.0043, -0.0583], device='cuda:1')
Middle force: tensor([0.9020, 0.5738, 0.6493, 0.5988, 0.8567, 0.5625, 0.9329, 1.6277, 0.5073,
        0.5865, 0.5920, 0.5245], device='cuda:1')
Thumb force: tensor([0.6832, 0.9733, 0.5188, 1.1622, 0.5524, 0.7080, 0.5721, 0.7978, 0.5457,
        0.6355, 0.5951, 0.6270], device='cuda:1')
Index force: tensor([1.0401, 0.5272, 0.7948, 0.7510, 0.6615, 0.5928, 0.5076, 0.9706, 0.6144,
        0.5465, 0.6055, 0.6734], device='cuda:1')
Storing NORMAL transition: reward=0.2828 (scaled=0.2828), steps=1
Reward stats updated: mean 0.0146 -> 0.0153, std: 0.0920
Collected 388 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=0.8816, Q2 Loss=0.8816, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4756
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=1.5397, Q2 Loss=1.5397, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6063
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7660, Q2 Loss=0.7660, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3143
SAC Update 4/5: Actor Loss=-0.0130, Q1 Loss=1.9383, Q2 Loss=1.9383, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7856
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=2.6036, Q2 Loss=2.6036, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9538

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009673
Q1 loss: 1.545840
Q2 loss: 1.545840
Current threshold: -149.5207
Global Scale Offset: 2965.9504
Reward stats: mean=0.0153, std=0.0920, count=388
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.5458, Q2 Loss: 1.5458, Entropy: 0.6931, Mean TD Error: 1.4271, Threshold: -149.5207
tensor([ 0.1014,  0.6157,  0.5526,  0.5258, -0.1474,  0.5340,  1.0106,  1.0328,
         1.4437,  0.2169,  0.0728,  0.9773, -0.0312, -0.0115, -0.3417,  2.8825],
       device='cuda:1')
Original likelihood: -148.4297332763672
Adjusted likelihood: -148.4297332763672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5001)
State is out of distribution
Projection step: 0, Loss: 133.81417846679688
Projection step: 1, Loss: 137.71194458007812
Projection step: 2, Loss: 135.93365478515625
Projection step: 3, Loss: 160.6357879638672
Projection step: 4, Loss: 130.30206298828125
Projection step: 5, Loss: 155.69723510742188
Projection step: 6, Loss: 136.8897705078125
Projection step: 7, Loss: 122.83076477050781
Projection step: 8, Loss: 123.46389770507812
Projection step: 9, Loss: 122.99093627929688
Projection step: 10, Loss: 125.58063507080078
Projection step: 11, Loss: 119.49729919433594
Projection step: 12, Loss: 134.0903778076172
Projection step: 13, Loss: 107.86822509765625
Projection step: 14, Loss: 109.66569519042969
Projection step: 15, Loss: 105.15560913085938
Projection step: 16, Loss: 102.8071517944336
Final likelihood: tensor([-116.1208, -105.9225, -129.5804,  -93.5127, -111.0614, -117.2421,
        -119.2374,  -64.7204, -119.5901,  -97.2056,  -83.0909,  -79.6319,
        -107.7963, -100.0044,  -94.4643, -105.7330])
Final projection likelihood: -102.8072
1 mode projection succeeded
New goal: tensor([ 0.0894,  0.5913,  0.5404,  0.5931, -0.0741,  0.5448,  0.9042,  0.9510,
         1.4191,  0.3046,  0.1491,  1.0034, -0.0271, -0.0027, -0.3123],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -108.25125122070312
Adjusted likelihood: -108.25125122070312
Likelihood residual: 0.0
Original likelihood: -143.91429138183594
Adjusted likelihood: -143.91429138183594
Likelihood residual: 0.0
{'index': 143.91429138183594, 'thumb_middle': 108.25125122070312}
Current yaw: tensor([-0.0312, -0.0115, -0.3417], device='cuda:1')
9 thumb_middle
tensor([ 0.1014,  0.6157,  0.5526,  0.5258, -0.1474,  0.5340,  1.0106,  1.0328,
         1.4437,  0.2169,  0.0728,  0.9773, -0.0312, -0.0115, -0.3417,  2.8825],
       device='cuda:1')
Solve time for step 1 9.185929794970434
Current ori: tensor([-0.0312, -0.0115, -0.3417], device='cuda:1')
Index force: tensor([0.5679, 0.5818, 0.5687, 0.5020], device='cuda:1')
tensor([ 0.0944,  0.5904,  0.5487,  0.5900, -0.1855,  0.5041,  0.8722,  0.9462,
         1.3571,  0.2725,  0.0448,  0.9554, -0.0208, -0.0056, -0.3411,  2.8929],
       device='cuda:1')
Solve time for step 2 3.651837650046218
Current ori: tensor([-0.0208, -0.0056, -0.3411], device='cuda:1')
Index force: tensor([0.5051, 0.5558, 0.5737], device='cuda:1')
tensor([ 0.0947,  0.5960,  0.5395,  0.5925, -0.1807,  0.4998,  0.8653,  0.9289,
         1.3692,  0.2897,  0.0325,  0.9419, -0.0218, -0.0058, -0.3411,  2.8925],
       device='cuda:1')
Solve time for step 3 3.389546006976161
Current ori: tensor([-0.0218, -0.0058, -0.3411], device='cuda:1')
Index force: tensor([0.5435, 0.5623], device='cuda:1')
tensor([ 0.1075,  0.5922,  0.5473,  0.6138, -0.1874,  0.5293,  0.8658,  0.9238,
         1.3470,  0.2913,  0.0326,  0.9659, -0.0186, -0.0131, -0.3411,  2.9174],
       device='cuda:1')
Solve time for step 4 3.2603400569641963
Current ori: tensor([-0.0186, -0.0131, -0.3411], device='cuda:1')
Index force: tensor([0.5550], device='cuda:1')
Storing RECOVERY transition: reward=0.0032 (scaled=0.0032), steps=1
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0919
Collected 389 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=0.7845, Q2 Loss=0.7845, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3619
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=0.9637, Q2 Loss=0.9637, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5619
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.1077, Q2 Loss=1.1077, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1259
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.0871, Q2 Loss=1.0871, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2605
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=0.8491, Q2 Loss=0.8491, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5224

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.8%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.4%)
Actor update: 0.09s (37.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009556
Q1 loss: 0.958418
Q2 loss: 0.958418
Current threshold: -149.5207
Global Scale Offset: 2978.2240
Reward stats: mean=0.0152, std=0.0919, count=389
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 0.9584, Q2 Loss: 0.9584, Entropy: 0.6930, Mean TD Error: 0.5665, Threshold: -149.5207
Original likelihood: -145.70082092285156
Adjusted likelihood: -145.70082092285156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Current yaw: tensor([-0.0175,  0.0039, -0.3433], device='cuda:1')
10 turn
Sampling time 3.581094429944642
tensor([ 0.0785,  0.5803,  0.5395,  0.6049, -0.1428,  0.5765,  0.8848,  0.9426,
         1.4382,  0.2765,  0.0943,  0.9749, -0.0175,  0.0039, -0.3433,  2.8796],
       device='cuda:1')
Original likelihood: -139.46621704101562
Adjusted likelihood: -139.46621704101562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5013)
State is out of distribution
Projection step: 0, Loss: 137.29742431640625
Projection step: 1, Loss: 132.05844116210938
Projection step: 2, Loss: 126.30885314941406
Projection step: 3, Loss: 125.52368927001953
Projection step: 4, Loss: 120.36463928222656
Projection step: 5, Loss: 114.62387084960938
Projection step: 6, Loss: 105.09841918945312
Projection step: 7, Loss: 107.67371368408203
Projection step: 8, Loss: 94.73059844970703
Final likelihood: tensor([-119.9879,  -82.1096,  -82.8421,  -89.4685, -102.7271,  -86.9667,
         -92.3838,  -94.4485,  -82.6817,  -89.2050, -103.9049,  -93.2436,
         -94.6685,  -89.3100, -120.5014,  -91.2403])
Final projection likelihood: -94.7306
1 mode projection succeeded
New goal: tensor([ 0.0912,  0.5768,  0.5391,  0.6361, -0.1035,  0.5503,  0.9000,  0.9190,
         1.4035,  0.3037,  0.1486,  1.0211, -0.0172,  0.0088, -0.5975],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -103.22969055175781
Adjusted likelihood: -103.22969055175781
Likelihood residual: 0.0
Original likelihood: -129.92059326171875
Adjusted likelihood: -129.92059326171875
Likelihood residual: 0.0
{'index': 129.92059326171875, 'thumb_middle': 103.22969055175781}
Current yaw: tensor([-0.0175,  0.0039, -0.3433], device='cuda:1')
11 thumb_middle
tensor([ 0.0785,  0.5803,  0.5395,  0.6049, -0.1428,  0.5765,  0.8848,  0.9426,
         1.4382,  0.2765,  0.0943,  0.9749, -0.0175,  0.0039, -0.3433,  2.8796],
       device='cuda:1')
Solve time for step 1 9.072144475008827
Current ori: tensor([-0.0175,  0.0039, -0.3433], device='cuda:1')
Index force: tensor([0.5896, 0.5630, 0.5656, 0.5939], device='cuda:1')
tensor([ 8.1788e-02,  5.8936e-01,  5.2535e-01,  6.1422e-01, -2.0413e-01,
         5.3096e-01,  8.5901e-01,  9.0099e-01,  1.3506e+00,  2.7885e-01,
         5.1852e-02,  9.7249e-01, -1.8731e-02,  2.0879e-03, -3.4330e-01,
         2.8838e+00], device='cuda:1')
Solve time for step 2 3.5240860379999503
Current ori: tensor([-0.0187,  0.0021, -0.3433], device='cuda:1')
Index force: tensor([0.5523, 0.5562, 0.5831], device='cuda:1')
tensor([ 0.0671,  0.5858,  0.5175,  0.6113, -0.2189,  0.5305,  0.8555,  0.8942,
         1.3531,  0.2849,  0.0511,  0.9791, -0.0184,  0.0108, -0.3433,  2.8631],
       device='cuda:1')
Solve time for step 3 3.5699212279869244
Current ori: tensor([-0.0184,  0.0108, -0.3433], device='cuda:1')
Index force: tensor([0.5487, 0.5749], device='cuda:1')
tensor([ 0.0718,  0.5842,  0.5226,  0.6145, -0.2176,  0.5328,  0.8580,  0.8913,
         1.3506,  0.2834,  0.0512,  0.9784, -0.0177,  0.0081, -0.3433,  2.8712],
       device='cuda:1')
Solve time for step 4 3.439129251986742
Current ori: tensor([-0.0177,  0.0081, -0.3433], device='cuda:1')
Index force: tensor([0.5606], device='cuda:1')
Storing RECOVERY transition: reward=0.0010 (scaled=0.0010), steps=0
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0918
Collected 390 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.8733, Q2 Loss=0.8733, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9450
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.3844, Q2 Loss=1.3844, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9132
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=1.2634, Q2 Loss=1.2634, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0105
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=1.3368, Q2 Loss=1.3368, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1952
SAC Update 5/5: Actor Loss=-0.0116, Q1 Loss=1.1325, Q2 Loss=1.1325, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4632

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.5%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010374
Q1 loss: 1.198089
Q2 loss: 1.198089
Current threshold: -149.5206
Global Scale Offset: 2989.5283
Reward stats: mean=0.0152, std=0.0918, count=390
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.1981, Q2 Loss: 1.1981, Entropy: 0.6931, Mean TD Error: 1.3054, Threshold: -149.5206
Original likelihood: -140.56752014160156
Adjusted likelihood: -140.56752014160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5012)
State is out of distribution
Projection step: 0, Loss: 131.771240234375
Projection step: 1, Loss: 122.39602661132812
Projection step: 2, Loss: 118.97708129882812
Projection step: 3, Loss: 114.25930786132812
Projection step: 4, Loss: 114.42036437988281
Projection step: 5, Loss: 112.42922973632812
Projection step: 6, Loss: 104.86502075195312
Final likelihood: tensor([-114.2665,  -93.2426, -106.7928, -102.3760, -103.5276, -112.0956,
        -113.3078, -112.4065,  -94.9936, -109.0840, -106.2543, -116.1833,
         -92.2137, -111.3742,  -95.3048,  -94.4169])
Final projection likelihood: -104.8650
1 mode projection succeeded
New goal: tensor([ 0.0890,  0.5718,  0.5463,  0.6435, -0.1176,  0.5643,  0.9011,  0.8930,
         1.3805,  0.3114,  0.1472,  1.0385, -0.0128,  0.0114, -0.5651],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -121.745849609375
Adjusted likelihood: -121.745849609375
Likelihood residual: 0.0
Original likelihood: -131.45278930664062
Adjusted likelihood: -131.45278930664062
Likelihood residual: 0.0
{'index': 131.45278930664062, 'thumb_middle': 121.745849609375}
Current yaw: tensor([-0.0135,  0.0080, -0.3443], device='cuda:1')
12 thumb_middle
tensor([ 0.0723,  0.5728,  0.5295,  0.6329, -0.1526,  0.5867,  0.8896,  0.9070,
         1.4108,  0.3010,  0.1053,  1.0127, -0.0135,  0.0080, -0.3443,  2.8812],
       device='cuda:1')
Solve time for step 1 8.857295183988754
Current ori: tensor([-0.0135,  0.0080, -0.3443], device='cuda:1')
Index force: tensor([0.5831, 0.5045, 0.6086, 0.6042], device='cuda:1')
tensor([ 8.5628e-02,  5.2849e-01,  5.7843e-01,  6.8218e-01, -2.1546e-01,
         5.4680e-01,  8.5947e-01,  8.7303e-01,  1.3375e+00,  2.9164e-01,
         6.2255e-02,  9.9969e-01,  1.8753e-03,  2.0179e-03, -3.4425e-01,
         2.9295e+00], device='cuda:1')
Solve time for step 2 3.5876856420072727
Current ori: tensor([ 0.0019,  0.0020, -0.3442], device='cuda:1')
Index force: tensor([0.5041, 0.5988, 0.5941], device='cuda:1')
tensor([ 8.2691e-02,  5.3853e-01,  5.7067e-01,  6.6363e-01, -2.2498e-01,
         5.4822e-01,  8.6113e-01,  8.6634e-01,  1.3376e+00,  2.9412e-01,
         6.0106e-02,  1.0010e+00, -2.4092e-03,  3.3652e-03, -3.4425e-01,
         2.9154e+00], device='cuda:1')
Solve time for step 3 3.6528809670126066
Current ori: tensor([-0.0024,  0.0034, -0.3442], device='cuda:1')
Index force: tensor([0.5894, 0.5873], device='cuda:1')
tensor([ 0.0759,  0.5706,  0.5372,  0.6305, -0.2253,  0.5496,  0.8625,  0.8696,
         1.3338,  0.2938,  0.0560,  1.0009, -0.0132,  0.0062, -0.3442,  2.8849],
       device='cuda:1')
Solve time for step 4 3.3755431050085463
Current ori: tensor([-0.0132,  0.0062, -0.3442], device='cuda:1')
Index force: tensor([0.5709], device='cuda:1')
Storing RECOVERY transition: reward=0.0041 (scaled=0.0041), steps=0
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0917
Collected 391 transitions for RL
SAC Update 1/5: Actor Loss=-0.0111, Q1 Loss=1.3884, Q2 Loss=1.3884, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4055
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.7680, Q2 Loss=0.7680, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5919
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=1.6873, Q2 Loss=1.6873, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3947
SAC Update 4/5: Actor Loss=-0.0100, Q1 Loss=2.5411, Q2 Loss=2.5411, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9254
SAC Update 5/5: Actor Loss=-0.0089, Q1 Loss=1.7029, Q2 Loss=1.7029, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9446

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009318
Q1 loss: 1.617526
Q2 loss: 1.617526
Current threshold: -149.5204
Global Scale Offset: 2998.1621
Reward stats: mean=0.0152, std=0.0917, count=391
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.6175, Q2 Loss: 1.6175, Entropy: 0.6931, Mean TD Error: 1.8524, Threshold: -149.5204
Original likelihood: -135.07473754882812
Adjusted likelihood: -135.07473754882812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5019)
State is out of distribution
Projection step: 0, Loss: 130.96157836914062
Projection step: 1, Loss: 123.99317932128906
Projection step: 2, Loss: 120.55946350097656
Projection step: 3, Loss: 114.22303771972656
Projection step: 4, Loss: 117.28160858154297
Projection step: 5, Loss: 108.81776428222656
Projection step: 6, Loss: 100.98958587646484
Final likelihood: tensor([ -79.6732, -105.4117, -107.2964, -107.2670, -108.3203,  -84.1997,
         -95.0638, -110.8157,  -80.0926, -114.3405, -123.1244, -101.5243,
         -89.8379, -112.7223, -113.3790,  -82.7646])
Final projection likelihood: -100.9896
1 mode projection succeeded
New goal: tensor([ 0.0867,  0.5647,  0.5588,  0.6394, -0.1252,  0.5722,  0.9024,  0.8747,
         1.3626,  0.3109,  0.1530,  1.0618, -0.0097,  0.0131, -0.5370],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -134.50534057617188
Adjusted likelihood: -134.50534057617188
Likelihood residual: 0.0
Original likelihood: -125.72516632080078
Adjusted likelihood: -125.72516632080078
Likelihood residual: 0.0
{'index': 125.72516632080078, 'thumb_middle': 134.50534057617188}
Current yaw: tensor([-0.0110,  0.0103, -0.3474], device='cuda:1')
13 index
tensor([ 0.0686,  0.5633,  0.5379,  0.6356, -0.1629,  0.5945,  0.8980,  0.8871,
         1.3943,  0.3078,  0.1149,  1.0351, -0.0110,  0.0103, -0.3474,  2.8830],
       device='cuda:1')
Solve time for step 1 10.616487676976249
Current ori: tensor([-0.0110,  0.0103, -0.3474], device='cuda:1')
Middle force: tensor([0.5636, 0.5223, 0.5033, 0.5327], device='cuda:1')
Thumb force: tensor([0.6183, 0.6211, 0.5246, 0.5637], device='cuda:1')
tensor([ 0.1328,  0.5080,  0.5032,  0.6144, -0.1624,  0.5899,  0.9075,  0.8830,
         1.3914,  0.3122,  0.1158,  1.0367, -0.0100,  0.0096, -0.3499,  1.9872],
       device='cuda:1')
Solve time for step 2 4.261469369987026
Current ori: tensor([-0.0100,  0.0096, -0.3499], device='cuda:1')
Middle force: tensor([0.5886, 0.5894, 0.5498], device='cuda:1')
Thumb force: tensor([0.5974, 0.6008, 0.5604], device='cuda:1')
tensor([ 0.1369,  0.5098,  0.5051,  0.6129, -0.1613,  0.5842,  0.9152,  0.8873,
         1.3898,  0.3138,  0.1126,  1.0442, -0.0078,  0.0080, -0.3535,  1.4000],
       device='cuda:1')
Solve time for step 3 4.001386368996464
Current ori: tensor([-0.0078,  0.0080, -0.3535], device='cuda:1')
Middle force: tensor([0.5171, 0.5008], device='cuda:1')
Thumb force: tensor([0.5151, 0.5175], device='cuda:1')
tensor([ 1.3738e-01,  5.1070e-01,  5.0463e-01,  6.1186e-01, -1.5162e-01,
         5.8226e-01,  9.2470e-01,  8.9369e-01,  1.3847e+00,  3.1582e-01,
         1.0155e-01,  1.0573e+00, -6.0977e-03,  1.6611e-04, -3.6319e-01,
         1.0559e+00], device='cuda:1')
Solve time for step 4 4.024349702056497
Current ori: tensor([-6.0977e-03,  1.6611e-04, -3.6319e-01], device='cuda:1')
Middle force: tensor([0.5313], device='cuda:1')
Thumb force: tensor([0.6005], device='cuda:1')
Storing RECOVERY transition: reward=0.0137 (scaled=0.0137), steps=0
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0916
Collected 392 transitions for RL
SAC Update 1/5: Actor Loss=-0.0116, Q1 Loss=1.4872, Q2 Loss=1.4872, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4209
SAC Update 2/5: Actor Loss=-0.0132, Q1 Loss=1.9448, Q2 Loss=1.9448, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7099
SAC Update 3/5: Actor Loss=-0.0120, Q1 Loss=1.3618, Q2 Loss=1.3618, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0079
SAC Update 4/5: Actor Loss=-0.0120, Q1 Loss=3.0319, Q2 Loss=3.0319, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1400
SAC Update 5/5: Actor Loss=-0.0134, Q1 Loss=1.2887, Q2 Loss=1.2887, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1306

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.012428
Q1 loss: 1.822903
Q2 loss: 1.822903
Current threshold: -149.5203
Global Scale Offset: 3014.4787
Reward stats: mean=0.0152, std=0.0916, count=392
----------------------------------------------
SAC Update - Actor Loss: -0.0124, Q1 Loss: 1.8229, Q2 Loss: 1.8229, Entropy: 0.6930, Mean TD Error: 1.4819, Threshold: -149.5203
Original likelihood: -127.35284423828125
Adjusted likelihood: -127.35284423828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5029)
State is out of distribution
Projection step: 0, Loss: 126.93695831298828
Projection step: 1, Loss: 120.747314453125
Projection step: 2, Loss: 115.6961669921875
Projection step: 3, Loss: 114.26346588134766
Projection step: 4, Loss: 107.45196533203125
Projection step: 5, Loss: 103.35256958007812
Final likelihood: tensor([-111.8909, -118.7109,  -97.9344, -102.1664,  -97.4140,  -80.6762,
         -86.9412,  -79.4465, -105.6689, -109.4723, -113.0687, -105.1920,
        -137.2306, -132.3328,  -91.9921,  -83.5033])
Final projection likelihood: -103.3526
1 mode projection succeeded
New goal: tensor([ 0.0911,  0.5650,  0.5594,  0.6400, -0.1261,  0.5688,  0.9230,  0.8801,
         1.3655,  0.3193,  0.1505,  1.0592, -0.0058,  0.0106, -0.5118],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -121.12879943847656
Adjusted likelihood: -121.12879943847656
Likelihood residual: 0.0
Original likelihood: -124.00729370117188
Adjusted likelihood: -124.00729370117188
Likelihood residual: 0.0
{'index': 124.00729370117188, 'thumb_middle': 121.12879943847656}
Current yaw: tensor([-0.0075,  0.0075, -0.3568], device='cuda:1')
14 thumb_middle
tensor([ 0.0807,  0.5667,  0.5467,  0.6317, -0.1607,  0.5818,  0.9193,  0.8864,
         1.3902,  0.3128,  0.1131,  1.0423, -0.0075,  0.0075, -0.3568,  0.9821],
       device='cuda:1')
Solve time for step 1 9.065360598964617
Current ori: tensor([-0.0075,  0.0075, -0.3568], device='cuda:1')
Index force: tensor([0.5822, 0.5794, 0.5952, 0.5889], device='cuda:1')
tensor([ 0.0842,  0.5613,  0.5537,  0.6396, -0.2347,  0.5499,  0.8834,  0.8630,
         1.3236,  0.2970,  0.0658,  1.0199, -0.0053,  0.0059, -0.3568,  0.9915],
       device='cuda:1')
Solve time for step 2 3.637416814977769
Current ori: tensor([-0.0053,  0.0059, -0.3568], device='cuda:1')
Index force: tensor([0.5698, 0.5853, 0.5792], device='cuda:1')
tensor([ 0.0841,  0.5614,  0.5559,  0.6346, -0.2303,  0.5462,  0.8836,  0.8500,
         1.3293,  0.2999,  0.0532,  1.0209, -0.0058,  0.0059, -0.3568,  0.9894],
       device='cuda:1')
Solve time for step 3 3.585615833988413
Current ori: tensor([-0.0058,  0.0059, -0.3568], device='cuda:1')
Index force: tensor([0.5743, 0.5691], device='cuda:1')
tensor([ 0.0866,  0.5644,  0.5471,  0.6486, -0.2370,  0.5552,  0.8809,  0.8610,
         1.3191,  0.3120,  0.0593,  1.0213, -0.0052,  0.0045, -0.3568,  0.9972],
       device='cuda:1')
Solve time for step 4 3.371955009002704
Current ori: tensor([-0.0052,  0.0045, -0.3568], device='cuda:1')
Index force: tensor([0.5521], device='cuda:1')
Storing RECOVERY transition: reward=0.0201 (scaled=0.0201), steps=0
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0915
Collected 393 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.8860, Q2 Loss=0.8860, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5948
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.8333, Q2 Loss=0.8333, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7532
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8340, Q2 Loss=0.8340, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3243
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8763, Q2 Loss=0.8763, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3237
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=0.9911, Q2 Loss=0.9911, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6838

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.4%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008522
Q1 loss: 0.884145
Q2 loss: 0.884145
Current threshold: -149.5203
Global Scale Offset: 3030.5656
Reward stats: mean=0.0152, std=0.0915, count=393
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.8841, Q2 Loss: 0.8841, Entropy: 0.6931, Mean TD Error: 0.9360, Threshold: -149.5203
Original likelihood: -147.298828125
Adjusted likelihood: -147.298828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5003)
Current yaw: tensor([-0.0064,  0.0101, -0.3632], device='cuda:1')
15 turn
Sampling time 3.6234316710033454
tensor([ 0.0761,  0.5590,  0.5582,  0.6215, -0.1766,  0.5989,  0.9157,  0.8839,
         1.3796,  0.3147,  0.1224,  1.0532, -0.0064,  0.0101, -0.3632,  0.9875],
       device='cuda:1')
Original likelihood: -129.7683563232422
Adjusted likelihood: -129.7683563232422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5026)
Solve time for step 1 14.066728258039802
Current ori: tensor([-0.0064,  0.0101, -0.3632], device='cuda:1')
Middle force: tensor([0.5804, 1.6290, 0.5704, 0.5269, 0.6601, 1.6178, 0.5694, 0.5192, 0.5457,
        0.8968, 0.5370, 0.5726], device='cuda:1')
Thumb force: tensor([0.6998, 0.8984, 0.4936, 0.8542, 0.8235, 1.0223, 0.7173, 0.5934, 1.0193,
        0.5463, 0.6180, 0.6037], device='cuda:1')
Index force: tensor([0.5155, 0.6976, 0.8786, 0.5998, 0.5063, 0.5128, 0.5113, 0.5979, 0.5406,
        0.4974, 0.6349, 0.6741], device='cuda:1')
Storing NORMAL transition: reward=0.0302 (scaled=0.0302), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0913
Collected 394 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.7756, Q2 Loss=0.7756, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3328
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8803, Q2 Loss=0.8803, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5668
SAC Update 3/5: Actor Loss=-0.0131, Q1 Loss=1.2802, Q2 Loss=1.2802, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3412
SAC Update 4/5: Actor Loss=-0.0116, Q1 Loss=2.1315, Q2 Loss=2.1315, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3591
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=0.9549, Q2 Loss=0.9549, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5126

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.0%)
Actor update: 0.11s (41.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009961
Q1 loss: 1.204498
Q2 loss: 1.204498
Current threshold: -149.5203
Global Scale Offset: 3042.0551
Reward stats: mean=0.0152, std=0.0913, count=394
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.2045, Q2 Loss: 1.2045, Entropy: 0.6931, Mean TD Error: 1.0225, Threshold: -149.5203
tensor([ 0.0618,  0.5322,  0.5688,  0.6476, -0.1652,  0.5787,  0.8408,  0.9964,
         1.4311,  0.2389,  0.1294,  1.0110,  0.0018,  0.0192, -0.3937,  1.0110],
       device='cuda:1')
Original likelihood: -132.28558349609375
Adjusted likelihood: -132.28558349609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5023)
Solve time for step 2 5.501496565004345
Current ori: tensor([ 0.0018,  0.0192, -0.3937], device='cuda:1')
Middle force: tensor([1.5331, 0.5904, 0.5216, 0.6438, 1.5376, 0.5560, 0.5163, 0.5425, 0.5316,
        0.5003, 0.5761], device='cuda:1')
Thumb force: tensor([0.8591, 0.5035, 0.8422, 0.8107, 0.9735, 0.7183, 0.5625, 0.9846, 0.9328,
        0.5432, 0.6275], device='cuda:1')
Index force: tensor([0.6760, 0.8574, 0.5880, 0.5035, 0.5151, 0.5000, 0.5610, 0.5357, 0.5441,
        0.7632, 0.5918], device='cuda:1')
Storing NORMAL transition: reward=0.0684 (scaled=0.0684), steps=1
Reward stats updated: mean 0.0152 -> 0.0154, std: 0.0913
Collected 395 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7545, Q2 Loss=0.7545, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2892
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8258, Q2 Loss=0.8258, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4047
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=1.6978, Q2 Loss=1.6978, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1908
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.6953, Q2 Loss=0.6953, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1683
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.5248, Q2 Loss=1.5248, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7891

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008550
Q1 loss: 1.099650
Q2 loss: 1.099650
Current threshold: -149.5201
Global Scale Offset: 3060.9420
Reward stats: mean=0.0154, std=0.0913, count=395
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 1.0997, Q2 Loss: 1.0997, Entropy: 0.6931, Mean TD Error: 1.1684, Threshold: -149.5201
tensor([ 0.0287,  0.5517,  0.5127,  0.6344, -0.1505,  0.4983,  0.9554,  1.0363,
         1.4765,  0.0662,  0.1591,  0.9760,  0.0219,  0.0036, -0.4623,  1.6567],
       device='cuda:1')
Original likelihood: -145.99444580078125
Adjusted likelihood: -145.99444580078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Solve time for step 3 5.214961622026749
Current ori: tensor([ 0.0219,  0.0036, -0.4623], device='cuda:1')
Middle force: tensor([0.6037, 0.5257, 0.6602, 1.5537, 0.5690, 0.5414, 0.5518, 0.8886, 0.5399,
        0.5958], device='cuda:1')
Thumb force: tensor([0.5017, 0.8131, 0.7857, 0.9591, 0.6837, 0.5517, 0.9582, 0.5409, 0.5963,
        0.5682], device='cuda:1')
Index force: tensor([0.8964, 0.5943, 0.5054, 0.5105, 0.5111, 0.5680, 0.5344, 0.5012, 0.6246,
        0.6581], device='cuda:1')
Storing NORMAL transition: reward=-0.0096 (scaled=-0.0096), steps=1
Reward stats updated: mean 0.0154 -> 0.0153, std: 0.0912
Collected 396 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8141, Q2 Loss=0.8141, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7440
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=1.2558, Q2 Loss=1.2558, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1712
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=3.5512, Q2 Loss=3.5512, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7923
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=0.9178, Q2 Loss=0.9178, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6020
SAC Update 5/5: Actor Loss=-0.0129, Q1 Loss=1.7853, Q2 Loss=1.7853, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6167

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009416
Q1 loss: 1.664848
Q2 loss: 1.664848
Current threshold: -149.5198
Global Scale Offset: 3079.9273
Reward stats: mean=0.0153, std=0.0912, count=396
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.6648, Q2 Loss: 1.6648, Entropy: 0.6931, Mean TD Error: 2.1853, Threshold: -149.5198
tensor([ 0.0665,  0.4842,  0.5423,  0.6980, -0.1749,  0.6864,  0.8081,  1.0384,
         1.4140,  0.2187,  0.1446,  0.8987,  0.0342, -0.0152, -0.4538,  1.8586],
       device='cuda:1')
Original likelihood: -209.47048950195312
Adjusted likelihood: -209.47048950195312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4922)
State is out of distribution
Projection step: 0, Loss: 198.04782104492188
Projection step: 1, Loss: 191.9808349609375
Projection step: 2, Loss: 184.40512084960938
Projection step: 3, Loss: 173.65234375
Projection step: 4, Loss: 172.37716674804688
Projection step: 5, Loss: 165.24754333496094
Projection step: 6, Loss: 152.17916870117188
Projection step: 7, Loss: 148.24697875976562
Projection step: 8, Loss: 147.399169921875
Projection step: 9, Loss: 133.7244415283203
Projection step: 10, Loss: 134.27603149414062
Projection step: 11, Loss: 133.61888122558594
Projection step: 12, Loss: 124.97956085205078
Projection step: 13, Loss: 120.93893432617188
Projection step: 14, Loss: 122.11813354492188
Projection step: 15, Loss: 118.63682556152344
Projection step: 16, Loss: 110.81273651123047
Projection step: 17, Loss: 109.01779174804688
Projection step: 18, Loss: 102.65872192382812
Final likelihood: tensor([-101.5077,  -82.0602, -102.3113, -136.1717,  -85.4913, -110.4724,
        -125.3428, -120.9921, -116.3010,  -82.1664,  -92.3685, -108.1898,
         -86.9405, -115.6382,  -90.7954,  -85.7901])
Final projection likelihood: -102.6587
1 mode projection succeeded
New goal: tensor([ 0.0697,  0.5066,  0.6184,  0.7182, -0.0855,  0.5839,  0.8455,  0.8977,
         1.3513,  0.1823,  0.1678,  1.0825,  0.0305, -0.0079, -1.1778],
       device='cuda:1')
tensor([[0.0070]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0064]], device='cuda:1')
Original likelihood: -128.863525390625
Adjusted likelihood: -128.863525390625
Likelihood residual: 0.0
Original likelihood: -182.24713134765625
Adjusted likelihood: -182.24713134765625
Likelihood residual: 0.0
{'index': 182.24713134765625, 'thumb_middle': 128.863525390625}
Current yaw: tensor([ 0.0342, -0.0152, -0.4538], device='cuda:1')
16 thumb_middle
tensor([ 0.0665,  0.4842,  0.5423,  0.6980, -0.1749,  0.6864,  0.8081,  1.0384,
         1.4140,  0.2187,  0.1446,  0.8987,  0.0342, -0.0152, -0.4538,  1.8586],
       device='cuda:1')
Solve time for step 1 8.966277310973965
Current ori: tensor([ 0.0342, -0.0152, -0.4538], device='cuda:1')
Index force: tensor([0.5640, 0.5041, 0.5806, 0.5050], device='cuda:1')
tensor([ 0.0620,  0.4582,  0.6020,  0.7715, -0.1712,  0.5859,  0.7979,  0.9159,
         1.3247,  0.1539,  0.1051,  1.0277,  0.0561, -0.0188, -0.4538,  1.9547],
       device='cuda:1')
Solve time for step 2 3.670572824019473
Current ori: tensor([ 0.0561, -0.0188, -0.4538], device='cuda:1')
Index force: tensor([0.5043, 0.5945, 0.5823], device='cuda:1')
tensor([ 0.0616,  0.4624,  0.6115,  0.7397, -0.1754,  0.5847,  0.8094,  0.8816,
         1.3221,  0.1581,  0.0957,  1.0504,  0.0556, -0.0162, -0.4538,  2.0250],
       device='cuda:1')
Solve time for step 3 3.481362442020327
Current ori: tensor([ 0.0556, -0.0162, -0.4538], device='cuda:1')
Index force: tensor([0.5841, 0.5754], device='cuda:1')
tensor([ 0.0577,  0.4896,  0.5933,  0.6956, -0.1764,  0.5847,  0.8082,  0.8750,
         1.3175,  0.1626,  0.0917,  1.0547,  0.0431, -0.0157, -0.4538,  1.9901],
       device='cuda:1')
Solve time for step 4 3.423265337012708
Current ori: tensor([ 0.0431, -0.0157, -0.4538], device='cuda:1')
Index force: tensor([0.5607], device='cuda:1')
Storing RECOVERY transition: reward=0.0176 (scaled=0.0059), steps=3
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0910
Collected 397 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.7851, Q2 Loss=0.7851, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3389
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.7146, Q2 Loss=0.7146, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4384
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.8733, Q2 Loss=0.8733, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5147
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.9230, Q2 Loss=0.9230, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8420
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=4.8736, Q2 Loss=4.8736, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.2591

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (18.9%)
Actor update: 0.12s (43.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008149
Q1 loss: 1.633917
Q2 loss: 1.633917
Current threshold: -149.5194
Global Scale Offset: 3097.3315
Reward stats: mean=0.0153, std=0.0910, count=397
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.6339, Q2 Loss: 1.6339, Entropy: 0.6931, Mean TD Error: 1.6786, Threshold: -149.5194
Original likelihood: -143.973876953125
Adjusted likelihood: -143.973876953125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5007)
Current yaw: tensor([ 0.0464, -0.0198, -0.4728], device='cuda:1')
17 turn
Sampling time 3.5919032599776983
tensor([ 0.0572,  0.4805,  0.5982,  0.7085, -0.1065,  0.6294,  0.8556,  0.8989,
         1.3801,  0.1859,  0.1479,  1.0889,  0.0464, -0.0198, -0.4728,  2.0233],
       device='cuda:1')
Original likelihood: -141.10491943359375
Adjusted likelihood: -141.10491943359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5011)
State is out of distribution
Projection step: 0, Loss: 149.78524780273438
Projection step: 1, Loss: 139.74725341796875
Projection step: 2, Loss: 134.18743896484375
Projection step: 3, Loss: 133.09170532226562
Projection step: 4, Loss: 124.75739288330078
Projection step: 5, Loss: 124.29193115234375
Projection step: 6, Loss: 117.32295227050781
Projection step: 7, Loss: 122.12644958496094
Projection step: 8, Loss: 110.55433654785156
Projection step: 9, Loss: 112.87983703613281
Projection step: 10, Loss: 111.15479278564453
Projection step: 11, Loss: 102.16000366210938
Final likelihood: tensor([ -96.8330,  -90.6533, -102.9069,  -94.8837, -113.1976,  -99.2699,
         -98.5526, -117.2628,  -86.1995,  -93.6250,  -89.3935, -106.0624,
        -128.4904, -114.2527,  -95.6667, -107.3102])
Final projection likelihood: -102.1600
1 mode projection succeeded
New goal: tensor([ 0.0638,  0.5063,  0.6141,  0.6864, -0.0719,  0.5628,  0.8518,  0.8833,
         1.3426,  0.1880,  0.1677,  1.1329,  0.0437, -0.0154, -1.0509],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0032]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -132.74142456054688
Adjusted likelihood: -132.74142456054688
Likelihood residual: 0.0
Original likelihood: -167.48683166503906
Adjusted likelihood: -167.48683166503906
Likelihood residual: 0.0
{'index': 167.48683166503906, 'thumb_middle': 132.74142456054688}
Current yaw: tensor([ 0.0464, -0.0198, -0.4728], device='cuda:1')
18 thumb_middle
tensor([ 0.0572,  0.4805,  0.5982,  0.7085, -0.1065,  0.6294,  0.8556,  0.8989,
         1.3801,  0.1859,  0.1479,  1.0889,  0.0464, -0.0198, -0.4728,  2.0233],
       device='cuda:1')
Solve time for step 1 8.945240564993583
Current ori: tensor([ 0.0464, -0.0198, -0.4728], device='cuda:1')
Index force: tensor([0.5864, 0.6005, 0.5996, 0.5963], device='cuda:1')
tensor([ 0.0558,  0.4813,  0.6035,  0.6929, -0.1584,  0.5677,  0.8174,  0.8614,
         1.3014,  0.1640,  0.0922,  1.0959,  0.0470, -0.0153, -0.4728,  2.0380],
       device='cuda:1')
Solve time for step 2 3.6526152130099945
Current ori: tensor([ 0.0470, -0.0153, -0.4728], device='cuda:1')
Index force: tensor([0.5947, 0.5961, 0.5930], device='cuda:1')
tensor([ 0.0509,  0.4847,  0.6016,  0.6796, -0.1658,  0.5679,  0.8165,  0.8584,
         1.3036,  0.1649,  0.0847,  1.1015,  0.0441, -0.0131, -0.4728,  2.0209],
       device='cuda:1')
Solve time for step 3 3.5902701599989086
Current ori: tensor([ 0.0441, -0.0131, -0.4728], device='cuda:1')
Index force: tensor([0.5909, 0.5898], device='cuda:1')
tensor([ 0.0576,  0.4885,  0.6026,  0.6792, -0.1630,  0.5712,  0.8202,  0.8591,
         1.3008,  0.1636,  0.0805,  1.1003,  0.0434, -0.0166, -0.4727,  2.0300],
       device='cuda:1')
Solve time for step 4 3.620112921053078
Current ori: tensor([ 0.0434, -0.0166, -0.4727], device='cuda:1')
Index force: tensor([0.5806], device='cuda:1')
Storing RECOVERY transition: reward=-0.0002 (scaled=-0.0002), steps=0
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0909
Collected 398 transitions for RL
SAC Update 1/5: Actor Loss=-0.0118, Q1 Loss=1.4478, Q2 Loss=1.4478, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3474
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=1.3110, Q2 Loss=1.3110, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9121
SAC Update 3/5: Actor Loss=-0.0120, Q1 Loss=1.2203, Q2 Loss=1.2203, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5973
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=0.9929, Q2 Loss=0.9929, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5339
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.0550, Q2 Loss=1.0550, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3820

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.7%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010929
Q1 loss: 1.205402
Q2 loss: 1.205402
Current threshold: -149.5190
Global Scale Offset: 3109.9285
Reward stats: mean=0.0152, std=0.0909, count=398
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.2054, Q2 Loss: 1.2054, Entropy: 0.6930, Mean TD Error: 0.9545, Threshold: -149.5190
Original likelihood: -142.42037963867188
Adjusted likelihood: -142.42037963867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Current yaw: tensor([ 0.0458, -0.0079, -0.4722], device='cuda:1')
19 turn
Sampling time 3.5801514880149625
tensor([ 0.0340,  0.4724,  0.5992,  0.6872, -0.1067,  0.6076,  0.8547,  0.8817,
         1.3651,  0.1888,  0.1478,  1.1419,  0.0458, -0.0079, -0.4722,  1.9902],
       device='cuda:1')
Original likelihood: -129.6729278564453
Adjusted likelihood: -129.6729278564453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5025)
State is out of distribution
Projection step: 0, Loss: 137.68930053710938
Projection step: 1, Loss: 123.84413146972656
Projection step: 2, Loss: 117.20702362060547
Projection step: 3, Loss: 121.99960327148438
Projection step: 4, Loss: 110.87651062011719
Projection step: 5, Loss: 100.90541076660156
Final likelihood: tensor([-126.5198,  -96.6202,  -94.8346,  -83.6577, -121.8830,  -92.9767,
         -95.8338,  -92.7837, -129.6684,  -87.7355,  -94.4529,  -97.7446,
         -88.1367, -125.5305,  -89.4414,  -96.6673])
Final projection likelihood: -100.9054
1 mode projection succeeded
New goal: tensor([ 0.0400,  0.4907,  0.6077,  0.6874, -0.0880,  0.5715,  0.8458,  0.8793,
         1.3420,  0.1890,  0.1578,  1.1632,  0.0441, -0.0068, -0.7598],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -171.99868774414062
Adjusted likelihood: -171.99868774414062
Likelihood residual: 0.0
Original likelihood: -157.3493194580078
Adjusted likelihood: -157.3493194580078
Likelihood residual: 0.0
{'index': 157.3493194580078, 'thumb_middle': 171.99868774414062}
Current yaw: tensor([ 0.0458, -0.0079, -0.4722], device='cuda:1')
20 index
tensor([ 0.0340,  0.4724,  0.5992,  0.6872, -0.1067,  0.6076,  0.8547,  0.8817,
         1.3651,  0.1888,  0.1478,  1.1419,  0.0458, -0.0079, -0.4722,  1.9902],
       device='cuda:1')
Solve time for step 1 9.960167361947242
Current ori: tensor([ 0.0458, -0.0079, -0.4722], device='cuda:1')
Middle force: tensor([0.5661, 0.5859, 0.5474, 0.5259], device='cuda:1')
Thumb force: tensor([0.5950, 0.5837, 0.6211, 0.5390], device='cuda:1')
tensor([ 0.0969,  0.4349,  0.5542,  0.6598, -0.1049,  0.6038,  0.8672,  0.8914,
         1.3615,  0.1927,  0.1437,  1.1472,  0.0490, -0.0122, -0.4944,  2.3562],
       device='cuda:1')
Solve time for step 2 4.105243289028294
Current ori: tensor([ 0.0490, -0.0122, -0.4944], device='cuda:1')
Middle force: tensor([0.5723, 0.5018, 0.5757], device='cuda:1')
Thumb force: tensor([0.6232, 0.5724, 0.5916], device='cuda:1')
tensor([ 0.0993,  0.4373,  0.5540,  0.6594, -0.1187,  0.6099,  0.8631,  0.8834,
         1.3699,  0.1876,  0.1564,  1.1217,  0.0460, -0.0059, -0.5017,  2.6275],
       device='cuda:1')
Solve time for step 3 4.068745755997952
Current ori: tensor([ 0.0460, -0.0059, -0.5017], device='cuda:1')
Middle force: tensor([0.5015, 0.5721], device='cuda:1')
Thumb force: tensor([0.5629, 0.5845], device='cuda:1')
tensor([ 0.0997,  0.4392,  0.5527,  0.6563, -0.1143,  0.6059,  0.8702,  0.8939,
         1.3756,  0.1706,  0.1389,  1.1538,  0.0519, -0.0094, -0.4923,  2.8784],
       device='cuda:1')
Solve time for step 4 3.97797393304063
Current ori: tensor([ 0.0519, -0.0094, -0.4923], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5539], device='cuda:1')
Storing RECOVERY transition: reward=0.0266 (scaled=0.0266), steps=0
Reward stats updated: mean 0.0152 -> 0.0153, std: 0.0908
Collected 399 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=1.9760, Q2 Loss=1.9760, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1164
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=1.0785, Q2 Loss=1.0785, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3300
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.9116, Q2 Loss=0.9116, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3837
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=2.6424, Q2 Loss=2.6424, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6730
SAC Update 5/5: Actor Loss=-0.0070, Q1 Loss=0.7004, Q2 Loss=0.7004, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1522

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009058
Q1 loss: 1.461799
Q2 loss: 1.461799
Current threshold: -149.5189
Global Scale Offset: 3131.2864
Reward stats: mean=0.0153, std=0.0908, count=399
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.4618, Q2 Loss: 1.4618, Entropy: 0.6930, Mean TD Error: 1.9311, Threshold: -149.5189
Original likelihood: -144.91505432128906
Adjusted likelihood: -144.91505432128906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 135.5904541015625
Projection step: 1, Loss: 138.22752380371094
Projection step: 2, Loss: 124.8631362915039
Projection step: 3, Loss: 125.90645599365234
Projection step: 4, Loss: 118.47840118408203
Projection step: 5, Loss: 107.12922668457031
Projection step: 6, Loss: 107.35896301269531
Projection step: 7, Loss: 102.83143615722656
Final likelihood: tensor([-138.4213,  -93.3021, -100.8553,  -95.2333, -107.5200, -121.1074,
         -94.6305,  -99.3372,  -92.8273,  -90.6012, -103.6041, -103.0112,
         -88.1546,  -96.1936,  -94.0493, -126.4546])
Final projection likelihood: -102.8314
1 mode projection succeeded
New goal: tensor([ 0.0546,  0.5061,  0.6066,  0.6712, -0.0849,  0.5621,  0.8582,  0.8896,
         1.3381,  0.1958,  0.1655,  1.1683,  0.0492, -0.0093, -0.8074],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 26
Loaded trajectory sampler
Current yaw: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
Current yaw: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
1 turn
Sampling time 3.769046911969781
tensor([ 1.4472e-01,  5.7287e-01,  6.2624e-01,  5.8175e-01, -1.3745e-01,
         5.1081e-01,  9.5969e-01,  9.3692e-01,  1.2206e+00,  3.4059e-01,
         2.2913e-01,  1.2019e+00, -6.7404e-04,  1.3941e-02, -3.5587e-02,
         4.5237e-01], device='cuda:1')
Original likelihood: -118.05548858642578
Adjusted likelihood: -118.05548858642578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5040)
State is out of distribution
Projection step: 0, Loss: 123.34355163574219
Projection step: 1, Loss: 99.54568481445312
Final likelihood: tensor([ -98.7925, -108.0037, -118.3242,  -71.8245, -106.9127, -101.0568,
        -114.8536,  -69.1565,  -82.1318,  -90.0187,  -71.0667, -128.5051,
         -90.2456, -128.9600, -113.1349,  -99.7436])
Final projection likelihood: -99.5457
1 mode projection succeeded
New goal: tensor([ 1.4038e-01,  5.6769e-01,  6.2299e-01,  5.8323e-01, -1.3056e-01,
         5.1246e-01,  9.5863e-01,  9.3080e-01,  1.2295e+00,  3.4168e-01,
         2.2948e-01,  1.1904e+00, -4.2243e-04,  1.3954e-02, -4.3728e-02],
       device='cuda:1')
tensor([[0.0037]], device='cuda:1') tensor([[0.0014]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -123.70710754394531
Adjusted likelihood: -123.70710754394531
Likelihood residual: 0.0
Original likelihood: -118.30571746826172
Adjusted likelihood: -118.30571746826172
Likelihood residual: 0.0
{'index': 118.30571746826172, 'thumb_middle': 123.70710754394531}
Current yaw: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
2 index
tensor([ 1.4472e-01,  5.7287e-01,  6.2624e-01,  5.8175e-01, -1.3745e-01,
         5.1081e-01,  9.5969e-01,  9.3692e-01,  1.2206e+00,  3.4059e-01,
         2.2913e-01,  1.2019e+00, -6.7404e-04,  1.3941e-02, -3.5587e-02,
         4.5237e-01], device='cuda:1')
Solve time for step 1 10.721060768002644
Current ori: tensor([-0.0007,  0.0139, -0.0356], device='cuda:1')
Middle force: tensor([0.5924, 0.6001, 0.5629, 0.5674], device='cuda:1')
Thumb force: tensor([0.5668, 0.5441, 0.5404, 0.6153], device='cuda:1')
tensor([ 0.1948,  0.5159,  0.5750,  0.5607, -0.1387,  0.5071,  0.9618,  0.9385,
         1.2388,  0.3221,  0.2215,  1.1887, -0.0035,  0.0064, -0.0604,  1.1244],
       device='cuda:1')
Solve time for step 2 4.189774346014019
Current ori: tensor([-0.0035,  0.0064, -0.0604], device='cuda:1')
Middle force: tensor([0.5953, 0.5595, 0.5632], device='cuda:1')
Thumb force: tensor([0.5391, 0.5369, 0.6106], device='cuda:1')
tensor([ 1.9155e-01,  5.1558e-01,  5.7524e-01,  5.5925e-01, -1.5398e-01,
         4.9667e-01,  9.6240e-01,  9.4331e-01,  1.2465e+00,  3.1847e-01,
         2.3992e-01,  1.1735e+00, -9.0227e-04,  1.6926e-02, -5.9824e-02,
         1.4400e+00], device='cuda:1')
Solve time for step 3 4.145006175967865
Current ori: tensor([-0.0009,  0.0169, -0.0598], device='cuda:1')
Middle force: tensor([0.5567, 0.5591], device='cuda:1')
Thumb force: tensor([0.5308, 0.6059], device='cuda:1')
tensor([ 0.1928,  0.5161,  0.5727,  0.5589, -0.1436,  0.5063,  0.9596,  0.9364,
         1.2464,  0.3180,  0.2271,  1.1729, -0.0058,  0.0102, -0.0701,  1.5806],
       device='cuda:1')
Solve time for step 4 4.006637607002631
Current ori: tensor([-0.0058,  0.0102, -0.0701], device='cuda:1')
Middle force: tensor([0.5088], device='cuda:1')
Thumb force: tensor([0.5497], device='cuda:1')
Storing RECOVERY transition: reward=0.0366 (scaled=0.0366), steps=0
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0907
Collected 400 transitions for RL
SAC Update 1/5: Actor Loss=-0.0071, Q1 Loss=0.6932, Q2 Loss=0.6932, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1325
SAC Update 2/5: Actor Loss=-0.0095, Q1 Loss=1.2529, Q2 Loss=1.2529, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6162
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=1.1583, Q2 Loss=1.1583, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7568
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.8296, Q2 Loss=0.8296, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0712
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.8444, Q2 Loss=0.8444, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6827

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (19.1%)
Actor update: 0.12s (40.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008806
Q1 loss: 0.955678
Q2 loss: 0.955678
Current threshold: -149.5189
Global Scale Offset: 3154.0293
Reward stats: mean=0.0153, std=0.0907, count=400
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 0.9557, Q2 Loss: 0.9557, Entropy: 0.6931, Mean TD Error: 0.8519, Threshold: -149.5189
Original likelihood: -109.50725555419922
Adjusted likelihood: -109.50725555419922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5051)
State is out of distribution
Projection step: 0, Loss: 121.7236328125
Projection step: 1, Loss: 102.16666412353516
Final likelihood: tensor([ -86.6745,  -94.2509, -128.7714, -111.8048, -141.0401, -129.5956,
         -79.4609,  -98.1451,  -97.3352,  -89.6619, -131.8171,  -89.8376,
         -90.7465,  -85.8843,  -82.1943,  -97.4465])
Final projection likelihood: -102.1667
1 mode projection succeeded
New goal: tensor([ 0.1347,  0.5719,  0.6145,  0.5812, -0.1401,  0.5114,  0.9558,  0.9311,
         1.2488,  0.3304,  0.2290,  1.1616, -0.0074,  0.0136, -0.1046],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -131.1133575439453
Adjusted likelihood: -131.1133575439453
Likelihood residual: 0.0
Original likelihood: -130.87538146972656
Adjusted likelihood: -130.87538146972656
Likelihood residual: 0.0
{'index': 130.87538146972656, 'thumb_middle': 131.1133575439453}
Current yaw: tensor([-0.0077,  0.0134, -0.0723], device='cuda:1')
3 index
tensor([ 0.1391,  0.5759,  0.6170,  0.5802, -0.1483,  0.5076,  0.9562,  0.9340,
         1.2454,  0.3268,  0.2292,  1.1737, -0.0077,  0.0134, -0.0723,  1.6008],
       device='cuda:1')
Solve time for step 1 10.823416553961579
Current ori: tensor([-0.0077,  0.0134, -0.0723], device='cuda:1')
Middle force: tensor([0.5562, 0.5112, 0.5393, 0.5237], device='cuda:1')
Thumb force: tensor([0.5183, 0.5330, 0.5491, 0.6053], device='cuda:1')
tensor([ 0.1873,  0.5190,  0.5665,  0.5570, -0.1421,  0.5111,  0.9575,  0.9320,
         1.2520,  0.3217,  0.2202,  1.1619, -0.0123,  0.0093, -0.0994,  2.1064],
       device='cuda:1')
Solve time for step 2 4.421891310019419
Current ori: tensor([-0.0123,  0.0093, -0.0994], device='cuda:1')
Middle force: tensor([0.5096, 0.5371, 0.5219], device='cuda:1')
Thumb force: tensor([0.5312, 0.5467, 0.6010], device='cuda:1')
tensor([ 0.1875,  0.5200,  0.5641,  0.5546, -0.1468,  0.5099,  0.9545,  0.9346,
         1.2570,  0.3169,  0.2245,  1.1559, -0.0120,  0.0125, -0.0991,  2.3391],
       device='cuda:1')
Solve time for step 3 4.3915194980218075
Current ori: tensor([-0.0120,  0.0125, -0.0991], device='cuda:1')
Middle force: tensor([0.5010, 0.5412], device='cuda:1')
Thumb force: tensor([0.5022, 0.5174], device='cuda:1')
tensor([ 0.1859,  0.5192,  0.5643,  0.5550, -0.1415,  0.5127,  0.9545,  0.9347,
         1.2612,  0.3099,  0.2142,  1.1597, -0.0132,  0.0089, -0.1059,  2.4089],
       device='cuda:1')
Solve time for step 4 3.8679516999982297
Current ori: tensor([-0.0132,  0.0089, -0.1059], device='cuda:1')
Middle force: tensor([0.5707], device='cuda:1')
Thumb force: tensor([0.5905], device='cuda:1')
Storing RECOVERY transition: reward=0.0764 (scaled=0.0764), steps=0
Reward stats updated: mean 0.0153 -> 0.0155, std: 0.0906
Collected 401 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8466, Q2 Loss=0.8466, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3467
SAC Update 2/5: Actor Loss=-0.0107, Q1 Loss=3.8920, Q2 Loss=3.8920, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6690
SAC Update 3/5: Actor Loss=-0.0132, Q1 Loss=1.9547, Q2 Loss=1.9547, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8031
SAC Update 4/5: Actor Loss=-0.0116, Q1 Loss=1.8086, Q2 Loss=1.8086, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9780
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=0.8361, Q2 Loss=0.8361, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9863

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010128
Q1 loss: 1.867591
Q2 loss: 1.867591
Current threshold: -149.5189
Global Scale Offset: 3174.7882
Reward stats: mean=0.0155, std=0.0906, count=401
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.8676, Q2 Loss: 1.8676, Entropy: 0.6931, Mean TD Error: 1.9566, Threshold: -149.5189
Original likelihood: -115.24739074707031
Adjusted likelihood: -115.24739074707031
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5043)
Current yaw: tensor([-0.0181,  0.0108, -0.1123], device='cuda:1')
4 turn
Sampling time 3.658096351020504
tensor([ 0.1330,  0.5792,  0.6084,  0.5772, -0.1437,  0.5182,  0.9493,  0.9268,
         1.2638,  0.3155,  0.2123,  1.1546, -0.0181,  0.0108, -0.1123,  2.4259],
       device='cuda:1')
Original likelihood: -116.95182800292969
Adjusted likelihood: -116.95182800292969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5041)
State is out of distribution
Projection step: 0, Loss: 115.83633422851562
Projection step: 1, Loss: 105.69306182861328
Projection step: 2, Loss: 98.40176391601562
Final likelihood: tensor([-117.7736, -107.2356, -112.5698, -142.0210,  -75.5953,  -78.6553,
         -70.4009,  -73.0154, -101.4599,  -78.7899,  -79.4732,  -78.1887,
        -121.3429,  -81.3150, -127.2875, -129.3041])
Final projection likelihood: -98.4018
1 mode projection succeeded
New goal: tensor([ 0.1264,  0.5734,  0.6040,  0.5807, -0.1277,  0.5260,  0.9463,  0.9231,
         1.2689,  0.3238,  0.2132,  1.1369, -0.0178,  0.0117, -0.2015],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -121.62983703613281
Adjusted likelihood: -121.62983703613281
Likelihood residual: 0.0
Original likelihood: -126.11849975585938
Adjusted likelihood: -126.11849975585938
Likelihood residual: 0.0
{'index': 126.11849975585938, 'thumb_middle': 121.62983703613281}
Current yaw: tensor([-0.0181,  0.0108, -0.1123], device='cuda:1')
5 thumb_middle
tensor([ 0.1330,  0.5792,  0.6084,  0.5772, -0.1437,  0.5182,  0.9493,  0.9268,
         1.2638,  0.3155,  0.2123,  1.1546, -0.0181,  0.0108, -0.1123,  2.4259],
       device='cuda:1')
Solve time for step 1 9.185572639980819
Current ori: tensor([-0.0181,  0.0108, -0.1123], device='cuda:1')
Index force: tensor([0.5968, 0.5961, 0.5955, 0.5747], device='cuda:1')
tensor([ 0.1317,  0.5830,  0.6037,  0.5733, -0.2298,  0.4930,  0.9079,  0.9043,
         1.2242,  0.3059,  0.1422,  1.1113, -0.0183,  0.0116, -0.1123,  2.4021],
       device='cuda:1')
Solve time for step 2 3.759234890982043
Current ori: tensor([-0.0183,  0.0116, -0.1123], device='cuda:1')
Index force: tensor([0.5862, 0.5871, 0.5675], device='cuda:1')
tensor([ 0.1293,  0.5909,  0.5927,  0.5700, -0.2355,  0.5013,  0.9123,  0.9022,
         1.2295,  0.3031,  0.1317,  1.1039, -0.0204,  0.0126, -0.1123,  2.3969],
       device='cuda:1')
Solve time for step 3 3.5590850739972666
Current ori: tensor([-0.0204,  0.0126, -0.1123], device='cuda:1')
Index force: tensor([0.5755, 0.5583], device='cuda:1')
tensor([ 0.1316,  0.5767,  0.6080,  0.5823, -0.2342,  0.5018,  0.9086,  0.9013,
         1.2309,  0.3063,  0.1277,  1.1052, -0.0163,  0.0120, -0.1123,  2.4059],
       device='cuda:1')
Solve time for step 4 3.4428647700115107
Current ori: tensor([-0.0163,  0.0120, -0.1123], device='cuda:1')
Index force: tensor([0.5349], device='cuda:1')
Storing RECOVERY transition: reward=-0.0003 (scaled=-0.0003), steps=0
Reward stats updated: mean 0.0155 -> 0.0154, std: 0.0905
Collected 402 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=1.1501, Q2 Loss=1.1501, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1201
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.7129, Q2 Loss=0.7129, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2342
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8501, Q2 Loss=0.8501, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5075
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.0978, Q2 Loss=1.0978, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2836
SAC Update 5/5: Actor Loss=-0.0124, Q1 Loss=1.3767, Q2 Loss=1.3767, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9339

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.8%)
Q1 update: 0.06s (21.6%)
Q2 update: 0.05s (20.3%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010122
Q1 loss: 1.037509
Q2 loss: 1.037509
Current threshold: -149.5188
Global Scale Offset: 3192.3963
Reward stats: mean=0.0154, std=0.0905, count=402
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0375, Q2 Loss: 1.0375, Entropy: 0.6931, Mean TD Error: 0.4158, Threshold: -149.5188
Original likelihood: -133.79029846191406
Adjusted likelihood: -133.79029846191406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 131.45619201660156
Projection step: 1, Loss: 122.10421752929688
Projection step: 2, Loss: 121.9244155883789
Projection step: 3, Loss: 108.43184661865234
Projection step: 4, Loss: 113.480224609375
Projection step: 5, Loss: 112.04414367675781
Projection step: 6, Loss: 103.02244567871094
Final likelihood: tensor([ -96.9031, -116.4535, -104.7961, -115.7794,  -96.9319, -104.8542,
        -126.0637, -113.4112, -118.1905,  -95.5102,  -98.9797,  -86.7949,
        -101.1174,  -97.6231,  -92.3989,  -82.5513])
Final projection likelihood: -103.0224
1 mode projection succeeded
New goal: tensor([ 0.1056,  0.5509,  0.5993,  0.5961, -0.1313,  0.5571,  0.9280,  0.8752,
         1.3002,  0.3258,  0.2009,  1.1252, -0.0137,  0.0204, -0.1995],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -118.26937866210938
Adjusted likelihood: -118.26937866210938
Likelihood residual: 0.0
Original likelihood: -125.27734375
Adjusted likelihood: -125.27734375
Likelihood residual: 0.0
{'index': 125.27734375, 'thumb_middle': 118.26937866210938}
Current yaw: tensor([-0.0140,  0.0218, -0.1122], device='cuda:1')
6 thumb_middle
tensor([ 0.1145,  0.5679,  0.6007,  0.5860, -0.1776,  0.5454,  0.9387,  0.9151,
         1.3022,  0.3274,  0.1910,  1.1332, -0.0140,  0.0218, -0.1122,  2.3929],
       device='cuda:1')
Solve time for step 1 9.21846101799747
Current ori: tensor([-0.0140,  0.0218, -0.1122], device='cuda:1')
Index force: tensor([0.5474, 0.5649, 0.5816, 0.5037], device='cuda:1')
tensor([ 0.1237,  0.5475,  0.6120,  0.6363, -0.2398,  0.5186,  0.8882,  0.8798,
         1.2494,  0.3001,  0.1310,  1.0988, -0.0055,  0.0181, -0.1122,  2.4139],
       device='cuda:1')
Solve time for step 2 3.6821032789885066
Current ori: tensor([-0.0055,  0.0181, -0.1122], device='cuda:1')
Index force: tensor([0.5007, 0.5926, 0.5904], device='cuda:1')
tensor([ 0.1178,  0.5612,  0.5974,  0.6158, -0.2463,  0.5308,  0.8847,  0.8485,
         1.2538,  0.3243,  0.1272,  1.0851, -0.0103,  0.0209, -0.1122,  2.4015],
       device='cuda:1')
Solve time for step 3 3.5707878399989568
Current ori: tensor([-0.0103,  0.0209, -0.1122], device='cuda:1')
Index force: tensor([0.5843, 0.5837], device='cuda:1')
tensor([ 0.1129,  0.5612,  0.6049,  0.5923, -0.2432,  0.5235,  0.8938,  0.8483,
         1.2699,  0.3028,  0.1146,  1.0801, -0.0121,  0.0234, -0.1122,  2.3889],
       device='cuda:1')
Solve time for step 4 3.4784562459681183
Current ori: tensor([-0.0121,  0.0234, -0.1122], device='cuda:1')
Index force: tensor([0.5673], device='cuda:1')
Storing RECOVERY transition: reward=-0.0061 (scaled=-0.0061), steps=0
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0904
Collected 403 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.8143, Q2 Loss=0.8143, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9591
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.6905, Q2 Loss=0.6905, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1728
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.0011, Q2 Loss=1.0011, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4263
SAC Update 4/5: Actor Loss=-0.0136, Q1 Loss=1.4054, Q2 Loss=1.4054, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6882
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.0027, Q2 Loss=1.0027, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7016

------ SAC Update Summary (5 iterations) ------
Total time: 0.19s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009656
Q1 loss: 0.982813
Q2 loss: 0.982813
Current threshold: -149.5187
Global Scale Offset: 3211.5416
Reward stats: mean=0.0154, std=0.0904, count=403
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 0.9828, Q2 Loss: 0.9828, Entropy: 0.6931, Mean TD Error: 0.5896, Threshold: -149.5187
Original likelihood: -179.38739013671875
Adjusted likelihood: -179.38739013671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4963)
State is out of distribution
Projection step: 0, Loss: 167.26129150390625
Projection step: 1, Loss: 158.52627563476562
Projection step: 2, Loss: 148.65872192382812
Projection step: 3, Loss: 146.8046875
Projection step: 4, Loss: 136.48069763183594
Projection step: 5, Loss: 130.89822387695312
Projection step: 6, Loss: 126.5429458618164
Projection step: 7, Loss: 122.71591186523438
Projection step: 8, Loss: 120.6302719116211
Projection step: 9, Loss: 112.90258026123047
Projection step: 10, Loss: 108.38519287109375
Projection step: 11, Loss: 103.06794738769531
Final likelihood: tensor([-107.4950, -103.7879,  -94.2708, -128.4632,  -98.0381, -105.1637,
         -89.6327, -102.4168, -104.0558, -105.0323, -104.9723, -120.3363,
         -88.6422, -105.4888,  -90.5093, -100.7822])
Final projection likelihood: -103.0679
1 mode projection succeeded
New goal: tensor([ 0.0945,  0.5301,  0.6032,  0.6450, -0.1235,  0.5779,  0.8709,  0.8284,
         1.3059,  0.3038,  0.1896,  1.1515, -0.0081,  0.0253, -0.2112],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -129.0750274658203
Adjusted likelihood: -129.0750274658203
Likelihood residual: 0.0
Original likelihood: -125.0776596069336
Adjusted likelihood: -125.0776596069336
Likelihood residual: 0.0
{'index': 125.0776596069336, 'thumb_middle': 129.0750274658203}
Current yaw: tensor([-0.0064,  0.0331, -0.1068], device='cuda:1')
7 index
tensor([ 0.0955,  0.5418,  0.6041,  0.6122, -0.1969,  0.5731,  0.9120,  0.8726,
         1.3304,  0.3333,  0.1754,  1.1306, -0.0064,  0.0331, -0.1068,  2.3935],
       device='cuda:1')
Solve time for step 1 10.588121995038819
Current ori: tensor([-0.0064,  0.0331, -0.1068], device='cuda:1')
Middle force: tensor([0.5930, 0.5096, 0.5521, 0.5305], device='cuda:1')
Thumb force: tensor([0.5667, 0.5059, 0.5593, 0.6107], device='cuda:1')
tensor([ 0.1423,  0.4791,  0.5529,  0.6124, -0.1876,  0.5938,  0.8960,  0.8494,
         1.3400,  0.3218,  0.1634,  1.1120, -0.0187,  0.0288, -0.1114,  3.1119],
       device='cuda:1')
Solve time for step 2 4.163164863013662
Current ori: tensor([-0.0187,  0.0288, -0.1114], device='cuda:1')
Middle force: tensor([0.5089, 0.5492, 0.5273], device='cuda:1')
Thumb force: tensor([0.5045, 0.5560, 0.6051], device='cuda:1')
tensor([ 0.1437,  0.4764,  0.5533,  0.6174, -0.1797,  0.5952,  0.9007,  0.8501,
         1.3720,  0.2669,  0.1231,  1.1378, -0.0192,  0.0228, -0.1195,  3.4114],
       device='cuda:1')
Solve time for step 3 4.006739524949808
Current ori: tensor([-0.0192,  0.0228, -0.1195], device='cuda:1')
Middle force: tensor([0.5451, 0.5236], device='cuda:1')
Thumb force: tensor([0.5495, 0.5979], device='cuda:1')
tensor([ 0.1446,  0.4777,  0.5505,  0.6179, -0.1857,  0.6041,  0.8866,  0.8394,
         1.3568,  0.3060,  0.1449,  1.1056, -0.0286,  0.0288, -0.1373,  3.4718],
       device='cuda:1')
Solve time for step 4 3.9878406229545362
Current ori: tensor([-0.0286,  0.0288, -0.1373], device='cuda:1')
Middle force: tensor([0.5210], device='cuda:1')
Thumb force: tensor([0.5866], device='cuda:1')
Storing RECOVERY transition: reward=0.0146 (scaled=0.0146), steps=0
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0903
Collected 404 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=5.4072, Q2 Loss=5.4072, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.4479
SAC Update 2/5: Actor Loss=-0.0099, Q1 Loss=0.9645, Q2 Loss=0.9645, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2433
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7797, Q2 Loss=0.7797, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6310
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=1.2367, Q2 Loss=1.2367, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7472
SAC Update 5/5: Actor Loss=-0.0089, Q1 Loss=1.1075, Q2 Loss=1.1075, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4908

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (18.6%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008875
Q1 loss: 1.899133
Q2 loss: 1.899133
Current threshold: -149.5184
Global Scale Offset: 3233.5639
Reward stats: mean=0.0154, std=0.0903, count=404
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.8991, Q2 Loss: 1.8991, Entropy: 0.6931, Mean TD Error: 2.1120, Threshold: -149.5184
Original likelihood: -141.5387725830078
Adjusted likelihood: -141.5387725830078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5010)
Current yaw: tensor([-0.0277,  0.0284, -0.1280], device='cuda:1')
8 turn
Sampling time 3.6530219460255466
tensor([ 0.0935,  0.5345,  0.5965,  0.6416, -0.1851,  0.6046,  0.8865,  0.8372,
         1.3514,  0.3139,  0.1386,  1.1279, -0.0277,  0.0284, -0.1280,  3.4406],
       device='cuda:1')
Original likelihood: -142.32861328125
Adjusted likelihood: -142.32861328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Solve time for step 1 13.915166880004108
Current ori: tensor([-0.0277,  0.0284, -0.1280], device='cuda:1')
Middle force: tensor([0.5569, 1.2450, 0.6326, 0.5506, 0.5083, 0.6566, 1.6354, 0.8099, 0.8702,
        0.5159, 0.4909, 0.4872], device='cuda:1')
Thumb force: tensor([0.5292, 0.5515, 0.8875, 0.5749, 0.6218, 0.5732, 0.5592, 0.8483, 0.5661,
        0.5378, 0.7096, 0.5304], device='cuda:1')
Index force: tensor([0.5487, 0.6128, 0.5275, 0.5998, 0.7346, 0.5291, 0.5596, 0.5375, 0.5747,
        0.6177, 0.7026, 0.7874], device='cuda:1')
Storing NORMAL transition: reward=-0.0725 (scaled=-0.0725), steps=1
Reward stats updated: mean 0.0154 -> 0.0152, std: 0.0903
Collected 405 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=0.8235, Q2 Loss=0.8235, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4605
SAC Update 2/5: Actor Loss=-0.0132, Q1 Loss=1.4692, Q2 Loss=1.4692, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9861
SAC Update 3/5: Actor Loss=-0.0113, Q1 Loss=1.4583, Q2 Loss=1.4583, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4010
SAC Update 4/5: Actor Loss=-0.0100, Q1 Loss=8.4039, Q2 Loss=8.4039, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.2358
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=2.5105, Q2 Loss=2.5105, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6718

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (40.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010001
Q1 loss: 2.933076
Q2 loss: 2.933076
Current threshold: -149.5183
Global Scale Offset: 3256.8289
Reward stats: mean=0.0152, std=0.0903, count=405
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 2.9331, Q2 Loss: 2.9331, Entropy: 0.6930, Mean TD Error: 3.1511, Threshold: -149.5183
tensor([ 0.1569,  0.4893,  0.6487,  0.7787, -0.1560,  0.6371,  0.8263,  0.8587,
         1.3197,  0.3392,  0.1128,  1.2070, -0.0178,  0.0136, -0.0544,  3.5233],
       device='cuda:1')
Original likelihood: -160.7940673828125
Adjusted likelihood: -160.7940673828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4986)
Solve time for step 2 5.481487379991449
Current ori: tensor([-0.0178,  0.0136, -0.0544], device='cuda:1')
Middle force: tensor([1.2840, 0.5008, 0.5013, 0.5442, 0.5299, 0.6295, 0.5374, 0.6347, 0.5570,
        0.5057, 0.5497], device='cuda:1')
Thumb force: tensor([1.0298, 0.5536, 0.5068, 1.7364, 0.5866, 0.6034, 0.5798, 0.5659, 0.5668,
        0.5688, 0.8681], device='cuda:1')
Index force: tensor([0.5019, 0.8728, 0.5949, 0.6052, 0.5164, 0.5682, 0.5608, 0.5504, 0.5850,
        0.6757, 0.5700], device='cuda:1')
Storing NORMAL transition: reward=0.0526 (scaled=0.0526), steps=1
Reward stats updated: mean 0.0152 -> 0.0153, std: 0.0902
Collected 406 transitions for RL
SAC Update 1/5: Actor Loss=-0.0130, Q1 Loss=3.7655, Q2 Loss=3.7655, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5136
SAC Update 2/5: Actor Loss=-0.0117, Q1 Loss=2.3705, Q2 Loss=2.3705, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6247
SAC Update 3/5: Actor Loss=-0.0119, Q1 Loss=2.1330, Q2 Loss=2.1330, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3353
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=0.8617, Q2 Loss=0.8617, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5280
SAC Update 5/5: Actor Loss=-0.0108, Q1 Loss=3.8078, Q2 Loss=3.8078, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7581

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (39.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011191
Q1 loss: 2.587705
Q2 loss: 2.587705
Current threshold: -149.5180
Global Scale Offset: 3280.7645
Reward stats: mean=0.0153, std=0.0902, count=406
----------------------------------------------
SAC Update - Actor Loss: -0.0112, Q1 Loss: 2.5877, Q2 Loss: 2.5877, Entropy: 0.6931, Mean TD Error: 2.3519, Threshold: -149.5180
tensor([-0.0341,  0.4100,  0.6369,  0.6766, -0.1578,  0.4622,  0.8383,  1.0875,
         1.4577,  0.1799, -0.0493,  1.1413, -0.0045,  0.0495, -0.1089,  3.4568],
       device='cuda:1')
Original likelihood: -212.09487915039062
Adjusted likelihood: -212.09487915039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4924)
State is out of distribution
Projection step: 0, Loss: 218.18626403808594
Projection step: 1, Loss: 203.49896240234375
Projection step: 2, Loss: 199.5369873046875
Projection step: 3, Loss: 192.17129516601562
Projection step: 4, Loss: 185.63546752929688
Projection step: 5, Loss: 178.3007354736328
Projection step: 6, Loss: 165.2325897216797
Projection step: 7, Loss: 181.27435302734375
Projection step: 8, Loss: 168.89889526367188
Projection step: 9, Loss: 159.48684692382812
Projection step: 10, Loss: 160.41900634765625
Projection step: 11, Loss: 148.63623046875
Projection step: 12, Loss: 152.31219482421875
Projection step: 13, Loss: 144.9456787109375
Projection step: 14, Loss: 148.43075561523438
Projection step: 15, Loss: 142.65869140625
Projection step: 16, Loss: 143.07974243164062
Projection step: 17, Loss: 137.70350646972656
Projection step: 18, Loss: 134.4336395263672
Projection step: 19, Loss: 128.9371795654297
Projection step: 20, Loss: 126.76885986328125
Projection step: 21, Loss: 133.80316162109375
Projection step: 22, Loss: 124.96824645996094
Projection step: 23, Loss: 114.21561431884766
Projection step: 24, Loss: 111.00112915039062
Final likelihood: tensor([-114.1307, -132.5718, -102.1474, -102.7812, -105.7351, -118.5048,
        -127.6821,  -81.0277, -118.9627, -114.0688, -120.1489, -108.2596,
        -123.7615, -115.4858, -107.1601, -127.4146])
Final projection likelihood: -113.7402
1 mode projection succeeded
New goal: tensor([ 0.0034,  0.5054,  0.6145,  0.6282, -0.1110,  0.4960,  0.8003,  0.9067,
         1.3445,  0.2134,  0.0913,  1.2249, -0.0110,  0.0315, -0.8004],
       device='cuda:1')
tensor([[0.0122]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -127.85916900634766
Adjusted likelihood: -127.85916900634766
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 127.85916900634766}
Current yaw: tensor([-0.0045,  0.0495, -0.1089], device='cuda:1')
9 thumb_middle
tensor([-0.0341,  0.4100,  0.6369,  0.6766, -0.1578,  0.4622,  0.8383,  1.0875,
         1.4577,  0.1799, -0.0493,  1.1413, -0.0045,  0.0495, -0.1089,  3.4568],
       device='cuda:1')
Solve time for step 1 9.140709514031187
Current ori: tensor([-0.0045,  0.0495, -0.1089], device='cuda:1')
Index force: tensor([0.6110, 0.6057, 0.6216, 0.5109], device='cuda:1')
tensor([-0.0107,  0.4132,  0.6464,  0.6847, -0.1965,  0.4750,  0.7814,  0.9228,
         1.3470,  0.1908,  0.0228,  1.1947, -0.0075,  0.0442, -0.1068,  3.4334],
       device='cuda:1')
Solve time for step 2 3.6490013360162266
Current ori: tensor([-0.0075,  0.0442, -0.1068], device='cuda:1')
Index force: tensor([0.6404, 0.6109, 0.5974], device='cuda:1')
tensor([-0.0165,  0.4505,  0.6124,  0.6408, -0.2069,  0.4833,  0.7790,  0.8976,
         1.3415,  0.1978,  0.0343,  1.2044, -0.0212,  0.0485, -0.1068,  3.3923],
       device='cuda:1')
Solve time for step 3 3.4156312289997004
Current ori: tensor([-0.0212,  0.0485, -0.1068], device='cuda:1')
Index force: tensor([0.5932, 0.6000], device='cuda:1')
tensor([-0.0080,  0.4735,  0.5948,  0.6265, -0.2031,  0.4879,  0.7774,  0.8923,
         1.3339,  0.1998,  0.0359,  1.2067, -0.0295,  0.0461, -0.1068,  3.3924],
       device='cuda:1')
Solve time for step 4 3.4564845269778743
Current ori: tensor([-0.0295,  0.0461, -0.1068], device='cuda:1')
Index force: tensor([0.5735], device='cuda:1')
Storing RECOVERY transition: reward=-0.0095 (scaled=-0.0047), steps=2
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0901
Collected 407 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=3.2704, Q2 Loss=3.2704, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8958
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8523, Q2 Loss=0.8523, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2574
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.7273, Q2 Loss=1.7273, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7639
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8482, Q2 Loss=0.8482, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4150
SAC Update 5/5: Actor Loss=-0.0117, Q1 Loss=4.1456, Q2 Loss=4.1456, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1609

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008970
Q1 loss: 2.168746
Q2 loss: 2.168746
Current threshold: -149.5177
Global Scale Offset: 3300.4597
Reward stats: mean=0.0152, std=0.0901, count=407
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 2.1687, Q2 Loss: 2.1687, Entropy: 0.6931, Mean TD Error: 2.8986, Threshold: -149.5177
Original likelihood: -148.49520874023438
Adjusted likelihood: -148.49520874023438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5001)
Current yaw: tensor([-0.0228,  0.0365, -0.0988], device='cuda:1')
10 turn
Sampling time 3.7663027759990655
tensor([-6.0267e-04,  4.6327e-01,  6.0438e-01,  6.4777e-01, -1.2856e-01,
         5.3603e-01,  8.1684e-01,  9.1250e-01,  1.3998e+00,  2.2538e-01,
         8.1488e-02,  1.2315e+00, -2.2834e-02,  3.6473e-02, -9.8829e-02,
         3.4183e+00], device='cuda:1')
Original likelihood: -162.45892333984375
Adjusted likelihood: -162.45892333984375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4984)
Solve time for step 1 13.808278089971282
Current ori: tensor([-0.0228,  0.0365, -0.0988], device='cuda:1')
Middle force: tensor([0.8402, 1.1797, 0.8876, 0.5351, 0.8255, 0.5633, 0.8021, 0.5190, 0.5892,
        0.5812, 0.6060, 0.5956], device='cuda:1')
Thumb force: tensor([3.2589, 1.1556, 0.6159, 0.5551, 0.9601, 0.5642, 0.5514, 0.5502, 1.8190,
        0.5225, 0.5131, 0.6158], device='cuda:1')
Index force: tensor([1.0879, 0.7707, 0.6469, 0.5466, 0.5885, 0.5495, 0.5189, 0.6140, 0.6038,
        0.6129, 0.5943, 0.6167], device='cuda:1')
Storing NORMAL transition: reward=0.0519 (scaled=0.0519), steps=1
Reward stats updated: mean 0.0152 -> 0.0153, std: 0.0900
Collected 408 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=1.1930, Q2 Loss=1.1930, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0042
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=1.1545, Q2 Loss=1.1545, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5525
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=0.9439, Q2 Loss=0.9439, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8723
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.7964, Q2 Loss=0.7964, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3054
SAC Update 5/5: Actor Loss=-0.0120, Q1 Loss=2.8902, Q2 Loss=2.8902, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1537

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (40.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009180
Q1 loss: 1.395623
Q2 loss: 1.395623
Current threshold: -149.5173
Global Scale Offset: 3319.9816
Reward stats: mean=0.0153, std=0.0900, count=408
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.3956, Q2 Loss: 1.3956, Entropy: 0.6931, Mean TD Error: 1.5776, Threshold: -149.5173
tensor([ 0.1252,  0.6134,  0.5259,  0.6250, -0.0790,  0.5932,  0.9613,  0.8571,
         1.3791,  0.4110, -0.0313,  1.1072, -0.0620, -0.0392, -0.1547,  3.5443],
       device='cuda:1')
Original likelihood: -157.66732788085938
Adjusted likelihood: -157.66732788085938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4990)
State is out of distribution
Projection step: 0, Loss: 159.998291015625
Projection step: 1, Loss: 151.39422607421875
Projection step: 2, Loss: 150.12960815429688
Projection step: 3, Loss: 140.798095703125
Projection step: 4, Loss: 140.92176818847656
Projection step: 5, Loss: 139.07290649414062
Projection step: 6, Loss: 134.64651489257812
Projection step: 7, Loss: 129.69924926757812
Projection step: 8, Loss: 131.01553344726562
Projection step: 9, Loss: 131.34579467773438
Projection step: 10, Loss: 128.1666259765625
Projection step: 11, Loss: 126.3833999633789
Projection step: 12, Loss: 122.67315673828125
Projection step: 13, Loss: 121.639404296875
Projection step: 14, Loss: 121.80378723144531
Projection step: 15, Loss: 118.39368438720703
Projection step: 16, Loss: 117.71141815185547
Projection step: 17, Loss: 116.26226806640625
Projection step: 18, Loss: 112.99827575683594
Projection step: 19, Loss: 113.93537902832031
Projection step: 20, Loss: 112.64292907714844
Projection step: 21, Loss: 111.59031677246094
Projection step: 22, Loss: 107.62184143066406
Projection step: 23, Loss: 106.2689208984375
Projection step: 24, Loss: 104.19821166992188
Final likelihood: tensor([-101.4468, -102.8518, -106.1624,  -98.8774,  -98.1265, -108.7236,
        -109.2291, -108.8413, -102.3155,  -99.9920, -110.4606, -102.0707,
        -112.9459,  -97.5714, -107.9604,  -99.5961])
Final projection likelihood: -104.1982
1 mode projection succeeded
New goal: tensor([ 0.1035,  0.5648,  0.5660,  0.5828, -0.0279,  0.6194,  0.8330,  0.8825,
         1.3894,  0.4024,  0.0775,  1.0172, -0.0597, -0.0266, -1.0003],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -140.88815307617188
Adjusted likelihood: -140.88815307617188
Likelihood residual: 0.0
Original likelihood: -157.0278778076172
Adjusted likelihood: -157.0278778076172
Likelihood residual: 0.0
{'index': 157.0278778076172, 'thumb_middle': 140.88815307617188}
Current yaw: tensor([-0.0620, -0.0392, -0.1547], device='cuda:1')
11 thumb_middle
tensor([ 0.1252,  0.6134,  0.5259,  0.6250, -0.0790,  0.5932,  0.9613,  0.8571,
         1.3791,  0.4110, -0.0313,  1.1072, -0.0620, -0.0392, -0.1547,  3.5443],
       device='cuda:1')
Solve time for step 1 8.838300985051319
Current ori: tensor([-0.0620, -0.0392, -0.1547], device='cuda:1')
Index force: tensor([0.5813, 0.5675, 0.5866, 0.5742], device='cuda:1')
tensor([ 0.1108,  0.5843,  0.5727,  0.5801, -0.1314,  0.5778,  0.8133,  0.8696,
         1.3342,  0.3814, -0.0258,  0.9864, -0.0592, -0.0282, -0.1547,  3.5286],
       device='cuda:1')
Solve time for step 2 3.5291492349933833
Current ori: tensor([-0.0592, -0.0282, -0.1547], device='cuda:1')
Index force: tensor([0.5587, 0.5776, 0.5661], device='cuda:1')
tensor([ 0.1111,  0.5819,  0.5754,  0.5820, -0.1392,  0.5907,  0.8026,  0.8533,
         1.3394,  0.4016, -0.0260,  0.9701, -0.0586, -0.0282, -0.1547,  3.5284],
       device='cuda:1')
Solve time for step 3 3.559018848987762
Current ori: tensor([-0.0586, -0.0282, -0.1547], device='cuda:1')
Index force: tensor([0.5643, 0.5559], device='cuda:1')
tensor([ 0.1026,  0.5763,  0.5726,  0.5879, -0.1338,  0.5809,  0.7904,  0.8518,
         1.3471,  0.3911, -0.0273,  0.9727, -0.0572, -0.0227, -0.1547,  3.5204],
       device='cuda:1')
Solve time for step 4 3.538150849053636
Current ori: tensor([-0.0572, -0.0227, -0.1547], device='cuda:1')
Index force: tensor([0.5744], device='cuda:1')
Storing RECOVERY transition: reward=0.0040 (scaled=0.0040), steps=1
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0899
Collected 409 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.8142, Q2 Loss=0.8142, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7879
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.9597, Q2 Loss=0.9597, Entropy=0.6926, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9925
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.8014, Q2 Loss=1.8014, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2990
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.8588, Q2 Loss=0.8588, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0798
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.4905, Q2 Loss=1.4905, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1011

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.6%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008617
Q1 loss: 1.184925
Q2 loss: 1.184925
Current threshold: -149.5170
Global Scale Offset: 3344.4750
Reward stats: mean=0.0153, std=0.0899, count=409
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1849, Q2 Loss: 1.1849, Entropy: 0.6930, Mean TD Error: 1.6520, Threshold: -149.5170
Original likelihood: -115.62174987792969
Adjusted likelihood: -115.62174987792969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5040)
State is out of distribution
Projection step: 0, Loss: 110.87411499023438
Projection step: 1, Loss: 104.24407958984375
Final likelihood: tensor([-101.9565, -103.8110,  -99.3643, -104.4227, -108.3848, -101.7164,
        -112.3142, -103.8192, -104.4216, -103.8178,  -96.5959, -100.9131,
        -114.4694, -106.6667, -102.1122, -103.1193])
Final projection likelihood: -104.2441
1 mode projection succeeded
New goal: tensor([ 0.0869,  0.5614,  0.5701,  0.5889, -0.0762,  0.6282,  0.8271,  0.8805,
         1.4063,  0.3994,  0.0446,  1.0093, -0.0529, -0.0164, -0.1691],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0023]], device='cuda:1')
Original likelihood: -123.24227905273438
Adjusted likelihood: -123.24227905273438
Likelihood residual: 0.0
Original likelihood: -128.73141479492188
Adjusted likelihood: -128.73141479492188
Likelihood residual: 0.0
{'index': 128.73141479492188, 'thumb_middle': 123.24227905273438}
Current yaw: tensor([-0.0529, -0.0170, -0.1562], device='cuda:1')
12 thumb_middle
tensor([ 0.0865,  0.5638,  0.5716,  0.5938, -0.0831,  0.6259,  0.8254,  0.8744,
         1.4055,  0.4000,  0.0336,  1.0075, -0.0529, -0.0170, -0.1562,  3.5276],
       device='cuda:1')
Solve time for step 1 9.148453040979803
Current ori: tensor([-0.0529, -0.0170, -0.1562], device='cuda:1')
Index force: tensor([0.6023, 0.6085, 0.5788, 0.6017], device='cuda:1')
tensor([ 0.0856,  0.5653,  0.5719,  0.5856, -0.1717,  0.5986,  0.7930,  0.8596,
         1.3684,  0.3918, -0.0317,  0.9732, -0.0563, -0.0109, -0.1563,  3.4922],
       device='cuda:1')
Solve time for step 2 3.506739670992829
Current ori: tensor([-0.0563, -0.0109, -0.1563], device='cuda:1')
Index force: tensor([0.6033, 0.5756, 0.5979], device='cuda:1')
tensor([ 0.0876,  0.5678,  0.5702,  0.5869, -0.1814,  0.6066,  0.7941,  0.8605,
         1.3734,  0.3888, -0.0402,  0.9694, -0.0564, -0.0123, -0.1563,  3.4981],
       device='cuda:1')
Solve time for step 3 3.471497051010374
Current ori: tensor([-0.0564, -0.0123, -0.1563], device='cuda:1')
Index force: tensor([0.5663, 0.5892], device='cuda:1')
tensor([ 0.0983,  0.5668,  0.5761,  0.5998, -0.1760,  0.6106,  0.7963,  0.8608,
         1.3712,  0.3889, -0.0448,  0.9700, -0.0548, -0.0193, -0.1563,  3.5137],
       device='cuda:1')
Solve time for step 4 3.4250789000070654
Current ori: tensor([-0.0548, -0.0193, -0.1563], device='cuda:1')
Index force: tensor([0.5586], device='cuda:1')
Storing RECOVERY transition: reward=0.0058 (scaled=0.0058), steps=1
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0898
Collected 410 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.9638, Q2 Loss=0.9638, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6096
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.8949, Q2 Loss=0.8949, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5304
SAC Update 3/5: Actor Loss=-0.0129, Q1 Loss=1.2655, Q2 Loss=1.2655, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2399
SAC Update 4/5: Actor Loss=-0.0125, Q1 Loss=1.2529, Q2 Loss=1.2529, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4108
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=1.1708, Q2 Loss=1.1708, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2257

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.7%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.4%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010527
Q1 loss: 1.109577
Q2 loss: 1.109577
Current threshold: -149.5166
Global Scale Offset: 3359.1938
Reward stats: mean=0.0152, std=0.0898, count=410
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.1096, Q2 Loss: 1.1096, Entropy: 0.6931, Mean TD Error: 0.6033, Threshold: -149.5166
Original likelihood: -136.89181518554688
Adjusted likelihood: -136.89181518554688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5015)
State is out of distribution
Projection step: 0, Loss: 142.26956176757812
Projection step: 1, Loss: 132.09603881835938
Projection step: 2, Loss: 128.86639404296875
Projection step: 3, Loss: 125.7926025390625
Projection step: 4, Loss: 126.96564483642578
Projection step: 5, Loss: 128.39149475097656
Projection step: 6, Loss: 113.81407928466797
Projection step: 7, Loss: 130.15924072265625
Projection step: 8, Loss: 114.25151062011719
Projection step: 9, Loss: 121.35739135742188
Projection step: 10, Loss: 120.74449920654297
Projection step: 11, Loss: 125.42271423339844
Projection step: 12, Loss: 111.66563415527344
Projection step: 13, Loss: 120.90895080566406
Projection step: 14, Loss: 110.61088562011719
Projection step: 15, Loss: 111.08580780029297
Projection step: 16, Loss: 98.8703842163086
Final likelihood: tensor([ -92.7286,  -88.3927,  -84.8127,  -85.0143,  -84.7172, -112.0749,
         -92.7672,  -85.7789, -114.8527, -122.5818, -142.0793, -117.0644,
         -90.1991,  -91.1986,  -94.5270,  -83.1367])
Final projection likelihood: -98.8704
1 mode projection succeeded
New goal: tensor([ 0.0937,  0.5453,  0.5814,  0.6500, -0.0469,  0.6388,  0.7948,  0.8834,
         1.4213,  0.3788,  0.1243,  0.9421, -0.0506, -0.0112, -0.4675],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -105.7620620727539
Adjusted likelihood: -105.7620620727539
Likelihood residual: 0.0
Original likelihood: -154.8170166015625
Adjusted likelihood: -154.8170166015625
Likelihood residual: 0.0
{'index': 154.8170166015625, 'thumb_middle': 105.7620620727539}
Current yaw: tensor([-0.0512, -0.0201, -0.1580], device='cuda:1')
13 thumb_middle
tensor([ 0.0916,  0.5598,  0.5775,  0.6028, -0.1128,  0.6595,  0.8341,  0.8799,
         1.4278,  0.3981,  0.0080,  1.0067, -0.0512, -0.0201, -0.1580,  3.5363],
       device='cuda:1')
Solve time for step 1 9.217659641988575
Current ori: tensor([-0.0512, -0.0201, -0.1580], device='cuda:1')
Index force: tensor([0.5835, 0.5821, 0.5709, 0.6002], device='cuda:1')
tensor([ 0.0901,  0.5606,  0.5671,  0.6176, -0.1568,  0.6068,  0.7625,  0.8607,
         1.3671,  0.3721,  0.0096,  0.9036, -0.0521, -0.0140, -0.1580,  3.5095],
       device='cuda:1')
Solve time for step 2 3.671139893005602
Current ori: tensor([-0.0521, -0.0140, -0.1580], device='cuda:1')
Index force: tensor([0.5747, 0.5665, 0.5939], device='cuda:1')
tensor([ 0.0970,  0.5461,  0.5786,  0.6480, -0.1588,  0.6109,  0.7604,  0.8608,
         1.3670,  0.3635,  0.0114,  0.8956, -0.0452, -0.0183, -0.1580,  3.5348],
       device='cuda:1')
Solve time for step 3 3.430549378041178
Current ori: tensor([-0.0452, -0.0183, -0.1580], device='cuda:1')
Index force: tensor([0.5594, 0.5858], device='cuda:1')
tensor([ 0.0938,  0.5426,  0.5772,  0.6541, -0.1579,  0.6105,  0.7551,  0.8595,
         1.3670,  0.3671,  0.0162,  0.8892, -0.0442, -0.0160, -0.1580,  3.5295],
       device='cuda:1')
Solve time for step 4 3.2513011940172873
Current ori: tensor([-0.0442, -0.0160, -0.1580], device='cuda:1')
Index force: tensor([0.5752], device='cuda:1')
Storing RECOVERY transition: reward=0.0109 (scaled=0.0109), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0897
Collected 411 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.1987, Q2 Loss=1.1987, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0476
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=1.1315, Q2 Loss=1.1315, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5763
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8254, Q2 Loss=0.8254, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3694
SAC Update 4/5: Actor Loss=-0.0138, Q1 Loss=1.5628, Q2 Loss=1.5628, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9713
SAC Update 5/5: Actor Loss=-0.0127, Q1 Loss=1.2862, Q2 Loss=1.2862, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4575

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011072
Q1 loss: 1.200947
Q2 loss: 1.200947
Current threshold: -149.5163
Global Scale Offset: 3370.8993
Reward stats: mean=0.0152, std=0.0897, count=411
----------------------------------------------
SAC Update - Actor Loss: -0.0111, Q1 Loss: 1.2009, Q2 Loss: 1.2009, Entropy: 0.6931, Mean TD Error: 0.6844, Threshold: -149.5163
Original likelihood: -109.03136444091797
Adjusted likelihood: -109.03136444091797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5048)
Current yaw: tensor([-0.0434, -0.0223, -0.1625], device='cuda:1')
14 turn
Sampling time 3.5865798739832826
tensor([ 0.0972,  0.5470,  0.5755,  0.6521, -0.0875,  0.6621,  0.7946,  0.8797,
         1.4205,  0.3774,  0.0684,  0.9225, -0.0434, -0.0223, -0.1625,  3.5607],
       device='cuda:1')
Original likelihood: -113.7789077758789
Adjusted likelihood: -113.7789077758789
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5042)
Solve time for step 1 14.111773418961093
Current ori: tensor([-0.0434, -0.0223, -0.1625], device='cuda:1')
Middle force: tensor([0.5675, 0.5548, 1.3735, 0.6427, 0.5606, 0.5452, 1.1060, 0.5272, 0.6481,
        0.5645, 1.0625, 0.7653], device='cuda:1')
Thumb force: tensor([0.6170, 1.0999, 1.0220, 1.2099, 0.5525, 1.0834, 0.8243, 0.5950, 0.5880,
        0.6268, 0.7209, 1.1446], device='cuda:1')
Index force: tensor([0.6512, 0.5168, 1.4084, 0.5789, 0.5512, 0.5469, 0.5416, 0.5105, 0.5241,
        0.6558, 0.5535, 0.6429], device='cuda:1')
Storing NORMAL transition: reward=-0.0017 (scaled=-0.0017), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0896
Collected 412 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=0.9313, Q2 Loss=0.9313, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1480
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.7291, Q2 Loss=0.7291, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2111
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=1.0756, Q2 Loss=1.0756, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1301
SAC Update 4/5: Actor Loss=-0.0106, Q1 Loss=1.2125, Q2 Loss=1.2125, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9902
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.1794, Q2 Loss=1.1794, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0953

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008662
Q1 loss: 1.025579
Q2 loss: 1.025579
Current threshold: -149.5159
Global Scale Offset: 3376.4890
Reward stats: mean=0.0152, std=0.0896, count=412
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.0256, Q2 Loss: 1.0256, Entropy: 0.6931, Mean TD Error: 1.1150, Threshold: -149.5159
tensor([ 0.0459,  0.6020,  0.4182,  0.7061, -0.0797,  0.6868,  0.6845,  1.0306,
         1.4061,  0.4001,  0.0703,  0.9556, -0.0313, -0.0244, -0.1601,  3.8871],
       device='cuda:1')
Original likelihood: -155.52670288085938
Adjusted likelihood: -155.52670288085938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4993)
Solve time for step 2 5.430062700994313
Current ori: tensor([-0.0313, -0.0244, -0.1601], device='cuda:1')
Middle force: tensor([0.5525, 1.4076, 0.6421, 0.5675, 0.5466, 1.0890, 0.5415, 0.6448, 0.5764,
        1.0559, 0.7706], device='cuda:1')
Thumb force: tensor([1.0828, 0.9683, 1.1921, 0.5487, 1.0602, 0.8164, 0.5791, 0.5849, 0.6113,
        0.7062, 1.1196], device='cuda:1')
Index force: tensor([0.5156, 1.3656, 0.5760, 0.5453, 0.5450, 0.5407, 0.5074, 0.5231, 0.6418,
        0.5523, 0.6351], device='cuda:1')
Storing NORMAL transition: reward=0.0730 (scaled=0.0730), steps=1
Reward stats updated: mean 0.0152 -> 0.0153, std: 0.0895
Collected 413 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=1.7766, Q2 Loss=1.7766, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5155
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=1.4086, Q2 Loss=1.4086, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7521
SAC Update 3/5: Actor Loss=-0.0123, Q1 Loss=2.6345, Q2 Loss=2.6345, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8074
SAC Update 4/5: Actor Loss=-0.0112, Q1 Loss=1.1150, Q2 Loss=1.1150, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3524
SAC Update 5/5: Actor Loss=-0.0136, Q1 Loss=1.3631, Q2 Loss=1.3631, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0962

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.3%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010914
Q1 loss: 1.659584
Q2 loss: 1.659584
Current threshold: -149.5155
Global Scale Offset: 3387.4195
Reward stats: mean=0.0153, std=0.0895, count=413
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.6596, Q2 Loss: 1.6596, Entropy: 0.6931, Mean TD Error: 2.1047, Threshold: -149.5155
tensor([ 5.5068e-03,  5.1271e-01,  5.5567e-01,  7.9799e-01,  1.2256e-02,
         7.9508e-01,  5.9729e-01,  1.1588e+00,  1.4355e+00,  3.2007e-01,
         1.4858e-03,  8.6740e-01, -3.5413e-02, -1.0903e-01, -2.4629e-01,
         4.8430e+00], device='cuda:1')
Original likelihood: -220.73992919921875
Adjusted likelihood: -220.73992919921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4916)
Solve time for step 3 5.1124709689756855
Current ori: tensor([-0.0354, -0.1090, -0.2463], device='cuda:1')
Middle force: tensor([1.4420, 0.6473, 0.5914, 0.5461, 1.0629, 0.5755, 0.6353, 0.6034, 1.0379,
        0.7846], device='cuda:1')
Thumb force: tensor([0.9216, 1.1806, 0.5454, 1.0404, 0.8186, 0.5658, 0.5824, 0.5978, 0.6974,
        1.1015], device='cuda:1')
Index force: tensor([1.2982, 0.5688, 0.5330, 0.5447, 0.5412, 0.5046, 0.5233, 0.6139, 0.5527,
        0.6197], device='cuda:1')
Storing NORMAL transition: reward=0.0909 (scaled=0.0909), steps=1
Reward stats updated: mean 0.0153 -> 0.0155, std: 0.0895
Collected 414 transitions for RL
SAC Update 1/5: Actor Loss=-0.0071, Q1 Loss=0.7259, Q2 Loss=0.7259, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4241
SAC Update 2/5: Actor Loss=-0.0080, Q1 Loss=0.9018, Q2 Loss=0.9018, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9113
SAC Update 3/5: Actor Loss=-0.0118, Q1 Loss=1.9811, Q2 Loss=1.9811, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1460
SAC Update 4/5: Actor Loss=-0.0097, Q1 Loss=0.9646, Q2 Loss=0.9646, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2152
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=1.3478, Q2 Loss=1.3478, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8395

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.7%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008908
Q1 loss: 1.184232
Q2 loss: 1.184232
Current threshold: -149.5154
Global Scale Offset: 3403.6406
Reward stats: mean=0.0155, std=0.0895, count=414
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.1842, Q2 Loss: 1.1842, Entropy: 0.6930, Mean TD Error: 1.3072, Threshold: -149.5154
tensor([ 0.0953,  0.5478,  0.5100,  0.8542,  0.0174,  0.6673,  0.7616,  1.0979,
         1.4986,  0.1383, -0.0469,  0.9260,  0.0148, -0.1303, -0.3470,  5.9781],
       device='cuda:1')
Original likelihood: -234.14077758789062
Adjusted likelihood: -234.14077758789062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4901)
State is out of distribution
Projection step: 0, Loss: 260.6855163574219
Projection step: 1, Loss: 240.34988403320312
Projection step: 2, Loss: 228.42344665527344
Projection step: 3, Loss: 215.29315185546875
Projection step: 4, Loss: 232.45657348632812
Projection step: 5, Loss: 217.96682739257812
Projection step: 6, Loss: 230.19659423828125
Projection step: 7, Loss: 232.96104431152344
Projection step: 8, Loss: 226.18582153320312
Projection step: 9, Loss: 243.705322265625
Projection step: 10, Loss: 240.42828369140625
Projection step: 11, Loss: 209.69302368164062
Projection step: 12, Loss: 215.47027587890625
Projection step: 13, Loss: 232.73681640625
Projection step: 14, Loss: 223.3148193359375
Projection step: 15, Loss: 234.47171020507812
Projection step: 16, Loss: 217.19822692871094
Projection step: 17, Loss: 228.1201171875
Projection step: 18, Loss: 222.3631591796875
Projection step: 19, Loss: 228.1339569091797
Projection step: 20, Loss: 230.34353637695312
Projection step: 21, Loss: 210.716064453125
Projection step: 22, Loss: 211.52088928222656
Projection step: 23, Loss: 222.36642456054688
Projection step: 24, Loss: 195.61541748046875
Final likelihood: tensor([-221.1850, -275.6818, -270.1191, -258.1377, -253.8627, -226.7983,
        -200.1298, -241.8020, -284.1673, -325.6898, -275.0277, -210.9695,
        -258.6446, -196.0021, -231.4907, -209.5469])
Final projection likelihood: -246.2034
1 mode projection failed, trying anyway
New goal: tensor([ 0.1177,  0.4626,  0.5868,  0.9119,  0.0255,  0.6982,  0.7622,  1.0010,
         1.4965,  0.0960,  0.0883,  0.9885,  0.0112, -0.1183, -0.4366],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0080]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -251.2039337158203
Adjusted likelihood: -251.2039337158203
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 251.2039337158203}
Current yaw: tensor([ 0.0148, -0.1303, -0.3470], device='cuda:1')
15 thumb_middle
tensor([ 0.0953,  0.5478,  0.5100,  0.8542,  0.0174,  0.6673,  0.7616,  1.0979,
         1.4986,  0.1383, -0.0469,  0.9260,  0.0148, -0.1303, -0.3470,  5.9781],
       device='cuda:1')
Solve time for step 1 9.128989638993517
Current ori: tensor([ 0.0148, -0.1303, -0.3470], device='cuda:1')
Index force: tensor([0.5991, 0.6071, 0.5984, 0.5070], device='cuda:1')
tensor([ 0.0798,  0.5337,  0.6180,  0.9236, -0.0292,  0.6926,  0.7427,  1.0053,
         1.3975,  0.0782, -0.0830,  0.9095,  0.0314, -0.2590, -0.3846, -5.4993],
       device='cuda:1')
Solve time for step 2 3.939349806983955
Current ori: tensor([ 0.0314, -0.2590, -0.3846], device='cuda:1')
Index force: tensor([0.5971, 0.5942, 0.5037], device='cuda:1')
tensor([ 0.0554,  0.5682,  0.6863,  0.9763,  0.0118,  0.7475,  0.7739,  1.0015,
         1.3576,  0.0663, -0.1370,  0.8844,  0.0636, -0.3520, -0.5195, -4.9756],
       device='cuda:1')
Solve time for step 3 3.49834050697973
Current ori: tensor([ 0.0636, -0.3520, -0.5195], device='cuda:1')
Index force: tensor([0.5689, 0.5024], device='cuda:1')
tensor([ 0.0245,  0.6681,  0.7350,  0.9878,  0.0591,  0.7831,  0.7784,  0.9885,
         1.3463,  0.0709, -0.1561,  0.8674,  0.1031, -0.4161, -0.6566, -3.9276],
       device='cuda:1')
Solve time for step 4 3.5666246339678764
Current ori: tensor([ 0.1031, -0.4161, -0.6566], device='cuda:1')
Index force: tensor([0.5019], device='cuda:1')
Storing RECOVERY transition: reward=-0.0201 (scaled=-0.0067), steps=3
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0894
Collected 415 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=0.9448, Q2 Loss=0.9448, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4049
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.9993, Q2 Loss=0.9993, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6799
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=1.2183, Q2 Loss=1.2183, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2315
SAC Update 4/5: Actor Loss=-0.0126, Q1 Loss=1.3087, Q2 Loss=1.3087, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4994
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=1.1793, Q2 Loss=1.1793, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0731

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.0%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010174
Q1 loss: 1.130069
Q2 loss: 1.130069
Current threshold: -149.5154
Global Scale Offset: 3422.4121
Reward stats: mean=0.0155, std=0.0894, count=415
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.1301, Q2 Loss: 1.1301, Entropy: 0.6931, Mean TD Error: 0.7778, Threshold: -149.5154
Original likelihood: -1218.0206298828125
Adjusted likelihood: -1218.0206298828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3775)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 27
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
1 turn
Sampling time 3.617683646036312
tensor([ 1.0921e-01,  6.3164e-01,  5.1150e-01,  5.7840e-01, -1.0769e-01,
         5.5846e-01,  8.6971e-01,  8.7851e-01,  1.2295e+00,  2.7769e-01,
         2.3081e-01,  1.2361e+00, -9.3450e-04,  1.4776e-02, -2.9111e-02,
         2.5557e-01], device='cuda:1')
Original likelihood: -88.3533935546875
Adjusted likelihood: -88.3533935546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5071)
Solve time for step 1 14.073103165952489
Current ori: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Middle force: tensor([0.5832, 0.5767, 1.1678, 0.5656, 1.1390, 0.6539, 0.5393, 0.5805, 0.5159,
        0.8315, 0.7353, 0.4987], device='cuda:1')
Thumb force: tensor([0.8873, 0.8714, 0.7862, 1.0936, 1.0250, 0.6646, 0.5277, 0.8511, 0.5413,
        0.5512, 0.6807, 0.6058], device='cuda:1')
Index force: tensor([0.6029, 0.6075, 0.5642, 0.5799, 0.8394, 0.5275, 1.0401, 0.9303, 0.6105,
        0.6000, 0.7874, 0.7340], device='cuda:1')
Storing NORMAL transition: reward=-0.0581 (scaled=-0.0581), steps=1
Reward stats updated: mean 0.0155 -> 0.0153, std: 0.0894
Collected 416 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.9699, Q2 Loss=0.9699, Entropy=0.6929, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7271
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8122, Q2 Loss=0.8122, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5765
SAC Update 3/5: Actor Loss=-0.0071, Q1 Loss=0.8358, Q2 Loss=0.8358, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3060
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=1.1147, Q2 Loss=1.1147, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7750
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=1.1345, Q2 Loss=1.1345, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1602

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (39.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008896
Q1 loss: 0.973401
Q2 loss: 0.973401
Current threshold: -149.5154
Global Scale Offset: 3449.8468
Reward stats: mean=0.0153, std=0.0894, count=416
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.9734, Q2 Loss: 0.9734, Entropy: 0.6930, Mean TD Error: 0.9090, Threshold: -149.5154
tensor([ 0.0427,  0.5692,  0.4996,  0.6400, -0.1074,  0.5403,  0.8639,  0.9181,
         1.2212,  0.2729,  0.2389,  1.2899,  0.0173,  0.0092,  0.0289,  0.4043],
       device='cuda:1')
Original likelihood: -57.91032409667969
Adjusted likelihood: -57.91032409667969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5106)
State is out of distribution
Projection step: 0, Loss: 59.76704406738281
Final likelihood: tensor([-59.4687, -58.0032, -59.2990, -59.1747, -59.3276, -63.7217, -59.4726,
        -54.7747, -59.1907, -65.0553, -58.6597, -56.8382, -59.0085, -67.4680,
        -59.2771, -57.5330])
Final projection likelihood: -59.7670
1 mode projection succeeded
New goal: tensor([ 0.0427,  0.5692,  0.4996,  0.6400, -0.1074,  0.5403,  0.8639,  0.9181,
         1.2212,  0.2729,  0.2389,  1.2899,  0.0173,  0.0092,  0.0289],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([0.0173, 0.0092, 0.0289], device='cuda:1')
2 turn
Sampling time 3.6597978839999996
tensor([ 0.0427,  0.5692,  0.4996,  0.6400, -0.1074,  0.5403,  0.8639,  0.9181,
         1.2212,  0.2729,  0.2389,  1.2899,  0.0173,  0.0092,  0.0289,  0.4043],
       device='cuda:1')
Original likelihood: -62.74189758300781
Adjusted likelihood: -62.74189758300781
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5100)
State is out of distribution
Projection step: 0, Loss: 61.07788848876953
Final likelihood: tensor([-55.5376, -60.4631, -56.2274, -62.7536, -54.8698, -61.1327, -68.3059,
        -55.1185, -60.0962, -56.1745, -61.3469, -97.0687, -53.9367, -55.9289,
        -60.3358, -57.9500])
Final projection likelihood: -61.0779
1 mode projection succeeded
New goal: tensor([ 0.0427,  0.5692,  0.4996,  0.6400, -0.1074,  0.5403,  0.8639,  0.9181,
         1.2212,  0.2729,  0.2389,  1.2899,  0.0173,  0.0092,  0.0289],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([0.0173, 0.0092, 0.0289], device='cuda:1')
3 turn
Sampling time 3.6991692949668504
tensor([ 0.0427,  0.5692,  0.4996,  0.6400, -0.1074,  0.5403,  0.8639,  0.9181,
         1.2212,  0.2729,  0.2389,  1.2899,  0.0173,  0.0092,  0.0289,  0.4043],
       device='cuda:1')
Original likelihood: -58.10602569580078
Adjusted likelihood: -58.10602569580078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5106)
Solve time for step 1 13.962975735019427
Current ori: tensor([0.0173, 0.0092, 0.0289], device='cuda:1')
Middle force: tensor([0.5172, 0.9809, 0.5170, 0.6263, 0.8809, 1.3732, 0.5542, 0.5962, 0.5751,
        0.6649, 0.5639, 0.5644], device='cuda:1')
Thumb force: tensor([1.0321, 1.0254, 0.6106, 0.6167, 0.5945, 0.5277, 0.5650, 0.5547, 0.5653,
        0.8379, 1.3999, 0.7989], device='cuda:1')
Index force: tensor([0.6087, 1.3096, 0.6862, 0.5747, 0.9534, 0.8500, 0.5642, 0.6305, 0.5687,
        0.5368, 0.5594, 0.6069], device='cuda:1')
Storing NORMAL transition: reward=0.1315 (scaled=0.1315), steps=1
Reward stats updated: mean 0.0153 -> 0.0156, std: 0.0894
Collected 417 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.4224, Q2 Loss=1.4224, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8749
SAC Update 2/5: Actor Loss=-0.0103, Q1 Loss=1.0564, Q2 Loss=1.0564, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6041
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.5109, Q2 Loss=1.5109, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9155
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=1.8817, Q2 Loss=1.8817, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8785
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=2.0576, Q2 Loss=2.0576, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7343

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (18.7%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010362
Q1 loss: 1.585800
Q2 loss: 1.585800
Current threshold: -149.5154
Global Scale Offset: 3473.9880
Reward stats: mean=0.0156, std=0.0894, count=417
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.5858, Q2 Loss: 1.5858, Entropy: 0.6931, Mean TD Error: 2.0015, Threshold: -149.5154
tensor([ 0.0264,  0.5922,  0.4751,  0.5973, -0.1209,  0.5307,  0.8376,  1.0022,
         1.3413,  0.1353,  0.2150,  1.1819,  0.0050,  0.0164, -0.1026,  0.4697],
       device='cuda:1')
Original likelihood: -50.26219940185547
Adjusted likelihood: -50.26219940185547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5114)
State is out of distribution
Projection step: 0, Loss: 49.52543640136719
Final likelihood: tensor([-49.0471, -47.2618, -49.8929, -51.2107, -49.1423, -50.4226, -49.6622,
        -48.1619, -48.3318, -49.2014, -52.6373, -46.1459, -49.1703, -50.9677,
        -50.9234, -50.2279])
Final projection likelihood: -49.5254
1 mode projection succeeded
New goal: tensor([ 0.0264,  0.5922,  0.4751,  0.5973, -0.1209,  0.5307,  0.8376,  1.0022,
         1.3413,  0.1353,  0.2150,  1.1819,  0.0050,  0.0164, -0.1026],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0050,  0.0164, -0.1026], device='cuda:1')
4 turn
Sampling time 3.60728510201443
tensor([ 0.0264,  0.5922,  0.4751,  0.5973, -0.1209,  0.5307,  0.8376,  1.0022,
         1.3413,  0.1353,  0.2150,  1.1819,  0.0050,  0.0164, -0.1026,  0.4697],
       device='cuda:1')
Original likelihood: -50.7750129699707
Adjusted likelihood: -50.7750129699707
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5113)
State is out of distribution
Projection step: 0, Loss: 49.39128875732422
Final likelihood: tensor([-50.5768, -51.4187, -50.4366, -47.8171, -47.8381, -51.2508, -51.6724,
        -50.1649, -45.2000, -50.0748, -50.1633, -48.0998, -47.5206, -49.8874,
        -51.8139, -46.3253])
Final projection likelihood: -49.3913
1 mode projection succeeded
New goal: tensor([ 0.0264,  0.5922,  0.4751,  0.5973, -0.1209,  0.5307,  0.8376,  1.0022,
         1.3413,  0.1353,  0.2150,  1.1819,  0.0050,  0.0164, -0.1026],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0050,  0.0164, -0.1026], device='cuda:1')
5 turn
Sampling time 3.6991822319687344
tensor([ 0.0264,  0.5922,  0.4751,  0.5973, -0.1209,  0.5307,  0.8376,  1.0022,
         1.3413,  0.1353,  0.2150,  1.1819,  0.0050,  0.0164, -0.1026,  0.4697],
       device='cuda:1')
Original likelihood: -49.353721618652344
Adjusted likelihood: -49.353721618652344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5115)
Solve time for step 1 13.872740892984439
Current ori: tensor([ 0.0050,  0.0164, -0.1026], device='cuda:1')
Middle force: tensor([0.5080, 0.9937, 0.5230, 0.6251, 0.8796, 1.3620, 0.5816, 0.5980, 0.5314,
        0.5758, 0.5923, 0.5172], device='cuda:1')
Thumb force: tensor([1.0295, 1.0532, 0.6135, 0.6130, 0.6004, 0.5333, 0.5858, 1.3319, 0.5923,
        0.9318, 1.1003, 0.8346], device='cuda:1')
Index force: tensor([0.6233, 1.2946, 0.6732, 0.5799, 0.9688, 0.8525, 0.5577, 0.5617, 0.6698,
        0.5393, 0.6148, 0.5979], device='cuda:1')
Storing NORMAL transition: reward=0.0293 (scaled=0.0293), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0893
Collected 418 transitions for RL
SAC Update 1/5: Actor Loss=-0.0127, Q1 Loss=2.9556, Q2 Loss=2.9556, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9874
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=0.9487, Q2 Loss=0.9487, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6468
SAC Update 3/5: Actor Loss=-0.0108, Q1 Loss=1.6124, Q2 Loss=1.6124, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8653
SAC Update 4/5: Actor Loss=-0.0129, Q1 Loss=1.4021, Q2 Loss=1.4021, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8065
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.7408, Q2 Loss=0.7408, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2343

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.3%)
Actor update: 0.08s (39.5%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010639
Q1 loss: 1.531929
Q2 loss: 1.531929
Current threshold: -149.5154
Global Scale Offset: 3498.5247
Reward stats: mean=0.0156, std=0.0893, count=418
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.5319, Q2 Loss: 1.5319, Entropy: 0.6930, Mean TD Error: 1.3081, Threshold: -149.5154
tensor([ 0.0881,  0.6250,  0.4658,  0.6414, -0.0765,  0.5531,  0.8243,  1.0286,
         1.3905,  0.0228,  0.1355,  1.2239,  0.0020, -0.0117, -0.1318,  0.4810],
       device='cuda:1')
Original likelihood: -121.76531982421875
Adjusted likelihood: -121.76531982421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5032)
State is out of distribution
Projection step: 0, Loss: 123.07431030273438
Projection step: 1, Loss: 121.15457153320312
Projection step: 2, Loss: 110.24011993408203
Projection step: 3, Loss: 114.20884704589844
Projection step: 4, Loss: 104.68109130859375
Final likelihood: tensor([ -96.6595, -127.4530,  -95.0373,  -98.5535,  -94.9408, -136.1761,
         -96.8260, -100.7491, -100.4926,  -97.9663, -105.3348,  -96.9571,
        -134.8359, -101.8119,  -96.1657,  -94.9380])
Final projection likelihood: -104.6811
1 mode projection succeeded
New goal: tensor([ 0.0850,  0.6012,  0.4986,  0.6149, -0.0764,  0.5500,  0.8257,  1.0004,
         1.3799,  0.0528,  0.1526,  1.2160,  0.0021, -0.0107, -0.2693],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -127.79541015625
Adjusted likelihood: -127.79541015625
Likelihood residual: 0.0
Original likelihood: -141.53509521484375
Adjusted likelihood: -141.53509521484375
Likelihood residual: 0.0
{'index': 141.53509521484375, 'thumb_middle': 127.79541015625}
Current yaw: tensor([ 0.0020, -0.0117, -0.1318], device='cuda:1')
6 thumb_middle
tensor([ 0.0881,  0.6250,  0.4658,  0.6414, -0.0765,  0.5531,  0.8243,  1.0286,
         1.3905,  0.0228,  0.1355,  1.2239,  0.0020, -0.0117, -0.1318,  0.4810],
       device='cuda:1')
Solve time for step 1 8.820327711990103
Current ori: tensor([ 0.0020, -0.0117, -0.1318], device='cuda:1')
Index force: tensor([0.5836, 0.5982, 0.5029, 0.5984], device='cuda:1')
tensor([ 0.0858,  0.6061,  0.5043,  0.6129, -0.1635,  0.5267,  0.7878,  0.9694,
         1.3287,  0.0141,  0.0767,  1.1862,  0.0040, -0.0119, -0.1318,  0.5181],
       device='cuda:1')
Solve time for step 2 3.6159020960330963
Current ori: tensor([ 0.0040, -0.0119, -0.1318], device='cuda:1')
Index force: tensor([0.5962, 0.5997, 0.5937], device='cuda:1')
tensor([ 6.4373e-02,  6.2105e-01,  4.8039e-01,  5.7887e-01, -1.8068e-01,
         5.2793e-01,  7.8837e-01,  9.7284e-01,  1.3355e+00,  1.5533e-02,
         7.0994e-02,  1.1880e+00, -3.3174e-03, -9.6732e-04, -1.3181e-01,
         4.7001e-01], device='cuda:1')
Solve time for step 3 3.542412211012561
Current ori: tensor([-0.0033, -0.0010, -0.1318], device='cuda:1')
Index force: tensor([0.5902, 0.5858], device='cuda:1')
tensor([ 0.0780,  0.6083,  0.4946,  0.6115, -0.1761,  0.5353,  0.7927,  0.9754,
         1.3347,  0.0143,  0.0598,  1.1819,  0.0030, -0.0077, -0.1318,  0.5048],
       device='cuda:1')
Solve time for step 4 3.4279196219868027
Current ori: tensor([ 0.0030, -0.0077, -0.1318], device='cuda:1')
Index force: tensor([0.5686], device='cuda:1')
Storing RECOVERY transition: reward=0.0081 (scaled=0.0081), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0892
Collected 419 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=0.9556, Q2 Loss=0.9556, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6738
SAC Update 2/5: Actor Loss=-0.0116, Q1 Loss=1.1975, Q2 Loss=1.1975, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4957
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.6513, Q2 Loss=1.6513, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2186
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=1.0926, Q2 Loss=1.0926, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2807
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=0.9301, Q2 Loss=0.9301, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0332

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (17.5%)
Actor update: 0.10s (39.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009796
Q1 loss: 1.165411
Q2 loss: 1.165411
Current threshold: -149.5153
Global Scale Offset: 3512.7252
Reward stats: mean=0.0156, std=0.0892, count=419
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.1654, Q2 Loss: 1.1654, Entropy: 0.6931, Mean TD Error: 1.1404, Threshold: -149.5153
Original likelihood: -105.17633056640625
Adjusted likelihood: -105.17633056640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5050)
Current yaw: tensor([ 0.0056, -0.0102, -0.1399], device='cuda:1')
7 turn
Sampling time 3.8304540470126085
tensor([ 0.0818,  0.6027,  0.5017,  0.6203, -0.1047,  0.5852,  0.8353,  0.9994,
         1.4082,  0.0540,  0.1091,  1.1926,  0.0056, -0.0102, -0.1399,  0.5426],
       device='cuda:1')
Original likelihood: -109.9197006225586
Adjusted likelihood: -109.9197006225586
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5045)
State is out of distribution
Projection step: 0, Loss: 109.84019470214844
Projection step: 1, Loss: 105.76321411132812
Projection step: 2, Loss: 98.96856689453125
Final likelihood: tensor([ -92.3768,  -99.4492,  -96.5229, -111.5115,  -92.4386, -105.8609,
        -100.4763,  -96.0842, -101.0141, -102.4435,  -99.5406,  -95.9408,
         -96.4257,  -99.8374,  -96.5596,  -97.0150])
Final projection likelihood: -98.9686
1 mode projection succeeded
New goal: tensor([ 0.0803,  0.5959,  0.5164,  0.6133, -0.1010,  0.5814,  0.8379,  0.9823,
         1.3982,  0.0625,  0.1261,  1.1789,  0.0057, -0.0098, -0.2180],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -129.02557373046875
Adjusted likelihood: -129.02557373046875
Likelihood residual: 0.0
Original likelihood: -128.46083068847656
Adjusted likelihood: -128.46083068847656
Likelihood residual: 0.0
{'index': 128.46083068847656, 'thumb_middle': 129.02557373046875}
Current yaw: tensor([ 0.0056, -0.0102, -0.1399], device='cuda:1')
8 index
tensor([ 0.0818,  0.6027,  0.5017,  0.6203, -0.1047,  0.5852,  0.8353,  0.9994,
         1.4082,  0.0540,  0.1091,  1.1926,  0.0056, -0.0102, -0.1399,  0.5426],
       device='cuda:1')
Solve time for step 1 10.786162877979223
Current ori: tensor([ 0.0056, -0.0102, -0.1399], device='cuda:1')
Middle force: tensor([0.5851, 0.5009, 0.5404, 0.5463], device='cuda:1')
Thumb force: tensor([0.5571, 0.5482, 0.5064, 0.5826], device='cuda:1')
tensor([ 1.3269e-01,  5.4037e-01,  4.6732e-01,  5.9077e-01, -1.1247e-01,
         5.8357e-01,  8.3547e-01,  9.8660e-01,  1.4538e+00, -1.6152e-02,
         1.1191e-01,  1.1573e+00, -6.6146e-04, -3.9999e-03, -1.6312e-01,
         8.2257e-01], device='cuda:1')
Solve time for step 2 4.37450189399533
Current ori: tensor([-0.0007, -0.0040, -0.1631], device='cuda:1')
Middle force: tensor([0.5006, 0.5369, 0.5421], device='cuda:1')
Thumb force: tensor([0.5420, 0.5050, 0.5773], device='cuda:1')
tensor([ 0.1328,  0.5442,  0.4644,  0.5867, -0.1156,  0.5779,  0.8421,  0.9926,
         1.4001,  0.0858,  0.1145,  1.1894,  0.0020, -0.0031, -0.1649,  0.9964],
       device='cuda:1')
Solve time for step 3 4.143338963971473
Current ori: tensor([ 0.0020, -0.0031, -0.1649], device='cuda:1')
Middle force: tensor([0.5000, 0.5202], device='cuda:1')
Thumb force: tensor([0.5016, 0.5100], device='cuda:1')
tensor([ 1.3263e-01,  5.4301e-01,  4.6391e-01,  5.8619e-01, -1.1571e-01,
         5.8195e-01,  8.3880e-01,  9.8587e-01,  1.4235e+00,  4.4181e-02,
         1.0410e-01,  1.1927e+00,  4.0832e-04, -2.8253e-03, -1.5817e-01,
         1.0940e+00], device='cuda:1')
Solve time for step 4 3.6980834460118786
Current ori: tensor([ 0.0004, -0.0028, -0.1582], device='cuda:1')
Middle force: tensor([0.5161], device='cuda:1')
Thumb force: tensor([0.5084], device='cuda:1')
Storing RECOVERY transition: reward=0.0123 (scaled=0.0123), steps=0
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0891
Collected 420 transitions for RL
SAC Update 1/5: Actor Loss=-0.0098, Q1 Loss=1.0328, Q2 Loss=1.0328, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6223
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=0.9930, Q2 Loss=0.9930, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6806
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=1.2975, Q2 Loss=1.2975, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5474
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=1.9910, Q2 Loss=1.9910, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6665
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=2.1702, Q2 Loss=2.1702, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2743

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.1%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (37.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009226
Q1 loss: 1.496912
Q2 loss: 1.496912
Current threshold: -149.5152
Global Scale Offset: 3526.4640
Reward stats: mean=0.0156, std=0.0891, count=420
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.4969, Q2 Loss: 1.4969, Entropy: 0.6931, Mean TD Error: 1.9582, Threshold: -149.5152
Original likelihood: -109.05621337890625
Adjusted likelihood: -109.05621337890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5046)
Current yaw: tensor([-0.0021, -0.0013, -0.1521], device='cuda:1')
9 turn
Sampling time 3.84330340300221
tensor([ 7.7021e-02,  6.0066e-01,  5.0707e-01,  6.0796e-01, -1.1771e-01,
         5.8685e-01,  8.3308e-01,  9.7813e-01,  1.4145e+00,  6.2544e-02,
         1.1155e-01,  1.1842e+00, -2.1071e-03, -1.2696e-03, -1.5209e-01,
         1.1186e+00], device='cuda:1')
Original likelihood: -108.75749206542969
Adjusted likelihood: -108.75749206542969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5046)
Solve time for step 1 13.799796610022895
Current ori: tensor([-0.0021, -0.0013, -0.1521], device='cuda:1')
Middle force: tensor([0.8490, 2.0998, 0.5631, 1.3894, 0.6559, 0.9486, 0.5502, 0.8222, 0.5052,
        0.6300, 0.5601, 0.6078], device='cuda:1')
Thumb force: tensor([0.6483, 1.1066, 1.5720, 0.5294, 0.5467, 0.6542, 0.5194, 0.6231, 1.1831,
        0.6469, 0.6778, 0.5688], device='cuda:1')
Index force: tensor([0.5895, 1.6217, 0.6254, 0.7025, 0.7428, 0.7251, 0.6523, 0.7795, 0.5867,
        0.7312, 0.5521, 0.5451], device='cuda:1')
Storing NORMAL transition: reward=-0.0070 (scaled=-0.0070), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0890
Collected 421 transitions for RL
SAC Update 1/5: Actor Loss=-0.0139, Q1 Loss=2.6666, Q2 Loss=2.6666, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5300
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.7202, Q2 Loss=1.7202, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5983
SAC Update 3/5: Actor Loss=-0.0111, Q1 Loss=1.2099, Q2 Loss=1.2099, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8603
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7177, Q2 Loss=0.7177, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1551
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=1.6303, Q2 Loss=1.6303, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9276

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.04s (19.4%)
Actor update: 0.08s (37.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010792
Q1 loss: 1.588963
Q2 loss: 1.588963
Current threshold: -149.5149
Global Scale Offset: 3538.1169
Reward stats: mean=0.0155, std=0.0890, count=421
----------------------------------------------
SAC Update - Actor Loss: -0.0108, Q1 Loss: 1.5890, Q2 Loss: 1.5890, Entropy: 0.6931, Mean TD Error: 1.4143, Threshold: -149.5149
tensor([-0.0672,  0.5522,  0.4419,  0.5976, -0.1110,  0.6352,  0.6952,  0.9969,
         1.4899,  0.1859, -0.0181,  1.1294, -0.0146,  0.0124, -0.1455,  0.8743],
       device='cuda:1')
Original likelihood: -154.3363494873047
Adjusted likelihood: -154.3363494873047
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4995)
State is out of distribution
Projection step: 0, Loss: 145.35919189453125
Projection step: 1, Loss: 136.61363220214844
Projection step: 2, Loss: 126.837890625
Projection step: 3, Loss: 124.9381103515625
Projection step: 4, Loss: 115.1811752319336
Projection step: 5, Loss: 106.85303497314453
Projection step: 6, Loss: 105.32138061523438
Projection step: 7, Loss: 95.44566345214844
Final likelihood: tensor([-102.8723,  -89.2388,  -96.1173, -107.7243,  -89.7000,  -90.2346,
        -103.9418,  -99.0599,  -93.0755,  -85.4508,  -93.0824,  -94.4608,
         -98.6895,  -92.4405,  -85.6167, -105.4253])
Final projection likelihood: -95.4457
1 mode projection succeeded
New goal: tensor([-0.0340,  0.5490,  0.5109,  0.6141, -0.0871,  0.6004,  0.6551,  1.0233,
         1.4337,  0.1748,  0.0327,  1.1368, -0.0152,  0.0101, -0.2729],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1')
Original likelihood: -120.74938201904297
Adjusted likelihood: -120.74938201904297
Likelihood residual: 0.0
Original likelihood: -153.4934844970703
Adjusted likelihood: -153.4934844970703
Likelihood residual: 0.0
{'index': 153.4934844970703, 'thumb_middle': 120.74938201904297}
Current yaw: tensor([-0.0146,  0.0124, -0.1455], device='cuda:1')
10 thumb_middle
tensor([-0.0672,  0.5522,  0.4419,  0.5976, -0.1110,  0.6352,  0.6952,  0.9969,
         1.4899,  0.1859, -0.0181,  1.1294, -0.0146,  0.0124, -0.1455,  0.8743],
       device='cuda:1')
Solve time for step 1 9.278504398011137
Current ori: tensor([-0.0146,  0.0124, -0.1455], device='cuda:1')
Index force: tensor([0.5790, 0.5988, 0.5964, 0.5997], device='cuda:1')
tensor([-0.0720,  0.5405,  0.4681,  0.5713, -0.1790,  0.5870,  0.6343,  1.0015,
         1.4123,  0.1595, -0.0386,  1.1095, -0.0172,  0.0175, -0.1436,  0.8803],
       device='cuda:1')
Solve time for step 2 3.691525649977848
Current ori: tensor([-0.0172,  0.0175, -0.1436], device='cuda:1')
Index force: tensor([0.5877, 0.5885, 0.5915], device='cuda:1')
tensor([-0.0481,  0.5157,  0.4963,  0.6224, -0.1679,  0.6004,  0.6361,  1.0049,
         1.4035,  0.1570, -0.0460,  1.1040, -0.0034,  0.0032, -0.1436,  0.9446],
       device='cuda:1')
Solve time for step 3 3.4775656259735115
Current ori: tensor([-0.0034,  0.0032, -0.1436], device='cuda:1')
Index force: tensor([0.5777, 0.5821], device='cuda:1')
tensor([-0.0580,  0.5223,  0.4871,  0.6068, -0.1735,  0.5976,  0.6346,  1.0056,
         1.4049,  0.1557, -0.0426,  1.1082, -0.0063,  0.0088, -0.1436,  0.9292],
       device='cuda:1')
Solve time for step 4 3.4025321769877337
Current ori: tensor([-0.0063,  0.0088, -0.1436], device='cuda:1')
Index force: tensor([0.5732], device='cuda:1')
Storing RECOVERY transition: reward=0.0027 (scaled=0.0027), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0889
Collected 422 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7571, Q2 Loss=0.7571, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2921
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.7573, Q2 Loss=0.7573, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5882
SAC Update 3/5: Actor Loss=-0.0125, Q1 Loss=1.4801, Q2 Loss=1.4801, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1483
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.7704, Q2 Loss=0.7704, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3882
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.5487, Q2 Loss=1.5487, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8652

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009181
Q1 loss: 1.062723
Q2 loss: 1.062723
Current threshold: -149.5145
Global Scale Offset: 3547.0436
Reward stats: mean=0.0155, std=0.0889, count=422
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.0627, Q2 Loss: 1.0627, Entropy: 0.6931, Mean TD Error: 0.8564, Threshold: -149.5145
Original likelihood: -140.73146057128906
Adjusted likelihood: -140.73146057128906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5010)
Current yaw: tensor([-0.0029,  0.0049, -0.1479], device='cuda:1')
11 turn
Sampling time 3.5851405519642867
tensor([-0.0518,  0.5122,  0.4984,  0.6222, -0.1001,  0.6461,  0.6740,  1.0272,
         1.4669,  0.1779,  0.0082,  1.1393, -0.0029,  0.0049, -0.1479,  0.9411],
       device='cuda:1')
Original likelihood: -134.38015747070312
Adjusted likelihood: -134.38015747070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Solve time for step 1 14.145474794029724
Current ori: tensor([-0.0029,  0.0049, -0.1479], device='cuda:1')
Middle force: tensor([0.9328, 1.5274, 1.1613, 0.5050, 1.3756, 0.7084, 0.8252, 0.7114, 0.6102,
        0.5696, 1.4324, 1.0457], device='cuda:1')
Thumb force: tensor([0.9030, 0.8346, 0.9865, 0.5418, 0.9978, 1.2283, 0.5448, 0.5477, 0.6074,
        1.1101, 0.5725, 0.5203], device='cuda:1')
Index force: tensor([0.8240, 0.8962, 0.5965, 0.8530, 1.2208, 0.5728, 0.5195, 0.5170, 0.6148,
        0.5014, 0.5010, 0.6906], device='cuda:1')
Storing NORMAL transition: reward=0.1555 (scaled=0.1555), steps=1
Reward stats updated: mean 0.0155 -> 0.0158, std: 0.0891
Collected 423 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=2.4244, Q2 Loss=2.4244, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1868
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=0.8933, Q2 Loss=0.8933, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3877
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=1.2516, Q2 Loss=1.2516, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3712
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.6327, Q2 Loss=1.6327, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7528
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.1565, Q2 Loss=1.1565, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9275

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (41.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009372
Q1 loss: 1.471706
Q2 loss: 1.471706
Current threshold: -149.5142
Global Scale Offset: 3557.6130
Reward stats: mean=0.0158, std=0.0891, count=423
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.4717, Q2 Loss: 1.4717, Entropy: 0.6931, Mean TD Error: 1.7252, Threshold: -149.5142
tensor([-0.0663,  0.4739,  0.4861,  0.7411, -0.1375,  0.5021,  0.8546,  1.0761,
         1.4671,  0.3020,  0.1171,  0.9312,  0.0076,  0.0209, -0.3040,  1.0275],
       device='cuda:1')
Original likelihood: -158.53744506835938
Adjusted likelihood: -158.53744506835938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4990)
State is out of distribution
Projection step: 0, Loss: 167.055419921875
Projection step: 1, Loss: 150.49557495117188
Projection step: 2, Loss: 142.69577026367188
Projection step: 3, Loss: 126.24576568603516
Projection step: 4, Loss: 116.81825256347656
Projection step: 5, Loss: 105.54545593261719
Projection step: 6, Loss: 104.28466033935547
Final likelihood: tensor([ -97.1509, -117.3417,  -74.6624,  -91.9417,  -86.6735,  -91.3216,
         -88.0429, -108.0216, -125.0211, -122.4772, -123.3951,  -87.3171,
        -112.6290, -131.1505, -106.5113, -104.8971])
Final projection likelihood: -104.2847
1 mode projection succeeded
New goal: tensor([-0.0458,  0.4952,  0.5137,  0.6686, -0.1125,  0.4966,  0.8128,  1.0364,
         1.4186,  0.3036,  0.1492,  0.9747,  0.0057,  0.0183, -0.5828],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -136.5399932861328
Adjusted likelihood: -136.5399932861328
Likelihood residual: 0.0
Original likelihood: -159.64010620117188
Adjusted likelihood: -159.64010620117188
Likelihood residual: 0.0
{'index': 159.64010620117188, 'thumb_middle': 136.5399932861328}
Current yaw: tensor([ 0.0076,  0.0209, -0.3040], device='cuda:1')
12 thumb_middle
tensor([-0.0663,  0.4739,  0.4861,  0.7411, -0.1375,  0.5021,  0.8546,  1.0761,
         1.4671,  0.3020,  0.1171,  0.9312,  0.0076,  0.0209, -0.3040,  1.0275],
       device='cuda:1')
Solve time for step 1 9.235130585031584
Current ori: tensor([ 0.0076,  0.0209, -0.3040], device='cuda:1')
Index force: tensor([0.5426, 0.5859, 0.6058, 0.6063], device='cuda:1')
tensor([-6.0978e-02,  4.8180e-01,  5.0510e-01,  6.8417e-01, -2.0130e-01,
         4.8596e-01,  7.9202e-01,  1.0247e+00,  1.3832e+00,  2.8840e-01,
         6.8566e-02,  9.3296e-01,  1.1550e-03,  1.8006e-02, -3.0397e-01,
         1.0430e+00], device='cuda:1')
Solve time for step 2 3.9792877300060354
Current ori: tensor([ 0.0012,  0.0180, -0.3040], device='cuda:1')
Index force: tensor([0.5789, 0.5997, 0.6006], device='cuda:1')
tensor([-5.4756e-02,  4.8145e-01,  5.0937e-01,  6.8536e-01, -1.9972e-01,
         4.9551e-01,  7.8853e-01,  1.0220e+00,  1.3801e+00,  2.9039e-01,
         6.0664e-02,  9.3505e-01,  4.3339e-04,  1.3838e-02, -3.0397e-01,
         1.0287e+00], device='cuda:1')
Solve time for step 3 3.316865798959043
Current ori: tensor([ 0.0004,  0.0138, -0.3040], device='cuda:1')
Index force: tensor([0.5900, 0.5933], device='cuda:1')
tensor([-0.0663,  0.4699,  0.5136,  0.6923, -0.2086,  0.4944,  0.7877,  1.0163,
         1.3827,  0.2872,  0.0647,  0.9392,  0.0038,  0.0201, -0.3040,  1.0332],
       device='cuda:1')
Solve time for step 4 3.33693680097349
Current ori: tensor([ 0.0038,  0.0201, -0.3040], device='cuda:1')
Index force: tensor([0.5850], device='cuda:1')
Storing RECOVERY transition: reward=-0.0044 (scaled=-0.0044), steps=1
Reward stats updated: mean 0.0158 -> 0.0158, std: 0.0890
Collected 424 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.5272, Q2 Loss=1.5272, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9072
SAC Update 2/5: Actor Loss=-0.0113, Q1 Loss=1.2305, Q2 Loss=1.2305, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8215
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=0.9002, Q2 Loss=0.9002, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6601
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=3.5897, Q2 Loss=3.5897, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0866
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.1850, Q2 Loss=1.1850, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9023

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009798
Q1 loss: 1.686538
Q2 loss: 1.686538
Current threshold: -149.5139
Global Scale Offset: 3575.0556
Reward stats: mean=0.0158, std=0.0890, count=424
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.6865, Q2 Loss: 1.6865, Entropy: 0.6930, Mean TD Error: 2.0755, Threshold: -149.5139
Original likelihood: -178.19058227539062
Adjusted likelihood: -178.19058227539062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4968)
Current yaw: tensor([ 0.0087,  0.0288, -0.3001], device='cuda:1')
13 turn
Sampling time 3.592121885973029
tensor([-0.0897,  0.4664,  0.5062,  0.6810, -0.1579,  0.5365,  0.8271,  1.0471,
         1.4502,  0.3122,  0.1216,  0.9747,  0.0087,  0.0288, -0.3001,  1.0328],
       device='cuda:1')
Original likelihood: -151.34609985351562
Adjusted likelihood: -151.34609985351562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4998)
Solve time for step 1 13.987110855989158
Current ori: tensor([ 0.0087,  0.0288, -0.3001], device='cuda:1')
Middle force: tensor([0.8474, 1.4874, 1.1059, 0.5099, 1.3238, 0.6273, 0.5762, 0.5574, 0.5848,
        0.9238, 0.5870, 0.5656], device='cuda:1')
Thumb force: tensor([0.8999, 0.7633, 0.8870, 0.5574, 0.9441, 1.1119, 0.5542, 0.5095, 0.5433,
        1.2430, 0.5873, 0.5386], device='cuda:1')
Index force: tensor([0.8144, 0.7940, 0.5722, 0.8258, 1.1361, 0.5621, 0.5613, 0.5491, 0.5011,
        0.5835, 0.6046, 0.6002], device='cuda:1')
Storing NORMAL transition: reward=-0.0136 (scaled=-0.0136), steps=1
Reward stats updated: mean 0.0158 -> 0.0157, std: 0.0889
Collected 425 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=1.4010, Q2 Loss=1.4010, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8837
SAC Update 2/5: Actor Loss=-0.0124, Q1 Loss=1.2450, Q2 Loss=1.2450, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2115
SAC Update 3/5: Actor Loss=-0.0095, Q1 Loss=0.9787, Q2 Loss=0.9787, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5431
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.9327, Q2 Loss=0.9327, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6556
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.0815, Q2 Loss=1.0815, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6984

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009615
Q1 loss: 1.127759
Q2 loss: 1.127759
Current threshold: -149.5135
Global Scale Offset: 3591.7613
Reward stats: mean=0.0157, std=0.0889, count=425
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.1278, Q2 Loss: 1.1278, Entropy: 0.6931, Mean TD Error: 1.3984, Threshold: -149.5135
tensor([-0.0791,  0.4348,  0.5520,  0.6938, -0.1519,  0.5398,  0.8328,  1.0322,
         1.4628,  0.3164,  0.0914,  0.9906,  0.0077,  0.0252, -0.2863,  0.9406],
       device='cuda:1')
Original likelihood: -156.31362915039062
Adjusted likelihood: -156.31362915039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4992)
State is out of distribution
Projection step: 0, Loss: 155.29815673828125
Projection step: 1, Loss: 152.70274353027344
Projection step: 2, Loss: 141.91566467285156
Projection step: 3, Loss: 127.62223815917969
Projection step: 4, Loss: 120.09717559814453
Projection step: 5, Loss: 115.24864196777344
Projection step: 6, Loss: 118.71611022949219
Projection step: 7, Loss: 113.24275970458984
Projection step: 8, Loss: 104.72870635986328
Final likelihood: tensor([-125.1171,  -92.4049,  -98.4240, -106.7034, -123.3959, -131.8926,
         -85.0912, -129.4565,  -96.5437, -127.8905,  -95.2639,  -88.3729,
         -94.5715,  -88.1330,  -98.2043,  -94.1942])
Final projection likelihood: -104.7287
1 mode projection succeeded
New goal: tensor([-0.0618,  0.4717,  0.5865,  0.6506, -0.1225,  0.5229,  0.7894,  0.9873,
         1.3933,  0.3045,  0.1193,  1.0432,  0.0061,  0.0207, -0.7853],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -128.26905822753906
Adjusted likelihood: -128.26905822753906
Likelihood residual: 0.0
Original likelihood: -154.70033264160156
Adjusted likelihood: -154.70033264160156
Likelihood residual: 0.0
{'index': 154.70033264160156, 'thumb_middle': 128.26905822753906}
Current yaw: tensor([ 0.0077,  0.0252, -0.2863], device='cuda:1')
14 thumb_middle
tensor([-0.0791,  0.4348,  0.5520,  0.6938, -0.1519,  0.5398,  0.8328,  1.0322,
         1.4628,  0.3164,  0.0914,  0.9906,  0.0077,  0.0252, -0.2863,  0.9406],
       device='cuda:1')
Solve time for step 1 9.054309120983817
Current ori: tensor([ 0.0077,  0.0252, -0.2863], device='cuda:1')
Index force: tensor([0.5497, 0.5850, 0.5937, 0.5850], device='cuda:1')
tensor([-0.0705,  0.4573,  0.5516,  0.6459, -0.2100,  0.5195,  0.7748,  0.9749,
         1.3683,  0.3106,  0.0416,  1.0062, -0.0014,  0.0241, -0.2863,  0.9727],
       device='cuda:1')
Solve time for step 2 3.6887713500182144
Current ori: tensor([-0.0014,  0.0241, -0.2863], device='cuda:1')
Index force: tensor([0.5779, 0.5878, 0.5835], device='cuda:1')
tensor([-0.0664,  0.4519,  0.5674,  0.6359, -0.2111,  0.5245,  0.7672,  0.9732,
         1.3595,  0.2941,  0.0443,  1.0207, -0.0026,  0.0234, -0.2863,  0.9652],
       device='cuda:1')
Solve time for step 3 3.532799379026983
Current ori: tensor([-0.0026,  0.0234, -0.2863], device='cuda:1')
Index force: tensor([0.5720, 0.5683], device='cuda:1')
tensor([-0.0610,  0.4364,  0.5835,  0.6547, -0.2049,  0.5347,  0.7539,  0.9587,
         1.3703,  0.2823,  0.0444,  1.0034,  0.0041,  0.0193, -0.2863,  0.9762],
       device='cuda:1')
Solve time for step 4 3.3016894750180654
Current ori: tensor([ 0.0041,  0.0193, -0.2863], device='cuda:1')
Index force: tensor([0.5994], device='cuda:1')
Storing RECOVERY transition: reward=0.0009 (scaled=0.0009), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0888
Collected 426 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7494, Q2 Loss=0.7494, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1825
SAC Update 2/5: Actor Loss=-0.0096, Q1 Loss=1.0379, Q2 Loss=1.0379, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7968
SAC Update 3/5: Actor Loss=-0.0134, Q1 Loss=1.4855, Q2 Loss=1.4855, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9060
SAC Update 4/5: Actor Loss=-0.0125, Q1 Loss=1.3988, Q2 Loss=1.3988, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8682
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=0.8079, Q2 Loss=0.8079, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3005

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (41.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010051
Q1 loss: 1.095906
Q2 loss: 1.095906
Current threshold: -149.5130
Global Scale Offset: 3606.2103
Reward stats: mean=0.0157, std=0.0888, count=426
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0959, Q2 Loss: 1.0959, Entropy: 0.6931, Mean TD Error: 0.8108, Threshold: -149.5130
Original likelihood: -130.33633422851562
Adjusted likelihood: -130.33633422851562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5021)
State is out of distribution
Projection step: 0, Loss: 121.7012939453125
Projection step: 1, Loss: 110.35794067382812
Projection step: 2, Loss: 103.5562744140625
Final likelihood: tensor([ -99.3991, -115.9614, -115.9748,  -98.6910, -110.2231, -115.6887,
         -88.4792, -105.0878, -100.5542, -101.1840, -102.5667, -103.0902,
        -103.6997,  -98.6725, -107.3665,  -90.2615])
Final projection likelihood: -103.5563
1 mode projection succeeded
New goal: tensor([-0.0620,  0.4598,  0.5909,  0.6314, -0.1299,  0.5622,  0.7941,  0.9786,
         1.4158,  0.3025,  0.1025,  1.0560,  0.0061,  0.0186, -0.4370],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -155.94500732421875
Adjusted likelihood: -155.94500732421875
Likelihood residual: 0.0
Original likelihood: -156.7809600830078
Adjusted likelihood: -156.7809600830078
Likelihood residual: 0.0
{'index': 156.7809600830078, 'thumb_middle': 155.94500732421875}
Current yaw: tensor([ 0.0066,  0.0193, -0.2869], device='cuda:1')
15 thumb_middle
tensor([-0.0664,  0.4462,  0.5779,  0.6299, -0.1356,  0.5728,  0.8014,  0.9882,
         1.4331,  0.3051,  0.0926,  1.0417,  0.0066,  0.0193, -0.2869,  1.0412],
       device='cuda:1')
Solve time for step 1 9.075263596023433
Current ori: tensor([ 0.0066,  0.0193, -0.2869], device='cuda:1')
Index force: tensor([0.5760, 0.5894, 0.6062, 0.5077], device='cuda:1')
tensor([-0.0705,  0.4396,  0.5848,  0.6278, -0.2182,  0.5457,  0.7641,  0.9581,
         1.3805,  0.2976,  0.0333,  1.0249,  0.0024,  0.0235, -0.2868,  0.9826],
       device='cuda:1')
Solve time for step 2 3.586227488995064
Current ori: tensor([ 0.0024,  0.0235, -0.2868], device='cuda:1')
Index force: tensor([0.5000, 0.5622, 0.5628], device='cuda:1')
tensor([-0.0688,  0.4353,  0.5922,  0.6277, -0.2189,  0.5420,  0.7624,  0.9625,
         1.3785,  0.2818,  0.0301,  1.0288,  0.0028,  0.0233, -0.2869,  0.9711],
       device='cuda:1')
Solve time for step 3 3.4536555460072123
Current ori: tensor([ 0.0028,  0.0233, -0.2869], device='cuda:1')
Index force: tensor([0.5471, 0.5384], device='cuda:1')
tensor([-4.9173e-02,  4.4860e-01,  5.8907e-01,  6.2745e-01, -2.1611e-01,
         5.6412e-01,  7.6205e-01,  9.5618e-01,  1.3855e+00,  2.8826e-01,
         3.3178e-03,  1.0223e+00, -1.0411e-03,  1.3296e-02, -2.8685e-01,
         9.8828e-01], device='cuda:1')
Solve time for step 4 3.3887774749891832
Current ori: tensor([-0.0010,  0.0133, -0.2869], device='cuda:1')
Index force: tensor([0.5328], device='cuda:1')
Storing RECOVERY transition: reward=-0.0144 (scaled=-0.0144), steps=1
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0887
Collected 427 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.8673, Q2 Loss=0.8673, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8605
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.0279, Q2 Loss=1.0279, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7992
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=0.9945, Q2 Loss=0.9945, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3329
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=1.3138, Q2 Loss=1.3138, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4245
SAC Update 5/5: Actor Loss=-0.0129, Q1 Loss=1.3003, Q2 Loss=1.3003, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4249

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.1%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.0%)
Actor update: 0.11s (41.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009951
Q1 loss: 1.100782
Q2 loss: 1.100782
Current threshold: -149.5126
Global Scale Offset: 3621.0988
Reward stats: mean=0.0156, std=0.0887, count=427
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.1008, Q2 Loss: 1.1008, Entropy: 0.6931, Mean TD Error: 0.7684, Threshold: -149.5126
Original likelihood: -167.53369140625
Adjusted likelihood: -167.53369140625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4980)
Current yaw: tensor([ 0.0082,  0.0276, -0.2720], device='cuda:1')
16 turn
Sampling time 3.6372900980059057
tensor([-0.0833,  0.4303,  0.5749,  0.6550, -0.1674,  0.6036,  0.7941,  0.9686,
         1.4404,  0.3136,  0.0745,  1.0738,  0.0082,  0.0276, -0.2720,  0.9644],
       device='cuda:1')
Original likelihood: -168.67979431152344
Adjusted likelihood: -168.67979431152344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4979)
Solve time for step 1 14.41063281201059
Current ori: tensor([ 0.0082,  0.0276, -0.2720], device='cuda:1')
Middle force: tensor([0.8197, 1.4059, 1.0964, 0.5056, 1.2517, 0.6367, 0.7806, 0.5301, 0.6552,
        0.5537, 1.2394, 1.2033], device='cuda:1')
Thumb force: tensor([0.8430, 0.7548, 0.8687, 0.5483, 0.9289, 1.0246, 0.5246, 0.5520, 0.5318,
        1.0897, 0.5519, 0.5894], device='cuda:1')
Index force: tensor([0.7586, 0.7722, 0.5566, 0.8024, 1.0563, 0.5480, 0.5160, 0.5608, 0.5926,
        0.7300, 0.5013, 0.8394], device='cuda:1')
Storing NORMAL transition: reward=0.0379 (scaled=0.0379), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0886
Collected 428 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7424, Q2 Loss=0.7424, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3142
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8635, Q2 Loss=0.8635, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5898
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.5108, Q2 Loss=1.5108, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8114
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=0.8947, Q2 Loss=0.8947, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2400
SAC Update 5/5: Actor Loss=-0.0126, Q1 Loss=1.5776, Q2 Loss=1.5776, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3348

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (18.1%)
Q2 update: 0.04s (19.7%)
Actor update: 0.08s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009498
Q1 loss: 1.117804
Q2 loss: 1.117804
Current threshold: -149.5122
Global Scale Offset: 3630.0036
Reward stats: mean=0.0156, std=0.0886, count=428
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.1178, Q2 Loss: 1.1178, Entropy: 0.6931, Mean TD Error: 0.8581, Threshold: -149.5122
tensor([-0.0742,  0.3864,  0.6072,  0.7266, -0.1687,  0.5789,  0.8177,  1.0127,
         1.4643,  0.3188,  0.0857,  1.0104,  0.0177,  0.0247, -0.3101,  1.0001],
       device='cuda:1')
Original likelihood: -181.78195190429688
Adjusted likelihood: -181.78195190429688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4965)
Solve time for step 2 5.337569579016417
Current ori: tensor([ 0.0177,  0.0247, -0.3101], device='cuda:1')
Middle force: tensor([1.3114, 1.0444, 0.5037, 1.1781, 0.6244, 0.7576, 0.5249, 0.6450, 0.5451,
        1.1861, 1.1619], device='cuda:1')
Thumb force: tensor([0.7322, 0.8273, 0.5407, 0.8781, 0.9690, 0.5210, 0.5461, 0.5234, 1.0595,
        0.5450, 0.5790], device='cuda:1')
Index force: tensor([0.7309, 0.5471, 0.8044, 0.9819, 0.5398, 0.5130, 0.5522, 0.5824, 0.7183,
        0.5007, 0.8128], device='cuda:1')
Storing NORMAL transition: reward=-0.0177 (scaled=-0.0177), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0885
Collected 429 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.8412, Q2 Loss=0.8412, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5230
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.8565, Q2 Loss=0.8565, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6323
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=0.8911, Q2 Loss=0.8911, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7759
SAC Update 4/5: Actor Loss=-0.0095, Q1 Loss=0.9922, Q2 Loss=0.9922, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6720
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.2273, Q2 Loss=1.2273, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6622

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.6%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (20.5%)
Actor update: 0.11s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008522
Q1 loss: 0.961637
Q2 loss: 0.961637
Current threshold: -149.5117
Global Scale Offset: 3644.5269
Reward stats: mean=0.0156, std=0.0885, count=429
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9616, Q2 Loss: 0.9616, Entropy: 0.6931, Mean TD Error: 0.8531, Threshold: -149.5117
tensor([-0.2119,  0.3405,  0.6133,  0.6560, -0.2306,  0.5427,  0.8113,  1.0425,
         1.5000,  0.4245,  0.1573,  0.8335,  0.0319,  0.0657, -0.2968,  0.7943],
       device='cuda:1')
Original likelihood: -198.23666381835938
Adjusted likelihood: -198.23666381835938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4947)
Solve time for step 3 5.0980142570333555
Current ori: tensor([ 0.0319,  0.0657, -0.2968], device='cuda:1')
Middle force: tensor([0.9943, 0.5030, 1.1408, 0.6235, 0.7411, 0.5215, 0.6489, 0.5421, 1.1350,
        1.1542], device='cuda:1')
Thumb force: tensor([0.7965, 0.5406, 0.8258, 0.9211, 0.5183, 0.5415, 0.5168, 1.0323, 0.5400,
        0.5623], device='cuda:1')
Index force: tensor([0.5482, 0.7872, 0.9116, 0.5318, 0.5103, 0.5448, 0.5692, 0.6973, 0.5003,
        0.7802], device='cuda:1')
Storing NORMAL transition: reward=0.0014 (scaled=0.0014), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0884
Collected 430 transitions for RL
SAC Update 1/5: Actor Loss=-0.0137, Q1 Loss=1.4438, Q2 Loss=1.4438, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6740
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.7159, Q2 Loss=0.7159, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5685
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.9420, Q2 Loss=0.9420, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7477
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.7899, Q2 Loss=0.7899, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6514
SAC Update 5/5: Actor Loss=-0.0137, Q1 Loss=1.2674, Q2 Loss=1.2674, Entropy=0.6919, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1354

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010084
Q1 loss: 1.031796
Q2 loss: 1.031796
Current threshold: -149.5113
Global Scale Offset: 3656.2621
Reward stats: mean=0.0155, std=0.0884, count=430
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0318, Q2 Loss: 1.0318, Entropy: 0.6929, Mean TD Error: 0.5554, Threshold: -149.5113
tensor([-0.1136,  0.4644,  0.5136,  0.6471, -0.3087,  0.5471,  0.8401,  1.0393,
         1.4004,  0.3874,  0.2169,  0.7651,  0.0144,  0.0611, -0.2968,  0.9460],
       device='cuda:1')
Original likelihood: -316.6706237792969
Adjusted likelihood: -316.6706237792969
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4818)
Solve time for step 4 4.864830823033117
Current ori: tensor([ 0.0144,  0.0611, -0.2968], device='cuda:1')
Middle force: tensor([0.5048, 1.1420, 0.6280, 0.5095, 0.6438, 0.5649, 0.5421, 0.9404, 1.0674],
       device='cuda:1')
Thumb force: tensor([0.5456, 0.8357, 0.9997, 0.5559, 0.7957, 0.5444, 1.4496, 0.5417, 0.7724],
       device='cuda:1')
Index force: tensor([0.8275, 0.9670, 0.5421, 0.5954, 0.5678, 0.6272, 0.5135, 0.5249, 0.5691],
       device='cuda:1')
Storing NORMAL transition: reward=-0.0038 (scaled=-0.0038), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0883
Collected 431 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=1.1095, Q2 Loss=1.1095, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5369
SAC Update 2/5: Actor Loss=-0.0110, Q1 Loss=1.1250, Q2 Loss=1.1250, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5077
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.3740, Q2 Loss=1.3740, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8584
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=2.9235, Q2 Loss=2.9235, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9094
SAC Update 5/5: Actor Loss=-0.0098, Q1 Loss=1.1780, Q2 Loss=1.1780, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3472

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010432
Q1 loss: 1.541989
Q2 loss: 1.541989
Current threshold: -149.5111
Global Scale Offset: 3654.2774
Reward stats: mean=0.0155, std=0.0883, count=431
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.5420, Q2 Loss: 1.5420, Entropy: 0.6931, Mean TD Error: 1.8319, Threshold: -149.5111
tensor([-0.1087,  0.3880,  0.5740,  0.7401, -0.2356,  0.5285,  0.9225,  1.1259,
         1.5000,  0.2616,  0.2016,  0.8241,  0.0503,  0.0295, -0.2924,  0.8802],
       device='cuda:1')
Original likelihood: -256.4883728027344
Adjusted likelihood: -256.4883728027344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4883)
State is out of distribution
Projection step: 0, Loss: 261.2032165527344
Projection step: 1, Loss: 251.70223999023438
Projection step: 2, Loss: 253.18280029296875
Projection step: 3, Loss: 239.1422576904297
Projection step: 4, Loss: 238.11508178710938
Projection step: 5, Loss: 221.11044311523438
Projection step: 6, Loss: 229.06643676757812
Projection step: 7, Loss: 219.37510681152344
Projection step: 8, Loss: 214.9006805419922
Projection step: 9, Loss: 201.26858520507812
Projection step: 10, Loss: 196.65863037109375
Projection step: 11, Loss: 188.86810302734375
Projection step: 12, Loss: 188.2740020751953
Projection step: 13, Loss: 186.09378051757812
Projection step: 14, Loss: 176.19442749023438
Projection step: 15, Loss: 172.78329467773438
Projection step: 16, Loss: 166.20913696289062
Projection step: 17, Loss: 166.10812377929688
Projection step: 18, Loss: 156.3263702392578
Projection step: 19, Loss: 155.26388549804688
Projection step: 20, Loss: 152.24465942382812
Projection step: 21, Loss: 149.91165161132812
Projection step: 22, Loss: 139.44647216796875
Projection step: 23, Loss: 143.66932678222656
Projection step: 24, Loss: 138.03042602539062
Final likelihood: tensor([-152.4837, -146.5656, -122.5961, -117.1416, -140.9025, -132.1949,
        -131.5210, -132.3973, -134.9719, -119.0887, -140.3052, -116.5311,
        -142.6555, -123.0807, -119.5277, -149.9506])
Final projection likelihood: -132.6196
1 mode projection succeeded
New goal: tensor([-0.0548,  0.4735,  0.6699,  0.6171, -0.1436,  0.5422,  0.7561,  0.9735,
         1.3247,  0.2045,  0.2016,  1.0270,  0.0418,  0.0229, -1.0188],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -168.576171875
Adjusted likelihood: -168.576171875
Likelihood residual: 0.0
Original likelihood: -214.7392578125
Adjusted likelihood: -214.7392578125
Likelihood residual: 0.0
{'index': 214.7392578125, 'thumb_middle': 168.576171875}
Current yaw: tensor([ 0.0503,  0.0295, -0.2924], device='cuda:1')
17 thumb_middle
tensor([-0.1087,  0.3880,  0.5740,  0.7401, -0.2356,  0.5285,  0.9225,  1.1259,
         1.5000,  0.2616,  0.2016,  0.8241,  0.0503,  0.0295, -0.2924,  0.8802],
       device='cuda:1')
Solve time for step 1 8.64964575797785
Current ori: tensor([ 0.0503,  0.0295, -0.2924], device='cuda:1')
Index force: tensor([0.6419, 0.6092, 0.5837, 0.5078], device='cuda:1')
tensor([-0.1069,  0.3967,  0.6041,  0.6560, -0.2429,  0.5495,  0.7760,  0.9950,
         1.3530,  0.2020,  0.1566,  0.9715,  0.0714,  0.0399, -0.2911,  1.1706],
       device='cuda:1')
Solve time for step 2 3.572798504959792
Current ori: tensor([ 0.0714,  0.0399, -0.2911], device='cuda:1')
Index force: tensor([0.6281, 0.6102, 0.5893], device='cuda:1')
tensor([-0.0835,  0.3943,  0.6356,  0.6312, -0.2289,  0.5644,  0.7529,  0.9672,
         1.3374,  0.1987,  0.1611,  1.0100,  0.1041,  0.0562, -0.2911,  1.4495],
       device='cuda:1')
Solve time for step 3 3.3574297690065578
Current ori: tensor([ 0.1041,  0.0562, -0.2911], device='cuda:1')
Index force: tensor([0.6009, 0.5778], device='cuda:1')
tensor([-0.0707,  0.4118,  0.6337,  0.6058, -0.2350,  0.5601,  0.7406,  0.9559,
         1.3477,  0.2054,  0.1840,  1.0277,  0.1109,  0.0969, -0.2911,  1.9228],
       device='cuda:1')
Solve time for step 4 3.349554542975966
Current ori: tensor([ 0.1109,  0.0969, -0.2911], device='cuda:1')
Index force: tensor([0.5563], device='cuda:1')
Storing RECOVERY transition: reward=-0.0164 (scaled=-0.0041), steps=4
Reward stats updated: mean 0.0155 -> 0.0154, std: 0.0882
Collected 432 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=1.6609, Q2 Loss=1.6609, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7758
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.9751, Q2 Loss=0.9751, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7817
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=0.8745, Q2 Loss=0.8745, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7804
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=0.9192, Q2 Loss=0.9192, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5507
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.5488, Q2 Loss=1.5488, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8641

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.3%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008962
Q1 loss: 1.195681
Q2 loss: 1.195681
Current threshold: -149.5109
Global Scale Offset: 3659.4143
Reward stats: mean=0.0154, std=0.0882, count=432
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 1.1957, Q2 Loss: 1.1957, Entropy: 0.6931, Mean TD Error: 1.5505, Threshold: -149.5109
Original likelihood: -196.3160858154297
Adjusted likelihood: -196.3160858154297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4949)
State is out of distribution
Projection step: 0, Loss: 196.93124389648438
Projection step: 1, Loss: 187.638671875
Projection step: 2, Loss: 154.30992126464844
Projection step: 3, Loss: 179.88525390625
Projection step: 4, Loss: 175.54331970214844
Projection step: 5, Loss: 186.28994750976562
Projection step: 6, Loss: 178.2405548095703
Projection step: 7, Loss: 185.0417938232422
Projection step: 8, Loss: 174.6234130859375
Projection step: 9, Loss: 180.3985595703125
Projection step: 10, Loss: 163.96261596679688
Projection step: 11, Loss: 165.00050354003906
Projection step: 12, Loss: 175.55368041992188
Projection step: 13, Loss: 157.8769073486328
Projection step: 14, Loss: 160.31814575195312
Projection step: 15, Loss: 165.6968536376953
Projection step: 16, Loss: 171.57838439941406
Projection step: 17, Loss: 166.76260375976562
Projection step: 18, Loss: 163.09878540039062
Projection step: 19, Loss: 171.30853271484375
Projection step: 20, Loss: 158.59371948242188
Projection step: 21, Loss: 157.25518798828125
Projection step: 22, Loss: 162.04653930664062
Projection step: 23, Loss: 152.69332885742188
Projection step: 24, Loss: 157.97886657714844
Final likelihood: tensor([-171.0983, -142.0417, -157.7161, -155.2862, -152.3830, -166.9752,
        -145.2649, -138.9546, -147.0108, -153.2923, -157.5085, -155.5933,
        -157.4106, -155.4644, -163.1870, -145.2802])
Final projection likelihood: -154.0292
1 mode projection failed, trying anyway
New goal: tensor([-0.0967,  0.4500,  0.3849,  0.8741, -0.1627,  0.5510,  0.6822,  1.0319,
         1.4192,  0.2403,  0.3148,  1.2393,  0.1026,  0.0729, -0.4796],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -162.66213989257812
Adjusted likelihood: -162.66213989257812
Likelihood residual: 0.0
Original likelihood: -178.28602600097656
Adjusted likelihood: -178.28602600097656
Likelihood residual: 0.0
{'index': 178.28602600097656, 'thumb_middle': 162.66213989257812}
Current yaw: tensor([ 0.1087,  0.0716, -0.2890], device='cuda:1')
18 thumb_middle
tensor([-0.0524,  0.4211,  0.6377,  0.5966, -0.1849,  0.5718,  0.7581,  0.9637,
         1.4155,  0.2224,  0.2730,  1.0916,  0.1087,  0.0716, -0.2890,  1.7913],
       device='cuda:1')
Solve time for step 1 8.814735404972453
Current ori: tensor([ 0.1087,  0.0716, -0.2890], device='cuda:1')
Index force: tensor([0.5795, 0.5926, 0.6058, 0.6136], device='cuda:1')
tensor([-0.0584,  0.4862,  0.4393,  0.7986, -0.2450,  0.5657,  0.6611,  0.9892,
         1.3364,  0.1940,  0.2056,  1.1661,  0.1135,  0.1171, -0.2812,  2.2079],
       device='cuda:1')
Solve time for step 2 3.556674382998608
Current ori: tensor([ 0.1135,  0.1171, -0.2812], device='cuda:1')
Index force: tensor([0.5878, 0.6024, 0.6104], device='cuda:1')
tensor([-0.0439,  0.4688,  0.4312,  0.8854, -0.2609,  0.5671,  0.6384,  0.9899,
         1.3530,  0.1970,  0.2126,  1.1916,  0.1164,  0.1269, -0.2504,  2.3355],
       device='cuda:1')
Solve time for step 3 3.4909908670233563
Current ori: tensor([ 0.1164,  0.1269, -0.2504], device='cuda:1')
Index force: tensor([0.5966, 0.6046], device='cuda:1')
tensor([-0.0310,  0.4672,  0.4273,  0.9183, -0.2653,  0.5693,  0.6315,  0.9885,
         1.3551,  0.1977,  0.2172,  1.1994,  0.1143,  0.1291, -0.2544,  2.4205],
       device='cuda:1')
Solve time for step 4 3.25308914296329
Current ori: tensor([ 0.1143,  0.1291, -0.2544], device='cuda:1')
Index force: tensor([0.5683], device='cuda:1')
Storing RECOVERY transition: reward=-0.0744 (scaled=-0.0186), steps=4
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0881
Collected 433 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.9171, Q2 Loss=0.9171, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8296
SAC Update 2/5: Actor Loss=-0.0080, Q1 Loss=0.8714, Q2 Loss=0.8714, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5572
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7827, Q2 Loss=0.7827, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4524
SAC Update 4/5: Actor Loss=-0.0135, Q1 Loss=1.5472, Q2 Loss=1.5472, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0927
SAC Update 5/5: Actor Loss=-0.0117, Q1 Loss=1.3712, Q2 Loss=1.3712, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1403

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (37.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009872
Q1 loss: 1.097928
Q2 loss: 1.097928
Current threshold: -149.5106
Global Scale Offset: 3668.3813
Reward stats: mean=0.0154, std=0.0881, count=433
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.0979, Q2 Loss: 1.0979, Entropy: 0.6931, Mean TD Error: 0.8145, Threshold: -149.5106
Original likelihood: -201.06857299804688
Adjusted likelihood: -201.06857299804688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4944)
Current yaw: tensor([ 0.1214,  0.1058, -0.2373], device='cuda:1')
19 turn
Sampling time 3.7752955760224722
tensor([-0.0344,  0.4810,  0.4125,  0.9037, -0.2242,  0.5720,  0.6625,  1.0138,
         1.4172,  0.2298,  0.2709,  1.2342,  0.1214,  0.1058, -0.2373,  2.1891],
       device='cuda:1')
Original likelihood: -211.8587188720703
Adjusted likelihood: -211.8587188720703
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4932)
State is out of distribution
Projection step: 0, Loss: 162.79669189453125
Projection step: 1, Loss: 174.01602172851562
Projection step: 2, Loss: 189.48248291015625
Projection step: 3, Loss: 182.19134521484375
Projection step: 4, Loss: 180.62281799316406
Projection step: 5, Loss: 179.531494140625
Projection step: 6, Loss: 183.7227783203125
Projection step: 7, Loss: 181.9963836669922
Projection step: 8, Loss: 177.99368286132812
Projection step: 9, Loss: 164.25689697265625
Projection step: 10, Loss: 175.3090057373047
Projection step: 11, Loss: 174.09580993652344
Projection step: 12, Loss: 169.1097412109375
Projection step: 13, Loss: 168.13650512695312
Projection step: 14, Loss: 165.13742065429688
Projection step: 15, Loss: 161.56808471679688
Projection step: 16, Loss: 164.17233276367188
Projection step: 17, Loss: 153.2416229248047
Projection step: 18, Loss: 158.0734100341797
Projection step: 19, Loss: 160.69349670410156
Projection step: 20, Loss: 157.6437225341797
Projection step: 21, Loss: 155.76397705078125
Projection step: 22, Loss: 157.164306640625
Projection step: 23, Loss: 148.67919921875
Projection step: 24, Loss: 152.46356201171875
Final likelihood: tensor([-148.7820, -144.2269, -167.9729, -152.0517, -152.9050, -152.5965,
        -145.2844, -155.5464, -144.8275, -154.6722, -149.3264, -161.5509,
        -153.8187, -149.4301, -163.3756, -154.3980])
Final projection likelihood: -153.1728
1 mode projection failed, trying anyway
New goal: tensor([-0.0969,  0.4703,  0.2775,  1.0067, -0.1926,  0.5868,  0.6282,  1.0852,
         1.4366,  0.2620,  0.3479,  1.1823,  0.1118,  0.1008,  0.7248],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -177.37799072265625
Adjusted likelihood: -177.37799072265625
Likelihood residual: 0.0
Original likelihood: -167.31484985351562
Adjusted likelihood: -167.31484985351562
Likelihood residual: 0.0
{'index': 167.31484985351562, 'thumb_middle': 177.37799072265625}
Current yaw: tensor([ 0.1214,  0.1058, -0.2373], device='cuda:1')
20 index
tensor([-0.0344,  0.4810,  0.4125,  0.9037, -0.2242,  0.5720,  0.6625,  1.0138,
         1.4172,  0.2298,  0.2709,  1.2342,  0.1214,  0.1058, -0.2373,  2.1891],
       device='cuda:1')
Solve time for step 1 10.383660466002766
Current ori: tensor([ 0.1214,  0.1058, -0.2373], device='cuda:1')
Middle force: tensor([0.5303, 0.5112, 0.5509, 0.5117], device='cuda:1')
Thumb force: tensor([0.6096, 0.5683, 0.5909, 0.5008], device='cuda:1')
tensor([-0.0661,  0.4354,  0.2685,  0.9671, -0.2267,  0.5888,  0.6243,  1.0627,
         1.4066,  0.2474,  0.2846,  1.2020,  0.1180,  0.1048, -0.2765,  4.7383],
       device='cuda:1')
Solve time for step 2 4.2918021499644965
Current ori: tensor([ 0.1180,  0.1048, -0.2765], device='cuda:1')
Middle force: tensor([0.5284, 0.5119, 0.5599], device='cuda:1')
Thumb force: tensor([0.5484, 0.5744, 0.5748], device='cuda:1')
tensor([-0.0760,  0.4371,  0.2508,  0.9785, -0.2285,  0.5914,  0.6165,  1.0704,
         1.4028,  0.2540,  0.2908,  1.1949,  0.1177,  0.1057, -0.2815, -5.7569],
       device='cuda:1')
Solve time for step 3 4.10804503899999
Current ori: tensor([ 0.1177,  0.1057, -0.2815], device='cuda:1')
Middle force: tensor([0.5157, 0.5372], device='cuda:1')
Thumb force: tensor([0.6036, 0.5414], device='cuda:1')
tensor([-0.0795,  0.4381,  0.2466,  0.9815, -0.2282,  0.5917,  0.6149,  1.0735,
         1.4049,  0.2515,  0.2892,  1.1921,  0.1171,  0.1054, -0.2882, -4.9716],
       device='cuda:1')
Solve time for step 4 3.840883408964146
Current ori: tensor([ 0.1171,  0.1054, -0.2882], device='cuda:1')
Middle force: tensor([0.5224], device='cuda:1')
Thumb force: tensor([0.5507], device='cuda:1')
Storing RECOVERY transition: reward=0.0433 (scaled=0.0433), steps=0
Reward stats updated: mean 0.0154 -> 0.0154, std: 0.0880
Collected 434 transitions for RL
SAC Update 1/5: Actor Loss=-0.0091, Q1 Loss=0.9973, Q2 Loss=0.9973, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1652
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9744, Q2 Loss=0.9744, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7844
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=1.5576, Q2 Loss=1.5576, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8446
SAC Update 4/5: Actor Loss=-0.0097, Q1 Loss=1.2425, Q2 Loss=1.2425, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5576
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=1.1471, Q2 Loss=1.1471, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2090

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.0%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009166
Q1 loss: 1.183773
Q2 loss: 1.183773
Current threshold: -149.5103
Global Scale Offset: 3673.3492
Reward stats: mean=0.0154, std=0.0880, count=434
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.1838, Q2 Loss: 1.1838, Entropy: 0.6931, Mean TD Error: 1.5122, Threshold: -149.5103
Original likelihood: -160.04071044921875
Adjusted likelihood: -160.04071044921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4989)
State is out of distribution
Projection step: 0, Loss: 166.31729125976562
Projection step: 1, Loss: 165.77682495117188
Projection step: 2, Loss: 160.7548828125
Projection step: 3, Loss: 155.7826690673828
Projection step: 4, Loss: 155.00607299804688
Projection step: 5, Loss: 149.7198944091797
Projection step: 6, Loss: 152.1324005126953
Projection step: 7, Loss: 148.35629272460938
Projection step: 8, Loss: 148.56393432617188
Projection step: 9, Loss: 144.26141357421875
Projection step: 10, Loss: 143.8090057373047
Projection step: 11, Loss: 146.218017578125
Projection step: 12, Loss: 141.62844848632812
Projection step: 13, Loss: 138.3017578125
Projection step: 14, Loss: 139.75637817382812
Projection step: 15, Loss: 137.44268798828125
Projection step: 16, Loss: 133.46875
Projection step: 17, Loss: 133.05621337890625
Projection step: 18, Loss: 131.36309814453125
Projection step: 19, Loss: 133.96502685546875
Projection step: 20, Loss: 127.88575744628906
Projection step: 21, Loss: 133.87188720703125
Projection step: 22, Loss: 134.10060119628906
Projection step: 23, Loss: 128.21495056152344
Projection step: 24, Loss: 129.10711669921875
Final likelihood: tensor([-138.1259, -133.1830, -137.2207, -125.1458, -119.2484, -128.9086,
        -120.1304, -130.6178, -126.8285, -130.5013, -121.6698, -141.6445,
        -140.5560, -125.7633, -124.5113, -122.0998])
Final projection likelihood: -129.1347
1 mode projection succeeded
New goal: tensor([-0.1574,  0.4976,  0.2154,  1.0449, -0.1827,  0.5652,  0.5680,  1.1146,
         1.4200,  0.2536,  0.3449,  1.1357,  0.1048,  0.1020,  0.9709],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 28
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Current yaw: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
1 turn
Sampling time 3.849798426963389
tensor([ 1.4243e-01,  5.9712e-01,  5.8561e-01,  5.9263e-01, -8.9915e-02,
         4.9469e-01,  9.0509e-01,  9.4759e-01,  1.2385e+00,  2.8055e-01,
         2.2510e-01,  1.2123e+00, -9.3450e-04,  1.4776e-02, -2.9111e-02,
         2.5557e-01], device='cuda:1')
Original likelihood: -92.80630493164062
Adjusted likelihood: -92.80630493164062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5062)
Solve time for step 1 13.946061223978177
Current ori: tensor([-0.0009,  0.0148, -0.0291], device='cuda:1')
Middle force: tensor([0.5497, 0.5701, 1.1982, 0.5689, 1.1824, 0.6462, 0.5370, 0.5155, 0.8781,
        0.5687, 0.5125, 0.5566], device='cuda:1')
Thumb force: tensor([0.9060, 0.8749, 0.7824, 1.0051, 0.9556, 0.6525, 0.5209, 0.8988, 0.5664,
        0.9906, 0.6270, 1.1126], device='cuda:1')
Index force: tensor([0.6096, 0.6131, 0.5488, 0.5722, 0.8072, 0.5338, 1.0007, 0.9667, 0.5204,
        0.6050, 0.5926, 0.5366], device='cuda:1')
Storing NORMAL transition: reward=0.1187 (scaled=0.1187), steps=1
Reward stats updated: mean 0.0154 -> 0.0157, std: 0.0881
Collected 435 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.8938, Q2 Loss=0.8938, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5729
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=1.2750, Q2 Loss=1.2750, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8026
SAC Update 3/5: Actor Loss=-0.0121, Q1 Loss=1.3288, Q2 Loss=1.3288, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8403
SAC Update 4/5: Actor Loss=-0.0131, Q1 Loss=1.7338, Q2 Loss=1.7338, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4993
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=1.6272, Q2 Loss=1.6272, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7613

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (18.9%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010810
Q1 loss: 1.371736
Q2 loss: 1.371736
Current threshold: -149.5099
Global Scale Offset: 3681.3288
Reward stats: mean=0.0157, std=0.0881, count=435
----------------------------------------------
SAC Update - Actor Loss: -0.0108, Q1 Loss: 1.3717, Q2 Loss: 1.3717, Entropy: 0.6931, Mean TD Error: 1.2953, Threshold: -149.5099
tensor([ 0.1966,  0.5975,  0.6263,  0.6266, -0.0560,  0.5557,  0.8076,  1.0587,
         1.2426,  0.2831,  0.1916,  1.1589, -0.0177, -0.0209, -0.1485,  1.1284],
       device='cuda:1')
Original likelihood: -161.88674926757812
Adjusted likelihood: -161.88674926757812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4987)
State is out of distribution
Projection step: 0, Loss: 160.07664489746094
Projection step: 1, Loss: 175.24526977539062
Projection step: 2, Loss: 156.89988708496094
Projection step: 3, Loss: 143.04052734375
Projection step: 4, Loss: 140.1906280517578
Projection step: 5, Loss: 134.4131317138672
Projection step: 6, Loss: 130.18325805664062
Projection step: 7, Loss: 130.44100952148438
Projection step: 8, Loss: 122.86936950683594
Projection step: 9, Loss: 121.64982604980469
Projection step: 10, Loss: 118.28632354736328
Projection step: 11, Loss: 113.20055389404297
Projection step: 12, Loss: 112.4896011352539
Projection step: 13, Loss: 115.06307983398438
Projection step: 14, Loss: 97.36058044433594
Final likelihood: tensor([ -90.7495,  -81.7944,  -81.4473, -113.0898,  -93.2096, -108.7811,
        -106.1556,  -83.8004,  -92.3123, -121.4459, -106.9786, -103.9411,
         -82.9732,  -95.0638, -111.8528,  -84.1736])
Final projection likelihood: -97.3606
1 mode projection succeeded
New goal: tensor([ 0.1341,  0.5693,  0.5978,  0.7068, -0.0354,  0.5552,  0.7869,  1.0075,
         1.2903,  0.3107,  0.1480,  1.0309, -0.0176, -0.0143, -0.1878],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -144.73667907714844
Adjusted likelihood: -144.73667907714844
Likelihood residual: 0.0
Original likelihood: -149.2985382080078
Adjusted likelihood: -149.2985382080078
Likelihood residual: 0.0
{'index': 149.2985382080078, 'thumb_middle': 144.73667907714844}
Current yaw: tensor([-0.0177, -0.0209, -0.1485], device='cuda:1')
2 thumb_middle
tensor([ 0.1966,  0.5975,  0.6263,  0.6266, -0.0560,  0.5557,  0.8076,  1.0587,
         1.2426,  0.2831,  0.1916,  1.1589, -0.0177, -0.0209, -0.1485,  1.1284],
       device='cuda:1')
Solve time for step 1 8.97991842997726
Current ori: tensor([-0.0177, -0.0209, -0.1485], device='cuda:1')
Index force: tensor([0.5476, 0.5032, 0.5620, 0.6019], device='cuda:1')
tensor([ 0.1981,  0.6118,  0.5836,  0.6749, -0.1189,  0.5216,  0.7497,  0.9957,
         1.2541,  0.3079,  0.0957,  1.0376, -0.0165, -0.0215, -0.1486,  1.1744],
       device='cuda:1')
Solve time for step 2 3.712097237003036
Current ori: tensor([-0.0165, -0.0215, -0.1486], device='cuda:1')
Index force: tensor([0.5029, 0.5574, 0.5969], device='cuda:1')
tensor([ 0.1969,  0.6065,  0.5845,  0.6846, -0.1408,  0.5356,  0.7609,  0.9895,
         1.2709,  0.3057,  0.0919,  1.0060, -0.0146, -0.0202, -0.1486,  1.1774],
       device='cuda:1')
Solve time for step 3 3.517675702983979
Current ori: tensor([-0.0146, -0.0202, -0.1486], device='cuda:1')
Index force: tensor([0.5522, 0.5920], device='cuda:1')
tensor([ 0.1795,  0.5860,  0.5934,  0.6847, -0.1513,  0.5355,  0.7547,  0.9788,
         1.2849,  0.3010,  0.0834,  1.0164, -0.0108, -0.0088, -0.1486,  1.1556],
       device='cuda:1')
Solve time for step 4 3.565954555000644
Current ori: tensor([-0.0108, -0.0088, -0.1486], device='cuda:1')
Index force: tensor([0.5826], device='cuda:1')
Storing RECOVERY transition: reward=-0.0019 (scaled=-0.0019), steps=1
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0880
Collected 436 transitions for RL
SAC Update 1/5: Actor Loss=-0.0139, Q1 Loss=1.3669, Q2 Loss=1.3669, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2782
SAC Update 2/5: Actor Loss=-0.0130, Q1 Loss=1.9781, Q2 Loss=1.9781, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8634
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.8022, Q2 Loss=0.8022, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3836
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=1.1277, Q2 Loss=1.1277, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7702
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.2863, Q2 Loss=1.2863, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2402

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.6%)
Actor update: 0.08s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010636
Q1 loss: 1.312260
Q2 loss: 1.312260
Current threshold: -149.5096
Global Scale Offset: 3693.6113
Reward stats: mean=0.0156, std=0.0880, count=436
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.3123, Q2 Loss: 1.3123, Entropy: 0.6930, Mean TD Error: 1.3071, Threshold: -149.5096
Original likelihood: -125.39970397949219
Adjusted likelihood: -125.39970397949219
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5026)
State is out of distribution
Projection step: 0, Loss: 114.51211547851562
Projection step: 1, Loss: 108.35002136230469
Projection step: 2, Loss: 98.02876281738281
Final likelihood: tensor([ -89.4567, -106.5703, -129.8674, -106.0517,  -87.9107,  -97.5536,
        -101.6636, -103.6790, -101.9736, -108.6891,  -85.7952,  -95.1506,
        -103.9176,  -82.4019,  -91.2268,  -76.5526])
Final projection likelihood: -98.0288
1 mode projection succeeded
New goal: tensor([ 0.1336,  0.5611,  0.5686,  0.6971, -0.1005,  0.5656,  0.8136,  0.9885,
         1.3467,  0.3351,  0.1606,  1.0508, -0.0045,  0.0141, -0.1827],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -111.90442657470703
Adjusted likelihood: -111.90442657470703
Likelihood residual: 0.0
Original likelihood: -110.09628295898438
Adjusted likelihood: -110.09628295898438
Likelihood residual: 0.0
{'index': 110.09628295898438, 'thumb_middle': 111.90442657470703}
Current yaw: tensor([-0.0051,  0.0140, -0.1460], device='cuda:1')
3 index
tensor([ 0.1421,  0.5654,  0.5727,  0.7022, -0.1094,  0.5694,  0.7731,  1.0106,
         1.3528,  0.3221,  0.1566,  1.0498, -0.0051,  0.0140, -0.1460,  1.1055],
       device='cuda:1')
Solve time for step 1 10.616076938982587
Current ori: tensor([-0.0051,  0.0140, -0.1460], device='cuda:1')
Middle force: tensor([0.5134, 0.5059, 0.5566, 0.5093], device='cuda:1')
Thumb force: tensor([0.5639, 0.5877, 0.6304, 0.5275], device='cuda:1')
tensor([ 0.1816,  0.5119,  0.5231,  0.6734, -0.1099,  0.5649,  0.7916,  0.9810,
         1.3617,  0.3130,  0.1584,  1.0279, -0.0102,  0.0147, -0.1605,  1.0084],
       device='cuda:1')
Solve time for step 2 4.341742802003864
Current ori: tensor([-0.0102,  0.0147, -0.1605], device='cuda:1')
Middle force: tensor([0.5053, 0.5528, 0.5082], device='cuda:1')
Thumb force: tensor([0.5794, 0.6268, 0.5254], device='cuda:1')
tensor([ 0.1817,  0.5135,  0.5207,  0.6715, -0.0997,  0.5611,  0.8050,  0.9850,
         1.3563,  0.3179,  0.1448,  1.0465, -0.0083,  0.0075, -0.1739,  0.9637],
       device='cuda:1')
Solve time for step 3 3.9560163299902342
Current ori: tensor([-0.0083,  0.0075, -0.1739], device='cuda:1')
Middle force: tensor([0.5635, 0.5262], device='cuda:1')
Thumb force: tensor([0.5538, 0.5722], device='cuda:1')
tensor([ 0.1809,  0.5119,  0.5203,  0.6721, -0.1077,  0.5666,  0.7989,  0.9749,
         1.3586,  0.3198,  0.1553,  1.0275, -0.0122,  0.0121, -0.1720,  0.9483],
       device='cuda:1')
Solve time for step 4 3.875468593032565
Current ori: tensor([-0.0122,  0.0121, -0.1720], device='cuda:1')
Middle force: tensor([0.5236], device='cuda:1')
Thumb force: tensor([0.5649], device='cuda:1')
Storing RECOVERY transition: reward=0.0386 (scaled=0.0386), steps=1
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0879
Collected 437 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=1.5455, Q2 Loss=1.5455, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7267
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=0.9437, Q2 Loss=0.9437, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0340
SAC Update 3/5: Actor Loss=-0.0123, Q1 Loss=1.3348, Q2 Loss=1.3348, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8488
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=0.8740, Q2 Loss=0.8740, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6417
SAC Update 5/5: Actor Loss=-0.0127, Q1 Loss=1.2641, Q2 Loss=1.2641, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1555

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (37.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010184
Q1 loss: 1.192455
Q2 loss: 1.192455
Current threshold: -149.5094
Global Scale Offset: 3710.6065
Reward stats: mean=0.0157, std=0.0879, count=437
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.1925, Q2 Loss: 1.1925, Entropy: 0.6931, Mean TD Error: 1.0813, Threshold: -149.5094
Original likelihood: -114.77015686035156
Adjusted likelihood: -114.77015686035156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5037)
State is out of distribution
Projection step: 0, Loss: 110.39692687988281
Projection step: 1, Loss: 107.63874053955078
Projection step: 2, Loss: 102.93468475341797
Final likelihood: tensor([ -93.7447,  -91.5744, -107.0777,  -99.7163, -120.3029,  -89.0608,
        -120.9226, -112.1548, -113.4481, -102.4764,  -97.3535,  -96.5891,
         -92.8013,  -88.5232, -102.1820, -119.0273])
Final projection likelihood: -102.9347
1 mode projection succeeded
New goal: tensor([ 0.1240,  0.5649,  0.5663,  0.6873, -0.1000,  0.5663,  0.8282,  0.9611,
         1.3607,  0.3248,  0.1428,  1.0412, -0.0144,  0.0118, -0.1830],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -123.88284301757812
Adjusted likelihood: -123.88284301757812
Likelihood residual: 0.0
Original likelihood: -125.32534790039062
Adjusted likelihood: -125.32534790039062
Likelihood residual: 0.0
{'index': 125.32534790039062, 'thumb_middle': 123.88284301757812}
Current yaw: tensor([-0.0145,  0.0113, -0.1866], device='cuda:1')
4 thumb_middle
tensor([ 0.1302,  0.5676,  0.5624,  0.6935, -0.1084,  0.5683,  0.8012,  0.9782,
         1.3662,  0.3149,  0.1378,  1.0432, -0.0145,  0.0113, -0.1866,  0.9827],
       device='cuda:1')
Solve time for step 1 8.891980841988698
Current ori: tensor([-0.0145,  0.0113, -0.1866], device='cuda:1')
Index force: tensor([0.5991, 0.5951, 0.5960, 0.5998], device='cuda:1')
tensor([ 0.1266,  0.5797,  0.5530,  0.6724, -0.2009,  0.5389,  0.7889,  0.9423,
         1.3236,  0.3112,  0.0692,  1.0094, -0.0185,  0.0131, -0.1866,  0.9496],
       device='cuda:1')
Solve time for step 2 3.592356294975616
Current ori: tensor([-0.0185,  0.0131, -0.1866], device='cuda:1')
Index force: tensor([0.5890, 0.5900, 0.5952], device='cuda:1')
tensor([ 0.1275,  0.5863,  0.5501,  0.6622, -0.2085,  0.5482,  0.7917,  0.9396,
         1.3272,  0.3102,  0.0600,  1.0063, -0.0207,  0.0122, -0.1866,  0.9463],
       device='cuda:1')
Solve time for step 3 3.48170676198788
Current ori: tensor([-0.0207,  0.0122, -0.1866], device='cuda:1')
Index force: tensor([0.5813, 0.5879], device='cuda:1')
tensor([ 0.1203,  0.5674,  0.5566,  0.6858, -0.2156,  0.5413,  0.7882,  0.9371,
         1.3324,  0.3118,  0.0641,  1.0088, -0.0147,  0.0174, -0.1866,  0.9476],
       device='cuda:1')
Solve time for step 4 3.355406866001431
Current ori: tensor([-0.0147,  0.0174, -0.1866], device='cuda:1')
Index force: tensor([0.5747], device='cuda:1')
Storing RECOVERY transition: reward=0.0485 (scaled=0.0485), steps=1
Reward stats updated: mean 0.0157 -> 0.0158, std: 0.0878
Collected 438 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=2.8321, Q2 Loss=2.8321, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9105
SAC Update 2/5: Actor Loss=-0.0117, Q1 Loss=1.1616, Q2 Loss=1.1616, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2355
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=0.9537, Q2 Loss=0.9537, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4655
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=0.9262, Q2 Loss=0.9262, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6544
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.7285, Q2 Loss=0.7285, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2304

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008886
Q1 loss: 1.320419
Q2 loss: 1.320419
Current threshold: -149.5093
Global Scale Offset: 3729.4990
Reward stats: mean=0.0158, std=0.0878, count=438
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.3204, Q2 Loss: 1.3204, Entropy: 0.6930, Mean TD Error: 1.4993, Threshold: -149.5093
Original likelihood: -131.42752075195312
Adjusted likelihood: -131.42752075195312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5019)
Current yaw: tensor([-0.0151,  0.0182, -0.1969], device='cuda:1')
5 turn
Sampling time 3.595002470014151
tensor([ 0.1184,  0.5698,  0.5499,  0.6887, -0.1471,  0.5921,  0.8222,  0.9515,
         1.3983,  0.3262,  0.1101,  1.0349, -0.0151,  0.0182, -0.1969,  0.9567],
       device='cuda:1')
Original likelihood: -130.47073364257812
Adjusted likelihood: -130.47073364257812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5020)
Solve time for step 1 14.072904373984784
Current ori: tensor([-0.0151,  0.0182, -0.1969], device='cuda:1')
Middle force: tensor([0.6390, 0.7151, 0.5291, 1.4427, 0.5418, 0.4858, 0.6780, 0.4950, 0.9807,
        0.6849, 0.5500, 0.6102], device='cuda:1')
Thumb force: tensor([1.5911, 0.7171, 2.2617, 1.1597, 2.0169, 0.5054, 0.9730, 0.5929, 0.5718,
        1.2445, 0.9559, 0.6153], device='cuda:1')
Index force: tensor([0.8731, 0.7207, 0.5749, 0.8815, 0.7246, 0.7671, 0.5511, 0.7683, 0.9981,
        0.5505, 0.5577, 0.6095], device='cuda:1')
Storing NORMAL transition: reward=-0.0728 (scaled=-0.0728), steps=1
Reward stats updated: mean 0.0158 -> 0.0156, std: 0.0878
Collected 439 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.9313, Q2 Loss=0.9313, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3877
SAC Update 2/5: Actor Loss=-0.0072, Q1 Loss=0.7851, Q2 Loss=0.7851, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2221
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.8385, Q2 Loss=0.8385, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6527
SAC Update 4/5: Actor Loss=-0.0127, Q1 Loss=2.6712, Q2 Loss=2.6712, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7113
SAC Update 5/5: Actor Loss=-0.0136, Q1 Loss=1.5510, Q2 Loss=1.5510, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0442

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.8%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (21.1%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009997
Q1 loss: 1.355400
Q2 loss: 1.355400
Current threshold: -149.5092
Global Scale Offset: 3753.3470
Reward stats: mean=0.0156, std=0.0878, count=439
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.3554, Q2 Loss: 1.3554, Entropy: 0.6931, Mean TD Error: 1.6036, Threshold: -149.5092
tensor([ 0.0860,  0.5671,  0.5045,  0.7211, -0.1601,  0.5906,  0.8022,  0.8940,
         1.3006,  0.5915,  0.0922,  1.2393, -0.0074,  0.0353, -0.1247,  0.7913],
       device='cuda:1')
Original likelihood: -164.84088134765625
Adjusted likelihood: -164.84088134765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4984)
Solve time for step 2 5.576028244977351
Current ori: tensor([-0.0074,  0.0353, -0.1247], device='cuda:1')
Middle force: tensor([0.5089, 0.5015, 0.5185, 0.5872, 0.5879, 1.0597, 0.7904, 0.8004, 0.5852,
        0.5003, 0.5027], device='cuda:1')
Thumb force: tensor([1.9920, 1.4956, 0.5825, 1.1108, 0.8317, 1.4692, 0.5811, 0.7289, 0.7090,
        0.6382, 0.7916], device='cuda:1')
Index force: tensor([0.8310, 0.8821, 0.6358, 0.5678, 0.5502, 0.5808, 0.5248, 0.5792, 0.5686,
        0.5155, 0.7116], device='cuda:1')
Storing NORMAL transition: reward=0.0155 (scaled=0.0155), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0877
Collected 440 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.0171, Q2 Loss=1.0171, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4819
SAC Update 2/5: Actor Loss=-0.0113, Q1 Loss=1.2192, Q2 Loss=1.2192, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8406
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.8373, Q2 Loss=0.8373, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1064
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8966, Q2 Loss=0.8966, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6934
SAC Update 5/5: Actor Loss=-0.0133, Q1 Loss=1.3177, Q2 Loss=1.3177, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1463

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.2%)
Q1 update: 0.06s (19.5%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (40.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010120
Q1 loss: 1.057574
Q2 loss: 1.057574
Current threshold: -149.5090
Global Scale Offset: 3773.0184
Reward stats: mean=0.0156, std=0.0877, count=440
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.0576, Q2 Loss: 1.0576, Entropy: 0.6931, Mean TD Error: 0.6537, Threshold: -149.5090
tensor([ 9.5231e-02,  5.4314e-01,  5.3499e-01,  7.4578e-01, -1.5899e-01,
         5.8650e-01,  7.9229e-01,  9.6232e-01,  1.3158e+00,  5.9897e-01,
         5.9149e-02,  1.2606e+00,  4.5863e-04,  3.0958e-02, -1.3992e-01,
         8.2731e-01], device='cuda:1')
Original likelihood: -163.82510375976562
Adjusted likelihood: -163.82510375976562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4985)
Solve time for step 3 5.262830323947128
Current ori: tensor([ 0.0005,  0.0310, -0.1399], device='cuda:1')
Middle force: tensor([0.5014, 0.5164, 0.5854, 0.5861, 1.0392, 0.7814, 0.7909, 0.5827, 0.5002,
        0.5028], device='cuda:1')
Thumb force: tensor([1.4549, 0.5777, 1.0884, 0.8185, 1.4456, 0.5787, 0.7181, 0.6984, 0.6354,
        0.7798], device='cuda:1')
Index force: tensor([0.8645, 0.6338, 0.5641, 0.5465, 0.5754, 0.5226, 0.5746, 0.5649, 0.5140,
        0.6994], device='cuda:1')
Storing NORMAL transition: reward=0.0159 (scaled=0.0159), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0876
Collected 441 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7883, Q2 Loss=0.7883, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7664
SAC Update 2/5: Actor Loss=-0.0134, Q1 Loss=1.7178, Q2 Loss=1.7178, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3925
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.7361, Q2 Loss=0.7361, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7317
SAC Update 4/5: Actor Loss=-0.0130, Q1 Loss=1.5926, Q2 Loss=1.5926, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1560
SAC Update 5/5: Actor Loss=-0.0074, Q1 Loss=0.9447, Q2 Loss=0.9447, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7063

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.6%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009753
Q1 loss: 1.155886
Q2 loss: 1.155886
Current threshold: -149.5087
Global Scale Offset: 3797.4093
Reward stats: mean=0.0156, std=0.0876, count=441
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.1559, Q2 Loss: 1.1559, Entropy: 0.6930, Mean TD Error: 1.3506, Threshold: -149.5087
tensor([ 0.0996,  0.5373,  0.5411,  0.7582, -0.1592,  0.5853,  0.7872,  1.0013,
         1.3142,  0.6348,  0.0754,  1.2103,  0.0025,  0.0286, -0.1557,  0.8576],
       device='cuda:1')
Original likelihood: -158.19178771972656
Adjusted likelihood: -158.19178771972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4991)
Solve time for step 4 4.911276124999858
Current ori: tensor([ 0.0025,  0.0286, -0.1557], device='cuda:1')
Middle force: tensor([0.5153, 0.5836, 0.5829, 1.0186, 0.7712, 0.7795, 0.5801, 0.5001, 0.5027],
       device='cuda:1')
Thumb force: tensor([0.5710, 1.0667, 0.8063, 1.4236, 0.5769, 0.7077, 0.6893, 0.6323, 0.7686],
       device='cuda:1')
Index force: tensor([0.6217, 0.5601, 0.5435, 0.5705, 0.5203, 0.5707, 0.5615, 0.5124, 0.6887],
       device='cuda:1')
Storing NORMAL transition: reward=0.0583 (scaled=0.0583), steps=1
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0875
Collected 442 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.0133, Q2 Loss=1.0133, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6502
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.8894, Q2 Loss=0.8894, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5697
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.8772, Q2 Loss=0.8772, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0930
SAC Update 4/5: Actor Loss=-0.0109, Q1 Loss=3.4776, Q2 Loss=3.4776, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9229
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.7572, Q2 Loss=0.7572, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3610

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.0%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008950
Q1 loss: 1.402936
Q2 loss: 1.402936
Current threshold: -149.5084
Global Scale Offset: 3815.9043
Reward stats: mean=0.0157, std=0.0875, count=442
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.4029, Q2 Loss: 1.4029, Entropy: 0.6931, Mean TD Error: 1.3193, Threshold: -149.5084
tensor([ 1.1982e-01,  5.4676e-01,  5.4598e-01,  7.6271e-01, -1.4324e-01,
         5.8122e-01,  7.9441e-01,  1.0338e+00,  1.3192e+00,  6.3197e-01,
         6.3249e-02,  1.1941e+00,  1.0240e-03,  1.7029e-02, -2.1364e-01,
         9.4590e-01], device='cuda:1')
Original likelihood: -137.21121215820312
Adjusted likelihood: -137.21121215820312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5013)
State is out of distribution
Projection step: 0, Loss: 141.34979248046875
Projection step: 1, Loss: 131.60943603515625
Projection step: 2, Loss: 127.71815490722656
Projection step: 3, Loss: 123.26791381835938
Projection step: 4, Loss: 119.13631439208984
Projection step: 5, Loss: 107.82791900634766
Projection step: 6, Loss: 107.50630187988281
Projection step: 7, Loss: 99.83930969238281
Final likelihood: tensor([-100.8631, -105.8472, -107.9883, -107.1802, -112.0161, -130.0142,
         -92.3425,  -76.5061,  -92.6121, -100.3756, -101.9730, -109.9588,
         -77.5093, -105.8076,  -88.8234,  -87.6116])
Final projection likelihood: -99.8393
1 mode projection succeeded
New goal: tensor([ 0.1076,  0.5387,  0.5435,  0.7462, -0.1011,  0.5775,  0.8594,  0.9599,
         1.3349,  0.5634,  0.1033,  1.1263,  0.0018,  0.0162,  0.0079],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -116.62608337402344
Adjusted likelihood: -116.62608337402344
Likelihood residual: 0.0
Original likelihood: -128.28546142578125
Adjusted likelihood: -128.28546142578125
Likelihood residual: 0.0
{'index': 128.28546142578125, 'thumb_middle': 116.62608337402344}
Current yaw: tensor([ 0.0010,  0.0170, -0.2136], device='cuda:1')
6 thumb_middle
tensor([ 1.1982e-01,  5.4676e-01,  5.4598e-01,  7.6271e-01, -1.4324e-01,
         5.8122e-01,  7.9441e-01,  1.0338e+00,  1.3192e+00,  6.3197e-01,
         6.3249e-02,  1.1941e+00,  1.0240e-03,  1.7029e-02, -2.1364e-01,
         9.4590e-01], device='cuda:1')
Solve time for step 1 8.905755865038373
Current ori: tensor([ 0.0010,  0.0170, -0.2136], device='cuda:1')
Index force: tensor([0.5976, 0.5734, 0.5992, 0.6012], device='cuda:1')
tensor([ 1.1807e-01,  5.4650e-01,  5.4909e-01,  7.5258e-01, -2.2481e-01,
         5.3964e-01,  7.9857e-01,  9.4355e-01,  1.2961e+00,  5.7144e-01,
         2.7963e-02,  1.1060e+00,  5.9166e-04,  1.8196e-02, -2.1366e-01,
         9.2831e-01], device='cuda:1')
Solve time for step 2 3.6118560470058583
Current ori: tensor([ 0.0006,  0.0182, -0.2137], device='cuda:1')
Index force: tensor([0.5672, 0.5935, 0.5953], device='cuda:1')
tensor([ 1.2875e-01,  5.4744e-01,  5.5552e-01,  7.5989e-01, -2.2513e-01,
         5.4856e-01,  8.0976e-01,  9.3388e-01,  1.2981e+00,  5.5945e-01,
         2.1059e-02,  1.0921e+00,  1.0226e-03,  1.2056e-02, -2.1366e-01,
         9.4744e-01], device='cuda:1')
Solve time for step 3 3.4820027709938586
Current ori: tensor([ 0.0010,  0.0121, -0.2137], device='cuda:1')
Index force: tensor([0.5865, 0.5895], device='cuda:1')
tensor([ 0.1281,  0.5466,  0.5551,  0.7618, -0.2269,  0.5495,  0.8123,  0.9317,
         1.2999,  0.5603,  0.0201,  1.0887,  0.0014,  0.0125, -0.2137,  0.9485],
       device='cuda:1')
Solve time for step 4 3.4124431789969094
Current ori: tensor([ 0.0014,  0.0125, -0.2137], device='cuda:1')
Index force: tensor([0.5830], device='cuda:1')
Storing RECOVERY transition: reward=0.0045 (scaled=0.0011), steps=4
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0874
Collected 443 transitions for RL
SAC Update 1/5: Actor Loss=-0.0127, Q1 Loss=3.6131, Q2 Loss=3.6131, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4959
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=1.2540, Q2 Loss=1.2540, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3992
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=1.5203, Q2 Loss=1.5203, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9172
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.7028, Q2 Loss=0.7028, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0753
SAC Update 5/5: Actor Loss=-0.0121, Q1 Loss=1.5224, Q2 Loss=1.5224, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3595

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.7%)
Q1 update: 0.04s (20.0%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010482
Q1 loss: 1.722516
Q2 loss: 1.722516
Current threshold: -149.5081
Global Scale Offset: 3830.2323
Reward stats: mean=0.0156, std=0.0874, count=443
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.7225, Q2 Loss: 1.7225, Entropy: 0.6931, Mean TD Error: 1.6494, Threshold: -149.5081
Original likelihood: -129.59024047851562
Adjusted likelihood: -129.59024047851562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5021)
Current yaw: tensor([ 0.0048,  0.0191, -0.2182], device='cuda:1')
7 turn
Sampling time 3.6515627980115823
tensor([ 0.1170,  0.5338,  0.5585,  0.7678, -0.1671,  0.5920,  0.8531,  0.9475,
         1.3524,  0.5580,  0.0834,  1.1233,  0.0048,  0.0191, -0.2182,  0.9387],
       device='cuda:1')
Original likelihood: -137.82156372070312
Adjusted likelihood: -137.82156372070312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5012)
Solve time for step 1 14.066039801982697
Current ori: tensor([ 0.0048,  0.0191, -0.2182], device='cuda:1')
Middle force: tensor([0.5291, 0.5776, 0.8384, 0.5305, 1.0199, 0.6314, 0.6367, 0.6391, 0.6810,
        0.5566, 0.5973, 0.5839], device='cuda:1')
Thumb force: tensor([0.5022, 1.4051, 1.5984, 0.5934, 1.5625, 1.0281, 1.1085, 1.1910, 1.2123,
        0.5285, 0.6075, 0.6462], device='cuda:1')
Index force: tensor([0.7799, 0.6146, 0.7311, 0.5824, 0.8215, 0.5976, 0.9682, 0.7308, 0.5918,
        0.5875, 0.6106, 0.5846], device='cuda:1')
Storing NORMAL transition: reward=-0.0018 (scaled=-0.0018), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0873
Collected 444 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=2.3889, Q2 Loss=2.3889, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8239
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.4497, Q2 Loss=1.4497, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9445
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=0.8535, Q2 Loss=0.8535, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3823
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8151, Q2 Loss=0.8151, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4259
SAC Update 5/5: Actor Loss=-0.0123, Q1 Loss=1.4649, Q2 Loss=1.4649, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2161

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.2%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.05s (19.0%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008938
Q1 loss: 1.394432
Q2 loss: 1.394432
Current threshold: -149.5078
Global Scale Offset: 3843.5304
Reward stats: mean=0.0156, std=0.0873, count=444
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.3944, Q2 Loss: 1.3944, Entropy: 0.6931, Mean TD Error: 2.1586, Threshold: -149.5078
tensor([ 0.0285,  0.4483,  0.5849,  0.6554, -0.3093,  0.6575,  1.0186,  0.8351,
         1.3805,  0.4400,  0.0646,  1.1504,  0.0069,  0.0307, -0.2169,  0.5937],
       device='cuda:1')
Original likelihood: -257.1120910644531
Adjusted likelihood: -257.1120910644531
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4888)
State is out of distribution
Projection step: 0, Loss: 260.95513916015625
Projection step: 1, Loss: 252.47531127929688
Projection step: 2, Loss: 241.9777374267578
Projection step: 3, Loss: 227.6721649169922
Projection step: 4, Loss: 219.15457153320312
Projection step: 5, Loss: 216.13214111328125
Projection step: 6, Loss: 201.84011840820312
Projection step: 7, Loss: 192.82254028320312
Projection step: 8, Loss: 194.37966918945312
Projection step: 9, Loss: 183.46290588378906
Projection step: 10, Loss: 183.77548217773438
Projection step: 11, Loss: 171.2384033203125
Projection step: 12, Loss: 171.73843383789062
Projection step: 13, Loss: 160.29525756835938
Projection step: 14, Loss: 157.23097229003906
Projection step: 15, Loss: 153.69534301757812
Projection step: 16, Loss: 147.96957397460938
Projection step: 17, Loss: 138.58502197265625
Projection step: 18, Loss: 134.35049438476562
Projection step: 19, Loss: 131.41827392578125
Projection step: 20, Loss: 129.44500732421875
Projection step: 21, Loss: 124.07919311523438
Projection step: 22, Loss: 118.91622161865234
Projection step: 23, Loss: 117.34906005859375
Projection step: 24, Loss: 114.0865249633789
Final likelihood: tensor([-105.8207,  -97.2996,  -90.9924, -101.7378, -101.1042, -112.2619,
        -115.1102, -140.6129, -103.7976, -104.4791, -120.9633, -103.9098,
        -105.7435, -108.5812, -105.4060, -102.3964])
Final projection likelihood: -107.5135
1 mode projection succeeded
New goal: tensor([ 0.0534,  0.4799,  0.6684,  0.6916, -0.1386,  0.6235,  0.8570,  0.8493,
         1.2976,  0.3161,  0.1528,  1.1578,  0.0032,  0.0179, -0.2069],
       device='cuda:1')
tensor([[0.0035]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0066]], device='cuda:1')
Original likelihood: -207.99594116210938
Adjusted likelihood: -207.99594116210938
Likelihood residual: 0.0
{'index': 207.99594116210938, 'thumb_middle': inf}
Current yaw: tensor([ 0.0069,  0.0307, -0.2169], device='cuda:1')
8 index
tensor([ 0.0285,  0.4483,  0.5849,  0.6554, -0.3093,  0.6575,  1.0186,  0.8351,
         1.3805,  0.4400,  0.0646,  1.1504,  0.0069,  0.0307, -0.2169,  0.5937],
       device='cuda:1')
Solve time for step 1 10.530727403005585
Current ori: tensor([ 0.0069,  0.0307, -0.2169], device='cuda:1')
Middle force: tensor([0.5563, 0.5176, 0.5530, 0.5390], device='cuda:1')
Thumb force: tensor([0.5144, 0.5232, 0.5782, 0.5244], device='cuda:1')
tensor([ 1.0089e-01,  4.0647e-01,  5.9193e-01,  6.5376e-01, -3.0234e-01,
         6.8971e-01,  9.5433e-01,  8.8879e-01,  1.3965e+00,  4.1556e-01,
         4.6808e-02,  1.1485e+00,  8.4311e-04,  2.6808e-02, -2.2030e-01,
         3.4741e-01], device='cuda:1')
Solve time for step 2 4.194833381974604
Current ori: tensor([ 0.0008,  0.0268, -0.2203], device='cuda:1')
Middle force: tensor([0.5685, 0.5710, 0.5272], device='cuda:1')
Thumb force: tensor([0.5924, 0.5603, 0.5224], device='cuda:1')
tensor([ 0.1094,  0.4077,  0.5973,  0.6541, -0.3052,  0.7026,  0.9413,  0.8957,
         1.4067,  0.4110,  0.0326,  1.1446, -0.0067,  0.0266, -0.2271,  0.2325],
       device='cuda:1')
Solve time for step 3 4.166751171986107
Current ori: tensor([-0.0067,  0.0266, -0.2271], device='cuda:1')
Middle force: tensor([0.5362, 0.5705], device='cuda:1')
Thumb force: tensor([0.5567, 0.5612], device='cuda:1')
tensor([ 0.1129,  0.4075,  0.5978,  0.6538, -0.2897,  0.7194,  0.9287,  0.8827,
         1.4026,  0.4143,  0.0206,  1.1409, -0.0154,  0.0169, -0.2243,  0.2362],
       device='cuda:1')
Solve time for step 4 4.001328820013441
Current ori: tensor([-0.0154,  0.0169, -0.2243], device='cuda:1')
Middle force: tensor([0.5009], device='cuda:1')
Thumb force: tensor([0.5763], device='cuda:1')
Storing RECOVERY transition: reward=0.0075 (scaled=0.0075), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0872
Collected 445 transitions for RL
SAC Update 1/5: Actor Loss=-0.0134, Q1 Loss=2.0578, Q2 Loss=2.0578, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9231
SAC Update 2/5: Actor Loss=-0.0127, Q1 Loss=1.2458, Q2 Loss=1.2458, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3252
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.0424, Q2 Loss=1.0424, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2668
SAC Update 4/5: Actor Loss=-0.0100, Q1 Loss=2.6058, Q2 Loss=2.6058, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0045
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=0.9518, Q2 Loss=0.9518, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3944

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011203
Q1 loss: 1.580720
Q2 loss: 1.580720
Current threshold: -149.5073
Global Scale Offset: 3853.2561
Reward stats: mean=0.0156, std=0.0872, count=445
----------------------------------------------
SAC Update - Actor Loss: -0.0112, Q1 Loss: 1.5807, Q2 Loss: 1.5807, Entropy: 0.6931, Mean TD Error: 0.9828, Threshold: -149.5073
Original likelihood: -218.98324584960938
Adjusted likelihood: -218.98324584960938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4928)
Current yaw: tensor([-0.0142,  0.0167, -0.2240], device='cuda:1')
9 turn
Sampling time 3.864184299018234
tensor([ 0.0649,  0.4653,  0.6446,  0.6791, -0.2898,  0.7183,  0.9296,  0.8856,
         1.4048,  0.4191,  0.0114,  1.1517, -0.0142,  0.0167, -0.2240,  0.2679],
       device='cuda:1')
Original likelihood: -239.15744018554688
Adjusted likelihood: -239.15744018554688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4907)
Solve time for step 1 14.21418646699749
Current ori: tensor([-0.0142,  0.0167, -0.2240], device='cuda:1')
Middle force: tensor([0.5738, 1.7954, 2.3319, 0.5791, 0.8652, 0.6469, 0.5262, 0.7933, 0.5125,
        0.6460, 0.7346, 0.5553], device='cuda:1')
Thumb force: tensor([0.9309, 1.5189, 0.7052, 0.5870, 0.5115, 1.1833, 1.3220, 1.5999, 0.5269,
        0.5073, 0.7950, 0.6221], device='cuda:1')
Index force: tensor([0.5939, 0.7998, 0.5701, 0.6095, 0.5341, 0.8574, 0.5241, 0.5645, 0.5131,
        0.6451, 0.5464, 0.6474], device='cuda:1')
Storing NORMAL transition: reward=-0.0115 (scaled=-0.0115), steps=1
Reward stats updated: mean 0.0156 -> 0.0155, std: 0.0871
Collected 446 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.8094, Q2 Loss=0.8094, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6662
SAC Update 2/5: Actor Loss=-0.0115, Q1 Loss=1.1996, Q2 Loss=1.1996, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7826
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=1.2837, Q2 Loss=1.2837, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0006
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.9100, Q2 Loss=0.9100, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6041
SAC Update 5/5: Actor Loss=-0.0138, Q1 Loss=7.1704, Q2 Loss=7.1704, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2792

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.5%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.06s (20.2%)
Actor update: 0.12s (41.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010215
Q1 loss: 2.274634
Q2 loss: 2.274634
Current threshold: -149.5070
Global Scale Offset: 3860.2330
Reward stats: mean=0.0155, std=0.0871, count=446
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 2.2746, Q2 Loss: 2.2746, Entropy: 0.6931, Mean TD Error: 1.8665, Threshold: -149.5070
tensor([-4.1664e-02,  4.6778e-01,  5.8475e-01,  6.1136e-01, -3.3611e-01,
         7.3864e-01,  8.1780e-01,  1.0382e+00,  1.4413e+00,  3.7059e-01,
         2.9775e-02,  1.1519e+00,  1.0269e-03,  4.7778e-02, -2.1414e-01,
         5.7869e-01], device='cuda:1')
Original likelihood: -284.94189453125
Adjusted likelihood: -284.94189453125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4860)
Solve time for step 2 5.472005846968386
Current ori: tensor([ 0.0010,  0.0478, -0.2141], device='cuda:1')
Middle force: tensor([1.7539, 2.2771, 0.5779, 0.8798, 0.6747, 0.5252, 0.7838, 0.5159, 0.6847,
        0.7316, 0.5636], device='cuda:1')
Thumb force: tensor([1.4728, 0.6882, 0.5779, 0.5081, 1.1248, 1.2881, 1.5578, 0.5210, 0.5038,
        0.7815, 0.6059], device='cuda:1')
Index force: tensor([0.7891, 0.5740, 0.6116, 0.5328, 0.8220, 0.5220, 0.5629, 0.5103, 0.6480,
        0.5425, 0.6337], device='cuda:1')
Storing NORMAL transition: reward=0.0208 (scaled=0.0208), steps=1
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0870
Collected 447 transitions for RL
SAC Update 1/5: Actor Loss=-0.0134, Q1 Loss=1.5908, Q2 Loss=1.5908, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1276
SAC Update 2/5: Actor Loss=-0.0113, Q1 Loss=1.1370, Q2 Loss=1.1370, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3056
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.8195, Q2 Loss=0.8195, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4436
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.0971, Q2 Loss=1.0971, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3077
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.9455, Q2 Loss=0.9455, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5249

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010102
Q1 loss: 1.117987
Q2 loss: 1.117987
Current threshold: -149.5069
Global Scale Offset: 3874.2784
Reward stats: mean=0.0155, std=0.0870, count=447
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.1180, Q2 Loss: 1.1180, Entropy: 0.6931, Mean TD Error: 1.5419, Threshold: -149.5069
tensor([-0.0130,  0.4677,  0.5793,  0.6664, -0.3159,  0.7168,  0.8810,  1.0162,
         1.4674,  0.3447, -0.0041,  1.1389,  0.0071,  0.0271, -0.2336,  0.6576],
       device='cuda:1')
Original likelihood: -260.02667236328125
Adjusted likelihood: -260.02667236328125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4886)
State is out of distribution
Projection step: 0, Loss: 263.126708984375
Projection step: 1, Loss: 249.6627655029297
Projection step: 2, Loss: 240.16212463378906
Projection step: 3, Loss: 234.82159423828125
Projection step: 4, Loss: 233.75186157226562
Projection step: 5, Loss: 220.30999755859375
Projection step: 6, Loss: 210.44586181640625
Projection step: 7, Loss: 215.2171173095703
Projection step: 8, Loss: 210.79934692382812
Projection step: 9, Loss: 198.23562622070312
Projection step: 10, Loss: 179.9762420654297
Projection step: 11, Loss: 184.42474365234375
Projection step: 12, Loss: 184.5643310546875
Projection step: 13, Loss: 175.69618225097656
Projection step: 14, Loss: 171.90109252929688
Projection step: 15, Loss: 166.2294921875
Projection step: 16, Loss: 171.2397003173828
Projection step: 17, Loss: 154.5010528564453
Projection step: 18, Loss: 161.43276977539062
Projection step: 19, Loss: 145.64682006835938
Projection step: 20, Loss: 144.52157592773438
Projection step: 21, Loss: 141.7974853515625
Projection step: 22, Loss: 139.85581970214844
Projection step: 23, Loss: 131.30908203125
Projection step: 24, Loss: 132.8737030029297
Final likelihood: tensor([-123.9089, -122.3043, -133.7432, -122.4137, -143.8785, -120.8671,
         -98.6730, -126.6835, -114.1372, -118.5507, -121.1486, -122.4303,
        -126.5504, -140.9253, -119.5309, -130.7833])
Final projection likelihood: -124.1581
1 mode projection succeeded
New goal: tensor([ 0.0266,  0.4782,  0.6981,  0.6855, -0.1576,  0.6676,  0.7778,  0.8900,
         1.3424,  0.2514,  0.0766,  1.1688,  0.0030,  0.0183, -1.0154],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -160.09121704101562
Adjusted likelihood: -160.09121704101562
Likelihood residual: 0.0
Original likelihood: -212.8645477294922
Adjusted likelihood: -212.8645477294922
Likelihood residual: 0.0
{'index': 212.8645477294922, 'thumb_middle': 160.09121704101562}
Current yaw: tensor([ 0.0071,  0.0271, -0.2336], device='cuda:1')
10 thumb_middle
tensor([-0.0130,  0.4677,  0.5793,  0.6664, -0.3159,  0.7168,  0.8810,  1.0162,
         1.4674,  0.3447, -0.0041,  1.1389,  0.0071,  0.0271, -0.2336,  0.6576],
       device='cuda:1')
Solve time for step 1 8.937320008990355
Current ori: tensor([ 0.0071,  0.0271, -0.2336], device='cuda:1')
Index force: tensor([0.5119, 0.4998, 0.5746, 0.5675], device='cuda:1')
tensor([-0.0182,  0.4450,  0.6267,  0.6247, -0.3163,  0.7030,  0.7914,  0.9078,
         1.3496,  0.2556,  0.0268,  1.1498,  0.0081,  0.0311, -0.2333,  0.6383],
       device='cuda:1')
Solve time for step 2 3.6195613099844195
Current ori: tensor([ 0.0081,  0.0311, -0.2333], device='cuda:1')
Index force: tensor([0.5000, 0.5643, 0.5552], device='cuda:1')
tensor([-0.0196,  0.4354,  0.6432,  0.6154, -0.3050,  0.7178,  0.7780,  0.8511,
         1.3435,  0.2489,  0.0340,  1.1510,  0.0096,  0.0317, -0.2333,  0.6362],
       device='cuda:1')
Solve time for step 3 3.4873869430157356
Current ori: tensor([ 0.0096,  0.0317, -0.2333], device='cuda:1')
Index force: tensor([0.5533, 0.5444], device='cuda:1')
tensor([-8.8380e-04,  4.1766e-01,  6.6243e-01,  6.5673e-01, -2.8993e-01,
         7.2111e-01,  7.5994e-01,  8.7898e-01,  1.3306e+00,  2.4747e-01,
         2.8302e-02,  1.1607e+00,  1.9121e-02,  2.0850e-02, -2.3334e-01,
         6.9675e-01], device='cuda:1')
Solve time for step 4 3.4458311969647184
Current ori: tensor([ 0.0191,  0.0209, -0.2333], device='cuda:1')
Index force: tensor([0.5347], device='cuda:1')
Storing RECOVERY transition: reward=0.0006 (scaled=0.0003), steps=2
Reward stats updated: mean 0.0155 -> 0.0155, std: 0.0869
Collected 448 transitions for RL
SAC Update 1/5: Actor Loss=-0.0081, Q1 Loss=0.8193, Q2 Loss=0.8193, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6768
SAC Update 2/5: Actor Loss=-0.0118, Q1 Loss=4.3493, Q2 Loss=4.3493, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.3126
SAC Update 3/5: Actor Loss=-0.0114, Q1 Loss=1.4481, Q2 Loss=1.4481, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4128
SAC Update 4/5: Actor Loss=-0.0102, Q1 Loss=2.6656, Q2 Loss=2.6656, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0539
SAC Update 5/5: Actor Loss=-0.0133, Q1 Loss=1.4712, Q2 Loss=1.4712, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9398

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.7%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (38.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010942
Q1 loss: 2.150704
Q2 loss: 2.150704
Current threshold: -149.5067
Global Scale Offset: 3885.0443
Reward stats: mean=0.0155, std=0.0869, count=448
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 2.1507, Q2 Loss: 2.1507, Entropy: 0.6931, Mean TD Error: 1.8792, Threshold: -149.5067
Original likelihood: -206.00552368164062
Adjusted likelihood: -206.00552368164062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4942)
State is out of distribution
Projection step: 0, Loss: 182.18234252929688
Projection step: 1, Loss: 183.04226684570312
Projection step: 2, Loss: 177.66799926757812
Projection step: 3, Loss: 167.56658935546875
Projection step: 4, Loss: 166.53240966796875
Projection step: 5, Loss: 163.85806274414062
Projection step: 6, Loss: 159.80728149414062
Projection step: 7, Loss: 150.90586853027344
Projection step: 8, Loss: 154.1153564453125
Projection step: 9, Loss: 142.7449951171875
Projection step: 10, Loss: 140.4984588623047
Projection step: 11, Loss: 140.57479858398438
Projection step: 12, Loss: 132.90701293945312
Projection step: 13, Loss: 134.41355895996094
Projection step: 14, Loss: 126.96607208251953
Projection step: 15, Loss: 126.11421203613281
Projection step: 16, Loss: 117.55471801757812
Projection step: 17, Loss: 112.84513854980469
Projection step: 18, Loss: 110.47627258300781
Projection step: 19, Loss: 106.69567108154297
Projection step: 20, Loss: 105.30339050292969
Projection step: 21, Loss: 99.94137573242188
Final likelihood: tensor([ -95.3906,  -81.7966,  -89.7723, -102.5948,  -97.3407, -123.8473,
         -91.3674,  -94.0776,  -74.7398, -125.6253, -107.4187, -106.2763,
         -90.6008, -125.2618,  -94.4332,  -98.5189])
Final projection likelihood: -99.9414
1 mode projection succeeded
New goal: tensor([ 0.0548,  0.5154,  0.6491,  0.6396, -0.1082,  0.6277,  0.7857,  0.8631,
         1.3108,  0.2270,  0.1528,  1.2081,  0.0144,  0.0115, -1.1957],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -117.20368957519531
Adjusted likelihood: -117.20368957519531
Likelihood residual: 0.0
Original likelihood: -177.54953002929688
Adjusted likelihood: -177.54953002929688
Likelihood residual: 0.0
{'index': 177.54953002929688, 'thumb_middle': 117.20368957519531}
Current yaw: tensor([ 0.0196,  0.0036, -0.2339], device='cuda:1')
11 thumb_middle
tensor([ 0.0307,  0.4338,  0.6589,  0.6729, -0.2028,  0.7322,  0.7931,  0.8905,
         1.3785,  0.2565,  0.0844,  1.1871,  0.0196,  0.0036, -0.2339,  0.7456],
       device='cuda:1')
Solve time for step 1 8.991217101051006
Current ori: tensor([ 0.0196,  0.0036, -0.2339], device='cuda:1')
Index force: tensor([0.5567, 0.5523, 0.5704, 0.5719], device='cuda:1')
tensor([ 0.0237,  0.4676,  0.6244,  0.6383, -0.2245,  0.6349,  0.7700,  0.8343,
         1.2836,  0.1932,  0.0663,  1.1970,  0.0050,  0.0077, -0.2339,  0.7047],
       device='cuda:1')
Solve time for step 2 3.590016909991391
Current ori: tensor([ 0.0050,  0.0077, -0.2339], device='cuda:1')
Index force: tensor([0.5419, 0.5590, 0.5612], device='cuda:1')
tensor([ 0.0237,  0.4767,  0.6157,  0.6305, -0.2030,  0.6259,  0.7378,  0.8464,
         1.2675,  0.2082,  0.0867,  1.1731,  0.0017,  0.0077, -0.2339,  0.6986],
       device='cuda:1')
Solve time for step 3 3.53239752096124
Current ori: tensor([ 0.0017,  0.0077, -0.2339], device='cuda:1')
Index force: tensor([0.5493, 0.5527], device='cuda:1')
tensor([ 3.6722e-02,  4.7290e-01,  6.2307e-01,  6.4886e-01, -2.0014e-01,
         6.2176e-01,  7.5922e-01,  8.4296e-01,  1.2679e+00,  2.1708e-01,
         6.7889e-02,  1.1772e+00,  5.0912e-03,  5.8309e-04, -2.3387e-01,
         7.2435e-01], device='cuda:1')
Solve time for step 4 3.3429342430317774
Current ori: tensor([ 0.0051,  0.0006, -0.2339], device='cuda:1')
Index force: tensor([0.5414], device='cuda:1')
Storing RECOVERY transition: reward=0.0030 (scaled=0.0015), steps=2
Reward stats updated: mean 0.0155 -> 0.0154, std: 0.0869
Collected 449 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7658, Q2 Loss=0.7658, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3664
SAC Update 2/5: Actor Loss=-0.0105, Q1 Loss=1.0508, Q2 Loss=1.0508, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1297
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=1.3186, Q2 Loss=1.3186, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9081
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=0.9420, Q2 Loss=0.9420, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5788
SAC Update 5/5: Actor Loss=-0.0132, Q1 Loss=1.4225, Q2 Loss=1.4225, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6152

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.9%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009455
Q1 loss: 1.099930
Q2 loss: 1.099930
Current threshold: -149.5064
Global Scale Offset: 3898.8742
Reward stats: mean=0.0154, std=0.0869, count=449
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.0999, Q2 Loss: 1.0999, Entropy: 0.6930, Mean TD Error: 0.9197, Threshold: -149.5064
Original likelihood: -121.64234161376953
Adjusted likelihood: -121.64234161376953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5029)
Current yaw: tensor([ 0.0081,  0.0040, -0.2359], device='cuda:1')
12 turn
Sampling time 3.890083306992892
tensor([ 0.0296,  0.4663,  0.6307,  0.6393, -0.1419,  0.6530,  0.8059,  0.8693,
         1.3467,  0.2129,  0.1324,  1.2008,  0.0081,  0.0040, -0.2359,  0.7272],
       device='cuda:1')
Original likelihood: -133.24710083007812
Adjusted likelihood: -133.24710083007812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Solve time for step 1 13.85288597503677
Current ori: tensor([ 0.0081,  0.0040, -0.2359], device='cuda:1')
Middle force: tensor([0.8987, 2.2503, 0.5587, 1.4199, 0.6984, 0.9794, 0.5519, 0.8533, 0.5271,
        0.6561, 0.6052, 0.6853], device='cuda:1')
Thumb force: tensor([0.6889, 1.0047, 1.5692, 0.5403, 0.5378, 0.6530, 0.5121, 0.6011, 1.2213,
        0.6257, 0.5603, 0.5789], device='cuda:1')
Index force: tensor([0.5834, 1.6246, 0.6323, 0.6969, 0.7164, 0.7226, 0.6153, 0.7603, 0.5670,
        0.7078, 0.5687, 0.5305], device='cuda:1')
Storing NORMAL transition: reward=0.0895 (scaled=0.0895), steps=1
Reward stats updated: mean 0.0154 -> 0.0156, std: 0.0868
Collected 450 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7932, Q2 Loss=0.7932, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6983
SAC Update 2/5: Actor Loss=-0.0103, Q1 Loss=1.1293, Q2 Loss=1.1293, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8907
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.0900, Q2 Loss=1.0900, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6760
SAC Update 4/5: Actor Loss=-0.0115, Q1 Loss=1.1428, Q2 Loss=1.1428, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1366
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=1.0363, Q2 Loss=1.0363, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3820

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009917
Q1 loss: 1.038322
Q2 loss: 1.038322
Current threshold: -149.5061
Global Scale Offset: 3924.4278
Reward stats: mean=0.0156, std=0.0868, count=450
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.0383, Q2 Loss: 1.0383, Entropy: 0.6931, Mean TD Error: 0.5567, Threshold: -149.5061
tensor([-0.0134,  0.4490,  0.5657,  0.7545, -0.2708,  0.5634,  0.9255,  1.0504,
         1.3838,  0.2038,  0.2204,  1.0858,  0.0207,  0.0453, -0.3282,  0.7122],
       device='cuda:1')
Original likelihood: -249.56332397460938
Adjusted likelihood: -249.56332397460938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4898)
Solve time for step 2 5.507777424005326
Current ori: tensor([ 0.0207,  0.0453, -0.3282], device='cuda:1')
Middle force: tensor([0.6653, 0.7438, 1.2553, 0.7930, 0.5574, 0.6563, 0.6772, 0.5143, 0.5637,
        0.5827, 0.6196], device='cuda:1')
Thumb force: tensor([0.5026, 0.6767, 0.6998, 0.5497, 0.5759, 0.5199, 1.2204, 0.9615, 0.5682,
        0.6081, 0.6193], device='cuda:1')
Index force: tensor([0.7822, 0.5681, 0.9173, 0.5020, 0.6678, 0.5062, 0.9214, 0.5663, 0.5604,
        0.6010, 0.5975], device='cuda:1')
Storing NORMAL transition: reward=0.0151 (scaled=0.0151), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0867
Collected 451 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=1.0361, Q2 Loss=1.0361, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5162
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8554, Q2 Loss=0.8554, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5364
SAC Update 3/5: Actor Loss=-0.0087, Q1 Loss=0.9352, Q2 Loss=0.9352, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0152
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=2.0962, Q2 Loss=2.0962, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2399
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.7130, Q2 Loss=0.7130, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1408

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008882
Q1 loss: 1.127172
Q2 loss: 1.127172
Current threshold: -149.5058
Global Scale Offset: 3942.9118
Reward stats: mean=0.0156, std=0.0867, count=451
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.1272, Q2 Loss: 1.1272, Entropy: 0.6931, Mean TD Error: 1.2897, Threshold: -149.5058
tensor([-0.0091,  0.4399,  0.5937,  0.7248, -0.2646,  0.5649,  0.9452,  1.0146,
         1.3758,  0.2170,  0.2221,  1.0637,  0.0145,  0.0412, -0.3427,  0.6189],
       device='cuda:1')
Original likelihood: -225.63861083984375
Adjusted likelihood: -225.63861083984375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4923)
Solve time for step 3 5.195983979967423
Current ori: tensor([ 0.0145,  0.0412, -0.3427], device='cuda:1')
Middle force: tensor([0.7346, 1.2346, 0.7888, 0.5520, 0.6528, 0.6636, 0.5133, 0.5602, 0.5779,
        0.6138], device='cuda:1')
Thumb force: tensor([0.6684, 0.6954, 0.5468, 0.5717, 0.5187, 1.2079, 0.9526, 0.5667, 0.6060,
        0.6168], device='cuda:1')
Index force: tensor([0.5642, 0.9061, 0.5017, 0.6668, 0.5058, 0.9128, 0.5632, 0.5582, 0.5975,
        0.5941], device='cuda:1')
Storing NORMAL transition: reward=0.0116 (scaled=0.0116), steps=1
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0866
Collected 452 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=1.2544, Q2 Loss=1.2544, Entropy=0.6930, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7459
SAC Update 2/5: Actor Loss=-0.0125, Q1 Loss=1.3156, Q2 Loss=1.3156, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6609
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=0.9887, Q2 Loss=0.9887, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3368
SAC Update 4/5: Actor Loss=-0.0127, Q1 Loss=1.5327, Q2 Loss=1.5327, Entropy=0.6926, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1204
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=0.9566, Q2 Loss=0.9566, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5202

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011267
Q1 loss: 1.209599
Q2 loss: 1.209599
Current threshold: -149.5056
Global Scale Offset: 3955.0603
Reward stats: mean=0.0156, std=0.0866, count=452
----------------------------------------------
SAC Update - Actor Loss: -0.0113, Q1 Loss: 1.2096, Q2 Loss: 1.2096, Entropy: 0.6930, Mean TD Error: 0.6768, Threshold: -149.5056
tensor([-0.0197,  0.3060,  0.6296,  0.6822, -0.1581,  0.6288,  1.0004,  0.7961,
         1.3865,  0.1495,  0.0930,  1.0629, -0.0405, -0.0250, -0.3548, -1.6490],
       device='cuda:1')
Original likelihood: -248.1034393310547
Adjusted likelihood: -248.1034393310547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4901)
Solve time for step 4 4.880872529989574
Current ori: tensor([-0.0405, -0.0250, -0.3548], device='cuda:1')
Middle force: tensor([1.3744, 0.7382, 1.0168, 0.5801, 0.8645, 0.5627, 0.7317, 0.6646, 0.7540],
       device='cuda:1')
Thumb force: tensor([0.5289, 0.5254, 0.5969, 0.5065, 0.5733, 1.1207, 0.5777, 0.5378, 0.5507],
       device='cuda:1')
Index force: tensor([0.6419, 0.6571, 0.6597, 0.5765, 0.7053, 0.5205, 0.6314, 0.5354, 0.5149],
       device='cuda:1')
Storing NORMAL transition: reward=0.1444 (scaled=0.1444), steps=1
Reward stats updated: mean 0.0156 -> 0.0159, std: 0.0867
Collected 453 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7829, Q2 Loss=0.7829, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0482
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=0.9079, Q2 Loss=0.9079, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8175
SAC Update 3/5: Actor Loss=-0.0095, Q1 Loss=1.0769, Q2 Loss=1.0769, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9342
SAC Update 4/5: Actor Loss=-0.0111, Q1 Loss=1.1987, Q2 Loss=1.1987, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8148
SAC Update 5/5: Actor Loss=-0.0108, Q1 Loss=1.2475, Q2 Loss=1.2475, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1471

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.9%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.05s (20.3%)
Actor update: 0.09s (39.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009614
Q1 loss: 1.042777
Q2 loss: 1.042777
Current threshold: -149.5053
Global Scale Offset: 3965.1650
Reward stats: mean=0.0159, std=0.0867, count=453
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.0428, Q2 Loss: 1.0428, Entropy: 0.6930, Mean TD Error: 0.9524, Threshold: -149.5053
tensor([-0.1990,  0.3390,  0.7963,  0.7557, -0.1247,  0.6625,  0.9474,  0.8707,
         1.4021,  0.1414,  0.0880,  0.9387, -0.0699, -0.0460, -0.5101, -3.0729],
       device='cuda:1')
Original likelihood: -237.34051513671875
Adjusted likelihood: -237.34051513671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4912)
State is out of distribution
Projection step: 0, Loss: 236.02928161621094
Projection step: 1, Loss: 222.29849243164062
Projection step: 2, Loss: 222.6031494140625
Projection step: 3, Loss: 206.6654052734375
Projection step: 4, Loss: 205.7608642578125
Projection step: 5, Loss: 200.0674285888672
Projection step: 6, Loss: 229.68331909179688
Projection step: 7, Loss: 197.703857421875
Projection step: 8, Loss: 177.11985778808594
Projection step: 9, Loss: 183.95053100585938
Projection step: 10, Loss: 181.645263671875
Projection step: 11, Loss: 174.0684814453125
Projection step: 12, Loss: 180.91757202148438
Projection step: 13, Loss: 191.387451171875
Projection step: 14, Loss: 179.61224365234375
Projection step: 15, Loss: 177.86331176757812
Projection step: 16, Loss: 167.70999145507812
Projection step: 17, Loss: 178.11817932128906
Projection step: 18, Loss: 188.69155883789062
Projection step: 19, Loss: 168.91172790527344
Projection step: 20, Loss: 176.18601989746094
Projection step: 21, Loss: 175.9212646484375
Projection step: 22, Loss: 148.22088623046875
Projection step: 23, Loss: 168.44699096679688
Projection step: 24, Loss: 165.91607666015625
Final likelihood: tensor([-193.1824, -190.0383, -140.9173, -179.2187, -135.4456, -143.8323,
        -191.5444, -129.2308, -125.7356, -131.2913, -135.0388, -194.1457,
        -130.3561, -198.7006, -327.3199, -181.0332])
Final projection likelihood: -170.4394
1 mode projection failed, trying anyway
New goal: tensor([-0.0939,  0.3465,  0.7699,  0.6462, -0.0877,  0.6386,  0.6907,  1.0498,
         1.3817,  0.0830,  0.1037,  0.7078, -0.0687, -0.0382, -0.1676],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0046]], device='cuda:1')
Original likelihood: -245.2986602783203
Adjusted likelihood: -245.2986602783203
Likelihood residual: 0.0
Original likelihood: -222.37838745117188
Adjusted likelihood: -222.37838745117188
Likelihood residual: 0.0
{'index': 222.37838745117188, 'thumb_middle': 245.2986602783203}
Current yaw: tensor([-0.0699, -0.0460, -0.5101], device='cuda:1')
13 index
tensor([-0.1990,  0.3390,  0.7963,  0.7557, -0.1247,  0.6625,  0.9474,  0.8707,
         1.4021,  0.1414,  0.0880,  0.9387, -0.0699, -0.0460, -0.5101, -3.0729],
       device='cuda:1')
Solve time for step 1 10.345707127999049
Current ori: tensor([-0.0699, -0.0460, -0.5101], device='cuda:1')
Middle force: tensor([0.5258, 0.5607, 0.5109, 0.5495], device='cuda:1')
Thumb force: tensor([0.5370, 0.5662, 0.5016, 0.5619], device='cuda:1')
tensor([-0.1503,  0.3149,  0.7357,  0.6425, -0.1176,  0.7455,  0.7660,  1.0180,
         1.4234,  0.1075,  0.1005,  0.8577, -0.0876, -0.0496, -0.5607, -4.0534],
       device='cuda:1')
Solve time for step 2 4.131456387985963
Current ori: tensor([-0.0876, -0.0496, -0.5607], device='cuda:1')
Middle force: tensor([0.5570, 0.5086, 0.5454], device='cuda:1')
Thumb force: tensor([0.5602, 0.5014, 0.5610], device='cuda:1')
tensor([-0.1404,  0.3149,  0.7287,  0.6250, -0.1273,  0.7617,  0.7256,  1.0275,
         1.4447,  0.0788,  0.1097,  0.8278, -0.0983, -0.0394, -0.5756, -4.3423],
       device='cuda:1')
Solve time for step 3 4.144299623963889
Current ori: tensor([-0.0983, -0.0394, -0.5756], device='cuda:1')
Middle force: tensor([0.5002, 0.5003], device='cuda:1')
Thumb force: tensor([0.5615, 0.5474], device='cuda:1')
tensor([-0.1374,  0.3190,  0.7290,  0.6209, -0.1418,  0.7849,  0.7195,  1.0221,
         1.4269,  0.1405,  0.1112,  0.8246, -0.1193, -0.0305, -0.5675, -4.1123],
       device='cuda:1')
Solve time for step 4 4.292491875006817
Current ori: tensor([-0.1193, -0.0305, -0.5675], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5401], device='cuda:1')
Storing RECOVERY transition: reward=0.0282 (scaled=0.0070), steps=4
Reward stats updated: mean 0.0159 -> 0.0159, std: 0.0867
Collected 454 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=1.5047, Q2 Loss=1.5047, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4295
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8532, Q2 Loss=0.8532, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4772
SAC Update 3/5: Actor Loss=-0.0108, Q1 Loss=1.3464, Q2 Loss=1.3464, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3193
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8168, Q2 Loss=0.8168, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7808
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.8525, Q2 Loss=0.8525, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4229

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (37.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009238
Q1 loss: 1.074707
Q2 loss: 1.074707
Current threshold: -149.5052
Global Scale Offset: 3975.0642
Reward stats: mean=0.0159, std=0.0867, count=454
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.0747, Q2 Loss: 1.0747, Entropy: 0.6931, Mean TD Error: 1.0859, Threshold: -149.5052
Original likelihood: -233.44143676757812
Adjusted likelihood: -233.44143676757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4916)
Current yaw: tensor([-0.1353, -0.0254, -0.5692], device='cuda:1')
14 turn
Sampling time 3.6540245569776744
tensor([-0.1154,  0.4080,  0.7845,  0.6477, -0.1452,  0.7941,  0.7157,  1.0152,
         1.4573,  0.0852,  0.0838,  0.8351, -0.1353, -0.0254, -0.5692, -3.9753],
       device='cuda:1')
Original likelihood: -237.38050842285156
Adjusted likelihood: -237.38050842285156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4912)
State is out of distribution
Projection step: 0, Loss: 239.62744140625
Projection step: 1, Loss: 227.522705078125
Projection step: 2, Loss: 226.54605102539062
Projection step: 3, Loss: 220.32533264160156
Projection step: 4, Loss: 239.97889709472656
Projection step: 5, Loss: 216.76602172851562
Projection step: 6, Loss: 215.63772583007812
Projection step: 7, Loss: 205.87039184570312
Projection step: 8, Loss: 206.76339721679688
Projection step: 9, Loss: 208.88047790527344
Projection step: 10, Loss: 206.1529541015625
Projection step: 11, Loss: 206.54562377929688
Projection step: 12, Loss: 203.89517211914062
Projection step: 13, Loss: 206.02865600585938
Projection step: 14, Loss: 197.03160095214844
Projection step: 15, Loss: 200.76605224609375
Projection step: 16, Loss: 202.37249755859375
Projection step: 17, Loss: 210.55642700195312
Projection step: 18, Loss: 199.79025268554688
Projection step: 19, Loss: 194.25662231445312
Projection step: 20, Loss: 204.1846466064453
Projection step: 21, Loss: 211.22698974609375
Projection step: 22, Loss: 195.4337158203125
Projection step: 23, Loss: 198.88836669921875
Projection step: 24, Loss: 195.85325622558594
Final likelihood: tensor([-200.5555, -220.6670, -209.4793, -180.4530, -188.3674, -173.6171,
        -188.0898, -185.1889, -203.5600, -180.3473, -186.2863, -184.8076,
        -168.8735, -192.9333, -174.0508, -167.7899])
Final projection likelihood: -187.8167
1 mode projection failed, trying anyway
New goal: tensor([-0.0493,  0.3846,  0.7192,  0.6396, -0.1098,  0.6867,  0.6482,  1.0846,
         1.4255,  0.0689,  0.1292,  0.7076, -0.1306, -0.0195, -0.2080],
       device='cuda:1')
tensor([[0.0030]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0017]], device='cuda:1')
Original likelihood: -225.4147491455078
Adjusted likelihood: -225.4147491455078
Likelihood residual: 0.0
Original likelihood: -211.00213623046875
Adjusted likelihood: -211.00213623046875
Likelihood residual: 0.0
{'index': 211.00213623046875, 'thumb_middle': 225.4147491455078}
Current yaw: tensor([-0.1353, -0.0254, -0.5692], device='cuda:1')
15 index
tensor([-0.1154,  0.4080,  0.7845,  0.6477, -0.1452,  0.7941,  0.7157,  1.0152,
         1.4573,  0.0852,  0.0838,  0.8351, -0.1353, -0.0254, -0.5692, -3.9753],
       device='cuda:1')
Solve time for step 1 10.777511595981196
Current ori: tensor([-0.1353, -0.0254, -0.5692], device='cuda:1')
Middle force: tensor([0.5287, 0.5854, 0.5490, 0.5048], device='cuda:1')
Thumb force: tensor([0.5780, 0.6238, 0.5935, 0.5347], device='cuda:1')
tensor([-0.0993,  0.3652,  0.7048,  0.6250, -0.1385,  0.8206,  0.6702,  1.0413,
         1.4594,  0.0847,  0.0935,  0.7897, -0.1490, -0.0277, -0.5733, -4.2977],
       device='cuda:1')
Solve time for step 2 4.267327455978375
Current ori: tensor([-0.1490, -0.0277, -0.5733], device='cuda:1')
Middle force: tensor([0.5218, 0.5270, 0.5137], device='cuda:1')
Thumb force: tensor([0.6334, 0.6143, 0.6247], device='cuda:1')
tensor([-0.0922,  0.3680,  0.6900,  0.6220, -0.1526,  0.8172,  0.6607,  1.0451,
         1.4767,  0.0701,  0.1099,  0.7630, -0.1583, -0.0109, -0.5838, -4.0478],
       device='cuda:1')
Solve time for step 3 4.097808471007738
Current ori: tensor([-0.1583, -0.0109, -0.5838], device='cuda:1')
Middle force: tensor([0.5402, 0.5517], device='cuda:1')
Thumb force: tensor([0.5447, 0.6321], device='cuda:1')
tensor([-0.0942,  0.3772,  0.6957,  0.6243, -0.1574,  0.8390,  0.6681,  1.0496,
         1.4722,  0.0755,  0.1071,  0.7451, -0.1742, -0.0161, -0.5456, -3.7019],
       device='cuda:1')
Solve time for step 4 3.9891524920240045
Current ori: tensor([-0.1742, -0.0161, -0.5456], device='cuda:1')
Middle force: tensor([0.5453], device='cuda:1')
Thumb force: tensor([0.6223], device='cuda:1')
Storing RECOVERY transition: reward=-0.0424 (scaled=-0.0424), steps=0
Reward stats updated: mean 0.0159 -> 0.0157, std: 0.0866
Collected 455 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8264, Q2 Loss=0.8264, Entropy=0.6929, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9795
SAC Update 2/5: Actor Loss=-0.0072, Q1 Loss=0.7117, Q2 Loss=0.7117, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1619
SAC Update 3/5: Actor Loss=-0.0124, Q1 Loss=1.5015, Q2 Loss=1.5015, Entropy=0.6926, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1152
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=4.9454, Q2 Loss=4.9454, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.5670
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=0.9885, Q2 Loss=0.9885, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6878

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.06s (19.3%)
Q2 update: 0.06s (19.3%)
Actor update: 0.12s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008877
Q1 loss: 1.794683
Q2 loss: 1.794683
Current threshold: -149.5051
Global Scale Offset: 3996.2301
Reward stats: mean=0.0157, std=0.0866, count=455
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.7947, Q2 Loss: 1.7947, Entropy: 0.6929, Mean TD Error: 1.9023, Threshold: -149.5051
Original likelihood: -233.8876190185547
Adjusted likelihood: -233.8876190185547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4916)
State is out of distribution
Projection step: 0, Loss: 231.4789581298828
Projection step: 1, Loss: 239.46022033691406
Projection step: 2, Loss: 238.75672912597656
Projection step: 3, Loss: 225.81063842773438
Projection step: 4, Loss: 243.1369171142578
Projection step: 5, Loss: 245.03488159179688
Projection step: 6, Loss: 222.8089599609375
Projection step: 7, Loss: 223.93148803710938
Projection step: 8, Loss: 230.30564880371094
Projection step: 9, Loss: 203.67416381835938
Projection step: 10, Loss: 208.87796020507812
Projection step: 11, Loss: 202.83908081054688
Projection step: 12, Loss: 194.35256958007812
Projection step: 13, Loss: 203.12356567382812
Projection step: 14, Loss: 212.15017700195312
Projection step: 15, Loss: 188.02008056640625
Projection step: 16, Loss: 194.8465576171875
Projection step: 17, Loss: 195.93527221679688
Projection step: 18, Loss: 200.2686004638672
Projection step: 19, Loss: 198.16046142578125
Projection step: 20, Loss: 185.65322875976562
Projection step: 21, Loss: 188.11679077148438
Projection step: 22, Loss: 188.0391082763672
Projection step: 23, Loss: 182.26834106445312
Projection step: 24, Loss: 176.90615844726562
Final likelihood: tensor([-199.6161, -179.0294, -172.5592, -192.0470, -170.1449, -169.7848,
        -187.4851, -166.8375, -164.5767, -169.1112, -167.8515, -170.4290,
        -178.4266, -180.4056, -201.3833, -184.7852])
Final projection likelihood: -178.4046
1 mode projection failed, trying anyway
New goal: tensor([-0.0455,  0.3903,  0.7123,  0.7020, -0.1113,  0.7581,  0.6096,  1.1873,
         1.4482,  0.1018,  0.1495,  0.6249, -0.1716, -0.0267, -0.1454],
       device='cuda:1')
tensor([[0.0031]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0022]], device='cuda:1')
Original likelihood: -326.01165771484375
Adjusted likelihood: -326.01165771484375
Likelihood residual: 0.0
Original likelihood: -263.811767578125
Adjusted likelihood: -263.811767578125
Likelihood residual: 0.0
{'index': 263.811767578125, 'thumb_middle': 326.01165771484375}
Current yaw: tensor([-0.1771, -0.0287, -0.5372], device='cuda:1')
16 index
tensor([-0.0921,  0.4820,  0.7530,  0.6497, -0.1433,  0.8435,  0.6757,  1.0565,
         1.4659,  0.0729,  0.0829,  0.7696, -0.1771, -0.0287, -0.5372, -3.4363],
       device='cuda:1')
Solve time for step 1 10.276577292010188
Current ori: tensor([-0.1771, -0.0287, -0.5372], device='cuda:1')
Middle force: tensor([0.5179, 0.5098, 0.5191, 0.5004], device='cuda:1')
Thumb force: tensor([0.6091, 0.6415, 0.5911, 0.5003], device='cuda:1')
tensor([-0.0922,  0.4034,  0.7053,  0.6801, -0.1623,  0.9099,  0.6049,  1.1003,
         1.4596,  0.0997,  0.1103,  0.6896, -0.2065, -0.0283, -0.4924, -3.5520],
       device='cuda:1')
Solve time for step 2 4.144862184999511
Current ori: tensor([-0.2065, -0.0283, -0.4924], device='cuda:1')
Middle force: tensor([0.5001, 0.5133, 0.5461], device='cuda:1')
Thumb force: tensor([0.5289, 0.5224, 0.5921], device='cuda:1')
tensor([-0.0903,  0.4294,  0.7125,  0.6939, -0.1650,  0.9536,  0.6042,  1.1144,
         1.4606,  0.0982,  0.1064,  0.6554, -0.2339, -0.0353, -0.4437, -3.8456],
       device='cuda:1')
Solve time for step 3 4.115081953001209
Current ori: tensor([-0.2339, -0.0353, -0.4437], device='cuda:1')
Middle force: tensor([0.5094, 0.5429], device='cuda:1')
Thumb force: tensor([0.5223, 0.5875], device='cuda:1')
tensor([-0.1027,  0.4861,  0.7173,  0.6849, -0.1601,  1.0082,  0.6308,  1.1070,
         1.4829,  0.1007,  0.1169,  0.6032, -0.3222, -0.0226, -0.3727, -4.0152],
       device='cuda:1')
Solve time for step 4 3.8796970539842732
Current ori: tensor([-0.3222, -0.0226, -0.3727], device='cuda:1')
Middle force: tensor([0.5002], device='cuda:1')
Thumb force: tensor([0.5644], device='cuda:1')
Storing RECOVERY transition: reward=-0.5024 (scaled=-0.5024), steps=0
Reward stats updated: mean 0.0157 -> 0.0146, std: 0.0898
Collected 456 transitions for RL
SAC Update 1/5: Actor Loss=-0.0107, Q1 Loss=1.1296, Q2 Loss=1.1296, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7766
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=8.0583, Q2 Loss=8.0583, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.2681
SAC Update 3/5: Actor Loss=-0.0133, Q1 Loss=1.5182, Q2 Loss=1.5182, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0217
SAC Update 4/5: Actor Loss=-0.0096, Q1 Loss=2.2076, Q2 Loss=2.2076, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2940
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=1.9524, Q2 Loss=1.9524, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9296

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (38.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010614
Q1 loss: 2.973237
Q2 loss: 2.973237
Current threshold: -149.5050
Global Scale Offset: 4018.8131
Reward stats: mean=0.0146, std=0.0898, count=456
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 2.9732, Q2 Loss: 2.9732, Entropy: 0.6931, Mean TD Error: 3.0580, Threshold: -149.5050
Original likelihood: -1475.447509765625
Adjusted likelihood: -1475.447509765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3708)
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 29
Loaded trajectory sampler
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
1 turn
Sampling time 3.713269953033887
tensor([ 1.4340e-01,  5.8950e-01,  5.7244e-01,  6.4058e-01, -1.4962e-01,
         5.7867e-01,  8.8621e-01,  9.2300e-01,  1.2510e+00,  2.6490e-01,
         2.4341e-01,  1.1728e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Original likelihood: -121.91407012939453
Adjusted likelihood: -121.91407012939453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5027)
State is out of distribution
Projection step: 0, Loss: 124.7087173461914
Projection step: 1, Loss: 112.48395538330078
Projection step: 2, Loss: 104.59135437011719
Final likelihood: tensor([ -97.0648, -136.5615, -120.4132,  -95.3271, -130.6793, -117.2027,
        -129.5756,  -81.0133, -108.9918, -118.8183, -102.9400,  -83.6795,
         -86.4725,  -78.1979, -104.1240,  -82.4001])
Final projection likelihood: -104.5914
1 mode projection succeeded
New goal: tensor([ 1.3444e-01,  5.8119e-01,  5.7025e-01,  6.3423e-01, -1.3335e-01,
         5.8504e-01,  8.9362e-01,  9.0651e-01,  1.2604e+00,  2.7760e-01,
         2.4103e-01,  1.1598e+00,  4.8039e-04,  1.4278e-02, -5.9899e-02],
       device='cuda:1')
tensor([[0.0035]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -142.4572296142578
Adjusted likelihood: -142.4572296142578
Likelihood residual: 0.0
Original likelihood: -125.29610443115234
Adjusted likelihood: -125.29610443115234
Likelihood residual: 0.0
{'index': 125.29610443115234, 'thumb_middle': 142.4572296142578}
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
2 index
tensor([ 1.4340e-01,  5.8950e-01,  5.7244e-01,  6.4058e-01, -1.4962e-01,
         5.7867e-01,  8.8621e-01,  9.2300e-01,  1.2510e+00,  2.6490e-01,
         2.4341e-01,  1.1728e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Solve time for step 1 10.457264897995628
Current ori: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Middle force: tensor([0.5914, 0.5432, 0.5278, 0.5155], device='cuda:1')
Thumb force: tensor([0.5666, 0.5288, 0.5024, 0.5520], device='cuda:1')
tensor([ 0.1834,  0.5324,  0.5254,  0.6110, -0.1555,  0.5734,  0.8907,  0.9148,
         1.2622,  0.2623,  0.2532,  1.1404, -0.0053,  0.0129, -0.0691,  4.7042],
       device='cuda:1')
Solve time for step 2 4.284034839016385
Current ori: tensor([-0.0053,  0.0129, -0.0691], device='cuda:1')
Middle force: tensor([0.5421, 0.5254, 0.5129], device='cuda:1')
Thumb force: tensor([0.5240, 0.5018, 0.5488], device='cuda:1')
tensor([ 0.1852,  0.5325,  0.5235,  0.6113, -0.1465,  0.5892,  0.8796,  0.8973,
         1.2729,  0.2502,  0.2395,  1.1280, -0.0142,  0.0082, -0.0805, -5.1396],
       device='cuda:1')
Solve time for step 3 4.2074038260034285
Current ori: tensor([-0.0142,  0.0082, -0.0805], device='cuda:1')
Middle force: tensor([0.5225, 0.5108], device='cuda:1')
Thumb force: tensor([0.5012, 0.5449], device='cuda:1')
tensor([ 0.1868,  0.5339,  0.5224,  0.6091, -0.1490,  0.5932,  0.8802,  0.8931,
         1.3074,  0.2011,  0.2182,  1.1340, -0.0160,  0.0083, -0.0801, -3.4831],
       device='cuda:1')
Solve time for step 4 4.035316192021128
Current ori: tensor([-0.0160,  0.0083, -0.0801], device='cuda:1')
Middle force: tensor([0.5089], device='cuda:1')
Thumb force: tensor([0.5391], device='cuda:1')
Storing RECOVERY transition: reward=0.0527 (scaled=0.0527), steps=0
Reward stats updated: mean 0.0146 -> 0.0147, std: 0.0898
Collected 457 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=0.9343, Q2 Loss=0.9343, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1482
SAC Update 2/5: Actor Loss=-0.0104, Q1 Loss=2.7116, Q2 Loss=2.7116, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5275
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=0.8731, Q2 Loss=0.8731, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5487
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8445, Q2 Loss=0.8445, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9172
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.9415, Q2 Loss=0.9415, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0141

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.3%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008636
Q1 loss: 1.260993
Q2 loss: 1.260993
Current threshold: -149.5049
Global Scale Offset: 4034.1927
Reward stats: mean=0.0147, std=0.0898, count=457
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.2610, Q2 Loss: 1.2610, Entropy: 0.6931, Mean TD Error: 1.6311, Threshold: -149.5049
Original likelihood: -138.45692443847656
Adjusted likelihood: -138.45692443847656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5011)
State is out of distribution
Projection step: 0, Loss: 138.1394500732422
Projection step: 1, Loss: 136.55368041992188
Projection step: 2, Loss: 124.04632568359375
Projection step: 3, Loss: 117.83322143554688
Projection step: 4, Loss: 111.46208953857422
Projection step: 5, Loss: 109.17411804199219
Projection step: 6, Loss: 104.89398193359375
Final likelihood: tensor([-105.0024,  -95.3490, -109.0400, -101.9680, -100.7399,  -94.2113,
        -143.9052, -109.8706, -108.5982, -111.2493,  -99.2998, -104.5462,
         -87.0522,  -94.0113, -109.5101, -103.9500])
Final projection likelihood: -104.8940
1 mode projection succeeded
New goal: tensor([ 0.1152,  0.5676,  0.5736,  0.6294, -0.1170,  0.5896,  0.9123,  0.8630,
         1.2813,  0.2972,  0.2269,  1.1231, -0.0129,  0.0146, -0.2105],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -112.23046112060547
Adjusted likelihood: -112.23046112060547
Likelihood residual: 0.0
Original likelihood: -129.76904296875
Adjusted likelihood: -129.76904296875
Likelihood residual: 0.0
{'index': 129.76904296875, 'thumb_middle': 112.23046112060547}
Current yaw: tensor([-0.0138,  0.0125, -0.0910], device='cuda:1')
3 thumb_middle
tensor([ 0.1332,  0.5894,  0.5664,  0.6327, -0.1592,  0.5841,  0.8895,  0.9071,
         1.2612,  0.2766,  0.2399,  1.1469, -0.0138,  0.0125, -0.0910, -3.1335],
       device='cuda:1')
Solve time for step 1 8.828200830030255
Current ori: tensor([-0.0138,  0.0125, -0.0910], device='cuda:1')
Index force: tensor([0.5665, 0.5853, 0.5648, 0.5700], device='cuda:1')
tensor([ 0.1326,  0.5858,  0.5681,  0.6372, -0.2362,  0.5557,  0.8596,  0.8442,
         1.2389,  0.2742,  0.1510,  1.0923, -0.0125,  0.0131, -0.0910, -3.1383],
       device='cuda:1')
Solve time for step 2 3.643875878013205
Current ori: tensor([-0.0125,  0.0131, -0.0910], device='cuda:1')
Index force: tensor([0.5721, 0.5541, 0.5589], device='cuda:1')
tensor([ 0.1323,  0.5739,  0.5932,  0.6198, -0.2374,  0.5603,  0.8663,  0.8261,
         1.2383,  0.2912,  0.1347,  1.0950, -0.0112,  0.0135, -0.0910, -3.1409],
       device='cuda:1')
Solve time for step 3 3.5057897070073523
Current ori: tensor([-0.0112,  0.0135, -0.0910], device='cuda:1')
Index force: tensor([0.5426, 0.5479], device='cuda:1')
tensor([ 0.1261,  0.5734,  0.5792,  0.6363, -0.2337,  0.5527,  0.8580,  0.8402,
         1.2531,  0.2609,  0.1438,  1.0750, -0.0098,  0.0173, -0.0910, -3.1470],
       device='cuda:1')
Solve time for step 4 3.3837413120199926
Current ori: tensor([-0.0098,  0.0173, -0.0910], device='cuda:1')
Index force: tensor([0.5343], device='cuda:1')
Storing RECOVERY transition: reward=0.0563 (scaled=0.0563), steps=0
Reward stats updated: mean 0.0147 -> 0.0148, std: 0.0897
Collected 458 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=1.3812, Q2 Loss=1.3812, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3177
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.9621, Q2 Loss=0.9621, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8355
SAC Update 3/5: Actor Loss=-0.0088, Q1 Loss=1.2184, Q2 Loss=1.2184, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1653
SAC Update 4/5: Actor Loss=-0.0126, Q1 Loss=1.6324, Q2 Loss=1.6324, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3880
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=3.0789, Q2 Loss=3.0789, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8949

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.4%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009320
Q1 loss: 1.654622
Q2 loss: 1.654622
Current threshold: -149.5049
Global Scale Offset: 4048.8609
Reward stats: mean=0.0148, std=0.0897, count=458
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.6546, Q2 Loss: 1.6546, Entropy: 0.6931, Mean TD Error: 2.3203, Threshold: -149.5049
Original likelihood: -135.62930297851562
Adjusted likelihood: -135.62930297851562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5014)
Current yaw: tensor([-0.0085,  0.0171, -0.0946], device='cuda:1')
4 turn
Sampling time 3.603921269008424
tensor([ 0.1265,  0.5757,  0.5694,  0.6503, -0.1807,  0.6064,  0.8974,  0.8646,
         1.2971,  0.3022,  0.2089,  1.1178, -0.0085,  0.0171, -0.0946, -3.1459],
       device='cuda:1')
Original likelihood: -140.108642578125
Adjusted likelihood: -140.108642578125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Solve time for step 1 14.127324861008674
Current ori: tensor([-0.0085,  0.0171, -0.0946], device='cuda:1')
Middle force: tensor([1.1281, 0.4846, 0.5274, 0.5468, 1.4358, 0.5254, 0.5585, 0.5149, 0.4995,
        0.5249, 0.5826, 0.5310], device='cuda:1')
Thumb force: tensor([1.2694, 0.5494, 0.6020, 1.7430, 0.8180, 0.5347, 0.5212, 0.9110, 0.5127,
        1.5246, 0.6293, 0.6146], device='cuda:1')
Index force: tensor([0.5680, 0.5087, 0.5658, 0.5175, 0.5632, 0.6265, 0.6034, 0.5172, 0.6250,
        0.7107, 0.5514, 0.4714], device='cuda:1')
Storing NORMAL transition: reward=0.2959 (scaled=0.2959), steps=1
Reward stats updated: mean 0.0148 -> 0.0154, std: 0.0905
Collected 459 transitions for RL
SAC Update 1/5: Actor Loss=-0.0103, Q1 Loss=1.0374, Q2 Loss=1.0374, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1397
SAC Update 2/5: Actor Loss=-0.0083, Q1 Loss=1.2630, Q2 Loss=1.2630, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4978
SAC Update 3/5: Actor Loss=-0.0087, Q1 Loss=1.0992, Q2 Loss=1.0992, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6138
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.7348, Q2 Loss=0.7348, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5913
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=1.1111, Q2 Loss=1.1111, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1022

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.5%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008406
Q1 loss: 1.049087
Q2 loss: 1.049087
Current threshold: -149.5049
Global Scale Offset: 4066.3637
Reward stats: mean=0.0154, std=0.0905, count=459
----------------------------------------------
SAC Update - Actor Loss: -0.0084, Q1 Loss: 1.0491, Q2 Loss: 1.0491, Entropy: 0.6931, Mean TD Error: 1.7890, Threshold: -149.5049
tensor([ 0.2186,  0.6081,  0.6248,  0.6533, -0.1100,  0.5440,  1.0510,  1.0819,
         1.2750,  0.2767,  0.1869,  1.0025,  0.0030, -0.0544, -0.3968, -2.3405],
       device='cuda:1')
Original likelihood: -199.73309326171875
Adjusted likelihood: -199.73309326171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4951)
State is out of distribution
Projection step: 0, Loss: 210.45228576660156
Projection step: 1, Loss: 180.07684326171875
Projection step: 2, Loss: 187.53359985351562
Projection step: 3, Loss: 179.9005126953125
Projection step: 4, Loss: 169.12380981445312
Projection step: 5, Loss: 171.52783203125
Projection step: 6, Loss: 174.8203582763672
Projection step: 7, Loss: 174.9488067626953
Projection step: 8, Loss: 164.90267944335938
Projection step: 9, Loss: 163.39324951171875
Projection step: 10, Loss: 158.14450073242188
Projection step: 11, Loss: 168.28070068359375
Projection step: 12, Loss: 151.8154296875
Projection step: 13, Loss: 155.27224731445312
Projection step: 14, Loss: 157.29705810546875
Projection step: 15, Loss: 145.99539184570312
Projection step: 16, Loss: 151.4114990234375
Projection step: 17, Loss: 141.61993408203125
Projection step: 18, Loss: 145.98789978027344
Projection step: 19, Loss: 135.3863525390625
Projection step: 20, Loss: 140.40277099609375
Projection step: 21, Loss: 133.69601440429688
Projection step: 22, Loss: 138.92135620117188
Projection step: 23, Loss: 139.38397216796875
Projection step: 24, Loss: 125.91279602050781
Final likelihood: tensor([-132.2225, -145.9654, -123.7984, -121.8302, -137.4905, -134.3278,
        -109.3380, -131.7469, -111.3654, -103.0704, -132.3743, -109.4060,
        -132.1751, -143.9373, -149.9988, -138.7353])
Final projection likelihood: -128.6114
1 mode projection succeeded
New goal: tensor([ 1.5710e-01,  5.4816e-01,  6.2914e-01,  7.0104e-01, -4.6490e-02,
         5.9564e-01,  9.5813e-01,  8.6970e-01,  1.3548e+00,  2.1839e-01,
         1.3848e-01,  1.0445e+00, -5.9790e-04, -4.1888e-02, -1.1118e+00],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -166.83322143554688
Adjusted likelihood: -166.83322143554688
Likelihood residual: 0.0
Original likelihood: -172.8587646484375
Adjusted likelihood: -172.8587646484375
Likelihood residual: 0.0
{'index': 172.8587646484375, 'thumb_middle': 166.83322143554688}
Current yaw: tensor([ 0.0030, -0.0544, -0.3968], device='cuda:1')
5 thumb_middle
tensor([ 0.2186,  0.6081,  0.6248,  0.6533, -0.1100,  0.5440,  1.0510,  1.0819,
         1.2750,  0.2767,  0.1869,  1.0025,  0.0030, -0.0544, -0.3968, -2.3405],
       device='cuda:1')
Solve time for step 1 8.71219710400328
Current ori: tensor([ 0.0030, -0.0544, -0.3968], device='cuda:1')
Index force: tensor([0.5876, 0.5715, 0.5926, 0.6003], device='cuda:1')
tensor([ 0.1945,  0.5634,  0.6397,  0.6884, -0.1735,  0.5372,  0.9247,  0.8829,
         1.2981,  0.2196,  0.0725,  1.0098,  0.0141, -0.0368, -0.3946, -2.3590],
       device='cuda:1')
Solve time for step 2 3.6388381629949436
Current ori: tensor([ 0.0141, -0.0368, -0.3946], device='cuda:1')
Index force: tensor([0.5655, 0.5868, 0.5949], device='cuda:1')
tensor([ 0.1976,  0.5555,  0.6396,  0.7162, -0.1696,  0.5648,  0.9014,  0.8435,
         1.3203,  0.2075,  0.0488,  1.0113,  0.0186, -0.0372, -0.3946, -2.3448],
       device='cuda:1')
Solve time for step 3 3.263599224970676
Current ori: tensor([ 0.0186, -0.0372, -0.3946], device='cuda:1')
Index force: tensor([0.5756, 0.5859], device='cuda:1')
tensor([ 0.2100,  0.5644,  0.6436,  0.7118, -0.1703,  0.5804,  0.9049,  0.8434,
         1.3082,  0.1950,  0.0548,  1.0058,  0.0173, -0.0448, -0.3946, -2.3288],
       device='cuda:1')
Solve time for step 4 3.292123665974941
Current ori: tensor([ 0.0173, -0.0448, -0.3946], device='cuda:1')
Index force: tensor([0.5695], device='cuda:1')
Storing RECOVERY transition: reward=-0.0043 (scaled=-0.0043), steps=1
Reward stats updated: mean 0.0154 -> 0.0153, std: 0.0904
Collected 460 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.4295, Q2 Loss=1.4295, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7227
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.1586, Q2 Loss=1.1586, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0563
SAC Update 3/5: Actor Loss=-0.0135, Q1 Loss=1.3836, Q2 Loss=1.3836, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4455
SAC Update 4/5: Actor Loss=-0.0127, Q1 Loss=1.4892, Q2 Loss=1.4892, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0830
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=1.1187, Q2 Loss=1.1187, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0990

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.7%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.04s (18.2%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010985
Q1 loss: 1.315918
Q2 loss: 1.315918
Current threshold: -149.5047
Global Scale Offset: 4078.7279
Reward stats: mean=0.0153, std=0.0904, count=460
----------------------------------------------
SAC Update - Actor Loss: -0.0110, Q1 Loss: 1.3159, Q2 Loss: 1.3159, Entropy: 0.6931, Mean TD Error: 1.2813, Threshold: -149.5047
Original likelihood: -174.53109741210938
Adjusted likelihood: -174.53109741210938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4976)
Current yaw: tensor([ 0.0223, -0.0273, -0.3886], device='cuda:1')
6 turn
Sampling time 3.5731340929633006
tensor([ 0.1813,  0.5391,  0.6388,  0.7265, -0.1298,  0.6266,  0.9335,  0.8577,
         1.3853,  0.2143,  0.1222,  1.0506,  0.0223, -0.0273, -0.3886, -2.3547],
       device='cuda:1')
Original likelihood: -155.36367797851562
Adjusted likelihood: -155.36367797851562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4994)
State is out of distribution
Projection step: 0, Loss: 166.7187957763672
Projection step: 1, Loss: 162.11781311035156
Projection step: 2, Loss: 149.80633544921875
Projection step: 3, Loss: 153.47314453125
Projection step: 4, Loss: 149.15379333496094
Projection step: 5, Loss: 150.09890747070312
Projection step: 6, Loss: 141.60691833496094
Projection step: 7, Loss: 143.88589477539062
Projection step: 8, Loss: 137.1525115966797
Projection step: 9, Loss: 136.02127075195312
Projection step: 10, Loss: 137.82525634765625
Projection step: 11, Loss: 136.16268920898438
Projection step: 12, Loss: 134.30517578125
Projection step: 13, Loss: 130.92837524414062
Projection step: 14, Loss: 134.66046142578125
Projection step: 15, Loss: 128.9947509765625
Projection step: 16, Loss: 126.08122253417969
Projection step: 17, Loss: 120.69580841064453
Projection step: 18, Loss: 128.6004638671875
Projection step: 19, Loss: 126.5377197265625
Projection step: 20, Loss: 128.57742309570312
Projection step: 21, Loss: 126.33619689941406
Projection step: 22, Loss: 130.55389404296875
Projection step: 23, Loss: 123.08905029296875
Projection step: 24, Loss: 128.0071563720703
Final likelihood: tensor([-123.0532, -123.5578, -129.6526, -122.4514, -112.3036,  -96.0179,
        -122.6414, -113.9249, -128.3927, -126.2187, -120.5500, -120.3058,
        -121.0480, -128.3461, -144.5170, -124.6386])
Final projection likelihood: -122.3512
1 mode projection succeeded
New goal: tensor([ 0.1303,  0.5132,  0.6286,  0.7422, -0.0579,  0.6080,  0.9262,  0.7995,
         1.3675,  0.2170,  0.1520,  1.1373,  0.0169, -0.0200, -0.6072],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -142.1616973876953
Adjusted likelihood: -142.1616973876953
Likelihood residual: 0.0
Original likelihood: -152.6320037841797
Adjusted likelihood: -152.6320037841797
Likelihood residual: 0.0
{'index': 152.6320037841797, 'thumb_middle': 142.1616973876953}
Current yaw: tensor([ 0.0223, -0.0273, -0.3886], device='cuda:1')
7 thumb_middle
tensor([ 0.1813,  0.5391,  0.6388,  0.7265, -0.1298,  0.6266,  0.9335,  0.8577,
         1.3853,  0.2143,  0.1222,  1.0506,  0.0223, -0.0273, -0.3886, -2.3547],
       device='cuda:1')
Solve time for step 1 9.204436540952884
Current ori: tensor([ 0.0223, -0.0273, -0.3886], device='cuda:1')
Index force: tensor([0.5688, 0.5844, 0.5671, 0.5596], device='cuda:1')
tensor([ 0.1718,  0.5280,  0.6270,  0.7598, -0.1747,  0.5868,  0.8704,  0.7749,
         1.3173,  0.2069,  0.0515,  1.0768,  0.0272, -0.0204, -0.3885, -2.3689],
       device='cuda:1')
Solve time for step 2 3.4242220720043406
Current ori: tensor([ 0.0272, -0.0204, -0.3885], device='cuda:1')
Index force: tensor([0.5733, 0.5582, 0.5515], device='cuda:1')
tensor([ 0.1809,  0.5270,  0.6392,  0.7570, -0.1699,  0.5920,  0.8727,  0.7676,
         1.3021,  0.1782,  0.0601,  1.0860,  0.0278, -0.0253, -0.3885, -2.3565],
       device='cuda:1')
Solve time for step 3 3.588415984006133
Current ori: tensor([ 0.0278, -0.0253, -0.3885], device='cuda:1')
Index force: tensor([0.5586, 0.5655], device='cuda:1')
tensor([ 0.1823,  0.5252,  0.6448,  0.7535, -0.1534,  0.5731,  0.8722,  0.7673,
         1.3031,  0.1762,  0.0508,  1.0996,  0.0280, -0.0261, -0.3885, -2.3551],
       device='cuda:1')
Solve time for step 4 3.482750875002239
Current ori: tensor([ 0.0280, -0.0261, -0.3885], device='cuda:1')
Index force: tensor([0.5477], device='cuda:1')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0056), steps=0
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0903
Collected 461 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.9344, Q2 Loss=0.9344, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9190
SAC Update 2/5: Actor Loss=-0.0116, Q1 Loss=1.3379, Q2 Loss=1.3379, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9529
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.1239, Q2 Loss=1.1239, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7360
SAC Update 4/5: Actor Loss=-0.0109, Q1 Loss=1.1106, Q2 Loss=1.1106, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2733
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=1.0390, Q2 Loss=1.0390, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2699

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009711
Q1 loss: 1.109141
Q2 loss: 1.109141
Current threshold: -149.5044
Global Scale Offset: 4099.7571
Reward stats: mean=0.0153, std=0.0903, count=461
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.1091, Q2 Loss: 1.1091, Entropy: 0.6930, Mean TD Error: 1.2302, Threshold: -149.5044
Original likelihood: -154.21942138671875
Adjusted likelihood: -154.21942138671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4995)
Current yaw: tensor([ 0.0276, -0.0082, -0.3825], device='cuda:1')
8 turn
Sampling time 3.6745346389943734
tensor([ 0.1490,  0.5143,  0.6312,  0.7402, -0.1183,  0.6163,  0.9038,  0.7855,
         1.3759,  0.2047,  0.1200,  1.1341,  0.0276, -0.0082, -0.3825, -2.3922],
       device='cuda:1')
Original likelihood: -135.50022888183594
Adjusted likelihood: -135.50022888183594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5014)
State is out of distribution
Projection step: 0, Loss: 145.88638305664062
Projection step: 1, Loss: 146.18960571289062
Projection step: 2, Loss: 133.82785034179688
Projection step: 3, Loss: 132.47915649414062
Projection step: 4, Loss: 127.74330139160156
Projection step: 5, Loss: 123.32575225830078
Projection step: 6, Loss: 119.45912170410156
Projection step: 7, Loss: 126.17465209960938
Projection step: 8, Loss: 123.91223907470703
Projection step: 9, Loss: 117.46440124511719
Projection step: 10, Loss: 119.06114959716797
Projection step: 11, Loss: 119.5935287475586
Projection step: 12, Loss: 113.7262954711914
Projection step: 13, Loss: 111.46996307373047
Projection step: 14, Loss: 109.55030822753906
Projection step: 15, Loss: 110.66973876953125
Projection step: 16, Loss: 106.52578735351562
Projection step: 17, Loss: 110.07717895507812
Projection step: 18, Loss: 103.95128631591797
Final likelihood: tensor([-124.8699,  -98.5788, -101.4117, -101.9210, -136.9698, -103.7917,
         -94.2198, -110.0465,  -90.1410, -114.2408, -117.0554,  -99.1490,
         -73.4879, -103.2479,  -90.8022, -103.2872])
Final projection likelihood: -103.9513
1 mode projection succeeded
New goal: tensor([ 0.1116,  0.5153,  0.6143,  0.7133, -0.0712,  0.5732,  0.9170,  0.8296,
         1.3467,  0.2524,  0.1837,  1.1511,  0.0248, -0.0024, -0.5061],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -121.09988403320312
Adjusted likelihood: -121.09988403320312
Likelihood residual: 0.0
Original likelihood: -134.4930419921875
Adjusted likelihood: -134.4930419921875
Likelihood residual: 0.0
{'index': 134.4930419921875, 'thumb_middle': 121.09988403320312}
Current yaw: tensor([ 0.0276, -0.0082, -0.3825], device='cuda:1')
9 thumb_middle
tensor([ 0.1490,  0.5143,  0.6312,  0.7402, -0.1183,  0.6163,  0.9038,  0.7855,
         1.3759,  0.2047,  0.1200,  1.1341,  0.0276, -0.0082, -0.3825, -2.3922],
       device='cuda:1')
Solve time for step 1 9.320546694041695
Current ori: tensor([ 0.0276, -0.0082, -0.3825], device='cuda:1')
Index force: tensor([0.5975, 0.5790, 0.5902, 0.5896], device='cuda:1')
tensor([ 0.1450,  0.5147,  0.6342,  0.7235, -0.1896,  0.5495,  0.8736,  0.7897,
         1.2919,  0.2137,  0.0847,  1.1150,  0.0255, -0.0061, -0.3825, -2.4234],
       device='cuda:1')
Solve time for step 2 3.70902065502014
Current ori: tensor([ 0.0255, -0.0061, -0.3825], device='cuda:1')
Index force: tensor([0.5703, 0.5826, 0.5856], device='cuda:1')
tensor([ 1.3003e-01,  5.2780e-01,  6.1152e-01,  7.0441e-01, -1.8596e-01,
         5.4089e-01,  8.5964e-01,  7.9215e-01,  1.2905e+00,  2.2086e-01,
         8.6249e-02,  1.1065e+00,  2.0209e-02,  9.1810e-04, -3.8249e-01,
        -2.4554e+00], device='cuda:1')
Solve time for step 3 3.5214682869846
Current ori: tensor([ 0.0202,  0.0009, -0.3825], device='cuda:1')
Index force: tensor([0.5671, 0.5826], device='cuda:1')
tensor([ 0.1270,  0.5223,  0.6133,  0.7096, -0.1879,  0.5550,  0.8444,  0.7866,
         1.2829,  0.2291,  0.0877,  1.1181,  0.0219,  0.0029, -0.3825, -2.4562],
       device='cuda:1')
Solve time for step 4 3.3985747270053253
Current ori: tensor([ 0.0219,  0.0029, -0.3825], device='cuda:1')
Index force: tensor([0.5808], device='cuda:1')
Storing RECOVERY transition: reward=0.0037 (scaled=0.0037), steps=0
Reward stats updated: mean 0.0153 -> 0.0153, std: 0.0903
Collected 462 transitions for RL
SAC Update 1/5: Actor Loss=-0.0134, Q1 Loss=1.3915, Q2 Loss=1.3915, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2987
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=1.1182, Q2 Loss=1.1182, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3957
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.0100, Q2 Loss=1.0100, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8616
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=0.7066, Q2 Loss=0.7066, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3339
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=0.9052, Q2 Loss=0.9052, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6442

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.9%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.06s (20.5%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009874
Q1 loss: 1.026309
Q2 loss: 1.026309
Current threshold: -149.5043
Global Scale Offset: 4125.3170
Reward stats: mean=0.0153, std=0.0903, count=462
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.0263, Q2 Loss: 1.0263, Entropy: 0.6930, Mean TD Error: 0.5068, Threshold: -149.5043
Original likelihood: -123.15322875976562
Adjusted likelihood: -123.15322875976562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5025)
Current yaw: tensor([ 0.0275,  0.0154, -0.3864], device='cuda:1')
10 turn
Sampling time 3.7009340040385723
tensor([ 0.1023,  0.4988,  0.6181,  0.7152, -0.1398,  0.5846,  0.8871,  0.8144,
         1.3618,  0.2437,  0.1581,  1.1347,  0.0275,  0.0154, -0.3864, -2.4892],
       device='cuda:1')
Original likelihood: -134.57888793945312
Adjusted likelihood: -134.57888793945312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5014)
Solve time for step 1 14.27574822504539
Current ori: tensor([ 0.0275,  0.0154, -0.3864], device='cuda:1')
Middle force: tensor([1.3716, 0.5032, 0.4979, 0.5324, 0.5653, 0.5862, 1.0926, 0.8357, 0.7710,
        0.5726, 0.5068, 0.5821], device='cuda:1')
Thumb force: tensor([1.9530, 2.0029, 1.4434, 0.5369, 1.1245, 0.8270, 1.4803, 0.5721, 0.7758,
        0.6787, 0.5713, 0.6296], device='cuda:1')
Index force: tensor([0.5605, 0.8524, 0.8193, 0.6198, 0.5612, 0.5485, 0.5851, 0.5214, 0.5714,
        0.5749, 0.5049, 0.6124], device='cuda:1')
Storing NORMAL transition: reward=-0.1583 (scaled=-0.1583), steps=1
Reward stats updated: mean 0.0153 -> 0.0149, std: 0.0905
Collected 463 transitions for RL
SAC Update 1/5: Actor Loss=-0.0124, Q1 Loss=1.4458, Q2 Loss=1.4458, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0662
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.8066, Q2 Loss=0.8066, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3149
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=2.2536, Q2 Loss=2.2536, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3026
SAC Update 4/5: Actor Loss=-0.0113, Q1 Loss=1.2951, Q2 Loss=1.2951, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0213
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.8051, Q2 Loss=0.8051, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1706

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.8%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.3%)
Actor update: 0.12s (42.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009760
Q1 loss: 1.321249
Q2 loss: 1.321249
Current threshold: -149.5040
Global Scale Offset: 4145.1272
Reward stats: mean=0.0149, std=0.0905, count=463
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.3212, Q2 Loss: 1.3212, Entropy: 0.6931, Mean TD Error: 1.3751, Threshold: -149.5040
tensor([ 0.2142,  0.4350,  0.4874,  0.6894, -0.1250,  0.6714,  0.7900,  0.6768,
         1.3993,  0.1809,  0.1448,  1.1480,  0.0149,  0.0266, -0.2278, -1.3379],
       device='cuda:1')
Original likelihood: -190.9641876220703
Adjusted likelihood: -190.9641876220703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4960)
Solve time for step 2 5.4370133049669676
Current ori: tensor([ 0.0149,  0.0266, -0.2278], device='cuda:1')
Middle force: tensor([0.5024, 0.5011, 0.5277, 0.5645, 0.5765, 1.0617, 0.8206, 0.7528, 0.5668,
        0.5060, 0.5766], device='cuda:1')
Thumb force: tensor([1.9660, 1.4167, 0.5353, 1.1019, 0.8290, 1.4539, 0.5694, 0.7767, 0.6783,
        0.5689, 0.6255], device='cuda:1')
Index force: tensor([0.8294, 0.8385, 0.6215, 0.5576, 0.5440, 0.5822, 0.5204, 0.5664, 0.5714,
        0.5043, 0.6093], device='cuda:1')
Storing NORMAL transition: reward=-0.0072 (scaled=-0.0072), steps=1
Reward stats updated: mean 0.0149 -> 0.0149, std: 0.0904
Collected 464 transitions for RL
SAC Update 1/5: Actor Loss=-0.0109, Q1 Loss=1.4074, Q2 Loss=1.4074, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4271
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=0.8540, Q2 Loss=0.8540, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3202
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.8055, Q2 Loss=0.8055, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6199
SAC Update 4/5: Actor Loss=-0.0119, Q1 Loss=1.2229, Q2 Loss=1.2229, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4998
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=1.0014, Q2 Loss=1.0014, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8079

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.3%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.3%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009520
Q1 loss: 1.058222
Q2 loss: 1.058222
Current threshold: -149.5037
Global Scale Offset: 4166.3435
Reward stats: mean=0.0149, std=0.0904, count=464
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.0582, Q2 Loss: 1.0582, Entropy: 0.6931, Mean TD Error: 0.9350, Threshold: -149.5037
tensor([ 0.0733,  0.3869,  0.6678,  0.8664, -0.0554,  0.5987,  0.6480,  0.7277,
         1.4078,  0.1266,  0.0987,  1.1749,  0.0365,  0.0496, -0.2227, -0.8711],
       device='cuda:1')
Original likelihood: -253.33444213867188
Adjusted likelihood: -253.33444213867188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4901)
Solve time for step 3 5.25751746102469
Current ori: tensor([ 0.0365,  0.0496, -0.2227], device='cuda:1')
Middle force: tensor([0.5007, 0.5231, 0.5607, 0.5710, 1.0233, 0.7950, 0.7336, 0.5608, 0.5044,
        0.5723], device='cuda:1')
Thumb force: tensor([1.3851, 0.5323, 1.0785, 0.8283, 1.4372, 0.5690, 0.7721, 0.6749, 0.5668,
        0.6233], device='cuda:1')
Index force: tensor([0.8737, 0.6371, 0.5578, 0.5382, 0.5808, 0.5207, 0.5640, 0.5690, 0.5043,
        0.6041], device='cuda:1')
Storing NORMAL transition: reward=0.0048 (scaled=0.0048), steps=1
Reward stats updated: mean 0.0149 -> 0.0148, std: 0.0903
Collected 465 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.9094, Q2 Loss=0.9094, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0332
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=0.8642, Q2 Loss=0.8642, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3583
SAC Update 3/5: Actor Loss=-0.0075, Q1 Loss=0.7975, Q2 Loss=0.7975, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1754
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.0152, Q2 Loss=1.0152, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4334
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.2074, Q2 Loss=1.2074, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0889

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (42.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008822
Q1 loss: 0.958742
Q2 loss: 0.958742
Current threshold: -149.5036
Global Scale Offset: 4184.1610
Reward stats: mean=0.0148, std=0.0903, count=465
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 0.9587, Q2 Loss: 0.9587, Entropy: 0.6931, Mean TD Error: 1.0178, Threshold: -149.5036
tensor([ 0.0656,  0.4698,  0.5584,  0.8353, -0.1394,  0.6658,  0.5500,  0.7720,
         1.3101,  0.3965,  0.2616,  1.1460,  0.0241,  0.0824, -0.2301, -0.9421],
       device='cuda:1')
Original likelihood: -299.23614501953125
Adjusted likelihood: -299.23614501953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4857)
State is out of distribution
Projection step: 0, Loss: 296.98291015625
Projection step: 1, Loss: 287.19317626953125
Projection step: 2, Loss: 275.37628173828125
Projection step: 3, Loss: 287.30157470703125
Projection step: 4, Loss: 276.8543701171875
Projection step: 5, Loss: 269.0194396972656
Projection step: 6, Loss: 250.9405059814453
Projection step: 7, Loss: 262.9139404296875
Projection step: 8, Loss: 247.74618530273438
Projection step: 9, Loss: 233.95046997070312
Projection step: 10, Loss: 225.54893493652344
Projection step: 11, Loss: 222.46461486816406
Projection step: 12, Loss: 226.73861694335938
Projection step: 13, Loss: 218.86654663085938
Projection step: 14, Loss: 207.14303588867188
Projection step: 15, Loss: 195.0495147705078
Projection step: 16, Loss: 196.64625549316406
Projection step: 17, Loss: 187.02955627441406
Projection step: 18, Loss: 186.47747802734375
Projection step: 19, Loss: 183.00506591796875
Projection step: 20, Loss: 181.24346923828125
Projection step: 21, Loss: 177.03427124023438
Projection step: 22, Loss: 163.61886596679688
Projection step: 23, Loss: 166.61233520507812
Projection step: 24, Loss: 164.0067138671875
Final likelihood: tensor([-143.3218, -137.9016, -155.2671, -191.8659, -145.8046, -151.6348,
        -133.2023, -169.1051, -153.7334, -170.2772, -144.1558, -146.2946,
        -149.0625, -153.8609, -138.3121, -138.6422])
Final projection likelihood: -151.4026
1 mode projection failed, trying anyway
New goal: tensor([ 0.0316,  0.5766,  0.5551,  0.6291, -0.1184,  0.6298,  0.5924,  0.8016,
         1.2921,  0.2916,  0.2132,  1.2182,  0.0312,  0.0517, -0.2794],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -214.4835662841797
Adjusted likelihood: -214.4835662841797
Likelihood residual: 0.0
Original likelihood: -172.85455322265625
Adjusted likelihood: -172.85455322265625
Likelihood residual: 0.0
{'index': 172.85455322265625, 'thumb_middle': 214.4835662841797}
Current yaw: tensor([ 0.0241,  0.0824, -0.2301], device='cuda:1')
11 index
tensor([ 0.0656,  0.4698,  0.5584,  0.8353, -0.1394,  0.6658,  0.5500,  0.7720,
         1.3101,  0.3965,  0.2616,  1.1460,  0.0241,  0.0824, -0.2301, -0.9421],
       device='cuda:1')
Solve time for step 1 10.278803939989302
Current ori: tensor([ 0.0241,  0.0824, -0.2301], device='cuda:1')
Middle force: tensor([0.5689, 0.5555, 0.5455, 0.5065], device='cuda:1')
Thumb force: tensor([0.5895, 0.5919, 0.5790, 0.5322], device='cuda:1')
tensor([ 0.0853,  0.4832,  0.4940,  0.6342, -0.1300,  0.6293,  0.5986,  0.8129,
         1.3443,  0.3517,  0.2080,  1.1959,  0.0354,  0.0749, -0.2641, -3.3506],
       device='cuda:1')
Solve time for step 2 4.047164089977741
Current ori: tensor([ 0.0354,  0.0749, -0.2641], device='cuda:1')
Middle force: tensor([0.5172, 0.5521, 0.5493], device='cuda:1')
Thumb force: tensor([0.5889, 0.5323, 0.5279], device='cuda:1')
tensor([ 0.0849,  0.4949,  0.4919,  0.6044, -0.1323,  0.6229,  0.6065,  0.8195,
         1.3646,  0.3293,  0.1848,  1.2149,  0.0370,  0.0755, -0.2739, -4.9602],
       device='cuda:1')
Solve time for step 3 4.074265277013183
Current ori: tensor([ 0.0370,  0.0755, -0.2739], device='cuda:1')
Middle force: tensor([0.5628, 0.5361], device='cuda:1')
Thumb force: tensor([0.5982, 0.5564], device='cuda:1')
tensor([ 0.0866,  0.4980,  0.4893,  0.5975, -0.1161,  0.6545,  0.5843,  0.7869,
         1.3346,  0.3674,  0.1947,  1.1951,  0.0249,  0.0666, -0.2658, -6.2689],
       device='cuda:1')
Solve time for step 4 3.9043790630530566
Current ori: tensor([ 0.0249,  0.0666, -0.2658], device='cuda:1')
Middle force: tensor([0.5341], device='cuda:1')
Thumb force: tensor([0.5513], device='cuda:1')
Storing RECOVERY transition: reward=0.0445 (scaled=0.0148), steps=3
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0902
Collected 466 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.0373, Q2 Loss=1.0373, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9185
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8308, Q2 Loss=0.8308, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0309
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8334, Q2 Loss=0.8334, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3402
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=1.3208, Q2 Loss=1.3208, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0936
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=1.0237, Q2 Loss=1.0237, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3654

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (41.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008080
Q1 loss: 1.009190
Q2 loss: 1.009190
Current threshold: -149.5035
Global Scale Offset: 4197.4052
Reward stats: mean=0.0148, std=0.0902, count=466
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.0092, Q2 Loss: 1.0092, Entropy: 0.6931, Mean TD Error: 1.5497, Threshold: -149.5035
Original likelihood: -224.117919921875
Adjusted likelihood: -224.117919921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4929)
Current yaw: tensor([ 0.0262,  0.0690, -0.2735], device='cuda:1')
12 turn
Sampling time 3.599908944044728
tensor([ 0.0403,  0.5546,  0.5291,  0.6169, -0.1206,  0.6486,  0.5878,  0.7931,
         1.3758,  0.3174,  0.1560,  1.2196,  0.0262,  0.0690, -0.2735,  6.0281],
       device='cuda:1')
Original likelihood: -218.6123504638672
Adjusted likelihood: -218.6123504638672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4934)
Solve time for step 1 14.253570494998712
Current ori: tensor([ 0.0262,  0.0690, -0.2735], device='cuda:1')
Middle force: tensor([1.5061, 0.8432, 0.9299, 1.4062, 1.2310, 0.6478, 0.5502, 0.5677, 0.7233,
        0.5306, 0.5358, 0.5014], device='cuda:1')
Thumb force: tensor([0.7300, 0.5519, 0.5874, 0.5890, 1.1003, 1.0904, 0.9430, 0.6335, 0.9591,
        0.5592, 0.6524, 0.6071], device='cuda:1')
Index force: tensor([0.7657, 0.6234, 0.6730, 0.5319, 0.9245, 0.7968, 0.5542, 0.5388, 0.5818,
        0.6542, 0.6172, 0.5984], device='cuda:1')
Storing NORMAL transition: reward=0.1226 (scaled=0.1226), steps=1
Reward stats updated: mean 0.0148 -> 0.0151, std: 0.0903
Collected 467 transitions for RL
SAC Update 1/5: Actor Loss=-0.0080, Q1 Loss=0.8739, Q2 Loss=0.8739, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5487
SAC Update 2/5: Actor Loss=-0.0080, Q1 Loss=0.9866, Q2 Loss=0.9866, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0337
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.4123, Q2 Loss=1.4123, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6316
SAC Update 4/5: Actor Loss=-0.0069, Q1 Loss=0.6926, Q2 Loss=0.6926, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1278
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=1.2084, Q2 Loss=1.2084, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0357

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (40.9%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009050
Q1 loss: 1.034757
Q2 loss: 1.034757
Current threshold: -149.5035
Global Scale Offset: 4203.0625
Reward stats: mean=0.0151, std=0.0903, count=467
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.0348, Q2 Loss: 1.0348, Entropy: 0.6931, Mean TD Error: 0.8755, Threshold: -149.5035
tensor([-0.0363,  0.4668,  0.5584,  0.6724, -0.1064,  0.5426,  0.7085,  0.9779,
         1.2281,  0.4110,  0.1972,  0.9816,  0.0551,  0.0447, -0.3971,  5.9973],
       device='cuda:1')
Original likelihood: -213.13265991210938
Adjusted likelihood: -213.13265991210938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4940)
State is out of distribution
Projection step: 0, Loss: 190.4813232421875
Projection step: 1, Loss: 181.2726287841797
Projection step: 2, Loss: 176.02935791015625
Projection step: 3, Loss: 171.60992431640625
Projection step: 4, Loss: 167.46115112304688
Projection step: 5, Loss: 162.92654418945312
Projection step: 6, Loss: 159.63247680664062
Projection step: 7, Loss: 160.82406616210938
Projection step: 8, Loss: 152.72218322753906
Projection step: 9, Loss: 151.62033081054688
Projection step: 10, Loss: 142.56576538085938
Projection step: 11, Loss: 138.07086181640625
Projection step: 12, Loss: 138.24319458007812
Projection step: 13, Loss: 134.93667602539062
Projection step: 14, Loss: 124.24539184570312
Projection step: 15, Loss: 123.04916381835938
Projection step: 16, Loss: 118.45594787597656
Projection step: 17, Loss: 117.1094970703125
Projection step: 18, Loss: 118.1536865234375
Projection step: 19, Loss: 108.27630615234375
Projection step: 20, Loss: 107.33522033691406
Projection step: 21, Loss: 103.65631866455078
Final likelihood: tensor([-106.8074,  -96.5577, -108.4005, -102.8268, -104.4806, -100.2336,
        -100.4177, -107.9981, -104.8199, -102.8247,  -94.5642, -103.6972,
        -105.7616, -112.9098, -105.4927, -100.7085])
Final projection likelihood: -103.6563
1 mode projection succeeded
New goal: tensor([ 0.0260,  0.5322,  0.5944,  0.5885, -0.1128,  0.5338,  0.7763,  0.9140,
         1.2673,  0.3572,  0.2224,  1.1887,  0.0464,  0.0308, -1.3704],
       device='cuda:1')
tensor([[0.0193]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -139.92294311523438
Adjusted likelihood: -139.92294311523438
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 139.92294311523438}
Current yaw: tensor([ 0.0551,  0.0447, -0.3971], device='cuda:1')
13 thumb_middle
tensor([-0.0363,  0.4668,  0.5584,  0.6724, -0.1064,  0.5426,  0.7085,  0.9779,
         1.2281,  0.4110,  0.1972,  0.9816,  0.0551,  0.0447, -0.3971,  5.9973],
       device='cuda:1')
Solve time for step 1 9.123494344006758
Current ori: tensor([ 0.0551,  0.0447, -0.3971], device='cuda:1')
Index force: tensor([0.5762, 0.5871, 0.5704, 0.5881], device='cuda:1')
tensor([-0.0210,  0.4669,  0.5913,  0.6292, -0.2010,  0.5298,  0.7398,  0.8896,
         1.2228,  0.3505,  0.1778,  1.1263,  0.0526,  0.0401, -0.3971,  6.0175],
       device='cuda:1')
Solve time for step 2 3.5094673489802517
Current ori: tensor([ 0.0526,  0.0401, -0.3971], device='cuda:1')
Index force: tensor([0.6209, 0.5775, 0.5718], device='cuda:1')
tensor([-0.0075,  0.4816,  0.5999,  0.5935, -0.2003,  0.5379,  0.7325,  0.8919,
         1.2267,  0.3673,  0.1498,  1.1520,  0.0456,  0.0334, -0.3971,  6.0237],
       device='cuda:1')
Solve time for step 3 3.40027011098573
Current ori: tensor([ 0.0456,  0.0334, -0.3971], device='cuda:1')
Index force: tensor([0.5645, 0.5622], device='cuda:1')
tensor([ 0.0077,  0.4887,  0.5931,  0.6129, -0.2072,  0.5464,  0.7523,  0.8968,
         1.2254,  0.3368,  0.1528,  1.1452,  0.0457,  0.0260, -0.3971,  6.0472],
       device='cuda:1')
Solve time for step 4 3.382010975969024
Current ori: tensor([ 0.0457,  0.0260, -0.3971], device='cuda:1')
Index force: tensor([0.5476], device='cuda:1')
Storing RECOVERY transition: reward=0.0022 (scaled=0.0022), steps=1
Reward stats updated: mean 0.0151 -> 0.0150, std: 0.0902
Collected 468 transitions for RL
SAC Update 1/5: Actor Loss=-0.0100, Q1 Loss=1.0883, Q2 Loss=1.0883, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9533
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.1002, Q2 Loss=1.1002, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2173
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.0797, Q2 Loss=1.0797, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9154
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=0.8387, Q2 Loss=0.8387, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3881
SAC Update 5/5: Actor Loss=-0.0083, Q1 Loss=1.2081, Q2 Loss=1.2081, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4772

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.4%)
Actor update: 0.08s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009052
Q1 loss: 1.063001
Q2 loss: 1.063001
Current threshold: -149.5033
Global Scale Offset: 4202.5548
Reward stats: mean=0.0150, std=0.0902, count=468
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.0630, Q2 Loss: 1.0630, Entropy: 0.6931, Mean TD Error: 1.3903, Threshold: -149.5033
Original likelihood: -165.71742248535156
Adjusted likelihood: -165.71742248535156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4985)
Current yaw: tensor([ 0.0449,  0.0360, -0.3972], device='cuda:1')
14 turn
Sampling time 3.57915388798574
tensor([-0.0144,  0.4959,  0.5727,  0.5965, -0.1513,  0.5746,  0.7951,  0.9309,
         1.2912,  0.3566,  0.2091,  1.2088,  0.0449,  0.0360, -0.3972,  6.0800],
       device='cuda:1')
Original likelihood: -143.27346801757812
Adjusted likelihood: -143.27346801757812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 146.87088012695312
Projection step: 1, Loss: 137.75628662109375
Projection step: 2, Loss: 134.90496826171875
Projection step: 3, Loss: 133.4281768798828
Projection step: 4, Loss: 130.52694702148438
Projection step: 5, Loss: 121.99665069580078
Projection step: 6, Loss: 126.61631774902344
Projection step: 7, Loss: 118.85725402832031
Projection step: 8, Loss: 112.61029052734375
Projection step: 9, Loss: 109.68350219726562
Projection step: 10, Loss: 102.6001205444336
Final likelihood: tensor([-104.0245,  -98.9329,  -99.8477, -105.4027,  -98.7029, -104.1608,
        -104.2825, -105.5206,  -96.5709, -105.5079, -102.9954, -103.9960,
        -108.3559,  -94.6341, -107.5782, -101.0890])
Final projection likelihood: -102.6001
1 mode projection succeeded
New goal: tensor([ 0.0129,  0.5209,  0.5927,  0.5915, -0.1288,  0.5433,  0.7840,  0.9266,
         1.2768,  0.3282,  0.1996,  1.2126,  0.0412,  0.0307, -0.8283],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -139.3194122314453
Adjusted likelihood: -139.3194122314453
Likelihood residual: 0.0
Original likelihood: -137.76995849609375
Adjusted likelihood: -137.76995849609375
Likelihood residual: 0.0
{'index': 137.76995849609375, 'thumb_middle': 139.3194122314453}
Current yaw: tensor([ 0.0449,  0.0360, -0.3972], device='cuda:1')
15 index
tensor([-0.0144,  0.4959,  0.5727,  0.5965, -0.1513,  0.5746,  0.7951,  0.9309,
         1.2912,  0.3566,  0.2091,  1.2088,  0.0449,  0.0360, -0.3972,  6.0800],
       device='cuda:1')
Solve time for step 1 10.461031454964541
Current ori: tensor([ 0.0449,  0.0360, -0.3972], device='cuda:1')
Middle force: tensor([0.5766, 0.5521, 0.5079, 0.6122], device='cuda:1')
Thumb force: tensor([0.5329, 0.5338, 0.5515, 0.5651], device='cuda:1')
tensor([ 0.0534,  0.4569,  0.5373,  0.5677, -0.1667,  0.5641,  0.8034,  0.9412,
         1.3201,  0.3240,  0.2053,  1.1967,  0.0468,  0.0428, -0.4184, -5.5445],
       device='cuda:1')
Solve time for step 2 4.080790271982551
Current ori: tensor([ 0.0468,  0.0428, -0.4184], device='cuda:1')
Middle force: tensor([0.5488, 0.5071, 0.6094], device='cuda:1')
Thumb force: tensor([0.5321, 0.5493, 0.5626], device='cuda:1')
tensor([ 0.0606,  0.4611,  0.5366,  0.5654, -0.1632,  0.5693,  0.8006,  0.9342,
         1.3209,  0.3234,  0.2019,  1.1916,  0.0432,  0.0409, -0.4217, -5.1810],
       device='cuda:1')
Solve time for step 3 4.167890156968497
Current ori: tensor([ 0.0432,  0.0409, -0.4217], device='cuda:1')
Middle force: tensor([0.5729, 0.5894], device='cuda:1')
Thumb force: tensor([0.5903, 0.5683], device='cuda:1')
tensor([ 0.0611,  0.4619,  0.5364,  0.5644, -0.1641,  0.5644,  0.8114,  0.9466,
         1.3200,  0.3260,  0.1934,  1.2051,  0.0467,  0.0382, -0.4334, -5.2435],
       device='cuda:1')
Solve time for step 4 4.021125286002643
Current ori: tensor([ 0.0467,  0.0382, -0.4334], device='cuda:1')
Middle force: tensor([0.5370], device='cuda:1')
Thumb force: tensor([0.5424], device='cuda:1')
Storing RECOVERY transition: reward=0.0202 (scaled=0.0202), steps=0
Reward stats updated: mean 0.0150 -> 0.0150, std: 0.0901
Collected 469 transitions for RL
SAC Update 1/5: Actor Loss=-0.0096, Q1 Loss=0.9614, Q2 Loss=0.9614, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2643
SAC Update 2/5: Actor Loss=-0.0131, Q1 Loss=1.3013, Q2 Loss=1.3013, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1394
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.8157, Q2 Loss=0.8157, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3264
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.0996, Q2 Loss=1.0996, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2390
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=2.2695, Q2 Loss=2.2695, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6435

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (16.5%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.2%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009937
Q1 loss: 1.289500
Q2 loss: 1.289500
Current threshold: -149.5032
Global Scale Offset: 4203.4029
Reward stats: mean=0.0150, std=0.0901, count=469
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.2895, Q2 Loss: 1.2895, Entropy: 0.6931, Mean TD Error: 1.3225, Threshold: -149.5032
Original likelihood: -120.80484771728516
Adjusted likelihood: -120.80484771728516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5027)
Current yaw: tensor([ 0.0439,  0.0343, -0.4173], device='cuda:1')
16 turn
Sampling time 3.6524212500080466
tensor([ 0.0152,  0.5174,  0.5734,  0.5862, -0.1561,  0.5740,  0.8077,  0.9320,
         1.3083,  0.3381,  0.1926,  1.2090,  0.0439,  0.0343, -0.4173, -5.3365],
       device='cuda:1')
Original likelihood: -127.42557525634766
Adjusted likelihood: -127.42557525634766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5021)
Solve time for step 1 14.128813361981884
Current ori: tensor([ 0.0439,  0.0343, -0.4173], device='cuda:1')
Middle force: tensor([0.5033, 0.6914, 0.5763, 1.0511, 0.5548, 0.5635, 0.5684, 0.5178, 0.8499,
        0.6529, 0.5763, 0.5387], device='cuda:1')
Thumb force: tensor([0.7788, 1.7024, 0.5221, 1.3247, 0.8765, 0.5645, 0.5326, 0.5601, 0.6131,
        0.5455, 0.5386, 0.7991], device='cuda:1')
Index force: tensor([1.0086, 0.8368, 0.5961, 0.5368, 0.5565, 0.5916, 0.4865, 0.6014, 0.8117,
        0.5457, 0.6760, 0.6483], device='cuda:1')
Storing NORMAL transition: reward=0.0377 (scaled=0.0377), steps=1
Reward stats updated: mean 0.0150 -> 0.0151, std: 0.0900
Collected 470 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=1.1757, Q2 Loss=1.1757, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5642
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.0680, Q2 Loss=1.0680, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6367
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=1.2685, Q2 Loss=1.2685, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6563
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=1.4938, Q2 Loss=1.4938, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9897
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.9829, Q2 Loss=0.9829, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0363

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (20.6%)
Actor update: 0.11s (42.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009975
Q1 loss: 1.197779
Q2 loss: 1.197779
Current threshold: -149.5029
Global Scale Offset: 4214.6023
Reward stats: mean=0.0151, std=0.0900, count=470
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.1978, Q2 Loss: 1.1978, Entropy: 0.6931, Mean TD Error: 1.3766, Threshold: -149.5029
tensor([ 0.0187,  0.4277,  0.6366,  0.7170, -0.1441,  0.5669,  0.7582,  1.0604,
         1.3307,  0.3005,  0.1928,  1.1771,  0.0556,  0.0281, -0.4560, -5.5086],
       device='cuda:1')
Original likelihood: -160.2291259765625
Adjusted likelihood: -160.2291259765625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4990)
State is out of distribution
Projection step: 0, Loss: 171.60891723632812
Projection step: 1, Loss: 164.276123046875
Projection step: 2, Loss: 153.78106689453125
Projection step: 3, Loss: 150.20114135742188
Projection step: 4, Loss: 144.08978271484375
Projection step: 5, Loss: 142.8436737060547
Projection step: 6, Loss: 137.9727783203125
Projection step: 7, Loss: 133.5421600341797
Projection step: 8, Loss: 128.63894653320312
Projection step: 9, Loss: 128.92050170898438
Projection step: 10, Loss: 122.17911529541016
Projection step: 11, Loss: 126.4629898071289
Projection step: 12, Loss: 123.79747772216797
Projection step: 13, Loss: 118.67622375488281
Projection step: 14, Loss: 122.58976745605469
Projection step: 15, Loss: 112.49227905273438
Projection step: 16, Loss: 109.98341369628906
Projection step: 17, Loss: 105.90953063964844
Projection step: 18, Loss: 107.99629211425781
Projection step: 19, Loss: 98.47935485839844
Final likelihood: tensor([ -97.9118,  -94.6152,  -95.9000,  -93.4530, -126.2465,  -93.8042,
         -99.7572,  -91.3659,  -90.0895,  -96.2460, -101.1342,  -97.3471,
        -109.5136,  -90.6397, -102.7436,  -94.9021])
Final projection likelihood: -98.4793
1 mode projection succeeded
New goal: tensor([ 0.0321,  0.5178,  0.6076,  0.6146, -0.1025,  0.5370,  0.7856,  0.9421,
         1.2798,  0.3107,  0.1999,  1.1995,  0.0461,  0.0208, -1.2008],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -112.0699462890625
Adjusted likelihood: -112.0699462890625
Likelihood residual: 0.0
Original likelihood: -127.29322814941406
Adjusted likelihood: -127.29322814941406
Likelihood residual: 0.0
{'index': 127.29322814941406, 'thumb_middle': 112.0699462890625}
Current yaw: tensor([ 0.0556,  0.0281, -0.4560], device='cuda:1')
17 thumb_middle
tensor([ 0.0187,  0.4277,  0.6366,  0.7170, -0.1441,  0.5669,  0.7582,  1.0604,
         1.3307,  0.3005,  0.1928,  1.1771,  0.0556,  0.0281, -0.4560, -5.5086],
       device='cuda:1')
Solve time for step 1 9.025207231054083
Current ori: tensor([ 0.0556,  0.0281, -0.4560], device='cuda:1')
Index force: tensor([0.5990, 0.5939, 0.5992, 0.5923], device='cuda:1')
tensor([ 0.0166,  0.4711,  0.6121,  0.6428, -0.2067,  0.5328,  0.7426,  0.9374,
         1.2470,  0.2902,  0.1376,  1.1747,  0.0423,  0.0308, -0.4560, -5.5170],
       device='cuda:1')
Solve time for step 2 3.671498289972078
Current ori: tensor([ 0.0423,  0.0308, -0.4560], device='cuda:1')
Index force: tensor([0.5795, 0.5882, 0.5841], device='cuda:1')
tensor([ 0.0211,  0.4997,  0.5926,  0.6111, -0.2065,  0.5348,  0.7494,  0.9200,
         1.2415,  0.2898,  0.1320,  1.1762,  0.0322,  0.0278, -0.4560, -5.5291],
       device='cuda:1')
Solve time for step 3 3.5121800120105036
Current ori: tensor([ 0.0322,  0.0278, -0.4560], device='cuda:1')
Index force: tensor([0.5794, 0.5770], device='cuda:1')
tensor([ 0.0236,  0.4991,  0.5952,  0.6119, -0.2055,  0.5383,  0.7487,  0.9159,
         1.2420,  0.2920,  0.1282,  1.1752,  0.0323,  0.0265, -0.4560, -5.5259],
       device='cuda:1')
Solve time for step 4 3.4487801239592955
Current ori: tensor([ 0.0323,  0.0265, -0.4560], device='cuda:1')
Index force: tensor([0.5625], device='cuda:1')
Storing RECOVERY transition: reward=0.0001 (scaled=0.0001), steps=1
Reward stats updated: mean 0.0151 -> 0.0151, std: 0.0899
Collected 471 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.8577, Q2 Loss=0.8577, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2513
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=1.1922, Q2 Loss=1.1922, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1084
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.0775, Q2 Loss=1.0775, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3908
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.8697, Q2 Loss=0.8697, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9726
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.7758, Q2 Loss=0.7758, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3142

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009073
Q1 loss: 0.954563
Q2 loss: 0.954563
Current threshold: -149.5028
Global Scale Offset: 4230.5016
Reward stats: mean=0.0151, std=0.0899, count=471
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9546, Q2 Loss: 0.9546, Entropy: 0.6931, Mean TD Error: 0.8075, Threshold: -149.5028
Original likelihood: -136.71417236328125
Adjusted likelihood: -136.71417236328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5012)
Current yaw: tensor([ 0.0395,  0.0324, -0.4548], device='cuda:1')
18 turn
Sampling time 3.575535504030995
tensor([ 0.0081,  0.4745,  0.6046,  0.6339, -0.1446,  0.5764,  0.7866,  0.9378,
         1.3135,  0.3156,  0.1934,  1.2042,  0.0395,  0.0324, -0.4548, -5.5404],
       device='cuda:1')
Original likelihood: -130.14788818359375
Adjusted likelihood: -130.14788818359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5018)
State is out of distribution
Projection step: 0, Loss: 134.00994873046875
Projection step: 1, Loss: 128.83335876464844
Projection step: 2, Loss: 123.66423797607422
Projection step: 3, Loss: 116.48136901855469
Projection step: 4, Loss: 110.89791107177734
Projection step: 5, Loss: 108.33805847167969
Projection step: 6, Loss: 100.26144409179688
Final likelihood: tensor([ -94.7552, -104.8244,  -95.7123,  -97.2423,  -93.9523, -101.6125,
         -88.6696,  -96.0594,  -91.8153, -102.5977,  -94.9753,  -99.3590,
        -121.4599, -121.6268, -101.3508,  -98.1703])
Final projection likelihood: -100.2614
1 mode projection succeeded
New goal: tensor([ 0.0197,  0.5083,  0.6060,  0.6129, -0.1289,  0.5533,  0.7853,  0.9255,
         1.2867,  0.3133,  0.1827,  1.2184,  0.0374,  0.0292, -0.7359],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -119.89569091796875
Adjusted likelihood: -119.89569091796875
Likelihood residual: 0.0
Original likelihood: -131.75555419921875
Adjusted likelihood: -131.75555419921875
Likelihood residual: 0.0
{'index': 131.75555419921875, 'thumb_middle': 119.89569091796875}
Current yaw: tensor([ 0.0395,  0.0324, -0.4548], device='cuda:1')
19 thumb_middle
tensor([ 0.0081,  0.4745,  0.6046,  0.6339, -0.1446,  0.5764,  0.7866,  0.9378,
         1.3135,  0.3156,  0.1934,  1.2042,  0.0395,  0.0324, -0.4548, -5.5404],
       device='cuda:1')
Solve time for step 1 9.090053218998946
Current ori: tensor([ 0.0395,  0.0324, -0.4548], device='cuda:1')
Index force: tensor([0.5749, 0.5809, 0.5783, 0.5054], device='cuda:1')
tensor([ 0.0207,  0.4852,  0.6087,  0.6180, -0.2055,  0.5461,  0.7526,  0.9086,
         1.2473,  0.2770,  0.1160,  1.2077,  0.0364,  0.0283, -0.4547, -5.5248],
       device='cuda:1')
Solve time for step 2 3.80973937001545
Current ori: tensor([ 0.0364,  0.0283, -0.4547], device='cuda:1')
Index force: tensor([0.5786, 0.6023, 0.6027], device='cuda:1')
tensor([ 0.0237,  0.5051,  0.5945,  0.5970, -0.2144,  0.5557,  0.7534,  0.9039,
         1.2458,  0.2864,  0.1111,  1.2011,  0.0298,  0.0265, -0.4547, -5.5324],
       device='cuda:1')
Solve time for step 3 3.3370276790228672
Current ori: tensor([ 0.0298,  0.0265, -0.4547], device='cuda:1')
Index force: tensor([0.5950, 0.5971], device='cuda:1')
tensor([ 0.0231,  0.4904,  0.6027,  0.6198, -0.2152,  0.5559,  0.7530,  0.9016,
         1.2482,  0.2901,  0.1120,  1.1982,  0.0354,  0.0272, -0.4547, -5.5208],
       device='cuda:1')
Solve time for step 4 3.353365658025723
Current ori: tensor([ 0.0354,  0.0272, -0.4547], device='cuda:1')
Index force: tensor([0.5451], device='cuda:1')
Storing RECOVERY transition: reward=0.0049 (scaled=0.0049), steps=0
Reward stats updated: mean 0.0151 -> 0.0150, std: 0.0898
Collected 472 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8083, Q2 Loss=0.8083, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3265
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.0086, Q2 Loss=1.0086, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3092
SAC Update 3/5: Actor Loss=-0.0095, Q1 Loss=1.6524, Q2 Loss=1.6524, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4834
SAC Update 4/5: Actor Loss=-0.0073, Q1 Loss=0.7285, Q2 Loss=0.7285, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1606
SAC Update 5/5: Actor Loss=-0.0075, Q1 Loss=0.9418, Q2 Loss=0.9418, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3435

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.7%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008417
Q1 loss: 1.027898
Q2 loss: 1.027898
Current threshold: -149.5026
Global Scale Offset: 4248.6409
Reward stats: mean=0.0150, std=0.0898, count=472
----------------------------------------------
SAC Update - Actor Loss: -0.0084, Q1 Loss: 1.0279, Q2 Loss: 1.0279, Entropy: 0.6931, Mean TD Error: 1.1246, Threshold: -149.5026
Original likelihood: -137.21194458007812
Adjusted likelihood: -137.21194458007812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5012)
Current yaw: tensor([ 0.0345,  0.0333, -0.4594], device='cuda:1')
20 turn
Sampling time 3.65086497599259
tensor([ 0.0092,  0.4910,  0.5979,  0.6040, -0.1623,  0.5976,  0.7901,  0.9296,
         1.3218,  0.3021,  0.1720,  1.2362,  0.0345,  0.0333, -0.4594, -5.5075],
       device='cuda:1')
Original likelihood: -135.92282104492188
Adjusted likelihood: -135.92282104492188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5013)
Solve time for step 1 14.067801565979607
Current ori: tensor([ 0.0345,  0.0333, -0.4594], device='cuda:1')
Middle force: tensor([0.6115, 0.7672, 0.5629, 0.5446, 0.5523, 0.8450, 0.5083, 0.4887, 0.6280,
        0.5541, 0.5449, 0.5752], device='cuda:1')
Thumb force: tensor([0.5462, 0.5669, 0.5219, 0.6938, 0.5427, 1.3446, 0.5400, 0.5438, 0.5712,
        0.5391, 0.5176, 0.5859], device='cuda:1')
Index force: tensor([0.5416, 0.5811, 0.6400, 0.5348, 0.6109, 0.5631, 0.6059, 0.7260, 0.5794,
        0.6908, 0.7473, 0.6341], device='cuda:1')
Storing NORMAL transition: reward=0.0786 (scaled=0.0786), steps=1
Reward stats updated: mean 0.0150 -> 0.0152, std: 0.0898
Collected 473 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7171, Q2 Loss=0.7171, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1482
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=3.6311, Q2 Loss=3.6311, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0127
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=1.1941, Q2 Loss=1.1941, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7970
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=1.2815, Q2 Loss=1.2815, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0785
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7223, Q2 Loss=0.7223, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6895

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (16.9%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008327
Q1 loss: 1.509229
Q2 loss: 1.509229
Current threshold: -149.5025
Global Scale Offset: 4269.4968
Reward stats: mean=0.0152, std=0.0898, count=473
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 1.5092, Q2 Loss: 1.5092, Entropy: 0.6931, Mean TD Error: 2.1452, Threshold: -149.5025
tensor([ 3.7750e-03,  4.8769e-01,  5.7523e-01,  6.4888e-01, -1.5832e-01,
         5.8198e-01,  8.2093e-01,  9.2102e-01,  1.3019e+00,  3.3558e-01,
         2.2072e-01,  1.1260e+00,  2.7979e-02,  2.8641e-02, -5.3757e-01,
        -5.8050e+00], device='cuda:1')
Original likelihood: -128.2354736328125
Adjusted likelihood: -128.2354736328125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 118.86000061035156
Projection step: 1, Loss: 117.5226821899414
Projection step: 2, Loss: 108.63394165039062
Projection step: 3, Loss: 102.85289764404297
Final likelihood: tensor([-108.3211, -113.2066,  -94.1201,  -91.8312, -101.6279, -107.6825,
         -91.8055, -102.5941, -105.8048, -108.3396, -104.7471, -108.4007,
        -104.9407, -109.1400, -102.8323,  -90.2521])
Final projection likelihood: -102.8529
1 mode projection succeeded
New goal: tensor([ 0.0102,  0.4971,  0.5819,  0.6433, -0.1401,  0.5622,  0.8131,  0.9184,
         1.2924,  0.3176,  0.2090,  1.1484,  0.0273,  0.0275, -0.5873],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 30
Loaded trajectory sampler
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
1 turn
Sampling time 3.6089038909994997
tensor([ 1.5031e-01,  6.0757e-01,  5.8328e-01,  5.8348e-01, -1.6015e-01,
         5.4492e-01,  9.7446e-01,  8.7471e-01,  1.2095e+00,  2.9921e-01,
         2.6932e-01,  1.1867e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Original likelihood: -151.39048767089844
Adjusted likelihood: -151.39048767089844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4998)
State is out of distribution
Projection step: 0, Loss: 139.75131225585938
Projection step: 1, Loss: 130.39405822753906
Projection step: 2, Loss: 135.28421020507812
Projection step: 3, Loss: 109.90426635742188
Projection step: 4, Loss: 107.56989288330078
Projection step: 5, Loss: 109.48473358154297
Projection step: 6, Loss: 92.0358657836914
Final likelihood: tensor([ -77.8424,  -55.4740, -118.1860, -109.3755,  -80.9025,  -70.7769,
         -95.7280, -110.2633,  -85.7407,  -87.0423, -105.4815, -100.1345,
         -95.7313,  -73.3343,  -89.2479, -117.3128])
Final projection likelihood: -92.0359
1 mode projection succeeded
New goal: tensor([ 0.1237,  0.5750,  0.5803,  0.6007, -0.1141,  0.5708,  0.9451,  0.8493,
         1.2599,  0.3150,  0.2603,  1.1475,  0.0014,  0.0141, -0.0754],
       device='cuda:1')
tensor([[0.0038]], device='cuda:1') tensor([[0.0016]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -134.18060302734375
Adjusted likelihood: -134.18060302734375
Likelihood residual: 0.0
Original likelihood: -136.16595458984375
Adjusted likelihood: -136.16595458984375
Likelihood residual: 0.0
{'index': 136.16595458984375, 'thumb_middle': 134.18060302734375}
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
2 thumb_middle
tensor([ 1.5031e-01,  6.0757e-01,  5.8328e-01,  5.8348e-01, -1.6015e-01,
         5.4492e-01,  9.7446e-01,  8.7471e-01,  1.2095e+00,  2.9921e-01,
         2.6932e-01,  1.1867e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Solve time for step 1 9.22891779098427
Current ori: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Index force: tensor([0.5760, 0.5849, 0.5682, 0.5798], device='cuda:1')
tensor([ 1.4677e-01,  6.0403e-01,  5.7940e-01,  5.9166e-01, -2.2932e-01,
         5.0997e-01,  9.0156e-01,  8.2721e-01,  1.2157e+00,  2.8934e-01,
         1.7907e-01,  1.1036e+00,  1.1536e-04,  1.2959e-02, -3.7436e-02,
         3.3976e-01], device='cuda:1')
Solve time for step 2 3.6189874279662035
Current ori: tensor([ 0.0001,  0.0130, -0.0374], device='cuda:1')
Index force: tensor([0.5010, 0.5589, 0.5660], device='cuda:1')
tensor([ 0.1456,  0.5943,  0.5952,  0.5842, -0.2320,  0.5179,  0.8930,  0.8327,
         1.2167,  0.3100,  0.1725,  1.0839,  0.0017,  0.0139, -0.0374,  0.3373],
       device='cuda:1')
Solve time for step 3 3.635975022043567
Current ori: tensor([ 0.0017,  0.0139, -0.0374], device='cuda:1')
Index force: tensor([0.5481, 0.5545], device='cuda:1')
tensor([ 1.5433e-01,  6.0248e-01,  5.8758e-01,  5.9643e-01, -2.3294e-01,
         5.3619e-01,  9.0265e-01,  8.1863e-01,  1.2073e+00,  2.8250e-01,
         1.6478e-01,  1.1090e+00,  7.8356e-04,  8.6883e-03, -3.7436e-02,
         3.5563e-01], device='cuda:1')
Solve time for step 4 3.5449166629696265
Current ori: tensor([ 0.0008,  0.0087, -0.0374], device='cuda:1')
Index force: tensor([0.5471], device='cuda:1')
Storing RECOVERY transition: reward=-0.0020 (scaled=-0.0020), steps=0
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0897
Collected 474 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.7380, Q2 Loss=0.7380, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5034
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=2.7829, Q2 Loss=2.7829, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7985
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=1.6439, Q2 Loss=1.6439, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4486
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7203, Q2 Loss=0.7203, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1466
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.8954, Q2 Loss=0.8954, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5785

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (18.8%)
Actor update: 0.09s (39.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008022
Q1 loss: 1.356110
Q2 loss: 1.356110
Current threshold: -149.5022
Global Scale Offset: 4291.2496
Reward stats: mean=0.0151, std=0.0897, count=474
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 1.3561, Q2 Loss: 1.3561, Entropy: 0.6931, Mean TD Error: 1.8951, Threshold: -149.5022
Original likelihood: -145.27200317382812
Adjusted likelihood: -145.27200317382812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5004)
Current yaw: tensor([ 0.0052,  0.0231, -0.0365], device='cuda:1')
3 turn
Sampling time 3.7257282360224053
tensor([ 0.1291,  0.5943,  0.5572,  0.6261, -0.1875,  0.5782,  0.9345,  0.8399,
         1.2922,  0.3070,  0.2229,  1.1296,  0.0052,  0.0231, -0.0365,  0.3443],
       device='cuda:1')
Original likelihood: -156.3008270263672
Adjusted likelihood: -156.3008270263672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4994)
Solve time for step 1 14.060314888018183
Current ori: tensor([ 0.0052,  0.0231, -0.0365], device='cuda:1')
Middle force: tensor([0.6089, 0.4824, 0.8450, 0.5215, 1.2849, 0.6048, 1.0019, 0.5004, 0.4868,
        0.5276, 0.4676, 0.5218], device='cuda:1')
Thumb force: tensor([1.4705, 0.5413, 2.1081, 0.5585, 0.5860, 0.6618, 0.5312, 0.5481, 0.5472,
        0.6983, 0.6100, 0.5358], device='cuda:1')
Index force: tensor([1.0454, 0.7242, 0.7304, 0.5675, 0.8149, 0.5446, 0.5083, 0.7025, 0.5689,
        0.5730, 0.7566, 0.5065], device='cuda:1')
Storing NORMAL transition: reward=0.0235 (scaled=0.0235), steps=1
Reward stats updated: mean 0.0151 -> 0.0152, std: 0.0896
Collected 475 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=0.8444, Q2 Loss=0.8444, Entropy=0.6930, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3450
SAC Update 2/5: Actor Loss=-0.0128, Q1 Loss=1.4753, Q2 Loss=1.4753, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0071
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.9678, Q2 Loss=0.9678, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6877
SAC Update 4/5: Actor Loss=-0.0127, Q1 Loss=1.4298, Q2 Loss=1.4298, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9690
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=1.6658, Q2 Loss=1.6658, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2342

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (39.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010452
Q1 loss: 1.276622
Q2 loss: 1.276622
Current threshold: -149.5019
Global Scale Offset: 4310.0657
Reward stats: mean=0.0152, std=0.0896, count=475
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.2766, Q2 Loss: 1.2766, Entropy: 0.6931, Mean TD Error: 1.0486, Threshold: -149.5019
tensor([ 0.1865,  0.5817,  0.6401,  0.6210, -0.1130,  0.6713,  0.8726,  0.8452,
         1.2889,  0.3301,  0.0850,  1.1844, -0.0233, -0.0341, -0.0611,  1.0033],
       device='cuda:1')
Original likelihood: -181.24374389648438
Adjusted likelihood: -181.24374389648438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4971)
State is out of distribution
Projection step: 0, Loss: 177.21002197265625
Projection step: 1, Loss: 163.53521728515625
Projection step: 2, Loss: 164.18960571289062
Projection step: 3, Loss: 167.4110870361328
Projection step: 4, Loss: 157.59872436523438
Projection step: 5, Loss: 156.72862243652344
Projection step: 6, Loss: 148.40158081054688
Projection step: 7, Loss: 151.8043212890625
Projection step: 8, Loss: 136.107421875
Projection step: 9, Loss: 136.32003784179688
Projection step: 10, Loss: 137.38182067871094
Projection step: 11, Loss: 134.26043701171875
Projection step: 12, Loss: 134.70993041992188
Projection step: 13, Loss: 136.37960815429688
Projection step: 14, Loss: 131.34652709960938
Projection step: 15, Loss: 128.40484619140625
Projection step: 16, Loss: 129.52511596679688
Projection step: 17, Loss: 126.60939025878906
Projection step: 18, Loss: 119.00507354736328
Projection step: 19, Loss: 119.00453186035156
Projection step: 20, Loss: 126.022216796875
Projection step: 21, Loss: 123.34999084472656
Projection step: 22, Loss: 121.93704223632812
Projection step: 23, Loss: 117.389404296875
Projection step: 24, Loss: 119.14421081542969
Final likelihood: tensor([-116.1025, -122.6800, -100.7490, -119.1414, -114.9670, -112.1259,
        -117.5575, -119.4261, -125.6032,  -89.7686, -122.6028, -114.5754,
        -110.5034, -113.7464, -110.0560, -123.6583])
Final projection likelihood: -114.5790
1 mode projection succeeded
New goal: tensor([ 0.1298,  0.5348,  0.5751,  0.7450, -0.0362,  0.6734,  0.8305,  0.7954,
         1.3577,  0.2821,  0.1556,  1.0258, -0.0230, -0.0258, -3.0872],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -120.9595947265625
Adjusted likelihood: -120.9595947265625
Likelihood residual: 0.0
Original likelihood: -141.38975524902344
Adjusted likelihood: -141.38975524902344
Likelihood residual: 0.0
{'index': 141.38975524902344, 'thumb_middle': 120.9595947265625}
Current yaw: tensor([-0.0233, -0.0341, -0.0611], device='cuda:1')
4 thumb_middle
tensor([ 0.1865,  0.5817,  0.6401,  0.6210, -0.1130,  0.6713,  0.8726,  0.8452,
         1.2889,  0.3301,  0.0850,  1.1844, -0.0233, -0.0341, -0.0611,  1.0033],
       device='cuda:1')
Solve time for step 1 8.96582732303068
Current ori: tensor([-0.0233, -0.0341, -0.0611], device='cuda:1')
Index force: tensor([0.5593, 0.5814, 0.5935, 0.6019], device='cuda:1')
tensor([ 0.1581,  0.5756,  0.5800,  0.6963, -0.1645,  0.6230,  0.7888,  0.7746,
         1.3041,  0.2740,  0.0603,  1.0138, -0.0165, -0.0148, -0.0612,  0.9722],
       device='cuda:1')
Solve time for step 2 3.8845725179999135
Current ori: tensor([-0.0165, -0.0148, -0.0612], device='cuda:1')
Index force: tensor([0.5560, 0.5775, 0.5743], device='cuda:1')
tensor([ 0.1520,  0.5520,  0.5796,  0.7479, -0.1650,  0.6267,  0.7698,  0.7547,
         1.3211,  0.2690,  0.0614,  0.9987, -0.0067, -0.0096, -0.0612,  0.9850],
       device='cuda:1')
Solve time for step 3 3.569283821969293
Current ori: tensor([-0.0067, -0.0096, -0.0612], device='cuda:1')
Index force: tensor([0.5639, 0.5638], device='cuda:1')
tensor([ 0.1719,  0.5690,  0.5845,  0.7345, -0.1615,  0.6317,  0.7867,  0.7824,
         1.3158,  0.2645,  0.0575,  0.9786, -0.0109, -0.0223, -0.0612,  1.0058],
       device='cuda:1')
Solve time for step 4 3.450846324034501
Current ori: tensor([-0.0109, -0.0223, -0.0612], device='cuda:1')
Index force: tensor([0.5498], device='cuda:1')
Storing RECOVERY transition: reward=-0.0103 (scaled=-0.0103), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0895
Collected 476 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=0.9585, Q2 Loss=0.9585, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3899
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=0.9333, Q2 Loss=0.9333, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3110
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.8189, Q2 Loss=0.8189, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4448
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7212, Q2 Loss=0.7212, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2296
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=2.0025, Q2 Loss=2.0025, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6992

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.6%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (17.7%)
Actor update: 0.10s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008640
Q1 loss: 1.086868
Q2 loss: 1.086868
Current threshold: -149.5015
Global Scale Offset: 4328.4213
Reward stats: mean=0.0151, std=0.0895, count=476
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.0869, Q2 Loss: 1.0869, Entropy: 0.6931, Mean TD Error: 1.0149, Threshold: -149.5015
Original likelihood: -143.76002502441406
Adjusted likelihood: -143.76002502441406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Current yaw: tensor([-0.0049, -0.0096, -0.0492], device='cuda:1')
5 turn
Sampling time 3.664406821015291
tensor([ 0.1511,  0.5448,  0.5882,  0.7488, -0.1077,  0.6726,  0.8159,  0.7736,
         1.3822,  0.2846,  0.1247,  1.0155, -0.0049, -0.0096, -0.0492,  0.9771],
       device='cuda:1')
Original likelihood: -147.4936981201172
Adjusted likelihood: -147.4936981201172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5002)
Solve time for step 1 14.326216075045522
Current ori: tensor([-0.0049, -0.0096, -0.0492], device='cuda:1')
Middle force: tensor([0.5357, 1.2105, 0.6554, 0.5407, 0.5121, 0.6107, 1.6194, 0.7574, 0.8234,
        0.4974, 0.5453, 0.5077], device='cuda:1')
Thumb force: tensor([0.5098, 0.5652, 0.8407, 0.5914, 0.6171, 0.5704, 0.5494, 0.8969, 0.5688,
        0.5858, 0.6729, 0.6741], device='cuda:1')
Index force: tensor([0.5351, 0.5961, 0.5306, 0.5971, 0.7226, 0.5375, 0.5714, 0.5392, 0.5678,
        0.6849, 0.5799, 0.7002], device='cuda:1')
Storing NORMAL transition: reward=0.0432 (scaled=0.0432), steps=1
Reward stats updated: mean 0.0151 -> 0.0152, std: 0.0894
Collected 477 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=0.9609, Q2 Loss=0.9609, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3363
SAC Update 2/5: Actor Loss=-0.0129, Q1 Loss=1.2789, Q2 Loss=1.2789, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1973
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.8877, Q2 Loss=0.8877, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0572
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.9288, Q2 Loss=0.9288, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6909
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.8476, Q2 Loss=0.8476, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3584

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (41.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009148
Q1 loss: 0.980778
Q2 loss: 0.980778
Current threshold: -149.5014
Global Scale Offset: 4350.4162
Reward stats: mean=0.0152, std=0.0894, count=477
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9808, Q2 Loss: 0.9808, Entropy: 0.6931, Mean TD Error: 0.9280, Threshold: -149.5014
tensor([ 0.1310,  0.5705,  0.5273,  0.7421, -0.0181,  0.7309,  0.7685,  0.8883,
         1.4693,  0.3210,  0.0514,  0.8340,  0.0032, -0.0787, -0.0988,  1.7832],
       device='cuda:1')
Original likelihood: -188.48818969726562
Adjusted likelihood: -188.48818969726562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4964)
Solve time for step 2 5.597494425019249
Current ori: tensor([ 0.0032, -0.0787, -0.0988], device='cuda:1')
Middle force: tensor([0.5173, 0.5012, 0.5091, 0.5893, 0.6018, 1.0483, 0.8200, 0.8148, 0.5856,
        0.5551, 0.5195], device='cuda:1')
Thumb force: tensor([1.8987, 1.2969, 0.5815, 1.0490, 0.7687, 1.4669, 0.5575, 0.6966, 0.6683,
        0.5218, 0.5559], device='cuda:1')
Index force: tensor([0.7625, 0.6476, 0.6267, 0.5360, 0.5305, 0.5743, 0.5175, 0.5756, 0.5472,
        0.5746, 0.6198], device='cuda:1')
Storing NORMAL transition: reward=0.0300 (scaled=0.0300), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0893
Collected 478 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7843, Q2 Loss=0.7843, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3609
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=1.1002, Q2 Loss=1.1002, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7319
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=6.6977, Q2 Loss=6.6977, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1470
SAC Update 4/5: Actor Loss=-0.0113, Q1 Loss=1.5994, Q2 Loss=1.5994, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7722
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=1.2778, Q2 Loss=1.2778, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8065

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.1%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (19.4%)
Actor update: 0.09s (41.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009808
Q1 loss: 2.291907
Q2 loss: 2.291907
Current threshold: -149.5013
Global Scale Offset: 4376.5128
Reward stats: mean=0.0152, std=0.0893, count=478
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 2.2919, Q2 Loss: 2.2919, Entropy: 0.6931, Mean TD Error: 2.3637, Threshold: -149.5013
tensor([ 0.0516,  0.3798,  0.6520,  0.7131, -0.2607,  0.6816,  0.7483,  0.9489,
         1.4793,  0.5335, -0.0480,  1.0519,  0.0560, -0.0679, -0.1309,  2.3054],
       device='cuda:1')
Original likelihood: -288.6439514160156
Adjusted likelihood: -288.6439514160156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4873)
Solve time for step 3 5.271107224980369
Current ori: tensor([ 0.0560, -0.0679, -0.1309], device='cuda:1')
Middle force: tensor([0.5014, 0.5121, 0.6004, 0.6481, 1.0167, 0.8369, 0.8340, 0.5892, 0.6057,
        0.5256], device='cuda:1')
Thumb force: tensor([1.2476, 0.5729, 1.0202, 0.7403, 1.4400, 0.5528, 0.6746, 0.6526, 0.5182,
        0.5524], device='cuda:1')
Index force: tensor([0.6361, 0.6011, 0.5302, 0.5181, 0.5757, 0.5124, 0.5634, 0.5443, 0.5345,
        0.5937], device='cuda:1')
Storing NORMAL transition: reward=-0.0199 (scaled=-0.0199), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0892
Collected 479 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=5.2024, Q2 Loss=5.2024, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.5267
SAC Update 2/5: Actor Loss=-0.0102, Q1 Loss=1.0656, Q2 Loss=1.0656, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6687
SAC Update 3/5: Actor Loss=-0.0071, Q1 Loss=0.7182, Q2 Loss=0.7182, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2388
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.4499, Q2 Loss=1.4499, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3013
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.1240, Q2 Loss=1.1240, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7511

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.5%)
Actor update: 0.09s (39.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009141
Q1 loss: 1.912016
Q2 loss: 1.912016
Current threshold: -149.5013
Global Scale Offset: 4401.8411
Reward stats: mean=0.0151, std=0.0892, count=479
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.9120, Q2 Loss: 1.9120, Entropy: 0.6931, Mean TD Error: 1.8973, Threshold: -149.5013
tensor([-0.1831,  0.5201,  0.5841,  0.8185, -0.2041,  0.8524,  0.7999,  0.9022,
         1.5000,  0.5507, -0.1557,  0.8722,  0.1200, -0.0934, -0.1276,  3.1307],
       device='cuda:1')
Original likelihood: -369.2265625
Adjusted likelihood: -369.2265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4801)
Solve time for step 4 5.020476295030676
Current ori: tensor([ 0.1200, -0.0934, -0.1276], device='cuda:1')
Middle force: tensor([0.5422, 0.6939, 0.6472, 1.5318, 0.7621, 0.9171, 0.5475, 0.5474, 0.5061],
       device='cuda:1')
Thumb force: tensor([0.5959, 0.5105, 0.5464, 0.5420, 0.8536, 0.5473, 0.5289, 0.5729, 0.5282],
       device='cuda:1')
Index force: tensor([0.5864, 0.5934, 0.5245, 0.5880, 0.5288, 0.5290, 0.5656, 0.5475, 0.7390],
       device='cuda:1')
Storing NORMAL transition: reward=-0.1146 (scaled=-0.1146), steps=1
Reward stats updated: mean 0.0151 -> 0.0149, std: 0.0893
Collected 480 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=0.9659, Q2 Loss=0.9659, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0710
SAC Update 2/5: Actor Loss=-0.0119, Q1 Loss=1.3292, Q2 Loss=1.3292, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9297
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=0.8642, Q2 Loss=0.8642, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7240
SAC Update 4/5: Actor Loss=-0.0129, Q1 Loss=1.4650, Q2 Loss=1.4650, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9806
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=1.2596, Q2 Loss=1.2596, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3862

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.05s (20.0%)
Actor update: 0.09s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010440
Q1 loss: 1.176760
Q2 loss: 1.176760
Current threshold: -149.5013
Global Scale Offset: 4417.8098
Reward stats: mean=0.0149, std=0.0893, count=480
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.1768, Q2 Loss: 1.1768, Entropy: 0.6931, Mean TD Error: 1.0183, Threshold: -149.5013
tensor([-0.2216,  0.5581,  0.6086,  0.5119, -0.1696,  1.0191,  0.8946,  0.8257,
         1.4595,  0.4314, -0.1362,  0.9244,  0.2999, -0.2327, -0.1276,  4.5741],
       device='cuda:1')
Original likelihood: -700.1441040039062
Adjusted likelihood: -700.1441040039062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4504)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 31
Loaded trajectory sampler
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
1 turn
Sampling time 3.642084528983105
tensor([ 1.2675e-01,  5.6814e-01,  5.7182e-01,  6.6698e-01, -1.1877e-01,
         4.9681e-01,  9.5737e-01,  8.7643e-01,  1.2106e+00,  2.8717e-01,
         2.9948e-01,  1.1458e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Original likelihood: -111.95125579833984
Adjusted likelihood: -111.95125579833984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5034)
Solve time for step 1 14.13790324900765
Current ori: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Middle force: tensor([0.6767, 0.7369, 0.5280, 0.5199, 0.6339, 0.9762, 1.0011, 0.5836, 0.6033,
        0.5465, 0.5510, 0.6418], device='cuda:1')
Thumb force: tensor([0.5685, 2.3888, 0.6246, 1.5262, 1.0382, 0.8978, 1.9725, 0.5971, 0.6097,
        0.6379, 0.5780, 0.6092], device='cuda:1')
Index force: tensor([0.5838, 0.5089, 0.6064, 0.5607, 0.5757, 0.5160, 0.5847, 0.6160, 0.5805,
        0.6386, 0.6164, 0.5923], device='cuda:1')
Storing NORMAL transition: reward=-0.0120 (scaled=-0.0120), steps=1
Reward stats updated: mean 0.0149 -> 0.0148, std: 0.0892
Collected 481 transitions for RL
SAC Update 1/5: Actor Loss=-0.0071, Q1 Loss=0.7037, Q2 Loss=0.7037, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0759
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=0.9270, Q2 Loss=0.9270, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4105
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=1.0996, Q2 Loss=1.0996, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6608
SAC Update 4/5: Actor Loss=-0.0124, Q1 Loss=1.3645, Q2 Loss=1.3645, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8155
SAC Update 5/5: Actor Loss=-0.0122, Q1 Loss=1.2360, Q2 Loss=1.2360, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3320

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.6%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (41.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010218
Q1 loss: 1.066173
Q2 loss: 1.066173
Current threshold: -149.5014
Global Scale Offset: 4432.6898
Reward stats: mean=0.0148, std=0.0892, count=481
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.0662, Q2 Loss: 1.0662, Entropy: 0.6931, Mean TD Error: 0.4589, Threshold: -149.5014
tensor([ 0.1801,  0.6477,  0.5586,  0.5941, -0.2610,  0.6076,  1.0360,  1.0279,
         1.1708,  0.2233,  0.3528,  1.0586, -0.0222, -0.0227, -0.0268,  0.3002],
       device='cuda:1')
Original likelihood: -290.8973388671875
Adjusted likelihood: -290.8973388671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4873)
State is out of distribution
Projection step: 0, Loss: 318.70489501953125
Projection step: 1, Loss: 285.2315673828125
Projection step: 2, Loss: 281.0694885253906
Projection step: 3, Loss: 255.81063842773438
Projection step: 4, Loss: 277.56353759765625
Projection step: 5, Loss: 231.86021423339844
Projection step: 6, Loss: 233.12112426757812
Projection step: 7, Loss: 227.97589111328125
Projection step: 8, Loss: 261.514404296875
Projection step: 9, Loss: 207.23854064941406
Projection step: 10, Loss: 206.42779541015625
Projection step: 11, Loss: 201.84918212890625
Projection step: 12, Loss: 191.8083038330078
Projection step: 13, Loss: 195.65231323242188
Projection step: 14, Loss: 180.24734497070312
Projection step: 15, Loss: 170.2377166748047
Projection step: 16, Loss: 165.02420043945312
Projection step: 17, Loss: 168.0365753173828
Projection step: 18, Loss: 156.20602416992188
Projection step: 19, Loss: 158.99136352539062
Projection step: 20, Loss: 148.7166748046875
Projection step: 21, Loss: 154.16744995117188
Projection step: 22, Loss: 143.1309814453125
Projection step: 23, Loss: 132.6661834716797
Projection step: 24, Loss: 131.86346435546875
Final likelihood: tensor([-143.0485, -111.0283, -128.3325, -132.4778, -147.1757, -138.9975,
        -152.3148, -116.6812, -118.7443, -120.4070, -156.3611, -107.7760,
        -150.0865, -136.4669, -124.0923, -109.1890])
Final projection likelihood: -130.8237
1 mode projection succeeded
New goal: tensor([ 0.1334,  0.5846,  0.5549,  0.6283, -0.0996,  0.6272,  0.9519,  0.8844,
         1.3295,  0.2971,  0.2110,  1.0104, -0.0206, -0.0083,  0.7535],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0060]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -147.5225830078125
Adjusted likelihood: -147.5225830078125
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 147.5225830078125}
Current yaw: tensor([-0.0222, -0.0227, -0.0268], device='cuda:1')
2 thumb_middle
tensor([ 0.1801,  0.6477,  0.5586,  0.5941, -0.2610,  0.6076,  1.0360,  1.0279,
         1.1708,  0.2233,  0.3528,  1.0586, -0.0222, -0.0227, -0.0268,  0.3002],
       device='cuda:1')
Solve time for step 1 9.066877498000395
Current ori: tensor([-0.0222, -0.0227, -0.0268], device='cuda:1')
Index force: tensor([0.5959, 0.5865, 0.6069, 0.5992], device='cuda:1')
tensor([ 0.1577,  0.6346,  0.5464,  0.6029, -0.2464,  0.5696,  0.9150,  0.8802,
         1.2589,  0.2688,  0.1443,  0.9749, -0.0195, -0.0082, -0.0269,  0.2744],
       device='cuda:1')
Solve time for step 2 3.6711170459748246
Current ori: tensor([-0.0195, -0.0082, -0.0269], device='cuda:1')
Index force: tensor([0.5772, 0.5994, 0.5927], device='cuda:1')
tensor([ 0.1501,  0.6292,  0.5449,  0.6042, -0.2446,  0.5735,  0.8975,  0.8594,
         1.2827,  0.2761,  0.1210,  0.9701, -0.0184, -0.0033, -0.0269,  0.2652],
       device='cuda:1')
Solve time for step 3 3.514130658004433
Current ori: tensor([-0.0184, -0.0033, -0.0269], device='cuda:1')
Index force: tensor([0.5916, 0.5878], device='cuda:1')
tensor([ 0.1478,  0.6218,  0.5462,  0.6165, -0.2465,  0.5750,  0.8932,  0.8545,
         1.2899,  0.2787,  0.1161,  0.9692, -0.0159, -0.0014, -0.0269,  0.2670],
       device='cuda:1')
Solve time for step 4 3.341837421001401
Current ori: tensor([-0.0159, -0.0014, -0.0269], device='cuda:1')
Index force: tensor([0.5704], device='cuda:1')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0056), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0892
Collected 482 transitions for RL
SAC Update 1/5: Actor Loss=-0.0136, Q1 Loss=2.5254, Q2 Loss=2.5254, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4483
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=1.2781, Q2 Loss=1.2781, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9241
SAC Update 3/5: Actor Loss=-0.0111, Q1 Loss=1.1200, Q2 Loss=1.1200, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2281
SAC Update 4/5: Actor Loss=-0.0131, Q1 Loss=1.3104, Q2 Loss=1.3104, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1358
SAC Update 5/5: Actor Loss=-0.0107, Q1 Loss=1.1766, Q2 Loss=1.1766, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9499

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (20.1%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (37.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011518
Q1 loss: 1.482083
Q2 loss: 1.482083
Current threshold: -149.5014
Global Scale Offset: 4448.3477
Reward stats: mean=0.0148, std=0.0892, count=482
----------------------------------------------
SAC Update - Actor Loss: -0.0115, Q1 Loss: 1.4821, Q2 Loss: 1.4821, Entropy: 0.6931, Mean TD Error: 1.1372, Threshold: -149.5014
Original likelihood: -156.64004516601562
Adjusted likelihood: -156.64004516601562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4994)
State is out of distribution
Projection step: 0, Loss: 148.44436645507812
Projection step: 1, Loss: 151.7401123046875
Projection step: 2, Loss: 140.81118774414062
Projection step: 3, Loss: 133.32534790039062
Projection step: 4, Loss: 121.87773132324219
Projection step: 5, Loss: 129.85879516601562
Projection step: 6, Loss: 125.37466430664062
Projection step: 7, Loss: 110.66981506347656
Projection step: 8, Loss: 111.49131774902344
Projection step: 9, Loss: 105.88351440429688
Projection step: 10, Loss: 102.0558090209961
Final likelihood: tensor([-112.5217, -101.9098, -108.8879, -129.1510,  -76.9057, -103.1145,
        -116.2280,  -99.4287,  -96.8864,  -84.0447,  -74.2454, -101.3706,
        -124.6413, -116.1598, -114.8192,  -72.5782])
Final projection likelihood: -102.0558
1 mode projection succeeded
New goal: tensor([ 0.1188,  0.5597,  0.5624,  0.6494, -0.1183,  0.6136,  0.9414,  0.8259,
         1.3527,  0.3141,  0.2032,  1.0804, -0.0038,  0.0140,  0.1690],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -127.85585021972656
Adjusted likelihood: -127.85585021972656
Likelihood residual: 0.0
Original likelihood: -144.2504425048828
Adjusted likelihood: -144.2504425048828
Likelihood residual: 0.0
{'index': 144.2504425048828, 'thumb_middle': 127.85585021972656}
Current yaw: tensor([-0.0064,  0.0113, -0.0205], device='cuda:1')
3 thumb_middle
tensor([ 0.1292,  0.5872,  0.5600,  0.6440, -0.1943,  0.6129,  0.9279,  0.8726,
         1.3541,  0.2969,  0.1826,  1.0077, -0.0064,  0.0113, -0.0205,  0.2529],
       device='cuda:1')
Solve time for step 1 8.781307478959206
Current ori: tensor([-0.0064,  0.0113, -0.0205], device='cuda:1')
Index force: tensor([0.5862, 0.5997, 0.5965, 0.5919], device='cuda:1')
tensor([ 0.1007,  0.5814,  0.5467,  0.6289, -0.2542,  0.5690,  0.8840,  0.8021,
         1.3077,  0.2925,  0.1120,  1.0274, -0.0062,  0.0279, -0.0204,  0.2028],
       device='cuda:1')
Solve time for step 2 3.5161233550170437
Current ori: tensor([-0.0062,  0.0279, -0.0204], device='cuda:1')
Index force: tensor([0.5886, 0.5871, 0.5830], device='cuda:1')
tensor([ 0.1129,  0.5820,  0.5540,  0.6367, -0.2523,  0.5720,  0.8884,  0.7943,
         1.3038,  0.2936,  0.1012,  1.0314, -0.0059,  0.0210, -0.0204,  0.2222],
       device='cuda:1')
Solve time for step 3 3.421942397020757
Current ori: tensor([-0.0059,  0.0210, -0.0204], device='cuda:1')
Index force: tensor([0.5752, 0.5729], device='cuda:1')
tensor([ 0.1165,  0.5730,  0.5619,  0.6526, -0.2523,  0.5731,  0.8872,  0.7962,
         1.3035,  0.2929,  0.1006,  1.0325, -0.0026,  0.0195, -0.0204,  0.2321],
       device='cuda:1')
Solve time for step 4 3.333149605023209
Current ori: tensor([-0.0026,  0.0195, -0.0204], device='cuda:1')
Index force: tensor([0.5830], device='cuda:1')
Storing RECOVERY transition: reward=0.0035 (scaled=0.0035), steps=1
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0891
Collected 483 transitions for RL
SAC Update 1/5: Actor Loss=-0.0120, Q1 Loss=1.4779, Q2 Loss=1.4779, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2925
SAC Update 2/5: Actor Loss=-0.0122, Q1 Loss=1.4147, Q2 Loss=1.4147, Entropy=0.6927, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0184
SAC Update 3/5: Actor Loss=-0.0079, Q1 Loss=0.8418, Q2 Loss=0.8418, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4917
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=2.9804, Q2 Loss=2.9804, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2242
SAC Update 5/5: Actor Loss=-0.0103, Q1 Loss=1.0928, Q2 Loss=1.0928, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6976

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (17.9%)
Actor update: 0.10s (39.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010891
Q1 loss: 1.561509
Q2 loss: 1.561509
Current threshold: -149.5013
Global Scale Offset: 4462.5995
Reward stats: mean=0.0147, std=0.0891, count=483
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.5615, Q2 Loss: 1.5615, Entropy: 0.6930, Mean TD Error: 1.3449, Threshold: -149.5013
Original likelihood: -144.10699462890625
Adjusted likelihood: -144.10699462890625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Current yaw: tensor([-0.0008,  0.0130, -0.0296], device='cuda:1')
4 turn
Sampling time 3.5809263140545227
tensor([ 1.2799e-01,  5.6907e-01,  5.7438e-01,  6.6185e-01, -1.8652e-01,
         6.1622e-01,  9.2655e-01,  8.1649e-01,  1.3558e+00,  3.0800e-01,
         1.5230e-01,  1.0657e+00, -7.7419e-04,  1.2966e-02, -2.9573e-02,
         2.5765e-01], device='cuda:1')
Original likelihood: -143.2144775390625
Adjusted likelihood: -143.2144775390625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5006)
Solve time for step 1 14.411502745992038
Current ori: tensor([-0.0008,  0.0130, -0.0296], device='cuda:1')
Middle force: tensor([2.5378, 1.9222, 1.1288, 0.5084, 0.5167, 0.5156, 0.8757, 0.9605, 0.6187,
        0.5851, 0.5149, 0.5283], device='cuda:1')
Thumb force: tensor([0.9549, 2.5366, 0.8131, 0.5539, 2.4031, 0.6004, 0.5812, 0.5882, 1.0833,
        1.2448, 0.6660, 0.6208], device='cuda:1')
Index force: tensor([1.3898, 0.5291, 1.0767, 0.6357, 0.7229, 0.5257, 0.5310, 0.6139, 0.5615,
        0.5362, 0.6799, 0.6584], device='cuda:1')
Storing NORMAL transition: reward=-0.0590 (scaled=-0.0590), steps=1
Reward stats updated: mean 0.0147 -> 0.0146, std: 0.0890
Collected 484 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=7.8737, Q2 Loss=7.8737, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.3003
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=1.6100, Q2 Loss=1.6100, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9095
SAC Update 3/5: Actor Loss=-0.0120, Q1 Loss=1.6281, Q2 Loss=1.6281, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5840
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=0.9150, Q2 Loss=0.9150, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3972
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.8123, Q2 Loss=0.8123, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9806

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009903
Q1 loss: 2.567821
Q2 loss: 2.567821
Current threshold: -149.5010
Global Scale Offset: 4477.5349
Reward stats: mean=0.0146, std=0.0890, count=484
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 2.5678, Q2 Loss: 2.5678, Entropy: 0.6931, Mean TD Error: 2.4343, Threshold: -149.5010
tensor([ 0.1039,  0.5800,  0.5628,  0.6093, -0.1833,  0.6423,  0.8989,  0.7719,
         1.3554,  0.3073,  0.1551,  1.0602, -0.0093,  0.0157,  0.0293,  0.2747],
       device='cuda:1')
Original likelihood: -142.4162139892578
Adjusted likelihood: -142.4162139892578
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 148.76168823242188
Projection step: 1, Loss: 138.40933227539062
Projection step: 2, Loss: 133.82455444335938
Projection step: 3, Loss: 136.2655487060547
Projection step: 4, Loss: 132.26991271972656
Projection step: 5, Loss: 127.39088439941406
Projection step: 6, Loss: 116.59012603759766
Projection step: 7, Loss: 111.71957397460938
Projection step: 8, Loss: 105.94314575195312
Projection step: 9, Loss: 110.72267150878906
Projection step: 10, Loss: 102.46654510498047
Final likelihood: tensor([-104.0880, -150.9979, -121.8524,  -89.3407,  -92.0999,  -83.8172,
         -93.3651,  -91.1919, -110.3750,  -94.6649, -102.8839,  -97.8029,
         -81.7217, -110.5149, -110.1139, -104.6344])
Final projection likelihood: -102.4665
1 mode projection succeeded
New goal: tensor([ 0.1032,  0.5620,  0.5737,  0.6234, -0.1173,  0.6326,  0.9017,  0.7614,
         1.3397,  0.2964,  0.1961,  1.1350, -0.0075,  0.0165,  0.2285],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -103.81190490722656
Adjusted likelihood: -103.81190490722656
Likelihood residual: 0.0
Original likelihood: -143.2374267578125
Adjusted likelihood: -143.2374267578125
Likelihood residual: 0.0
{'index': 143.2374267578125, 'thumb_middle': 103.81190490722656}
Current yaw: tensor([-0.0093,  0.0157,  0.0293], device='cuda:1')
5 thumb_middle
tensor([ 0.1039,  0.5800,  0.5628,  0.6093, -0.1833,  0.6423,  0.8989,  0.7719,
         1.3554,  0.3073,  0.1551,  1.0602, -0.0093,  0.0157,  0.0293,  0.2747],
       device='cuda:1')
Solve time for step 1 9.13651771802688
Current ori: tensor([-0.0093,  0.0157,  0.0293], device='cuda:1')
Index force: tensor([0.5533, 0.5670, 0.5832, 0.5559], device='cuda:1')
tensor([ 0.1028,  0.5738,  0.5673,  0.6132, -0.2336,  0.5950,  0.8604,  0.7308,
         1.2892,  0.2795,  0.0952,  1.0916, -0.0076,  0.0173,  0.0294,  0.2660],
       device='cuda:1')
Solve time for step 2 3.5970959619735368
Current ori: tensor([-0.0076,  0.0173,  0.0294], device='cuda:1')
Index force: tensor([0.5581, 0.5734, 0.5480], device='cuda:1')
tensor([ 0.0961,  0.5752,  0.5610,  0.6099, -0.2391,  0.6002,  0.8589,  0.7377,
         1.2927,  0.2784,  0.0892,  1.0884, -0.0082,  0.0210,  0.0294,  0.2553],
       device='cuda:1')
Solve time for step 3 3.543876455980353
Current ori: tensor([-0.0082,  0.0210,  0.0294], device='cuda:1')
Index force: tensor([0.5604, 0.5389], device='cuda:1')
tensor([ 0.1017,  0.5603,  0.5749,  0.6336, -0.2290,  0.5971,  0.8552,  0.7185,
         1.2867,  0.2720,  0.0964,  1.0884, -0.0029,  0.0186,  0.0294,  0.2739],
       device='cuda:1')
Solve time for step 4 3.352854294993449
Current ori: tensor([-0.0029,  0.0186,  0.0294], device='cuda:1')
Index force: tensor([0.5750], device='cuda:1')
Storing RECOVERY transition: reward=0.0098 (scaled=0.0098), steps=1
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0889
Collected 485 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.8518, Q2 Loss=0.8518, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3620
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8697, Q2 Loss=0.8697, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4320
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.0622, Q2 Loss=1.0622, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1734
SAC Update 4/5: Actor Loss=-0.0091, Q1 Loss=1.4673, Q2 Loss=1.4673, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3298
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=1.5014, Q2 Loss=1.5014, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5079

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008628
Q1 loss: 1.150484
Q2 loss: 1.150484
Current threshold: -149.5009
Global Scale Offset: 4489.3555
Reward stats: mean=0.0146, std=0.0889, count=485
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1505, Q2 Loss: 1.1505, Entropy: 0.6931, Mean TD Error: 1.7610, Threshold: -149.5009
Original likelihood: -134.35845947265625
Adjusted likelihood: -134.35845947265625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5013)
Current yaw: tensor([-0.0009,  0.0138,  0.0196], device='cuda:1')
6 turn
Sampling time 3.7378258630051278
tensor([ 1.1009e-01,  5.5556e-01,  5.8590e-01,  6.4115e-01, -1.7779e-01,
         6.4413e-01,  8.9730e-01,  7.5160e-01,  1.3458e+00,  2.8708e-01,
         1.4740e-01,  1.1185e+00, -9.4669e-04,  1.3766e-02,  1.9648e-02,
         2.8948e-01], device='cuda:1')
Original likelihood: -126.821044921875
Adjusted likelihood: -126.821044921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 130.73214721679688
Projection step: 1, Loss: 118.47196960449219
Projection step: 2, Loss: 124.78421020507812
Projection step: 3, Loss: 120.00806427001953
Projection step: 4, Loss: 114.48191833496094
Projection step: 5, Loss: 114.40274047851562
Projection step: 6, Loss: 105.89515686035156
Projection step: 7, Loss: 100.61775207519531
Final likelihood: tensor([ -72.3899, -108.4362, -103.7773, -139.0278, -106.9658,  -88.8203,
         -92.6145, -102.8560,  -91.4397, -111.5128, -107.2611,  -95.1148,
        -100.7194,  -90.9674, -104.7043,  -93.2770])
Final projection likelihood: -100.6178
1 mode projection succeeded
New goal: tensor([ 1.0724e-01,  5.5061e-01,  5.8139e-01,  6.4440e-01, -1.2697e-01,
         6.4576e-01,  8.9797e-01,  7.5985e-01,  1.3310e+00,  2.7736e-01,
         1.8490e-01,  1.1540e+00,  6.8611e-04,  1.4714e-02,  1.4452e-01],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -112.57450866699219
Adjusted likelihood: -112.57450866699219
Likelihood residual: 0.0
Original likelihood: -141.7266845703125
Adjusted likelihood: -141.7266845703125
Likelihood residual: 0.0
{'index': 141.7266845703125, 'thumb_middle': 112.57450866699219}
Current yaw: tensor([-0.0009,  0.0138,  0.0196], device='cuda:1')
7 thumb_middle
tensor([ 1.1009e-01,  5.5556e-01,  5.8590e-01,  6.4115e-01, -1.7779e-01,
         6.4413e-01,  8.9730e-01,  7.5160e-01,  1.3458e+00,  2.8708e-01,
         1.4740e-01,  1.1185e+00, -9.4669e-04,  1.3766e-02,  1.9648e-02,
         2.8948e-01], device='cuda:1')
Solve time for step 1 8.989019935950637
Current ori: tensor([-0.0009,  0.0138,  0.0196], device='cuda:1')
Index force: tensor([0.5874, 0.5879, 0.5732, 0.5906], device='cuda:1')
tensor([ 0.1086,  0.5566,  0.5846,  0.6368, -0.2405,  0.6108,  0.8544,  0.7354,
         1.2890,  0.2567,  0.0925,  1.1122, -0.0018,  0.0149,  0.0197,  0.2941],
       device='cuda:1')
Solve time for step 2 3.599320825014729
Current ori: tensor([-0.0018,  0.0149,  0.0197], device='cuda:1')
Index force: tensor([0.5782, 0.5657, 0.5821], device='cuda:1')
tensor([ 0.1053,  0.5653,  0.5765,  0.6240, -0.2417,  0.6155,  0.8526,  0.7328,
         1.2865,  0.2551,  0.0887,  1.1089, -0.0048,  0.0162,  0.0197,  0.2847],
       device='cuda:1')
Solve time for step 3 3.627431405999232
Current ori: tensor([-0.0048,  0.0162,  0.0197], device='cuda:1')
Index force: tensor([0.5568, 0.5729], device='cuda:1')
tensor([ 0.1029,  0.5473,  0.5848,  0.6512, -0.2427,  0.6145,  0.8542,  0.7287,
         1.2910,  0.2558,  0.0880,  1.1099,  0.0015,  0.0185,  0.0197,  0.2901],
       device='cuda:1')
Solve time for step 4 3.5913353500072844
Current ori: tensor([0.0015, 0.0185, 0.0197], device='cuda:1')
Index force: tensor([0.5633], device='cuda:1')
Storing RECOVERY transition: reward=-0.0026 (scaled=-0.0026), steps=0
Reward stats updated: mean 0.0146 -> 0.0145, std: 0.0889
Collected 486 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7667, Q2 Loss=0.7667, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2500
SAC Update 2/5: Actor Loss=-0.0134, Q1 Loss=2.5247, Q2 Loss=2.5247, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4857
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=0.9545, Q2 Loss=0.9545, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6743
SAC Update 4/5: Actor Loss=-0.0107, Q1 Loss=1.1137, Q2 Loss=1.1137, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4933
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8104, Q2 Loss=0.8104, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3252

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.2%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (19.6%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009658
Q1 loss: 1.234000
Q2 loss: 1.234000
Current threshold: -149.5008
Global Scale Offset: 4502.6906
Reward stats: mean=0.0145, std=0.0889, count=486
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.2340, Q2 Loss: 1.2340, Entropy: 0.6931, Mean TD Error: 0.8457, Threshold: -149.5008
Original likelihood: -136.0302734375
Adjusted likelihood: -136.0302734375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5012)
State is out of distribution
Projection step: 0, Loss: 135.82635498046875
Projection step: 1, Loss: 145.81640625
Projection step: 2, Loss: 129.61740112304688
Projection step: 3, Loss: 129.61868286132812
Projection step: 4, Loss: 125.68763732910156
Projection step: 5, Loss: 115.31048583984375
Projection step: 6, Loss: 110.76638793945312
Projection step: 7, Loss: 111.53919982910156
Projection step: 8, Loss: 101.14082336425781
Final likelihood: tensor([ -82.9212,  -97.7629,  -96.1508,  -94.0941,  -96.6088,  -75.5906,
         -92.5982, -100.8795,  -99.6434,  -95.2113,  -96.4788, -129.1458,
        -101.0186, -137.0034, -131.2283,  -91.9177])
Final projection likelihood: -101.1408
1 mode projection succeeded
New goal: tensor([ 0.0936,  0.5428,  0.5845,  0.6395, -0.1356,  0.6519,  0.8779,  0.7574,
         1.3260,  0.2571,  0.1817,  1.1946,  0.0029,  0.0186,  0.0959],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -118.59507751464844
Adjusted likelihood: -118.59507751464844
Likelihood residual: 0.0
Original likelihood: -128.67127990722656
Adjusted likelihood: -128.67127990722656
Likelihood residual: 0.0
{'index': 128.67127990722656, 'thumb_middle': 118.59507751464844}
Current yaw: tensor([0.0029, 0.0233, 0.0219], device='cuda:1')
8 thumb_middle
tensor([ 0.0941,  0.5435,  0.5817,  0.6510, -0.1910,  0.6536,  0.8845,  0.7446,
         1.3525,  0.2722,  0.1507,  1.1489,  0.0029,  0.0233,  0.0219,  0.2754],
       device='cuda:1')
Solve time for step 1 9.252737344999332
Current ori: tensor([0.0029, 0.0233, 0.0219], device='cuda:1')
Index force: tensor([0.5517, 0.5954, 0.5351, 0.6045], device='cuda:1')
tensor([ 0.0861,  0.5523,  0.5729,  0.6288, -0.2449,  0.6243,  0.8366,  0.7293,
         1.2868,  0.2364,  0.0980,  1.1529, -0.0014,  0.0276,  0.0220,  0.2588],
       device='cuda:1')
Solve time for step 2 3.682003400987014
Current ori: tensor([-0.0014,  0.0276,  0.0220], device='cuda:1')
Index force: tensor([0.5896, 0.5335, 0.6008], device='cuda:1')
tensor([ 0.0828,  0.5591,  0.5665,  0.6169, -0.2477,  0.6285,  0.8347,  0.7292,
         1.2897,  0.2346,  0.0908,  1.1549, -0.0040,  0.0291,  0.0220,  0.2508],
       device='cuda:1')
Solve time for step 3 3.681719641026575
Current ori: tensor([-0.0040,  0.0291,  0.0220], device='cuda:1')
Index force: tensor([0.5316, 0.5970], device='cuda:1')
tensor([ 8.6191e-02,  5.4962e-01,  5.7618e-01,  6.2983e-01, -2.4748e-01,
         6.2942e-01,  8.3433e-01,  7.2904e-01,  1.2893e+00,  2.3343e-01,
         8.9605e-02,  1.1566e+00, -7.3576e-04,  2.7625e-02,  2.1953e-02,
         2.5946e-01], device='cuda:1')
Solve time for step 4 3.389954067999497
Current ori: tensor([-0.0007,  0.0276,  0.0220], device='cuda:1')
Index force: tensor([0.5797], device='cuda:1')
Storing RECOVERY transition: reward=0.0006 (scaled=0.0006), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0888
Collected 487 transitions for RL
SAC Update 1/5: Actor Loss=-0.0104, Q1 Loss=1.5753, Q2 Loss=1.5753, Entropy=0.6927, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8850
SAC Update 2/5: Actor Loss=-0.0105, Q1 Loss=1.0789, Q2 Loss=1.0789, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4553
SAC Update 3/5: Actor Loss=-0.0098, Q1 Loss=1.3341, Q2 Loss=1.3341, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6807
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7251, Q2 Loss=0.7251, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1558
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.1895, Q2 Loss=1.1895, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4820

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.5%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (41.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009842
Q1 loss: 1.180574
Q2 loss: 1.180574
Current threshold: -149.5007
Global Scale Offset: 4527.8465
Reward stats: mean=0.0145, std=0.0888, count=487
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.1806, Q2 Loss: 1.1806, Entropy: 0.6930, Mean TD Error: 0.9318, Threshold: -149.5007
Original likelihood: -126.74687194824219
Adjusted likelihood: -126.74687194824219
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5020)
Current yaw: tensor([0.0017, 0.0253, 0.0187], device='cuda:1')
9 turn
Sampling time 3.7661123580182903
tensor([ 0.0904,  0.5442,  0.5821,  0.6410, -0.1933,  0.6641,  0.8676,  0.7491,
         1.3518,  0.2575,  0.1448,  1.1853,  0.0017,  0.0253,  0.0187,  0.2759],
       device='cuda:1')
Original likelihood: -137.00634765625
Adjusted likelihood: -137.00634765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5011)
Solve time for step 1 13.94729785900563
Current ori: tensor([0.0017, 0.0253, 0.0187], device='cuda:1')
Middle force: tensor([0.6866, 0.7510, 0.5557, 1.5386, 0.5862, 0.4823, 0.7198, 0.4908, 0.5418,
        0.5849, 0.5853, 0.5963], device='cuda:1')
Thumb force: tensor([1.5353, 0.7521, 2.1895, 1.0575, 1.9756, 0.5037, 0.9082, 0.5611, 0.5777,
        0.6131, 0.7224, 0.6089], device='cuda:1')
Index force: tensor([0.9337, 0.7544, 0.5547, 0.8888, 0.6723, 0.7335, 0.5448, 0.7219, 0.5723,
        0.6095, 0.5673, 0.5553], device='cuda:1')
Storing NORMAL transition: reward=0.1708 (scaled=0.1708), steps=1
Reward stats updated: mean 0.0145 -> 0.0148, std: 0.0890
Collected 488 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=1.0817, Q2 Loss=1.0817, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6100
SAC Update 2/5: Actor Loss=-0.0079, Q1 Loss=0.9124, Q2 Loss=0.9124, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3818
SAC Update 3/5: Actor Loss=-0.0101, Q1 Loss=1.2154, Q2 Loss=1.2154, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2682
SAC Update 4/5: Actor Loss=-0.0089, Q1 Loss=0.9460, Q2 Loss=0.9460, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6607
SAC Update 5/5: Actor Loss=-0.0122, Q1 Loss=1.2540, Q2 Loss=1.2540, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2739

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.6%)
Actor update: 0.08s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009887
Q1 loss: 1.081875
Q2 loss: 1.081875
Current threshold: -149.5005
Global Scale Offset: 4556.9500
Reward stats: mean=0.0148, std=0.0890, count=488
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.0819, Q2 Loss: 1.0819, Entropy: 0.6931, Mean TD Error: 0.8389, Threshold: -149.5005
tensor([ 0.1253,  0.6559,  0.4846,  0.5991, -0.1600,  0.6402,  0.8905,  0.8166,
         1.3899,  0.2696,  0.1760,  0.9125, -0.0268,  0.0020, -0.1525,  0.4780],
       device='cuda:1')
Original likelihood: -163.44625854492188
Adjusted likelihood: -163.44625854492188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4988)
Solve time for step 2 5.3312823079759255
Current ori: tensor([-0.0268,  0.0020, -0.1525], device='cuda:1')
Middle force: tensor([0.5025, 0.5035, 0.5023, 0.5626, 0.5586, 0.9591, 0.7689, 0.7407, 0.5596,
        0.5696, 0.5486], device='cuda:1')
Thumb force: tensor([1.6717, 1.2393, 0.5616, 1.0133, 0.7514, 1.3089, 0.5536, 0.6948, 0.6502,
        0.5587, 0.5454], device='cuda:1')
Index force: tensor([0.7440, 0.8438, 0.6021, 0.5325, 0.5238, 0.5485, 0.5125, 0.5545, 0.5452,
        0.5033, 0.5963], device='cuda:1')
Storing NORMAL transition: reward=0.0029 (scaled=0.0029), steps=1
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0889
Collected 489 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=0.7575, Q2 Loss=0.7575, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5651
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.7980, Q2 Loss=0.7980, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0892
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.9452, Q2 Loss=0.9452, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6287
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.7913, Q2 Loss=0.7913, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3342
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=1.0055, Q2 Loss=1.0055, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1915

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008115
Q1 loss: 0.859474
Q2 loss: 0.859474
Current threshold: -149.5003
Global Scale Offset: 4583.0050
Reward stats: mean=0.0148, std=0.0889, count=489
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 0.8595, Q2 Loss: 0.8595, Entropy: 0.6931, Mean TD Error: 0.5617, Threshold: -149.5003
tensor([ 0.1031,  0.5899,  0.5825,  0.5454, -0.2085,  0.7260,  0.7377,  0.8787,
         1.3425,  0.3438,  0.2673,  0.8473, -0.0168,  0.0165, -0.1552,  0.4497],
       device='cuda:1')
Original likelihood: -198.2114715576172
Adjusted likelihood: -198.2114715576172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4958)
State is out of distribution
Projection step: 0, Loss: 203.51348876953125
Projection step: 1, Loss: 193.52635192871094
Projection step: 2, Loss: 182.9588165283203
Projection step: 3, Loss: 181.3958740234375
Projection step: 4, Loss: 183.639892578125
Projection step: 5, Loss: 173.79298400878906
Projection step: 6, Loss: 163.69581604003906
Projection step: 7, Loss: 158.26666259765625
Projection step: 8, Loss: 154.03836059570312
Projection step: 9, Loss: 136.35287475585938
Projection step: 10, Loss: 134.57461547851562
Projection step: 11, Loss: 131.60791015625
Projection step: 12, Loss: 133.5146484375
Projection step: 13, Loss: 118.64641571044922
Projection step: 14, Loss: 116.0938491821289
Projection step: 15, Loss: 115.20658874511719
Projection step: 16, Loss: 113.60200500488281
Projection step: 17, Loss: 109.11460876464844
Projection step: 18, Loss: 104.7983627319336
Final likelihood: tensor([ -97.7162, -118.2176,  -94.0943, -119.2789, -112.5746, -107.6136,
         -91.7573, -115.8550,  -98.0457, -124.8204,  -89.4380, -101.8625,
        -115.7217,  -98.7313,  -98.8298,  -92.2168])
Final projection likelihood: -104.7984
1 mode projection succeeded
New goal: tensor([ 0.0993,  0.5717,  0.5630,  0.6040, -0.1096,  0.6479,  0.8609,  0.7505,
         1.3516,  0.2802,  0.2296,  1.1262, -0.0170,  0.0162,  1.3018],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0045]], device='cuda:1') tensor([[0.0025]], device='cuda:1')
Original likelihood: -135.0536346435547
Adjusted likelihood: -135.0536346435547
Likelihood residual: 0.0
Original likelihood: -166.45596313476562
Adjusted likelihood: -166.45596313476562
Likelihood residual: 0.0
{'index': 166.45596313476562, 'thumb_middle': 135.0536346435547}
Current yaw: tensor([-0.0168,  0.0165, -0.1552], device='cuda:1')
10 thumb_middle
tensor([ 0.1031,  0.5899,  0.5825,  0.5454, -0.2085,  0.7260,  0.7377,  0.8787,
         1.3425,  0.3438,  0.2673,  0.8473, -0.0168,  0.0165, -0.1552,  0.4497],
       device='cuda:1')
Solve time for step 1 9.200042010983452
Current ori: tensor([-0.0168,  0.0165, -0.1552], device='cuda:1')
Index force: tensor([0.5379, 0.5731, 0.5928, 0.5857], device='cuda:1')
tensor([ 0.0986,  0.5945,  0.5525,  0.5783, -0.2386,  0.6462,  0.7979,  0.7415,
         1.2776,  0.2709,  0.1442,  1.0337, -0.0153,  0.0199, -0.1551,  0.4508],
       device='cuda:1')
Solve time for step 2 3.8198932060040534
Current ori: tensor([-0.0153,  0.0199, -0.1551], device='cuda:1')
Index force: tensor([0.5648, 0.5855, 0.5793], device='cuda:1')
tensor([ 0.0982,  0.5982,  0.5428,  0.5874, -0.2312,  0.6283,  0.8202,  0.7194,
         1.2789,  0.2434,  0.1262,  1.0679, -0.0154,  0.0200, -0.1551,  0.4523],
       device='cuda:1')
Solve time for step 3 3.4957879459834658
Current ori: tensor([-0.0154,  0.0200, -0.1551], device='cuda:1')
Index force: tensor([0.5769, 0.5733], device='cuda:1')
tensor([ 0.0922,  0.5741,  0.5586,  0.6100, -0.2311,  0.6227,  0.8164,  0.7265,
         1.2889,  0.2402,  0.1175,  1.0798, -0.0082,  0.0245, -0.1551,  0.4531],
       device='cuda:1')
Solve time for step 4 3.4151173239806667
Current ori: tensor([-0.0082,  0.0245, -0.1551], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-0.0044 (scaled=-0.0022), steps=2
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0888
Collected 490 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=1.0633, Q2 Loss=1.0633, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0188
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.7044, Q2 Loss=1.7044, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5733
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=3.0605, Q2 Loss=3.0605, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9469
SAC Update 4/5: Actor Loss=-0.0117, Q1 Loss=1.6046, Q2 Loss=1.6046, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6011
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7381, Q2 Loss=0.7381, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3070

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.6%)
Actor update: 0.10s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009423
Q1 loss: 1.634183
Q2 loss: 1.634183
Current threshold: -149.5000
Global Scale Offset: 4610.6686
Reward stats: mean=0.0148, std=0.0888, count=490
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.6342, Q2 Loss: 1.6342, Entropy: 0.6931, Mean TD Error: 2.4894, Threshold: -149.5000
Original likelihood: -133.95712280273438
Adjusted likelihood: -133.95712280273438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5013)
State is out of distribution
Projection step: 0, Loss: 134.2210693359375
Projection step: 1, Loss: 128.0959014892578
Projection step: 2, Loss: 120.52046203613281
Projection step: 3, Loss: 126.34622192382812
Projection step: 4, Loss: 122.42807006835938
Projection step: 5, Loss: 123.49198150634766
Projection step: 6, Loss: 123.42391967773438
Projection step: 7, Loss: 113.25607299804688
Projection step: 8, Loss: 111.197509765625
Projection step: 9, Loss: 101.86827850341797
Final likelihood: tensor([ -91.8622,  -91.6239,  -99.1643, -108.9187, -116.1397,  -97.0075,
         -94.0996, -128.5460,  -98.0538,  -78.4350,  -82.6479,  -97.8489,
         -93.6463, -128.1794, -128.9823,  -94.7371])
Final projection likelihood: -101.8683
1 mode projection succeeded
New goal: tensor([ 0.0975,  0.5699,  0.5672,  0.6030, -0.1195,  0.6459,  0.8559,  0.7377,
         1.3230,  0.2526,  0.1963,  1.1772, -0.0091,  0.0197, -0.2295],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -228.32998657226562
Adjusted likelihood: -228.32998657226562
Likelihood residual: 0.0
Original likelihood: -129.81448364257812
Adjusted likelihood: -129.81448364257812
Likelihood residual: 0.0
{'index': 129.81448364257812, 'thumb_middle': 228.32998657226562}
Current yaw: tensor([-0.0095,  0.0226, -0.1509], device='cuda:1')
11 index
tensor([ 0.0925,  0.5793,  0.5573,  0.5982, -0.1683,  0.6646,  0.8407,  0.7309,
         1.3453,  0.2627,  0.1785,  1.1046, -0.0095,  0.0226, -0.1509,  0.4623],
       device='cuda:1')
Solve time for step 1 10.68508570099948
Current ori: tensor([-0.0095,  0.0226, -0.1509], device='cuda:1')
Middle force: tensor([0.5439, 0.5569, 0.5314, 0.5432], device='cuda:1')
Thumb force: tensor([0.5698, 0.5797, 0.6074, 0.6286], device='cuda:1')
tensor([ 0.1433,  0.5182,  0.5178,  0.5794, -0.1616,  0.6489,  0.8640,  0.7490,
         1.3453,  0.2620,  0.1531,  1.1385, -0.0047,  0.0154, -0.1740,  0.1057],
       device='cuda:1')
Solve time for step 2 4.218568941985723
Current ori: tensor([-0.0047,  0.0154, -0.1740], device='cuda:1')
Middle force: tensor([0.5525, 0.5297, 0.5397], device='cuda:1')
Thumb force: tensor([0.5756, 0.6039, 0.6265], device='cuda:1')
tensor([ 0.1478,  0.5187,  0.5189,  0.5788, -0.1582,  0.6508,  0.8646,  0.7484,
         1.3481,  0.2547,  0.1451,  1.1467, -0.0044,  0.0128, -0.1707, -0.0769],
       device='cuda:1')
Solve time for step 3 4.150395973003469
Current ori: tensor([-0.0044,  0.0128, -0.1707], device='cuda:1')
Middle force: tensor([0.5104, 0.5708], device='cuda:1')
Thumb force: tensor([0.5572, 0.5429], device='cuda:1')
tensor([ 0.1457,  0.5189,  0.5186,  0.5782, -0.1671,  0.6456,  0.8671,  0.7519,
         1.3504,  0.2596,  0.1490,  1.1473, -0.0043,  0.0182, -0.1763, -0.1208],
       device='cuda:1')
Solve time for step 4 3.994206148025114
Current ori: tensor([-0.0043,  0.0182, -0.1763], device='cuda:1')
Middle force: tensor([0.5522], device='cuda:1')
Thumb force: tensor([0.5247], device='cuda:1')
Storing RECOVERY transition: reward=0.0057 (scaled=0.0029), steps=2
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0887
Collected 491 transitions for RL
SAC Update 1/5: Actor Loss=-0.0125, Q1 Loss=1.4250, Q2 Loss=1.4250, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9668
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.0839, Q2 Loss=1.0839, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7872
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=1.0142, Q2 Loss=1.0142, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7638
SAC Update 4/5: Actor Loss=-0.0132, Q1 Loss=1.6240, Q2 Loss=1.6240, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2459
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=1.0235, Q2 Loss=1.0235, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2699

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010766
Q1 loss: 1.234107
Q2 loss: 1.234107
Current threshold: -149.4996
Global Scale Offset: 4643.5921
Reward stats: mean=0.0147, std=0.0887, count=491
----------------------------------------------
SAC Update - Actor Loss: -0.0108, Q1 Loss: 1.2341, Q2 Loss: 1.2341, Entropy: 0.6931, Mean TD Error: 0.8067, Threshold: -149.4996
Original likelihood: -125.91497802734375
Adjusted likelihood: -125.91497802734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5020)
Current yaw: tensor([-0.0076,  0.0181, -0.1607], device='cuda:1')
12 turn
Sampling time 3.6108988230116665
tensor([ 0.0936,  0.5779,  0.5602,  0.5992, -0.1643,  0.6571,  0.8552,  0.7371,
         1.3498,  0.2602,  0.1495,  1.1439, -0.0076,  0.0181, -0.1607, -0.1312],
       device='cuda:1')
Original likelihood: -127.5284652709961
Adjusted likelihood: -127.5284652709961
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5019)
State is out of distribution
Projection step: 0, Loss: 132.27696228027344
Projection step: 1, Loss: 133.09014892578125
Projection step: 2, Loss: 128.14903259277344
Projection step: 3, Loss: 121.55615234375
Projection step: 4, Loss: 119.9493637084961
Projection step: 5, Loss: 109.097900390625
Projection step: 6, Loss: 105.80403900146484
Projection step: 7, Loss: 101.76789855957031
Final likelihood: tensor([-104.0573, -114.8539,  -90.6763,  -81.9544, -117.0732, -104.3450,
        -109.5024,  -92.6136,  -81.6535, -112.3267, -112.8848,  -98.9741,
        -111.7460,  -99.3155,  -99.9465,  -96.3631])
Final projection likelihood: -101.7679
1 mode projection succeeded
New goal: tensor([ 0.0950,  0.5695,  0.5653,  0.6035, -0.1211,  0.6487,  0.8570,  0.7406,
         1.3309,  0.2499,  0.1808,  1.1844, -0.0062,  0.0177, -0.1505],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -123.49664306640625
Adjusted likelihood: -123.49664306640625
Likelihood residual: 0.0
Original likelihood: -125.55319213867188
Adjusted likelihood: -125.55319213867188
Likelihood residual: 0.0
{'index': 125.55319213867188, 'thumb_middle': 123.49664306640625}
Current yaw: tensor([-0.0076,  0.0181, -0.1607], device='cuda:1')
13 thumb_middle
tensor([ 0.0936,  0.5779,  0.5602,  0.5992, -0.1643,  0.6571,  0.8552,  0.7371,
         1.3498,  0.2602,  0.1495,  1.1439, -0.0076,  0.0181, -0.1607, -0.1312],
       device='cuda:1')
Solve time for step 1 9.13515623100102
Current ori: tensor([-0.0076,  0.0181, -0.1607], device='cuda:1')
Index force: tensor([0.5838, 0.5853, 0.5957, 0.6018], device='cuda:1')
tensor([ 0.0865,  0.5839,  0.5522,  0.5857, -0.2273,  0.6265,  0.8155,  0.7172,
         1.2828,  0.2273,  0.0969,  1.1458, -0.0100,  0.0219, -0.1606, -0.1496],
       device='cuda:1')
Solve time for step 2 3.598923562967684
Current ori: tensor([-0.0100,  0.0219, -0.1606], device='cuda:1')
Index force: tensor([0.5734, 0.5841, 0.5907], device='cuda:1')
tensor([ 0.0811,  0.5863,  0.5460,  0.5809, -0.2300,  0.6279,  0.8158,  0.7112,
         1.2838,  0.2245,  0.0953,  1.1503, -0.0109,  0.0249, -0.1606, -0.1591],
       device='cuda:1')
Solve time for step 3 3.518528874963522
Current ori: tensor([-0.0109,  0.0249, -0.1606], device='cuda:1')
Index force: tensor([0.5712, 0.5786], device='cuda:1')
tensor([ 0.0796,  0.5784,  0.5511,  0.5890, -0.2312,  0.6291,  0.8128,  0.7139,
         1.2859,  0.2240,  0.0945,  1.1525, -0.0085,  0.0261, -0.1606, -0.1583],
       device='cuda:1')
Solve time for step 4 3.364412683993578
Current ori: tensor([-0.0085,  0.0261, -0.1606], device='cuda:1')
Index force: tensor([0.5619], device='cuda:1')
Storing RECOVERY transition: reward=0.0037 (scaled=0.0037), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0886
Collected 492 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8553, Q2 Loss=0.8553, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3666
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=2.5474, Q2 Loss=2.5474, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0293
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=1.3971, Q2 Loss=1.3971, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5719
SAC Update 4/5: Actor Loss=-0.0122, Q1 Loss=1.2314, Q2 Loss=1.2314, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3161
SAC Update 5/5: Actor Loss=-0.0115, Q1 Loss=1.1613, Q2 Loss=1.1613, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2973

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.4%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011011
Q1 loss: 1.438498
Q2 loss: 1.438498
Current threshold: -149.4992
Global Scale Offset: 4670.0241
Reward stats: mean=0.0147, std=0.0886, count=492
----------------------------------------------
SAC Update - Actor Loss: -0.0110, Q1 Loss: 1.4385, Q2 Loss: 1.4385, Entropy: 0.6931, Mean TD Error: 0.9162, Threshold: -149.4992
Original likelihood: -142.3223419189453
Adjusted likelihood: -142.3223419189453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5006)
Current yaw: tensor([-0.0058,  0.0188, -0.1644], device='cuda:1')
14 turn
Sampling time 3.609160878986586
tensor([ 0.0924,  0.5723,  0.5647,  0.6035, -0.1701,  0.6681,  0.8494,  0.7332,
         1.3478,  0.2491,  0.1445,  1.1780, -0.0058,  0.0188, -0.1644, -0.1324],
       device='cuda:1')
Original likelihood: -135.65951538085938
Adjusted likelihood: -135.65951538085938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5012)
State is out of distribution
Projection step: 0, Loss: 132.82284545898438
Projection step: 1, Loss: 121.27218627929688
Projection step: 2, Loss: 122.59357452392578
Projection step: 3, Loss: 122.64839172363281
Projection step: 4, Loss: 120.85201263427734
Projection step: 5, Loss: 117.51697540283203
Projection step: 6, Loss: 111.79657745361328
Projection step: 7, Loss: 108.16935729980469
Projection step: 8, Loss: 101.24940490722656
Final likelihood: tensor([-124.6789, -118.6164, -107.8555,  -96.3943, -116.8849,  -95.6208,
         -85.9242, -105.1788,  -99.1964,  -95.9044,  -77.7992,  -96.8079,
        -121.9526, -100.1468,  -88.8363,  -88.1930])
Final projection likelihood: -101.2494
1 mode projection succeeded
New goal: tensor([ 0.0928,  0.5654,  0.5694,  0.6020, -0.1228,  0.6575,  0.8477,  0.7445,
         1.3247,  0.2385,  0.1829,  1.2096, -0.0040,  0.0178, -0.0376],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -120.12025451660156
Adjusted likelihood: -120.12025451660156
Likelihood residual: 0.0
Original likelihood: -122.18035888671875
Adjusted likelihood: -122.18035888671875
Likelihood residual: 0.0
{'index': 122.18035888671875, 'thumb_middle': 120.12025451660156}
Current yaw: tensor([-0.0058,  0.0188, -0.1644], device='cuda:1')
15 thumb_middle
tensor([ 0.0924,  0.5723,  0.5647,  0.6035, -0.1701,  0.6681,  0.8494,  0.7332,
         1.3478,  0.2491,  0.1445,  1.1780, -0.0058,  0.0188, -0.1644, -0.1324],
       device='cuda:1')
Solve time for step 1 8.977179756970145
Current ori: tensor([-0.0058,  0.0188, -0.1644], device='cuda:1')
Index force: tensor([0.5717, 0.5787, 0.5944, 0.6002], device='cuda:1')
tensor([ 0.0912,  0.5693,  0.5660,  0.6058, -0.2338,  0.6289,  0.8202,  0.7212,
         1.2802,  0.2120,  0.0984,  1.1757, -0.0051,  0.0200, -0.1643, -0.1332],
       device='cuda:1')
Solve time for step 2 3.61663949402282
Current ori: tensor([-0.0051,  0.0200, -0.1643], device='cuda:1')
Index force: tensor([0.5705, 0.5872, 0.5926], device='cuda:1')
tensor([ 0.0947,  0.5691,  0.5650,  0.6159, -0.2335,  0.6454,  0.8034,  0.7132,
         1.2756,  0.2128,  0.0947,  1.1666, -0.0042,  0.0180, -0.1643, -0.1255],
       device='cuda:1')
Solve time for step 3 3.4781421899679117
Current ori: tensor([-0.0042,  0.0180, -0.1643], device='cuda:1')
Index force: tensor([0.5787, 0.5851], device='cuda:1')
tensor([ 0.0913,  0.5655,  0.5779,  0.5936, -0.2329,  0.6367,  0.8112,  0.7256,
         1.2739,  0.2158,  0.0930,  1.1734, -0.0052,  0.0198, -0.1644, -0.1346],
       device='cuda:1')
Solve time for step 4 3.352298628014978
Current ori: tensor([-0.0052,  0.0198, -0.1644], device='cuda:1')
Index force: tensor([0.5693], device='cuda:1')
Storing RECOVERY transition: reward=-0.0099 (scaled=-0.0099), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0885
Collected 493 transitions for RL
SAC Update 1/5: Actor Loss=-0.0108, Q1 Loss=10.3512, Q2 Loss=10.3512, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=7.9912
SAC Update 2/5: Actor Loss=-0.0123, Q1 Loss=1.5253, Q2 Loss=1.5253, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3166
SAC Update 3/5: Actor Loss=-0.0126, Q1 Loss=1.2657, Q2 Loss=1.2657, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1717
SAC Update 4/5: Actor Loss=-0.0131, Q1 Loss=1.4470, Q2 Loss=1.4470, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8228
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=2.1707, Q2 Loss=2.1707, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5642

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (19.9%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (19.1%)
Actor update: 0.08s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.012026
Q1 loss: 3.351958
Q2 loss: 3.351958
Current threshold: -149.4990
Global Scale Offset: 4688.2417
Reward stats: mean=0.0147, std=0.0885, count=493
----------------------------------------------
SAC Update - Actor Loss: -0.0120, Q1 Loss: 3.3520, Q2 Loss: 3.3520, Entropy: 0.6931, Mean TD Error: 2.5733, Threshold: -149.4990
Original likelihood: -126.56338500976562
Adjusted likelihood: -126.56338500976562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 118.32288360595703
Projection step: 1, Loss: 136.39111328125
Projection step: 2, Loss: 125.0534896850586
Projection step: 3, Loss: 120.2544937133789
Projection step: 4, Loss: 117.66673278808594
Projection step: 5, Loss: 105.76276397705078
Projection step: 6, Loss: 108.14289093017578
Projection step: 7, Loss: 102.52338409423828
Final likelihood: tensor([ -93.9203,  -96.5051, -119.7027, -120.1554,  -99.9864, -110.2568,
         -93.3826,  -94.6537,  -95.4850,  -93.7405, -103.3109,  -94.1013,
        -104.5857, -105.0097, -116.8497,  -98.7284])
Final projection likelihood: -102.5234
1 mode projection succeeded
New goal: tensor([ 9.1674e-02,  5.5925e-01,  5.7266e-01,  6.1444e-01, -1.3296e-01,
         6.7002e-01,  8.4091e-01,  7.5230e-01,  1.3195e+00,  2.2631e-01,
         1.7594e-01,  1.2258e+00,  2.0934e-04,  1.7044e-02, -3.3096e-02],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -130.88058471679688
Adjusted likelihood: -130.88058471679688
Likelihood residual: 0.0
Original likelihood: -117.9715347290039
Adjusted likelihood: -117.9715347290039
Likelihood residual: 0.0
{'index': 117.9715347290039, 'thumb_middle': 130.88058471679688}
Current yaw: tensor([-0.0015,  0.0188, -0.1545], device='cuda:1')
16 index
tensor([ 0.0935,  0.5619,  0.5681,  0.6271, -0.1728,  0.6821,  0.8339,  0.7384,
         1.3389,  0.2309,  0.1530,  1.2093, -0.0015,  0.0188, -0.1545, -0.1329],
       device='cuda:1')
Solve time for step 1 10.419554969004821
Current ori: tensor([-0.0015,  0.0188, -0.1545], device='cuda:1')
Middle force: tensor([0.5317, 0.5456, 0.5337, 0.5182], device='cuda:1')
Thumb force: tensor([0.5365, 0.5517, 0.5503, 0.5556], device='cuda:1')
tensor([ 0.1379,  0.5063,  0.5213,  0.5920, -0.1836,  0.6789,  0.8305,  0.7432,
         1.3591,  0.2097,  0.1596,  1.1826, -0.0041,  0.0257, -0.1746,  0.2721],
       device='cuda:1')
Solve time for step 2 4.1670575789758
Current ori: tensor([-0.0041,  0.0257, -0.1746], device='cuda:1')
Middle force: tensor([0.5426, 0.5312, 0.5163], device='cuda:1')
Thumb force: tensor([0.5468, 0.5472, 0.5529], device='cuda:1')
tensor([ 0.1381,  0.5063,  0.5241,  0.5898, -0.1812,  0.6742,  0.8382,  0.7514,
         1.3481,  0.2284,  0.1531,  1.1970, -0.0025,  0.0225, -0.1881,  0.5673],
       device='cuda:1')
Solve time for step 3 4.020893679000437
Current ori: tensor([-0.0025,  0.0225, -0.1881], device='cuda:1')
Middle force: tensor([0.5711, 0.5003], device='cuda:1')
Thumb force: tensor([0.6132, 0.6044], device='cuda:1')
tensor([ 0.1415,  0.5067,  0.5235,  0.5892, -0.1646,  0.6911,  0.8297,  0.7393,
         1.3414,  0.2299,  0.1336,  1.2048, -0.0089,  0.0110, -0.1865,  0.7532],
       device='cuda:1')
Solve time for step 4 4.006004097987898
Current ori: tensor([-0.0089,  0.0110, -0.1865], device='cuda:1')
Middle force: tensor([0.5329], device='cuda:1')
Thumb force: tensor([0.5915], device='cuda:1')
Storing RECOVERY transition: reward=0.0302 (scaled=0.0302), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0884
Collected 494 transitions for RL
SAC Update 1/5: Actor Loss=-0.0111, Q1 Loss=1.6177, Q2 Loss=1.6177, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8991
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=0.9544, Q2 Loss=0.9544, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4819
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=1.3967, Q2 Loss=1.3967, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5235
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=0.9285, Q2 Loss=0.9285, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7254
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=0.9477, Q2 Loss=0.9477, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3195

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (42.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009061
Q1 loss: 1.168978
Q2 loss: 1.168978
Current threshold: -149.4988
Global Scale Offset: 4706.6095
Reward stats: mean=0.0147, std=0.0884, count=494
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.1690, Q2 Loss: 1.1690, Entropy: 0.6931, Mean TD Error: 1.7899, Threshold: -149.4988
Original likelihood: -128.0913848876953
Adjusted likelihood: -128.0913848876953
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5018)
State is out of distribution
Projection step: 0, Loss: 137.08660888671875
Projection step: 1, Loss: 141.4041748046875
Projection step: 2, Loss: 135.38165283203125
Projection step: 3, Loss: 128.1009521484375
Projection step: 4, Loss: 123.91827392578125
Projection step: 5, Loss: 120.53739929199219
Projection step: 6, Loss: 116.341552734375
Projection step: 7, Loss: 110.54444885253906
Projection step: 8, Loss: 111.17227172851562
Projection step: 9, Loss: 109.13526916503906
Projection step: 10, Loss: 106.9366455078125
Projection step: 11, Loss: 104.22988891601562
Final likelihood: tensor([ -80.1956,  -95.6677,  -74.2854, -121.2464,  -94.0038, -102.6557,
        -120.3760, -108.7985, -114.6177, -104.2897, -113.6654,  -98.7550,
        -117.0261,  -94.3794, -102.3294, -125.3861])
Final projection likelihood: -104.2299
1 mode projection succeeded
New goal: tensor([ 0.0894,  0.5615,  0.5705,  0.6084, -0.1135,  0.6593,  0.8398,  0.7432,
         1.3224,  0.2263,  0.1786,  1.2233, -0.0047,  0.0161, -0.2396],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -115.11248779296875
Adjusted likelihood: -115.11248779296875
Likelihood residual: 0.0
Original likelihood: -130.69381713867188
Adjusted likelihood: -130.69381713867188
Likelihood residual: 0.0
{'index': 130.69381713867188, 'thumb_middle': 115.11248779296875}
Current yaw: tensor([-0.0082,  0.0143, -0.1945], device='cuda:1')
17 thumb_middle
tensor([ 0.0879,  0.5650,  0.5667,  0.6108, -0.1699,  0.6859,  0.8329,  0.7433,
         1.3471,  0.2317,  0.1282,  1.2110, -0.0082,  0.0143, -0.1945,  0.8023],
       device='cuda:1')
Solve time for step 1 8.75593253201805
Current ori: tensor([-0.0082,  0.0143, -0.1945], device='cuda:1')
Index force: tensor([0.5522, 0.5006, 0.6015, 0.5743], device='cuda:1')
tensor([ 8.9536e-02,  5.2986e-01,  6.1520e-01,  6.1315e-01, -2.2205e-01,
         6.4653e-01,  7.8983e-01,  7.1711e-01,  1.2773e+00,  1.9821e-01,
         8.5399e-02,  1.1931e+00,  1.4346e-04,  1.4374e-02, -1.9446e-01,
         8.1090e-01], device='cuda:1')
Solve time for step 2 3.6695278100087307
Current ori: tensor([ 1.4346e-04,  1.4374e-02, -1.9446e-01], device='cuda:1')
Index force: tensor([0.5004, 0.5937, 0.5685], device='cuda:1')
tensor([ 0.0833,  0.5421,  0.6000,  0.5975, -0.2240,  0.6367,  0.7965,  0.7169,
         1.2734,  0.2018,  0.0922,  1.1958, -0.0041,  0.0175, -0.1945,  0.7958],
       device='cuda:1')
Solve time for step 3 3.371478863991797
Current ori: tensor([-0.0041,  0.0175, -0.1945], device='cuda:1')
Index force: tensor([0.5867, 0.5644], device='cuda:1')
tensor([ 0.0788,  0.5699,  0.5604,  0.5929, -0.2287,  0.6376,  0.8055,  0.7197,
         1.2671,  0.1941,  0.1042,  1.1845, -0.0109,  0.0192, -0.1945,  0.7860],
       device='cuda:1')
Solve time for step 4 3.223825402033981
Current ori: tensor([-0.0109,  0.0192, -0.1945], device='cuda:1')
Index force: tensor([0.5506], device='cuda:1')
Storing RECOVERY transition: reward=0.0299 (scaled=0.0299), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0884
Collected 495 transitions for RL
SAC Update 1/5: Actor Loss=-0.0092, Q1 Loss=1.8884, Q2 Loss=1.8884, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1744
SAC Update 2/5: Actor Loss=-0.0131, Q1 Loss=1.3549, Q2 Loss=1.3549, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3638
SAC Update 3/5: Actor Loss=-0.0115, Q1 Loss=1.1875, Q2 Loss=1.1875, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2496
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=1.6077, Q2 Loss=1.6077, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5583
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=1.0974, Q2 Loss=1.0974, Entropy=0.6924, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2068

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.2%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (39.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.011452
Q1 loss: 1.427195
Q2 loss: 1.427195
Current threshold: -149.4987
Global Scale Offset: 4720.2395
Reward stats: mean=0.0147, std=0.0884, count=495
----------------------------------------------
SAC Update - Actor Loss: -0.0115, Q1 Loss: 1.4272, Q2 Loss: 1.4272, Entropy: 0.6930, Mean TD Error: 1.1106, Threshold: -149.4987
Original likelihood: -127.61847686767578
Adjusted likelihood: -127.61847686767578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5018)
Current yaw: tensor([-0.0076,  0.0117, -0.1941], device='cuda:1')
18 turn
Sampling time 3.8781895699794404
tensor([ 0.0924,  0.5628,  0.5743,  0.6108, -0.1638,  0.6843,  0.8365,  0.7369,
         1.3360,  0.2246,  0.1393,  1.2160, -0.0076,  0.0117, -0.1941,  0.8092],
       device='cuda:1')
Original likelihood: -132.56292724609375
Adjusted likelihood: -132.56292724609375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5014)
State is out of distribution
Projection step: 0, Loss: 127.52293395996094
Projection step: 1, Loss: 125.25496673583984
Projection step: 2, Loss: 128.11404418945312
Projection step: 3, Loss: 124.27623748779297
Projection step: 4, Loss: 121.71929931640625
Projection step: 5, Loss: 120.77880859375
Projection step: 6, Loss: 112.7363510131836
Projection step: 7, Loss: 106.67472076416016
Projection step: 8, Loss: 102.03022766113281
Final likelihood: tensor([-113.3493,  -88.8802,  -82.6995, -116.3845,  -96.1579,  -80.1045,
         -94.0472, -104.0101, -136.3272, -104.9912,  -85.9661, -107.9142,
        -103.9050, -106.1476, -101.6326, -109.9666])
Final projection likelihood: -102.0302
1 mode projection succeeded
New goal: tensor([ 0.0937,  0.5613,  0.5766,  0.6047, -0.1222,  0.6656,  0.8482,  0.7422,
         1.3196,  0.2219,  0.1766,  1.2233, -0.0047,  0.0146, -0.1725],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -119.80269622802734
Adjusted likelihood: -119.80269622802734
Likelihood residual: 0.0
Original likelihood: -118.65088653564453
Adjusted likelihood: -118.65088653564453
Likelihood residual: 0.0
{'index': 118.65088653564453, 'thumb_middle': 119.80269622802734}
Current yaw: tensor([-0.0076,  0.0117, -0.1941], device='cuda:1')
19 index
tensor([ 0.0924,  0.5628,  0.5743,  0.6108, -0.1638,  0.6843,  0.8365,  0.7369,
         1.3360,  0.2246,  0.1393,  1.2160, -0.0076,  0.0117, -0.1941,  0.8092],
       device='cuda:1')
Solve time for step 1 10.632012482965365
Current ori: tensor([-0.0076,  0.0117, -0.1941], device='cuda:1')
Middle force: tensor([0.5911, 0.5337, 0.5003, 0.5923], device='cuda:1')
Thumb force: tensor([0.5702, 0.5254, 0.5685, 0.6116], device='cuda:1')
tensor([ 0.1400,  0.5078,  0.5265,  0.5808, -0.1714,  0.6729,  0.8462,  0.7409,
         1.3426,  0.2217,  0.1484,  1.1999, -0.0067,  0.0165, -0.2159,  0.8309],
       device='cuda:1')
Solve time for step 2 4.266339038033038
Current ori: tensor([-0.0067,  0.0165, -0.2159], device='cuda:1')
Middle force: tensor([0.5319, 0.5002, 0.5874], device='cuda:1')
Thumb force: tensor([0.5217, 0.5646, 0.6074], device='cuda:1')
tensor([ 0.1438,  0.5083,  0.5253,  0.5802, -0.1637,  0.6845,  0.8377,  0.7306,
         1.3549,  0.2004,  0.1328,  1.1958, -0.0130,  0.0116, -0.2208,  0.8540],
       device='cuda:1')
Solve time for step 3 4.598152749007568
Current ori: tensor([-0.0130,  0.0116, -0.2208], device='cuda:1')
Middle force: tensor([0.5001, 0.5827], device='cuda:1')
Thumb force: tensor([0.5561, 0.6028], device='cuda:1')
tensor([ 0.1432,  0.5090,  0.5269,  0.5796, -0.1632,  0.6678,  0.8575,  0.7514,
         1.3353,  0.2262,  0.1361,  1.2157, -0.0039,  0.0090, -0.2315,  0.9061],
       device='cuda:1')
Solve time for step 4 4.35411842999747
Current ori: tensor([-0.0039,  0.0090, -0.2315], device='cuda:1')
Middle force: tensor([0.5856], device='cuda:1')
Thumb force: tensor([0.5768], device='cuda:1')
Storing RECOVERY transition: reward=0.0272 (scaled=0.0272), steps=0
Reward stats updated: mean 0.0147 -> 0.0148, std: 0.0883
Collected 496 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=0.9749, Q2 Loss=0.9749, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3161
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.2544, Q2 Loss=1.2544, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5362
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.8082, Q2 Loss=0.8082, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3444
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.9267, Q2 Loss=0.9267, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6664
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=1.3158, Q2 Loss=1.3158, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8127

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.6%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009181
Q1 loss: 1.055994
Q2 loss: 1.055994
Current threshold: -149.4986
Global Scale Offset: 4722.8215
Reward stats: mean=0.0148, std=0.0883, count=496
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.0560, Q2 Loss: 1.0560, Entropy: 0.6931, Mean TD Error: 1.1352, Threshold: -149.4986
Original likelihood: -134.17984008789062
Adjusted likelihood: -134.17984008789062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5013)
State is out of distribution
Projection step: 0, Loss: 129.0384063720703
Projection step: 1, Loss: 122.41558837890625
Projection step: 2, Loss: 125.52669525146484
Projection step: 3, Loss: 118.58419036865234
Projection step: 4, Loss: 117.233154296875
Projection step: 5, Loss: 117.47743225097656
Projection step: 6, Loss: 103.92212677001953
Final likelihood: tensor([-102.2712, -104.3540,  -96.6639, -104.7113, -109.8952,  -99.4670,
        -110.7262, -116.0923,  -95.6497, -114.5371,  -83.2365,  -94.1313,
        -106.6079,  -96.1607, -103.0528, -125.1970])
Final projection likelihood: -103.9221
1 mode projection succeeded
New goal: tensor([ 0.0936,  0.5632,  0.5817,  0.5898, -0.1303,  0.6629,  0.8551,  0.7482,
         1.3207,  0.2158,  0.1668,  1.2119, -0.0032,  0.0140, -0.2543],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0031]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -132.72442626953125
Adjusted likelihood: -132.72442626953125
Likelihood residual: 0.0
Original likelihood: -123.85513305664062
Adjusted likelihood: -123.85513305664062
Likelihood residual: 0.0
{'index': 123.85513305664062, 'thumb_middle': 132.72442626953125}
Current yaw: tensor([-0.0054,  0.0120, -0.2213], device='cuda:1')
20 index
tensor([ 0.0892,  0.5675,  0.5694,  0.6009, -0.1662,  0.6719,  0.8514,  0.7447,
         1.3388,  0.2231,  0.1405,  1.2097, -0.0054,  0.0120, -0.2213,  0.9013],
       device='cuda:1')
Solve time for step 1 10.421164555009454
Current ori: tensor([-0.0054,  0.0120, -0.2213], device='cuda:1')
Middle force: tensor([0.5364, 0.5857, 0.5308, 0.5111], device='cuda:1')
Thumb force: tensor([0.5700, 0.5754, 0.5905, 0.6003], device='cuda:1')
tensor([ 0.1409,  0.5110,  0.5297,  0.5651, -0.1635,  0.6637,  0.8619,  0.7580,
         1.3367,  0.2319,  0.1300,  1.2147, -0.0046,  0.0084, -0.2543,  1.0676],
       device='cuda:1')
Solve time for step 2 4.280790580029134
Current ori: tensor([-0.0046,  0.0084, -0.2543], device='cuda:1')
Middle force: tensor([0.5824, 0.5279, 0.5098], device='cuda:1')
Thumb force: tensor([0.5691, 0.5869, 0.5962], device='cuda:1')
tensor([ 0.1475,  0.5115,  0.5325,  0.5668, -0.1651,  0.6705,  0.8533,  0.7450,
         1.3511,  0.2128,  0.1278,  1.2056, -0.0088,  0.0110, -0.2461,  1.1442],
       device='cuda:1')
Solve time for step 3 4.1298554399982095
Current ori: tensor([-0.0088,  0.0110, -0.2461], device='cuda:1')
Middle force: tensor([0.5258, 0.5086], device='cuda:1')
Thumb force: tensor([0.5756, 0.5901], device='cuda:1')
tensor([ 0.1414,  0.5091,  0.5299,  0.5647, -0.1694,  0.6699,  0.8509,  0.7420,
         1.3680,  0.1907,  0.1257,  1.1993, -0.0101,  0.0146, -0.2479,  1.2018],
       device='cuda:1')
Solve time for step 4 3.8494404410012066
Current ori: tensor([-0.0101,  0.0146, -0.2479], device='cuda:1')
Middle force: tensor([0.5075], device='cuda:1')
Thumb force: tensor([0.5786], device='cuda:1')
Storing RECOVERY transition: reward=0.0503 (scaled=0.0503), steps=0
Reward stats updated: mean 0.0148 -> 0.0148, std: 0.0882
Collected 497 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.9743, Q2 Loss=0.9743, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6892
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.0311, Q2 Loss=1.0311, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5816
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=0.9280, Q2 Loss=0.9280, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4704
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.9746, Q2 Loss=0.9746, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3997
SAC Update 5/5: Actor Loss=-0.0084, Q1 Loss=0.8569, Q2 Loss=0.8569, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4921

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (42.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008471
Q1 loss: 0.952971
Q2 loss: 0.952971
Current threshold: -149.4986
Global Scale Offset: 4731.5745
Reward stats: mean=0.0148, std=0.0882, count=497
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9530, Q2 Loss: 0.9530, Entropy: 0.6931, Mean TD Error: 1.3266, Threshold: -149.4986
Original likelihood: -139.197509765625
Adjusted likelihood: -139.197509765625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Marked last transition as done (final step)
{}

Trial 32
Loaded trajectory sampler
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
1 turn
Sampling time 3.7621617219992913
tensor([ 1.3022e-01,  6.5379e-01,  5.2601e-01,  5.2990e-01, -1.0274e-01,
         5.3373e-01,  9.0198e-01,  8.5951e-01,  1.2015e+00,  2.9579e-01,
         2.8673e-01,  1.1699e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Original likelihood: -101.15081787109375
Adjusted likelihood: -101.15081787109375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5041)
State is out of distribution
Projection step: 0, Loss: 96.13755798339844
Final likelihood: tensor([-111.1913,  -72.6974,  -96.7675,  -74.0776, -101.7954,  -97.2628,
         -88.2563, -106.0775, -128.4717,  -97.4861,  -89.2119, -114.8162,
         -72.4795,  -94.1547, -108.8315,  -84.6236])
Final projection likelihood: -96.1376
1 mode projection succeeded
New goal: tensor([ 1.3022e-01,  6.5379e-01,  5.2601e-01,  5.2990e-01, -1.0274e-01,
         5.3373e-01,  9.0198e-01,  8.5951e-01,  1.2015e+00,  2.9579e-01,
         2.8673e-01,  1.1699e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
2 turn
Sampling time 3.797376937000081
tensor([ 1.3022e-01,  6.5379e-01,  5.2601e-01,  5.2990e-01, -1.0274e-01,
         5.3373e-01,  9.0198e-01,  8.5951e-01,  1.2015e+00,  2.9579e-01,
         2.8673e-01,  1.1699e+00, -7.4229e-05,  1.3967e-02, -3.8121e-02,
         2.7615e-01], device='cuda:1')
Original likelihood: -100.95454406738281
Adjusted likelihood: -100.95454406738281
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5041)
Solve time for step 1 14.206058492010925
Current ori: tensor([-7.4229e-05,  1.3967e-02, -3.8121e-02], device='cuda:1')
Middle force: tensor([1.1231, 1.6776, 0.8127, 0.5248, 0.5632, 0.9622, 1.1547, 0.4988, 0.5091,
        0.5216, 0.5151, 0.5627], device='cuda:1')
Thumb force: tensor([0.9070, 1.4464, 0.5716, 0.5352, 0.5109, 1.2319, 0.6727, 0.5616, 0.6430,
        0.5977, 0.8275, 0.6306], device='cuda:1')
Index force: tensor([0.9438, 1.8143, 0.5535, 0.6002, 0.5810, 0.8173, 0.5379, 0.5807, 0.5601,
        0.5981, 0.6419, 0.5910], device='cuda:1')
Storing NORMAL transition: reward=0.1190 (scaled=0.1190), steps=1
Reward stats updated: mean 0.0148 -> 0.0150, std: 0.0882
Collected 498 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.0472, Q2 Loss=1.0472, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5273
SAC Update 2/5: Actor Loss=-0.0115, Q1 Loss=1.1781, Q2 Loss=1.1781, Entropy=0.6929, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1273
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8128, Q2 Loss=0.8128, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8144
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.7386, Q2 Loss=0.7386, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6830
SAC Update 5/5: Actor Loss=-0.0085, Q1 Loss=0.8644, Q2 Loss=0.8644, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3834

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008982
Q1 loss: 0.928222
Q2 loss: 0.928222
Current threshold: -149.4986
Global Scale Offset: 4739.9897
Reward stats: mean=0.0150, std=0.0882, count=498
----------------------------------------------
SAC Update - Actor Loss: -0.0090, Q1 Loss: 0.9282, Q2 Loss: 0.9282, Entropy: 0.6931, Mean TD Error: 0.5071, Threshold: -149.4986
tensor([ 0.1278,  0.7038,  0.4655,  0.4823, -0.1322,  0.5330,  0.8366,  1.0213,
         1.1889,  0.3467,  0.3631,  1.0264, -0.0143,  0.0201, -0.1577,  0.4886],
       device='cuda:1')
Original likelihood: -144.36630249023438
Adjusted likelihood: -144.36630249023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5004)
State is out of distribution
Projection step: 0, Loss: 148.7448272705078
Projection step: 1, Loss: 141.16738891601562
Projection step: 2, Loss: 134.59298706054688
Projection step: 3, Loss: 118.89037322998047
Projection step: 4, Loss: 108.64913940429688
Projection step: 5, Loss: 116.59457397460938
Projection step: 6, Loss: 95.53045654296875
Final likelihood: tensor([ -76.1230, -103.1143,  -97.0806,  -91.8283,  -93.1859,  -88.9485,
        -100.0920,  -81.6272, -110.1059,  -78.4516, -102.6452,  -90.3151,
         -98.9072,  -89.7074, -104.1316, -122.2236])
Final projection likelihood: -95.5305
1 mode projection succeeded
New goal: tensor([ 0.1091,  0.6603,  0.5018,  0.4791, -0.1088,  0.5056,  0.8158,  1.0064,
         1.2335,  0.3344,  0.3059,  1.0893, -0.0140,  0.0180, -1.0934],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -140.7279815673828
Adjusted likelihood: -140.7279815673828
Likelihood residual: 0.0
Original likelihood: -143.7080535888672
Adjusted likelihood: -143.7080535888672
Likelihood residual: 0.0
{'index': 143.7080535888672, 'thumb_middle': 140.7279815673828}
Current yaw: tensor([-0.0143,  0.0201, -0.1577], device='cuda:1')
3 thumb_middle
tensor([ 0.1278,  0.7038,  0.4655,  0.4823, -0.1322,  0.5330,  0.8366,  1.0213,
         1.1889,  0.3467,  0.3631,  1.0264, -0.0143,  0.0201, -0.1577,  0.4886],
       device='cuda:1')
Solve time for step 1 9.004642786982004
Current ori: tensor([-0.0143,  0.0201, -0.1577], device='cuda:1')
Index force: tensor([0.5911, 0.5942, 0.6147, 0.5041], device='cuda:1')
tensor([ 0.1234,  0.6878,  0.4912,  0.4692, -0.2038,  0.4863,  0.7875,  0.9897,
         1.1792,  0.3169,  0.2449,  1.0514, -0.0118,  0.0229, -0.1578,  0.4825],
       device='cuda:1')
Solve time for step 2 4.041386422992218
Current ori: tensor([-0.0118,  0.0229, -0.1578], device='cuda:1')
Index force: tensor([0.5941, 0.5909, 0.6018], device='cuda:1')
tensor([ 0.1105,  0.6745,  0.4968,  0.4738, -0.2157,  0.4891,  0.7838,  0.9871,
         1.1913,  0.3145,  0.2314,  1.0607, -0.0084,  0.0307, -0.1578,  0.4677],
       device='cuda:1')
Solve time for step 3 3.5971144619979896
Current ori: tensor([-0.0084,  0.0307, -0.1578], device='cuda:1')
Index force: tensor([0.5822, 0.5935], device='cuda:1')
tensor([ 0.1204,  0.6727,  0.5070,  0.4844, -0.2093,  0.4933,  0.7866,  0.9862,
         1.1910,  0.3153,  0.2233,  1.0544, -0.0076,  0.0248, -0.1578,  0.4858],
       device='cuda:1')
Solve time for step 4 3.715918567031622
Current ori: tensor([-0.0076,  0.0248, -0.1578], device='cuda:1')
Index force: tensor([0.5760], device='cuda:1')
Storing RECOVERY transition: reward=0.0048 (scaled=0.0048), steps=1
Reward stats updated: mean 0.0150 -> 0.0150, std: 0.0881
Collected 499 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.8090, Q2 Loss=0.8090, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9658
SAC Update 2/5: Actor Loss=-0.0112, Q1 Loss=1.7062, Q2 Loss=1.7062, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9539
SAC Update 3/5: Actor Loss=-0.0117, Q1 Loss=1.2200, Q2 Loss=1.2200, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4955
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=0.8772, Q2 Loss=0.8772, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7764
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7378, Q2 Loss=0.7378, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2422

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.5%)
Q1 update: 0.06s (20.4%)
Q2 update: 0.05s (17.8%)
Actor update: 0.11s (40.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009259
Q1 loss: 1.070023
Q2 loss: 1.070023
Current threshold: -149.4985
Global Scale Offset: 4749.0629
Reward stats: mean=0.0150, std=0.0881, count=499
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.0700, Q2 Loss: 1.0700, Entropy: 0.6931, Mean TD Error: 0.8868, Threshold: -149.4985
Original likelihood: -149.417724609375
Adjusted likelihood: -149.417724609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5000)
Current yaw: tensor([-0.0049,  0.0261, -0.1627], device='cuda:1')
4 turn
Sampling time 3.6323782230028883
tensor([ 0.1166,  0.6625,  0.5153,  0.4947, -0.1393,  0.5406,  0.8228,  1.0053,
         1.2543,  0.3378,  0.2793,  1.0810, -0.0049,  0.0261, -0.1627,  0.5226],
       device='cuda:1')
Original likelihood: -126.54011535644531
Adjusted likelihood: -126.54011535644531
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5019)
Solve time for step 1 14.305747066973709
Current ori: tensor([-0.0049,  0.0261, -0.1627], device='cuda:1')
Middle force: tensor([1.3936, 0.7069, 0.5784, 1.0918, 0.4956, 0.5311, 1.0065, 0.7409, 0.5692,
        0.5016, 0.5087, 0.5842], device='cuda:1')
Thumb force: tensor([1.7782, 0.7594, 1.0613, 0.7199, 0.6113, 1.1993, 0.5859, 1.0638, 0.5083,
        0.7294, 0.7134, 0.5966], device='cuda:1')
Index force: tensor([0.6946, 0.7986, 0.5229, 0.5464, 0.6946, 0.5308, 0.6675, 0.5309, 0.5044,
        0.6037, 0.6808, 0.5923], device='cuda:1')
Storing NORMAL transition: reward=0.1562 (scaled=0.1562), steps=1
Reward stats updated: mean 0.0150 -> 0.0153, std: 0.0883
Collected 500 transitions for RL
SAC Update 1/5: Actor Loss=-0.0119, Q1 Loss=1.7751, Q2 Loss=1.7751, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9386
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=2.6634, Q2 Loss=2.6634, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7894
SAC Update 3/5: Actor Loss=-0.0134, Q1 Loss=1.3757, Q2 Loss=1.3757, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3902
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.7006, Q2 Loss=0.7006, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0900
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.8891, Q2 Loss=0.8891, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2580

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010066
Q1 loss: 1.480764
Q2 loss: 1.480764
Current threshold: -149.4984
Global Scale Offset: 4752.7564
Reward stats: mean=0.0153, std=0.0883, count=500
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.4808, Q2 Loss: 1.4808, Entropy: 0.6931, Mean TD Error: 1.2933, Threshold: -149.4984
tensor([ 0.1488,  0.6650,  0.5519,  0.4808, -0.1135,  0.4889,  0.8059,  1.1012,
         1.2893,  0.3090,  0.2902,  0.9904, -0.0059,  0.0264, -0.3192,  0.4503],
       device='cuda:1')
Original likelihood: -140.084716796875
Adjusted likelihood: -140.084716796875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5008)
Solve time for step 2 5.496509052987676
Current ori: tensor([-0.0059,  0.0264, -0.3192], device='cuda:1')
Middle force: tensor([0.8589, 0.5269, 0.5086, 1.0380, 0.8387, 0.5666, 0.5544, 0.5015, 0.5051,
        0.5042, 0.5520], device='cuda:1')
Thumb force: tensor([1.3561, 1.0340, 0.9352, 0.7660, 0.5292, 0.5019, 1.2537, 0.6949, 0.7792,
        0.5610, 0.6899], device='cuda:1')
Index force: tensor([1.5027, 0.5347, 0.5329, 0.5189, 0.5639, 0.5640, 0.6012, 0.6706, 0.7206,
        0.7827, 0.5610], device='cuda:1')
Storing NORMAL transition: reward=0.1683 (scaled=0.1683), steps=1
Reward stats updated: mean 0.0153 -> 0.0156, std: 0.0885
Collected 501 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=1.2565, Q2 Loss=1.2565, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6525
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9392, Q2 Loss=0.9392, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6411
SAC Update 3/5: Actor Loss=-0.0083, Q1 Loss=0.9021, Q2 Loss=0.9021, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9776
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.8356, Q2 Loss=0.8356, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3335
SAC Update 5/5: Actor Loss=-0.0073, Q1 Loss=0.7367, Q2 Loss=0.7367, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3328

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.10s (38.7%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008078
Q1 loss: 0.934030
Q2 loss: 0.934030
Current threshold: -149.4984
Global Scale Offset: 4761.2207
Reward stats: mean=0.0156, std=0.0885, count=501
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 0.9340, Q2 Loss: 0.9340, Entropy: 0.6931, Mean TD Error: 1.1875, Threshold: -149.4984
tensor([ 0.0949,  0.6038,  0.5132,  0.3386, -0.1434,  0.4240,  0.8845,  1.1243,
         1.4081,  0.2817,  0.2278,  0.8930, -0.0384,  0.0583, -0.4991,  2.4816],
       device='cuda:1')
Original likelihood: -178.29598999023438
Adjusted likelihood: -178.29598999023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4976)
State is out of distribution
Projection step: 0, Loss: 176.87844848632812
Projection step: 1, Loss: 170.51148986816406
Projection step: 2, Loss: 168.42422485351562
Projection step: 3, Loss: 167.1062774658203
Projection step: 4, Loss: 158.19094848632812
Projection step: 5, Loss: 150.072998046875
Projection step: 6, Loss: 150.63973999023438
Projection step: 7, Loss: 147.32247924804688
Projection step: 8, Loss: 138.74307250976562
Projection step: 9, Loss: 143.18113708496094
Projection step: 10, Loss: 140.9129638671875
Projection step: 11, Loss: 138.61868286132812
Projection step: 12, Loss: 148.63278198242188
Projection step: 13, Loss: 151.7525634765625
Projection step: 14, Loss: 143.0068359375
Projection step: 15, Loss: 126.53904724121094
Projection step: 16, Loss: 140.0995330810547
Projection step: 17, Loss: 131.01467895507812
Projection step: 18, Loss: 124.73197937011719
Projection step: 19, Loss: 123.44137573242188
Projection step: 20, Loss: 125.65593719482422
Projection step: 21, Loss: 128.44326782226562
Projection step: 22, Loss: 133.9556884765625
Projection step: 23, Loss: 125.40999603271484
Projection step: 24, Loss: 117.9172134399414
Final likelihood: tensor([-121.3322, -126.8417, -131.5527, -127.1762, -135.6970, -110.1836,
        -121.5702, -121.7831, -123.9338,  -99.7149, -124.5737, -123.3478,
        -146.9522, -101.3211, -133.8414, -128.3104])
Final projection likelihood: -123.6332
1 mode projection succeeded
New goal: tensor([ 0.0563,  0.6459,  0.4238,  0.5798, -0.1002,  0.4438,  0.7565,  1.0309,
         1.3739,  0.2590,  0.1830,  1.0720, -0.0435,  0.0363, -1.9561],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0078]], device='cuda:1')
Original likelihood: -105.59808349609375
Adjusted likelihood: -105.59808349609375
Likelihood residual: 0.0
{'index': 105.59808349609375, 'thumb_middle': inf}
Current yaw: tensor([-0.0384,  0.0583, -0.4991], device='cuda:1')
5 index
tensor([ 0.0949,  0.6038,  0.5132,  0.3386, -0.1434,  0.4240,  0.8845,  1.1243,
         1.4081,  0.2817,  0.2278,  0.8930, -0.0384,  0.0583, -0.4991,  2.4816],
       device='cuda:1')
Solve time for step 1 10.806473642995115
Current ori: tensor([-0.0384,  0.0583, -0.4991], device='cuda:1')
Middle force: tensor([0.5987, 0.5908, 0.5788, 0.5765], device='cuda:1')
Thumb force: tensor([0.6080, 0.5434, 0.6239, 0.5903], device='cuda:1')
tensor([ 0.0997,  0.5795,  0.3941,  0.5170, -0.1080,  0.4570,  0.8652,  1.1305,
         1.4097,  0.2649,  0.1583,  0.9676, -0.0470,  0.0366, -0.5186,  1.6477],
       device='cuda:1')
Solve time for step 2 4.277127433975693
Current ori: tensor([-0.0470,  0.0366, -0.5186], device='cuda:1')
Middle force: tensor([0.5845, 0.5730, 0.5701], device='cuda:1')
Thumb force: tensor([0.5376, 0.6214, 0.5872], device='cuda:1')
tensor([ 0.0981,  0.5879,  0.3777,  0.5476, -0.0895,  0.4913,  0.8438,  1.1018,
         1.4066,  0.2580,  0.1310,  0.9845, -0.0568,  0.0232, -0.4922,  3.7497],
       device='cuda:1')
Solve time for step 3 4.151748340984341
Current ori: tensor([-0.0568,  0.0232, -0.4922], device='cuda:1')
Middle force: tensor([0.5668, 0.5629], device='cuda:1')
Thumb force: tensor([0.6119, 0.5826], device='cuda:1')
tensor([ 0.0934,  0.5846,  0.3764,  0.5514, -0.0977,  0.4867,  0.8435,  1.1011,
         1.4130,  0.2487,  0.1325,  0.9879, -0.0552,  0.0281, -0.4803,  0.0522],
       device='cuda:1')
Solve time for step 4 3.8431611980195157
Current ori: tensor([-0.0552,  0.0281, -0.4803], device='cuda:1')
Middle force: tensor([0.5558], device='cuda:1')
Thumb force: tensor([0.5716], device='cuda:1')
Storing RECOVERY transition: reward=-0.0155 (scaled=-0.0077), steps=2
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0884
Collected 502 transitions for RL
SAC Update 1/5: Actor Loss=-0.0131, Q1 Loss=5.7905, Q2 Loss=5.7905, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9035
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8018, Q2 Loss=0.8018, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7479
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=1.0895, Q2 Loss=1.0895, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1509
SAC Update 4/5: Actor Loss=-0.0096, Q1 Loss=0.9591, Q2 Loss=0.9591, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3818
SAC Update 5/5: Actor Loss=-0.0119, Q1 Loss=1.3186, Q2 Loss=1.3186, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8218

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.2%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010639
Q1 loss: 1.991897
Q2 loss: 1.991897
Current threshold: -149.4985
Global Scale Offset: 4770.2998
Reward stats: mean=0.0156, std=0.0884, count=502
----------------------------------------------
SAC Update - Actor Loss: -0.0106, Q1 Loss: 1.9919, Q2 Loss: 1.9919, Entropy: 0.6931, Mean TD Error: 1.4012, Threshold: -149.4985
Original likelihood: -108.576171875
Adjusted likelihood: -108.576171875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5034)
Current yaw: tensor([-0.0528,  0.0220, -0.4788], device='cuda:1')
6 turn
Sampling time 3.6571396429790184
tensor([ 0.0507,  0.6478,  0.4194,  0.5792, -0.0888,  0.4877,  0.8454,  1.1087,
         1.4008,  0.2639,  0.1269,  1.0050, -0.0528,  0.0220, -0.4788,  1.9754],
       device='cuda:1')
Original likelihood: -101.08421325683594
Adjusted likelihood: -101.08421325683594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5040)
State is out of distribution
Projection step: 0, Loss: 112.14918518066406
Projection step: 1, Loss: 106.04598999023438
Projection step: 2, Loss: 101.74209594726562
Final likelihood: tensor([ -86.3322, -104.4756, -104.1247, -106.1580,  -88.6992, -125.2339,
        -126.6517, -119.3078, -102.5479,  -79.6861,  -80.6667,  -92.6238,
         -99.5056, -104.9871, -102.4844, -104.3886])
Final projection likelihood: -101.7421
1 mode projection succeeded
New goal: tensor([ 0.0507,  0.6453,  0.4125,  0.5901, -0.0842,  0.4819,  0.8116,  1.0878,
         1.3986,  0.2662,  0.1300,  1.0172, -0.0528,  0.0207, -0.4480],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -115.1825942993164
Adjusted likelihood: -115.1825942993164
Likelihood residual: 0.0
Original likelihood: -108.22978973388672
Adjusted likelihood: -108.22978973388672
Likelihood residual: 0.0
{'index': 108.22978973388672, 'thumb_middle': 115.1825942993164}
Current yaw: tensor([-0.0528,  0.0220, -0.4788], device='cuda:1')
7 index
tensor([ 0.0507,  0.6478,  0.4194,  0.5792, -0.0888,  0.4877,  0.8454,  1.1087,
         1.4008,  0.2639,  0.1269,  1.0050, -0.0528,  0.0220, -0.4788,  1.9754],
       device='cuda:1')
Solve time for step 1 10.685274882009253
Current ori: tensor([-0.0528,  0.0220, -0.4788], device='cuda:1')
Middle force: tensor([0.5452, 0.5640, 0.5874, 0.5224], device='cuda:1')
Thumb force: tensor([0.5082, 0.5970, 0.5560, 0.5499], device='cuda:1')
tensor([ 0.0849,  0.5829,  0.3659,  0.5655, -0.0733,  0.5030,  0.8345,  1.1015,
         1.4050,  0.2689,  0.1019,  1.0112, -0.0657,  0.0171, -0.5230,  1.4430],
       device='cuda:1')
Solve time for step 2 4.28347764495993
Current ori: tensor([-0.0657,  0.0171, -0.5230], device='cuda:1')
Middle force: tensor([0.5524, 0.5110, 0.5611], device='cuda:1')
Thumb force: tensor([0.5838, 0.6517, 0.5479], device='cuda:1')
tensor([ 0.0847,  0.5861,  0.3623,  0.5625, -0.0824,  0.5081,  0.8255,  1.0940,
         1.4106,  0.2641,  0.0976,  1.0211, -0.0696,  0.0229, -0.5204,  1.3013],
       device='cuda:1')
Solve time for step 3 4.129966942011379
Current ori: tensor([-0.0696,  0.0229, -0.5204], device='cuda:1')
Middle force: tensor([0.5782, 0.5164], device='cuda:1')
Thumb force: tensor([0.5498, 0.5467], device='cuda:1')
tensor([ 0.0813,  0.5836,  0.3628,  0.5643, -0.0848,  0.5110,  0.8204,  1.0910,
         1.4134,  0.2560,  0.0896,  1.0387, -0.0689,  0.0233, -0.4989,  1.4605],
       device='cuda:1')
Solve time for step 4 3.8480422209831886
Current ori: tensor([-0.0689,  0.0233, -0.4989], device='cuda:1')
Middle force: tensor([0.5533], device='cuda:1')
Thumb force: tensor([0.5369], device='cuda:1')
Storing RECOVERY transition: reward=0.0215 (scaled=0.0215), steps=0
Reward stats updated: mean 0.0156 -> 0.0156, std: 0.0883
Collected 503 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.7482, Q2 Loss=0.7482, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1907
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=1.8624, Q2 Loss=1.8624, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6586
SAC Update 3/5: Actor Loss=-0.0123, Q1 Loss=2.1928, Q2 Loss=2.1928, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3621
SAC Update 4/5: Actor Loss=-0.0088, Q1 Loss=0.9845, Q2 Loss=0.9845, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0786
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=0.8234, Q2 Loss=0.8234, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5038

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (37.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008826
Q1 loss: 1.322273
Q2 loss: 1.322273
Current threshold: -149.4986
Global Scale Offset: 4774.9511
Reward stats: mean=0.0156, std=0.0883, count=503
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.3223, Q2 Loss: 1.3223, Entropy: 0.6931, Mean TD Error: 1.9588, Threshold: -149.4986
Original likelihood: -129.33352661132812
Adjusted likelihood: -129.33352661132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Current yaw: tensor([-0.0722,  0.0303, -0.5033], device='cuda:1')
8 turn
Sampling time 3.836161808052566
tensor([ 0.0351,  0.6454,  0.4018,  0.5846, -0.0945,  0.5095,  0.8198,  1.0881,
         1.4121,  0.2674,  0.0994,  1.0317, -0.0722,  0.0303, -0.5033,  1.5171],
       device='cuda:1')
Original likelihood: -122.63111877441406
Adjusted likelihood: -122.63111877441406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5022)
Solve time for step 1 14.271860729029868
Current ori: tensor([-0.0722,  0.0303, -0.5033], device='cuda:1')
Middle force: tensor([1.0673, 0.6157, 0.7515, 0.6138, 0.5013, 0.5600, 0.7774, 0.5417, 0.7790,
        0.5367, 0.7566, 0.5533], device='cuda:1')
Thumb force: tensor([0.7286, 0.9962, 0.5550, 0.5743, 0.9575, 0.5098, 0.5481, 0.7180, 1.0719,
        0.7713, 1.6883, 0.5982], device='cuda:1')
Index force: tensor([1.2114, 0.5201, 0.9317, 0.5970, 0.5264, 0.5692, 0.5631, 0.5877, 0.5181,
        0.5588, 0.5210, 0.5649], device='cuda:1')
Storing NORMAL transition: reward=0.0969 (scaled=0.0969), steps=1
Reward stats updated: mean 0.0156 -> 0.0157, std: 0.0883
Collected 504 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=1.8843, Q2 Loss=1.8843, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6592
SAC Update 2/5: Actor Loss=-0.0093, Q1 Loss=1.6788, Q2 Loss=1.6788, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5050
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.8746, Q2 Loss=0.8746, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6678
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=1.5483, Q2 Loss=1.5483, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3685
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8849, Q2 Loss=0.8849, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9890

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (41.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008937
Q1 loss: 1.374177
Q2 loss: 1.374177
Current threshold: -149.4987
Global Scale Offset: 4786.2978
Reward stats: mean=0.0157, std=0.0883, count=504
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 1.3742, Q2 Loss: 1.3742, Entropy: 0.6931, Mean TD Error: 2.2379, Threshold: -149.4987
tensor([ 0.1380,  0.6211,  0.5881,  0.4840, -0.0326,  0.4867,  0.9227,  1.0494,
         1.4027,  0.2576,  0.0419,  1.0558, -0.0721, -0.0093, -0.6006,  0.8612],
       device='cuda:1')
Original likelihood: -129.217529296875
Adjusted likelihood: -129.217529296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5017)
State is out of distribution
Projection step: 0, Loss: 127.18988800048828
Projection step: 1, Loss: 118.3414306640625
Projection step: 2, Loss: 123.67845153808594
Projection step: 3, Loss: 116.44505310058594
Projection step: 4, Loss: 109.04194641113281
Projection step: 5, Loss: 106.16691589355469
Projection step: 6, Loss: 98.32450866699219
Final likelihood: tensor([-102.1186, -100.1016,  -94.6120,  -95.7236, -100.2002,  -96.6692,
        -103.0465, -102.2643,  -98.4235, -104.7263,  -96.5974,  -95.5530,
         -98.1138,  -95.2763,  -92.5769,  -97.1890])
Final projection likelihood: -98.3245
1 mode projection succeeded
New goal: tensor([ 0.1217,  0.6116,  0.5237,  0.5544, -0.0376,  0.4812,  0.8776,  1.0265,
         1.3904,  0.2745,  0.0723,  1.0517, -0.0710, -0.0061, -0.7277],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -113.14085388183594
Adjusted likelihood: -113.14085388183594
Likelihood residual: 0.0
Original likelihood: -140.902099609375
Adjusted likelihood: -140.902099609375
Likelihood residual: 0.0
{'index': 140.902099609375, 'thumb_middle': 113.14085388183594}
Current yaw: tensor([-0.0721, -0.0093, -0.6006], device='cuda:1')
9 thumb_middle
tensor([ 0.1380,  0.6211,  0.5881,  0.4840, -0.0326,  0.4867,  0.9227,  1.0494,
         1.4027,  0.2576,  0.0419,  1.0558, -0.0721, -0.0093, -0.6006,  0.8612],
       device='cuda:1')
Solve time for step 1 9.127884636982344
Current ori: tensor([-0.0721, -0.0093, -0.6006], device='cuda:1')
Index force: tensor([0.5956, 0.5888, 0.5915, 0.5004], device='cuda:1')
tensor([ 0.1376,  0.6407,  0.5301,  0.5543, -0.1327,  0.4625,  0.8593,  1.0228,
         1.3346,  0.2482,  0.0018,  1.0482, -0.0710, -0.0112, -0.6006,  0.8774],
       device='cuda:1')
Solve time for step 2 3.6773697499884292
Current ori: tensor([-0.0710, -0.0112, -0.6006], device='cuda:1')
Index force: tensor([0.5816, 0.5868, 0.4998], device='cuda:1')
tensor([ 0.1280,  0.6384,  0.5302,  0.5383, -0.1390,  0.4763,  0.8467,  1.0189,
         1.3401,  0.2653, -0.0033,  1.0246, -0.0720, -0.0045, -0.6006,  0.8604],
       device='cuda:1')
Solve time for step 3 3.671078058949206
Current ori: tensor([-0.0720, -0.0045, -0.6006], device='cuda:1')
Index force: tensor([0.6062, 0.5969], device='cuda:1')
tensor([ 0.1269,  0.6327,  0.5309,  0.5549, -0.1448,  0.4769,  0.8487,  1.0139,
         1.3433,  0.2583, -0.0021,  1.0235, -0.0695, -0.0039, -0.6006,  0.8644],
       device='cuda:1')
Solve time for step 4 3.4465477929916233
Current ori: tensor([-0.0695, -0.0039, -0.6006], device='cuda:1')
Index force: tensor([0.5716], device='cuda:1')
Storing RECOVERY transition: reward=0.0023 (scaled=0.0023), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0882
Collected 505 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.8388, Q2 Loss=0.8388, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3967
SAC Update 2/5: Actor Loss=-0.0077, Q1 Loss=1.1391, Q2 Loss=1.1391, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7691
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=1.0035, Q2 Loss=1.0035, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8666
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=0.7263, Q2 Loss=0.7263, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2696
SAC Update 5/5: Actor Loss=-0.0087, Q1 Loss=0.9265, Q2 Loss=0.9265, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7326

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (41.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008094
Q1 loss: 0.926856
Q2 loss: 0.926856
Current threshold: -149.4986
Global Scale Offset: 4804.7237
Reward stats: mean=0.0157, std=0.0882, count=505
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 0.9269, Q2 Loss: 0.9269, Entropy: 0.6931, Mean TD Error: 1.0069, Threshold: -149.4986
Original likelihood: -101.86354064941406
Adjusted likelihood: -101.86354064941406
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5040)
Current yaw: tensor([-0.0668,  0.0037, -0.6019], device='cuda:1')
10 turn
Sampling time 3.769997688999865
tensor([ 0.1099,  0.6220,  0.5262,  0.5610, -0.0800,  0.5286,  0.8777,  1.0194,
         1.4075,  0.2717,  0.0524,  1.0561, -0.0668,  0.0037, -0.6019,  0.8711],
       device='cuda:1')
Original likelihood: -106.64593505859375
Adjusted likelihood: -106.64593505859375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5036)
Solve time for step 1 14.154207799001597
Current ori: tensor([-0.0668,  0.0037, -0.6019], device='cuda:1')
Middle force: tensor([0.5384, 1.6827, 0.5149, 0.5846, 0.7107, 0.6341, 0.5138, 0.5160, 0.5235,
        0.5613, 0.5444, 0.6863], device='cuda:1')
Thumb force: tensor([0.6038, 2.0343, 0.7570, 1.2587, 0.5187, 0.5375, 0.5522, 0.8393, 0.5644,
        0.6540, 0.5778, 0.5228], device='cuda:1')
Index force: tensor([0.6387, 0.5759, 0.5993, 0.9652, 0.6129, 0.5894, 0.5050, 0.5819, 0.6438,
        0.6072, 0.5601, 0.5444], device='cuda:1')
Storing NORMAL transition: reward=0.0258 (scaled=0.0258), steps=1
Reward stats updated: mean 0.0157 -> 0.0157, std: 0.0881
Collected 506 transitions for RL
SAC Update 1/5: Actor Loss=-0.0097, Q1 Loss=1.1011, Q2 Loss=1.1011, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0346
SAC Update 2/5: Actor Loss=-0.0087, Q1 Loss=1.2042, Q2 Loss=1.2042, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9865
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=2.4711, Q2 Loss=2.4711, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0088
SAC Update 4/5: Actor Loss=-0.0110, Q1 Loss=1.2476, Q2 Loss=1.2476, Entropy=0.6928, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0639
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.7207, Q2 Loss=0.7207, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1142

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.6%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (41.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009295
Q1 loss: 1.348947
Q2 loss: 1.348947
Current threshold: -149.4984
Global Scale Offset: 4820.8491
Reward stats: mean=0.0157, std=0.0881, count=506
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.3489, Q2 Loss: 1.3489, Entropy: 0.6931, Mean TD Error: 1.0416, Threshold: -149.4984
tensor([ 0.0339,  0.5458,  0.5510,  0.5879, -0.0141,  0.6097,  0.7849,  1.1325,
         1.4590,  0.1261,  0.0161,  0.9541, -0.0651, -0.0497, -0.6301,  1.7574],
       device='cuda:1')
Original likelihood: -153.03268432617188
Adjusted likelihood: -153.03268432617188
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4997)
Solve time for step 2 5.259449826029595
Current ori: tensor([-0.0651, -0.0497, -0.6301], device='cuda:1')
Middle force: tensor([0.6269, 0.8915, 0.6942, 0.9651, 0.5944, 0.7021, 0.5473, 0.8474, 0.5704,
        0.5529, 0.5667], device='cuda:1')
Thumb force: tensor([0.9943, 0.5178, 1.0785, 0.5300, 0.6963, 0.5721, 0.5823, 0.9317, 0.6145,
        0.6607, 0.5638], device='cuda:1')
Index force: tensor([0.5152, 0.8315, 0.6748, 0.6583, 0.5952, 0.5767, 0.5959, 0.5675, 0.5898,
        0.5389, 0.5547], device='cuda:1')
Storing NORMAL transition: reward=-0.0337 (scaled=-0.0337), steps=1
Reward stats updated: mean 0.0157 -> 0.0156, std: 0.0880
Collected 507 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.8689, Q2 Loss=0.8689, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6120
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=1.2716, Q2 Loss=1.2716, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5771
SAC Update 3/5: Actor Loss=-0.0077, Q1 Loss=0.8620, Q2 Loss=0.8620, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2047
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=0.9855, Q2 Loss=0.9855, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5308
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=0.9171, Q2 Loss=0.9171, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5773

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.4%)
Actor update: 0.09s (38.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008500
Q1 loss: 0.981035
Q2 loss: 0.981035
Current threshold: -149.4982
Global Scale Offset: 4835.4686
Reward stats: mean=0.0156, std=0.0880, count=507
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9810, Q2 Loss: 0.9810, Entropy: 0.6931, Mean TD Error: 1.1004, Threshold: -149.4982
tensor([-0.0043,  0.5399,  0.5316,  0.6283,  0.0327,  0.5919,  0.8410,  1.0363,
         1.4532,  0.1960, -0.0026,  0.8307, -0.1206, -0.0766, -0.6091,  1.1574],
       device='cuda:1')
Original likelihood: -227.5872039794922
Adjusted likelihood: -227.5872039794922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4936)
State is out of distribution
Projection step: 0, Loss: 216.7098388671875
Projection step: 1, Loss: 214.52490234375
Projection step: 2, Loss: 213.70062255859375
Projection step: 3, Loss: 210.11436462402344
Projection step: 4, Loss: 203.86941528320312
Projection step: 5, Loss: 204.16685485839844
Projection step: 6, Loss: 207.6965789794922
Projection step: 7, Loss: 203.3743896484375
Projection step: 8, Loss: 196.8482208251953
Projection step: 9, Loss: 198.6363983154297
Projection step: 10, Loss: 198.1376495361328
Projection step: 11, Loss: 193.061767578125
Projection step: 12, Loss: 194.3583221435547
Projection step: 13, Loss: 190.3829345703125
Projection step: 14, Loss: 193.97543334960938
Projection step: 15, Loss: 192.27996826171875
Projection step: 16, Loss: 188.50538635253906
Projection step: 17, Loss: 188.52630615234375
Projection step: 18, Loss: 194.6789093017578
Projection step: 19, Loss: 184.94882202148438
Projection step: 20, Loss: 186.1961669921875
Projection step: 21, Loss: 184.31582641601562
Projection step: 22, Loss: 182.26654052734375
Projection step: 23, Loss: 181.9063720703125
Projection step: 24, Loss: 181.8746795654297
Final likelihood: tensor([-191.1709, -187.6764, -185.7320, -181.2176, -186.2510, -179.2957,
        -181.1843, -178.9856, -172.8275, -184.8925, -165.1754, -173.1786,
        -178.5438, -175.2748, -186.4981, -178.4218])
Final projection likelihood: -180.3954
1 mode projection failed, trying anyway
New goal: tensor([ 0.0407,  0.4562,  0.5904,  0.6577,  0.0098,  0.5973,  0.7797,  1.0600,
         1.4370,  0.1440,  0.0587,  0.8614, -0.1144, -0.0637, -0.1478],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0065]], device='cuda:1') tensor([[0.0068]], device='cuda:1')
Original likelihood: -206.83982849121094
Adjusted likelihood: -206.83982849121094
Likelihood residual: 0.0
Original likelihood: -216.23684692382812
Adjusted likelihood: -216.23684692382812
Likelihood residual: 0.0
{'index': 216.23684692382812, 'thumb_middle': 206.83982849121094}
Current yaw: tensor([-0.1206, -0.0766, -0.6091], device='cuda:1')
11 thumb_middle
tensor([-0.0043,  0.5399,  0.5316,  0.6283,  0.0327,  0.5919,  0.8410,  1.0363,
         1.4532,  0.1960, -0.0026,  0.8307, -0.1206, -0.0766, -0.6091,  1.1574],
       device='cuda:1')
Solve time for step 1 9.10572312399745
Current ori: tensor([-0.1206, -0.0766, -0.6091], device='cuda:1')
Index force: tensor([0.5992, 0.5982, 0.5903, 0.5811], device='cuda:1')
tensor([-0.0590,  0.5573,  0.6298,  0.6660, -0.0776,  0.5771,  0.7603,  1.0413,
         1.3992,  0.1416, -0.0412,  0.8209, -0.2051, -0.1264, -0.5558,  1.5543],
       device='cuda:1')
Solve time for step 2 3.5130332639673725
Current ori: tensor([-0.2051, -0.1264, -0.5558], device='cuda:1')
Index force: tensor([0.5891, 0.5868, 0.5711], device='cuda:1')
tensor([-0.0794,  0.6271,  0.6660,  0.6782, -0.0518,  0.6309,  0.7782,  1.0499,
         1.3731,  0.1265, -0.0805,  0.8064, -0.3221, -0.1737, -0.4511,  2.8409],
       device='cuda:1')
Solve time for step 3 3.5018361670081504
Current ori: tensor([-0.3221, -0.1737, -0.4511], device='cuda:1')
Index force: tensor([0.5654, 0.5559], device='cuda:1')
tensor([-0.1130,  0.7412,  0.7027,  0.6796, -0.0401,  0.6956,  0.7626,  1.0195,
         1.3716,  0.1208, -0.0546,  0.8172, -0.7167, -0.3191, -0.4219,  3.3277],
       device='cuda:1')
Solve time for step 4 3.303337842982728
Current ori: tensor([-0.7167, -0.3191, -0.4219], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-1.1507 (scaled=-0.5753), steps=2
Reward stats updated: mean 0.0156 -> 0.0145, std: 0.0918
Collected 508 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.9589, Q2 Loss=1.9589, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1368
SAC Update 2/5: Actor Loss=-0.0071, Q1 Loss=0.7367, Q2 Loss=0.7367, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5362
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=1.3003, Q2 Loss=1.3003, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7544
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=1.3251, Q2 Loss=1.3251, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0600
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7344, Q2 Loss=0.7344, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0039

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.3%)
Q1 update: 0.06s (19.7%)
Q2 update: 0.05s (18.2%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007973
Q1 loss: 1.211067
Q2 loss: 1.211067
Current threshold: -149.4981
Global Scale Offset: 4853.2903
Reward stats: mean=0.0145, std=0.0918, count=508
----------------------------------------------
SAC Update - Actor Loss: -0.0080, Q1 Loss: 1.2111, Q2 Loss: 1.2111, Entropy: 0.6931, Mean TD Error: 2.0983, Threshold: -149.4981
Original likelihood: -2342.29931640625
Adjusted likelihood: -2342.29931640625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3257)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 33
Loaded trajectory sampler
Current yaw: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
Current yaw: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
1 turn
Sampling time 3.5769253409816884
tensor([ 0.1323,  0.5807,  0.6197,  0.5498, -0.1228,  0.5549,  0.9078,  0.8641,
         1.2017,  0.3326,  0.2719,  1.1635, -0.0018,  0.0146, -0.0285,  0.2316],
       device='cuda:1')
Original likelihood: -92.71736145019531
Adjusted likelihood: -92.71736145019531
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5047)
State is out of distribution
Projection step: 0, Loss: 110.19734954833984
Projection step: 1, Loss: 95.29132843017578
Final likelihood: tensor([-109.1741, -121.0775,  -88.7400,  -75.8793,  -69.0313,  -71.8805,
         -98.5980, -129.6866,  -92.1915,  -78.3071, -107.3688, -100.4728,
         -86.0822,  -74.8312,  -94.9947, -126.3458])
Final projection likelihood: -95.2913
1 mode projection succeeded
New goal: tensor([ 0.1279,  0.5759,  0.6159,  0.5562, -0.1168,  0.5546,  0.9105,  0.8563,
         1.2121,  0.3343,  0.2731,  1.1600, -0.0016,  0.0145, -0.0225],
       device='cuda:1')
tensor([[0.0038]], device='cuda:1') tensor([[0.0011]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -118.55846405029297
Adjusted likelihood: -118.55846405029297
Likelihood residual: 0.0
Original likelihood: -117.52500915527344
Adjusted likelihood: -117.52500915527344
Likelihood residual: 0.0
{'index': 117.52500915527344, 'thumb_middle': 118.55846405029297}
Current yaw: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
2 index
tensor([ 0.1323,  0.5807,  0.6197,  0.5498, -0.1228,  0.5549,  0.9078,  0.8641,
         1.2017,  0.3326,  0.2719,  1.1635, -0.0018,  0.0146, -0.0285,  0.2316],
       device='cuda:1')
Solve time for step 1 10.718365437991451
Current ori: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
Middle force: tensor([0.5453, 0.5522, 0.5174, 0.5761], device='cuda:1')
Thumb force: tensor([0.6082, 0.5535, 0.5811, 0.6067], device='cuda:1')
tensor([ 0.1812,  0.5206,  0.5658,  0.5317, -0.1310,  0.5457,  0.9123,  0.8653,
         1.2180,  0.3223,  0.2785,  1.1387, -0.0045,  0.0119, -0.0560,  1.8555],
       device='cuda:1')
Solve time for step 2 4.2613809339818545
Current ori: tensor([-0.0045,  0.0119, -0.0560], device='cuda:1')
Middle force: tensor([0.5490, 0.5155, 0.5727], device='cuda:1')
Thumb force: tensor([0.5477, 0.5766, 0.6028], device='cuda:1')
tensor([ 0.1821,  0.5202,  0.5636,  0.5326, -0.1385,  0.5441,  0.9121,  0.8641,
         1.2383,  0.3026,  0.2741,  1.1293, -0.0066,  0.0164, -0.0658,  2.7237],
       device='cuda:1')
Solve time for step 3 4.2529781450284645
Current ori: tensor([-0.0066,  0.0164, -0.0658], device='cuda:1')
Middle force: tensor([0.5137, 0.5705], device='cuda:1')
Thumb force: tensor([0.5669, 0.5971], device='cuda:1')
tensor([ 0.1814,  0.5191,  0.5653,  0.5315, -0.1273,  0.5497,  0.9129,  0.8643,
         1.2348,  0.3031,  0.2583,  1.1414, -0.0081,  0.0086, -0.0735,  3.1737],
       device='cuda:1')
Solve time for step 4 3.836387181014288
Current ori: tensor([-0.0081,  0.0086, -0.0735], device='cuda:1')
Middle force: tensor([0.5022], device='cuda:1')
Thumb force: tensor([0.5103], device='cuda:1')
Storing RECOVERY transition: reward=0.0406 (scaled=0.0406), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0917
Collected 509 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=0.7947, Q2 Loss=0.7947, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5072
SAC Update 2/5: Actor Loss=-0.0097, Q1 Loss=1.0221, Q2 Loss=1.0221, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4298
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=0.9949, Q2 Loss=0.9949, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3977
SAC Update 4/5: Actor Loss=-0.0126, Q1 Loss=1.2860, Q2 Loss=1.2860, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4295
SAC Update 5/5: Actor Loss=-0.0123, Q1 Loss=1.9695, Q2 Loss=1.9695, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0892

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.5%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (38.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010350
Q1 loss: 1.213428
Q2 loss: 1.213428
Current threshold: -149.4982
Global Scale Offset: 4873.1467
Reward stats: mean=0.0145, std=0.0917, count=509
----------------------------------------------
SAC Update - Actor Loss: -0.0103, Q1 Loss: 1.2134, Q2 Loss: 1.2134, Entropy: 0.6931, Mean TD Error: 0.7707, Threshold: -149.4982
Original likelihood: -122.12565612792969
Adjusted likelihood: -122.12565612792969
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5022)
State is out of distribution
Projection step: 0, Loss: 120.59442138671875
Projection step: 1, Loss: 99.50071716308594
Final likelihood: tensor([-126.4509,  -93.6288,  -71.7160, -133.6134, -130.3619,  -77.5346,
        -117.9905,  -88.7262, -102.1219,  -71.7683,  -65.6378, -100.2773,
        -126.3597,  -87.4248, -115.8770,  -82.5224])
Final projection likelihood: -99.5007
1 mode projection succeeded
New goal: tensor([ 0.1267,  0.5811,  0.6099,  0.5525, -0.1130,  0.5643,  0.9096,  0.8511,
         1.2315,  0.3217,  0.2549,  1.1339, -0.0118,  0.0049, -0.1160],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -137.53012084960938
Adjusted likelihood: -137.53012084960938
Likelihood residual: 0.0
Original likelihood: -134.0170135498047
Adjusted likelihood: -134.0170135498047
Likelihood residual: 0.0
{'index': 134.0170135498047, 'thumb_middle': 137.53012084960938}
Current yaw: tensor([-0.0121,  0.0042, -0.0691], device='cuda:1')
3 index
tensor([ 0.1301,  0.5849,  0.6108,  0.5529, -0.1199,  0.5611,  0.9065,  0.8520,
         1.2239,  0.3159,  0.2581,  1.1379, -0.0121,  0.0042, -0.0691,  3.2543],
       device='cuda:1')
Solve time for step 1 10.63262001198018
Current ori: tensor([-0.0121,  0.0042, -0.0691], device='cuda:1')
Middle force: tensor([0.5105, 0.5313, 0.5713, 0.5539], device='cuda:1')
Thumb force: tensor([0.5581, 0.6033, 0.5904, 0.6470], device='cuda:1')
tensor([ 0.1819,  0.5245,  0.5637,  0.5280, -0.1326,  0.5733,  0.9108,  0.8548,
         1.2280,  0.3209,  0.2590,  1.1126, -0.0253,  0.0048, -0.0880,  4.4970],
       device='cuda:1')
Solve time for step 2 4.264296617999207
Current ori: tensor([-0.0253,  0.0048, -0.0880], device='cuda:1')
Middle force: tensor([0.5296, 0.5668, 0.5507], device='cuda:1')
Thumb force: tensor([0.5928, 0.5839, 0.6386], device='cuda:1')
tensor([ 1.8238e-01,  5.2672e-01,  5.5819e-01,  5.2734e-01, -1.2649e-01,
         5.6788e-01,  9.2271e-01,  8.5708e-01,  1.2480e+00,  2.9182e-01,
         2.3299e-01,  1.1268e+00, -2.4778e-02,  2.2906e-04, -1.0669e-01,
         5.2071e+00], device='cuda:1')
Solve time for step 3 4.169014363025781
Current ori: tensor([-0.0248,  0.0002, -0.1067], device='cuda:1')
Middle force: tensor([0.5608, 0.5465], device='cuda:1')
Thumb force: tensor([0.5782, 0.6329], device='cuda:1')
tensor([ 1.7894e-01,  5.2493e-01,  5.5717e-01,  5.2876e-01, -1.3367e-01,
         5.6441e-01,  9.1864e-01,  8.6670e-01,  1.2442e+00,  2.9893e-01,
         2.4663e-01,  1.1205e+00, -2.2594e-02,  4.9843e-03, -1.0195e-01,
         5.6366e+00], device='cuda:1')
Solve time for step 4 4.038321107975207
Current ori: tensor([-0.0226,  0.0050, -0.1019], device='cuda:1')
Middle force: tensor([0.5625], device='cuda:1')
Thumb force: tensor([0.5595], device='cuda:1')
Storing RECOVERY transition: reward=0.0782 (scaled=0.0782), steps=0
Reward stats updated: mean 0.0145 -> 0.0146, std: 0.0916
Collected 510 transitions for RL
SAC Update 1/5: Actor Loss=-0.0106, Q1 Loss=1.0904, Q2 Loss=1.0904, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2984
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=0.7809, Q2 Loss=0.7809, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9791
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.3258, Q2 Loss=1.3258, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3500
SAC Update 4/5: Actor Loss=-0.0139, Q1 Loss=1.5207, Q2 Loss=1.5207, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8344
SAC Update 5/5: Actor Loss=-0.0135, Q1 Loss=1.4918, Q2 Loss=1.4918, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7976

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.05s (18.3%)
Actor update: 0.10s (38.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011170
Q1 loss: 1.241928
Q2 loss: 1.241928
Current threshold: -149.4982
Global Scale Offset: 4894.7474
Reward stats: mean=0.0146, std=0.0916, count=510
----------------------------------------------
SAC Update - Actor Loss: -0.0112, Q1 Loss: 1.2419, Q2 Loss: 1.2419, Entropy: 0.6931, Mean TD Error: 0.8519, Threshold: -149.4982
Original likelihood: -124.86865997314453
Adjusted likelihood: -124.86865997314453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5020)
Current yaw: tensor([-0.0227,  0.0104, -0.1071], device='cuda:1')
4 turn
Sampling time 3.642300935985986
tensor([ 0.1202,  0.5852,  0.6022,  0.5493, -0.1423,  0.5593,  0.9207,  0.8691,
         1.2472,  0.3017,  0.2547,  1.1132, -0.0227,  0.0104, -0.1071,  5.7541],
       device='cuda:1')
Original likelihood: -128.1992950439453
Adjusted likelihood: -128.1992950439453
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5017)
State is out of distribution
Projection step: 0, Loss: 123.01983642578125
Projection step: 1, Loss: 118.724365234375
Projection step: 2, Loss: 119.20426940917969
Projection step: 3, Loss: 109.4747085571289
Projection step: 4, Loss: 101.30975341796875
Final likelihood: tensor([ -86.6799, -110.3250,  -67.8523, -121.4086, -107.3150,  -73.4986,
        -125.1455, -114.2685, -118.2501,  -78.9478,  -90.6025, -118.3132,
         -88.0384,  -87.6522, -106.9428, -125.7158])
Final projection likelihood: -101.3098
1 mode projection succeeded
New goal: tensor([ 0.1114,  0.5680,  0.6022,  0.5514, -0.1151,  0.5625,  0.9255,  0.8625,
         1.2660,  0.3086,  0.2391,  1.1029, -0.0225,  0.0122, -0.1150],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -129.4900360107422
Adjusted likelihood: -129.4900360107422
Likelihood residual: 0.0
Original likelihood: -117.36669158935547
Adjusted likelihood: -117.36669158935547
Likelihood residual: 0.0
{'index': 117.36669158935547, 'thumb_middle': 129.4900360107422}
Current yaw: tensor([-0.0227,  0.0104, -0.1071], device='cuda:1')
5 index
tensor([ 0.1202,  0.5852,  0.6022,  0.5493, -0.1423,  0.5593,  0.9207,  0.8691,
         1.2472,  0.3017,  0.2547,  1.1132, -0.0227,  0.0104, -0.1071,  5.7541],
       device='cuda:1')
Solve time for step 1 10.703262183000334
Current ori: tensor([-0.0227,  0.0104, -0.1071], device='cuda:1')
Middle force: tensor([0.5014, 0.5617, 0.5140, 0.5835], device='cuda:1')
Thumb force: tensor([0.5602, 0.5578, 0.5006, 0.5526], device='cuda:1')
tensor([ 0.1660,  0.5169,  0.5556,  0.5290, -0.1420,  0.5628,  0.9272,  0.8629,
         1.2555,  0.3024,  0.2394,  1.1031, -0.0335,  0.0081, -0.1358, -6.0713],
       device='cuda:1')
Solve time for step 2 4.265269413997885
Current ori: tensor([-0.0335,  0.0081, -0.1358], device='cuda:1')
Middle force: tensor([0.5543, 0.5077, 0.5012], device='cuda:1')
Thumb force: tensor([0.5687, 0.5016, 0.5091], device='cuda:1')
tensor([ 0.1627,  0.5154,  0.5513,  0.5267, -0.1436,  0.5602,  0.9276,  0.8665,
         1.2606,  0.2950,  0.2378,  1.1061, -0.0320,  0.0092, -0.1343, -5.4690],
       device='cuda:1')
Solve time for step 3 4.054406212992035
Current ori: tensor([-0.0320,  0.0092, -0.1343], device='cuda:1')
Middle force: tensor([0.5160, 0.5257], device='cuda:1')
Thumb force: tensor([0.5473, 0.5015], device='cuda:1')
tensor([ 0.1608,  0.5134,  0.5516,  0.5256, -0.1405,  0.5611,  0.9288,  0.8672,
         1.2611,  0.2929,  0.2322,  1.1096, -0.0323,  0.0069, -0.1382, -4.9615],
       device='cuda:1')
Solve time for step 4 4.0143188899965025
Current ori: tensor([-0.0323,  0.0069, -0.1382], device='cuda:1')
Middle force: tensor([0.5001], device='cuda:1')
Thumb force: tensor([0.5039], device='cuda:1')
Storing RECOVERY transition: reward=0.0267 (scaled=0.0267), steps=0
Reward stats updated: mean 0.0146 -> 0.0147, std: 0.0916
Collected 511 transitions for RL
SAC Update 1/5: Actor Loss=-0.0121, Q1 Loss=1.2202, Q2 Loss=1.2202, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3782
SAC Update 2/5: Actor Loss=-0.0122, Q1 Loss=1.3953, Q2 Loss=1.3953, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9997
SAC Update 3/5: Actor Loss=-0.0102, Q1 Loss=1.0299, Q2 Loss=1.0299, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1829
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=0.9294, Q2 Loss=0.9294, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6059
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=1.0627, Q2 Loss=1.0627, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6355

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010064
Q1 loss: 1.127485
Q2 loss: 1.127485
Current threshold: -149.4979
Global Scale Offset: 4909.0644
Reward stats: mean=0.0147, std=0.0916, count=511
----------------------------------------------
SAC Update - Actor Loss: -0.0101, Q1 Loss: 1.1275, Q2 Loss: 1.1275, Entropy: 0.6931, Mean TD Error: 0.9604, Threshold: -149.4979
Original likelihood: -125.11534881591797
Adjusted likelihood: -125.11534881591797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 117.65090942382812
Projection step: 1, Loss: 111.77325439453125
Projection step: 2, Loss: 105.53411865234375
Projection step: 3, Loss: 109.1526870727539
Projection step: 4, Loss: 103.16624450683594
Final likelihood: tensor([-105.2994,  -86.0170, -105.5022, -110.9585, -114.4134,  -84.4322,
        -106.4694, -104.8820, -121.0374,  -95.9167, -123.7085,  -84.1990,
         -96.5223, -107.1126, -110.9366,  -93.2527])
Final projection likelihood: -103.1662
1 mode projection succeeded
New goal: tensor([ 0.0983,  0.5659,  0.5888,  0.5607, -0.1165,  0.5677,  0.9296,  0.8437,
         1.2850,  0.2973,  0.2190,  1.1139, -0.0352,  0.0089, -0.1567],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -123.051513671875
Adjusted likelihood: -123.051513671875
Likelihood residual: 0.0
Original likelihood: -132.62039184570312
Adjusted likelihood: -132.62039184570312
Likelihood residual: 0.0
{'index': 132.62039184570312, 'thumb_middle': 123.051513671875}
Current yaw: tensor([-0.0354,  0.0072, -0.1345], device='cuda:1')
6 thumb_middle
tensor([ 0.1053,  0.5790,  0.5970,  0.5467, -0.1402,  0.5678,  0.9222,  0.8595,
         1.2642,  0.2907,  0.2306,  1.1057, -0.0354,  0.0072, -0.1345, -4.8375],
       device='cuda:1')
Solve time for step 1 9.128589315048885
Current ori: tensor([-0.0354,  0.0072, -0.1345], device='cuda:1')
Index force: tensor([0.5591, 0.6025, 0.5771, 0.5974], device='cuda:1')
tensor([ 0.0861,  0.5862,  0.5745,  0.5322, -0.2262,  0.5305,  0.8883,  0.8242,
         1.2367,  0.2747,  0.1502,  1.0848, -0.0383,  0.0194, -0.1346, -4.8726],
       device='cuda:1')
Solve time for step 2 3.665524288022425
Current ori: tensor([-0.0383,  0.0194, -0.1346], device='cuda:1')
Index force: tensor([0.5948, 0.5722, 0.5915], device='cuda:1')
tensor([ 0.0907,  0.5818,  0.5797,  0.5446, -0.2330,  0.5391,  0.8877,  0.8208,
         1.2435,  0.2758,  0.1370,  1.0815, -0.0364,  0.0164, -0.1346, -4.8617],
       device='cuda:1')
Solve time for step 3 3.5952919449773617
Current ori: tensor([-0.0364,  0.0164, -0.1346], device='cuda:1')
Index force: tensor([0.5602, 0.5797], device='cuda:1')
tensor([ 0.1039,  0.5752,  0.5919,  0.5644, -0.2261,  0.5417,  0.8921,  0.8219,
         1.2375,  0.2737,  0.1330,  1.0819, -0.0332,  0.0086, -0.1346, -4.8363],
       device='cuda:1')
Solve time for step 4 3.4528940049931407
Current ori: tensor([-0.0332,  0.0086, -0.1346], device='cuda:1')
Index force: tensor([0.5473], device='cuda:1')
Storing RECOVERY transition: reward=0.0222 (scaled=0.0222), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0915
Collected 512 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.9066, Q2 Loss=1.9066, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9117
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=0.9331, Q2 Loss=0.9331, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3917
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=0.8174, Q2 Loss=0.8174, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8377
SAC Update 4/5: Actor Loss=-0.0121, Q1 Loss=1.6368, Q2 Loss=1.6368, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5551
SAC Update 5/5: Actor Loss=-0.0100, Q1 Loss=1.0799, Q2 Loss=1.0799, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7728

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.0%)
Q1 update: 0.06s (20.1%)
Q2 update: 0.06s (20.5%)
Actor update: 0.11s (41.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009320
Q1 loss: 1.274760
Q2 loss: 1.274760
Current threshold: -149.4977
Global Scale Offset: 4926.6126
Reward stats: mean=0.0147, std=0.0915, count=512
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.2748, Q2 Loss: 1.2748, Entropy: 0.6931, Mean TD Error: 1.8938, Threshold: -149.4977
Original likelihood: -113.66609954833984
Adjusted likelihood: -113.66609954833984
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5029)
State is out of distribution
Projection step: 0, Loss: 117.9844970703125
Projection step: 1, Loss: 106.27254486083984
Projection step: 2, Loss: 102.53477478027344
Final likelihood: tensor([ -91.5740, -108.5613, -118.6372, -114.2614, -117.3385,  -86.2485,
         -93.8962,  -97.1966, -118.1129, -111.1295,  -84.6257,  -91.7885,
        -113.0396, -112.6211,  -93.3429,  -88.1826])
Final projection likelihood: -102.5348
1 mode projection succeeded
New goal: tensor([ 0.0921,  0.5560,  0.5938,  0.5687, -0.1554,  0.5897,  0.9407,  0.8203,
         1.2963,  0.3072,  0.1978,  1.1295, -0.0303,  0.0152, -0.1024],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -120.84126281738281
Adjusted likelihood: -120.84126281738281
Likelihood residual: 0.0
Original likelihood: -126.37309265136719
Adjusted likelihood: -126.37309265136719
Likelihood residual: 0.0
{'index': 126.37309265136719, 'thumb_middle': 120.84126281738281}
Current yaw: tensor([-0.0304,  0.0146, -0.1299], device='cuda:1')
7 thumb_middle
tensor([ 0.0935,  0.5628,  0.5988,  0.5641, -0.1693,  0.5917,  0.9310,  0.8250,
         1.2915,  0.3134,  0.1967,  1.1183, -0.0304,  0.0146, -0.1299, -4.8439],
       device='cuda:1')
Solve time for step 1 9.117427340999711
Current ori: tensor([-0.0304,  0.0146, -0.1299], device='cuda:1')
Index force: tensor([0.5845, 0.5813, 0.5778, 0.5004], device='cuda:1')
tensor([ 0.1009,  0.5897,  0.5794,  0.5444, -0.2436,  0.5655,  0.9054,  0.8041,
         1.2440,  0.2846,  0.1153,  1.0981, -0.0381,  0.0099, -0.1299, -4.8538],
       device='cuda:1')
Solve time for step 2 3.668171903991606
Current ori: tensor([-0.0381,  0.0099, -0.1299], device='cuda:1')
Index force: tensor([0.5719, 0.5673, 0.5000], device='cuda:1')
tensor([ 0.0951,  0.5973,  0.5688,  0.5255, -0.2515,  0.5702,  0.9108,  0.7866,
         1.2546,  0.2820,  0.1036,  1.0999, -0.0413,  0.0140, -0.1299, -4.8711],
       device='cuda:1')
Solve time for step 3 3.555413876019884
Current ori: tensor([-0.0413,  0.0140, -0.1299], device='cuda:1')
Index force: tensor([0.5519, 0.5000], device='cuda:1')
tensor([ 0.0900,  0.5769,  0.5916,  0.5332, -0.2526,  0.5618,  0.9097,  0.8042,
         1.2540,  0.2873,  0.1094,  1.1017, -0.0362,  0.0170, -0.1299, -4.8697],
       device='cuda:1')
Solve time for step 4 3.4473745180293918
Current ori: tensor([-0.0362,  0.0170, -0.1299], device='cuda:1')
Index force: tensor([0.5538], device='cuda:1')
Storing RECOVERY transition: reward=0.0070 (scaled=0.0070), steps=0
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0914
Collected 513 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.9923, Q2 Loss=0.9923, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0436
SAC Update 2/5: Actor Loss=-0.0111, Q1 Loss=1.1353, Q2 Loss=1.1353, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2008
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.3645, Q2 Loss=1.3645, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0090
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.7475, Q2 Loss=0.7475, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2907
SAC Update 5/5: Actor Loss=-0.0101, Q1 Loss=2.5124, Q2 Loss=2.5124, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4487

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.6%)
Q2 update: 0.04s (19.1%)
Actor update: 0.08s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009143
Q1 loss: 1.350397
Q2 loss: 1.350397
Current threshold: -149.4977
Global Scale Offset: 4953.7627
Reward stats: mean=0.0147, std=0.0914, count=513
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.3504, Q2 Loss: 1.3504, Entropy: 0.6931, Mean TD Error: 1.5985, Threshold: -149.4977
Original likelihood: -158.52474975585938
Adjusted likelihood: -158.52474975585938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4993)
Current yaw: tensor([-0.0253,  0.0302, -0.1150], device='cuda:1')
8 turn
Sampling time 3.607667995034717
tensor([ 0.0681,  0.5410,  0.6038,  0.5649, -0.2098,  0.6031,  0.9333,  0.8208,
         1.3213,  0.3105,  0.1823,  1.1339, -0.0253,  0.0302, -0.1150, -4.8893],
       device='cuda:1')
Original likelihood: -148.90902709960938
Adjusted likelihood: -148.90902709960938
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5000)
Solve time for step 1 14.295697371009737
Current ori: tensor([-0.0253,  0.0302, -0.1150], device='cuda:1')
Middle force: tensor([0.5599, 0.5842, 0.5897, 1.8326, 0.5922, 1.2296, 0.5113, 0.6025, 0.9425,
        0.6062, 0.6195, 0.6102], device='cuda:1')
Thumb force: tensor([0.5830, 0.7838, 0.6189, 1.4686, 0.5467, 0.7850, 0.5631, 0.5197, 0.9017,
        0.5957, 0.5880, 0.6048], device='cuda:1')
Index force: tensor([0.7353, 0.5038, 0.5183, 0.5312, 0.5731, 0.6134, 0.7126, 0.6233, 0.5638,
        0.5701, 0.5647, 0.5990], device='cuda:1')
Storing NORMAL transition: reward=0.0810 (scaled=0.0810), steps=1
Reward stats updated: mean 0.0147 -> 0.0148, std: 0.0913
Collected 514 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7338, Q2 Loss=0.7338, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4463
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.9068, Q2 Loss=0.9068, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9659
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=0.9260, Q2 Loss=0.9260, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4767
SAC Update 4/5: Actor Loss=-0.0092, Q1 Loss=0.9731, Q2 Loss=0.9731, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8308
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=1.0122, Q2 Loss=1.0122, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8554

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.6%)
Q1 update: 0.04s (19.9%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008450
Q1 loss: 0.910382
Q2 loss: 0.910382
Current threshold: -149.4977
Global Scale Offset: 4977.0909
Reward stats: mean=0.0148, std=0.0913, count=514
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9104, Q2 Loss: 0.9104, Entropy: 0.6931, Mean TD Error: 0.9150, Threshold: -149.4977
tensor([ 0.0807,  0.5397,  0.5993,  0.6001, -0.2050,  0.5866,  0.9351,  0.9016,
         1.3242,  0.3071,  0.1871,  1.0911, -0.0228,  0.0237, -0.1958, -4.7838],
       device='cuda:1')
Original likelihood: -140.82794189453125
Adjusted likelihood: -140.82794189453125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5007)
Solve time for step 2 5.642700602009427
Current ori: tensor([-0.0228,  0.0237, -0.1958], device='cuda:1')
Middle force: tensor([0.5861, 0.5810, 1.8074, 0.5799, 1.2000, 0.5997, 0.5491, 0.8689, 0.6077,
        0.6134, 0.5897], device='cuda:1')
Thumb force: tensor([0.7830, 0.6075, 1.4143, 0.5357, 0.7555, 0.5866, 0.5886, 1.1593, 0.6043,
        0.5706, 0.5676], device='cuda:1')
Index force: tensor([0.5001, 0.5178, 0.5245, 0.5718, 0.6170, 0.5844, 0.6768, 0.5604, 0.6004,
        0.5833, 0.5850], device='cuda:1')
Storing NORMAL transition: reward=0.0555 (scaled=0.0555), steps=1
Reward stats updated: mean 0.0148 -> 0.0149, std: 0.0913
Collected 515 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=1.4047, Q2 Loss=1.4047, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3206
SAC Update 2/5: Actor Loss=-0.0089, Q1 Loss=2.3566, Q2 Loss=2.3566, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.8824
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=1.4228, Q2 Loss=1.4228, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1775
SAC Update 4/5: Actor Loss=-0.0097, Q1 Loss=1.1303, Q2 Loss=1.1303, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1283
SAC Update 5/5: Actor Loss=-0.0120, Q1 Loss=2.9160, Q2 Loss=2.9160, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1790

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010182
Q1 loss: 1.846093
Q2 loss: 1.846093
Current threshold: -149.4977
Global Scale Offset: 5005.5127
Reward stats: mean=0.0149, std=0.0913, count=515
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.8461, Q2 Loss: 1.8461, Entropy: 0.6931, Mean TD Error: 2.1376, Threshold: -149.4977
tensor([ 0.1395,  0.5108,  0.6736,  0.6352, -0.2355,  0.4795,  1.0456,  0.9928,
         1.2547,  0.3505,  0.3115,  1.0432,  0.0211,  0.0322, -0.2519, -5.3305],
       device='cuda:1')
Original likelihood: -214.60252380371094
Adjusted likelihood: -214.60252380371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4948)
Solve time for step 3 5.272980134002864
Current ori: tensor([ 0.0211,  0.0322, -0.2519], device='cuda:1')
Middle force: tensor([0.5633, 1.7628, 0.5689, 1.1832, 0.5956, 0.5319, 0.8392, 0.5985, 0.6088,
        0.5850], device='cuda:1')
Thumb force: tensor([0.6176, 1.3796, 0.5367, 0.7390, 0.5834, 0.6306, 1.1426, 0.6038, 0.5657,
        0.5629], device='cuda:1')
Index force: tensor([0.5153, 0.5231, 0.5658, 0.6067, 0.5792, 0.6442, 0.5571, 0.5936, 0.5784,
        0.5799], device='cuda:1')
Storing NORMAL transition: reward=-0.0690 (scaled=-0.0690), steps=1
Reward stats updated: mean 0.0149 -> 0.0147, std: 0.0912
Collected 516 transitions for RL
SAC Update 1/5: Actor Loss=-0.0071, Q1 Loss=0.7331, Q2 Loss=0.7331, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4593
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=1.4481, Q2 Loss=1.4481, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2014
SAC Update 3/5: Actor Loss=-0.0085, Q1 Loss=0.9630, Q2 Loss=0.9630, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3069
SAC Update 4/5: Actor Loss=-0.0108, Q1 Loss=1.1929, Q2 Loss=1.1929, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8657
SAC Update 5/5: Actor Loss=-0.0112, Q1 Loss=1.4312, Q2 Loss=1.4312, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4374

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.4%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (42.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009945
Q1 loss: 1.153647
Q2 loss: 1.153647
Current threshold: -149.4975
Global Scale Offset: 5032.0525
Reward stats: mean=0.0147, std=0.0912, count=516
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.1536, Q2 Loss: 1.1536, Entropy: 0.6931, Mean TD Error: 1.0542, Threshold: -149.4975
tensor([ 1.3393e-01,  5.9672e-01,  5.5596e-01,  6.3407e-01, -1.9611e-01,
         5.6953e-01,  9.1847e-01,  9.7550e-01,  1.2859e+00,  3.0386e-01,
         2.6321e-01,  1.0395e+00, -1.9601e-04,  1.9391e-02, -1.8143e-01,
        -5.1934e+00], device='cuda:1')
Original likelihood: -155.14759826660156
Adjusted likelihood: -155.14759826660156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4996)
Solve time for step 4 5.164962150971405
Current ori: tensor([-0.0002,  0.0194, -0.1814], device='cuda:1')
Middle force: tensor([1.7232, 0.5654, 1.1495, 0.5922, 0.5292, 0.8229, 0.5932, 0.6030, 0.5793],
       device='cuda:1')
Thumb force: tensor([1.3340, 0.5332, 0.7271, 0.5793, 0.6166, 1.1160, 0.5984, 0.5614, 0.5586],
       device='cuda:1')
Index force: tensor([0.5195, 0.5623, 0.6016, 0.5742, 0.6422, 0.5536, 0.5890, 0.5747, 0.5762],
       device='cuda:1')
Storing NORMAL transition: reward=0.2243 (scaled=0.2243), steps=1
Reward stats updated: mean 0.0147 -> 0.0151, std: 0.0916
Collected 517 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.9002, Q2 Loss=0.9002, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7972
SAC Update 2/5: Actor Loss=-0.0104, Q1 Loss=2.9824, Q2 Loss=2.9824, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4400
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=3.1687, Q2 Loss=3.1687, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.9728
SAC Update 4/5: Actor Loss=-0.0120, Q1 Loss=1.2517, Q2 Loss=1.2517, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5009
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7236, Q2 Loss=0.7236, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1128

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (19.3%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (18.0%)
Actor update: 0.09s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009686
Q1 loss: 1.805322
Q2 loss: 1.805322
Current threshold: -149.4975
Global Scale Offset: 5057.5180
Reward stats: mean=0.0151, std=0.0916, count=517
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.8053, Q2 Loss: 1.8053, Entropy: 0.6931, Mean TD Error: 1.5647, Threshold: -149.4975
tensor([ 0.1138,  0.4872,  0.5237,  0.5282, -0.1274,  0.5041,  1.0478,  1.0389,
         1.3416,  0.1965,  0.1491,  1.0676,  0.0055, -0.0287, -0.4072, -5.1156],
       device='cuda:1')
Original likelihood: -178.61306762695312
Adjusted likelihood: -178.61306762695312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4977)
Solve time for step 5 4.814711551996879
Current ori: tensor([ 0.0055, -0.0287, -0.4072], device='cuda:1')
Middle force: tensor([0.5242, 0.8043, 0.5193, 0.5070, 0.7256, 0.6024, 0.6287, 0.5366],
       device='cuda:1')
Thumb force: tensor([0.6058, 1.1530, 0.5193, 0.5180, 0.5005, 0.5637, 0.5367, 0.9011],
       device='cuda:1')
Index force: tensor([0.5501, 0.7864, 0.5158, 0.5419, 0.5310, 0.5545, 0.5389, 0.5245],
       device='cuda:1')
Storing NORMAL transition: reward=0.0995 (scaled=0.0995), steps=1
Reward stats updated: mean 0.0151 -> 0.0153, std: 0.0916
Collected 518 transitions for RL
SAC Update 1/5: Actor Loss=-0.0107, Q1 Loss=1.1113, Q2 Loss=1.1113, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5065
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=1.0315, Q2 Loss=1.0315, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0405
SAC Update 3/5: Actor Loss=-0.0111, Q1 Loss=3.1936, Q2 Loss=3.1936, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.7476
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.7784, Q2 Loss=0.7784, Entropy=0.6928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5947
SAC Update 5/5: Actor Loss=-0.0116, Q1 Loss=1.2140, Q2 Loss=1.2140, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5205

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (19.7%)
Actor update: 0.09s (40.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010046
Q1 loss: 1.465753
Q2 loss: 1.465753
Current threshold: -149.4976
Global Scale Offset: 5076.7501
Reward stats: mean=0.0153, std=0.0916, count=518
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.4658, Q2 Loss: 1.4658, Entropy: 0.6931, Mean TD Error: 1.2820, Threshold: -149.4976
tensor([ 0.0284,  0.5213,  0.5753,  0.5934, -0.1496,  0.4956,  1.0397,  1.0450,
         1.4125,  0.1244,  0.1943,  0.9136, -0.0147, -0.0061, -0.5058, -5.1022],
       device='cuda:1')
Original likelihood: -139.66993713378906
Adjusted likelihood: -139.66993713378906
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5008)
State is out of distribution
Projection step: 0, Loss: 143.74102783203125
Projection step: 1, Loss: 141.46307373046875
Projection step: 2, Loss: 121.96809387207031
Projection step: 3, Loss: 120.04264831542969
Projection step: 4, Loss: 113.86621856689453
Projection step: 5, Loss: 107.29885864257812
Projection step: 6, Loss: 100.97344970703125
Final likelihood: tensor([ -80.2924, -110.2803,  -92.7763, -102.9982, -101.7477, -106.8863,
        -100.7882,  -86.7316,  -99.8267, -107.3842, -101.5842, -107.5456,
        -103.6329, -104.6064,  -99.5404, -108.9539])
Final projection likelihood: -100.9734
1 mode projection succeeded
New goal: tensor([ 0.0307,  0.5349,  0.5818,  0.5744, -0.1026,  0.4989,  0.9664,  0.9614,
         1.3931,  0.1415,  0.2110,  0.8816, -0.0159, -0.0039, -0.4517],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -111.73957061767578
Adjusted likelihood: -111.73957061767578
Likelihood residual: 0.0
Original likelihood: -143.416015625
Adjusted likelihood: -143.416015625
Likelihood residual: 0.0
{'index': 143.416015625, 'thumb_middle': 111.73957061767578}
Current yaw: tensor([-0.0147, -0.0061, -0.5058], device='cuda:1')
9 thumb_middle
tensor([ 0.0284,  0.5213,  0.5753,  0.5934, -0.1496,  0.4956,  1.0397,  1.0450,
         1.4125,  0.1244,  0.1943,  0.9136, -0.0147, -0.0061, -0.5058, -5.1022],
       device='cuda:1')
Solve time for step 1 9.196716313017532
Current ori: tensor([-0.0147, -0.0061, -0.5058], device='cuda:1')
Index force: tensor([0.5884, 0.5967, 0.6039, 0.5025], device='cuda:1')
tensor([ 0.0475,  0.5185,  0.5936,  0.5990, -0.1929,  0.4828,  0.9438,  0.9549,
         1.3502,  0.1182,  0.1360,  0.8600, -0.0108, -0.0174, -0.5059, -5.0713],
       device='cuda:1')
Solve time for step 2 3.596063036005944
Current ori: tensor([-0.0108, -0.0174, -0.5059], device='cuda:1')
Index force: tensor([0.5737, 0.5497, 0.5680], device='cuda:1')
tensor([ 0.0632,  0.5301,  0.5935,  0.5962, -0.1885,  0.5072,  0.9356,  0.9419,
         1.3414,  0.1111,  0.1292,  0.8578, -0.0130, -0.0266, -0.5059, -5.0539],
       device='cuda:1')
Solve time for step 3 3.3919613340403885
Current ori: tensor([-0.0130, -0.0266, -0.5059], device='cuda:1')
Index force: tensor([0.5409, 0.5588], device='cuda:1')
tensor([ 0.0421,  0.5287,  0.5836,  0.5812, -0.1941,  0.4979,  0.9287,  0.9246,
         1.3546,  0.1118,  0.1412,  0.8383, -0.0156, -0.0145, -0.5059, -5.0882],
       device='cuda:1')
Solve time for step 4 3.403471730009187
Current ori: tensor([-0.0156, -0.0145, -0.5059], device='cuda:1')
Index force: tensor([0.5619], device='cuda:1')
Storing RECOVERY transition: reward=-0.0040 (scaled=-0.0008), steps=5
Reward stats updated: mean 0.0153 -> 0.0152, std: 0.0915
Collected 519 transitions for RL
SAC Update 1/5: Actor Loss=-0.0076, Q1 Loss=2.0394, Q2 Loss=2.0394, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5289
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=0.9379, Q2 Loss=0.9379, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3748
SAC Update 3/5: Actor Loss=-0.0135, Q1 Loss=1.3684, Q2 Loss=1.3684, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1586
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=0.9548, Q2 Loss=0.9548, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2711
SAC Update 5/5: Actor Loss=-0.0102, Q1 Loss=1.1880, Q2 Loss=1.1880, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0724

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.04s (17.6%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009982
Q1 loss: 1.297708
Q2 loss: 1.297708
Current threshold: -149.4978
Global Scale Offset: 5097.8025
Reward stats: mean=0.0152, std=0.0915, count=519
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.2977, Q2 Loss: 1.2977, Entropy: 0.6931, Mean TD Error: 1.4812, Threshold: -149.4978
Original likelihood: -131.51016235351562
Adjusted likelihood: -131.51016235351562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5014)
Current yaw: tensor([-0.0139, -0.0033, -0.5016], device='cuda:1')
10 turn
Sampling time 3.6088401149609126
tensor([ 1.9561e-02,  5.3420e-01,  5.5640e-01,  5.8027e-01, -1.3465e-01,
         5.2974e-01,  9.6042e-01,  9.4519e-01,  1.4250e+00,  1.2857e-01,
         1.9848e-01,  8.8751e-01, -1.3868e-02, -3.2746e-03, -5.0164e-01,
        -5.0971e+00], device='cuda:1')
Original likelihood: -126.11117553710938
Adjusted likelihood: -126.11117553710938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5018)
State is out of distribution
Projection step: 0, Loss: 128.60494995117188
Projection step: 1, Loss: 118.03653717041016
Projection step: 2, Loss: 109.15293884277344
Projection step: 3, Loss: 101.78564453125
Final likelihood: tensor([-104.3707,  -96.1718, -104.4813, -103.2840, -100.6911, -100.7123,
        -101.9231,  -97.9453, -105.8947, -101.7787, -101.2747, -105.5170,
         -99.1665,  -98.9740, -100.3263, -106.0587])
Final projection likelihood: -101.7857
1 mode projection succeeded
New goal: tensor([ 0.0206,  0.5444,  0.5600,  0.5659, -0.1102,  0.5331,  0.9318,  0.9024,
         1.4091,  0.1310,  0.2068,  0.8862, -0.0145, -0.0025, -0.5240],
       device='cuda:1')
tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -106.33554077148438
Adjusted likelihood: -106.33554077148438
Likelihood residual: 0.0
Original likelihood: -126.21832275390625
Adjusted likelihood: -126.21832275390625
Likelihood residual: 0.0
{'index': 126.21832275390625, 'thumb_middle': 106.33554077148438}
Current yaw: tensor([-0.0139, -0.0033, -0.5016], device='cuda:1')
11 thumb_middle
tensor([ 1.9561e-02,  5.3420e-01,  5.5640e-01,  5.8027e-01, -1.3465e-01,
         5.2974e-01,  9.6042e-01,  9.4519e-01,  1.4250e+00,  1.2857e-01,
         1.9848e-01,  8.8751e-01, -1.3868e-02, -3.2746e-03, -5.0164e-01,
        -5.0971e+00], device='cuda:1')
Solve time for step 1 9.254394048009999
Current ori: tensor([-0.0139, -0.0033, -0.5016], device='cuda:1')
Index force: tensor([0.5664, 0.5796, 0.5814, 0.5744], device='cuda:1')
tensor([ 1.7155e-02,  5.3959e-01,  5.4980e-01,  5.7336e-01, -2.0351e-01,
         5.1072e-01,  8.9361e-01,  8.8601e-01,  1.3659e+00,  1.1787e-01,
         1.4489e-01,  8.5949e-01, -1.9061e-02, -1.1843e-03, -5.0159e-01,
        -5.1190e+00], device='cuda:1')
Solve time for step 2 3.632765762042254
Current ori: tensor([-0.0191, -0.0012, -0.5016], device='cuda:1')
Index force: tensor([0.5686, 0.5716, 0.5659], device='cuda:1')
tensor([ 0.0243,  0.5421,  0.5576,  0.5644, -0.2029,  0.5240,  0.8944,  0.8802,
         1.3635,  0.1109,  0.1304,  0.8647, -0.0203, -0.0054, -0.5016, -5.1120],
       device='cuda:1')
Solve time for step 3 3.531814455986023
Current ori: tensor([-0.0203, -0.0054, -0.5016], device='cuda:1')
Index force: tensor([0.5590, 0.5555], device='cuda:1')
tensor([ 0.0265,  0.5365,  0.5577,  0.5832, -0.2085,  0.5275,  0.8994,  0.8859,
         1.3704,  0.0962,  0.1319,  0.8531, -0.0168, -0.0066, -0.5016, -5.1009],
       device='cuda:1')
Solve time for step 4 3.4309176019742154
Current ori: tensor([-0.0168, -0.0066, -0.5016], device='cuda:1')
Index force: tensor([0.5404], device='cuda:1')
Storing RECOVERY transition: reward=0.0005 (scaled=0.0005), steps=0
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0914
Collected 520 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=0.9355, Q2 Loss=0.9355, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1204
SAC Update 2/5: Actor Loss=-0.0086, Q1 Loss=1.0185, Q2 Loss=1.0185, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4110
SAC Update 3/5: Actor Loss=-0.0112, Q1 Loss=1.1436, Q2 Loss=1.1436, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3015
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.7807, Q2 Loss=0.7807, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5443
SAC Update 5/5: Actor Loss=-0.0076, Q1 Loss=0.8213, Q2 Loss=0.8213, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7700

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.7%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (39.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008667
Q1 loss: 0.939922
Q2 loss: 0.939922
Current threshold: -149.4980
Global Scale Offset: 5119.1074
Reward stats: mean=0.0152, std=0.0914, count=520
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 0.9399, Q2 Loss: 0.9399, Entropy: 0.6931, Mean TD Error: 0.8294, Threshold: -149.4980
Original likelihood: -136.48435974121094
Adjusted likelihood: -136.48435974121094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5010)
Current yaw: tensor([-0.0153,  0.0045, -0.5022], device='cuda:1')
12 turn
Sampling time 3.6996019480284303
tensor([ 5.9155e-03,  5.3197e-01,  5.5265e-01,  5.7030e-01, -1.5205e-01,
         5.6580e-01,  9.3510e-01,  9.0316e-01,  1.4394e+00,  1.2077e-01,
         1.9525e-01,  8.8618e-01, -1.5306e-02,  4.5224e-03, -5.0222e-01,
        -5.1201e+00], device='cuda:1')
Original likelihood: -140.37200927734375
Adjusted likelihood: -140.37200927734375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5007)
Solve time for step 1 14.272841724974569
Current ori: tensor([-0.0153,  0.0045, -0.5022], device='cuda:1')
Middle force: tensor([0.5498, 2.2133, 1.7094, 1.1666, 0.5298, 0.9897, 0.7452, 0.6415, 0.5812,
        0.6044, 0.6180, 0.5339], device='cuda:1')
Thumb force: tensor([0.5725, 1.7481, 0.5371, 1.0118, 0.5495, 0.5721, 0.5853, 0.5954, 1.2604,
        0.5642, 0.5734, 1.1576], device='cuda:1')
Index force: tensor([0.5466, 1.3270, 0.8548, 0.5459, 0.5616, 0.5222, 0.5125, 0.5397, 0.5831,
        0.5794, 0.5901, 0.5451], device='cuda:1')
Storing NORMAL transition: reward=-0.0164 (scaled=-0.0164), steps=1
Reward stats updated: mean 0.0152 -> 0.0152, std: 0.0914
Collected 521 transitions for RL
SAC Update 1/5: Actor Loss=-0.0083, Q1 Loss=0.8692, Q2 Loss=0.8692, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7366
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=1.5110, Q2 Loss=1.5110, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3066
SAC Update 3/5: Actor Loss=-0.0122, Q1 Loss=1.3859, Q2 Loss=1.3859, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9784
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.5247, Q2 Loss=1.5247, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.6409
SAC Update 5/5: Actor Loss=-0.0082, Q1 Loss=0.9555, Q2 Loss=0.9555, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6527

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.2%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (20.2%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009957
Q1 loss: 1.249290
Q2 loss: 1.249290
Current threshold: -149.4981
Global Scale Offset: 5139.5223
Reward stats: mean=0.0152, std=0.0914, count=521
----------------------------------------------
SAC Update - Actor Loss: -0.0100, Q1 Loss: 1.2493, Q2 Loss: 1.2493, Entropy: 0.6931, Mean TD Error: 1.2630, Threshold: -149.4981
tensor([ 0.0074,  0.5764,  0.5540,  0.4499, -0.1531,  0.5452,  0.8101,  1.0235,
         1.4464,  0.1280,  0.2256,  0.9295,  0.0161,  0.0311, -0.4867, -4.1264],
       device='cuda:1')
Original likelihood: -131.15115356445312
Adjusted likelihood: -131.15115356445312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5014)
Solve time for step 2 5.576288143987767
Current ori: tensor([ 0.0161,  0.0311, -0.4867], device='cuda:1')
Middle force: tensor([0.5880, 0.7566, 0.6789, 0.9062, 0.5421, 1.1786, 0.5744, 0.5489, 0.5443,
        0.7642, 0.9330], device='cuda:1')
Thumb force: tensor([0.5029, 0.6578, 0.5348, 0.5116, 0.5105, 1.0985, 0.5273, 0.5784, 0.8905,
        1.1740, 0.7977], device='cuda:1')
Index force: tensor([0.6163, 0.9835, 0.6032, 0.5256, 0.5156, 1.0568, 0.5373, 0.6006, 0.5692,
        0.5036, 0.5646], device='cuda:1')
Storing NORMAL transition: reward=-0.0031 (scaled=-0.0031), steps=1
Reward stats updated: mean 0.0152 -> 0.0151, std: 0.0913
Collected 522 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=0.9988, Q2 Loss=0.9988, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6140
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=0.9772, Q2 Loss=0.9772, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1103
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=2.3885, Q2 Loss=2.3885, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0468
SAC Update 4/5: Actor Loss=-0.0080, Q1 Loss=0.8417, Q2 Loss=0.8417, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7703
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=0.9427, Q2 Loss=0.9427, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4029

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.9%)
Q1 update: 0.05s (19.2%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009137
Q1 loss: 1.229777
Q2 loss: 1.229777
Current threshold: -149.4980
Global Scale Offset: 5151.5430
Reward stats: mean=0.0151, std=0.0913, count=522
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.2298, Q2 Loss: 1.2298, Entropy: 0.6931, Mean TD Error: 0.9889, Threshold: -149.4980
tensor([ 0.1039,  0.6299,  0.5557,  0.4813, -0.1133,  0.6047,  0.8600,  1.0119,
         1.4438,  0.2518,  0.1505,  0.8171,  0.0073, -0.0235, -0.4830, -4.0005],
       device='cuda:1')
Original likelihood: -150.658935546875
Adjusted likelihood: -150.658935546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4999)
State is out of distribution
Projection step: 0, Loss: 151.1871337890625
Projection step: 1, Loss: 137.3235321044922
Projection step: 2, Loss: 141.34368896484375
Projection step: 3, Loss: 142.3910675048828
Projection step: 4, Loss: 135.96263122558594
Projection step: 5, Loss: 138.47862243652344
Projection step: 6, Loss: 151.01718139648438
Projection step: 7, Loss: 134.25157165527344
Projection step: 8, Loss: 139.28973388671875
Projection step: 9, Loss: 128.917724609375
Projection step: 10, Loss: 128.80868530273438
Projection step: 11, Loss: 128.21063232421875
Projection step: 12, Loss: 122.71138000488281
Projection step: 13, Loss: 115.84153747558594
Projection step: 14, Loss: 120.791259765625
Projection step: 15, Loss: 121.2034912109375
Projection step: 16, Loss: 118.77763366699219
Projection step: 17, Loss: 115.6109848022461
Projection step: 18, Loss: 115.1102294921875
Projection step: 19, Loss: 112.45570373535156
Projection step: 20, Loss: 109.3490219116211
Projection step: 21, Loss: 109.26567077636719
Projection step: 22, Loss: 100.79069519042969
Final likelihood: tensor([ -93.0751,  -91.2455,  -95.4043,  -79.0094, -120.3287, -116.3634,
         -81.6361, -113.7298,  -97.9463, -103.8580, -105.6490, -100.0765,
        -101.0978, -119.7367, -110.6266,  -82.8679])
Final projection likelihood: -100.7907
1 mode projection succeeded
New goal: tensor([ 0.0744,  0.5595,  0.5754,  0.5677, -0.0577,  0.5418,  0.8387,  0.9005,
         1.3958,  0.2618,  0.1877,  1.0817,  0.0045, -0.0172, -2.5479],
       device='cuda:1')
tensor([[0.0041]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -120.17140197753906
Adjusted likelihood: -120.17140197753906
Likelihood residual: 0.0
Original likelihood: -159.88290405273438
Adjusted likelihood: -159.88290405273438
Likelihood residual: 0.0
{'index': 159.88290405273438, 'thumb_middle': 120.17140197753906}
Current yaw: tensor([ 0.0073, -0.0235, -0.4830], device='cuda:1')
13 thumb_middle
tensor([ 0.1039,  0.6299,  0.5557,  0.4813, -0.1133,  0.6047,  0.8600,  1.0119,
         1.4438,  0.2518,  0.1505,  0.8171,  0.0073, -0.0235, -0.4830, -4.0005],
       device='cuda:1')
Solve time for step 1 8.814140614995267
Current ori: tensor([ 0.0073, -0.0235, -0.4830], device='cuda:1')
Index force: tensor([0.5857, 0.5716, 0.5986, 0.6004], device='cuda:1')
tensor([ 0.0801,  0.5880,  0.5606,  0.5384, -0.1586,  0.5381,  0.8029,  0.8980,
         1.3354,  0.2349,  0.0851,  0.9896,  0.0204, -0.0074, -0.4830, -4.0207],
       device='cuda:1')
Solve time for step 2 3.520697781990748
Current ori: tensor([ 0.0204, -0.0074, -0.4830], device='cuda:1')
Index force: tensor([0.5607, 0.5890, 0.5913], device='cuda:1')
tensor([ 0.0785,  0.5864,  0.5604,  0.5400, -0.1589,  0.5399,  0.8048,  0.8785,
         1.3256,  0.2330,  0.0766,  1.0208,  0.0209, -0.0064, -0.4830, -4.0224],
       device='cuda:1')
Solve time for step 3 3.500062484003138
Current ori: tensor([ 0.0209, -0.0064, -0.4830], device='cuda:1')
Index force: tensor([0.5812, 0.5846], device='cuda:1')
tensor([ 0.0798,  0.5785,  0.5660,  0.5523, -0.1585,  0.5410,  0.8056,  0.8746,
         1.3222,  0.2339,  0.0787,  1.0241,  0.0238, -0.0066, -0.4830, -4.0143],
       device='cuda:1')
Solve time for step 4 3.4550399929867126
Current ori: tensor([ 0.0238, -0.0066, -0.4830], device='cuda:1')
Index force: tensor([0.5656], device='cuda:1')
Storing RECOVERY transition: reward=-0.0143 (scaled=-0.0071), steps=2
Reward stats updated: mean 0.0151 -> 0.0151, std: 0.0912
Collected 523 transitions for RL
SAC Update 1/5: Actor Loss=-0.0106, Q1 Loss=1.1202, Q2 Loss=1.1202, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6401
SAC Update 2/5: Actor Loss=-0.0092, Q1 Loss=1.0793, Q2 Loss=1.0793, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2296
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.0502, Q2 Loss=1.0502, Entropy=0.6928, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9015
SAC Update 4/5: Actor Loss=-0.0128, Q1 Loss=1.3121, Q2 Loss=1.3121, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3556
SAC Update 5/5: Actor Loss=-0.0121, Q1 Loss=1.8334, Q2 Loss=1.8334, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9028

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (15.0%)
Q1 update: 0.06s (21.1%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010917
Q1 loss: 1.279055
Q2 loss: 1.279055
Current threshold: -149.4977
Global Scale Offset: 5152.6196
Reward stats: mean=0.0151, std=0.0912, count=523
----------------------------------------------
SAC Update - Actor Loss: -0.0109, Q1 Loss: 1.2791, Q2 Loss: 1.2791, Entropy: 0.6931, Mean TD Error: 1.0059, Threshold: -149.4977
Original likelihood: -124.1144790649414
Adjusted likelihood: -124.1144790649414
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5020)
State is out of distribution
Projection step: 0, Loss: 120.28466796875
Projection step: 1, Loss: 109.88069152832031
Projection step: 2, Loss: 102.78570556640625
Final likelihood: tensor([ -90.4425, -117.4593,  -89.4120, -118.9017, -135.0517,  -83.2873,
         -92.8873, -127.4392, -105.3478,  -95.4407,  -90.9385,  -95.2016,
         -88.7207, -115.2882, -110.6449,  -88.1080])
Final projection likelihood: -102.7857
1 mode projection succeeded
New goal: tensor([ 0.0603,  0.5465,  0.5835,  0.5966, -0.0968,  0.5622,  0.8195,  0.8922,
         1.4065,  0.2585,  0.1351,  1.0856,  0.0346,  0.0054, -0.6066],
       device='cuda:1')
tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -123.03285217285156
Adjusted likelihood: -123.03285217285156
Likelihood residual: 0.0
Original likelihood: -136.69139099121094
Adjusted likelihood: -136.69139099121094
Likelihood residual: 0.0
{'index': 136.69139099121094, 'thumb_middle': 123.03285217285156}
Current yaw: tensor([ 0.0354,  0.0051, -0.4693], device='cuda:1')
14 thumb_middle
tensor([ 0.0565,  0.5392,  0.5796,  0.5880, -0.1017,  0.5793,  0.8280,  0.8936,
         1.4189,  0.2585,  0.1204,  1.0631,  0.0354,  0.0051, -0.4693, -3.9750],
       device='cuda:1')
Solve time for step 1 9.152787686034571
Current ori: tensor([ 0.0354,  0.0051, -0.4693], device='cuda:1')
Index force: tensor([0.5926, 0.5963, 0.5678, 0.5822], device='cuda:1')
tensor([ 0.0571,  0.5363,  0.5805,  0.5953, -0.1811,  0.5593,  0.7878,  0.8697,
         1.3590,  0.2379,  0.0541,  1.0483,  0.0370,  0.0062, -0.4692, -4.0014],
       device='cuda:1')
Solve time for step 2 3.6808974010054953
Current ori: tensor([ 0.0370,  0.0062, -0.4692], device='cuda:1')
Index force: tensor([0.5895, 0.5641, 0.5780], device='cuda:1')
tensor([ 0.0511,  0.5391,  0.5745,  0.5884, -0.1944,  0.5645,  0.7853,  0.8669,
         1.3627,  0.2390,  0.0483,  1.0507,  0.0356,  0.0091, -0.4692, -4.0137],
       device='cuda:1')
Solve time for step 3 3.75836217001779
Current ori: tensor([ 0.0356,  0.0091, -0.4692], device='cuda:1')
Index force: tensor([0.5574, 0.5714], device='cuda:1')
tensor([ 0.0580,  0.5366,  0.5794,  0.5980, -0.1902,  0.5664,  0.7879,  0.8680,
         1.3607,  0.2387,  0.0466,  1.0489,  0.0372,  0.0058, -0.4692, -3.9987],
       device='cuda:1')
Solve time for step 4 3.599532449967228
Current ori: tensor([ 0.0372,  0.0058, -0.4692], device='cuda:1')
Index force: tensor([0.5556], device='cuda:1')
Storing RECOVERY transition: reward=-0.0195 (scaled=-0.0098), steps=2
Reward stats updated: mean 0.0151 -> 0.0150, std: 0.0911
Collected 524 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=1.2399, Q2 Loss=1.2399, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9007
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.7998, Q2 Loss=0.7998, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3563
SAC Update 3/5: Actor Loss=-0.0082, Q1 Loss=0.9535, Q2 Loss=0.9535, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6681
SAC Update 4/5: Actor Loss=-0.0126, Q1 Loss=2.1727, Q2 Loss=2.1727, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2661
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.8148, Q2 Loss=0.8148, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8040

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (40.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009470
Q1 loss: 1.196136
Q2 loss: 1.196136
Current threshold: -149.4973
Global Scale Offset: 5155.2591
Reward stats: mean=0.0150, std=0.0911, count=524
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.1961, Q2 Loss: 1.1961, Entropy: 0.6931, Mean TD Error: 0.9990, Threshold: -149.4973
Original likelihood: -145.62802124023438
Adjusted likelihood: -145.62802124023438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5003)
State is out of distribution
Projection step: 0, Loss: 141.96060180664062
Projection step: 1, Loss: 131.32594299316406
Projection step: 2, Loss: 115.57862854003906
Projection step: 3, Loss: 109.78309631347656
Projection step: 4, Loss: 108.30451965332031
Projection step: 5, Loss: 106.76481628417969
Projection step: 6, Loss: 108.20004272460938
Projection step: 7, Loss: 99.93331909179688
Final likelihood: tensor([-106.7330,  -96.0323, -129.4130,  -84.4329,  -95.8828, -107.9577,
         -90.5949,  -87.7917,  -94.1828, -104.8801, -101.0520, -101.2478,
        -113.4441,  -90.4191,  -97.6024,  -97.2666])
Final projection likelihood: -99.9333
1 mode projection succeeded
New goal: tensor([ 0.0542,  0.5530,  0.5859,  0.5941, -0.1076,  0.5631,  0.7956,  0.8770,
         1.3841,  0.2478,  0.1463,  1.1403,  0.0368,  0.0125, -0.8986],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0030]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -125.26786804199219
Adjusted likelihood: -125.26786804199219
Likelihood residual: 0.0
Original likelihood: -139.32301330566406
Adjusted likelihood: -139.32301330566406
Likelihood residual: 0.0
{'index': 139.32301330566406, 'thumb_middle': 125.26786804199219}
Current yaw: tensor([ 0.0396,  0.0123, -0.4644], device='cuda:1')
15 thumb_middle
tensor([ 0.0426,  0.5311,  0.5740,  0.5955, -0.1320,  0.6050,  0.8233,  0.8899,
         1.4257,  0.2570,  0.1101,  1.0893,  0.0396,  0.0123, -0.4644, -3.9672],
       device='cuda:1')
Solve time for step 1 9.204743052017875
Current ori: tensor([ 0.0396,  0.0123, -0.4644], device='cuda:1')
Index force: tensor([0.5815, 0.5901, 0.5975, 0.5904], device='cuda:1')
tensor([ 0.0410,  0.5426,  0.5687,  0.5724, -0.1903,  0.5689,  0.7699,  0.8573,
         1.3369,  0.2281,  0.0640,  1.1001,  0.0332,  0.0139, -0.4644, -4.0390],
       device='cuda:1')
Solve time for step 2 3.579129925055895
Current ori: tensor([ 0.0332,  0.0139, -0.4644], device='cuda:1')
Index force: tensor([0.5849, 0.5941, 0.5870], device='cuda:1')
tensor([ 0.0417,  0.5386,  0.5701,  0.5817, -0.1970,  0.5736,  0.7695,  0.8563,
         1.3385,  0.2246,  0.0576,  1.1032,  0.0350,  0.0137, -0.4644, -4.0332],
       device='cuda:1')
Solve time for step 3 3.4727061149897054
Current ori: tensor([ 0.0350,  0.0137, -0.4644], device='cuda:1')
Index force: tensor([0.5869, 0.5815], device='cuda:1')
tensor([ 0.0424,  0.5297,  0.5748,  0.5978, -0.1970,  0.5747,  0.7684,  0.8547,
         1.3372,  0.2257,  0.0586,  1.1066,  0.0387,  0.0138, -0.4644, -4.0232],
       device='cuda:1')
Solve time for step 4 3.4447877839556895
Current ori: tensor([ 0.0387,  0.0138, -0.4644], device='cuda:1')
Index force: tensor([0.5000], device='cuda:1')
Storing RECOVERY transition: reward=-0.0179 (scaled=-0.0089), steps=2
Reward stats updated: mean 0.0150 -> 0.0150, std: 0.0910
Collected 525 transitions for RL
SAC Update 1/5: Actor Loss=-0.0090, Q1 Loss=1.1172, Q2 Loss=1.1172, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5199
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=1.0818, Q2 Loss=1.0818, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9623
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=1.1250, Q2 Loss=1.1250, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4126
SAC Update 4/5: Actor Loss=-0.0128, Q1 Loss=1.2926, Q2 Loss=1.2926, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2339
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=2.0537, Q2 Loss=2.0537, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7050

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.1%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.4%)
Actor update: 0.11s (43.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009551
Q1 loss: 1.334043
Q2 loss: 1.334043
Current threshold: -149.4972
Global Scale Offset: 5168.2577
Reward stats: mean=0.0150, std=0.0910, count=525
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.3340, Q2 Loss: 1.3340, Entropy: 0.6931, Mean TD Error: 1.9667, Threshold: -149.4972
Original likelihood: -129.02041625976562
Adjusted likelihood: -129.02041625976562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5016)
State is out of distribution
Projection step: 0, Loss: 130.9795684814453
Projection step: 1, Loss: 121.32015991210938
Projection step: 2, Loss: 113.79324340820312
Projection step: 3, Loss: 107.91654205322266
Projection step: 4, Loss: 108.72069549560547
Projection step: 5, Loss: 94.80498504638672
Final likelihood: tensor([ -92.8761, -107.1152,  -81.7524,  -89.0514,  -84.8309, -105.1715,
         -92.3362,  -85.5103,  -94.3788, -111.1633,  -89.0503, -103.5871,
        -101.3282,  -88.6060,  -91.4141,  -98.7081])
Final projection likelihood: -94.8050
1 mode projection succeeded
New goal: tensor([ 0.0496,  0.5525,  0.5819,  0.5907, -0.1127,  0.5827,  0.7892,  0.8768,
         1.3658,  0.2348,  0.1400,  1.1676,  0.0358,  0.0127, -0.8063],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -126.74174499511719
Adjusted likelihood: -126.74174499511719
Likelihood residual: 0.0
Original likelihood: -156.95851135253906
Adjusted likelihood: -156.95851135253906
Likelihood residual: 0.0
{'index': 156.95851135253906, 'thumb_middle': 126.74174499511719}
Current yaw: tensor([ 0.0377,  0.0124, -0.4659], device='cuda:1')
16 thumb_middle
tensor([ 0.0392,  0.5376,  0.5665,  0.5849, -0.1268,  0.6198,  0.8057,  0.8778,
         1.3982,  0.2447,  0.1135,  1.1406,  0.0377,  0.0124, -0.4659, -3.9270],
       device='cuda:1')
Solve time for step 1 9.237335856014397
Current ori: tensor([ 0.0377,  0.0124, -0.4659], device='cuda:1')
Index force: tensor([0.5705, 0.5761, 0.5963, 0.5042], device='cuda:1')
tensor([ 0.0552,  0.5412,  0.5683,  0.6022, -0.1810,  0.5788,  0.7732,  0.8601,
         1.3212,  0.2218,  0.0581,  1.1249,  0.0371,  0.0053, -0.4659, -3.9465],
       device='cuda:1')
Solve time for step 2 3.6717193570220843
Current ori: tensor([ 0.0371,  0.0053, -0.4659], device='cuda:1')
Index force: tensor([0.5000, 0.5569, 0.5793], device='cuda:1')
tensor([ 0.0504,  0.5407,  0.5651,  0.6001, -0.2035,  0.5952,  0.7649,  0.8513,
         1.3254,  0.2133,  0.0580,  1.1355,  0.0372,  0.0078, -0.4659, -3.9493],
       device='cuda:1')
Solve time for step 3 3.5018495509866625
Current ori: tensor([ 0.0372,  0.0078, -0.4659], device='cuda:1')
Index force: tensor([0.5460, 0.5675], device='cuda:1')
tensor([ 0.0515,  0.5324,  0.5796,  0.5968, -0.1957,  0.5949,  0.7600,  0.8598,
         1.3056,  0.2156,  0.0678,  1.1461,  0.0387,  0.0074, -0.4659, -3.9504],
       device='cuda:1')
Solve time for step 4 3.361587925988715
Current ori: tensor([ 0.0387,  0.0074, -0.4659], device='cuda:1')
Index force: tensor([0.5500], device='cuda:1')
Storing RECOVERY transition: reward=-0.0252 (scaled=-0.0126), steps=2
Reward stats updated: mean 0.0150 -> 0.0149, std: 0.0910
Collected 526 transitions for RL
SAC Update 1/5: Actor Loss=-0.0107, Q1 Loss=1.1823, Q2 Loss=1.1823, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8710
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9262, Q2 Loss=0.9262, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9650
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=2.7439, Q2 Loss=2.7439, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0759
SAC Update 4/5: Actor Loss=-0.0130, Q1 Loss=1.8190, Q2 Loss=1.8190, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6721
SAC Update 5/5: Actor Loss=-0.0137, Q1 Loss=1.3766, Q2 Loss=1.3766, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1340

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.05s (19.9%)
Actor update: 0.09s (39.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010979
Q1 loss: 1.609611
Q2 loss: 1.609611
Current threshold: -149.4970
Global Scale Offset: 5186.6265
Reward stats: mean=0.0149, std=0.0910, count=526
----------------------------------------------
SAC Update - Actor Loss: -0.0110, Q1 Loss: 1.6096, Q2 Loss: 1.6096, Entropy: 0.6931, Mean TD Error: 1.5436, Threshold: -149.4970
Original likelihood: -141.4239501953125
Adjusted likelihood: -141.4239501953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 152.30999755859375
Projection step: 1, Loss: 143.80540466308594
Projection step: 2, Loss: 135.521484375
Projection step: 3, Loss: 132.82098388671875
Projection step: 4, Loss: 122.0528564453125
Projection step: 5, Loss: 119.08660888671875
Projection step: 6, Loss: 120.8341293334961
Projection step: 7, Loss: 118.59965515136719
Projection step: 8, Loss: 113.7992172241211
Projection step: 9, Loss: 116.66728210449219
Projection step: 10, Loss: 105.96511840820312
Projection step: 11, Loss: 115.2370376586914
Projection step: 12, Loss: 102.36911010742188
Final likelihood: tensor([-100.5174,  -97.7863, -107.8024, -107.0507,  -90.5633, -100.2208,
        -106.5694,  -95.0454,  -90.4215,  -98.1871, -110.9127,  -97.5005,
        -125.3918, -125.9630,  -91.1047,  -92.8687])
Final projection likelihood: -102.3691
1 mode projection succeeded
New goal: tensor([ 0.0338,  0.5508,  0.5844,  0.5782, -0.1260,  0.5729,  0.7542,  0.8866,
         1.3302,  0.2199,  0.1536,  1.2010,  0.0367,  0.0239, -1.0048],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -121.41212463378906
Adjusted likelihood: -121.41212463378906
Likelihood residual: 0.0
Original likelihood: -148.5729522705078
Adjusted likelihood: -148.5729522705078
Likelihood residual: 0.0
{'index': 148.5729522705078, 'thumb_middle': 121.41212463378906}
Current yaw: tensor([ 0.0408,  0.0271, -0.4593], device='cuda:1')
17 thumb_middle
tensor([ 0.0101,  0.5264,  0.5594,  0.5795, -0.1625,  0.6272,  0.7944,  0.8988,
         1.3903,  0.2208,  0.1375,  1.1850,  0.0408,  0.0271, -0.4593, -3.9448],
       device='cuda:1')
Solve time for step 1 9.086693122982979
Current ori: tensor([ 0.0408,  0.0271, -0.4593], device='cuda:1')
Index force: tensor([0.5928, 0.5749, 0.5953, 0.5950], device='cuda:1')
tensor([ 0.0202,  0.5487,  0.5516,  0.5523, -0.2042,  0.5851,  0.7369,  0.8695,
         1.3001,  0.1971,  0.0904,  1.1780,  0.0306,  0.0223, -0.4593, -4.0205],
       device='cuda:1')
Solve time for step 2 3.667892698023934
Current ori: tensor([ 0.0306,  0.0223, -0.4593], device='cuda:1')
Index force: tensor([0.5666, 0.5880, 0.5881], device='cuda:1')
tensor([ 0.0143,  0.5391,  0.5550,  0.5616, -0.2078,  0.5868,  0.7317,  0.8667,
         1.2990,  0.1988,  0.0913,  1.1830,  0.0337,  0.0255, -0.4593, -4.0202],
       device='cuda:1')
Solve time for step 3 3.472479975025635
Current ori: tensor([ 0.0337,  0.0255, -0.4593], device='cuda:1')
Index force: tensor([0.5762, 0.5771], device='cuda:1')
tensor([ 0.0114,  0.5266,  0.5661,  0.5689, -0.2099,  0.5888,  0.7303,  0.8660,
         1.3008,  0.2014,  0.0924,  1.1818,  0.0373,  0.0273, -0.4593, -4.0188],
       device='cuda:1')
Solve time for step 4 3.3771896319813095
Current ori: tensor([ 0.0373,  0.0273, -0.4593], device='cuda:1')
Index force: tensor([0.5518], device='cuda:1')
Storing RECOVERY transition: reward=-0.0327 (scaled=-0.0163), steps=2
Reward stats updated: mean 0.0149 -> 0.0149, std: 0.0909
Collected 527 transitions for RL
SAC Update 1/5: Actor Loss=-0.0094, Q1 Loss=1.3811, Q2 Loss=1.3811, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0183
SAC Update 2/5: Actor Loss=-0.0072, Q1 Loss=0.7219, Q2 Loss=0.7219, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1934
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=1.0369, Q2 Loss=1.0369, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8117
SAC Update 4/5: Actor Loss=-0.0112, Q1 Loss=1.3837, Q2 Loss=1.3837, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3484
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=1.4418, Q2 Loss=1.4418, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2668

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.1%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.04s (18.1%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009835
Q1 loss: 1.193080
Q2 loss: 1.193080
Current threshold: -149.4969
Global Scale Offset: 5202.2584
Reward stats: mean=0.0149, std=0.0909, count=527
----------------------------------------------
SAC Update - Actor Loss: -0.0098, Q1 Loss: 1.1931, Q2 Loss: 1.1931, Entropy: 0.6931, Mean TD Error: 1.1277, Threshold: -149.4969
Original likelihood: -141.86976623535156
Adjusted likelihood: -141.86976623535156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5006)
State is out of distribution
Projection step: 0, Loss: 130.8453826904297
Projection step: 1, Loss: 128.31069946289062
Projection step: 2, Loss: 116.79234313964844
Projection step: 3, Loss: 106.40858459472656
Projection step: 4, Loss: 107.69674682617188
Projection step: 5, Loss: 106.92793273925781
Projection step: 6, Loss: 107.81947326660156
Projection step: 7, Loss: 99.48359680175781
Final likelihood: tensor([-123.3431, -110.9081,  -96.6405,  -83.1345,  -94.1926,  -93.5528,
         -96.6177,  -98.0583, -108.2220, -106.9457, -100.6675,  -87.7858,
         -91.4196, -110.8744,  -88.5731, -100.8017])
Final projection likelihood: -99.4836
1 mode projection succeeded
New goal: tensor([ 0.0357,  0.5443,  0.5922,  0.5802, -0.1171,  0.5939,  0.7475,  0.8829,
         1.3209,  0.2301,  0.1534,  1.2264,  0.0371,  0.0202, -0.8844],
       device='cuda:1')
tensor([[0.0020]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -127.975830078125
Adjusted likelihood: -127.975830078125
Likelihood residual: 0.0
Original likelihood: -137.95462036132812
Adjusted likelihood: -137.95462036132812
Likelihood residual: 0.0
{'index': 137.95462036132812, 'thumb_middle': 127.975830078125}
Current yaw: tensor([ 0.0395,  0.0217, -0.4515], device='cuda:1')
18 thumb_middle
tensor([ 0.0206,  0.5192,  0.5831,  0.5710, -0.1277,  0.6446,  0.7521,  0.8784,
         1.3565,  0.2256,  0.1530,  1.2260,  0.0395,  0.0217, -0.4515, -3.9799],
       device='cuda:1')
Solve time for step 1 9.100003683008254
Current ori: tensor([ 0.0395,  0.0217, -0.4515], device='cuda:1')
Index force: tensor([0.5947, 0.5921, 0.5576, 0.5742], device='cuda:1')
tensor([ 0.0334,  0.5175,  0.5896,  0.5850, -0.1969,  0.6167,  0.7187,  0.8517,
         1.2789,  0.1997,  0.0982,  1.2003,  0.0409,  0.0167, -0.4515, -3.9896],
       device='cuda:1')
Solve time for step 2 3.9360735440277494
Current ori: tensor([ 0.0409,  0.0167, -0.4515], device='cuda:1')
Index force: tensor([0.5851, 0.5533, 0.5750], device='cuda:1')
tensor([ 0.0278,  0.5284,  0.5752,  0.5744, -0.1990,  0.5982,  0.7211,  0.8637,
         1.2838,  0.2165,  0.0783,  1.2134,  0.0373,  0.0191, -0.4515, -4.0052],
       device='cuda:1')
Solve time for step 3 3.5231357679585926
Current ori: tensor([ 0.0373,  0.0191, -0.4515], device='cuda:1')
Index force: tensor([0.5453, 0.5667], device='cuda:1')
tensor([ 0.0055,  0.5295,  0.5639,  0.5552, -0.2072,  0.5948,  0.7165,  0.8581,
         1.2920,  0.2074,  0.0925,  1.2105,  0.0354,  0.0301, -0.4515, -4.0393],
       device='cuda:1')
Solve time for step 4 3.529908967029769
Current ori: tensor([ 0.0354,  0.0301, -0.4515], device='cuda:1')
Index force: tensor([0.5512], device='cuda:1')
Storing RECOVERY transition: reward=-0.0351 (scaled=-0.0176), steps=2
Reward stats updated: mean 0.0149 -> 0.0148, std: 0.0908
Collected 528 transitions for RL
SAC Update 1/5: Actor Loss=-0.0101, Q1 Loss=1.1868, Q2 Loss=1.1868, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1658
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.9468, Q2 Loss=0.9468, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0273
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=2.2041, Q2 Loss=2.2041, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5986
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.2586, Q2 Loss=1.2586, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9198
SAC Update 5/5: Actor Loss=-0.0126, Q1 Loss=1.8369, Q2 Loss=1.8369, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7854

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.8%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.06s (20.0%)
Actor update: 0.11s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009424
Q1 loss: 1.486637
Q2 loss: 1.486637
Current threshold: -149.4967
Global Scale Offset: 5220.2306
Reward stats: mean=0.0148, std=0.0908, count=528
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.4866, Q2 Loss: 1.4866, Entropy: 0.6931, Mean TD Error: 2.4994, Threshold: -149.4967
Original likelihood: -137.03172302246094
Adjusted likelihood: -137.03172302246094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5010)
State is out of distribution
Projection step: 0, Loss: 130.81002807617188
Projection step: 1, Loss: 122.99312591552734
Projection step: 2, Loss: 115.24533081054688
Projection step: 3, Loss: 112.12037658691406
Projection step: 4, Loss: 111.15586853027344
Projection step: 5, Loss: 103.23320007324219
Final likelihood: tensor([ -87.8359, -109.8940,  -93.3800,  -97.6995, -128.1295,  -94.0589,
        -117.2945,  -96.1329,  -93.5604, -123.1630, -101.8151,  -90.4490,
         -92.8582, -136.7286, -104.0307,  -84.7010])
Final projection likelihood: -103.2332
1 mode projection succeeded
New goal: tensor([ 0.0320,  0.5426,  0.5900,  0.5766, -0.1226,  0.6092,  0.7467,  0.8818,
         1.3193,  0.2347,  0.1529,  1.2430,  0.0364,  0.0208, -0.7802],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -134.9047393798828
Adjusted likelihood: -134.9047393798828
Likelihood residual: 0.0
Original likelihood: -143.435302734375
Adjusted likelihood: -143.435302734375
Likelihood residual: 0.0
{'index': 143.435302734375, 'thumb_middle': 134.9047393798828}
Current yaw: tensor([ 0.0380,  0.0218, -0.4490], device='cuda:1')
19 thumb_middle
tensor([ 0.0206,  0.5227,  0.5814,  0.5649, -0.1318,  0.6513,  0.7483,  0.8804,
         1.3446,  0.2357,  0.1555,  1.2395,  0.0380,  0.0218, -0.4490, -3.9926],
       device='cuda:1')
Solve time for step 1 9.145871253975201
Current ori: tensor([ 0.0380,  0.0218, -0.4490], device='cuda:1')
Index force: tensor([0.5949, 0.5782, 0.5980, 0.5882], device='cuda:1')
tensor([ 0.0168,  0.5230,  0.5792,  0.5609, -0.2098,  0.6103,  0.7143,  0.8597,
         1.2840,  0.2128,  0.0959,  1.2242,  0.0376,  0.0246, -0.4490, -4.0196],
       device='cuda:1')
Solve time for step 2 3.856285571004264
Current ori: tensor([ 0.0376,  0.0246, -0.4490], device='cuda:1')
Index force: tensor([0.5716, 0.5916, 0.5836], device='cuda:1')
tensor([ 0.0254,  0.5199,  0.5847,  0.5743, -0.2090,  0.6157,  0.7167,  0.8591,
         1.2807,  0.2103,  0.0844,  1.2221,  0.0394,  0.0204, -0.4490, -4.0063],
       device='cuda:1')
Solve time for step 3 3.566497032006737
Current ori: tensor([ 0.0394,  0.0204, -0.4490], device='cuda:1')
Index force: tensor([0.5823, 0.5769], device='cuda:1')
tensor([ 0.0320,  0.5215,  0.5835,  0.5839, -0.2076,  0.6191,  0.7196,  0.8572,
         1.2770,  0.2100,  0.0829,  1.2200,  0.0399,  0.0172, -0.4490, -3.9956],
       device='cuda:1')
Solve time for step 4 3.5587237480212934
Current ori: tensor([ 0.0399,  0.0172, -0.4490], device='cuda:1')
Index force: tensor([0.5616], device='cuda:1')
Storing RECOVERY transition: reward=-0.0372 (scaled=-0.0186), steps=2
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0907
Collected 529 transitions for RL
SAC Update 1/5: Actor Loss=-0.0079, Q1 Loss=1.2618, Q2 Loss=1.2618, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4130
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=1.0273, Q2 Loss=1.0273, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6026
SAC Update 3/5: Actor Loss=-0.0100, Q1 Loss=2.4691, Q2 Loss=2.4691, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0417
SAC Update 4/5: Actor Loss=-0.0094, Q1 Loss=0.9652, Q2 Loss=0.9652, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3794
SAC Update 5/5: Actor Loss=-0.0117, Q1 Loss=1.1843, Q2 Loss=1.1843, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1819

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (18.5%)
Q2 update: 0.04s (19.4%)
Actor update: 0.09s (41.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009746
Q1 loss: 1.381532
Q2 loss: 1.381532
Current threshold: -149.4966
Global Scale Offset: 5236.5680
Reward stats: mean=0.0147, std=0.0907, count=529
----------------------------------------------
SAC Update - Actor Loss: -0.0097, Q1 Loss: 1.3815, Q2 Loss: 1.3815, Entropy: 0.6931, Mean TD Error: 1.3237, Threshold: -149.4966
Original likelihood: -142.55636596679688
Adjusted likelihood: -142.55636596679688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5005)
State is out of distribution
Projection step: 0, Loss: 138.14044189453125
Projection step: 1, Loss: 134.7383270263672
Projection step: 2, Loss: 126.2891845703125
Projection step: 3, Loss: 120.590576171875
Projection step: 4, Loss: 114.60160827636719
Projection step: 5, Loss: 117.82585144042969
Projection step: 6, Loss: 104.92356872558594
Final likelihood: tensor([ -94.9599, -122.3435,  -99.6618,  -96.4259, -102.5881, -126.5750,
        -101.9898, -126.7347,  -95.8528, -101.1940, -102.4802,  -90.9811,
        -100.8893,  -99.7087, -111.5881, -104.8042])
Final projection likelihood: -104.9236
1 mode projection succeeded
New goal: tensor([ 0.0284,  0.5404,  0.5917,  0.5840, -0.1323,  0.6114,  0.7478,  0.8826,
         1.3194,  0.2304,  0.1440,  1.2525,  0.0388,  0.0217, -0.7995],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -140.4723663330078
Adjusted likelihood: -140.4723663330078
Likelihood residual: 0.0
Original likelihood: -157.47576904296875
Adjusted likelihood: -157.47576904296875
Likelihood residual: 0.0
{'index': 157.47576904296875, 'thumb_middle': 140.4723663330078}
Current yaw: tensor([ 0.0409,  0.0229, -0.4471], device='cuda:1')
20 thumb_middle
tensor([ 0.0184,  0.5188,  0.5799,  0.5744, -0.1449,  0.6596,  0.7559,  0.8828,
         1.3493,  0.2382,  0.1465,  1.2506,  0.0409,  0.0229, -0.4471, -3.9695],
       device='cuda:1')
Solve time for step 1 8.637755555973854
Current ori: tensor([ 0.0409,  0.0229, -0.4471], device='cuda:1')
Index force: tensor([0.5528, 0.5920, 0.5825, 0.5881], device='cuda:1')
tensor([ 0.0152,  0.5167,  0.5781,  0.5776, -0.2185,  0.6205,  0.7211,  0.8548,
         1.2995,  0.2029,  0.0779,  1.2341,  0.0405,  0.0258, -0.4471, -4.0176],
       device='cuda:1')
Solve time for step 2 3.439125297998544
Current ori: tensor([ 0.0405,  0.0258, -0.4471], device='cuda:1')
Index force: tensor([0.5828, 0.5750, 0.5809], device='cuda:1')
tensor([ 0.0228,  0.5158,  0.5864,  0.5776, -0.2164,  0.6244,  0.7167,  0.8623,
         1.2761,  0.2100,  0.0845,  1.2405,  0.0405,  0.0220, -0.4471, -4.0114],
       device='cuda:1')
Solve time for step 3 3.3223265950218774
Current ori: tensor([ 0.0405,  0.0220, -0.4471], device='cuda:1')
Index force: tensor([0.5673, 0.5795], device='cuda:1')
tensor([ 0.0240,  0.5133,  0.5846,  0.5902, -0.2187,  0.6259,  0.7256,  0.8585,
         1.2825,  0.2007,  0.0781,  1.2428,  0.0424,  0.0216, -0.4471, -4.0041],
       device='cuda:1')
Solve time for step 4 3.301498578977771
Current ori: tensor([ 0.0424,  0.0216, -0.4471], device='cuda:1')
Index force: tensor([0.5648], device='cuda:1')
Storing RECOVERY transition: reward=-0.0267 (scaled=-0.0134), steps=2
Reward stats updated: mean 0.0147 -> 0.0147, std: 0.0907
Collected 530 transitions for RL
SAC Update 1/5: Actor Loss=-0.0111, Q1 Loss=1.2443, Q2 Loss=1.2443, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8793
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8694, Q2 Loss=0.8694, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4684
SAC Update 3/5: Actor Loss=-0.0136, Q1 Loss=2.8446, Q2 Loss=2.8446, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.7497
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=4.1503, Q2 Loss=4.1503, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.1623
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.0328, Q2 Loss=1.0328, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5210

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009902
Q1 loss: 2.028291
Q2 loss: 2.028291
Current threshold: -149.4965
Global Scale Offset: 5266.7369
Reward stats: mean=0.0147, std=0.0907, count=530
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 2.0283, Q2 Loss: 2.0283, Entropy: 0.6931, Mean TD Error: 2.5561, Threshold: -149.4965
Original likelihood: -143.4995880126953
Adjusted likelihood: -143.4995880126953
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Marked last transition as done (final step)
{}

Trial 34
Loaded trajectory sampler
Current yaw: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
Current yaw: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
1 turn
Sampling time 3.6542218899703585
tensor([ 0.1371,  0.6083,  0.5841,  0.5546, -0.1425,  0.5690,  0.9311,  0.8293,
         1.2158,  0.3199,  0.2649,  1.1590, -0.0018,  0.0146, -0.0285,  0.2316],
       device='cuda:1')
Original likelihood: -127.10087585449219
Adjusted likelihood: -127.10087585449219
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Solve time for step 1 14.29010039003333
Current ori: tensor([-0.0018,  0.0146, -0.0285], device='cuda:1')
Middle force: tensor([0.8547, 1.0325, 0.6108, 1.3220, 0.5668, 0.4916, 0.6229, 1.1431, 0.4920,
        0.5808, 0.5366, 0.6882], device='cuda:1')
Thumb force: tensor([1.6205, 0.5771, 0.6194, 0.7093, 0.9188, 0.5854, 0.7222, 0.6316, 0.4870,
        0.5988, 1.1515, 1.1205], device='cuda:1')
Index force: tensor([1.1856, 0.5229, 0.5367, 0.7640, 0.5412, 0.6909, 0.8628, 0.4944, 0.4730,
        0.6029, 0.5250, 0.5425], device='cuda:1')
Storing NORMAL transition: reward=0.0600 (scaled=0.0600), steps=1
Reward stats updated: mean 0.0147 -> 0.0148, std: 0.0906
Collected 531 transitions for RL
SAC Update 1/5: Actor Loss=-0.0074, Q1 Loss=1.0413, Q2 Loss=1.0413, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3427
SAC Update 2/5: Actor Loss=-0.0121, Q1 Loss=1.2727, Q2 Loss=1.2727, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6257
SAC Update 3/5: Actor Loss=-0.0103, Q1 Loss=2.9935, Q2 Loss=2.9935, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4137
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.7697, Q2 Loss=0.7697, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3615
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=1.0235, Q2 Loss=1.0235, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4277

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (17.5%)
Q1 update: 0.04s (15.8%)
Q2 update: 0.05s (17.2%)
Actor update: 0.09s (33.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009234
Q1 loss: 1.420160
Q2 loss: 1.420160
Current threshold: -149.4964
Global Scale Offset: 5291.9174
Reward stats: mean=0.0148, std=0.0906, count=531
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 1.4202, Q2 Loss: 1.4202, Entropy: 0.6931, Mean TD Error: 1.6342, Threshold: -149.4964
tensor([ 0.1165,  0.6498,  0.5283,  0.5075, -0.1581,  0.5708,  0.9007,  0.8634,
         1.2606,  0.3052,  0.2777,  1.0677, -0.0155,  0.0196, -0.0890,  0.3668],
       device='cuda:1')
Original likelihood: -129.09939575195312
Adjusted likelihood: -129.09939575195312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5015)
Solve time for step 2 5.634838154015597
Current ori: tensor([-0.0155,  0.0196, -0.0890], device='cuda:1')
Middle force: tensor([0.5042, 0.5833, 0.5027, 0.5048, 0.9625, 0.5004, 0.5636, 0.5504, 0.5157,
        0.5509, 0.5588], device='cuda:1')
Thumb force: tensor([0.6511, 0.8721, 0.6021, 0.7931, 0.9278, 1.1525, 0.6538, 0.5323, 0.5487,
        0.6652, 0.5446], device='cuda:1')
Index force: tensor([0.6971, 0.5568, 0.6829, 0.6666, 0.6420, 0.6754, 0.5548, 0.5988, 0.5764,
        0.5859, 0.5546], device='cuda:1')
Storing NORMAL transition: reward=-0.0034 (scaled=-0.0034), steps=1
Reward stats updated: mean 0.0148 -> 0.0147, std: 0.0905
Collected 532 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.7938, Q2 Loss=0.7938, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4807
SAC Update 2/5: Actor Loss=-0.0075, Q1 Loss=0.8668, Q2 Loss=0.8668, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9922
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=0.9752, Q2 Loss=0.9752, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3750
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=1.2305, Q2 Loss=1.2305, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1889
SAC Update 5/5: Actor Loss=-0.0071, Q1 Loss=0.7331, Q2 Loss=0.7331, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2113

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (17.2%)
Q1 update: 0.05s (20.8%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008457
Q1 loss: 0.919875
Q2 loss: 0.919875
Current threshold: -149.4964
Global Scale Offset: 5301.4931
Reward stats: mean=0.0147, std=0.0905, count=532
----------------------------------------------
SAC Update - Actor Loss: -0.0085, Q1 Loss: 0.9199, Q2 Loss: 0.9199, Entropy: 0.6931, Mean TD Error: 0.8496, Threshold: -149.4964
tensor([ 0.2023,  0.6594,  0.5698,  0.4957, -0.2847,  0.5216,  0.8993,  1.0058,
         1.2520,  0.2149,  0.1610,  1.1491, -0.0380,  0.0487, -0.0890, -5.5350],
       device='cuda:1')
Original likelihood: -219.16737365722656
Adjusted likelihood: -219.16737365722656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4948)
State is out of distribution
Projection step: 0, Loss: 230.017333984375
Projection step: 1, Loss: 227.63331604003906
Projection step: 2, Loss: 215.3662109375
Projection step: 3, Loss: 208.82992553710938
Projection step: 4, Loss: 204.77783203125
Projection step: 5, Loss: 199.2710418701172
Projection step: 6, Loss: 196.16275024414062
Projection step: 7, Loss: 195.9730224609375
Projection step: 8, Loss: 186.4751434326172
Projection step: 9, Loss: 186.74557495117188
Projection step: 10, Loss: 183.1401824951172
Projection step: 11, Loss: 184.81117248535156
Projection step: 12, Loss: 179.6737518310547
Projection step: 13, Loss: 171.76727294921875
Projection step: 14, Loss: 174.65826416015625
Projection step: 15, Loss: 168.89456176757812
Projection step: 16, Loss: 168.11305236816406
Projection step: 17, Loss: 163.37521362304688
Projection step: 18, Loss: 158.489013671875
Projection step: 19, Loss: 163.1389617919922
Projection step: 20, Loss: 161.02249145507812
Projection step: 21, Loss: 166.24661254882812
Projection step: 22, Loss: 156.9888458251953
Projection step: 23, Loss: 155.65792846679688
Projection step: 24, Loss: 152.5332489013672
Final likelihood: tensor([-122.6893, -145.4414, -124.5723, -132.4843, -138.7182, -172.6533,
        -183.5873, -130.3915, -117.8734, -124.3262, -154.6659, -155.9666,
        -128.3412, -170.4266, -132.8894, -155.0121])
Final projection likelihood: -143.1274
1 mode projection succeeded
New goal: tensor([ 0.1325,  0.6627,  0.4592,  0.5574, -0.1641,  0.5182,  0.8135,  0.9706,
         1.3276,  0.1776,  0.1582,  1.1525, -0.0406,  0.0415, -2.7813],
       device='cuda:1')
tensor([[0.0157]], device='cuda:1') tensor([[0.0089]], device='cuda:1') tensor([[0.0039]], device='cuda:1')
Original likelihood: -169.26564025878906
Adjusted likelihood: -169.26564025878906
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 169.26564025878906}
Current yaw: tensor([-0.0380,  0.0487, -0.0890], device='cuda:1')
2 thumb_middle
tensor([ 0.2023,  0.6594,  0.5698,  0.4957, -0.2847,  0.5216,  0.8993,  1.0058,
         1.2520,  0.2149,  0.1610,  1.1491, -0.0380,  0.0487, -0.0890, -5.5350],
       device='cuda:1')
Solve time for step 1 9.083168369019404
Current ori: tensor([-0.0380,  0.0487, -0.0890], device='cuda:1')
Index force: tensor([0.5848, 0.5013, 0.5860, 0.6024], device='cuda:1')
tensor([ 0.1714,  0.6935,  0.5194,  0.6118, -0.2754,  0.5226,  0.8307,  0.9662,
         1.3222,  0.1802,  0.1286,  1.1410, -0.0885,  0.1124, -0.0890, -5.8728],
       device='cuda:1')
Solve time for step 2 3.6407255069934763
Current ori: tensor([-0.0885,  0.1124, -0.0890], device='cuda:1')
Index force: tensor([0.5010, 0.5775, 0.5909], device='cuda:1')
tensor([ 0.1478,  0.7418,  0.5213,  0.6124, -0.2830,  0.5221,  0.8186,  0.9666,
         1.3496,  0.1916,  0.1391,  1.1570, -0.2151,  0.2466, -0.1036, -5.5512],
       device='cuda:1')
Solve time for step 3 3.5916981190093793
Current ori: tensor([-0.2151,  0.2466, -0.1036], device='cuda:1')
Index force: tensor([0.5574, 0.5784], device='cuda:1')
tensor([ 0.0334,  0.7960,  0.5813,  0.6267, -0.2884,  0.5244,  0.8150,  0.9634,
         1.4035,  0.1828,  0.1693,  1.1604, -0.5020,  0.5810, -0.1035, -4.8007],
       device='cuda:1')
Solve time for step 4 3.402806845959276
Current ori: tensor([-0.5020,  0.5810, -0.1035], device='cuda:1')
Index force: tensor([0.5005], device='cuda:1')
Storing RECOVERY transition: reward=-1.0230 (scaled=-0.5115), steps=2
Reward stats updated: mean 0.0147 -> 0.0138, std: 0.0932
Collected 533 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=1.3407, Q2 Loss=1.3407, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2291
SAC Update 2/5: Actor Loss=-0.0101, Q1 Loss=1.5755, Q2 Loss=1.5755, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.1154
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=0.9856, Q2 Loss=0.9856, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6952
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.8832, Q2 Loss=0.8832, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9133
SAC Update 5/5: Actor Loss=-0.0080, Q1 Loss=2.5446, Q2 Loss=2.5446, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5760

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.2%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.09s (37.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008772
Q1 loss: 1.465910
Q2 loss: 1.465910
Current threshold: -149.4964
Global Scale Offset: 5312.8424
Reward stats: mean=0.0138, std=0.0932, count=533
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.4659, Q2 Loss: 1.4659, Entropy: 0.6931, Mean TD Error: 2.5058, Threshold: -149.4964
Original likelihood: -1985.38720703125
Adjusted likelihood: -1985.38720703125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3649)
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 35
Loaded trajectory sampler
Current yaw: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
Current yaw: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
1 turn
Sampling time 3.6997591460240074
tensor([ 1.1804e-01,  5.5501e-01,  5.8884e-01,  6.5219e-01, -9.8543e-02,
         5.2955e-01,  8.9905e-01,  8.3016e-01,  1.2007e+00,  3.1231e-01,
         2.9091e-01,  1.1628e+00,  1.3754e-04,  1.4038e-02, -4.5622e-02,
         3.6219e-01], device='cuda:1')
Original likelihood: -86.85284423828125
Adjusted likelihood: -86.85284423828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5047)
State is out of distribution
Projection step: 0, Loss: 85.67730712890625
Final likelihood: tensor([ -71.4684,  -87.5068,  -58.1352,  -67.3722,  -71.2162, -111.7453,
        -116.7127,  -65.8672,  -98.3205, -128.7340, -100.5629,  -84.7583,
         -65.3510,  -66.0985,  -89.8030,  -87.1846])
Final projection likelihood: -85.6773
1 mode projection succeeded
New goal: tensor([ 1.1804e-01,  5.5501e-01,  5.8884e-01,  6.5219e-01, -9.8543e-02,
         5.2955e-01,  8.9905e-01,  8.3016e-01,  1.2007e+00,  3.1231e-01,
         2.9091e-01,  1.1628e+00,  1.3754e-04,  1.4038e-02, -4.5622e-02],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
2 turn
Sampling time 3.6413890690309927
tensor([ 1.1804e-01,  5.5501e-01,  5.8884e-01,  6.5219e-01, -9.8543e-02,
         5.2955e-01,  8.9905e-01,  8.3016e-01,  1.2007e+00,  3.1231e-01,
         2.9091e-01,  1.1628e+00,  1.3754e-04,  1.4038e-02, -4.5622e-02,
         3.6219e-01], device='cuda:1')
Original likelihood: -84.39555358886719
Adjusted likelihood: -84.39555358886719
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5049)
Solve time for step 1 14.190414201002568
Current ori: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
Middle force: tensor([1.1575, 0.5028, 0.5438, 0.5454, 1.3412, 0.5315, 0.5175, 0.5847, 0.6415,
        0.5939, 0.4853, 0.7030], device='cuda:1')
Thumb force: tensor([1.2516, 0.5625, 0.6204, 1.6993, 0.7795, 0.5181, 0.5348, 0.5326, 0.8432,
        0.5895, 0.6192, 0.5676], device='cuda:1')
Index force: tensor([0.5753, 0.5183, 0.5725, 0.5009, 0.5769, 0.6483, 0.5684, 0.5750, 0.5768,
        0.5904, 0.7690, 0.5682], device='cuda:1')
Storing NORMAL transition: reward=0.1629 (scaled=0.1629), steps=1
Reward stats updated: mean 0.0138 -> 0.0140, std: 0.0934
Collected 534 transitions for RL
SAC Update 1/5: Actor Loss=-0.0122, Q1 Loss=1.5850, Q2 Loss=1.5850, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4826
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=1.5427, Q2 Loss=1.5427, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8059
SAC Update 3/5: Actor Loss=-0.0105, Q1 Loss=1.0601, Q2 Loss=1.0601, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1113
SAC Update 4/5: Actor Loss=-0.0081, Q1 Loss=0.8756, Q2 Loss=0.8756, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9161
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=0.9565, Q2 Loss=0.9565, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4855

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.9%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010171
Q1 loss: 1.203974
Q2 loss: 1.203974
Current threshold: -149.4962
Global Scale Offset: 5320.8638
Reward stats: mean=0.0140, std=0.0934, count=534
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.2040, Q2 Loss: 1.2040, Entropy: 0.6931, Mean TD Error: 0.9603, Threshold: -149.4962
tensor([ 0.2036,  0.5946,  0.6161,  0.6364, -0.1482,  0.4800,  0.9161,  0.8744,
         1.3057,  0.3273,  0.2765,  1.0101, -0.0168,  0.0448, -0.2115, -0.2668],
       device='cuda:1')
Original likelihood: -167.74876403808594
Adjusted likelihood: -167.74876403808594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4986)
State is out of distribution
Projection step: 0, Loss: 181.83807373046875
Projection step: 1, Loss: 182.35398864746094
Projection step: 2, Loss: 173.63015747070312
Projection step: 3, Loss: 171.03199768066406
Projection step: 4, Loss: 159.1568603515625
Projection step: 5, Loss: 158.22401428222656
Projection step: 6, Loss: 156.9832000732422
Projection step: 7, Loss: 150.497314453125
Projection step: 8, Loss: 148.67974853515625
Projection step: 9, Loss: 141.24716186523438
Projection step: 10, Loss: 145.19395446777344
Projection step: 11, Loss: 137.51766967773438
Projection step: 12, Loss: 137.90133666992188
Projection step: 13, Loss: 137.8274688720703
Projection step: 14, Loss: 127.19093322753906
Projection step: 15, Loss: 123.32270812988281
Projection step: 16, Loss: 116.4879150390625
Projection step: 17, Loss: 115.90675354003906
Projection step: 18, Loss: 120.15750122070312
Projection step: 19, Loss: 105.02398681640625
Projection step: 20, Loss: 105.8321533203125
Projection step: 21, Loss: 99.26930236816406
Final likelihood: tensor([ -85.1539,  -99.4768,  -92.6612,  -93.3704, -104.0000, -143.3704,
         -93.6737, -127.8276,  -95.5637,  -89.9719, -100.3682, -101.9250,
         -86.6713,  -90.9505,  -82.9841, -100.3399])
Final projection likelihood: -99.2693
1 mode projection succeeded
New goal: tensor([ 0.1255,  0.5090,  0.6285,  0.6668, -0.0874,  0.5515,  0.8815,  0.8647,
         1.3175,  0.3376,  0.2558,  1.0743, -0.0216,  0.0263, -0.8371],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -173.2279052734375
Adjusted likelihood: -173.2279052734375
Likelihood residual: 0.0
Original likelihood: -95.1625747680664
Adjusted likelihood: -95.1625747680664
Likelihood residual: 0.0
{'index': 95.1625747680664, 'thumb_middle': 173.2279052734375}
Current yaw: tensor([-0.0168,  0.0448, -0.2115], device='cuda:1')
3 index
tensor([ 0.2036,  0.5946,  0.6161,  0.6364, -0.1482,  0.4800,  0.9161,  0.8744,
         1.3057,  0.3273,  0.2765,  1.0101, -0.0168,  0.0448, -0.2115, -0.2668],
       device='cuda:1')
Solve time for step 1 10.700375451007858
Current ori: tensor([-0.0168,  0.0448, -0.2115], device='cuda:1')
Middle force: tensor([0.5302, 0.5624, 0.5628, 0.5165], device='cuda:1')
Thumb force: tensor([0.5459, 0.5284, 0.5537, 0.5085], device='cuda:1')
tensor([ 0.1753,  0.4712,  0.5787,  0.6360, -0.1322,  0.5117,  0.8843,  0.8710,
         1.3146,  0.3128,  0.2558,  0.9998, -0.0280,  0.0357, -0.2228, -0.1814],
       device='cuda:1')
Solve time for step 2 4.122648153977934
Current ori: tensor([-0.0280,  0.0357, -0.2228], device='cuda:1')
Middle force: tensor([0.5600, 0.5582, 0.5147], device='cuda:1')
Thumb force: tensor([0.5257, 0.5507, 0.5076], device='cuda:1')
tensor([ 0.1714,  0.4652,  0.5794,  0.6402, -0.1130,  0.5303,  0.8768,  0.8637,
         1.3166,  0.3025,  0.2274,  1.0139, -0.0338,  0.0230, -0.2291,  0.0990],
       device='cuda:1')
Solve time for step 3 3.963910288992338
Current ori: tensor([-0.0338,  0.0230, -0.2291], device='cuda:1')
Middle force: tensor([0.5063, 0.5290], device='cuda:1')
Thumb force: tensor([0.5199, 0.5866], device='cuda:1')
tensor([ 0.1703,  0.4631,  0.5815,  0.6414, -0.1057,  0.5240,  0.8853,  0.8789,
         1.3061,  0.3119,  0.2143,  1.0462, -0.0286,  0.0173, -0.2284,  0.4650],
       device='cuda:1')
Solve time for step 4 3.951879522006493
Current ori: tensor([-0.0286,  0.0173, -0.2284], device='cuda:1')
Middle force: tensor([0.5173], device='cuda:1')
Thumb force: tensor([0.5013], device='cuda:1')
Storing RECOVERY transition: reward=0.0162 (scaled=0.0162), steps=1
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0933
Collected 535 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=1.1009, Q2 Loss=1.1009, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7888
SAC Update 2/5: Actor Loss=-0.0099, Q1 Loss=1.2837, Q2 Loss=1.2837, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5086
SAC Update 3/5: Actor Loss=-0.0103, Q1 Loss=2.8609, Q2 Loss=2.8609, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3233
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7334, Q2 Loss=0.7334, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0981
SAC Update 5/5: Actor Loss=-0.0105, Q1 Loss=1.0961, Q2 Loss=1.0961, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5087

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.5%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.04s (17.5%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009297
Q1 loss: 1.414991
Q2 loss: 1.414991
Current threshold: -149.4960
Global Scale Offset: 5335.7798
Reward stats: mean=0.0140, std=0.0933, count=535
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.4150, Q2 Loss: 1.4150, Entropy: 0.6931, Mean TD Error: 1.2455, Threshold: -149.4960
Original likelihood: -99.59618377685547
Adjusted likelihood: -99.59618377685547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5037)
State is out of distribution
Projection step: 0, Loss: 96.9234619140625
Final likelihood: tensor([-146.5572,  -82.9094,  -99.8261, -145.2840,  -87.0504,  -55.8406,
         -99.1886,  -91.0437, -114.9248,  -88.9579,  -77.2243,  -91.6817,
         -96.3462,  -87.0689,  -82.8079, -104.0640])
Final projection likelihood: -96.9235
1 mode projection succeeded
New goal: tensor([ 0.1183,  0.5217,  0.6255,  0.6652, -0.0970,  0.5335,  0.8819,  0.8726,
         1.2979,  0.3206,  0.2088,  1.0507, -0.0308,  0.0114, -0.2261],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0308,  0.0114, -0.2261], device='cuda:1')
4 turn
Sampling time 3.594193874974735
tensor([ 0.1183,  0.5217,  0.6255,  0.6652, -0.0970,  0.5335,  0.8819,  0.8726,
         1.2979,  0.3206,  0.2088,  1.0507, -0.0308,  0.0114, -0.2261,  0.6015],
       device='cuda:1')
Original likelihood: -98.97615814208984
Adjusted likelihood: -98.97615814208984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5038)
Solve time for step 1 13.963369586970657
Current ori: tensor([-0.0308,  0.0114, -0.2261], device='cuda:1')
Middle force: tensor([0.5827, 0.5361, 0.5803, 0.5414, 0.5759, 1.0463, 0.5549, 0.5559, 0.6827,
        0.5558, 0.8047, 0.5688], device='cuda:1')
Thumb force: tensor([0.5001, 0.5225, 1.3499, 0.7089, 0.5857, 0.8143, 0.6107, 0.5617, 0.6456,
        0.5357, 0.6399, 0.5957], device='cuda:1')
Index force: tensor([0.5551, 0.5695, 0.5047, 0.6236, 0.5741, 0.5169, 0.5172, 0.5606, 0.5451,
        0.5854, 0.7467, 0.5296], device='cuda:1')
Storing NORMAL transition: reward=0.0647 (scaled=0.0647), steps=1
Reward stats updated: mean 0.0140 -> 0.0141, std: 0.0932
Collected 536 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=1.0225, Q2 Loss=1.0225, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1608
SAC Update 2/5: Actor Loss=-0.0078, Q1 Loss=0.8526, Q2 Loss=0.8526, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5146
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.7619, Q2 Loss=1.7619, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.5444
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.7738, Q2 Loss=0.7738, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6690
SAC Update 5/5: Actor Loss=-0.0095, Q1 Loss=0.9981, Q2 Loss=0.9981, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5411

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.4%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008132
Q1 loss: 1.081794
Q2 loss: 1.081794
Current threshold: -149.4959
Global Scale Offset: 5346.3118
Reward stats: mean=0.0141, std=0.0932, count=536
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.0818, Q2 Loss: 1.0818, Entropy: 0.6931, Mean TD Error: 2.0860, Threshold: -149.4959
tensor([ 0.1226,  0.4980,  0.6370,  0.7145, -0.0963,  0.4984,  0.9210,  0.9053,
         1.3358,  0.2607,  0.1819,  1.0585, -0.0213,  0.0084, -0.2904,  0.7137],
       device='cuda:1')
Original likelihood: -99.9313735961914
Adjusted likelihood: -99.9313735961914
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5037)
State is out of distribution
Projection step: 0, Loss: 95.47327423095703
Final likelihood: tensor([ -95.5067,  -95.7724,  -97.2888,  -89.7969,  -84.4957,  -93.8507,
         -95.2229,  -84.7405, -108.9057,  -89.2998, -101.7309,  -84.0781,
         -93.7364, -110.5886,  -91.5490, -111.0090])
Final projection likelihood: -95.4733
1 mode projection succeeded
New goal: tensor([ 0.1226,  0.4980,  0.6370,  0.7145, -0.0963,  0.4984,  0.9210,  0.9053,
         1.3358,  0.2607,  0.1819,  1.0585, -0.0213,  0.0084, -0.2904],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0213,  0.0084, -0.2904], device='cuda:1')
5 turn
Sampling time 3.5805042199790478
tensor([ 0.1226,  0.4980,  0.6370,  0.7145, -0.0963,  0.4984,  0.9210,  0.9053,
         1.3358,  0.2607,  0.1819,  1.0585, -0.0213,  0.0084, -0.2904,  0.7137],
       device='cuda:1')
Original likelihood: -95.77102661132812
Adjusted likelihood: -95.77102661132812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5040)
State is out of distribution
Projection step: 0, Loss: 95.02311706542969
Final likelihood: tensor([-107.2855,  -88.6090, -101.9138,  -96.8466,  -76.1397,  -89.2017,
         -90.1353,  -85.6997, -110.4495,  -98.1615,  -81.0104, -111.8132,
        -103.0525,  -89.2647,  -84.4561, -106.3307])
Final projection likelihood: -95.0231
1 mode projection succeeded
New goal: tensor([ 0.1226,  0.4980,  0.6370,  0.7145, -0.0963,  0.4984,  0.9210,  0.9053,
         1.3358,  0.2607,  0.1819,  1.0585, -0.0213,  0.0084, -0.2904],
       device='cuda:1')
Goal is the same as current state
Current yaw: tensor([-0.0213,  0.0084, -0.2904], device='cuda:1')
6 turn
Sampling time 3.6127966449712403
tensor([ 0.1226,  0.4980,  0.6370,  0.7145, -0.0963,  0.4984,  0.9210,  0.9053,
         1.3358,  0.2607,  0.1819,  1.0585, -0.0213,  0.0084, -0.2904,  0.7137],
       device='cuda:1')
Original likelihood: -94.0516357421875
Adjusted likelihood: -94.0516357421875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5041)
Solve time for step 1 14.135492104978766
Current ori: tensor([-0.0213,  0.0084, -0.2904], device='cuda:1')
Middle force: tensor([0.5126, 0.5521, 0.5546, 1.5371, 0.5440, 1.0687, 0.5042, 0.9797, 0.6513,
        0.5721, 0.5980, 0.5877], device='cuda:1')
Thumb force: tensor([0.5931, 0.7124, 0.5450, 1.2273, 0.5429, 0.7421, 0.5209, 1.1493, 1.6200,
        0.5179, 0.5697, 0.5832], device='cuda:1')
Index force: tensor([0.6920, 0.5027, 0.5389, 0.5134, 0.5622, 0.6095, 0.7154, 0.5688, 0.5598,
        0.5593, 0.5595, 0.5908], device='cuda:1')
Storing NORMAL transition: reward=-0.0283 (scaled=-0.0283), steps=1
Reward stats updated: mean 0.0141 -> 0.0141, std: 0.0932
Collected 537 transitions for RL
SAC Update 1/5: Actor Loss=-0.0082, Q1 Loss=1.0091, Q2 Loss=1.0091, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3868
SAC Update 2/5: Actor Loss=-0.0100, Q1 Loss=1.0326, Q2 Loss=1.0326, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4479
SAC Update 3/5: Actor Loss=-0.0091, Q1 Loss=0.9389, Q2 Loss=0.9389, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4202
SAC Update 4/5: Actor Loss=-0.0085, Q1 Loss=0.8621, Q2 Loss=0.8621, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3930
SAC Update 5/5: Actor Loss=-0.0097, Q1 Loss=1.0537, Q2 Loss=1.0537, Entropy=0.6929, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8753

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.6%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.9%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009117
Q1 loss: 0.979271
Q2 loss: 0.979271
Current threshold: -149.4958
Global Scale Offset: 5352.5989
Reward stats: mean=0.0141, std=0.0932, count=537
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 0.9793, Q2 Loss: 0.9793, Entropy: 0.6931, Mean TD Error: 0.7046, Threshold: -149.4958
tensor([ 0.0688,  0.4833,  0.6533,  0.6198, -0.1327,  0.5151,  0.8636,  0.9181,
         1.3826,  0.1082,  0.2685,  0.9814, -0.0261,  0.0347, -0.2633,  0.6632],
       device='cuda:1')
Original likelihood: -124.93177795410156
Adjusted likelihood: -124.93177795410156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5018)
Solve time for step 2 5.5505135980201885
Current ori: tensor([-0.0261,  0.0347, -0.2633], device='cuda:1')
Middle force: tensor([0.5434, 0.5480, 1.4209, 0.5394, 1.0100, 0.5031, 0.9170, 0.6316, 0.5602,
        0.5875, 0.5761], device='cuda:1')
Thumb force: tensor([0.6787, 0.5354, 1.1045, 0.5347, 0.6990, 0.5171, 1.0601, 1.4762, 0.5116,
        0.5589, 0.5709], device='cuda:1')
Index force: tensor([0.5028, 0.5361, 0.5104, 0.5540, 0.5876, 0.6984, 0.5561, 0.5512, 0.5532,
        0.5521, 0.5795], device='cuda:1')
Storing NORMAL transition: reward=0.0112 (scaled=0.0112), steps=1
Reward stats updated: mean 0.0141 -> 0.0141, std: 0.0931
Collected 538 transitions for RL
SAC Update 1/5: Actor Loss=-0.0110, Q1 Loss=1.2335, Q2 Loss=1.2335, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8719
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9306, Q2 Loss=0.9306, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7982
SAC Update 3/5: Actor Loss=-0.0109, Q1 Loss=1.2297, Q2 Loss=1.2297, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8899
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=0.9006, Q2 Loss=0.9006, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4587
SAC Update 5/5: Actor Loss=-0.0135, Q1 Loss=1.5460, Q2 Loss=1.5460, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9802

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.5%)
Actor update: 0.10s (41.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010421
Q1 loss: 1.168078
Q2 loss: 1.168078
Current threshold: -149.4958
Global Scale Offset: 5368.2845
Reward stats: mean=0.0141, std=0.0931, count=538
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.1681, Q2 Loss: 1.1681, Entropy: 0.6931, Mean TD Error: 0.7998, Threshold: -149.4958
tensor([ 0.0198,  0.4687,  0.6007,  0.6777, -0.1703,  0.4724,  0.9081,  0.9157,
         1.3793,  0.0120,  0.3069,  1.0285, -0.0184,  0.0562, -0.2761,  0.6302],
       device='cuda:1')
Original likelihood: -194.4315185546875
Adjusted likelihood: -194.4315185546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4967)
State is out of distribution
Projection step: 0, Loss: 194.87008666992188
Projection step: 1, Loss: 184.835693359375
Projection step: 2, Loss: 173.18641662597656
Projection step: 3, Loss: 173.19964599609375
Projection step: 4, Loss: 178.3368682861328
Projection step: 5, Loss: 157.78656005859375
Projection step: 6, Loss: 153.66543579101562
Projection step: 7, Loss: 150.29498291015625
Projection step: 8, Loss: 135.94619750976562
Projection step: 9, Loss: 137.09808349609375
Projection step: 10, Loss: 133.7271728515625
Projection step: 11, Loss: 136.68431091308594
Projection step: 12, Loss: 125.42761993408203
Projection step: 13, Loss: 128.71234130859375
Projection step: 14, Loss: 123.51045227050781
Projection step: 15, Loss: 134.7351837158203
Projection step: 16, Loss: 129.93441772460938
Projection step: 17, Loss: 117.7100830078125
Projection step: 18, Loss: 119.07435607910156
Projection step: 19, Loss: 118.05208587646484
Projection step: 20, Loss: 110.70802307128906
Projection step: 21, Loss: 116.40077209472656
Projection step: 22, Loss: 108.73204040527344
Projection step: 23, Loss: 118.10652923583984
Projection step: 24, Loss: 116.10444641113281
Final likelihood: tensor([-156.4452,  -98.9693, -113.3442, -107.0331, -100.7360,  -92.5723,
        -163.3809, -160.3859,  -98.7006, -141.1094, -139.7782, -126.7997,
        -101.6208, -104.2229,  -96.0872, -163.3224])
Final projection likelihood: -122.7818
1 mode projection succeeded
New goal: tensor([ 0.0328,  0.5514,  0.4724,  0.7104, -0.1190,  0.4707,  0.8900,  0.8066,
         1.3264,  0.1217,  0.1991,  1.0681, -0.0256,  0.0363, -0.5071],
       device='cuda:1')
tensor([[0.0086]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -121.53038024902344
Adjusted likelihood: -121.53038024902344
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 121.53038024902344}
Current yaw: tensor([-0.0184,  0.0562, -0.2761], device='cuda:1')
7 thumb_middle
tensor([ 0.0198,  0.4687,  0.6007,  0.6777, -0.1703,  0.4724,  0.9081,  0.9157,
         1.3793,  0.0120,  0.3069,  1.0285, -0.0184,  0.0562, -0.2761,  0.6302],
       device='cuda:1')
Solve time for step 1 8.785512774949893
Current ori: tensor([-0.0184,  0.0562, -0.2761], device='cuda:1')
Index force: tensor([0.6039, 0.6050, 0.6065, 0.5993], device='cuda:1')
tensor([ 0.0224,  0.5292,  0.5015,  0.7130, -0.2180,  0.4589,  0.8706,  0.8113,
         1.3352,  0.0919,  0.1933,  1.0574, -0.0287,  0.0575, -0.2761,  0.6105],
       device='cuda:1')
Solve time for step 2 3.5513948230072856
Current ori: tensor([-0.0287,  0.0575, -0.2761], device='cuda:1')
Index force: tensor([0.5932, 0.5952, 0.5869], device='cuda:1')
tensor([ 0.0350,  0.5505,  0.4810,  0.7166, -0.2147,  0.4707,  0.8679,  0.7926,
         1.3319,  0.1096,  0.1694,  1.0630, -0.0337,  0.0494, -0.2760,  0.6316],
       device='cuda:1')
Solve time for step 3 3.4668742009671405
Current ori: tensor([-0.0337,  0.0494, -0.2760], device='cuda:1')
Index force: tensor([0.5540, 0.5628], device='cuda:1')
tensor([ 0.0535,  0.5543,  0.4856,  0.7306, -0.2031,  0.4771,  0.8704,  0.7727,
         1.3137,  0.1092,  0.1718,  1.0700, -0.0338,  0.0386, -0.2760,  0.6581],
       device='cuda:1')
Solve time for step 4 3.4218610389507376
Current ori: tensor([-0.0338,  0.0386, -0.2760], device='cuda:1')
Index force: tensor([0.5630], device='cuda:1')
Storing RECOVERY transition: reward=0.0172 (scaled=0.0086), steps=2
Reward stats updated: mean 0.0141 -> 0.0140, std: 0.0930
Collected 539 transitions for RL
SAC Update 1/5: Actor Loss=-0.0110, Q1 Loss=1.5372, Q2 Loss=1.5372, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6961
SAC Update 2/5: Actor Loss=-0.0076, Q1 Loss=0.8082, Q2 Loss=0.8082, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7136
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=0.8108, Q2 Loss=0.8108, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1760
SAC Update 4/5: Actor Loss=-0.0133, Q1 Loss=1.9275, Q2 Loss=1.9275, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7925
SAC Update 5/5: Actor Loss=-0.0082, Q1 Loss=0.9536, Q2 Loss=0.9536, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6626

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.6%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (17.6%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009412
Q1 loss: 1.207475
Q2 loss: 1.207475
Current threshold: -149.4957
Global Scale Offset: 5397.9089
Reward stats: mean=0.0140, std=0.0930, count=539
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.2075, Q2 Loss: 1.2075, Entropy: 0.6931, Mean TD Error: 1.6081, Threshold: -149.4957
Original likelihood: -127.16083526611328
Adjusted likelihood: -127.16083526611328
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5017)
State is out of distribution
Projection step: 0, Loss: 125.27410888671875
Projection step: 1, Loss: 120.92819213867188
Projection step: 2, Loss: 110.14354705810547
Projection step: 3, Loss: 110.89259338378906
Projection step: 4, Loss: 102.23475646972656
Final likelihood: tensor([-100.4065,  -92.1661,  -96.1023, -110.6512,  -93.9726,  -94.7449,
         -79.3270,  -95.7829, -114.3516, -111.5883, -122.0745, -112.0169,
        -115.9541,  -97.8727,  -99.9126,  -98.8318])
Final projection likelihood: -102.2348
1 mode projection succeeded
New goal: tensor([ 0.0570,  0.5807,  0.4436,  0.7466, -0.1059,  0.5333,  0.8790,  0.7853,
         1.3812,  0.1215,  0.1928,  1.0788, -0.0432,  0.0302, -0.1656],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -99.62306213378906
Adjusted likelihood: -99.62306213378906
Likelihood residual: 0.0
Original likelihood: -113.76296997070312
Adjusted likelihood: -113.76296997070312
Likelihood residual: 0.0
{'index': 113.76296997070312, 'thumb_middle': 99.62306213378906}
Current yaw: tensor([-0.0421,  0.0331, -0.2928], device='cuda:1')
8 thumb_middle
tensor([ 0.0553,  0.5819,  0.4613,  0.7056, -0.1250,  0.5318,  0.8986,  0.7854,
         1.3878,  0.1401,  0.2084,  1.0625, -0.0421,  0.0331, -0.2928,  0.7015],
       device='cuda:1')
Solve time for step 1 9.001453520962968
Current ori: tensor([-0.0421,  0.0331, -0.2928], device='cuda:1')
Index force: tensor([0.5634, 0.5919, 0.5898, 0.5000], device='cuda:1')
tensor([ 0.0581,  0.6150,  0.4217,  0.6959, -0.1988,  0.5151,  0.8536,  0.7672,
         1.3368,  0.0975,  0.1352,  1.0549, -0.0505,  0.0372, -0.2928,  0.6309],
       device='cuda:1')
Solve time for step 2 3.707341715984512
Current ori: tensor([-0.0505,  0.0372, -0.2928], device='cuda:1')
Index force: tensor([0.5047, 0.5790, 0.5003], device='cuda:1')
tensor([ 0.0556,  0.6221,  0.4148,  0.6842, -0.2087,  0.5171,  0.8455,  0.7619,
         1.3471,  0.0842,  0.1374,  1.0678, -0.0529,  0.0390, -0.2928,  0.6182],
       device='cuda:1')
Solve time for step 3 3.511682979995385
Current ori: tensor([-0.0529,  0.0390, -0.2928], device='cuda:1')
Index force: tensor([0.5820, 0.5978], device='cuda:1')
tensor([ 0.0664,  0.5966,  0.4357,  0.7352, -0.2082,  0.5212,  0.8462,  0.7636,
         1.3429,  0.0863,  0.1324,  1.0648, -0.0430,  0.0316, -0.2928,  0.6677],
       device='cuda:1')
Solve time for step 4 3.3888519660104066
Current ori: tensor([-0.0430,  0.0316, -0.2928], device='cuda:1')
Index force: tensor([0.5876], device='cuda:1')
Storing RECOVERY transition: reward=0.0218 (scaled=0.0109), steps=2
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0929
Collected 540 transitions for RL
SAC Update 1/5: Actor Loss=-0.0085, Q1 Loss=1.4513, Q2 Loss=1.4513, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8183
SAC Update 2/5: Actor Loss=-0.0085, Q1 Loss=1.1689, Q2 Loss=1.1689, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0104
SAC Update 3/5: Actor Loss=-0.0090, Q1 Loss=0.9375, Q2 Loss=0.9375, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6012
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=1.2053, Q2 Loss=1.2053, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.4106
SAC Update 5/5: Actor Loss=-0.0086, Q1 Loss=1.1525, Q2 Loss=1.1525, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8207

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.7%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (38.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008575
Q1 loss: 1.183101
Q2 loss: 1.183101
Current threshold: -149.4956
Global Scale Offset: 5429.1527
Reward stats: mean=0.0140, std=0.0929, count=540
----------------------------------------------
SAC Update - Actor Loss: -0.0086, Q1 Loss: 1.1831, Q2 Loss: 1.1831, Entropy: 0.6931, Mean TD Error: 1.7323, Threshold: -149.4956
Original likelihood: -125.78221130371094
Adjusted likelihood: -125.78221130371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5017)
Current yaw: tensor([-0.0415,  0.0345, -0.2975], device='cuda:1')
9 turn
Sampling time 3.590919730020687
tensor([ 0.0549,  0.5886,  0.4400,  0.7278, -0.1465,  0.5661,  0.8832,  0.7844,
         1.4085,  0.1203,  0.1785,  1.0913, -0.0415,  0.0345, -0.2975,  0.6970],
       device='cuda:1')
Original likelihood: -123.9557876586914
Adjusted likelihood: -123.9557876586914
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5019)
State is out of distribution
Projection step: 0, Loss: 123.076416015625
Projection step: 1, Loss: 116.02316284179688
Projection step: 2, Loss: 111.42041778564453
Projection step: 3, Loss: 108.83879089355469
Projection step: 4, Loss: 108.18637084960938
Projection step: 5, Loss: 100.85224914550781
Final likelihood: tensor([-101.4265, -106.6254,  -97.4840,  -99.3470, -101.4625, -106.2567,
         -98.8156, -128.7767, -102.2759, -100.8478,  -89.8420, -100.3075,
         -96.8949,  -99.6419,  -89.9223,  -93.7092])
Final projection likelihood: -100.8522
1 mode projection succeeded
New goal: tensor([ 0.0605,  0.5873,  0.4355,  0.7545, -0.1202,  0.5614,  0.8666,  0.7841,
         1.4019,  0.0945,  0.1601,  1.1185, -0.0423,  0.0317, -0.1252],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -111.6231689453125
Adjusted likelihood: -111.6231689453125
Likelihood residual: 0.0
Original likelihood: -107.67608642578125
Adjusted likelihood: -107.67608642578125
Likelihood residual: 0.0
{'index': 107.67608642578125, 'thumb_middle': 111.6231689453125}
Current yaw: tensor([-0.0415,  0.0345, -0.2975], device='cuda:1')
10 index
tensor([ 0.0549,  0.5886,  0.4400,  0.7278, -0.1465,  0.5661,  0.8832,  0.7844,
         1.4085,  0.1203,  0.1785,  1.0913, -0.0415,  0.0345, -0.2975,  0.6970],
       device='cuda:1')
Solve time for step 1 10.987381830986124
Current ori: tensor([-0.0415,  0.0345, -0.2975], device='cuda:1')
Middle force: tensor([0.5546, 0.5363, 0.5748, 0.5662], device='cuda:1')
Thumb force: tensor([0.5343, 0.5235, 0.5531, 0.5530], device='cuda:1')
tensor([ 0.1000,  0.5277,  0.3871,  0.7229, -0.1588,  0.5779,  0.8809,  0.7906,
         1.4677,  0.0372,  0.1411,  1.0881, -0.0638,  0.0393, -0.3050,  2.1296],
       device='cuda:1')
Solve time for step 2 4.283045305986889
Current ori: tensor([-0.0638,  0.0393, -0.3050], device='cuda:1')
Middle force: tensor([0.5346, 0.5718, 0.5624], device='cuda:1')
Thumb force: tensor([0.5213, 0.5501, 0.5504], device='cuda:1')
tensor([ 0.0996,  0.5282,  0.3840,  0.7245, -0.1565,  0.5699,  0.8880,  0.8057,
         1.4310,  0.1157,  0.1345,  1.1089, -0.0634,  0.0370, -0.3341,  2.8569],
       device='cuda:1')
Solve time for step 3 4.370452108967584
Current ori: tensor([-0.0634,  0.0370, -0.3341], device='cuda:1')
Middle force: tensor([0.5807, 0.5706], device='cuda:1')
Thumb force: tensor([0.5337, 0.5419], device='cuda:1')
tensor([ 0.0981,  0.5268,  0.3844,  0.7241, -0.1627,  0.5699,  0.8844,  0.8022,
         1.4463,  0.0978,  0.1266,  1.1183, -0.0654,  0.0422, -0.3396,  2.9336],
       device='cuda:1')
Solve time for step 4 4.108729044965003
Current ori: tensor([-0.0654,  0.0422, -0.3396], device='cuda:1')
Middle force: tensor([0.5008], device='cuda:1')
Thumb force: tensor([0.5379], device='cuda:1')
Storing RECOVERY transition: reward=0.0389 (scaled=0.0389), steps=0
Reward stats updated: mean 0.0140 -> 0.0141, std: 0.0928
Collected 541 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=1.1427, Q2 Loss=1.1427, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2305
SAC Update 2/5: Actor Loss=-0.0128, Q1 Loss=1.5641, Q2 Loss=1.5641, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2634
SAC Update 3/5: Actor Loss=-0.0107, Q1 Loss=1.1089, Q2 Loss=1.1089, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4919
SAC Update 4/5: Actor Loss=-0.0101, Q1 Loss=1.1132, Q2 Loss=1.1132, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9200
SAC Update 5/5: Actor Loss=-0.0114, Q1 Loss=1.1640, Q2 Loss=1.1640, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2958

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (20.2%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011268
Q1 loss: 1.218563
Q2 loss: 1.218563
Current threshold: -149.4956
Global Scale Offset: 5451.1214
Reward stats: mean=0.0141, std=0.0928, count=541
----------------------------------------------
SAC Update - Actor Loss: -0.0113, Q1 Loss: 1.2186, Q2 Loss: 1.2186, Entropy: 0.6931, Mean TD Error: 0.6403, Threshold: -149.4956
Original likelihood: -160.78524780273438
Adjusted likelihood: -160.78524780273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4992)
Current yaw: tensor([-0.0660,  0.0488, -0.3405], device='cuda:1')
11 turn
Sampling time 3.7717070099897683
tensor([ 0.0483,  0.5858,  0.4235,  0.7471, -0.1715,  0.5674,  0.8821,  0.8007,
         1.4480,  0.1134,  0.1204,  1.1312, -0.0660,  0.0488, -0.3405,  2.8731],
       device='cuda:1')
Original likelihood: -161.3213348388672
Adjusted likelihood: -161.3213348388672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4991)
Solve time for step 1 14.545008838991635
Current ori: tensor([-0.0660,  0.0488, -0.3405], device='cuda:1')
Middle force: tensor([0.9110, 0.5033, 0.5347, 0.5130, 0.5364, 0.8253, 0.5194, 0.5922, 0.6855,
        0.5498, 1.2884, 0.8053], device='cuda:1')
Thumb force: tensor([0.5305, 0.5346, 0.9126, 0.6638, 1.1301, 0.5297, 0.5806, 0.9100, 1.2497,
        0.5867, 1.8559, 0.5940], device='cuda:1')
Index force: tensor([0.5080, 0.7104, 0.5960, 0.5205, 0.5897, 0.5666, 0.5419, 0.5970, 0.6154,
        0.5398, 0.6920, 0.7781], device='cuda:1')
Storing NORMAL transition: reward=-0.0442 (scaled=-0.0442), steps=1
Reward stats updated: mean 0.0141 -> 0.0140, std: 0.0928
Collected 542 transitions for RL
SAC Update 1/5: Actor Loss=-0.0089, Q1 Loss=1.8841, Q2 Loss=1.8841, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3481
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9482, Q2 Loss=0.9482, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5787
SAC Update 3/5: Actor Loss=-0.0074, Q1 Loss=0.9355, Q2 Loss=0.9355, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8965
SAC Update 4/5: Actor Loss=-0.0082, Q1 Loss=0.9537, Q2 Loss=0.9537, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7182
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=0.8592, Q2 Loss=0.8592, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6586

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.2%)
Q1 update: 0.06s (20.8%)
Q2 update: 0.06s (19.9%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008084
Q1 loss: 1.116160
Q2 loss: 1.116160
Current threshold: -149.4955
Global Scale Offset: 5468.5520
Reward stats: mean=0.0140, std=0.0928, count=542
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 1.1162, Q2 Loss: 1.1162, Entropy: 0.6931, Mean TD Error: 1.6400, Threshold: -149.4955
tensor([ 0.0309,  0.5611,  0.4477,  0.7375, -0.1631,  0.5974,  0.8525,  0.7924,
         1.4382,  0.3394, -0.0114,  1.1751, -0.0614,  0.0410, -0.2947,  2.9844],
       device='cuda:1')
Original likelihood: -166.592041015625
Adjusted likelihood: -166.592041015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4988)
State is out of distribution
Projection step: 0, Loss: 166.7564697265625
Projection step: 1, Loss: 155.82188415527344
Projection step: 2, Loss: 160.59030151367188
Projection step: 3, Loss: 159.4215087890625
Projection step: 4, Loss: 145.5423583984375
Projection step: 5, Loss: 147.17715454101562
Projection step: 6, Loss: 143.53585815429688
Projection step: 7, Loss: 144.93966674804688
Projection step: 8, Loss: 133.17575073242188
Projection step: 9, Loss: 131.38262939453125
Projection step: 10, Loss: 129.1435546875
Projection step: 11, Loss: 133.71469116210938
Projection step: 12, Loss: 122.54273986816406
Projection step: 13, Loss: 121.60875701904297
Projection step: 14, Loss: 120.730224609375
Projection step: 15, Loss: 117.07826232910156
Projection step: 16, Loss: 116.8459701538086
Projection step: 17, Loss: 118.78388977050781
Projection step: 18, Loss: 115.83200073242188
Projection step: 19, Loss: 116.5233154296875
Projection step: 20, Loss: 116.36204528808594
Projection step: 21, Loss: 114.32699584960938
Projection step: 22, Loss: 116.57626342773438
Projection step: 23, Loss: 110.88972473144531
Projection step: 24, Loss: 113.59403991699219
Final likelihood: tensor([-118.9993, -111.6642, -114.2065, -120.2887, -118.1972, -119.0939,
        -120.1901, -123.2136, -110.5286,  -92.3909, -122.4738, -134.4641,
        -113.7784,  -94.0315, -123.7866,  -88.1263])
Final projection likelihood: -114.0896
1 mode projection succeeded
New goal: tensor([ 0.0664,  0.5689,  0.4231,  0.8486, -0.0788,  0.5308,  0.8037,  0.8170,
         1.4153,  0.2171,  0.0880,  1.1305, -0.0584,  0.0305, -0.1991],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -112.43885040283203
Adjusted likelihood: -112.43885040283203
Likelihood residual: 0.0
Original likelihood: -152.29876708984375
Adjusted likelihood: -152.29876708984375
Likelihood residual: 0.0
{'index': 152.29876708984375, 'thumb_middle': 112.43885040283203}
Current yaw: tensor([-0.0614,  0.0410, -0.2947], device='cuda:1')
12 thumb_middle
tensor([ 0.0309,  0.5611,  0.4477,  0.7375, -0.1631,  0.5974,  0.8525,  0.7924,
         1.4382,  0.3394, -0.0114,  1.1751, -0.0614,  0.0410, -0.2947,  2.9844],
       device='cuda:1')
Solve time for step 1 9.020954766019713
Current ori: tensor([-0.0614,  0.0410, -0.2947], device='cuda:1')
Index force: tensor([0.5688, 0.6251, 0.5765, 0.5024], device='cuda:1')
tensor([ 0.0271,  0.5770,  0.3965,  0.7829, -0.1925,  0.5172,  0.7800,  0.7931,
         1.3735,  0.2189,  0.0110,  1.1148, -0.0576,  0.0673, -0.2947,  2.7910],
       device='cuda:1')
Solve time for step 2 3.4718675179756247
Current ori: tensor([-0.0576,  0.0673, -0.2947], device='cuda:1')
Index force: tensor([0.5827, 0.5838, 0.5983], device='cuda:1')
tensor([ 0.0470,  0.5636,  0.4155,  0.8206, -0.2019,  0.5160,  0.7817,  0.7969,
         1.3832,  0.2001,  0.0187,  1.1038, -0.0452,  0.0691, -0.2947,  2.7599],
       device='cuda:1')
Solve time for step 3 3.5915014750207774
Current ori: tensor([-0.0452,  0.0691, -0.2947], device='cuda:1')
Index force: tensor([0.5788, 0.5925], device='cuda:1')
tensor([ 0.0618,  0.5727,  0.4097,  0.8340, -0.2038,  0.5158,  0.7718,  0.7938,
         1.3769,  0.1911,  0.0401,  1.1079, -0.0446,  0.0630, -0.2947,  2.7669],
       device='cuda:1')
Solve time for step 4 3.4217426799586974
Current ori: tensor([-0.0446,  0.0630, -0.2947], device='cuda:1')
Index force: tensor([0.5769], device='cuda:1')
Storing RECOVERY transition: reward=0.0198 (scaled=0.0198), steps=1
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0927
Collected 543 transitions for RL
SAC Update 1/5: Actor Loss=-0.0138, Q1 Loss=1.9451, Q2 Loss=1.9451, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6999
SAC Update 2/5: Actor Loss=-0.0099, Q1 Loss=1.0536, Q2 Loss=1.0536, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7044
SAC Update 3/5: Actor Loss=-0.0098, Q1 Loss=1.2656, Q2 Loss=1.2656, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5134
SAC Update 4/5: Actor Loss=-0.0114, Q1 Loss=1.4059, Q2 Loss=1.4059, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2562
SAC Update 5/5: Actor Loss=-0.0135, Q1 Loss=1.5926, Q2 Loss=1.5926, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1050

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.3%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.04s (17.7%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.011660
Q1 loss: 1.452553
Q2 loss: 1.452553
Current threshold: -149.4951
Global Scale Offset: 5491.5645
Reward stats: mean=0.0140, std=0.0927, count=543
----------------------------------------------
SAC Update - Actor Loss: -0.0117, Q1 Loss: 1.4526, Q2 Loss: 1.4526, Entropy: 0.6931, Mean TD Error: 1.2558, Threshold: -149.4951
Original likelihood: -148.27398681640625
Adjusted likelihood: -148.27398681640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5001)
Current yaw: tensor([-0.0452,  0.0411, -0.3131], device='cuda:1')
13 turn
Sampling time 3.6097864120383747
tensor([ 0.0852,  0.5688,  0.4244,  0.8617, -0.1200,  0.5616,  0.8060,  0.8136,
         1.4369,  0.2123,  0.0713,  1.1364, -0.0452,  0.0411, -0.3131,  2.8873],
       device='cuda:1')
Original likelihood: -145.57493591308594
Adjusted likelihood: -145.57493591308594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5003)
State is out of distribution
Projection step: 0, Loss: 138.01869201660156
Projection step: 1, Loss: 139.12094116210938
Projection step: 2, Loss: 130.7094268798828
Projection step: 3, Loss: 134.35433959960938
Projection step: 4, Loss: 127.44125366210938
Projection step: 5, Loss: 124.72856903076172
Projection step: 6, Loss: 125.78140258789062
Projection step: 7, Loss: 119.52986145019531
Projection step: 8, Loss: 117.65767669677734
Projection step: 9, Loss: 117.64207458496094
Projection step: 10, Loss: 119.1543960571289
Projection step: 11, Loss: 115.29536437988281
Projection step: 12, Loss: 113.57012939453125
Projection step: 13, Loss: 113.20402526855469
Projection step: 14, Loss: 111.27760314941406
Projection step: 15, Loss: 108.57215881347656
Projection step: 16, Loss: 106.26288604736328
Projection step: 17, Loss: 102.85818481445312
Final likelihood: tensor([-105.7481, -106.3785,  -99.6521,  -96.5566, -102.1945, -107.5197,
        -108.1432, -105.6313,  -96.0535, -108.9014, -101.8589, -107.8439,
        -103.3721, -106.3814,  -99.6550,  -89.8408])
Final projection likelihood: -102.8582
1 mode projection succeeded
New goal: tensor([ 0.0832,  0.5738,  0.3764,  0.9529, -0.0826,  0.5327,  0.8069,  0.8004,
         1.4057,  0.1859,  0.1100,  1.1434, -0.0463,  0.0291, -0.5224],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -117.19851684570312
Adjusted likelihood: -117.19851684570312
Likelihood residual: 0.0
Original likelihood: -124.1561279296875
Adjusted likelihood: -124.1561279296875
Likelihood residual: 0.0
{'index': 124.1561279296875, 'thumb_middle': 117.19851684570312}
Current yaw: tensor([-0.0452,  0.0411, -0.3131], device='cuda:1')
14 thumb_middle
tensor([ 0.0852,  0.5688,  0.4244,  0.8617, -0.1200,  0.5616,  0.8060,  0.8136,
         1.4369,  0.2123,  0.0713,  1.1364, -0.0452,  0.0411, -0.3131,  2.8873],
       device='cuda:1')
Solve time for step 1 9.148063073051162
Current ori: tensor([-0.0452,  0.0411, -0.3131], device='cuda:1')
Index force: tensor([0.5844, 0.5940, 0.6022, 0.5770], device='cuda:1')
tensor([ 0.0815,  0.5859,  0.3701,  0.9115, -0.1917,  0.5153,  0.7741,  0.7805,
         1.3687,  0.1675,  0.0466,  1.1211, -0.0415,  0.0487, -0.3131,  2.8448],
       device='cuda:1')
Solve time for step 2 3.4213337050168775
Current ori: tensor([-0.0415,  0.0487, -0.3131], device='cuda:1')
Index force: tensor([0.5826, 0.5912, 0.5693], device='cuda:1')
tensor([ 0.0995,  0.5887,  0.3715,  0.9378, -0.1867,  0.5249,  0.7766,  0.7822,
         1.3624,  0.1614,  0.0392,  1.1205, -0.0398,  0.0373, -0.3131,  2.8689],
       device='cuda:1')
Solve time for step 3 3.4903398089809343
Current ori: tensor([-0.0398,  0.0373, -0.3131], device='cuda:1')
Index force: tensor([0.5791, 0.5607], device='cuda:1')
tensor([ 0.1000,  0.5727,  0.3828,  0.9623, -0.1862,  0.5226,  0.7785,  0.7806,
         1.3648,  0.1580,  0.0377,  1.1207, -0.0338,  0.0371, -0.3131,  2.8810],
       device='cuda:1')
Solve time for step 4 3.434696988959331
Current ori: tensor([-0.0338,  0.0371, -0.3131], device='cuda:1')
Index force: tensor([0.5774], device='cuda:1')
Storing RECOVERY transition: reward=0.0110 (scaled=0.0110), steps=0
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0926
Collected 544 transitions for RL
SAC Update 1/5: Actor Loss=-0.0117, Q1 Loss=1.1793, Q2 Loss=1.1793, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2382
SAC Update 2/5: Actor Loss=-0.0134, Q1 Loss=1.6343, Q2 Loss=1.6343, Entropy=0.6929, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1294
SAC Update 3/5: Actor Loss=-0.0109, Q1 Loss=1.1847, Q2 Loss=1.1847, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8416
SAC Update 4/5: Actor Loss=-0.0072, Q1 Loss=0.7311, Q2 Loss=0.7311, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3102
SAC Update 5/5: Actor Loss=-0.0077, Q1 Loss=0.9177, Q2 Loss=0.9177, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9790

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.2%)
Q1 update: 0.06s (20.9%)
Q2 update: 0.05s (20.1%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010167
Q1 loss: 1.129411
Q2 loss: 1.129411
Current threshold: -149.4948
Global Scale Offset: 5530.2900
Reward stats: mean=0.0140, std=0.0926, count=544
----------------------------------------------
SAC Update - Actor Loss: -0.0102, Q1 Loss: 1.1294, Q2 Loss: 1.1294, Entropy: 0.6931, Mean TD Error: 0.8997, Threshold: -149.4948
Original likelihood: -145.1201629638672
Adjusted likelihood: -145.1201629638672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5003)
State is out of distribution
Projection step: 0, Loss: 146.1529998779297
Projection step: 1, Loss: 149.4996795654297
Projection step: 2, Loss: 147.6830291748047
Projection step: 3, Loss: 140.4864501953125
Projection step: 4, Loss: 135.17010498046875
Projection step: 5, Loss: 130.88333129882812
Projection step: 6, Loss: 130.44232177734375
Projection step: 7, Loss: 130.3906707763672
Projection step: 8, Loss: 128.32199096679688
Projection step: 9, Loss: 123.91523742675781
Projection step: 10, Loss: 123.71768188476562
Projection step: 11, Loss: 123.65721130371094
Projection step: 12, Loss: 119.94831848144531
Projection step: 13, Loss: 118.632080078125
Projection step: 14, Loss: 115.9117431640625
Projection step: 15, Loss: 118.68490600585938
Projection step: 16, Loss: 114.72276306152344
Projection step: 17, Loss: 113.36203002929688
Projection step: 18, Loss: 111.42658996582031
Projection step: 19, Loss: 107.98347473144531
Projection step: 20, Loss: 106.2774658203125
Projection step: 21, Loss: 104.47662353515625
Final likelihood: tensor([ -98.2408, -101.2753, -115.2542, -105.7049, -107.6288, -103.3357,
        -111.3999,  -99.5421, -105.0886, -106.2790, -110.7182, -104.4918,
        -100.1856, -103.3885, -101.3809,  -97.7118])
Final projection likelihood: -104.4766
1 mode projection succeeded
New goal: tensor([ 0.0823,  0.5878,  0.3450,  0.9691, -0.0851,  0.5195,  0.8125,  0.8063,
         1.3967,  0.1599,  0.1103,  1.1376, -0.0457,  0.0298, -0.4890],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -114.03691101074219
Adjusted likelihood: -114.03691101074219
Likelihood residual: 0.0
Original likelihood: -107.1934814453125
Adjusted likelihood: -107.1934814453125
Likelihood residual: 0.0
{'index': 107.1934814453125, 'thumb_middle': 114.03691101074219}
Current yaw: tensor([-0.0428,  0.0462, -0.3244], device='cuda:1')
15 index
tensor([ 0.0847,  0.5947,  0.3595,  0.9148, -0.1329,  0.5572,  0.8189,  0.8053,
         1.4359,  0.1879,  0.0915,  1.1477, -0.0428,  0.0462, -0.3244,  2.8436],
       device='cuda:1')
Solve time for step 1 10.855918874964118
Current ori: tensor([-0.0428,  0.0462, -0.3244], device='cuda:1')
Middle force: tensor([0.5117, 0.5616, 0.5016, 0.5757], device='cuda:1')
Thumb force: tensor([0.6091, 0.5533, 0.5214, 0.5971], device='cuda:1')
tensor([ 0.1180,  0.5302,  0.2960,  0.9264, -0.1345,  0.5470,  0.8297,  0.8108,
         1.4424,  0.1773,  0.0892,  1.1492, -0.0403,  0.0469, -0.3346,  2.3327],
       device='cuda:1')
Solve time for step 2 4.216690419008955
Current ori: tensor([-0.0403,  0.0469, -0.3346], device='cuda:1')
Middle force: tensor([0.5600, 0.5010, 0.5707], device='cuda:1')
Thumb force: tensor([0.5455, 0.5189, 0.5901], device='cuda:1')
tensor([ 0.1187,  0.5259,  0.2938,  0.9367, -0.1301,  0.5543,  0.8237,  0.8068,
         1.4529,  0.1621,  0.0802,  1.1361, -0.0457,  0.0444, -0.3563,  1.7714],
       device='cuda:1')
Solve time for step 3 4.15220141998725
Current ori: tensor([-0.0457,  0.0444, -0.3563], device='cuda:1')
Middle force: tensor([0.5403, 0.5036], device='cuda:1')
Thumb force: tensor([0.5327, 0.5895], device='cuda:1')
tensor([ 0.1175,  0.5253,  0.2934,  0.9363, -0.1268,  0.5556,  0.8248,  0.8066,
         1.4473,  0.1705,  0.0752,  1.1466, -0.0458,  0.0419, -0.3568,  1.3249],
       device='cuda:1')
Solve time for step 4 4.080738826014567
Current ori: tensor([-0.0458,  0.0419, -0.3568], device='cuda:1')
Middle force: tensor([0.5760], device='cuda:1')
Thumb force: tensor([0.5632], device='cuda:1')
Storing RECOVERY transition: reward=0.0397 (scaled=0.0397), steps=0
Reward stats updated: mean 0.0140 -> 0.0140, std: 0.0925
Collected 545 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=2.5473, Q2 Loss=2.5473, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6575
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.9186, Q2 Loss=0.9186, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5335
SAC Update 3/5: Actor Loss=-0.0106, Q1 Loss=1.5005, Q2 Loss=1.5005, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7819
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.9125, Q2 Loss=0.9125, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5285
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8228, Q2 Loss=0.8228, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6223

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (16.6%)
Q1 update: 0.05s (20.7%)
Q2 update: 0.04s (18.9%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008760
Q1 loss: 1.340332
Q2 loss: 1.340332
Current threshold: -149.4946
Global Scale Offset: 5568.6221
Reward stats: mean=0.0140, std=0.0925, count=545
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.3403, Q2 Loss: 1.3403, Entropy: 0.6931, Mean TD Error: 1.8247, Threshold: -149.4946
Original likelihood: -145.05105590820312
Adjusted likelihood: -145.05105590820312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5003)
State is out of distribution
Projection step: 0, Loss: 142.15553283691406
Projection step: 1, Loss: 135.40789794921875
Projection step: 2, Loss: 133.1445770263672
Projection step: 3, Loss: 130.99478149414062
Projection step: 4, Loss: 127.48113250732422
Projection step: 5, Loss: 128.7671356201172
Projection step: 6, Loss: 128.22084045410156
Projection step: 7, Loss: 126.32841491699219
Projection step: 8, Loss: 120.04671478271484
Projection step: 9, Loss: 120.05917358398438
Projection step: 10, Loss: 118.79672241210938
Projection step: 11, Loss: 118.73738098144531
Projection step: 12, Loss: 118.65046691894531
Projection step: 13, Loss: 116.31674194335938
Projection step: 14, Loss: 115.38690948486328
Projection step: 15, Loss: 111.23672485351562
Projection step: 16, Loss: 110.38645935058594
Projection step: 17, Loss: 110.11146545410156
Projection step: 18, Loss: 106.97601318359375
Projection step: 19, Loss: 108.6811294555664
Projection step: 20, Loss: 104.09417724609375
Final likelihood: tensor([-107.4552,  -95.6730, -105.3343, -101.7460,  -98.9840, -103.8677,
        -111.9504, -108.4800, -108.1775, -105.2688, -112.2213, -111.7532,
         -91.2784,  -95.7560, -111.4580,  -96.1031])
Final projection likelihood: -104.0942
1 mode projection succeeded
New goal: tensor([ 0.0776,  0.5827,  0.3406,  0.9798, -0.0831,  0.5137,  0.8135,  0.8101,
         1.3978,  0.1568,  0.1090,  1.1199, -0.0476,  0.0298, -0.4262],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -104.3956298828125
Adjusted likelihood: -104.3956298828125
Likelihood residual: 0.0
Original likelihood: -121.50019073486328
Adjusted likelihood: -121.50019073486328
Likelihood residual: 0.0
{'index': 121.50019073486328, 'thumb_middle': 104.3956298828125}
Current yaw: tensor([-0.0469,  0.0434, -0.3535], device='cuda:1')
16 thumb_middle
tensor([ 0.0679,  0.5836,  0.3326,  0.9627, -0.1283,  0.5584,  0.8212,  0.8018,
         1.4473,  0.1730,  0.0740,  1.1506, -0.0469,  0.0434, -0.3535,  1.2588],
       device='cuda:1')
Solve time for step 1 8.985581604996696
Current ori: tensor([-0.0469,  0.0434, -0.3535], device='cuda:1')
Index force: tensor([0.5746, 0.5918, 0.5925, 0.5954], device='cuda:1')
tensor([ 0.0796,  0.5939,  0.3240,  0.9732, -0.1774,  0.5150,  0.7785,  0.8026,
         1.3689,  0.1242,  0.0518,  1.1119, -0.0481,  0.0369, -0.3534,  1.2348],
       device='cuda:1')
Solve time for step 2 3.666628918959759
Current ori: tensor([-0.0481,  0.0369, -0.3534], device='cuda:1')
Index force: tensor([0.5846, 0.5872, 0.5894], device='cuda:1')
tensor([ 0.0747,  0.5872,  0.3309,  0.9694, -0.1944,  0.5203,  0.7932,  0.7878,
         1.3668,  0.1521,  0.0443,  1.1042, -0.0469,  0.0399, -0.3534,  1.2291],
       device='cuda:1')
Solve time for step 3 3.452579607022926
Current ori: tensor([-0.0469,  0.0399, -0.3534], device='cuda:1')
Index force: tensor([0.5771, 0.5803], device='cuda:1')
tensor([ 0.0802,  0.5908,  0.3233,  0.9847, -0.1864,  0.5211,  0.7862,  0.7896,
         1.3605,  0.1307,  0.0629,  1.0975, -0.0462,  0.0363, -0.3534,  1.2413],
       device='cuda:1')
Solve time for step 4 3.5233131750137545
Current ori: tensor([-0.0462,  0.0363, -0.3534], device='cuda:1')
Index force: tensor([0.5755], device='cuda:1')
Storing RECOVERY transition: reward=0.0440 (scaled=0.0440), steps=0
Reward stats updated: mean 0.0140 -> 0.0141, std: 0.0924
Collected 546 transitions for RL
SAC Update 1/5: Actor Loss=-0.0072, Q1 Loss=0.7324, Q2 Loss=0.7324, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1371
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=2.7319, Q2 Loss=2.7319, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6286
SAC Update 3/5: Actor Loss=-0.0072, Q1 Loss=0.7164, Q2 Loss=0.7164, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1896
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=0.7994, Q2 Loss=0.7994, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1738
SAC Update 5/5: Actor Loss=-0.0081, Q1 Loss=0.8594, Q2 Loss=0.8594, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9233

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.05s (19.3%)
Actor update: 0.10s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007633
Q1 loss: 1.167913
Q2 loss: 1.167913
Current threshold: -149.4946
Global Scale Offset: 5593.8768
Reward stats: mean=0.0141, std=0.0924, count=546
----------------------------------------------
SAC Update - Actor Loss: -0.0076, Q1 Loss: 1.1679, Q2 Loss: 1.1679, Entropy: 0.6931, Mean TD Error: 1.6105, Threshold: -149.4946
Original likelihood: -130.79046630859375
Adjusted likelihood: -130.79046630859375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5013)
Current yaw: tensor([-0.0427,  0.0378, -0.3570], device='cuda:1')
17 turn
Sampling time 3.6003287640050985
tensor([ 0.0724,  0.5761,  0.3365,  0.9865, -0.1164,  0.5531,  0.8192,  0.8153,
         1.4229,  0.1562,  0.1132,  1.1520, -0.0427,  0.0378, -0.3570,  1.3689],
       device='cuda:1')
Original likelihood: -128.7530975341797
Adjusted likelihood: -128.7530975341797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5015)
State is out of distribution
Projection step: 0, Loss: 127.14424133300781
Projection step: 1, Loss: 127.06902313232422
Projection step: 2, Loss: 123.07154083251953
Projection step: 3, Loss: 122.827392578125
Projection step: 4, Loss: 120.72032165527344
Projection step: 5, Loss: 116.42005157470703
Projection step: 6, Loss: 115.11578369140625
Projection step: 7, Loss: 112.71893310546875
Projection step: 8, Loss: 112.99028778076172
Projection step: 9, Loss: 112.20121002197266
Projection step: 10, Loss: 108.14041137695312
Projection step: 11, Loss: 107.38766479492188
Projection step: 12, Loss: 107.28672790527344
Projection step: 13, Loss: 105.26061248779297
Projection step: 14, Loss: 102.60325622558594
Final likelihood: tensor([ -99.9679, -106.4357,  -96.6484, -103.5204, -102.1418, -105.3432,
        -107.6781, -109.7029, -103.8668, -103.9300,  -94.4605, -102.4456,
        -107.3246, -101.9093,  -95.9217, -100.3551])
Final projection likelihood: -102.6032
1 mode projection succeeded
New goal: tensor([ 0.0794,  0.5750,  0.3396,  1.0004, -0.0847,  0.5232,  0.8176,  0.8035,
         1.3892,  0.1562,  0.1155,  1.1182, -0.0438,  0.0284, -0.5869],
       device='cuda:1')
tensor([[0.0022]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -124.34942626953125
Adjusted likelihood: -124.34942626953125
Likelihood residual: 0.0
Original likelihood: -98.85943603515625
Adjusted likelihood: -98.85943603515625
Likelihood residual: 0.0
{'index': 98.85943603515625, 'thumb_middle': 124.34942626953125}
Current yaw: tensor([-0.0427,  0.0378, -0.3570], device='cuda:1')
18 index
tensor([ 0.0724,  0.5761,  0.3365,  0.9865, -0.1164,  0.5531,  0.8192,  0.8153,
         1.4229,  0.1562,  0.1132,  1.1520, -0.0427,  0.0378, -0.3570,  1.3689],
       device='cuda:1')
Solve time for step 1 10.730132071999833
Current ori: tensor([-0.0427,  0.0378, -0.3570], device='cuda:1')
Middle force: tensor([0.5534, 0.5222, 0.5130, 0.5255], device='cuda:1')
Thumb force: tensor([0.5832, 0.6403, 0.6283, 0.5048], device='cuda:1')
tensor([ 0.1145,  0.5157,  0.2890,  0.9659, -0.1099,  0.5535,  0.8280,  0.8066,
         1.4222,  0.1589,  0.1114,  1.1364, -0.0466,  0.0334, -0.3840,  0.5251],
       device='cuda:1')
Solve time for step 2 4.345831451995764
Current ori: tensor([-0.0466,  0.0334, -0.3840], device='cuda:1')
Middle force: tensor([0.5197, 0.5113, 0.5227], device='cuda:1')
Thumb force: tensor([0.6316, 0.6244, 0.5038], device='cuda:1')
tensor([ 0.1160,  0.5157,  0.2880,  0.9656, -0.1083,  0.5578,  0.8254,  0.8022,
         1.4260,  0.1531,  0.1070,  1.1342, -0.0492,  0.0324, -0.3895,  0.2628],
       device='cuda:1')
Solve time for step 3 4.218655215983745
Current ori: tensor([-0.0492,  0.0324, -0.3895], device='cuda:1')
Middle force: tensor([0.5094, 0.5201], device='cuda:1')
Thumb force: tensor([0.6175, 0.5029], device='cuda:1')
tensor([ 0.1156,  0.5158,  0.2871,  0.9669, -0.1144,  0.5503,  0.8283,  0.8091,
         1.4292,  0.1516,  0.1085,  1.1409, -0.0469,  0.0366, -0.3904,  0.4058],
       device='cuda:1')
Solve time for step 4 4.030590351030696
Current ori: tensor([-0.0469,  0.0366, -0.3904], device='cuda:1')
Middle force: tensor([0.5175], device='cuda:1')
Thumb force: tensor([0.5013], device='cuda:1')
Storing RECOVERY transition: reward=0.0308 (scaled=0.0308), steps=0
Reward stats updated: mean 0.0141 -> 0.0141, std: 0.0924
Collected 547 transitions for RL
SAC Update 1/5: Actor Loss=-0.0111, Q1 Loss=1.6960, Q2 Loss=1.6960, Entropy=0.6931, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9771
SAC Update 2/5: Actor Loss=-0.0091, Q1 Loss=0.9558, Q2 Loss=0.9558, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7099
SAC Update 3/5: Actor Loss=-0.0071, Q1 Loss=0.7092, Q2 Loss=0.7092, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0637
SAC Update 4/5: Actor Loss=-0.0075, Q1 Loss=0.8128, Q2 Loss=0.8128, Entropy=0.6930, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6141
SAC Update 5/5: Actor Loss=-0.0106, Q1 Loss=1.0728, Q2 Loss=1.0728, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3637

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.1%)
Q1 update: 0.07s (21.8%)
Q2 update: 0.06s (19.3%)
Actor update: 0.12s (39.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009088
Q1 loss: 1.049311
Q2 loss: 1.049311
Current threshold: -149.4946
Global Scale Offset: 5612.6290
Reward stats: mean=0.0141, std=0.0924, count=547
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.0493, Q2 Loss: 1.0493, Entropy: 0.6931, Mean TD Error: 0.7457, Threshold: -149.4946
Original likelihood: -117.02186584472656
Adjusted likelihood: -117.02186584472656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5023)
Current yaw: tensor([-0.0495,  0.0314, -0.3881], device='cuda:1')
19 turn
Sampling time 3.647034298046492
tensor([ 0.0673,  0.5749,  0.3275,  0.9938, -0.1067,  0.5593,  0.8253,  0.7997,
         1.4231,  0.1572,  0.1025,  1.1440, -0.0495,  0.0314, -0.3881,  0.5443],
       device='cuda:1')
Original likelihood: -122.38668060302734
Adjusted likelihood: -122.38668060302734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5019)
Solve time for step 1 14.267347784014419
Current ori: tensor([-0.0495,  0.0314, -0.3881], device='cuda:1')
Middle force: tensor([0.5712, 0.9957, 1.1612, 0.7143, 0.4768, 2.1165, 0.4991, 0.5364, 0.5241,
        1.0547, 0.4867, 0.4864], device='cuda:1')
Thumb force: tensor([0.9831, 0.5736, 1.2955, 0.6399, 0.5646, 1.2056, 0.5775, 0.6174, 0.5687,
        1.3283, 0.5546, 0.7012], device='cuda:1')
Index force: tensor([0.9648, 0.6493, 0.5705, 0.7522, 0.7029, 0.7628, 0.6305, 0.5137, 0.6130,
        0.9533, 0.6786, 0.6496], device='cuda:1')
Storing NORMAL transition: reward=0.1131 (scaled=0.1131), steps=1
Reward stats updated: mean 0.0141 -> 0.0143, std: 0.0924
Collected 548 transitions for RL
SAC Update 1/5: Actor Loss=-0.0136, Q1 Loss=1.3557, Q2 Loss=1.3557, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1354
SAC Update 2/5: Actor Loss=-0.0070, Q1 Loss=0.7423, Q2 Loss=0.7423, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1854
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=0.7759, Q2 Loss=0.7759, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3237
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=0.8528, Q2 Loss=0.8528, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4149
SAC Update 5/5: Actor Loss=-0.0116, Q1 Loss=1.4478, Q2 Loss=1.4478, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3347

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009527
Q1 loss: 1.034894
Q2 loss: 1.034894
Current threshold: -149.4946
Global Scale Offset: 5626.9768
Reward stats: mean=0.0143, std=0.0924, count=548
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.0349, Q2 Loss: 1.0349, Entropy: 0.6931, Mean TD Error: 1.0788, Threshold: -149.4946
tensor([ 0.1326,  0.5629,  0.4210,  0.9803, -0.2133,  0.5628,  0.9115,  0.8417,
         1.3352,  0.3164,  0.2336,  1.0603, -0.0155,  0.0514, -0.5015, -0.6781],
       device='cuda:1')
Original likelihood: -225.40591430664062
Adjusted likelihood: -225.40591430664062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4946)
State is out of distribution
Projection step: 0, Loss: 238.580810546875
Projection step: 1, Loss: 223.3687286376953
Projection step: 2, Loss: 206.30726623535156
Projection step: 3, Loss: 197.6529541015625
Projection step: 4, Loss: 191.3841552734375
Projection step: 5, Loss: 182.71942138671875
Projection step: 6, Loss: 171.80245971679688
Projection step: 7, Loss: 177.3214874267578
Projection step: 8, Loss: 168.72042846679688
Projection step: 9, Loss: 151.27978515625
Projection step: 10, Loss: 153.63681030273438
Projection step: 11, Loss: 157.9046173095703
Projection step: 12, Loss: 154.09771728515625
Projection step: 13, Loss: 153.17369079589844
Projection step: 14, Loss: 139.07598876953125
Projection step: 15, Loss: 135.51426696777344
Projection step: 16, Loss: 136.4808807373047
Projection step: 17, Loss: 133.69586181640625
Projection step: 18, Loss: 128.98202514648438
Projection step: 19, Loss: 133.71499633789062
Projection step: 20, Loss: 123.37307739257812
Projection step: 21, Loss: 118.25752258300781
Projection step: 22, Loss: 117.859375
Projection step: 23, Loss: 119.57666015625
Projection step: 24, Loss: 127.66807556152344
Final likelihood: tensor([-116.2674, -129.7585, -125.5178, -123.1477,  -91.1131, -150.3605,
        -107.9638, -144.6744, -124.5317, -135.0669, -118.9502, -122.4733,
        -127.4394, -121.8830,  -85.7538, -126.3794])
Final projection likelihood: -121.9550
1 mode projection succeeded
New goal: tensor([ 0.0834,  0.5250,  0.5455,  0.7561, -0.1039,  0.5689,  0.8536,  0.7941,
         1.3312,  0.2723,  0.1869,  1.0802, -0.0238,  0.0289,  0.0662],
       device='cuda:1')
tensor([[0.0021]], device='cuda:1') tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -150.2750244140625
Adjusted likelihood: -150.2750244140625
Likelihood residual: 0.0
Original likelihood: -134.69276428222656
Adjusted likelihood: -134.69276428222656
Likelihood residual: 0.0
{'index': 134.69276428222656, 'thumb_middle': 150.2750244140625}
Current yaw: tensor([-0.0155,  0.0514, -0.5015], device='cuda:1')
20 index
tensor([ 0.1326,  0.5629,  0.4210,  0.9803, -0.2133,  0.5628,  0.9115,  0.8417,
         1.3352,  0.3164,  0.2336,  1.0603, -0.0155,  0.0514, -0.5015, -0.6781],
       device='cuda:1')
Solve time for step 1 10.904994050040841
Current ori: tensor([-0.0155,  0.0514, -0.5015], device='cuda:1')
Middle force: tensor([0.5536, 0.5813, 0.5680, 0.5928], device='cuda:1')
Thumb force: tensor([0.5299, 0.6068, 0.5901, 0.5805], device='cuda:1')
tensor([ 0.1313,  0.4736,  0.4717,  0.7656, -0.1789,  0.5951,  0.8976,  0.8259,
         1.3502,  0.2800,  0.1755,  1.0788, -0.0291,  0.0281, -0.5191, -0.2835],
       device='cuda:1')
Solve time for step 2 4.173648367985152
Current ori: tensor([-0.0291,  0.0281, -0.5191], device='cuda:1')
Middle force: tensor([0.5739, 0.5634, 0.5874], device='cuda:1')
Thumb force: tensor([0.5990, 0.5864, 0.5767], device='cuda:1')
tensor([ 0.1284,  0.4709,  0.4850,  0.7337, -0.1679,  0.6094,  0.8901,  0.8167,
         1.3531,  0.2710,  0.1586,  1.0816, -0.0349,  0.0205, -0.5211,  0.1368],
       device='cuda:1')
Solve time for step 3 3.962880610022694
Current ori: tensor([-0.0349,  0.0205, -0.5211], device='cuda:1')
Middle force: tensor([0.5148, 0.5820], device='cuda:1')
Thumb force: tensor([0.5826, 0.5369], device='cuda:1')
tensor([ 0.1275,  0.4694,  0.4889,  0.7264, -0.1609,  0.6162,  0.8880,  0.8130,
         1.3482,  0.2754,  0.1509,  1.0870, -0.0371,  0.0154, -0.5212,  0.5974],
       device='cuda:1')
Solve time for step 4 3.9690496569965035
Current ori: tensor([-0.0371,  0.0154, -0.5212], device='cuda:1')
Middle force: tensor([0.5671], device='cuda:1')
Thumb force: tensor([0.5788], device='cuda:1')
Storing RECOVERY transition: reward=0.0114 (scaled=0.0114), steps=1
Reward stats updated: mean 0.0143 -> 0.0143, std: 0.0923
Collected 549 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.8044, Q2 Loss=0.8044, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.9309
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=1.9962, Q2 Loss=1.9962, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.3708
SAC Update 3/5: Actor Loss=-0.0089, Q1 Loss=1.3472, Q2 Loss=1.3472, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2476
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=2.0039, Q2 Loss=2.0039, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1401
SAC Update 5/5: Actor Loss=-0.0118, Q1 Loss=1.1863, Q2 Loss=1.1863, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2195

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.6%)
Actor update: 0.08s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009253
Q1 loss: 1.467590
Q2 loss: 1.467590
Current threshold: -149.4945
Global Scale Offset: 5645.3974
Reward stats: mean=0.0143, std=0.0923, count=549
----------------------------------------------
SAC Update - Actor Loss: -0.0093, Q1 Loss: 1.4676, Q2 Loss: 1.4676, Entropy: 0.6931, Mean TD Error: 2.1818, Threshold: -149.4945
Original likelihood: -151.16464233398438
Adjusted likelihood: -151.16464233398438
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4999)
State is out of distribution
Projection step: 0, Loss: 136.73123168945312
Projection step: 1, Loss: 131.89073181152344
Projection step: 2, Loss: 126.53102111816406
Projection step: 3, Loss: 119.08570861816406
Projection step: 4, Loss: 117.58152770996094
Projection step: 5, Loss: 115.11131286621094
Projection step: 6, Loss: 115.46399688720703
Projection step: 7, Loss: 111.26892852783203
Projection step: 8, Loss: 108.6058120727539
Projection step: 9, Loss: 104.2423095703125
Final likelihood: tensor([-123.0710, -104.8895,  -88.3930, -104.5219, -106.1202,  -90.0820,
        -106.0747, -136.3109,  -81.6082,  -97.4327, -108.2517,  -97.2064,
        -106.0757, -102.5791, -105.4197, -109.8402])
Final projection likelihood: -104.2423
1 mode projection succeeded
New goal: tensor([ 0.0826,  0.5370,  0.5061,  0.8197, -0.0988,  0.6170,  0.8709,  0.7734,
         1.3497,  0.2458,  0.1461,  1.1244, -0.0386,  0.0109, -0.3557],
       device='cuda:1')
Marked last transition as done (final step)
{}

Trial 36
Loaded trajectory sampler
Current yaw: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
Current yaw: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
1 turn
Sampling time 3.6057469740044326
tensor([ 1.1111e-01,  5.6516e-01,  5.7707e-01,  6.3471e-01, -8.7697e-02,
         4.8623e-01,  9.2425e-01,  8.9630e-01,  1.2442e+00,  2.7922e-01,
         2.4025e-01,  1.1787e+00,  1.3754e-04,  1.4038e-02, -4.5622e-02,
         3.6219e-01], device='cuda:1')
Original likelihood: -72.13548278808594
Adjusted likelihood: -72.13548278808594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5055)
Solve time for step 1 14.21100920002209
Current ori: tensor([ 0.0001,  0.0140, -0.0456], device='cuda:1')
Middle force: tensor([0.5282, 0.5681, 0.5791, 1.8527, 0.5675, 1.3199, 0.5128, 1.1234, 0.5745,
        0.5625, 0.6833, 0.5992], device='cuda:1')
Thumb force: tensor([0.6553, 0.8370, 0.5770, 1.4870, 0.5467, 0.8112, 0.5636, 1.3212, 0.5373,
        0.5917, 0.5718, 0.7320], device='cuda:1')
Index force: tensor([0.7543, 0.5041, 0.5173, 0.5302, 0.5805, 0.6492, 0.7555, 0.6062, 0.6301,
        0.5788, 0.5746, 0.6225], device='cuda:1')
Storing NORMAL transition: reward=0.1686 (scaled=0.1686), steps=1
Reward stats updated: mean 0.0143 -> 0.0146, std: 0.0924
Collected 550 transitions for RL
SAC Update 1/5: Actor Loss=-0.0107, Q1 Loss=1.0824, Q2 Loss=1.0824, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2914
SAC Update 2/5: Actor Loss=-0.0073, Q1 Loss=0.7588, Q2 Loss=0.7588, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9746
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.8470, Q2 Loss=0.8470, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6974
SAC Update 4/5: Actor Loss=-0.0103, Q1 Loss=1.0325, Q2 Loss=1.0325, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3010
SAC Update 5/5: Actor Loss=-0.0130, Q1 Loss=1.3155, Q2 Loss=1.3155, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3572

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.5%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009887
Q1 loss: 1.007236
Q2 loss: 1.007236
Current threshold: -149.4944
Global Scale Offset: 5668.8433
Reward stats: mean=0.0146, std=0.0924, count=550
----------------------------------------------
SAC Update - Actor Loss: -0.0099, Q1 Loss: 1.0072, Q2 Loss: 1.0072, Entropy: 0.6931, Mean TD Error: 0.5243, Threshold: -149.4944
tensor([ 0.1708,  0.6073,  0.5828,  0.6332, -0.0906,  0.4722,  1.0590,  0.8899,
         1.3406,  0.2488,  0.1685,  0.9938, -0.0098, -0.0228, -0.2149,  0.6005],
       device='cuda:1')
Original likelihood: -137.94680786132812
Adjusted likelihood: -137.94680786132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5008)
Solve time for step 2 5.652366696042009
Current ori: tensor([-0.0098, -0.0228, -0.2149], device='cuda:1')
Middle force: tensor([0.5613, 0.5827, 1.8125, 0.5658, 1.3046, 0.5118, 1.1159, 0.5707, 0.5550,
        0.6763, 0.5950], device='cuda:1')
Thumb force: tensor([0.8223, 0.5666, 1.4557, 0.5420, 0.7943, 0.5602, 1.2876, 0.5364, 0.5953,
        0.5680, 0.7240], device='cuda:1')
Index force: tensor([0.5035, 0.5143, 0.5284, 0.5740, 0.6409, 0.7413, 0.6011, 0.6204, 0.5710,
        0.5707, 0.6178], device='cuda:1')
Storing NORMAL transition: reward=0.0326 (scaled=0.0326), steps=1
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0924
Collected 551 transitions for RL
SAC Update 1/5: Actor Loss=-0.0078, Q1 Loss=0.9591, Q2 Loss=0.9591, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.0037
SAC Update 2/5: Actor Loss=-0.0088, Q1 Loss=0.8944, Q2 Loss=0.8944, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4976
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=2.3797, Q2 Loss=2.3797, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8722
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.7638, Q2 Loss=0.7638, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1639
SAC Update 5/5: Actor Loss=-0.0115, Q1 Loss=1.1591, Q2 Loss=1.1591, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2510

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.6%)
Actor update: 0.08s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009081
Q1 loss: 1.231218
Q2 loss: 1.231218
Current threshold: -149.4944
Global Scale Offset: 5686.0782
Reward stats: mean=0.0146, std=0.0924, count=551
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.2312, Q2 Loss: 1.2312, Entropy: 0.6931, Mean TD Error: 1.1577, Threshold: -149.4944
tensor([ 0.2756,  0.6165,  0.6793,  0.5792, -0.1656,  0.3984,  1.0493,  1.0295,
         1.4267,  0.2297,  0.1428,  1.0260, -0.0059,  0.0347, -0.2485, -2.2052],
       device='cuda:1')
Original likelihood: -208.68771362304688
Adjusted likelihood: -208.68771362304688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4958)
State is out of distribution
Projection step: 0, Loss: 218.85345458984375
Projection step: 1, Loss: 233.3330078125
Projection step: 2, Loss: 192.7406005859375
Projection step: 3, Loss: 193.6852264404297
Projection step: 4, Loss: 186.3291015625
Projection step: 5, Loss: 188.8648681640625
Projection step: 6, Loss: 177.0810546875
Projection step: 7, Loss: 166.75601196289062
Projection step: 8, Loss: 164.8436279296875
Projection step: 9, Loss: 170.62135314941406
Projection step: 10, Loss: 153.23756408691406
Projection step: 11, Loss: 163.765625
Projection step: 12, Loss: 154.58364868164062
Projection step: 13, Loss: 138.92202758789062
Projection step: 14, Loss: 134.44674682617188
Projection step: 15, Loss: 129.55096435546875
Projection step: 16, Loss: 126.61833190917969
Projection step: 17, Loss: 122.54206848144531
Projection step: 18, Loss: 121.6000747680664
Projection step: 19, Loss: 116.42465209960938
Projection step: 20, Loss: 116.02928924560547
Projection step: 21, Loss: 118.00592041015625
Projection step: 22, Loss: 107.53448486328125
Projection step: 23, Loss: 115.2132339477539
Projection step: 24, Loss: 109.40116882324219
Final likelihood: tensor([-101.9123, -118.8266, -102.5002, -116.2681, -102.7124, -105.7140,
        -112.0603, -101.9893, -160.3711, -114.7622, -115.5377, -101.3722,
        -103.1565,  -87.2168, -121.3737, -158.0620])
Final projection likelihood: -113.9897
1 mode projection succeeded
New goal: tensor([ 0.1746,  0.5331,  0.5855,  0.6241, -0.1000,  0.5087,  0.9370,  1.0810,
         1.3817,  0.4394,  0.1884,  1.0291, -0.0096,  0.0183, -2.1542],
       device='cuda:1')
tensor([[0.0029]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0042]], device='cuda:1')
Original likelihood: -209.80538940429688
Adjusted likelihood: -209.80538940429688
Likelihood residual: 0.0
Original likelihood: -118.67556762695312
Adjusted likelihood: -118.67556762695312
Likelihood residual: 0.0
{'index': 118.67556762695312, 'thumb_middle': 209.80538940429688}
Current yaw: tensor([-0.0059,  0.0347, -0.2485], device='cuda:1')
2 index
tensor([ 0.2756,  0.6165,  0.6793,  0.5792, -0.1656,  0.3984,  1.0493,  1.0295,
         1.4267,  0.2297,  0.1428,  1.0260, -0.0059,  0.0347, -0.2485, -2.2052],
       device='cuda:1')
Solve time for step 1 10.65380826004548
Current ori: tensor([-0.0059,  0.0347, -0.2485], device='cuda:1')
Middle force: tensor([0.5392, 0.5323, 0.5590, 0.5297], device='cuda:1')
Thumb force: tensor([0.5115, 0.5121, 0.5764, 0.6136], device='cuda:1')
tensor([ 0.2145,  0.5202,  0.5694,  0.6024, -0.1370,  0.4638,  0.9587,  1.0828,
         1.3452,  0.3602,  0.1839,  0.9890, -0.0195,  0.0186, -0.2534, -3.9416],
       device='cuda:1')
Solve time for step 2 4.242207135015633
Current ori: tensor([-0.0195,  0.0186, -0.2534], device='cuda:1')
Middle force: tensor([0.5305, 0.5550, 0.5276], device='cuda:1')
Thumb force: tensor([0.5104, 0.5727, 0.6089], device='cuda:1')
tensor([ 0.2000,  0.5136,  0.5621,  0.6070, -0.1332,  0.4774,  0.9469,  1.0970,
         1.3414,  0.3683,  0.1752,  0.9950, -0.0228,  0.0145, -0.2611, -5.0796],
       device='cuda:1')
Solve time for step 3 4.089840558997821
Current ori: tensor([-0.0228,  0.0145, -0.2611], device='cuda:1')
Middle force: tensor([0.5097, 0.5581], device='cuda:1')
Thumb force: tensor([0.5034, 0.6042], device='cuda:1')
tensor([ 1.9639e-01,  5.1195e-01,  5.6060e-01,  6.0991e-01, -1.1871e-01,
         4.8506e-01,  9.4685e-01,  1.1016e+00,  1.3206e+00,  3.9485e-01,
         1.7029e-01,  1.0093e+00, -2.2761e-02,  4.1306e-03, -2.6432e-01,
        -5.7222e+00], device='cuda:1')
Solve time for step 4 3.9905258400249295
Current ori: tensor([-0.0228,  0.0041, -0.2643], device='cuda:1')
Middle force: tensor([0.5022], device='cuda:1')
Thumb force: tensor([0.5002], device='cuda:1')
Storing RECOVERY transition: reward=0.0065 (scaled=0.0033), steps=2
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0923
Collected 552 transitions for RL
SAC Update 1/5: Actor Loss=-0.0135, Q1 Loss=1.3612, Q2 Loss=1.3612, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2752
SAC Update 2/5: Actor Loss=-0.0129, Q1 Loss=1.2949, Q2 Loss=1.2949, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1784
SAC Update 3/5: Actor Loss=-0.0094, Q1 Loss=0.9494, Q2 Loss=0.9494, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4034
SAC Update 4/5: Actor Loss=-0.0084, Q1 Loss=0.9121, Q2 Loss=0.9121, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0976
SAC Update 5/5: Actor Loss=-0.0079, Q1 Loss=1.0572, Q2 Loss=1.0572, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3441

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.06s (21.1%)
Q2 update: 0.05s (19.9%)
Actor update: 0.10s (37.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.010421
Q1 loss: 1.114964
Q2 loss: 1.114964
Current threshold: -149.4946
Global Scale Offset: 5701.8900
Reward stats: mean=0.0146, std=0.0923, count=552
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 1.1150, Q2 Loss: 1.1150, Entropy: 0.6931, Mean TD Error: 0.8598, Threshold: -149.4946
Original likelihood: -106.63896179199219
Adjusted likelihood: -106.63896179199219
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5030)
State is out of distribution
Projection step: 0, Loss: 111.25608825683594
Projection step: 1, Loss: 118.42692565917969
Projection step: 2, Loss: 108.97163391113281
Projection step: 3, Loss: 103.92408752441406
Final likelihood: tensor([ -83.8118, -166.6702,  -83.7571, -124.5558,  -86.8862, -106.0631,
        -108.7569, -104.9325, -116.6413,  -84.6278, -102.2370,  -96.7430,
        -105.2702, -111.4856,  -99.6969,  -80.6501])
Final projection likelihood: -103.9241
1 mode projection succeeded
New goal: tensor([ 0.1374,  0.5615,  0.5905,  0.6372, -0.1029,  0.4949,  0.9369,  1.0875,
         1.3294,  0.3997,  0.1712,  1.0028, -0.0248,  0.0053, -0.3151],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0021]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -133.21751403808594
Adjusted likelihood: -133.21751403808594
Likelihood residual: 0.0
Original likelihood: -129.12826538085938
Adjusted likelihood: -129.12826538085938
Likelihood residual: 0.0
{'index': 129.12826538085938, 'thumb_middle': 133.21751403808594}
Current yaw: tensor([-0.0250,  0.0041, -0.2542], device='cuda:1')
3 index
tensor([ 1.4428e-01,  5.7031e-01,  6.0362e-01,  6.3278e-01, -1.2027e-01,
         4.9164e-01,  9.4431e-01,  1.0948e+00,  1.3270e+00,  3.8414e-01,
         1.6284e-01,  1.0119e+00, -2.5034e-02,  4.0555e-03, -2.5417e-01,
        -5.8487e+00], device='cuda:1')
Solve time for step 1 10.591931400995236
Current ori: tensor([-0.0250,  0.0041, -0.2542], device='cuda:1')
Middle force: tensor([0.5393, 0.5229, 0.5410, 0.5089], device='cuda:1')
Thumb force: tensor([0.5394, 0.5598, 0.6287, 0.5034], device='cuda:1')
tensor([ 0.1823,  0.5119,  0.5451,  0.6143, -0.1302,  0.5100,  0.9441,  1.0943,
         1.3329,  0.3900,  0.1557,  1.0002, -0.0406,  0.0072, -0.2555, -5.3185],
       device='cuda:1')
Solve time for step 2 4.260498618998099
Current ori: tensor([-0.0406,  0.0072, -0.2555], device='cuda:1')
Middle force: tensor([0.5207, 0.5390, 0.5076], device='cuda:1')
Thumb force: tensor([0.5556, 0.6251, 0.5029], device='cuda:1')
tensor([ 0.1827,  0.5126,  0.5425,  0.6118, -0.1283,  0.5135,  0.9429,  1.0869,
         1.3345,  0.3877,  0.1539,  0.9966, -0.0430,  0.0065, -0.2528, -4.8266],
       device='cuda:1')
Solve time for step 3 4.345784084987827
Current ori: tensor([-0.0430,  0.0065, -0.2528], device='cuda:1')
Middle force: tensor([0.5037, 0.5901], device='cuda:1')
Thumb force: tensor([0.5289, 0.5410], device='cuda:1')
tensor([ 0.1819,  0.5121,  0.5416,  0.6109, -0.1314,  0.5212,  0.9464,  1.0895,
         1.3365,  0.3921,  0.1424,  1.0045, -0.0502,  0.0065, -0.2516, -4.4114],
       device='cuda:1')
Solve time for step 4 3.969382048002444
Current ori: tensor([-0.0502,  0.0065, -0.2516], device='cuda:1')
Middle force: tensor([0.5259], device='cuda:1')
Thumb force: tensor([0.5487], device='cuda:1')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0008), steps=2
Reward stats updated: mean 0.0146 -> 0.0146, std: 0.0922
Collected 553 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=0.9561, Q2 Loss=0.9561, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9919
SAC Update 2/5: Actor Loss=-0.0082, Q1 Loss=0.9481, Q2 Loss=0.9481, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6454
SAC Update 3/5: Actor Loss=-0.0125, Q1 Loss=1.3392, Q2 Loss=1.3392, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7614
SAC Update 4/5: Actor Loss=-0.0113, Q1 Loss=2.0276, Q2 Loss=2.0276, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3353
SAC Update 5/5: Actor Loss=-0.0119, Q1 Loss=1.1640, Q2 Loss=1.1640, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1984

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (41.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010519
Q1 loss: 1.287006
Q2 loss: 1.287006
Current threshold: -149.4947
Global Scale Offset: 5717.3815
Reward stats: mean=0.0146, std=0.0922, count=553
----------------------------------------------
SAC Update - Actor Loss: -0.0105, Q1 Loss: 1.2870, Q2 Loss: 1.2870, Entropy: 0.6931, Mean TD Error: 0.9865, Threshold: -149.4947
Original likelihood: -137.7025604248047
Adjusted likelihood: -137.7025604248047
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5008)
Current yaw: tensor([-0.0506,  0.0052, -0.2522], device='cuda:1')
4 turn
Sampling time 3.7334394850186072
tensor([ 0.1267,  0.5700,  0.5841,  0.6327, -0.1294,  0.5223,  0.9466,  1.0885,
         1.3364,  0.3915,  0.1397,  1.0061, -0.0506,  0.0052, -0.2522, -4.2884],
       device='cuda:1')
Original likelihood: -143.7318878173828
Adjusted likelihood: -143.7318878173828
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5004)
State is out of distribution
Projection step: 0, Loss: 141.73764038085938
Projection step: 1, Loss: 133.68515014648438
Projection step: 2, Loss: 140.35255432128906
Projection step: 3, Loss: 129.0370635986328
Projection step: 4, Loss: 118.43853759765625
Projection step: 5, Loss: 114.92259216308594
Projection step: 6, Loss: 111.30372619628906
Projection step: 7, Loss: 105.54766082763672
Projection step: 8, Loss: 100.33277893066406
Final likelihood: tensor([-128.4764,  -90.8597,  -94.9987,  -95.2725,  -70.8183,  -94.0968,
        -108.5972, -122.0439, -100.0503,  -94.0896,  -99.7770,  -91.9251,
         -93.3680,  -99.8826,  -93.2115, -127.8570])
Final projection likelihood: -100.3328
1 mode projection succeeded
New goal: tensor([ 0.1164,  0.5580,  0.5508,  0.6591, -0.0820,  0.5219,  0.8895,  1.0436,
         1.3683,  0.3570,  0.1280,  1.0117, -0.0504,  0.0059, -0.5504],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1')
Original likelihood: -104.43018341064453
Adjusted likelihood: -104.43018341064453
Likelihood residual: 0.0
Original likelihood: -117.98493957519531
Adjusted likelihood: -117.98493957519531
Likelihood residual: 0.0
{'index': 117.98493957519531, 'thumb_middle': 104.43018341064453}
Current yaw: tensor([-0.0506,  0.0052, -0.2522], device='cuda:1')
5 thumb_middle
tensor([ 0.1267,  0.5700,  0.5841,  0.6327, -0.1294,  0.5223,  0.9466,  1.0885,
         1.3364,  0.3915,  0.1397,  1.0061, -0.0506,  0.0052, -0.2522, -4.2884],
       device='cuda:1')
Solve time for step 1 9.036787253047805
Current ori: tensor([-0.0506,  0.0052, -0.2522], device='cuda:1')
Index force: tensor([0.5712, 0.5989, 0.5872, 0.5925], device='cuda:1')
tensor([ 0.1068,  0.5900,  0.5406,  0.6247, -0.2001,  0.4797,  0.8596,  1.0345,
         1.3225,  0.3508,  0.0603,  0.9809, -0.0557,  0.0206, -0.2522, -4.3584],
       device='cuda:1')
Solve time for step 2 3.5708300080150366
Current ori: tensor([-0.0557,  0.0206, -0.2522], device='cuda:1')
Index force: tensor([0.5942, 0.5843, 0.5893], device='cuda:1')
tensor([ 0.1107,  0.5799,  0.5476,  0.6460, -0.2097,  0.4851,  0.8516,  1.0247,
         1.3331,  0.3448,  0.0517,  0.9799, -0.0516,  0.0186, -0.2522, -4.3480],
       device='cuda:1')
Solve time for step 3 3.633199670992326
Current ori: tensor([-0.0516,  0.0186, -0.2522], device='cuda:1')
Index force: tensor([0.5716, 0.5638], device='cuda:1')
tensor([ 0.1299,  0.5866,  0.5535,  0.6549, -0.1907,  0.4922,  0.8437,  1.0289,
         1.3318,  0.3334,  0.0425,  0.9744, -0.0523,  0.0057, -0.2522, -4.3157],
       device='cuda:1')
Solve time for step 4 3.232352129998617
Current ori: tensor([-0.0523,  0.0057, -0.2522], device='cuda:1')
Index force: tensor([0.5739], device='cuda:1')
Storing RECOVERY transition: reward=0.0035 (scaled=0.0035), steps=0
Reward stats updated: mean 0.0146 -> 0.0145, std: 0.0921
Collected 554 transitions for RL
SAC Update 1/5: Actor Loss=-0.0084, Q1 Loss=1.0224, Q2 Loss=1.0224, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7941
SAC Update 2/5: Actor Loss=-0.0120, Q1 Loss=6.3020, Q2 Loss=6.3020, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3926
SAC Update 3/5: Actor Loss=-0.0099, Q1 Loss=1.0125, Q2 Loss=1.0125, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4428
SAC Update 4/5: Actor Loss=-0.0086, Q1 Loss=1.9450, Q2 Loss=1.9450, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.6714
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7701, Q2 Loss=0.7701, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4162

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (41.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009223
Q1 loss: 2.210402
Q2 loss: 2.210402
Current threshold: -149.4946
Global Scale Offset: 5736.7495
Reward stats: mean=0.0145, std=0.0921, count=554
----------------------------------------------
SAC Update - Actor Loss: -0.0092, Q1 Loss: 2.2104, Q2 Loss: 2.2104, Entropy: 0.6931, Mean TD Error: 2.3434, Threshold: -149.4946
Original likelihood: -135.04408264160156
Adjusted likelihood: -135.04408264160156
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5010)
Current yaw: tensor([-0.0490,  0.0101, -0.2557], device='cuda:1')
6 turn
Sampling time 3.615552539995406
tensor([ 0.1132,  0.5744,  0.5485,  0.6651, -0.1240,  0.5394,  0.8848,  1.0283,
         1.3796,  0.3531,  0.1032,  1.0143, -0.0490,  0.0101, -0.2557, -4.2592],
       device='cuda:1')
Original likelihood: -122.42742919921875
Adjusted likelihood: -122.42742919921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5019)
Solve time for step 1 14.193128220038489
Current ori: tensor([-0.0490,  0.0101, -0.2557], device='cuda:1')
Middle force: tensor([0.5335, 1.7770, 0.5139, 0.5852, 0.7241, 0.6267, 0.5102, 0.5083, 0.5823,
        0.5158, 0.6566, 0.5792], device='cuda:1')
Thumb force: tensor([0.5968, 2.0891, 0.7673, 1.3053, 0.5122, 0.5326, 0.5453, 0.8935, 1.0174,
        0.5650, 0.5333, 0.5874], device='cuda:1')
Index force: tensor([0.6262, 0.5702, 0.6050, 0.9949, 0.5998, 0.5987, 0.5007, 0.5504, 0.6102,
        0.5321, 0.5511, 0.5982], device='cuda:1')
Storing NORMAL transition: reward=0.0134 (scaled=0.0134), steps=1
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0920
Collected 555 transitions for RL
SAC Update 1/5: Actor Loss=-0.0106, Q1 Loss=3.3840, Q2 Loss=3.3840, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.0351
SAC Update 2/5: Actor Loss=-0.0126, Q1 Loss=1.3650, Q2 Loss=1.3650, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7944
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=2.8528, Q2 Loss=2.8528, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.1025
SAC Update 4/5: Actor Loss=-0.0083, Q1 Loss=1.5585, Q2 Loss=1.5585, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.1983
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=0.7236, Q2 Loss=0.7236, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0739

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (19.6%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009649
Q1 loss: 1.976790
Q2 loss: 1.976790
Current threshold: -149.4944
Global Scale Offset: 5762.0186
Reward stats: mean=0.0145, std=0.0920, count=555
----------------------------------------------
SAC Update - Actor Loss: -0.0096, Q1 Loss: 1.9768, Q2 Loss: 1.9768, Entropy: 0.6931, Mean TD Error: 2.4408, Threshold: -149.4944
tensor([ 0.0838,  0.5401,  0.5723,  0.6538, -0.1386,  0.5630,  0.7955,  1.1306,
         1.4264,  0.2789,  0.0890,  1.0118, -0.0426,  0.0197, -0.2688, -4.1883],
       device='cuda:1')
Original likelihood: -149.33753967285156
Adjusted likelihood: -149.33753967285156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5000)
State is out of distribution
Projection step: 0, Loss: 145.52333068847656
Projection step: 1, Loss: 132.33323669433594
Projection step: 2, Loss: 121.3872299194336
Projection step: 3, Loss: 121.5284423828125
Projection step: 4, Loss: 110.8271484375
Projection step: 5, Loss: 106.42533874511719
Projection step: 6, Loss: 101.16934967041016
Final likelihood: tensor([-108.0625, -101.8510,  -57.9849,  -98.0841, -113.1397, -103.4398,
        -101.5301,  -97.0744, -102.8158, -100.3480, -106.7455, -101.7634,
        -103.6399, -116.2472, -107.8187,  -98.1647])
Final projection likelihood: -101.1693
1 mode projection succeeded
New goal: tensor([ 0.0865,  0.5318,  0.5605,  0.6807, -0.0951,  0.5678,  0.7434,  1.1005,
         1.4255,  0.2522,  0.1026,  1.0529, -0.0434,  0.0162, -0.3004],
       device='cuda:1')
tensor([[0.0026]], device='cuda:1') tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -103.23092651367188
Adjusted likelihood: -103.23092651367188
Likelihood residual: 0.0
Original likelihood: -115.8414535522461
Adjusted likelihood: -115.8414535522461
Likelihood residual: 0.0
{'index': 115.8414535522461, 'thumb_middle': 103.23092651367188}
Current yaw: tensor([-0.0426,  0.0197, -0.2688], device='cuda:1')
7 thumb_middle
tensor([ 0.0838,  0.5401,  0.5723,  0.6538, -0.1386,  0.5630,  0.7955,  1.1306,
         1.4264,  0.2789,  0.0890,  1.0118, -0.0426,  0.0197, -0.2688, -4.1883],
       device='cuda:1')
Solve time for step 1 8.867419329995755
Current ori: tensor([-0.0426,  0.0197, -0.2688], device='cuda:1')
Index force: tensor([0.5809, 0.5814, 0.5824, 0.5916], device='cuda:1')
tensor([ 0.0825,  0.5417,  0.5601,  0.6701, -0.2112,  0.5362,  0.7260,  1.0832,
         1.3790,  0.2463,  0.0224,  1.0107, -0.0415,  0.0253, -0.2688, -4.2244],
       device='cuda:1')
Solve time for step 2 3.533007753023412
Current ori: tensor([-0.0415,  0.0253, -0.2688], device='cuda:1')
Index force: tensor([0.5714, 0.5749, 0.5844], device='cuda:1')
tensor([ 0.0909,  0.5570,  0.5529,  0.6598, -0.2051,  0.5428,  0.7192,  1.0812,
         1.3732,  0.2241,  0.0268,  1.0061, -0.0459,  0.0195, -0.2688, -4.2159],
       device='cuda:1')
Solve time for step 3 3.3774640139890835
Current ori: tensor([-0.0459,  0.0195, -0.2688], device='cuda:1')
Index force: tensor([0.5658, 0.5756], device='cuda:1')
tensor([ 0.0822,  0.5402,  0.5572,  0.6804, -0.2192,  0.5509,  0.7064,  1.0862,
         1.3814,  0.2326,  0.0171,  1.0180, -0.0403,  0.0252, -0.2688, -4.2177],
       device='cuda:1')
Solve time for step 4 3.296339872002136
Current ori: tensor([-0.0403,  0.0252, -0.2688], device='cuda:1')
Index force: tensor([0.5867], device='cuda:1')
Storing RECOVERY transition: reward=0.0078 (scaled=0.0078), steps=1
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0920
Collected 556 transitions for RL
SAC Update 1/5: Actor Loss=-0.0071, Q1 Loss=0.8390, Q2 Loss=0.8390, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.8280
SAC Update 2/5: Actor Loss=-0.0090, Q1 Loss=0.9230, Q2 Loss=0.9230, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4053
SAC Update 3/5: Actor Loss=-0.0073, Q1 Loss=0.9026, Q2 Loss=0.9026, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.5577
SAC Update 4/5: Actor Loss=-0.0104, Q1 Loss=1.0427, Q2 Loss=1.0427, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1816
SAC Update 5/5: Actor Loss=-0.0078, Q1 Loss=0.8610, Q2 Loss=0.8610, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4653

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (41.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008319
Q1 loss: 0.913662
Q2 loss: 0.913662
Current threshold: -149.4944
Global Scale Offset: 5792.3975
Reward stats: mean=0.0145, std=0.0920, count=556
----------------------------------------------
SAC Update - Actor Loss: -0.0083, Q1 Loss: 0.9137, Q2 Loss: 0.9137, Entropy: 0.6931, Mean TD Error: 1.2876, Threshold: -149.4944
Original likelihood: -154.36427307128906
Adjusted likelihood: -154.36427307128906
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4997)
Current yaw: tensor([-0.0413,  0.0221, -0.2767], device='cuda:1')
8 turn
Sampling time 3.7155634610098787
tensor([ 0.0770,  0.5430,  0.5523,  0.6729, -0.1456,  0.5977,  0.7411,  1.0967,
         1.4396,  0.2484,  0.0662,  1.0477, -0.0413,  0.0221, -0.2767, -4.1676],
       device='cuda:1')
Original likelihood: -143.01060485839844
Adjusted likelihood: -143.01060485839844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5004)
State is out of distribution
Projection step: 0, Loss: 145.90634155273438
Projection step: 1, Loss: 139.8583984375
Projection step: 2, Loss: 127.46171569824219
Projection step: 3, Loss: 124.09869384765625
Projection step: 4, Loss: 118.8163833618164
Projection step: 5, Loss: 116.25444030761719
Projection step: 6, Loss: 112.55782318115234
Projection step: 7, Loss: 108.9901123046875
Projection step: 8, Loss: 101.98908233642578
Final likelihood: tensor([-108.2324, -102.7894,  -94.2433, -103.0229,  -99.6950, -101.6885,
         -96.2307,  -99.7909, -103.2962, -101.2796,  -97.3912, -102.6623,
        -107.8766, -105.8687, -105.8240, -101.9335])
Final projection likelihood: -101.9891
1 mode projection succeeded
New goal: tensor([ 0.0806,  0.5366,  0.5527,  0.6861, -0.0949,  0.5914,  0.7037,  1.0556,
         1.4276,  0.2219,  0.0864,  1.0884, -0.0425,  0.0182, -0.3707],
       device='cuda:1')
tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -128.16860961914062
Adjusted likelihood: -128.16860961914062
Likelihood residual: 0.0
Original likelihood: -125.96559143066406
Adjusted likelihood: -125.96559143066406
Likelihood residual: 0.0
{'index': 125.96559143066406, 'thumb_middle': 128.16860961914062}
Current yaw: tensor([-0.0413,  0.0221, -0.2767], device='cuda:1')
9 index
tensor([ 0.0770,  0.5430,  0.5523,  0.6729, -0.1456,  0.5977,  0.7411,  1.0967,
         1.4396,  0.2484,  0.0662,  1.0477, -0.0413,  0.0221, -0.2767, -4.1676],
       device='cuda:1')
Solve time for step 1 10.837849102041218
Current ori: tensor([-0.0413,  0.0221, -0.2767], device='cuda:1')
Middle force: tensor([0.5818, 0.5283, 0.5010, 0.5648], device='cuda:1')
Thumb force: tensor([0.5961, 0.5586, 0.5363, 0.6175], device='cuda:1')
tensor([ 0.1184,  0.4789,  0.5035,  0.6554, -0.1331,  0.6155,  0.7328,  1.0770,
         1.4546,  0.2319,  0.0334,  1.0488, -0.0524,  0.0147, -0.2963, -3.2371],
       device='cuda:1')
Solve time for step 2 4.364001742040273
Current ori: tensor([-0.0524,  0.0147, -0.2963], device='cuda:1')
Middle force: tensor([0.5264, 0.5008, 0.5607], device='cuda:1')
Thumb force: tensor([0.5533, 0.5350, 0.6140], device='cuda:1')
tensor([ 0.1195,  0.4798,  0.5001,  0.6584, -0.1400,  0.6265,  0.7257,  1.0704,
         1.4667,  0.2164,  0.0220,  1.0462, -0.0613,  0.0177, -0.2959, -2.9505],
       device='cuda:1')
Solve time for step 3 4.1762888910016045
Current ori: tensor([-0.0613,  0.0177, -0.2959], device='cuda:1')
Middle force: tensor([0.5005, 0.5562], device='cuda:1')
Thumb force: tensor([0.5292, 0.6067], device='cuda:1')
tensor([ 0.1189,  0.4797,  0.5009,  0.6564, -0.1328,  0.6249,  0.7325,  1.0755,
         1.4532,  0.2379,  0.0102,  1.0774, -0.0579,  0.0117, -0.2918, -3.1008],
       device='cuda:1')
Solve time for step 4 4.0039974540122785
Current ori: tensor([-0.0579,  0.0117, -0.2918], device='cuda:1')
Middle force: tensor([0.5095], device='cuda:1')
Thumb force: tensor([0.5181], device='cuda:1')
Storing RECOVERY transition: reward=0.0123 (scaled=0.0123), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0919
Collected 557 transitions for RL
SAC Update 1/5: Actor Loss=-0.0087, Q1 Loss=1.1308, Q2 Loss=1.1308, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.7205
SAC Update 2/5: Actor Loss=-0.0074, Q1 Loss=1.4819, Q2 Loss=1.4819, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3455
SAC Update 3/5: Actor Loss=-0.0096, Q1 Loss=0.9863, Q2 Loss=0.9863, Entropy=0.6930, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2785
SAC Update 4/5: Actor Loss=-0.0093, Q1 Loss=1.5138, Q2 Loss=1.5138, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3946
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=1.2393, Q2 Loss=1.2393, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.8703

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (17.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008811
Q1 loss: 1.270420
Q2 loss: 1.270420
Current threshold: -149.4944
Global Scale Offset: 5821.3863
Reward stats: mean=0.0145, std=0.0919, count=557
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.2704, Q2 Loss: 1.2704, Entropy: 0.6931, Mean TD Error: 2.1219, Threshold: -149.4944
Original likelihood: -141.65721130371094
Adjusted likelihood: -141.65721130371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5005)
Current yaw: tensor([-0.0627,  0.0125, -0.2908], device='cuda:1')
10 turn
Sampling time 3.6446122149936855
tensor([ 0.0723,  0.5431,  0.5402,  0.6792, -0.1328,  0.6328,  0.7252,  1.0631,
         1.4569,  0.2327,  0.0120,  1.0642, -0.0627,  0.0125, -0.2908, -3.1946],
       device='cuda:1')
Original likelihood: -136.9430389404297
Adjusted likelihood: -136.9430389404297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5009)
Solve time for step 1 14.295979998016264
Current ori: tensor([-0.0627,  0.0125, -0.2908], device='cuda:1')
Middle force: tensor([0.5520, 1.7106, 0.5166, 0.5890, 0.7380, 0.6414, 0.5516, 0.5201, 0.8234,
        0.5498, 0.5885, 0.5680], device='cuda:1')
Thumb force: tensor([0.6089, 2.0754, 0.7544, 1.3495, 0.5262, 0.5261, 0.8940, 0.5776, 1.2878,
        0.5599, 0.5742, 0.5892], device='cuda:1')
Index force: tensor([0.6086, 0.5762, 0.5806, 0.9707, 0.5853, 0.6160, 0.5939, 0.5854, 0.5297,
        0.7510, 0.5749, 0.5705], device='cuda:1')
Storing NORMAL transition: reward=0.0082 (scaled=0.0082), steps=1
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0918
Collected 558 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=0.7825, Q2 Loss=0.7825, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4741
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=1.4141, Q2 Loss=1.4141, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.0861
SAC Update 3/5: Actor Loss=-0.0097, Q1 Loss=1.0215, Q2 Loss=1.0215, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6793
SAC Update 4/5: Actor Loss=-0.0090, Q1 Loss=1.4249, Q2 Loss=1.4249, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2043
SAC Update 5/5: Actor Loss=-0.0132, Q1 Loss=1.4698, Q2 Loss=1.4698, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8019

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.6%)
Q1 update: 0.05s (20.5%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (39.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009546
Q1 loss: 1.222529
Q2 loss: 1.222529
Current threshold: -149.4944
Global Scale Offset: 5849.2866
Reward stats: mean=0.0145, std=0.0918, count=558
----------------------------------------------
SAC Update - Actor Loss: -0.0095, Q1 Loss: 1.2225, Q2 Loss: 1.2225, Entropy: 0.6931, Mean TD Error: 1.2492, Threshold: -149.4944
tensor([ 0.0048,  0.4312,  0.6497,  0.6438, -0.0887,  0.5280,  0.7229,  1.2035,
         1.4388,  0.2013,  0.0217,  1.1092, -0.0306,  0.0182, -0.2963, -2.9055],
       device='cuda:1')
Original likelihood: -137.36468505859375
Adjusted likelihood: -137.36468505859375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5008)
State is out of distribution
Projection step: 0, Loss: 130.92169189453125
Projection step: 1, Loss: 127.76872253417969
Projection step: 2, Loss: 118.32893371582031
Projection step: 3, Loss: 118.34629821777344
Projection step: 4, Loss: 107.59405517578125
Projection step: 5, Loss: 107.71125030517578
Projection step: 6, Loss: 100.02030181884766
Final likelihood: tensor([ -91.6590, -104.2403, -110.5162,  -87.1626,  -89.9037, -105.3723,
         -92.1139, -110.9978, -100.2300,  -99.5466, -109.1902,  -96.0015,
        -101.2230,  -95.2924, -103.0388, -103.8366])
Final projection likelihood: -100.0203
1 mode projection succeeded
New goal: tensor([ 0.0050,  0.4643,  0.6327,  0.6532, -0.0750,  0.5272,  0.7010,  1.1145,
         1.3999,  0.2053,  0.0483,  1.1387, -0.0313,  0.0129, -0.5187],
       device='cuda:1')
tensor([[0.0052]], device='cuda:1') tensor([[0.0025]], device='cuda:1') tensor([[0.0030]], device='cuda:1')
Original likelihood: -127.70764923095703
Adjusted likelihood: -127.70764923095703
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 127.70764923095703}
Current yaw: tensor([-0.0306,  0.0182, -0.2963], device='cuda:1')
11 thumb_middle
tensor([ 0.0048,  0.4312,  0.6497,  0.6438, -0.0887,  0.5280,  0.7229,  1.2035,
         1.4388,  0.2013,  0.0217,  1.1092, -0.0306,  0.0182, -0.2963, -2.9055],
       device='cuda:1')
Solve time for step 1 9.12708255497273
Current ori: tensor([-0.0306,  0.0182, -0.2963], device='cuda:1')
Index force: tensor([0.5858, 0.6001, 0.6045, 0.6029], device='cuda:1')
tensor([ 2.3118e-03,  4.3981e-01,  6.3385e-01,  6.4985e-01, -1.6894e-01,
         5.0602e-01,  6.7601e-01,  1.1148e+00,  1.3776e+00,  1.8711e-01,
        -8.5663e-03,  1.1147e+00, -3.6807e-02,  3.5882e-02, -2.9635e-01,
        -3.1234e+00], device='cuda:1')
Solve time for step 2 3.6583094450179487
Current ori: tensor([-0.0368,  0.0359, -0.2963], device='cuda:1')
Index force: tensor([0.5945, 0.6006, 0.5983], device='cuda:1')
tensor([ 0.0233,  0.4558,  0.6304,  0.6501, -0.1743,  0.5183,  0.6765,  1.1016,
         1.3770,  0.1901, -0.0178,  1.1159, -0.0442,  0.0594, -0.2963, -3.3325],
       device='cuda:1')
Solve time for step 3 3.5872657330473885
Current ori: tensor([-0.0442,  0.0594, -0.2963], device='cuda:1')
Index force: tensor([0.5938, 0.5926], device='cuda:1')
tensor([ 0.0393,  0.4622,  0.6317,  0.6574, -0.1969,  0.5033,  0.6662,  1.0946,
         1.3884,  0.1897, -0.0056,  1.1231, -0.0390,  0.0718, -0.2963, -3.4251],
       device='cuda:1')
Solve time for step 4 3.446930459002033
Current ori: tensor([-0.0390,  0.0718, -0.2963], device='cuda:1')
Index force: tensor([0.5947], device='cuda:1')
Storing RECOVERY transition: reward=0.0171 (scaled=0.0171), steps=1
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0917
Collected 559 transitions for RL
SAC Update 1/5: Actor Loss=-0.0088, Q1 Loss=1.6691, Q2 Loss=1.6691, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.9717
SAC Update 2/5: Actor Loss=-0.0098, Q1 Loss=2.2530, Q2 Loss=2.2530, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.2744
SAC Update 3/5: Actor Loss=-0.0081, Q1 Loss=0.8204, Q2 Loss=0.8204, Entropy=0.6930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1976
SAC Update 4/5: Actor Loss=-0.0079, Q1 Loss=1.3025, Q2 Loss=1.3025, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=3.4020
SAC Update 5/5: Actor Loss=-0.0093, Q1 Loss=1.5008, Q2 Loss=1.5008, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.3589

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008796
Q1 loss: 1.509176
Q2 loss: 1.509176
Current threshold: -149.4944
Global Scale Offset: 5878.8866
Reward stats: mean=0.0145, std=0.0917, count=559
----------------------------------------------
SAC Update - Actor Loss: -0.0088, Q1 Loss: 1.5092, Q2 Loss: 1.5092, Entropy: 0.6931, Mean TD Error: 2.4409, Threshold: -149.4944
Original likelihood: -169.7112579345703
Adjusted likelihood: -169.7112579345703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4986)
Current yaw: tensor([-0.0412,  0.0508, -0.3165], device='cuda:1')
12 turn
Sampling time 3.593344127992168
tensor([ 0.0568,  0.4615,  0.6403,  0.6737, -0.1357,  0.5433,  0.6917,  1.1058,
         1.4591,  0.2150,  0.0462,  1.1519, -0.0412,  0.0508, -0.3165, -3.3094],
       device='cuda:1')
Original likelihood: -166.4013671875
Adjusted likelihood: -166.4013671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4989)
State is out of distribution
Projection step: 0, Loss: 166.79205322265625
Projection step: 1, Loss: 151.37173461914062
Projection step: 2, Loss: 162.8619384765625
Projection step: 3, Loss: 161.1441650390625
Projection step: 4, Loss: 159.08740234375
Projection step: 5, Loss: 143.44976806640625
Projection step: 6, Loss: 143.62197875976562
Projection step: 7, Loss: 141.1443328857422
Projection step: 8, Loss: 128.3972930908203
Projection step: 9, Loss: 131.01907348632812
Projection step: 10, Loss: 129.420166015625
Projection step: 11, Loss: 122.66661071777344
Projection step: 12, Loss: 126.27954864501953
Projection step: 13, Loss: 129.5550537109375
Projection step: 14, Loss: 122.74838256835938
Projection step: 15, Loss: 116.95835876464844
Projection step: 16, Loss: 109.56150817871094
Projection step: 17, Loss: 113.75038146972656
Projection step: 18, Loss: 104.03762817382812
Final likelihood: tensor([ -98.3932, -100.5754, -110.1161, -106.9540, -106.6796, -107.9194,
         -86.6982, -113.1780, -100.5905, -106.6044,  -95.1422, -116.0343,
        -104.4577, -105.3165, -100.8057, -105.1366])
Final projection likelihood: -104.0376
1 mode projection succeeded
New goal: tensor([ 0.0513,  0.5218,  0.5592,  0.6942, -0.0868,  0.5267,  0.7066,  0.9599,
         1.4116,  0.2081,  0.0815,  1.1395, -0.0441,  0.0384, -1.0309],
       device='cuda:1')
tensor([[0.0024]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0031]], device='cuda:1')
Original likelihood: -145.03903198242188
Adjusted likelihood: -145.03903198242188
Likelihood residual: 0.0
Original likelihood: -132.03924560546875
Adjusted likelihood: -132.03924560546875
Likelihood residual: 0.0
{'index': 132.03924560546875, 'thumb_middle': 145.03903198242188}
Current yaw: tensor([-0.0412,  0.0508, -0.3165], device='cuda:1')
13 index
tensor([ 0.0568,  0.4615,  0.6403,  0.6737, -0.1357,  0.5433,  0.6917,  1.1058,
         1.4591,  0.2150,  0.0462,  1.1519, -0.0412,  0.0508, -0.3165, -3.3094],
       device='cuda:1')
Solve time for step 1 10.884068179002497
Current ori: tensor([-0.0412,  0.0508, -0.3165], device='cuda:1')
Middle force: tensor([0.5561, 0.6080, 0.5400, 0.5090], device='cuda:1')
Thumb force: tensor([0.5183, 0.6052, 0.5745, 0.5852], device='cuda:1')
tensor([ 0.0901,  0.4485,  0.5200,  0.6619, -0.1415,  0.5463,  0.7352,  1.0207,
         1.4678,  0.2054,  0.0512,  1.1138, -0.0579,  0.0535, -0.3053, -1.5595],
       device='cuda:1')
Solve time for step 2 4.441385700949468
Current ori: tensor([-0.0579,  0.0535, -0.3053], device='cuda:1')
Middle force: tensor([0.6052, 0.5376, 0.5081], device='cuda:1')
Thumb force: tensor([0.5958, 0.5710, 0.5815], device='cuda:1')
tensor([ 0.0904,  0.4561,  0.5104,  0.6627, -0.1197,  0.5621,  0.7431,  0.9905,
         1.4628,  0.2058,  0.0350,  1.1050, -0.0678,  0.0396, -0.3230, -0.4173],
       device='cuda:1')
Solve time for step 3 4.282062976970337
Current ori: tensor([-0.0678,  0.0396, -0.3230], device='cuda:1')
Middle force: tensor([0.5004, 0.5702], device='cuda:1')
Thumb force: tensor([0.5014, 0.5465], device='cuda:1')
tensor([ 0.0906,  0.4597,  0.5055,  0.6628, -0.1073,  0.5621,  0.7498,  0.9990,
         1.4489,  0.2318,  0.0202,  1.1288, -0.0674,  0.0309, -0.3417,  0.6110],
       device='cuda:1')
Solve time for step 4 4.062614328984637
Current ori: tensor([-0.0674,  0.0309, -0.3417], device='cuda:1')
Middle force: tensor([0.5047], device='cuda:1')
Thumb force: tensor([0.5718], device='cuda:1')
Storing RECOVERY transition: reward=0.0108 (scaled=0.0108), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0916
Collected 560 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.9441, Q2 Loss=0.9441, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1846
SAC Update 2/5: Actor Loss=-0.0110, Q1 Loss=1.1125, Q2 Loss=1.1125, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2646
SAC Update 3/5: Actor Loss=-0.0086, Q1 Loss=1.1555, Q2 Loss=1.1555, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8898
SAC Update 4/5: Actor Loss=-0.0078, Q1 Loss=0.8227, Q2 Loss=0.8227, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3484
SAC Update 5/5: Actor Loss=-0.0088, Q1 Loss=1.2710, Q2 Loss=1.2710, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0210

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.0%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (41.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.009085
Q1 loss: 1.061145
Q2 loss: 1.061145
Current threshold: -149.4944
Global Scale Offset: 5902.1036
Reward stats: mean=0.0145, std=0.0916, count=560
----------------------------------------------
SAC Update - Actor Loss: -0.0091, Q1 Loss: 1.0611, Q2 Loss: 1.0611, Entropy: 0.6931, Mean TD Error: 0.5417, Threshold: -149.4944
Original likelihood: -147.73895263671875
Adjusted likelihood: -147.73895263671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5001)
State is out of distribution
Projection step: 0, Loss: 141.6899871826172
Projection step: 1, Loss: 132.27870178222656
Projection step: 2, Loss: 133.81591796875
Projection step: 3, Loss: 133.35829162597656
Projection step: 4, Loss: 131.21600341796875
Projection step: 5, Loss: 129.1614990234375
Projection step: 6, Loss: 126.2886962890625
Projection step: 7, Loss: 122.55766296386719
Projection step: 8, Loss: 121.42357635498047
Projection step: 9, Loss: 119.60596466064453
Projection step: 10, Loss: 118.62479400634766
Projection step: 11, Loss: 115.89483642578125
Projection step: 12, Loss: 112.15666198730469
Projection step: 13, Loss: 114.42302703857422
Projection step: 14, Loss: 116.11642456054688
Projection step: 15, Loss: 111.46025085449219
Projection step: 16, Loss: 113.14907836914062
Projection step: 17, Loss: 107.59539031982422
Projection step: 18, Loss: 107.15156555175781
Projection step: 19, Loss: 107.670654296875
Projection step: 20, Loss: 102.05764770507812
Final likelihood: tensor([ -92.7446,  -94.3486,  -98.6281, -104.5148, -100.0390,  -97.3929,
        -105.3023, -107.8579, -101.7783, -101.2149, -109.6323,  -98.2185,
        -103.1815, -105.9440,  -98.1681, -113.9568])
Final projection likelihood: -102.0576
1 mode projection succeeded
New goal: tensor([ 0.0608,  0.5485,  0.5297,  0.6698, -0.0639,  0.5196,  0.7222,  0.9704,
         1.4280,  0.1906,  0.0892,  1.0846, -0.0630,  0.0274, -0.7106],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0029]], device='cuda:1') tensor([[0.0028]], device='cuda:1')
Original likelihood: -107.45819091796875
Adjusted likelihood: -107.45819091796875
Likelihood residual: 0.0
Original likelihood: -118.87109375
Adjusted likelihood: -118.87109375
Likelihood residual: 0.0
{'index': 118.87109375, 'thumb_middle': 107.45819091796875}
Current yaw: tensor([-0.0668,  0.0370, -0.3289], device='cuda:1')
14 thumb_middle
tensor([ 0.0433,  0.5156,  0.5460,  0.6848, -0.1163,  0.5597,  0.7485,  0.9938,
         1.4570,  0.2199,  0.0236,  1.1278, -0.0668,  0.0370, -0.3289,  0.8688],
       device='cuda:1')
Solve time for step 1 8.833734238985926
Current ori: tensor([-0.0668,  0.0370, -0.3289], device='cuda:1')
Index force: tensor([0.5825, 0.5661, 0.5977, 0.5002], device='cuda:1')
tensor([ 0.0479,  0.5567,  0.5147,  0.6414, -0.1513,  0.5110,  0.7055,  0.9678,
         1.3819,  0.1659,  0.0150,  1.0679, -0.0800,  0.0416, -0.3289,  0.8210],
       device='cuda:1')
Solve time for step 2 3.6025638899882324
Current ori: tensor([-0.0800,  0.0416, -0.3289], device='cuda:1')
Index force: tensor([0.5584, 0.5899, 0.4999], device='cuda:1')
tensor([ 0.0552,  0.5381,  0.5353,  0.6662, -0.1621,  0.5157,  0.7069,  0.9486,
         1.3868,  0.1594,  0.0182,  1.0557, -0.0737,  0.0357, -0.3289,  0.8416],
       device='cuda:1')
Solve time for step 3 3.781377503008116
Current ori: tensor([-0.0737,  0.0357, -0.3289], device='cuda:1')
Index force: tensor([0.5816, 0.5749], device='cuda:1')
tensor([ 0.0557,  0.5355,  0.5334,  0.6779, -0.1593,  0.5153,  0.7008,  0.9531,
         1.3868,  0.1645,  0.0149,  1.0557, -0.0721,  0.0349, -0.3289,  0.8469],
       device='cuda:1')
Solve time for step 4 3.3105710050440393
Current ori: tensor([-0.0721,  0.0349, -0.3289], device='cuda:1')
Index force: tensor([0.5438], device='cuda:1')
Storing RECOVERY transition: reward=0.0167 (scaled=0.0167), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0915
Collected 561 transitions for RL
SAC Update 1/5: Actor Loss=-0.0086, Q1 Loss=0.8602, Q2 Loss=0.8602, Entropy=0.6931, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1552
SAC Update 2/5: Actor Loss=-0.0084, Q1 Loss=1.0339, Q2 Loss=1.0339, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6443
SAC Update 3/5: Actor Loss=-0.0092, Q1 Loss=1.5204, Q2 Loss=1.5204, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2535
SAC Update 4/5: Actor Loss=-0.0114, Q1 Loss=1.1819, Q2 Loss=1.1819, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4217
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=0.9999, Q2 Loss=0.9999, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6917

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.7%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.6%)
Actor update: 0.09s (38.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.009383
Q1 loss: 1.119249
Q2 loss: 1.119249
Current threshold: -149.4943
Global Scale Offset: 5922.9165
Reward stats: mean=0.0145, std=0.0915, count=561
----------------------------------------------
SAC Update - Actor Loss: -0.0094, Q1 Loss: 1.1192, Q2 Loss: 1.1192, Entropy: 0.6931, Mean TD Error: 0.8333, Threshold: -149.4943
Original likelihood: -118.55985260009766
Adjusted likelihood: -118.55985260009766
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5021)
State is out of distribution
Projection step: 0, Loss: 120.35374450683594
Projection step: 1, Loss: 117.19725036621094
Projection step: 2, Loss: 116.27967834472656
Projection step: 3, Loss: 112.72628784179688
Projection step: 4, Loss: 116.62551879882812
Projection step: 5, Loss: 112.75906372070312
Projection step: 6, Loss: 112.897705078125
Projection step: 7, Loss: 108.82262420654297
Projection step: 8, Loss: 110.42689514160156
Projection step: 9, Loss: 108.9993896484375
Projection step: 10, Loss: 105.76261901855469
Projection step: 11, Loss: 106.33586883544922
Projection step: 12, Loss: 101.38020324707031
Final likelihood: tensor([ -95.3137, -102.5831, -101.3446, -106.0754,  -91.1486, -101.6680,
        -102.7258, -100.4204, -102.5351, -103.3379, -100.7584, -104.8291,
        -101.0139, -103.5623, -102.9601, -101.8067])
Final projection likelihood: -101.3802
1 mode projection succeeded
New goal: tensor([ 0.0661,  0.5480,  0.5319,  0.6722, -0.0584,  0.5371,  0.7115,  0.9811,
         1.4311,  0.1794,  0.0972,  1.0708, -0.0687,  0.0215, -0.5289],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0027]], device='cuda:1') tensor([[0.0027]], device='cuda:1')
Original likelihood: -108.93174743652344
Adjusted likelihood: -108.93174743652344
Likelihood residual: 0.0
Original likelihood: -120.76325225830078
Adjusted likelihood: -120.76325225830078
Likelihood residual: 0.0
{'index': 120.76325225830078, 'thumb_middle': 108.93174743652344}
Current yaw: tensor([-0.0711,  0.0276, -0.3349], device='cuda:1')
15 thumb_middle
tensor([ 0.0519,  0.5321,  0.5325,  0.6819, -0.0864,  0.5667,  0.7334,  0.9648,
         1.4503,  0.1865,  0.0513,  1.0866, -0.0711,  0.0276, -0.3349,  0.9124],
       device='cuda:1')
Solve time for step 1 9.686012428021058
Current ori: tensor([-0.0711,  0.0276, -0.3349], device='cuda:1')
Index force: tensor([0.5624, 0.5650, 0.5759, 0.5000], device='cuda:1')
tensor([ 0.0574,  0.5633,  0.5126,  0.6451, -0.1384,  0.5351,  0.6889,  0.9630,
         1.3816,  0.1579,  0.0139,  1.0378, -0.0814,  0.0343, -0.3349,  0.8427],
       device='cuda:1')
Solve time for step 2 3.7707451850292273
Current ori: tensor([-0.0814,  0.0343, -0.3349], device='cuda:1')
Index force: tensor([0.5002, 0.5738, 0.5880], device='cuda:1')
tensor([ 0.0562,  0.5608,  0.5156,  0.6426, -0.1578,  0.5233,  0.6880,  0.9648,
         1.3889,  0.1572,  0.0199,  1.0421, -0.0808,  0.0423, -0.3349,  0.7517],
       device='cuda:1')
Solve time for step 3 3.5116151419933885
Current ori: tensor([-0.0808,  0.0423, -0.3349], device='cuda:1')
Index force: tensor([0.5661, 0.5803], device='cuda:1')
tensor([ 0.0645,  0.5601,  0.5193,  0.6538, -0.1602,  0.5278,  0.6834,  0.9644,
         1.3877,  0.1525,  0.0220,  1.0460, -0.0798,  0.0364, -0.3349,  0.7658],
       device='cuda:1')
Solve time for step 4 3.405959044001065
Current ori: tensor([-0.0798,  0.0364, -0.3349], device='cuda:1')
Index force: tensor([0.5627], device='cuda:1')
Storing RECOVERY transition: reward=0.0163 (scaled=0.0163), steps=0
Reward stats updated: mean 0.0145 -> 0.0145, std: 0.0915
Collected 562 transitions for RL
SAC Update 1/5: Actor Loss=-0.0075, Q1 Loss=0.7938, Q2 Loss=0.7938, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7806
SAC Update 2/5: Actor Loss=-0.0081, Q1 Loss=0.8486, Q2 Loss=0.8486, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6241
SAC Update 3/5: Actor Loss=-0.0084, Q1 Loss=0.8650, Q2 Loss=0.8650, Entropy=0.6931, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5060
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=0.8227, Q2 Loss=0.8227, Entropy=0.6931, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3506
SAC Update 5/5: Actor Loss=-0.0094, Q1 Loss=0.9756, Q2 Loss=0.9756, Entropy=0.6931, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5668

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (15.3%)
Q1 update: 0.05s (20.1%)
Q2 update: 0.06s (20.4%)
Actor update: 0.11s (40.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008249
Q1 loss: 0.861123
Q2 loss: 0.861123
Current threshold: -149.4942
Global Scale Offset: 5947.2230
Reward stats: mean=0.0145, std=0.0915, count=562
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 0.8611, Q2 Loss: 0.8611, Entropy: 0.6931, Mean TD Error: 0.5656, Threshold: -149.4942
Original likelihood: -137.53131103515625
Adjusted likelihood: -137.53131103515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5008)
State is out of distribution
Projection step: 0, Loss: 138.60975646972656
Projection step: 1, Loss: 129.04945373535156
Projection step: 2, Loss: 134.62030029296875
Projection step: 3, Loss: 133.031494140625
Projection step: 4, Loss: 131.44012451171875
Projection step: 5, Loss: 127.39949035644531
Projection step: 6, Loss: 128.14132690429688
Projection step: 7, Loss: 126.80706787109375
Projection step: 8, Loss: 122.01695251464844
Projection step: 9, Loss: 121.6025161743164
Projection step: 10, Loss: 120.73054504394531
Projection step: 11, Loss: 119.98190307617188
Projection step: 12, Loss: 117.70515441894531
Projection step: 13, Loss: 116.02081298828125
Projection step: 14, Loss: 116.07931518554688
Projection step: 15, Loss: 113.88031005859375
Projection step: 16, Loss: 111.03379821777344
Projection step: 17, Loss: 115.5107421875
Projection step: 18, Loss: 115.50645446777344
Projection step: 19, Loss: 107.18194580078125
Projection step: 20, Loss: 105.96165466308594
Projection step: 21, Loss: 109.58328247070312
Projection step: 22, Loss: 106.42152404785156
Projection step: 23, Loss: 105.16845703125
Projection step: 24, Loss: 106.93890380859375
Final likelihood: tensor([ -96.0481, -115.1573, -103.4725, -113.6871, -110.1669, -108.2968,
        -114.5744,  -97.1883, -115.4848, -109.3034, -104.4159, -110.1677,
        -116.5845, -112.0662, -107.7213,  -96.2343])
Final projection likelihood: -108.1606
1 mode projection succeeded
New goal: tensor([ 0.0522,  0.5662,  0.5025,  0.6619, -0.0571,  0.5157,  0.7195,  0.9681,
         1.4151,  0.1522,  0.1119,  1.0732, -0.0664,  0.0273, -0.6777],
       device='cuda:1')
tensor([[0.0023]], device='cuda:1') tensor([[0.0026]], device='cuda:1') tensor([[0.0029]], device='cuda:1')
Original likelihood: -103.8305892944336
Adjusted likelihood: -103.8305892944336
Likelihood residual: 0.0
Original likelihood: -123.24110412597656
Adjusted likelihood: -123.24110412597656
Likelihood residual: 0.0
{'index': 123.24110412597656, 'thumb_middle': 103.8305892944336}
Current yaw: tensor([-0.0706,  0.0412, -0.3353], device='cuda:1')
16 thumb_middle
tensor([ 0.0389,  0.5300,  0.5251,  0.6791, -0.1058,  0.5639,  0.7158,  0.9788,
         1.4570,  0.1801,  0.0741,  1.0744, -0.0706,  0.0412, -0.3353,  0.8826],
       device='cuda:1')
[1;34mwandb[0m: 🚀 View run [33mallegro_screwdriver_recovery_data_5_10_15_lower_proj_lr_2025-03-17-17-36-52[0m at: [34mhttps://wandb.ai/abhinavk99/ccai-screwdriver/runs/3pq970ps[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250317_173653-3pq970ps/logs[0m
