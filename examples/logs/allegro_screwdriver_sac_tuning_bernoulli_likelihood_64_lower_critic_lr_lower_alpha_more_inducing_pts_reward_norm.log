Importing module 'gym_38' (/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_38.so)
Setting GYM_USD_PLUG_INFO_PATH to /home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json
PyTorch version 2.4.1+cu121
Device count 2
/home/abhinav/Documents/isaacgym/python/isaacgym/_bindings/src/gymtorch
ninja: no work to do.
No ROS install found, continuing
CCAI_PATH /home/abhinav/Documents/ccai
Not connected to PVD
Physics Engine: PhysX
Physics Device: cpu
GPU Pipeline: disabled
Using VHACD cache directory '/home/abhinav/.isaacgym/vhacd'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/base_ns.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/allegro/link_1.0.stl'
Found existing convex decomposition for mesh '/home/abhinav/Documents/github/isaacgym-arm-envs/isaac_victor_envs/assets/xela_models/mesh/ft_c.stl'
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]
[ models/temporal ] Channel dimensions: [(37, 128), (128, 256), (256, 512)]

Trial 1
Loaded trajectory sampler
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:0')
Current yaw: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:0')
1 turn
Sampling time 3.8055595539917704
tensor([ 1.5538e-01,  6.1090e-01,  5.7053e-01,  6.0998e-01, -1.1557e-01,
         5.3958e-01,  8.8539e-01,  9.3525e-01,  1.2574e+00,  2.2958e-01,
         2.3280e-01,  1.2081e+00,  5.5207e-05,  1.3631e-02, -4.8130e-02,
         4.4650e-01], device='cuda:0')
Original likelihood: -19.054738998413086
Adjusted likelihood: -19.054738998413086
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.416501711995807
Current ori: tensor([ 5.5207e-05,  1.3631e-02, -4.8130e-02], device='cuda:0')
Middle force: tensor([0.5791, 0.5709, 1.1438, 0.5580, 1.1024, 0.6482, 0.5358, 0.5249, 0.5829,
        0.5540, 0.5206, 0.5708], device='cuda:0')
Thumb force: tensor([0.8664, 0.8197, 0.7561, 1.0166, 0.9685, 0.6757, 0.5213, 0.5700, 0.5453,
        0.6043, 0.5627, 0.5500], device='cuda:0')
Index force: tensor([0.5978, 0.6008, 0.5560, 0.5699, 0.7921, 0.5254, 1.0088, 0.5495, 0.5799,
        0.6410, 0.5969, 0.5416], device='cuda:0')
Storing NORMAL transition: reward=0.0014 (scaled=0.0014), steps=1
Reward stats updated: mean 0.0000 -> 0.0014, std: 0.0000
Collected 1 transitions for RL
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:0')
Original likelihood: -33.53627395629883
Adjusted likelihood: -33.53627395629883
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0268)
State is out of distribution
Projection step: 0, Loss: 34.35027313232422
Projection step: 1, Loss: 29.099729537963867
Projection step: 2, Loss: 26.991527557373047
Projection step: 3, Loss: 25.764873504638672
Projection step: 4, Loss: 23.53175163269043
Projection step: 5, Loss: 20.392465591430664
Projection step: 6, Loss: 21.663925170898438
Projection step: 7, Loss: 20.9437198638916
Projection step: 8, Loss: 16.31324577331543
Projection step: 9, Loss: 16.232877731323242
Projection step: 10, Loss: 14.254530906677246
Final likelihood: tensor([-13.6021, -12.1652, -16.5882, -16.5739, -11.3720, -15.9999, -17.4104,
        -15.4567, -11.9681, -13.5928, -10.5148, -12.2766, -13.5226, -17.9277,
        -15.1772, -13.9245])
Final projection likelihood: -14.2545
1 mode projection succeeded
New goal: tensor([ 0.1550,  0.6027,  0.5125,  0.5472, -0.0919,  0.4683,  0.8355,  1.0997,
         1.2831,  0.3535,  0.1974,  1.0819,  0.0030,  0.0129, -2.3615],
       device='cuda:0')
tensor([[0.0068]], device='cuda:0') tensor([[0.0077]], device='cuda:0') tensor([[0.0106]], device='cuda:0')
Original likelihood: -24.68484878540039
Adjusted likelihood: -24.68484878540039
Likelihood residual: 0.0
Original likelihood: -20.608436584472656
Adjusted likelihood: -20.608436584472656
Likelihood residual: 0.0
{'index': 20.608436584472656, 'thumb_middle': 24.68484878540039}
Current yaw: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:0')
2 index
tensor([ 0.2647,  0.6666,  0.4227,  0.6614, -0.2022,  0.4756,  0.8889,  1.0473,
         1.2578,  0.2486,  0.2143,  1.1629,  0.0055,  0.0214, -0.0499, -0.7408],
       device='cuda:0')
Solve time for step 1 10.83220951599651
Current ori: tensor([ 0.0055,  0.0214, -0.0499], device='cuda:0')
Middle force: tensor([0.5953, 0.5054, 0.5774, 0.5885], device='cuda:0')
Thumb force: tensor([0.5662, 0.5216, 0.5847, 0.5614], device='cuda:0')
tensor([ 0.2030,  0.5897,  0.4704,  0.5625, -0.1570,  0.5427,  0.8624,  1.0828,
         1.2919,  0.2658,  0.2338,  1.1029, -0.0040,  0.0128, -0.0952, -1.3779],
       device='cuda:0')
Solve time for step 2 2.263983974000439
Current ori: tensor([-0.0040,  0.0128, -0.0952], device='cuda:0')
Middle force: tensor([0.5051, 0.5753, 0.5866], device='cuda:0')
Thumb force: tensor([0.5201, 0.5828, 0.5593], device='cuda:0')
tensor([ 0.1872,  0.5878,  0.4837,  0.5401, -0.1600,  0.5509,  0.8618,  1.0896,
         1.2668,  0.3100,  0.2336,  1.1184, -0.0071,  0.0111, -0.1078, -1.7153],
       device='cuda:0')
Solve time for step 3 2.1545989440055564
Current ori: tensor([-0.0071,  0.0111, -0.1078], device='cuda:0')
Middle force: tensor([0.5745, 0.5836], device='cuda:0')
Thumb force: tensor([0.5760, 0.5566], device='cuda:0')
tensor([ 0.1844,  0.5865,  0.4869,  0.5391, -0.1576,  0.5609,  0.8526,  1.0770,
         1.2854,  0.2875,  0.2168,  1.1192, -0.0136,  0.0108, -0.1061, -1.9042],
       device='cuda:0')
Solve time for step 4 2.168762637011241
Current ori: tensor([-0.0136,  0.0108, -0.1061], device='cuda:0')
Middle force: tensor([0.5095], device='cuda:0')
Thumb force: tensor([0.5553], device='cuda:0')
Storing RECOVERY transition: reward=0.0601 (scaled=0.0601), steps=1
Reward stats updated: mean 0.0014 -> 0.0307, std: 0.0293
Collected 2 transitions for RL
Original likelihood: -21.992385864257812
Adjusted likelihood: -21.992385864257812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0169,  0.0163, -0.1100], device='cuda:0')
3 turn
Sampling time 3.896667830005754
tensor([ 0.1266,  0.6438,  0.5249,  0.5536, -0.1669,  0.5612,  0.8518,  1.0770,
         1.2776,  0.3139,  0.2197,  1.1263, -0.0169,  0.0163, -0.1100, -1.9308],
       device='cuda:0')
Original likelihood: -23.851118087768555
Adjusted likelihood: -23.851118087768555
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Solve time for step 1 14.454189615003997
Current ori: tensor([-0.0169,  0.0163, -0.1100], device='cuda:0')
Middle force: tensor([0.5766, 1.6180, 0.4823, 0.5019, 0.6344, 1.6031, 0.5648, 0.4524, 0.5582,
        0.5204, 0.5518, 0.4698], device='cuda:0')
Thumb force: tensor([0.8519, 0.9159, 0.4726, 1.0005, 0.8920, 1.0886, 0.7136, 0.5522, 1.0186,
        0.8978, 0.6833, 0.6238], device='cuda:0')
Index force: tensor([0.5140, 0.7289, 0.8049, 0.6286, 0.5062, 0.5236, 0.5142, 0.7300, 0.5348,
        0.5370, 0.5066, 0.6514], device='cuda:0')
Storing NORMAL transition: reward=-0.2051 (scaled=-0.2051), steps=1
Reward stats updated: mean 0.0307 -> -0.0479, std: 0.1137
Collected 3 transitions for RL
tensor([ 0.0531,  0.6427,  0.4310,  0.5942, -0.2088,  0.6364,  0.7503,  0.8756,
         1.2620,  0.3524,  0.2354,  1.3030, -0.0132,  0.0612,  0.0929, -2.3134],
       device='cuda:0')
Original likelihood: -29.780637741088867
Adjusted likelihood: -29.780637741088867
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5476)
Solve time for step 2 2.898680462007178
Current ori: tensor([-0.0132,  0.0612,  0.0929], device='cuda:0')
Middle force: tensor([1.6051, 0.5036, 0.5018, 0.6296, 1.5831, 0.5638, 0.4849, 0.5590, 0.5190,
        0.5516, 0.4887], device='cuda:0')
Thumb force: tensor([0.9048, 0.5027, 1.0333, 0.8967, 1.0928, 0.7088, 0.5726, 1.0096, 0.8999,
        0.6854, 0.6438], device='cuda:0')
Index force: tensor([0.7183, 0.8119, 0.6209, 0.5058, 0.5224, 0.5139, 0.7378, 0.5333, 0.5366,
        0.5060, 0.6913], device='cuda:0')
Storing NORMAL transition: reward=-0.0457 (scaled=-0.0457), steps=1
Reward stats updated: mean -0.0479 -> -0.0473, std: 0.0985
Collected 4 transitions for RL
tensor([ 0.0513,  0.6167,  0.4670,  0.5929, -0.2041,  0.6641,  0.7070,  0.8941,
         1.3708,  0.1979,  0.1489,  1.3702, -0.0112,  0.0579,  0.1390, -2.2942],
       device='cuda:0')
Original likelihood: -26.495479583740234
Adjusted likelihood: -26.495479583740234
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9721)
Solve time for step 3 2.8026509849878494
Current ori: tensor([-0.0112,  0.0579,  0.1390], device='cuda:0')
Middle force: tensor([0.5011, 1.3662, 0.6176, 0.5011, 0.5571, 0.5012, 0.5257, 0.5204, 0.5017,
        0.5203], device='cuda:0')
Thumb force: tensor([1.3079, 0.6918, 0.5357, 0.9804, 1.0733, 0.5160, 0.8890, 0.5504, 0.5893,
        0.5592], device='cuda:0')
Index force: tensor([0.7127, 0.7129, 0.5294, 0.6263, 0.6654, 0.5669, 0.5758, 0.5639, 0.6236,
        0.5447], device='cuda:0')
Storing NORMAL transition: reward=0.0476 (scaled=0.0476), steps=1
Reward stats updated: mean -0.0473 -> -0.0283, std: 0.0959
Collected 5 transitions for RL
tensor([ 0.0818,  0.6790,  0.4294,  0.5379, -0.1783,  0.6558,  0.7750,  0.8069,
         1.3751,  0.3092, -0.0069,  1.4187, -0.0286,  0.0404,  0.0920, -2.2432],
       device='cuda:0')
Original likelihood: -28.059471130371094
Adjusted likelihood: -28.059471130371094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8552)
Solve time for step 4 2.6852187649928965
Current ori: tensor([-0.0286,  0.0404,  0.0920], device='cuda:0')
Middle force: tensor([1.3420, 0.6167, 0.5010, 0.5471, 0.5011, 0.5245, 0.5188, 0.5016, 0.5196],
       device='cuda:0')
Thumb force: tensor([0.6787, 0.5332, 0.9781, 1.0938, 0.5159, 0.8814, 0.5483, 0.5838, 0.5570],
       device='cuda:0')
Index force: tensor([0.7082, 0.5286, 0.6177, 0.6481, 0.5628, 0.5723, 0.5619, 0.6192, 0.5424],
       device='cuda:0')
Storing NORMAL transition: reward=-0.1036 (scaled=-0.1036), steps=1
Reward stats updated: mean -0.0283 -> -0.0409, std: 0.0920
Collected 6 transitions for RL
tensor([ 0.0242,  0.5968,  0.5211,  0.4808, -0.1719,  0.6805,  0.7520,  0.7642,
         1.3128,  0.3197,  0.0164,  1.4084, -0.0207,  0.0405,  0.1960, -2.1189],
       device='cuda:0')
Original likelihood: -26.177181243896484
Adjusted likelihood: -26.177181243896484
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9815)
Solve time for step 5 2.519443044991931
Current ori: tensor([-0.0207,  0.0405,  0.1960], device='cuda:0')
Middle force: tensor([0.6128, 0.5015, 0.5465, 0.5013, 0.5244, 0.5177, 0.5025, 0.5193],
       device='cuda:0')
Thumb force: tensor([0.5306, 0.9494, 1.0676, 0.5129, 0.8659, 0.5452, 0.5664, 0.5540],
       device='cuda:0')
Index force: tensor([0.5289, 0.6098, 0.6453, 0.5644, 0.5710, 0.5593, 0.6160, 0.5399],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0058 (scaled=-0.0058), steps=1
Reward stats updated: mean -0.0409 -> -0.0359, std: 0.0860
Collected 7 transitions for RL
tensor([ 0.0414,  0.5761,  0.5532,  0.5209, -0.1600,  0.6838,  0.7402,  0.8083,
         1.3211,  0.3582,  0.0499,  1.3811, -0.0134,  0.0301,  0.2024, -2.0903],
       device='cuda:0')
Original likelihood: -23.7495174407959
Adjusted likelihood: -23.7495174407959
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 6 2.363957580004353
Current ori: tensor([-0.0134,  0.0301,  0.2024], device='cuda:0')
Middle force: tensor([0.5019, 0.5451, 0.5012, 0.5237, 0.5165, 0.5027, 0.5187],
       device='cuda:0')
Thumb force: tensor([0.9333, 1.0537, 0.5113, 0.8536, 0.5422, 0.5573, 0.5513],
       device='cuda:0')
Index force: tensor([0.6005, 0.6379, 0.5637, 0.5696, 0.5568, 0.6107, 0.5374],
       device='cuda:0')
Storing NORMAL transition: reward=0.0409 (scaled=0.0409), steps=1
Reward stats updated: mean -0.0359 -> -0.0263, std: 0.0844
Collected 8 transitions for RL
tensor([ 0.0480,  0.5569,  0.5696,  0.5525, -0.1600,  0.6683,  0.7465,  0.8564,
         1.3127,  0.3703,  0.0540,  1.3815, -0.0067,  0.0272,  0.1617, -2.0292],
       device='cuda:0')
Original likelihood: -23.88544464111328
Adjusted likelihood: -23.88544464111328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Solve time for step 7 2.318713426007889
Current ori: tensor([-0.0067,  0.0272,  0.1617], device='cuda:0')
Middle force: tensor([0.5429, 0.5011, 0.5229, 0.5156, 0.5026, 0.5181], device='cuda:0')
Thumb force: tensor([1.0359, 0.5103, 0.8436, 0.5397, 0.5524, 0.5491], device='cuda:0')
Index force: tensor([0.6319, 0.5628, 0.5681, 0.5548, 0.6067, 0.5354], device='cuda:0')
Storing NORMAL transition: reward=-0.1585 (scaled=-0.1585), steps=1
Reward stats updated: mean -0.0263 -> -0.0410, std: 0.0897
Collected 9 transitions for RL
tensor([ 0.1991,  0.5769,  0.6234,  0.5341, -0.0935,  0.7580,  0.7014,  0.7967,
         1.2064,  0.3389,  0.1221,  1.3939, -0.0031, -0.0183,  0.3205, -2.1595],
       device='cuda:0')
Original likelihood: -31.000213623046875
Adjusted likelihood: -31.000213623046875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2926)
State is out of distribution
Projection step: 0, Loss: 35.52392578125
Projection step: 1, Loss: 29.126785278320312
Projection step: 2, Loss: 26.142414093017578
Projection step: 3, Loss: 23.416976928710938
Projection step: 4, Loss: 22.171537399291992
Projection step: 5, Loss: 20.710323333740234
Projection step: 6, Loss: 21.335369110107422
Projection step: 7, Loss: 20.31352996826172
Projection step: 8, Loss: 19.777320861816406
Projection step: 9, Loss: 18.835254669189453
Projection step: 10, Loss: 18.370197296142578
Projection step: 11, Loss: 17.597644805908203
Projection step: 12, Loss: 17.878406524658203
Projection step: 13, Loss: 16.799510955810547
Projection step: 14, Loss: 16.774377822875977
Final likelihood: tensor([-18.4553, -18.4061, -15.6097, -16.7064, -17.6584, -14.7682, -13.5852,
        -16.5680, -15.5684, -17.1999, -16.3317, -13.8696, -15.2620, -15.9498,
        -16.7709, -17.8919])
Final projection likelihood: -16.2876
1 mode projection succeeded
New goal: tensor([ 0.1159,  0.5335,  0.5869,  0.7222, -0.0532,  0.6187,  0.8711,  0.7597,
         1.3338,  0.2787,  0.1597,  1.1391, -0.0039, -0.0127, -2.8919],
       device='cuda:0')
tensor([[0.0030]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0069]], device='cuda:0')
Original likelihood: -21.183692932128906
Adjusted likelihood: -21.183692932128906
Likelihood residual: 0.0
{'index': 21.183692932128906, 'thumb_middle': inf}
Current yaw: tensor([-0.0031, -0.0183,  0.3205], device='cuda:0')
4 index
tensor([ 0.1991,  0.5769,  0.6234,  0.5341, -0.0935,  0.7580,  0.7014,  0.7967,
         1.2064,  0.3389,  0.1221,  1.3939, -0.0031, -0.0183,  0.3205, -2.1595],
       device='cuda:0')
Solve time for step 1 10.340100761008216
Current ori: tensor([-0.0031, -0.0183,  0.3205], device='cuda:0')
Middle force: tensor([0.5665, 0.5263, 0.5031, 0.5942], device='cuda:0')
Thumb force: tensor([0.5895, 0.5103, 0.5320, 0.5723], device='cuda:0')
tensor([ 0.1943,  0.4998,  0.5557,  0.6569, -0.1094,  0.7142,  0.7996,  0.7154,
         1.2481,  0.2951,  0.1068,  1.3612, -0.0129, -0.0124,  0.2799, -2.1750],
       device='cuda:0')
Solve time for step 2 2.3318745479919016
Current ori: tensor([-0.0129, -0.0124,  0.2799], device='cuda:0')
Middle force: tensor([0.5248, 0.5027, 0.5926], device='cuda:0')
Thumb force: tensor([0.5101, 0.5317, 0.5703], device='cuda:0')
tensor([ 1.8028e-01,  4.9755e-01,  5.4621e-01,  6.8424e-01, -1.2297e-01,
         7.0100e-01,  8.1502e-01,  6.9786e-01,  1.2677e+00,  2.7618e-01,
         1.1838e-01,  1.3414e+00, -1.3328e-02, -1.9251e-03,  2.7527e-01,
        -2.2832e+00], device='cuda:0')
Solve time for step 3 2.1877518160035834
Current ori: tensor([-0.0133, -0.0019,  0.2753], device='cuda:0')
Middle force: tensor([0.5026, 0.5911], device='cuda:0')
Thumb force: tensor([0.5290, 0.5682], device='cuda:0')
tensor([ 0.1783,  0.4990,  0.5457,  0.6912, -0.1329,  0.6927,  0.8172,  0.7003,
         1.2821,  0.2635,  0.1263,  1.3262, -0.0134,  0.0056,  0.2640, -2.3888],
       device='cuda:0')
Solve time for step 4 2.1286246710224077
Current ori: tensor([-0.0134,  0.0056,  0.2640], device='cuda:0')
Middle force: tensor([0.5759], device='cuda:0')
Thumb force: tensor([0.5196], device='cuda:0')
Storing RECOVERY transition: reward=0.0481 (scaled=0.0069), steps=7
Reward stats updated: mean -0.0410 -> -0.0362, std: 0.0863
Collected 10 transitions for RL
Original likelihood: -22.01620101928711
Adjusted likelihood: -22.01620101928711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0135,  0.0194,  0.2723], device='cuda:0')
5 turn
Sampling time 3.7316361029807013
tensor([ 0.1183,  0.5391,  0.5778,  0.7156, -0.1496,  0.6874,  0.8142,  0.6910,
         1.2930,  0.2596,  0.1520,  1.3006, -0.0135,  0.0194,  0.2723, -2.4226],
       device='cuda:0')
Original likelihood: -22.31058120727539
Adjusted likelihood: -22.31058120727539
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.617713622021256
Current ori: tensor([-0.0135,  0.0194,  0.2723], device='cuda:0')
Middle force: tensor([0.6030, 0.7303, 0.5324, 1.4093, 0.5455, 0.4934, 0.6891, 0.5719, 0.5715,
        0.5561, 0.5558, 0.6680], device='cuda:0')
Thumb force: tensor([1.4954, 0.7123, 2.0914, 1.0585, 1.9118, 0.5040, 0.8769, 0.5418, 0.5933,
        0.5731, 1.2373, 0.7958], device='cuda:0')
Index force: tensor([0.8616, 0.7466, 0.5504, 0.8398, 0.6901, 0.7831, 0.5414, 0.5688, 0.5643,
        0.6050, 0.5286, 0.7967], device='cuda:0')
Storing NORMAL transition: reward=0.3044 (scaled=0.3044), steps=1
Reward stats updated: mean -0.0362 -> -0.0052, std: 0.1279
Collected 11 transitions for RL
tensor([ 0.1216,  0.4152,  0.6641,  0.8855, -0.1795,  0.6526,  0.7429,  0.9006,
         1.3715,  0.2855,  0.2025,  1.0510,  0.0185,  0.0398, -0.0359, -1.7017],
       device='cuda:0')
Original likelihood: -31.882400512695312
Adjusted likelihood: -31.882400512695312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1522)
State is out of distribution
Projection step: 0, Loss: 33.29016876220703
Projection step: 1, Loss: 29.202922821044922
Projection step: 2, Loss: 27.397478103637695
Projection step: 3, Loss: 25.352310180664062
Projection step: 4, Loss: 22.942584991455078
Projection step: 5, Loss: 21.508224487304688
Projection step: 6, Loss: 19.680763244628906
Projection step: 7, Loss: 18.449111938476562
Projection step: 8, Loss: 16.830270767211914
Projection step: 9, Loss: 14.95635986328125
Final likelihood: tensor([-19.1046, -11.7217, -18.7686, -13.1144, -14.9511, -14.6365, -16.3630,
        -14.8889, -16.8411, -14.8564, -14.0073, -15.9622, -11.8625, -14.8613,
        -13.1464, -14.2157])
Final projection likelihood: -14.9564
1 mode projection succeeded
New goal: tensor([ 0.0931,  0.5059,  0.6003,  0.6848, -0.0987,  0.5764,  0.8784,  0.8334,
         1.3408,  0.3335,  0.2076,  1.1322,  0.0144,  0.0203, -0.4613],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0024]], device='cuda:0')
Original likelihood: -22.29737091064453
Adjusted likelihood: -22.29737091064453
Likelihood residual: 0.0
Original likelihood: -20.38369369506836
Adjusted likelihood: -20.38369369506836
Likelihood residual: 0.0
{'index': 20.38369369506836, 'thumb_middle': 22.29737091064453}
Current yaw: tensor([ 0.0185,  0.0398, -0.0359], device='cuda:0')
6 index
tensor([ 0.1216,  0.4152,  0.6641,  0.8855, -0.1795,  0.6526,  0.7429,  0.9006,
         1.3715,  0.2855,  0.2025,  1.0510,  0.0185,  0.0398, -0.0359, -1.7017],
       device='cuda:0')
Solve time for step 1 10.13478981499793
Current ori: tensor([ 0.0185,  0.0398, -0.0359], device='cuda:0')
Middle force: tensor([0.5058, 0.5705, 0.5862, 0.5657], device='cuda:0')
Thumb force: tensor([0.5961, 0.6078, 0.5416, 0.5972], device='cuda:0')
tensor([ 0.1427,  0.4419,  0.5708,  0.6994, -0.1654,  0.6053,  0.8518,  0.8423,
         1.3499,  0.3167,  0.1821,  1.0892,  0.0263,  0.0266, -0.0614, -5.6103],
       device='cuda:0')
Solve time for step 2 2.238814311014721
Current ori: tensor([ 0.0263,  0.0266, -0.0614], device='cuda:0')
Middle force: tensor([0.5814, 0.5784, 0.5679], device='cuda:0')
Thumb force: tensor([0.5187, 0.5455, 0.6025], device='cuda:0')
tensor([ 0.1412,  0.4640,  0.5670,  0.6697, -0.1719,  0.6029,  0.8709,  0.8287,
         1.3541,  0.3093,  0.1790,  1.0980,  0.0300,  0.0273, -0.0620,  4.4607],
       device='cuda:0')
Solve time for step 3 2.0307526830001734
Current ori: tensor([ 0.0300,  0.0273, -0.0620], device='cuda:0')
Middle force: tensor([0.5660, 0.5150], device='cuda:0')
Thumb force: tensor([0.5847, 0.5735], device='cuda:0')
tensor([ 0.1374,  0.4683,  0.5640,  0.6635, -0.1563,  0.6232,  0.8588,  0.7971,
         1.3519,  0.3195,  0.1709,  1.0726,  0.0177,  0.0193, -0.0840,  3.1132],
       device='cuda:0')
Solve time for step 4 2.0871280349965673
Current ori: tensor([ 0.0177,  0.0193, -0.0840], device='cuda:0')
Middle force: tensor([0.5336], device='cuda:0')
Thumb force: tensor([0.5933], device='cuda:0')
Storing RECOVERY transition: reward=0.0545 (scaled=0.0545), steps=1
Reward stats updated: mean -0.0052 -> -0.0003, std: 0.1236
Collected 12 transitions for RL
Original likelihood: -20.124542236328125
Adjusted likelihood: -20.124542236328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0189,  0.0249, -0.0890], device='cuda:0')
7 turn
Sampling time 3.675093148020096
tensor([ 0.0860,  0.5140,  0.5968,  0.6852, -0.1680,  0.6197,  0.8611,  0.8032,
         1.3586,  0.3245,  0.1596,  1.0921,  0.0189,  0.0249, -0.0890,  2.8804],
       device='cuda:0')
Original likelihood: -23.426551818847656
Adjusted likelihood: -23.426551818847656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9998)
Solve time for step 1 14.468004973983625
Current ori: tensor([ 0.0189,  0.0249, -0.0890], device='cuda:0')
Middle force: tensor([1.3603, 0.5033, 0.5007, 0.5271, 0.5672, 0.5826, 1.0730, 0.8320, 0.7581,
        0.5876, 0.5079, 0.9225], device='cuda:0')
Thumb force: tensor([1.9527, 1.9718, 1.4212, 0.5584, 1.1142, 0.8144, 1.4608, 0.5709, 0.7551,
        0.7090, 0.6567, 0.5400], device='cuda:0')
Index force: tensor([0.5582, 0.8321, 0.8389, 0.6255, 0.5626, 0.5485, 0.5861, 0.5189, 0.5722,
        0.5714, 0.6773, 0.6102], device='cuda:0')
Storing NORMAL transition: reward=-0.1919 (scaled=-0.1919), steps=1
Reward stats updated: mean -0.0003 -> -0.0150, std: 0.1292
Collected 13 transitions for RL
tensor([ 0.0531,  0.5415,  0.5500,  0.6456, -0.1636,  0.7465,  0.6566,  0.7881,
         1.3620,  0.4040,  0.0865,  1.2152,  0.0094,  0.0401,  0.1026,  2.6532],
       device='cuda:0')
Original likelihood: -31.92347526550293
Adjusted likelihood: -31.92347526550293
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1470)
State is out of distribution
Projection step: 0, Loss: 29.08354377746582
Projection step: 1, Loss: 29.487548828125
Projection step: 2, Loss: 27.09225845336914
Projection step: 3, Loss: 26.403461456298828
Projection step: 4, Loss: 24.293298721313477
Projection step: 5, Loss: 24.835206985473633
Projection step: 6, Loss: 23.694494247436523
Projection step: 7, Loss: 22.399494171142578
Projection step: 8, Loss: 21.720458984375
Projection step: 9, Loss: 20.088430404663086
Projection step: 10, Loss: 19.37499237060547
Projection step: 11, Loss: 16.89690589904785
Projection step: 12, Loss: 16.281957626342773
Projection step: 13, Loss: 15.534308433532715
Projection step: 14, Loss: 12.305910110473633
Final likelihood: tensor([-11.5119, -14.3234, -14.1426,  -8.4898, -13.7858, -14.8640,  -8.7311,
        -12.7362, -14.2625, -13.6687, -14.1317, -14.3333, -11.5608,  -9.5134,
        -11.9604,  -8.8791])
Final projection likelihood: -12.3059
1 mode projection succeeded
New goal: tensor([ 0.0778,  0.5747,  0.5217,  0.6605, -0.0674,  0.5723,  0.8017,  0.8192,
         1.2950,  0.3794,  0.1826,  1.1746,  0.0090,  0.0144, -1.3006],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0023]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -16.832542419433594
Adjusted likelihood: -16.832542419433594
Likelihood residual: 0.0
Original likelihood: -24.100582122802734
Adjusted likelihood: -24.100582122802734
Likelihood residual: 0.0
{'index': 24.100582122802734, 'thumb_middle': 16.832542419433594}
Current yaw: tensor([0.0094, 0.0401, 0.1026], device='cuda:0')
8 thumb_middle
tensor([ 0.0531,  0.5415,  0.5500,  0.6456, -0.1636,  0.7465,  0.6566,  0.7881,
         1.3620,  0.4040,  0.0865,  1.2152,  0.0094,  0.0401,  0.1026,  2.6532],
       device='cuda:0')
Solve time for step 1 8.658735720993718
Current ori: tensor([0.0094, 0.0401, 0.1026], device='cuda:0')
Index force: tensor([0.5565, 0.5913, 0.5773, 0.5030], device='cuda:0')
tensor([ 0.0491,  0.5521,  0.5134,  0.6764, -0.1997,  0.5883,  0.7203,  0.7669,
         1.2890,  0.3774,  0.0792,  1.1584,  0.0104,  0.0453,  0.1027,  2.6014],
       device='cuda:0')
Solve time for step 2 1.9455825040058699
Current ori: tensor([0.0104, 0.0453, 0.1027], device='cuda:0')
Index force: tensor([0.5522, 0.5698, 0.5924], device='cuda:0')
tensor([ 0.0600,  0.5657,  0.5145,  0.6576, -0.1979,  0.5748,  0.7496,  0.7808,
         1.2868,  0.3705,  0.0800,  1.1401,  0.0053,  0.0389,  0.1027,  2.6113],
       device='cuda:0')
Solve time for step 3 1.8728360139939468
Current ori: tensor([0.0053, 0.0389, 0.1027], device='cuda:0')
Index force: tensor([0.5674, 0.5910], device='cuda:0')
tensor([ 7.0804e-02,  5.8047e-01,  5.1298e-01,  6.4073e-01, -1.9381e-01,
         5.6906e-01,  7.6007e-01,  7.8965e-01,  1.2827e+00,  3.7299e-01,
         7.6043e-02,  1.1321e+00,  2.8761e-04,  3.2336e-02,  1.0266e-01,
         2.6217e+00], device='cuda:0')
Solve time for step 4 1.851748523011338
Current ori: tensor([0.0003, 0.0323, 0.1027], device='cuda:0')
Index force: tensor([0.5872], device='cuda:0')
Storing RECOVERY transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean -0.0150 -> -0.0138, std: 0.1246
Collected 14 transitions for RL
Original likelihood: -27.937313079833984
Adjusted likelihood: -27.937313079833984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8698)
Current yaw: tensor([0.0022, 0.0336, 0.1012], device='cuda:0')
9 turn
Sampling time 3.8051125779747963
tensor([ 6.7691e-02,  5.7696e-01,  5.1090e-01,  6.4867e-01, -1.4072e-01,
         6.0653e-01,  7.9408e-01,  8.0808e-01,  1.3452e+00,  3.8419e-01,
         1.2600e-01,  1.1607e+00,  2.1745e-03,  3.3559e-02,  1.0122e-01,
         2.6350e+00], device='cuda:0')
Original likelihood: -24.83979034423828
Adjusted likelihood: -24.83979034423828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9976)
Solve time for step 1 14.170627700019395
Current ori: tensor([0.0022, 0.0336, 0.1012], device='cuda:0')
Middle force: tensor([0.5283, 0.6836, 0.5542, 0.5026, 0.7640, 1.0305, 0.5774, 0.5660, 0.5178,
        0.5577, 0.5866, 0.6035], device='cuda:0')
Thumb force: tensor([0.8484, 0.6137, 1.4841, 2.2584, 0.8369, 1.6676, 0.5916, 0.6607, 0.5342,
        1.5291, 0.5933, 0.5880], device='cuda:0')
Index force: tensor([0.5108, 0.8397, 0.5905, 0.5968, 0.5821, 0.5797, 0.5823, 0.5261, 0.4956,
        0.7944, 0.5868, 0.5969], device='cuda:0')
Storing NORMAL transition: reward=0.0021 (scaled=0.0021), steps=1
Reward stats updated: mean -0.0138 -> -0.0127, std: 0.1205
Collected 15 transitions for RL
tensor([ 0.0132,  0.6033,  0.4668,  0.5644, -0.1713,  0.6625,  0.6282,  0.8813,
         1.3947,  0.3989,  0.1001,  1.1489, -0.0088,  0.0634,  0.0963,  2.5226],
       device='cuda:0')
Original likelihood: -32.314239501953125
Adjusted likelihood: -32.314239501953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1033)
State is out of distribution
Projection step: 0, Loss: 32.673744201660156
Projection step: 1, Loss: 30.421112060546875
Projection step: 2, Loss: 30.440046310424805
Projection step: 3, Loss: 28.80477523803711
Projection step: 4, Loss: 28.069440841674805
Projection step: 5, Loss: 27.613283157348633
Projection step: 6, Loss: 25.628707885742188
Projection step: 7, Loss: 25.672225952148438
Projection step: 8, Loss: 24.21630096435547
Projection step: 9, Loss: 23.39441680908203
Projection step: 10, Loss: 23.003293991088867
Projection step: 11, Loss: 22.255292892456055
Projection step: 12, Loss: 21.658275604248047
Projection step: 13, Loss: 19.096372604370117
Projection step: 14, Loss: 20.302265167236328
Final likelihood: tensor([-19.8989, -19.9601, -20.0753, -20.1345, -18.6436, -19.7866, -20.1526,
        -19.3690, -20.6838, -16.3043, -19.3251, -16.7188, -20.0481, -20.1370,
        -20.0514, -19.3997])
Final projection likelihood: -19.4180
1 mode projection succeeded
New goal: tensor([ 0.0405,  0.5986,  0.4843,  0.6164, -0.0834,  0.6340,  0.5558,  0.9328,
         1.3476,  0.2371,  0.1370,  1.1398, -0.0262,  0.0387, -0.9335],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0029]], device='cuda:0') tensor([[0.0023]], device='cuda:0')
Original likelihood: -24.99622917175293
Adjusted likelihood: -24.99622917175293
Likelihood residual: 0.0
Original likelihood: -26.771387100219727
Adjusted likelihood: -26.771387100219727
Likelihood residual: 0.0
{'index': 26.771387100219727, 'thumb_middle': 24.99622917175293}
Current yaw: tensor([-0.0088,  0.0634,  0.0963], device='cuda:0')
10 thumb_middle
tensor([ 0.0132,  0.6033,  0.4668,  0.5644, -0.1713,  0.6625,  0.6282,  0.8813,
         1.3947,  0.3989,  0.1001,  1.1489, -0.0088,  0.0634,  0.0963,  2.5226],
       device='cuda:0')
Solve time for step 1 9.05997992499033
Current ori: tensor([-0.0088,  0.0634,  0.0963], device='cuda:0')
Index force: tensor([0.5616, 0.6118, 0.5761, 0.5948], device='cuda:0')
tensor([ 0.0066,  0.6028,  0.4591,  0.5673, -0.2032,  0.6310,  0.5472,  0.9027,
         1.3471,  0.2611,  0.0904,  1.1268, -0.0080,  0.0673,  0.0963,  2.5142],
       device='cuda:0')
Solve time for step 2 2.068963405996328
Current ori: tensor([-0.0080,  0.0673,  0.0963], device='cuda:0')
Index force: tensor([0.6063, 0.5724, 0.5901], device='cuda:0')
tensor([ 0.0216,  0.6149,  0.4428,  0.5927, -0.1947,  0.6387,  0.5512,  0.9141,
         1.3499,  0.2348,  0.0829,  1.1206, -0.0094,  0.0588,  0.0963,  2.5385],
       device='cuda:0')
Solve time for step 3 1.8226217810006347
Current ori: tensor([-0.0094,  0.0588,  0.0963], device='cuda:0')
Index force: tensor([0.5800, 0.5870], device='cuda:0')
tensor([ 0.0365,  0.6088,  0.4622,  0.5985, -0.1970,  0.6528,  0.5547,  0.9077,
         1.3512,  0.2307,  0.0696,  1.1173, -0.0084,  0.0506,  0.0963,  2.5619],
       device='cuda:0')
Solve time for step 4 1.7466555870196316
Current ori: tensor([-0.0084,  0.0506,  0.0963], device='cuda:0')
Index force: tensor([0.5773], device='cuda:0')
Storing RECOVERY transition: reward=0.0053 (scaled=0.0053), steps=1
Reward stats updated: mean -0.0127 -> -0.0116, std: 0.1167
Collected 16 transitions for RL
Original likelihood: -28.24967384338379
Adjusted likelihood: -28.24967384338379
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8302)
Current yaw: tensor([-0.0084,  0.0420,  0.0931], device='cuda:0')
11 turn
Sampling time 3.6709838160022628
tensor([ 0.0504,  0.6092,  0.4730,  0.6022, -0.1238,  0.6880,  0.5694,  0.9237,
         1.4108,  0.2519,  0.1114,  1.1358, -0.0084,  0.0420,  0.0931,  2.6011],
       device='cuda:0')
Original likelihood: -28.148941040039062
Adjusted likelihood: -28.148941040039062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8438)
Solve time for step 1 14.838076852000086
Current ori: tensor([-0.0084,  0.0420,  0.0931], device='cuda:0')
Middle force: tensor([0.5114, 0.6541, 0.5514, 0.5061, 0.7034, 0.9382, 0.5547, 0.5368, 0.5913,
        0.5262, 0.5574, 0.5671], device='cuda:0')
Thumb force: tensor([0.8811, 0.6066, 1.3405, 2.0232, 0.7565, 1.5050, 0.5864, 0.7024, 0.5295,
        1.3352, 0.5413, 0.5845], device='cuda:0')
Index force: tensor([0.5487, 0.8731, 0.6029, 0.5603, 0.5767, 0.5770, 0.5675, 0.5116, 0.4967,
        0.7446, 0.6881, 0.5436], device='cuda:0')
Storing NORMAL transition: reward=-0.0220 (scaled=-0.0220), steps=1
Reward stats updated: mean -0.0116 -> -0.0122, std: 0.1133
Collected 17 transitions for RL
tensor([ 0.1100,  0.6591,  0.4970,  0.5154, -0.0229,  0.7700,  0.5993,  0.8228,
         1.2337,  0.4053, -0.0581,  1.0838, -0.0252, -0.0347,  0.1151,  3.0419],
       device='cuda:0')
Original likelihood: -28.624679565429688
Adjusted likelihood: -28.624679565429688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7735)
Solve time for step 2 2.8940710540045984
Current ori: tensor([-0.0252, -0.0347,  0.1151], device='cuda:0')
Middle force: tensor([0.7118, 0.5584, 0.5044, 0.7451, 1.0065, 0.5911, 0.5443, 0.5889, 0.5755,
        0.5060, 0.6519], device='cuda:0')
Thumb force: tensor([0.5956, 1.5223, 2.3296, 0.8167, 1.7375, 0.5741, 0.7089, 0.5428, 1.4560,
        0.5981, 0.5420], device='cuda:0')
Index force: tensor([0.8681, 0.5911, 0.5870, 0.5808, 0.5847, 0.5732, 0.5001, 0.5018, 0.7164,
        0.6247, 0.5803], device='cuda:0')
Storing NORMAL transition: reward=-0.0088 (scaled=-0.0088), steps=1
Reward stats updated: mean -0.0122 -> -0.0120, std: 0.1101
Collected 18 transitions for RL
tensor([ 0.1149,  0.6184,  0.5352,  0.4892, -0.0610,  0.7534,  0.6622,  0.8121,
         1.1946,  0.4216,  0.0794,  1.0806, -0.0621, -0.0877,  0.1151,  2.7580],
       device='cuda:0')
Original likelihood: -34.54179763793945
Adjusted likelihood: -34.54179763793945
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0066)
State is out of distribution
Projection step: 0, Loss: 33.82936096191406
Projection step: 1, Loss: 32.72820281982422
Projection step: 2, Loss: 31.112857818603516
Projection step: 3, Loss: 29.922954559326172
Projection step: 4, Loss: 28.045772552490234
Projection step: 5, Loss: 26.607070922851562
Projection step: 6, Loss: 25.566865921020508
Projection step: 7, Loss: 25.01058578491211
Projection step: 8, Loss: 24.41122817993164
Projection step: 9, Loss: 23.74388313293457
Projection step: 10, Loss: 23.073204040527344
Projection step: 11, Loss: 22.608051300048828
Projection step: 12, Loss: 22.107311248779297
Projection step: 13, Loss: 21.58841323852539
Projection step: 14, Loss: 20.974794387817383
Final likelihood: tensor([-20.9284, -20.2799, -20.4779, -20.6876, -20.7360, -20.1354, -20.5391,
        -20.3625, -20.2379, -21.2532, -20.1562, -20.6910, -20.5410, -20.4790,
        -20.2795, -20.7378])
Final projection likelihood: -20.5326
1 mode projection succeeded
New goal: tensor([ 1.3664e-01,  5.5801e-01,  5.8945e-01,  6.0697e-01, -8.0045e-04,
         6.7699e-01,  8.0054e-01,  8.4695e-01,  1.2845e+00,  3.3348e-01,
         5.8888e-02,  1.1283e+00, -4.9348e-02, -6.7273e-02, -5.4648e-01],
       device='cuda:0')
tensor([[0.0055]], device='cuda:0') tensor([[0.0114]], device='cuda:0') tensor([[0.0045]], device='cuda:0')
Original likelihood: -22.091232299804688
Adjusted likelihood: -22.091232299804688
Likelihood residual: 0.0
Original likelihood: -21.368125915527344
Adjusted likelihood: -21.368125915527344
Likelihood residual: 0.0
{'index': 21.368125915527344, 'thumb_middle': 22.091232299804688}
Current yaw: tensor([-0.0621, -0.0877,  0.1151], device='cuda:0')
12 index
tensor([ 0.1149,  0.6184,  0.5352,  0.4892, -0.0610,  0.7534,  0.6622,  0.8121,
         1.1946,  0.4216,  0.0794,  1.0806, -0.0621, -0.0877,  0.1151,  2.7580],
       device='cuda:0')
Solve time for step 1 10.456735663989093
Current ori: tensor([-0.0621, -0.0877,  0.1151], device='cuda:0')
Middle force: tensor([0.6015, 0.5923, 0.5340, 0.5929], device='cuda:0')
Thumb force: tensor([0.5988, 0.5797, 0.5197, 0.5855], device='cuda:0')
tensor([ 0.1685,  0.5231,  0.5398,  0.5576, -0.0466,  0.7490,  0.7833,  0.8326,
         1.2749,  0.3035,  0.0639,  1.1022, -0.0596, -0.0731,  0.1072,  2.5869],
       device='cuda:0')
Solve time for step 2 2.2730142210202757
Current ori: tensor([-0.0596, -0.0731,  0.1072], device='cuda:0')
Middle force: tensor([0.5899, 0.5327, 0.5910], device='cuda:0')
Thumb force: tensor([0.5749, 0.5186, 0.5827], device='cuda:0')
tensor([ 0.1705,  0.5232,  0.5491,  0.5766, -0.0558,  0.7492,  0.8037,  0.8344,
         1.2805,  0.2954,  0.0540,  1.1023, -0.0673, -0.0750,  0.1204,  2.4942],
       device='cuda:0')
Solve time for step 3 2.228205869992962
Current ori: tensor([-0.0673, -0.0750,  0.1204], device='cuda:0')
Middle force: tensor([0.5323, 0.5896], device='cuda:0')
Thumb force: tensor([0.5175, 0.5807], device='cuda:0')
tensor([ 0.1687,  0.5287,  0.5522,  0.5811, -0.0438,  0.7589,  0.8038,  0.8306,
         1.2710,  0.3097,  0.0425,  1.1008, -0.0710, -0.0856,  0.1025,  2.5279],
       device='cuda:0')
Solve time for step 4 2.0781739320082124
Current ori: tensor([-0.0710, -0.0856,  0.1025], device='cuda:0')
Middle force: tensor([0.5294], device='cuda:0')
Thumb force: tensor([0.5306], device='cuda:0')
Storing RECOVERY transition: reward=-0.0009 (scaled=-0.0005), steps=2
Reward stats updated: mean -0.0120 -> -0.0114, std: 0.1072
Collected 19 transitions for RL
Original likelihood: -34.56585693359375
Adjusted likelihood: -34.56585693359375
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0064)
State is out of distribution
Projection step: 0, Loss: 34.80281066894531
Projection step: 1, Loss: 32.551795959472656
Projection step: 2, Loss: 31.782337188720703
Projection step: 3, Loss: 30.86007308959961
Projection step: 4, Loss: 30.225866317749023
Projection step: 5, Loss: 29.730051040649414
Projection step: 6, Loss: 29.051525115966797
Projection step: 7, Loss: 28.636215209960938
Projection step: 8, Loss: 27.996158599853516
Projection step: 9, Loss: 28.740768432617188
Projection step: 10, Loss: 27.864225387573242
Projection step: 11, Loss: 29.53515625
Projection step: 12, Loss: 27.025184631347656
Projection step: 13, Loss: 28.52665901184082
Projection step: 14, Loss: 27.178550720214844
Final likelihood: tensor([-25.2896, -25.2414, -31.1858, -24.1683, -25.5640, -24.9463, -33.0221,
        -25.7783, -25.1630, -25.0729, -29.3417, -25.1305, -25.4193, -25.0959,
        -28.8517, -25.5639])
Final projection likelihood: -26.5522
1 mode projection succeeded
New goal: tensor([ 0.1698,  0.4804,  0.6784,  0.7106,  0.0020,  0.7095,  0.8277,  0.7841,
         1.3190,  0.2600,  0.0208,  1.0346, -0.0830, -0.0767, -0.0686],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0020]], device='cuda:0')
Original likelihood: -30.09099006652832
Adjusted likelihood: -30.09099006652832
Likelihood residual: 0.0
Original likelihood: -34.08270263671875
Adjusted likelihood: -34.08270263671875
Likelihood residual: 0.0
{'index': 34.08270263671875, 'thumb_middle': 30.09099006652832}
Current yaw: tensor([-0.0891, -0.0974,  0.1107], device='cuda:0')
13 thumb_middle
tensor([ 0.1244,  0.5827,  0.5912,  0.6057, -0.0492,  0.7727,  0.8244,  0.8422,
         1.2824,  0.2930,  0.0094,  1.0983, -0.0891, -0.0974,  0.1107,  2.6404],
       device='cuda:0')
Solve time for step 1 8.888151713006664
Current ori: tensor([-0.0891, -0.0974,  0.1107], device='cuda:0')
Index force: tensor([0.4988, 0.5000, 0.6551, 0.5006], device='cuda:0')
tensor([ 0.1067,  0.5738,  0.5910,  0.6036, -0.0757,  0.6936,  0.7949,  0.7879,
         1.2790,  0.2471, -0.0803,  1.0003, -0.1714, -0.1762,  0.1406,  2.2442],
       device='cuda:0')
Solve time for step 2 1.8987276910047513
Current ori: tensor([-0.1714, -0.1762,  0.1406], device='cuda:0')
Index force: tensor([0.6042, 0.6064, 0.6029], device='cuda:0')
tensor([ 0.0719,  0.5841,  0.6974,  0.6770, -0.0536,  0.7213,  0.8186,  0.7808,
         1.2673,  0.2364, -0.1447,  0.9636, -0.2488, -0.2333,  0.2499,  2.2333],
       device='cuda:0')
Solve time for step 3 1.803645810985472
Current ori: tensor([-0.2488, -0.2333,  0.2499], device='cuda:0')
Index force: tensor([0.5977, 0.5993], device='cuda:0')
tensor([ 0.0416,  0.6648,  0.7223,  0.6832, -0.0282,  0.7586,  0.8373,  0.7842,
         1.2615,  0.2382, -0.1890,  0.9384, -0.3853, -0.2906,  0.3899,  2.3142],
       device='cuda:0')
Solve time for step 4 1.8045834549993742
Current ori: tensor([-0.3853, -0.2906,  0.3899], device='cuda:0')
Index force: tensor([0.5474], device='cuda:0')
Storing RECOVERY transition: reward=-0.7475 (scaled=-0.3738), steps=2
Reward stats updated: mean -0.0114 -> -0.0295, std: 0.1309
Collected 20 transitions for RL
Original likelihood: -770.598388671875
Adjusted likelihood: -770.598388671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 2
Loaded trajectory sampler
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:0')
Current yaw: tensor([-0.0020,  0.0145, -0.0306], device='cuda:0')
1 turn
Sampling time 3.7529769239772577
tensor([ 0.1479,  0.6005,  0.5797,  0.6059, -0.1236,  0.5446,  0.8891,  0.9433,
         1.2300,  0.2942,  0.2475,  1.1776, -0.0020,  0.0145, -0.0306,  0.2450],
       device='cuda:0')
Original likelihood: -20.109432220458984
Adjusted likelihood: -20.109432220458984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.758100271021249
Current ori: tensor([-0.0020,  0.0145, -0.0306], device='cuda:0')
Middle force: tensor([0.5207, 0.5006, 1.2931, 1.3042, 0.5227, 0.5396, 0.5043, 0.6073, 0.5677,
        0.5722, 0.5778, 0.5691], device='cuda:0')
Thumb force: tensor([0.7651, 0.6014, 1.1844, 1.0950, 0.8208, 0.8874, 0.5113, 0.5274, 0.7066,
        0.5642, 0.5688, 0.8365], device='cuda:0')
Index force: tensor([0.5015, 0.6188, 0.5912, 0.5283, 0.9815, 0.5370, 0.6198, 0.5607, 0.5844,
        0.5977, 0.5620, 0.5691], device='cuda:0')
Storing NORMAL transition: reward=-0.0013 (scaled=-0.0013), steps=1
Reward stats updated: mean -0.0295 -> -0.0282, std: 0.1279
Collected 21 transitions for RL
tensor([ 0.2134,  0.5840,  0.6345,  0.6815, -0.1651,  0.5914,  0.7590,  0.9763,
         1.3371,  0.0712,  0.0766,  1.2767,  0.0081, -0.0259, -0.0298,  0.4644],
       device='cuda:0')
Original likelihood: -35.466033935546875
Adjusted likelihood: -35.466033935546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0014)
State is out of distribution
Projection step: 0, Loss: 35.121307373046875
Projection step: 1, Loss: 29.604976654052734
Projection step: 2, Loss: 25.726181030273438
Projection step: 3, Loss: 24.304080963134766
Projection step: 4, Loss: 23.468673706054688
Projection step: 5, Loss: 22.369239807128906
Projection step: 6, Loss: 20.826631546020508
Projection step: 7, Loss: 20.681175231933594
Projection step: 8, Loss: 18.73346519470215
Projection step: 9, Loss: 18.081298828125
Projection step: 10, Loss: 17.257610321044922
Projection step: 11, Loss: 17.899356842041016
Projection step: 12, Loss: 16.447736740112305
Projection step: 13, Loss: 15.61177921295166
Projection step: 14, Loss: 16.09217071533203
Final likelihood: tensor([-13.6928, -14.1537, -14.9831, -14.3604, -13.4341, -16.1585, -16.0683,
        -16.6989, -12.8289, -13.5991, -15.2092, -16.0537, -16.7873, -14.0993,
        -18.3837, -15.6309])
Final projection likelihood: -15.1339
1 mode projection succeeded
New goal: tensor([ 1.2547e-01,  5.3391e-01,  6.2397e-01,  6.6523e-01, -5.0607e-02,
         5.9049e-01,  9.0485e-01,  7.7668e-01,  1.3712e+00,  2.0640e-01,
         1.4051e-01,  1.1284e+00,  1.4851e-03, -2.0614e-02, -1.9214e+00],
       device='cuda:0')
tensor([[0.0056]], device='cuda:0') tensor([[0.0123]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -19.921672821044922
Adjusted likelihood: -19.921672821044922
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 19.921672821044922}
Current yaw: tensor([ 0.0081, -0.0259, -0.0298], device='cuda:0')
2 thumb_middle
tensor([ 0.2134,  0.5840,  0.6345,  0.6815, -0.1651,  0.5914,  0.7590,  0.9763,
         1.3371,  0.0712,  0.0766,  1.2767,  0.0081, -0.0259, -0.0298,  0.4644],
       device='cuda:0')
Solve time for step 1 9.593065340013709
Current ori: tensor([ 0.0081, -0.0259, -0.0298], device='cuda:0')
Index force: tensor([0.5515, 0.5954, 0.5905, 0.5901], device='cuda:0')
tensor([ 0.1719,  0.5828,  0.6099,  0.6435, -0.1824,  0.5650,  0.8285,  0.7998,
         1.3301,  0.1578,  0.0456,  1.1134,  0.0036, -0.0033, -0.0298,  0.3953],
       device='cuda:0')
Solve time for step 2 1.9891308989899699
Current ori: tensor([ 0.0036, -0.0033, -0.0298], device='cuda:0')
Index force: tensor([0.5911, 0.5878, 0.5873], device='cuda:0')
tensor([ 0.1783,  0.5681,  0.6268,  0.6624, -0.1799,  0.5704,  0.8557,  0.7693,
         1.3386,  0.1855,  0.0311,  1.0987,  0.0085, -0.0056, -0.0298,  0.4115],
       device='cuda:0')
Solve time for step 3 2.2147266359825153
Current ori: tensor([ 0.0085, -0.0056, -0.0298], device='cuda:0')
Index force: tensor([0.5810, 0.5817], device='cuda:0')
tensor([ 0.1794,  0.5626,  0.6335,  0.6660, -0.1824,  0.5779,  0.8706,  0.7375,
         1.3341,  0.1817,  0.0417,  1.0930,  0.0101, -0.0058, -0.0298,  0.4151],
       device='cuda:0')
Solve time for step 4 1.8935655599925667
Current ori: tensor([ 0.0101, -0.0058, -0.0298], device='cuda:0')
Index force: tensor([0.5462], device='cuda:0')
Storing RECOVERY transition: reward=0.0068 (scaled=0.0068), steps=1
Reward stats updated: mean -0.0282 -> -0.0266, std: 0.1252
Collected 22 transitions for RL
Original likelihood: -21.483596801757812
Adjusted likelihood: -21.483596801757812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.0148,  0.0066, -0.0361], device='cuda:0')
3 turn
Sampling time 3.8845912200049497
tensor([ 0.1555,  0.5421,  0.6365,  0.6646, -0.1362,  0.5996,  0.9101,  0.7676,
         1.4083,  0.1986,  0.1072,  1.1130,  0.0148,  0.0066, -0.0361,  0.3726],
       device='cuda:0')
Original likelihood: -23.050399780273438
Adjusted likelihood: -23.050399780273438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 14.2430859550077
Current ori: tensor([ 0.0148,  0.0066, -0.0361], device='cuda:0')
Middle force: tensor([1.8030, 1.3758, 0.5079, 0.5206, 0.8879, 0.4984, 0.4924, 0.5688, 0.4892,
        0.5222, 0.5498, 0.5799], device='cuda:0')
Thumb force: tensor([0.8709, 0.5246, 1.0633, 0.5973, 1.7005, 0.7159, 1.6730, 1.1048, 0.5503,
        0.6038, 0.6156, 0.6521], device='cuda:0')
Index force: tensor([0.6690, 1.0205, 1.0201, 0.6223, 0.8366, 0.6385, 0.6782, 0.5623, 0.7807,
        0.6397, 0.6628, 0.5981], device='cuda:0')
Storing NORMAL transition: reward=-0.0841 (scaled=-0.0841), steps=1
Reward stats updated: mean -0.0266 -> -0.0291, std: 0.1230
Collected 23 transitions for RL
tensor([ 0.1049,  0.4853,  0.6797,  0.6259, -0.1420,  0.6225,  0.7650,  0.7742,
         1.5000,  0.0344,  0.2113,  0.9642,  0.0174,  0.0453,  0.0463,  0.4760],
       device='cuda:0')
Original likelihood: -31.597423553466797
Adjusted likelihood: -31.597423553466797
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1917)
State is out of distribution
Projection step: 0, Loss: 31.805389404296875
Projection step: 1, Loss: 28.869342803955078
Projection step: 2, Loss: 25.848377227783203
Projection step: 3, Loss: 24.009952545166016
Projection step: 4, Loss: 23.465442657470703
Projection step: 5, Loss: 19.491722106933594
Projection step: 6, Loss: 18.211090087890625
Projection step: 7, Loss: 17.865821838378906
Projection step: 8, Loss: 15.784648895263672
Projection step: 9, Loss: 16.82115364074707
Projection step: 10, Loss: 15.534000396728516
Projection step: 11, Loss: 15.691734313964844
Projection step: 12, Loss: 15.729633331298828
Projection step: 13, Loss: 13.740055084228516
Final likelihood: tensor([-13.6307, -13.8757, -11.7589, -15.9203,  -9.8809, -16.9073, -16.1880,
        -13.4385, -14.6510, -11.0638, -13.3789, -18.0221, -14.2542, -10.2119,
        -13.5668, -13.0919])
Final projection likelihood: -13.7401
1 mode projection succeeded
New goal: tensor([ 0.0739,  0.5781,  0.5633,  0.5637, -0.0901,  0.5589,  0.8562,  0.7888,
         1.4227,  0.1684,  0.2424,  1.1433,  0.0166,  0.0175, -1.7138],
       device='cuda:0')
tensor([[0.0029]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -20.45164680480957
Adjusted likelihood: -20.45164680480957
Likelihood residual: 0.0
{'index': 20.45164680480957, 'thumb_middle': inf}
Current yaw: tensor([0.0174, 0.0453, 0.0463], device='cuda:0')
4 index
tensor([ 0.1049,  0.4853,  0.6797,  0.6259, -0.1420,  0.6225,  0.7650,  0.7742,
         1.5000,  0.0344,  0.2113,  0.9642,  0.0174,  0.0453,  0.0463,  0.4760],
       device='cuda:0')
Solve time for step 1 10.896641676023137
Current ori: tensor([0.0174, 0.0453, 0.0463], device='cuda:0')
Middle force: tensor([0.5321, 0.6163, 0.5777, 0.5585], device='cuda:0')
Thumb force: tensor([0.5772, 0.5715, 0.6228, 0.5656], device='cuda:0')
tensor([ 0.1238,  0.5018,  0.5395,  0.5551, -0.1392,  0.5743,  0.8385,  0.7909,
         1.4503,  0.1089,  0.2163,  1.0129,  0.0362,  0.0396,  0.0358,  0.8137],
       device='cuda:0')
Solve time for step 2 2.1383888729906175
Current ori: tensor([0.0362, 0.0396, 0.0358], device='cuda:0')
Middle force: tensor([0.6136, 0.5752, 0.5561], device='cuda:0')
Thumb force: tensor([0.5672, 0.6196, 0.5632], device='cuda:0')
tensor([ 0.1151,  0.5162,  0.5253,  0.5487, -0.1162,  0.5822,  0.8490,  0.7835,
         1.4235,  0.1349,  0.1971,  1.0431,  0.0360,  0.0245,  0.0386,  0.7995],
       device='cuda:0')
Solve time for step 3 2.2832738060096744
Current ori: tensor([0.0360, 0.0245, 0.0386], device='cuda:0')
Middle force: tensor([0.5349, 0.5549], device='cuda:0')
Thumb force: tensor([0.5661, 0.5655], device='cuda:0')
tensor([ 0.1166,  0.5201,  0.5249,  0.5479, -0.1034,  0.5845,  0.8554,  0.7873,
         1.4157,  0.1368,  0.1795,  1.0648,  0.0369,  0.0145,  0.0325,  0.5715],
       device='cuda:0')
Solve time for step 4 2.0181371069920715
Current ori: tensor([0.0369, 0.0145, 0.0325], device='cuda:0')
Middle force: tensor([0.5361], device='cuda:0')
Thumb force: tensor([0.5641], device='cuda:0')
Storing RECOVERY transition: reward=0.0033 (scaled=0.0033), steps=1
Reward stats updated: mean -0.0291 -> -0.0278, std: 0.1206
Collected 24 transitions for RL
Original likelihood: -16.830093383789062
Adjusted likelihood: -16.830093383789062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([0.0363, 0.0125, 0.0438], device='cuda:0')
5 turn
Sampling time 3.8042810409970116
tensor([ 0.0722,  0.5734,  0.5601,  0.5611, -0.0992,  0.5906,  0.8515,  0.7816,
         1.4079,  0.1463,  0.1770,  1.0724,  0.0363,  0.0125,  0.0438,  0.4969],
       device='cuda:0')
Original likelihood: -19.1491756439209
Adjusted likelihood: -19.1491756439209
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.400923490000423
Current ori: tensor([0.0363, 0.0125, 0.0438], device='cuda:0')
Middle force: tensor([0.7288, 2.3203, 0.8589, 0.4971, 0.7492, 0.5223, 0.5841, 0.9115, 0.5447,
        0.5632, 0.5353, 0.5718], device='cuda:0')
Thumb force: tensor([0.9719, 0.7503, 0.5715, 1.0515, 0.5435, 1.2648, 0.5024, 0.7989, 1.2411,
        0.5870, 0.6138, 0.5633], device='cuda:0')
Index force: tensor([0.9670, 0.9862, 0.5552, 0.7624, 0.6022, 0.5793, 0.5046, 0.8404, 0.5472,
        0.6504, 0.6721, 0.5938], device='cuda:0')
Storing NORMAL transition: reward=-0.0028 (scaled=-0.0028), steps=1
Reward stats updated: mean -0.0278 -> -0.0268, std: 0.1183
Collected 25 transitions for RL
tensor([ 0.0893,  0.4721,  0.6378,  0.7145, -0.0632,  0.5632,  0.7875,  0.8133,
         1.4615, -0.0520,  0.2478,  1.0923,  0.0739,  0.0145,  0.0425,  0.5663],
       device='cuda:0')
Original likelihood: -30.439090728759766
Adjusted likelihood: -30.439090728759766
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4053)
State is out of distribution
Projection step: 0, Loss: 29.699417114257812
Projection step: 1, Loss: 26.997920989990234
Projection step: 2, Loss: 25.243576049804688
Projection step: 3, Loss: 24.699291229248047
Projection step: 4, Loss: 24.302730560302734
Projection step: 5, Loss: 24.090927124023438
Projection step: 6, Loss: 22.20049476623535
Projection step: 7, Loss: 21.69377326965332
Projection step: 8, Loss: 21.7053165435791
Projection step: 9, Loss: 21.9636173248291
Projection step: 10, Loss: 19.99930763244629
Projection step: 11, Loss: 19.938112258911133
Projection step: 12, Loss: 19.86478614807129
Projection step: 13, Loss: 18.948360443115234
Projection step: 14, Loss: 18.38916015625
Final likelihood: tensor([-16.7274, -18.9417, -15.9836, -20.2655, -16.1241, -19.3878, -18.4577,
        -18.0140, -16.2890, -16.2372, -16.5996, -16.9226, -15.6493, -15.9550,
        -19.4992, -20.2269])
Final projection likelihood: -17.5800
1 mode projection succeeded
New goal: tensor([ 6.4419e-02,  5.5137e-01,  5.7122e-01,  5.9391e-01, -6.5293e-02,
         4.8732e-01,  8.9716e-01,  9.0428e-01,  1.3967e+00,  1.0169e-01,
         2.0849e-01,  1.1920e+00,  5.6556e-02,  6.0892e-04, -1.1392e+00],
       device='cuda:0')
tensor([[0.0033]], device='cuda:0') tensor([[0.0045]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -21.629796981811523
Adjusted likelihood: -21.629796981811523
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 21.629796981811523}
Current yaw: tensor([0.0739, 0.0145, 0.0425], device='cuda:0')
6 thumb_middle
tensor([ 0.0893,  0.4721,  0.6378,  0.7145, -0.0632,  0.5632,  0.7875,  0.8133,
         1.4615, -0.0520,  0.2478,  1.0923,  0.0739,  0.0145,  0.0425,  0.5663],
       device='cuda:0')
Solve time for step 1 8.890235925995512
Current ori: tensor([0.0739, 0.0145, 0.0425], device='cuda:0')
Index force: tensor([0.5750, 0.6025, 0.6160, 0.5040], device='cuda:0')
tensor([ 0.0930,  0.5032,  0.6223,  0.6665, -0.1569,  0.4757,  0.8362,  0.8582,
         1.3580,  0.0294,  0.1273,  1.1255,  0.0620,  0.0099,  0.0425,  0.5431],
       device='cuda:0')
Solve time for step 2 2.0319756489770953
Current ori: tensor([0.0620, 0.0099, 0.0425], device='cuda:0')
Index force: tensor([0.5966, 0.6125, 0.5020], device='cuda:0')
tensor([ 0.0856,  0.4593,  0.6581,  0.6994, -0.1778,  0.4770,  0.8570,  0.8732,
         1.3689,  0.0564,  0.1077,  1.1392,  0.0756,  0.0162,  0.0425,  0.5576],
       device='cuda:0')
Solve time for step 3 1.9473451109952293
Current ori: tensor([0.0756, 0.0162, 0.0425], device='cuda:0')
Index force: tensor([0.6049, 0.5006], device='cuda:0')
tensor([ 0.0827,  0.4368,  0.6688,  0.7334, -0.1806,  0.4703,  0.8554,  0.8768,
         1.3789,  0.0640,  0.1047,  1.1433,  0.0842,  0.0202,  0.0425,  0.5737],
       device='cuda:0')
Solve time for step 4 1.899936219007941
Current ori: tensor([0.0842, 0.0202, 0.0425], device='cuda:0')
Index force: tensor([0.5006], device='cuda:0')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0061), steps=1
Reward stats updated: mean -0.0268 -> -0.0255, std: 0.1161
Collected 26 transitions for RL
Original likelihood: -31.82577133178711
Adjusted likelihood: -31.82577133178711
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1596)
State is out of distribution
Projection step: 0, Loss: 30.792964935302734
Projection step: 1, Loss: 29.25713348388672
Projection step: 2, Loss: 28.12660789489746
Projection step: 3, Loss: 26.176376342773438
Projection step: 4, Loss: 24.972869873046875
Projection step: 5, Loss: 24.61292839050293
Projection step: 6, Loss: 24.05622673034668
Projection step: 7, Loss: 24.37217140197754
Projection step: 8, Loss: 23.38869857788086
Projection step: 9, Loss: 23.146968841552734
Projection step: 10, Loss: 22.034902572631836
Projection step: 11, Loss: 22.261600494384766
Projection step: 12, Loss: 21.574169158935547
Projection step: 13, Loss: 21.471866607666016
Projection step: 14, Loss: 21.20694351196289
Final likelihood: tensor([-21.3576, -20.5399, -18.9246, -18.8423, -17.2457, -18.2354, -20.5561,
        -19.7359, -21.9592, -19.4177, -20.6140, -21.9031, -23.1160, -24.1085,
        -18.2369, -20.3834])
Final projection likelihood: -20.3235
1 mode projection succeeded
New goal: tensor([ 0.0701,  0.5387,  0.5736,  0.6252, -0.0600,  0.4763,  0.9071,  0.9560,
         1.3728,  0.1452,  0.2130,  1.2302,  0.0637, -0.0017, -1.0915],
       device='cuda:0')
tensor([[0.0031]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -22.987342834472656
Adjusted likelihood: -22.987342834472656
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.987342834472656}
Current yaw: tensor([0.0813, 0.0117, 0.0354], device='cuda:0')
7 thumb_middle
tensor([ 0.0806,  0.4408,  0.6796,  0.6943, -0.1012,  0.5176,  0.9042,  0.8979,
         1.4330,  0.0985,  0.1512,  1.1762,  0.0813,  0.0117,  0.0354,  0.4675],
       device='cuda:0')
Solve time for step 1 8.805834388011135
Current ori: tensor([0.0813, 0.0117, 0.0354], device='cuda:0')
Index force: tensor([0.5801, 0.5670, 0.5621, 0.5744], device='cuda:0')
tensor([ 0.0747,  0.4984,  0.6180,  0.6530, -0.1809,  0.4567,  0.8636,  0.9081,
         1.3339,  0.0934,  0.0997,  1.1802,  0.0634,  0.0187,  0.0354,  0.4674],
       device='cuda:0')
Solve time for step 2 1.956239095015917
Current ori: tensor([0.0634, 0.0187, 0.0354], device='cuda:0')
Index force: tensor([0.5614, 0.5576, 0.5693], device='cuda:0')
tensor([ 0.0751,  0.5355,  0.5793,  0.6300, -0.1776,  0.4432,  0.8713,  0.9143,
         1.3438,  0.0875,  0.0947,  1.1623,  0.0525,  0.0165,  0.0354,  0.4486],
       device='cuda:0')
Solve time for step 3 1.8837403890211135
Current ori: tensor([0.0525, 0.0165, 0.0354], device='cuda:0')
Index force: tensor([0.5516, 0.5636], device='cuda:0')
tensor([ 0.0799,  0.5472,  0.5665,  0.6328, -0.1855,  0.4598,  0.8693,  0.9263,
         1.3275,  0.0896,  0.1022,  1.1730,  0.0501,  0.0138,  0.0354,  0.4496],
       device='cuda:0')
Solve time for step 4 1.8471107340010349
Current ori: tensor([0.0501, 0.0138, 0.0354], device='cuda:0')
Index force: tensor([0.5593], device='cuda:0')
Storing RECOVERY transition: reward=-0.0056 (scaled=-0.0056), steps=1
Reward stats updated: mean -0.0255 -> -0.0248, std: 0.1140
Collected 27 transitions for RL
Original likelihood: -25.59756088256836
Adjusted likelihood: -25.59756088256836
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9919)
Current yaw: tensor([0.0570, 0.0195, 0.0501], device='cuda:0')
8 turn
Sampling time 3.881585245981114
tensor([ 0.0682,  0.5155,  0.6025,  0.6255, -0.1347,  0.5055,  0.9065,  0.9302,
         1.4040,  0.1244,  0.1539,  1.2098,  0.0570,  0.0195,  0.0501,  0.4612],
       device='cuda:0')
Original likelihood: -24.630956649780273
Adjusted likelihood: -24.630956649780273
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9983)
Solve time for step 1 14.37402594301966
Current ori: tensor([0.0570, 0.0195, 0.0501], device='cuda:0')
Middle force: tensor([0.8515, 1.3986, 0.6898, 0.5112, 0.5281, 0.7255, 0.5441, 0.5981, 0.5882,
        0.5587, 0.5517, 0.5896], device='cuda:0')
Thumb force: tensor([1.5894, 1.4941, 0.5706, 0.5429, 0.8947, 2.0178, 1.0165, 0.5914, 0.5602,
        0.6521, 0.5149, 0.6356], device='cuda:0')
Index force: tensor([1.0810, 1.4279, 1.0028, 0.6300, 1.2602, 0.7394, 0.5276, 0.6065, 0.6278,
        0.6332, 0.8587, 0.5542], device='cuda:0')
Storing NORMAL transition: reward=0.1341 (scaled=0.1341), steps=1
Reward stats updated: mean -0.0248 -> -0.0191, std: 0.1158
Collected 28 transitions for RL
tensor([ 0.1219,  0.5914,  0.5426,  0.6225, -0.0842,  0.4783,  0.9698,  1.0790,
         1.1681,  0.4661,  0.4360,  0.8368,  0.0726, -0.0256, -0.0881, -0.0883],
       device='cuda:0')
Original likelihood: -33.291046142578125
Adjusted likelihood: -33.291046142578125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0363)
State is out of distribution
Projection step: 0, Loss: 33.441776275634766
Projection step: 1, Loss: 30.774147033691406
Projection step: 2, Loss: 27.58551025390625
Projection step: 3, Loss: 25.254514694213867
Projection step: 4, Loss: 24.89581298828125
Projection step: 5, Loss: 22.879512786865234
Projection step: 6, Loss: 21.572925567626953
Projection step: 7, Loss: 21.708820343017578
Projection step: 8, Loss: 19.69021224975586
Projection step: 9, Loss: 19.990169525146484
Projection step: 10, Loss: 19.504070281982422
Projection step: 11, Loss: 18.7689208984375
Projection step: 12, Loss: 18.931148529052734
Projection step: 13, Loss: 17.922067642211914
Projection step: 14, Loss: 17.992332458496094
Final likelihood: tensor([-18.9798, -16.8267, -16.8102, -18.8603, -19.1212, -20.2971, -18.4605,
        -18.8081, -15.5999, -17.0775, -19.6548, -18.9839, -18.7667, -18.7703,
        -19.4135, -19.6702])
Final projection likelihood: -18.5063
1 mode projection succeeded
New goal: tensor([ 0.0705,  0.5371,  0.6216,  0.5641, -0.0593,  0.4906,  0.9155,  0.8819,
         1.2780,  0.2736,  0.2320,  1.1481,  0.0585, -0.0124, -1.0794],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0021]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -25.369243621826172
Adjusted likelihood: -25.369243621826172
Likelihood residual: 0.0
Original likelihood: -30.034015655517578
Adjusted likelihood: -30.034015655517578
Likelihood residual: 0.0
{'index': 30.034015655517578, 'thumb_middle': 25.369243621826172}
Current yaw: tensor([ 0.0726, -0.0256, -0.0881], device='cuda:0')
9 thumb_middle
tensor([ 0.1219,  0.5914,  0.5426,  0.6225, -0.0842,  0.4783,  0.9698,  1.0790,
         1.1681,  0.4661,  0.4360,  0.8368,  0.0726, -0.0256, -0.0881, -0.0883],
       device='cuda:0')
Solve time for step 1 8.790079427009914
Current ori: tensor([ 0.0726, -0.0256, -0.0881], device='cuda:0')
Index force: tensor([0.5880, 0.5934, 0.6003, 0.6038], device='cuda:0')
tensor([ 0.1160,  0.5643,  0.6028,  0.5664, -0.1365,  0.4690,  0.8952,  0.9076,
         1.2133,  0.3087,  0.1919,  1.0380,  0.0734, -0.0236, -0.0881, -0.1107],
       device='cuda:0')
Solve time for step 2 1.913399662997108
Current ori: tensor([ 0.0734, -0.0236, -0.0881], device='cuda:0')
Index force: tensor([0.5888, 0.5983, 0.6013], device='cuda:0')
tensor([ 0.0774,  0.5204,  0.6232,  0.5700, -0.1648,  0.4810,  0.8842,  0.8686,
         1.2558,  0.2792,  0.1644,  1.0884,  0.0826, -0.0038, -0.0881, -0.1375],
       device='cuda:0')
Solve time for step 3 1.8786343669926282
Current ori: tensor([ 0.0826, -0.0038, -0.0881], device='cuda:0')
Index force: tensor([0.5912, 0.5958], device='cuda:0')
tensor([ 0.0858,  0.5304,  0.6222,  0.5608, -0.1554,  0.4951,  0.8864,  0.8626,
         1.2593,  0.2625,  0.1445,  1.0965,  0.0796, -0.0084, -0.0881, -0.1361],
       device='cuda:0')
Solve time for step 4 1.846442220004974
Current ori: tensor([ 0.0796, -0.0084, -0.0881], device='cuda:0')
Index force: tensor([0.5001], device='cuda:0')
Storing RECOVERY transition: reward=0.0176 (scaled=0.0176), steps=1
Reward stats updated: mean -0.0191 -> -0.0178, std: 0.1140
Collected 29 transitions for RL
Original likelihood: -25.371501922607422
Adjusted likelihood: -25.371501922607422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9942)
Current yaw: tensor([ 0.0791, -0.0155, -0.1069], device='cuda:0')
10 turn
Sampling time 3.8806047179969028
tensor([ 0.0855,  0.5372,  0.6308,  0.5211, -0.0816,  0.5399,  0.9360,  0.8944,
         1.3087,  0.2799,  0.1962,  1.1387,  0.0791, -0.0155, -0.1069, -0.1638],
       device='cuda:0')
Original likelihood: -23.94284439086914
Adjusted likelihood: -23.94284439086914
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 1 14.920917339011794
Current ori: tensor([ 0.0791, -0.0155, -0.1069], device='cuda:0')
Middle force: tensor([0.5316, 1.0601, 0.5633, 0.5489, 0.9072, 1.3395, 0.6023, 0.5462, 0.5324,
        0.5450, 0.5813, 0.5540], device='cuda:0')
Thumb force: tensor([1.2255, 1.0287, 0.6237, 0.5769, 0.5467, 0.5220, 0.5953, 1.2157, 0.5858,
        0.5344, 1.0796, 0.5910], device='cuda:0')
Index force: tensor([0.6870, 1.2761, 0.5763, 0.5511, 0.9171, 0.8270, 0.5559, 0.5174, 0.5567,
        0.5110, 0.6013, 0.6237], device='cuda:0')
Storing NORMAL transition: reward=0.0388 (scaled=0.0388), steps=1
Reward stats updated: mean -0.0178 -> -0.0159, std: 0.1125
Collected 30 transitions for RL
tensor([ 0.0254,  0.5948,  0.5066,  0.4988, -0.1974,  0.6003,  0.9086,  0.9488,
         1.5000, -0.0112,  0.2025,  1.0188,  0.0762,  0.0129, -0.1456,  0.0520],
       device='cuda:0')
Original likelihood: -34.973777770996094
Adjusted likelihood: -34.973777770996094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0033)
State is out of distribution
Projection step: 0, Loss: 34.69280242919922
Projection step: 1, Loss: 31.99830436706543
Projection step: 2, Loss: 29.693904876708984
Projection step: 3, Loss: 27.48882484436035
Projection step: 4, Loss: 26.93377685546875
Projection step: 5, Loss: 26.35245132446289
Projection step: 6, Loss: 25.821048736572266
Projection step: 7, Loss: 24.07985496520996
Projection step: 8, Loss: 23.747657775878906
Projection step: 9, Loss: 23.6871337890625
Projection step: 10, Loss: 23.337099075317383
Projection step: 11, Loss: 24.159469604492188
Projection step: 12, Loss: 21.865510940551758
Projection step: 13, Loss: 21.17896842956543
Projection step: 14, Loss: 22.189502716064453
Final likelihood: tensor([-20.7816, -21.0210, -19.2058, -20.2484, -21.1073, -19.8889, -24.3144,
        -18.3893, -22.1262, -19.3641, -19.6312, -20.6528, -23.6429, -19.7544,
        -22.5339, -19.1050])
Final projection likelihood: -20.7355
1 mode projection succeeded
New goal: tensor([ 0.0535,  0.5976,  0.5313,  0.5089, -0.0954,  0.5058,  0.8470,  0.8807,
         1.4400,  0.0726,  0.2368,  1.1336,  0.0584,  0.0094, -1.0654],
       device='cuda:0')
tensor([[0.0036]], device='cuda:0') tensor([[0.0031]], device='cuda:0') tensor([[0.0026]], device='cuda:0')
Original likelihood: -26.322341918945312
Adjusted likelihood: -26.322341918945312
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 26.322341918945312}
Current yaw: tensor([ 0.0762,  0.0129, -0.1456], device='cuda:0')
11 thumb_middle
tensor([ 0.0254,  0.5948,  0.5066,  0.4988, -0.1974,  0.6003,  0.9086,  0.9488,
         1.5000, -0.0112,  0.2025,  1.0188,  0.0762,  0.0129, -0.1456,  0.0520],
       device='cuda:0')
Solve time for step 1 8.889411526004551
Current ori: tensor([ 0.0762,  0.0129, -0.1456], device='cuda:0')
Index force: tensor([0.5655, 0.5759, 0.5873, 0.5879], device='cuda:0')
tensor([ 0.0225,  0.5855,  0.5211,  0.4866, -0.1980,  0.5082,  0.8297,  0.8828,
         1.3932,  0.0119,  0.1428,  1.0771,  0.1104,  0.0401, -0.1456,  0.6499],
       device='cuda:0')
Solve time for step 2 1.9682513950101566
Current ori: tensor([ 0.1104,  0.0401, -0.1456], device='cuda:0')
Index force: tensor([0.5721, 0.5838, 0.5842], device='cuda:0')
tensor([ 0.0383,  0.6019,  0.5049,  0.5030, -0.1946,  0.5112,  0.8236,  0.8559,
         1.4103,  0.0169,  0.1401,  1.0841,  0.1065,  0.0297, -0.1456,  0.6885],
       device='cuda:0')
Solve time for step 3 1.8434488030034117
Current ori: tensor([ 0.1065,  0.0297, -0.1456], device='cuda:0')
Index force: tensor([0.5779, 0.5787], device='cuda:0')
tensor([ 0.0393,  0.5968,  0.5149,  0.4997, -0.1878,  0.5120,  0.8130,  0.8437,
         1.4097,  0.0317,  0.1378,  1.0987,  0.1075,  0.0294, -0.1456,  0.6751],
       device='cuda:0')
Solve time for step 4 1.7450520519923884
Current ori: tensor([ 0.1075,  0.0294, -0.1456], device='cuda:0')
Index force: tensor([0.5520], device='cuda:0')
Storing RECOVERY transition: reward=0.0080 (scaled=0.0080), steps=1
Reward stats updated: mean -0.0159 -> -0.0152, std: 0.1108
Collected 31 transitions for RL
Original likelihood: -39.164249420166016
Adjusted likelihood: -39.164249420166016
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 39.12425994873047
Projection step: 1, Loss: 34.9864501953125
Projection step: 2, Loss: 33.4539794921875
Projection step: 3, Loss: 33.83557891845703
Projection step: 4, Loss: 31.583646774291992
Projection step: 5, Loss: 32.500709533691406
Projection step: 6, Loss: 32.78016662597656
Projection step: 7, Loss: 31.422191619873047
Projection step: 8, Loss: 30.823070526123047
Projection step: 9, Loss: 31.45081329345703
Projection step: 10, Loss: 29.98592758178711
Projection step: 11, Loss: 30.1392765045166
Projection step: 12, Loss: 30.065570831298828
Projection step: 13, Loss: 29.017982482910156
Projection step: 14, Loss: 27.852142333984375
Final likelihood: tensor([-27.2745, -26.7564, -33.8687, -27.4019, -30.3375, -28.0805, -30.4240,
        -27.2230, -29.3441, -27.7941, -25.2676, -31.3746, -30.1236, -29.4140,
        -26.2086, -26.8508])
Final projection likelihood: -28.6090
1 mode projection succeeded
New goal: tensor([ 0.0589,  0.6219,  0.5233,  0.4950, -0.0924,  0.4984,  0.8474,  0.8618,
         1.4303,  0.0772,  0.2270,  1.1520,  0.0859,  0.0165, -0.3596],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[0.0021]], device='cuda:0') tensor([[0.0022]], device='cuda:0')
Original likelihood: -34.3476676940918
Adjusted likelihood: -34.3476676940918
Likelihood residual: 0.0
Original likelihood: -33.199066162109375
Adjusted likelihood: -33.199066162109375
Likelihood residual: 0.0
{'index': 33.199066162109375, 'thumb_middle': 34.3476676940918}
Current yaw: tensor([ 0.1049,  0.0246, -0.1596], device='cuda:0')
12 index
tensor([ 0.0282,  0.6126,  0.4907,  0.4779, -0.1136,  0.5579,  0.8759,  0.8835,
         1.4745,  0.0689,  0.1874,  1.1314,  0.1049,  0.0246, -0.1596,  0.5779],
       device='cuda:0')
Solve time for step 1 10.394554694998078
Current ori: tensor([ 0.1049,  0.0246, -0.1596], device='cuda:0')
Middle force: tensor([0.5753, 0.5384, 0.5212, 0.5555], device='cuda:0')
Thumb force: tensor([0.5556, 0.6057, 0.5362, 0.5774], device='cuda:0')
tensor([ 0.0701,  0.4751,  0.4782,  0.4967, -0.1109,  0.5920,  0.8774,  0.8583,
         1.4717,  0.0863,  0.1801,  1.1063,  0.1030,  0.0157, -0.1422, -0.8247],
       device='cuda:0')
Solve time for step 2 2.286974136979552
Current ori: tensor([ 0.1030,  0.0157, -0.1422], device='cuda:0')
Middle force: tensor([0.5363, 0.5205, 0.5540], device='cuda:0')
Thumb force: tensor([0.6031, 0.5355, 0.5758], device='cuda:0')
tensor([ 0.0783,  0.4840,  0.4851,  0.5004, -0.1102,  0.6470,  0.8884,  0.8449,
         1.5000,  0.0783,  0.1828,  1.0892,  0.1534,  0.0107, -0.1311, -1.7603],
       device='cuda:0')
Solve time for step 3 2.17303085399908
Current ori: tensor([ 0.1534,  0.0107, -0.1311], device='cuda:0')
Middle force: tensor([0.5195, 0.5529], device='cuda:0')
Thumb force: tensor([0.5344, 0.5729], device='cuda:0')
tensor([ 0.0679,  0.4511,  0.4846,  0.5046, -0.1066,  0.7095,  0.9020,  0.8334,
         1.5000,  0.1086,  0.2044,  1.0577,  0.2490,  0.0197, -0.1421, -1.8229],
       device='cuda:0')
Solve time for step 4 2.18443713299348
Current ori: tensor([ 0.2490,  0.0197, -0.1421], device='cuda:0')
Middle force: tensor([0.5499], device='cuda:0')
Thumb force: tensor([0.5666], device='cuda:0')
Storing RECOVERY transition: reward=-0.0328 (scaled=-0.0328), steps=1
Reward stats updated: mean -0.0152 -> -0.0157, std: 0.1091
Collected 32 transitions for RL
Original likelihood: -50.13987350463867
Adjusted likelihood: -50.13987350463867
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 54.73640441894531
Projection step: 1, Loss: 48.29065704345703
Projection step: 2, Loss: 50.773712158203125
Projection step: 3, Loss: 47.98579025268555
Projection step: 4, Loss: 47.62361145019531
Projection step: 5, Loss: 44.35319519042969
Projection step: 6, Loss: 47.15406036376953
Projection step: 7, Loss: 43.248023986816406
Projection step: 8, Loss: 42.61030197143555
Projection step: 9, Loss: 42.901920318603516
Projection step: 10, Loss: 43.228675842285156
Projection step: 11, Loss: 43.62891387939453
Projection step: 12, Loss: 42.58087921142578
Projection step: 13, Loss: 40.858333587646484
Projection step: 14, Loss: 41.22229766845703
Final likelihood: tensor([-32.1734, -36.5942, -39.1988, -32.9356, -38.6130, -40.0123, -40.9499,
        -42.4368, -40.3322, -41.9646, -44.1150, -38.7184, -44.5006, -35.6188,
        -46.3084, -38.8233])
Final projection likelihood: -39.5809
1 mode projection failed, trying anyway
New goal: tensor([ 0.0603,  0.4992,  0.6348,  0.7108, -0.0769,  0.6091,  0.8715,  1.0605,
         1.4653, -0.0312,  0.2987,  0.9046,  0.2316,  0.0196,  0.2401],
       device='cuda:0')
tensor([[0.0076]], device='cuda:0') tensor([[0.0030]], device='cuda:0') tensor([[0.0007]], device='cuda:0')
Original likelihood: -46.165225982666016
Adjusted likelihood: -46.165225982666016
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 46.165225982666016}
Current yaw: tensor([ 0.2437,  0.0179, -0.1672], device='cuda:0')
13 thumb_middle
tensor([ 0.0789,  0.4987,  0.5629,  0.5088, -0.0859,  0.7418,  0.9185,  0.8858,
         1.5000,  0.1421,  0.2402,  1.1049,  0.2437,  0.0179, -0.1672, -1.9635],
       device='cuda:0')
Solve time for step 1 8.766457452991745
Current ori: tensor([ 0.2437,  0.0179, -0.1672], device='cuda:0')
Index force: tensor([0.6026, 0.5483, 0.5897, 0.5878], device='cuda:0')
tensor([ 0.0909,  0.5001,  0.6398,  0.6688, -0.2097,  0.5229,  0.8678,  1.0164,
         1.4672, -0.0192,  0.3077,  1.0119,  0.2430,  0.0185, -0.1896, -1.9981],
       device='cuda:0')
Solve time for step 2 1.9561721019854303
Current ori: tensor([ 0.2430,  0.0185, -0.1896], device='cuda:0')
Index force: tensor([0.5471, 0.5865, 0.5847], device='cuda:0')
tensor([ 0.0914,  0.4993,  0.6498,  0.7004, -0.2195,  0.5241,  0.8632,  1.0379,
         1.4890, -0.0353,  0.3081,  0.9861,  0.2437,  0.0224, -0.2087, -2.0051],
       device='cuda:0')
Solve time for step 3 1.8964223559887614
Current ori: tensor([ 0.2437,  0.0224, -0.2087], device='cuda:0')
Index force: tensor([0.5835, 0.5821], device='cuda:0')
tensor([ 0.0978,  0.5037,  0.6590,  0.7099, -0.2207,  0.5254,  0.8655,  1.0482,
         1.4887, -0.0464,  0.3242,  0.9863,  0.2430,  0.0243, -0.2207, -1.9622],
       device='cuda:0')
Solve time for step 4 1.8200081380200572
Current ori: tensor([ 0.2430,  0.0243, -0.2207], device='cuda:0')
Index force: tensor([0.5424], device='cuda:0')
Storing RECOVERY transition: reward=-0.0147 (scaled=-0.0147), steps=1
Reward stats updated: mean -0.0157 -> -0.0157, std: 0.1074
Collected 33 transitions for RL
Original likelihood: -52.745826721191406
Adjusted likelihood: -52.745826721191406
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 52.89751434326172
Projection step: 1, Loss: 48.29430389404297
Projection step: 2, Loss: 50.42451095581055
Projection step: 3, Loss: 44.46583557128906
Projection step: 4, Loss: 44.72224807739258
Projection step: 5, Loss: 43.11896514892578
Projection step: 6, Loss: 44.15802764892578
Projection step: 7, Loss: 43.13597106933594
Projection step: 8, Loss: 43.149391174316406
Projection step: 9, Loss: 45.80150604248047
Projection step: 10, Loss: 43.39213562011719
Projection step: 11, Loss: 41.99568176269531
Projection step: 12, Loss: 42.19350051879883
Projection step: 13, Loss: 39.44574737548828
Projection step: 14, Loss: 41.17203140258789
Final likelihood: tensor([-37.8036, -49.0154, -38.9701, -45.9846, -38.7297, -32.6150, -36.8479,
        -39.2638, -41.8988, -39.7630, -37.5757, -39.3277, -36.2831, -50.6406,
        -71.9057, -33.3909])
Final projection likelihood: -41.8760
1 mode projection failed, trying anyway
New goal: tensor([ 0.0583,  0.4364,  0.6438,  0.8319, -0.0807,  0.5761,  0.8593,  1.1463,
         1.4990, -0.1238,  0.4569,  0.7679,  0.2334,  0.0263,  0.4067],
       device='cuda:0')
tensor([[0.0042]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0006]], device='cuda:0')
Original likelihood: -49.066017150878906
Adjusted likelihood: -49.066017150878906
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 49.066017150878906}
Current yaw: tensor([ 0.2453,  0.0261, -0.1890], device='cuda:0')
14 thumb_middle
tensor([ 6.8566e-02,  4.9641e-01,  6.6650e-01,  7.2642e-01, -1.1141e-01,
         6.3338e-01,  9.1467e-01,  1.0838e+00,  1.5000e+00,  4.3874e-04,
         4.4392e-01,  1.0085e+00,  2.4530e-01,  2.6073e-02, -1.8901e-01,
        -1.9648e+00], device='cuda:0')
Solve time for step 1 9.053714644978754
Current ori: tensor([ 0.2453,  0.0261, -0.1890], device='cuda:0')
Index force: tensor([0.6039, 0.5477, 0.5984, 0.5472], device='cuda:0')
tensor([ 0.0776,  0.5000,  0.6686,  0.7878, -0.2205,  0.4683,  0.8461,  1.1105,
         1.4890, -0.1050,  0.4566,  0.8784,  0.2447,  0.0273, -0.2056, -1.9872],
       device='cuda:0')
Solve time for step 2 1.931174272991484
Current ori: tensor([ 0.2447,  0.0273, -0.2056], device='cuda:0')
Index force: tensor([0.5459, 0.5951, 0.5451], device='cuda:0')
tensor([ 0.0746,  0.4969,  0.6632,  0.8136, -0.2303,  0.4676,  0.8412,  1.1277,
         1.5000, -0.1050,  0.4534,  0.8457,  0.2457,  0.0308, -0.2257, -2.0227],
       device='cuda:0')
Solve time for step 3 1.8665432650013827
Current ori: tensor([ 0.2457,  0.0308, -0.2257], device='cuda:0')
Index force: tensor([0.5912, 0.5431], device='cuda:0')
tensor([ 0.0777,  0.4976,  0.6555,  0.8243, -0.2378,  0.4742,  0.8357,  1.1236,
         1.5000, -0.1050,  0.4523,  0.8267,  0.2462,  0.0354, -0.2524, -2.0497],
       device='cuda:0')
Solve time for step 4 1.7585340039804578
Current ori: tensor([ 0.2462,  0.0354, -0.2524], device='cuda:0')
Index force: tensor([0.5844], device='cuda:0')
Storing RECOVERY transition: reward=0.0416 (scaled=0.0416), steps=1
Reward stats updated: mean -0.0157 -> -0.0140, std: 0.1062
Collected 34 transitions for RL
Original likelihood: -48.09690475463867
Adjusted likelihood: -48.09690475463867
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 52.87355041503906
Projection step: 1, Loss: 47.51847839355469
Projection step: 2, Loss: 49.88755798339844
Projection step: 3, Loss: 47.507667541503906
Projection step: 4, Loss: 46.697265625
Projection step: 5, Loss: 45.390167236328125
Projection step: 6, Loss: 45.09895324707031
Projection step: 7, Loss: 45.10978317260742
Projection step: 8, Loss: 45.019649505615234
Projection step: 9, Loss: 43.81177520751953
Projection step: 10, Loss: 40.990684509277344
Projection step: 11, Loss: 44.28413772583008
Projection step: 12, Loss: 42.29447555541992
Projection step: 13, Loss: 41.72649383544922
Projection step: 14, Loss: 40.359771728515625
Final likelihood: tensor([-35.6088, -36.2688, -35.4818, -52.5535, -37.2901, -34.7762, -39.0095,
        -57.2865, -40.8765, -36.4394, -36.7003, -37.0433, -62.7420, -33.8819,
        -43.7731, -38.0284])
Final projection likelihood: -41.1100
1 mode projection failed, trying anyway
New goal: tensor([ 0.0548,  0.4176,  0.6336,  0.8718, -0.0866,  0.5612,  0.8520,  1.1847,
         1.5172, -0.1652,  0.5601,  0.6554,  0.2347,  0.0313,  0.3983],
       device='cuda:0')
tensor([[0.0045]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0005]], device='cuda:0')
Original likelihood: -49.15222930908203
Adjusted likelihood: -49.15222930908203
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 49.15222930908203}
Current yaw: tensor([ 0.2472,  0.0317, -0.2566], device='cuda:0')
15 thumb_middle
tensor([ 0.0601,  0.4962,  0.6465,  0.8231, -0.1177,  0.5952,  0.8861,  1.1646,
         1.5000, -0.0699,  0.5745,  0.8717,  0.2472,  0.0317, -0.2566, -2.0133],
       device='cuda:0')
Solve time for step 1 8.732631733000744
Current ori: tensor([ 0.2472,  0.0317, -0.2566], device='cuda:0')
Index force: tensor([0.5990, 0.5862, 0.5941, 0.5749], device='cuda:0')
tensor([ 0.0727,  0.4949,  0.6511,  0.8618, -0.2270,  0.4310,  0.8295,  1.1544,
         1.5000, -0.1050,  0.5631,  0.7678,  0.2628,  0.0753, -0.2851, -1.9784],
       device='cuda:0')
Solve time for step 2 2.024609670974314
Current ori: tensor([ 0.2628,  0.0753, -0.2851], device='cuda:0')
Index force: tensor([0.5830, 0.5903, 0.5711], device='cuda:0')
tensor([ 0.0765,  0.4950,  0.6559,  0.8732, -0.2542,  0.3930,  0.8356,  1.1711,
         1.5000, -0.1050,  0.5638,  0.7406,  0.2728,  0.0868, -0.3210, -1.8523],
       device='cuda:0')
Solve time for step 3 1.9188387890171725
Current ori: tensor([ 0.2728,  0.0868, -0.3210], device='cuda:0')
Index force: tensor([0.6032, 0.5856], device='cuda:0')
tensor([ 0.0695,  0.4920,  0.6720,  0.8778, -0.2467,  0.4233,  0.8596,  1.1971,
         1.5000, -0.1050,  0.5934,  0.7113,  0.2818,  0.0956, -0.3480, -1.8597],
       device='cuda:0')
Solve time for step 4 1.8471130279940553
Current ori: tensor([ 0.2818,  0.0956, -0.3480], device='cuda:0')
Index force: tensor([0.5781], device='cuda:0')
Storing RECOVERY transition: reward=0.0773 (scaled=0.0773), steps=1
Reward stats updated: mean -0.0140 -> -0.0114, std: 0.1058
Collected 35 transitions for RL
Original likelihood: -92.24685668945312
Adjusted likelihood: -92.24685668945312
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 85.74958801269531
Projection step: 1, Loss: 85.35060119628906
Projection step: 2, Loss: 81.00108337402344
Projection step: 3, Loss: 85.32994842529297
Projection step: 4, Loss: 83.10118103027344
Projection step: 5, Loss: 85.55224609375
Projection step: 6, Loss: 80.50159454345703
Projection step: 7, Loss: 79.87449645996094
Projection step: 8, Loss: 82.41030883789062
Projection step: 9, Loss: 86.00701904296875
Projection step: 10, Loss: 81.47050476074219
Projection step: 11, Loss: 80.20632934570312
Projection step: 12, Loss: 80.05842590332031
Projection step: 13, Loss: 77.9114761352539
Projection step: 14, Loss: 80.38563537597656
Final likelihood: tensor([ -57.9105,  -67.7557,  -96.4832,  -82.6210,  -54.7517,  -71.8068,
         -77.5300,  -70.2072,  -62.6809,  -97.6142,  -81.1510,  -85.8310,
        -106.9238,  -73.2307,  -77.1105,  -90.0924])
Final projection likelihood: -78.3563
1 mode projection failed, trying anyway
New goal: tensor([ 9.6930e-02,  4.3022e-01,  6.9708e-01,  9.3330e-01, -1.8739e-01,
         4.8152e-01,  9.6213e-01,  1.2274e+00,  1.4213e+00,  1.0110e-03,
         7.3354e-01,  6.3539e-01,  2.6971e-01,  9.7887e-02,  2.3826e-01],
       device='cuda:0')
tensor([[0.0087]], device='cuda:0') tensor([[0.0015]], device='cuda:0') tensor([[-0.0002]], device='cuda:0')
Original likelihood: -88.00569915771484
Adjusted likelihood: -88.00569915771484
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 88.00569915771484}
Current yaw: tensor([ 0.2765,  0.0898, -0.3363], device='cuda:0')
16 thumb_middle
tensor([ 0.0981,  0.5050,  0.6690,  0.8853, -0.2129,  0.4448,  0.8365,  1.1870,
         1.5000, -0.0602,  0.7135,  0.7399,  0.2765,  0.0898, -0.3363, -1.8625],
       device='cuda:0')
Solve time for step 1 8.850140158989234
Current ori: tensor([ 0.2765,  0.0898, -0.3363], device='cuda:0')
Index force: tensor([0.5258, 0.6006, 0.6061, 0.5818], device='cuda:0')
tensor([ 0.0894,  0.5051,  0.6992,  0.9265, -0.3238,  0.2393,  0.9467,  1.2304,
         1.4303, -0.0287,  0.7104,  0.6598,  0.2907,  0.1027, -0.3822, -1.8723],
       device='cuda:0')
Solve time for step 2 1.9777438750024885
Current ori: tensor([ 0.2907,  0.1027, -0.3822], device='cuda:0')
Index force: tensor([0.5831, 0.5450, 0.5275], device='cuda:0')
tensor([ 0.0851,  0.5114,  0.7678,  0.9371, -0.3233,  0.2160,  0.9755,  1.2458,
         1.4438, -0.0091,  0.7204,  0.6440,  0.3082,  0.1119, -0.3814, -1.8537],
       device='cuda:0')
Solve time for step 3 1.8478743360028602
Current ori: tensor([ 0.3082,  0.1119, -0.3814], device='cuda:0')
Index force: tensor([0.5365, 0.5242], device='cuda:0')
tensor([ 0.0900,  0.5136,  0.7354,  0.9347, -0.3287,  0.2738,  0.9659,  1.2434,
         1.4530,  0.0046,  0.7291,  0.6500,  0.3064,  0.1106, -0.3715, -1.8563],
       device='cuda:0')
Solve time for step 4 1.8147094809974078
Current ori: tensor([ 0.3064,  0.1106, -0.3715], device='cuda:0')
Index force: tensor([0.5200], device='cuda:0')
Storing RECOVERY transition: reward=0.0743 (scaled=0.0743), steps=1
Reward stats updated: mean -0.0114 -> -0.0090, std: 0.1053
Collected 36 transitions for RL
Original likelihood: -134.2907257080078
Adjusted likelihood: -134.2907257080078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 142.917724609375
Projection step: 1, Loss: 129.9779052734375
Projection step: 2, Loss: 129.45333862304688
Projection step: 3, Loss: 123.04048156738281
Projection step: 4, Loss: 129.48135375976562
Projection step: 5, Loss: 127.37245178222656
Projection step: 6, Loss: 124.47071838378906
Projection step: 7, Loss: 118.58416748046875
Projection step: 8, Loss: 122.55307006835938
Projection step: 9, Loss: 119.60417175292969
Projection step: 10, Loss: 121.7318115234375
Projection step: 11, Loss: 123.42282104492188
Projection step: 12, Loss: 122.42251586914062
Projection step: 13, Loss: 123.84989929199219
Projection step: 14, Loss: 120.4875259399414
Final likelihood: tensor([-150.1040, -130.1587, -111.1563, -149.2559, -127.8770, -120.2192,
         -99.7054, -158.3454, -120.3114, -138.8991, -128.9895, -138.2354,
        -144.2894, -123.9055, -109.2911, -149.1553])
Final projection likelihood: -131.2437
1 mode projection failed, trying anyway
New goal: tensor([ 0.0815,  0.5152,  0.7375,  0.9541, -0.2851,  0.3315,  1.0588,  1.2852,
         1.4068,  0.1043,  0.8010,  0.7335,  0.2960,  0.1101, -0.1128],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0009]], device='cuda:0') tensor([[-0.0006]], device='cuda:0')
Original likelihood: -129.69027709960938
Adjusted likelihood: -129.69027709960938
Likelihood residual: 0.0
Original likelihood: -129.71371459960938
Adjusted likelihood: -129.71371459960938
Likelihood residual: 0.0
{'index': 129.71371459960938, 'thumb_middle': 129.69027709960938}
Current yaw: tensor([ 0.3014,  0.1052, -0.3627], device='cuda:0')
17 thumb_middle
tensor([ 0.1222,  0.5256,  0.7177,  0.9182, -0.2913,  0.3087,  0.9463,  1.2529,
         1.5000,  0.0504,  0.8048,  0.6847,  0.3014,  0.1052, -0.3627, -1.8969],
       device='cuda:0')
Solve time for step 1 9.086700351006584
Current ori: tensor([ 0.3014,  0.1052, -0.3627], device='cuda:0')
Index force: tensor([0.6550, 0.6249, 0.6011, 0.5700], device='cuda:0')
tensor([ 0.1095,  0.5217,  0.7350,  0.9528, -0.3137,  0.1299,  0.9772,  1.2457,
         1.3949,  0.0508,  0.7503,  0.7027,  0.3133,  0.1125, -0.3738, -2.0650],
       device='cuda:0')
Solve time for step 2 2.0388295610027853
Current ori: tensor([ 0.3133,  0.1125, -0.3738], device='cuda:0')
Index force: tensor([0.6144, 0.5785, 0.5718], device='cuda:0')
tensor([ 0.1134,  0.5235,  0.7343,  0.9638, -0.3079,  0.1232,  1.0024,  1.2679,
         1.3907,  0.0697,  0.7485,  0.7237,  0.3143,  0.1116, -0.3820, -2.1448],
       device='cuda:0')
Solve time for step 3 1.8568752669962123
Current ori: tensor([ 0.3143,  0.1116, -0.3820], device='cuda:0')
Index force: tensor([0.5805, 0.5663], device='cuda:0')
tensor([ 0.1126,  0.5240,  0.7454,  0.9603, -0.3050,  0.1312,  0.9960,  1.2852,
         1.4011,  0.0739,  0.7455,  0.7093,  0.3136,  0.1114, -0.3781, -2.1199],
       device='cuda:0')
Solve time for step 4 1.9270067799952812
Current ori: tensor([ 0.3136,  0.1114, -0.3781], device='cuda:0')
Index force: tensor([0.5543], device='cuda:0')
Storing RECOVERY transition: reward=0.0711 (scaled=0.0711), steps=1
Reward stats updated: mean -0.0090 -> -0.0068, std: 0.1047
Collected 37 transitions for RL
Original likelihood: -139.51486206054688
Adjusted likelihood: -139.51486206054688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 141.57337951660156
Projection step: 1, Loss: 143.94448852539062
Projection step: 2, Loss: 138.74925231933594
Projection step: 3, Loss: 143.19656372070312
Projection step: 4, Loss: 136.84530639648438
Projection step: 5, Loss: 142.83560180664062
Projection step: 6, Loss: 138.69577026367188
Projection step: 7, Loss: 134.7362060546875
Projection step: 8, Loss: 137.2077178955078
Projection step: 9, Loss: 138.02764892578125
Projection step: 10, Loss: 134.10794067382812
Projection step: 11, Loss: 143.37661743164062
Projection step: 12, Loss: 144.25997924804688
Projection step: 13, Loss: 133.41067504882812
Projection step: 14, Loss: 136.09825134277344
Final likelihood: tensor([ -97.0638, -114.0904, -138.9124, -151.7220, -122.0853, -114.7000,
        -148.2543, -131.5297, -125.6636, -165.5756, -184.9339, -154.3452,
        -147.3624, -158.1395, -100.2617, -182.4064])
Final projection likelihood: -139.8154
1 mode projection failed, trying anyway
New goal: tensor([ 0.0877,  0.5350,  0.7509,  1.0149, -0.3065,  0.1966,  1.0730,  1.3089,
         1.3553,  0.1382,  0.8150,  0.8462,  0.3076,  0.1133, -0.1383],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0016]], device='cuda:0') tensor([[-0.0005]], device='cuda:0')
Original likelihood: -127.34902954101562
Adjusted likelihood: -127.34902954101562
Likelihood residual: 0.0
Original likelihood: -130.46261596679688
Adjusted likelihood: -130.46261596679688
Likelihood residual: 0.0
{'index': 130.46261596679688, 'thumb_middle': 127.34902954101562}
Current yaw: tensor([ 0.3116,  0.1097, -0.3713], device='cuda:0')
18 thumb_middle
tensor([ 0.1217,  0.5277,  0.7298,  0.9607, -0.3018,  0.1751,  0.9961,  1.2716,
         1.4446,  0.1017,  0.8009,  0.7589,  0.3116,  0.1097, -0.3713, -2.1410],
       device='cuda:0')
Solve time for step 1 8.857416860992089
Current ori: tensor([ 0.3116,  0.1097, -0.3713], device='cuda:0')
Index force: tensor([0.7099, 0.5480, 0.6148, 0.5853], device='cuda:0')
tensor([ 0.0981,  0.5170,  0.7294,  1.0055, -0.3476, -0.0530,  0.9712,  1.2087,
         1.3361,  0.0898,  0.7525,  0.8033,  0.3210,  0.1165, -0.3810, -2.2075],
       device='cuda:0')
Solve time for step 2 1.900983804021962
Current ori: tensor([ 0.3210,  0.1165, -0.3810], device='cuda:0')
Index force: tensor([0.5404, 0.6103, 0.5810], device='cuda:0')
tensor([ 0.0892,  0.5144,  0.7313,  1.0178, -0.3383, -0.0413,  1.0030,  1.2347,
         1.3307,  0.0979,  0.7441,  0.8106,  0.3230,  0.1178, -0.3794, -2.2404],
       device='cuda:0')
Solve time for step 3 1.893265988008352
Current ori: tensor([ 0.3230,  0.1178, -0.3794], device='cuda:0')
Index force: tensor([0.6169, 0.5772], device='cuda:0')
tensor([ 0.0779,  0.5091,  0.7307,  1.0150, -0.3231, -0.0370,  1.0062,  1.2456,
         1.3389,  0.1036,  0.7462,  0.8193,  0.3332,  0.1222, -0.4274, -2.3167],
       device='cuda:0')
Solve time for step 4 1.86996316400473
Current ori: tensor([ 0.3332,  0.1222, -0.4274], device='cuda:0')
Index force: tensor([0.5570], device='cuda:0')
Storing RECOVERY transition: reward=0.0718 (scaled=0.0718), steps=1
Reward stats updated: mean -0.0068 -> -0.0048, std: 0.1040
Collected 38 transitions for RL
Original likelihood: -153.471435546875
Adjusted likelihood: -153.471435546875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 169.5150604248047
Projection step: 1, Loss: 153.6837158203125
Projection step: 2, Loss: 182.96054077148438
Projection step: 3, Loss: 171.33409118652344
Projection step: 4, Loss: 157.905029296875
Projection step: 5, Loss: 161.8096923828125
Projection step: 6, Loss: 173.80775451660156
Projection step: 7, Loss: 156.5491943359375
Projection step: 8, Loss: 159.17724609375
Projection step: 9, Loss: 160.11972045898438
Projection step: 10, Loss: 164.88442993164062
Projection step: 11, Loss: 171.04376220703125
Projection step: 12, Loss: 166.9150390625
Projection step: 13, Loss: 170.79220581054688
Projection step: 14, Loss: 166.39337158203125
Final likelihood: tensor([-133.4650, -163.8158, -129.8424, -181.5998, -165.3934, -140.7381,
        -152.0340, -174.9880, -216.8505, -206.3934, -221.9837, -191.7431,
        -179.5091, -194.4733, -161.6021, -122.8310])
Final projection likelihood: -171.0789
1 mode projection failed, trying anyway
New goal: tensor([ 0.0680,  0.5242,  0.7328,  1.0719, -0.3213,  0.0635,  1.0915,  1.3215,
         1.3060,  0.1494,  0.8142,  0.9484,  0.3242,  0.1206, -0.1832],
       device='cuda:0')
tensor([[0.0028]], device='cuda:0') tensor([[0.0016]], device='cuda:0') tensor([[-0.0004]], device='cuda:0')
Original likelihood: -153.46795654296875
Adjusted likelihood: -153.46795654296875
Likelihood residual: 0.0
Original likelihood: -154.29718017578125
Adjusted likelihood: -154.29718017578125
Likelihood residual: 0.0
{'index': 154.29718017578125, 'thumb_middle': 153.46795654296875}
Current yaw: tensor([ 0.3252,  0.1182, -0.3939], device='cuda:0')
19 thumb_middle
tensor([ 0.0893,  0.5128,  0.7179,  1.0156, -0.3150,  0.0556,  1.0276,  1.2904,
         1.3851,  0.1432,  0.8040,  0.8529,  0.3252,  0.1182, -0.3939, -2.3210],
       device='cuda:0')
Solve time for step 1 8.832473215996288
Current ori: tensor([ 0.3252,  0.1182, -0.3939], device='cuda:0')
Index force: tensor([0.5160, 0.5387, 0.5430, 0.5562], device='cuda:0')
tensor([ 8.8797e-02,  5.0369e-01,  8.1616e-01,  1.0615e+00, -3.5908e-01,
        -3.9473e-04,  1.0314e+00,  1.2496e+00,  1.2793e+00,  9.8218e-02,
         7.6524e-01,  9.0359e-01,  3.5317e-01,  1.3170e-01, -4.3770e-01,
        -2.3233e+00], device='cuda:0')
Solve time for step 2 1.8888375200040173
Current ori: tensor([ 0.3532,  0.1317, -0.4377], device='cuda:0')
Index force: tensor([0.5362, 0.5367, 0.5519], device='cuda:0')
tensor([ 0.0753,  0.5304,  0.8327,  1.0603, -0.3422, -0.0329,  1.0576,  1.2842,
         1.2871,  0.1190,  0.7605,  0.9157,  0.3628,  0.1499, -0.5043, -2.4273],
       device='cuda:0')
Solve time for step 3 1.8123496730113402
Current ori: tensor([ 0.3628,  0.1499, -0.5043], device='cuda:0')
Index force: tensor([0.5339, 0.5457], device='cuda:0')
tensor([ 0.0319,  0.5904,  0.7577,  1.0775, -0.3243, -0.0285,  1.0538,  1.2796,
         1.2903,  0.1107,  0.7790,  0.9360,  0.3638,  0.1490, -0.5458, -2.3396],
       device='cuda:0')
Solve time for step 4 1.7448957310116384
Current ori: tensor([ 0.3638,  0.1490, -0.5458], device='cuda:0')
Index force: tensor([0.5744], device='cuda:0')
Storing RECOVERY transition: reward=0.0927 (scaled=0.0927), steps=1
Reward stats updated: mean -0.0048 -> -0.0023, std: 0.1038
Collected 39 transitions for RL
Original likelihood: -241.67835998535156
Adjusted likelihood: -241.67835998535156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 217.1096649169922
Projection step: 1, Loss: 220.96917724609375
Projection step: 2, Loss: 229.111083984375
Projection step: 3, Loss: 225.8529815673828
Projection step: 4, Loss: 225.29966735839844
Projection step: 5, Loss: 228.68472290039062
Projection step: 6, Loss: 220.36036682128906
Projection step: 7, Loss: 228.4629364013672
Projection step: 8, Loss: 233.69619750976562
Projection step: 9, Loss: 225.71377563476562
Projection step: 10, Loss: 236.57015991210938
Projection step: 11, Loss: 234.32064819335938
Projection step: 12, Loss: 231.3959503173828
Projection step: 13, Loss: 223.90570068359375
Projection step: 14, Loss: 235.67605590820312
Final likelihood: tensor([-246.5248, -268.2237, -237.0094, -286.6572, -248.4954, -199.1107,
        -227.8626, -239.9846, -248.5783, -222.4900, -246.2567, -276.8413,
        -219.3823, -213.7549, -256.1362, -193.1947])
Final projection likelihood: -239.4064
1 mode projection failed, trying anyway
New goal: tensor([-0.0056,  0.6558,  0.7572,  1.1092, -0.2779, -0.0120,  1.0585,  1.2913,
         1.3024,  0.1975,  0.8496,  1.0213,  0.3687,  0.1515, -0.5793],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[-0.0051]], device='cuda:0') tensor([[0.0019]], device='cuda:0')
Original likelihood: -236.42034912109375
Adjusted likelihood: -236.42034912109375
Likelihood residual: 0.0
Original likelihood: -217.599609375
Adjusted likelihood: -217.599609375
Likelihood residual: 0.0
{'index': 217.599609375, 'thumb_middle': 236.42034912109375}
Current yaw: tensor([ 0.3684,  0.1512, -0.6329], device='cuda:0')
20 index
tensor([ 0.0037,  0.6491,  0.7644,  1.0753, -0.2726, -0.0127,  1.0226,  1.2797,
         1.3516,  0.1896,  0.8481,  0.9667,  0.3684,  0.1512, -0.6329, -1.9524],
       device='cuda:0')
Solve time for step 1 10.136983190983301
Current ori: tensor([ 0.3684,  0.1512, -0.6329], device='cuda:0')
Middle force: tensor([0.5100, 0.5941, 0.5678, 0.6036], device='cuda:0')
Thumb force: tensor([0.5855, 0.5785, 0.5759, 0.5314], device='cuda:0')
tensor([ 0.2942,  0.8849,  0.7908,  1.1125, -0.2766, -0.0269,  1.0172,  1.2447,
         1.3597,  0.2135,  0.8642,  0.9137,  0.3730,  0.1575, -0.6913, -1.8780],
       device='cuda:0')
Solve time for step 2 2.2268906109966338
Current ori: tensor([ 0.3730,  0.1575, -0.6913], device='cuda:0')
Middle force: tensor([0.5944, 0.5660, 0.6021], device='cuda:0')
Thumb force: tensor([0.5758, 0.5744, 0.5315], device='cuda:0')
tensor([ 0.3399,  0.9676,  0.7950,  1.1196, -0.2878, -0.0192,  0.9829,  1.2854,
         1.4025,  0.2106,  0.8536,  0.8699,  0.3733,  0.1601, -0.7090, -1.8054],
       device='cuda:0')
Solve time for step 3 2.095669898990309
Current ori: tensor([ 0.3733,  0.1601, -0.7090], device='cuda:0')
Middle force: tensor([0.5596, 0.5993], device='cuda:0')
Thumb force: tensor([0.5729, 0.5306], device='cuda:0')
tensor([ 0.2978,  0.8702,  0.8035,  1.1255, -0.2906, -0.0267,  0.9929,  1.2424,
         1.4124,  0.2233,  0.8315,  0.8880,  0.3748,  0.1627, -0.7267, -1.8173],
       device='cuda:0')
Solve time for step 4 1.9986948970181402
Current ori: tensor([ 0.3748,  0.1627, -0.7267], device='cuda:0')
Middle force: tensor([0.5426], device='cuda:0')
Thumb force: tensor([0.5698], device='cuda:0')
Storing RECOVERY transition: reward=0.0507 (scaled=0.0507), steps=1
Reward stats updated: mean -0.0023 -> -0.0009, std: 0.1029
Collected 40 transitions for RL
Original likelihood: -247.8555908203125
Adjusted likelihood: -247.8555908203125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 257.3600769042969
Projection step: 1, Loss: 267.7328796386719
Projection step: 2, Loss: 271.0938415527344
Projection step: 3, Loss: 262.92999267578125
Projection step: 4, Loss: 259.33441162109375
Projection step: 5, Loss: 267.1480712890625
Projection step: 6, Loss: 264.204345703125
Projection step: 7, Loss: 270.55615234375
Projection step: 8, Loss: 261.73040771484375
Projection step: 9, Loss: 265.2559814453125
Projection step: 10, Loss: 255.08984375
Projection step: 11, Loss: 261.0619201660156
Projection step: 12, Loss: 257.2094421386719
Projection step: 13, Loss: 266.0999450683594
Projection step: 14, Loss: 267.60107421875
Final likelihood: tensor([-252.0896, -274.5204, -267.3964, -298.7319, -265.6452, -301.4807,
        -255.5118, -257.6480, -295.5317, -250.9907, -253.3366, -271.0233,
        -247.7435, -264.9933, -226.5047, -269.5812])
Final projection likelihood: -265.7956
1 mode projection failed, trying anyway
New goal: tensor([-0.0355,  0.7744,  0.8064,  1.1570, -0.1943, -0.0188,  0.9460,  1.1718,
         1.3654,  0.2807,  0.8293,  0.9718,  0.3890,  0.1806, -0.7068],
       device='cuda:0')
Marked last transition as done (final step)
{}

Trial 3
Loaded trajectory sampler
Current yaw: tensor([-0.0021,  0.0145, -0.0311], device='cuda:0')
Current yaw: tensor([-0.0021,  0.0145, -0.0311], device='cuda:0')
1 turn
Sampling time 3.7999263209931087
tensor([ 0.1175,  0.6192,  0.5525,  0.5482, -0.1179,  0.5593,  0.8782,  0.8861,
         1.2157,  0.2793,  0.2581,  1.2236, -0.0021,  0.0145, -0.0311,  0.2435],
       device='cuda:0')
Original likelihood: -18.620670318603516
Adjusted likelihood: -18.620670318603516
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.319461676990613
Current ori: tensor([-0.0021,  0.0145, -0.0311], device='cuda:0')
Middle force: tensor([0.5504, 0.5745, 1.1804, 0.5667, 1.1496, 0.6449, 0.5327, 0.5326, 0.5129,
        0.5110, 0.5849, 0.6038], device='cuda:0')
Thumb force: tensor([0.8523, 0.8460, 0.7633, 1.0204, 0.9402, 0.6385, 0.5205, 0.8499, 0.5348,
        0.5822, 0.5941, 0.5851], device='cuda:0')
Index force: tensor([0.6030, 0.6070, 0.5511, 0.5709, 0.7983, 0.5323, 1.0120, 0.9378, 0.5943,
        0.5525, 0.5870, 0.5824], device='cuda:0')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0009 -> -0.0006, std: 0.1016
Collected 41 transitions for RL
tensor([ 0.1450,  0.6725,  0.5372,  0.4776, -0.1118,  0.5281,  0.8831,  0.9802,
         1.2204,  0.2009,  0.3060,  1.2064,  0.0191,  0.0021, -0.0444, -0.3259],
       device='cuda:0')
Original likelihood: -22.162843704223633
Adjusted likelihood: -22.162843704223633
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.0173235980037134
Current ori: tensor([ 0.0191,  0.0021, -0.0444], device='cuda:0')
Middle force: tensor([0.5710, 1.1724, 0.5632, 1.1306, 0.6394, 0.5325, 0.5387, 0.5115, 0.5093,
        0.5846, 0.6024], device='cuda:0')
Thumb force: tensor([0.8287, 0.7520, 1.0031, 0.9245, 0.6353, 0.5182, 0.8105, 0.5346, 0.5767,
        0.5867, 0.5802], device='cuda:0')
Index force: tensor([0.5996, 0.5469, 0.5671, 0.7912, 0.5307, 0.9984, 0.9198, 0.5905, 0.5517,
        0.5836, 0.5783], device='cuda:0')
Storing NORMAL transition: reward=0.1017 (scaled=0.1017), steps=1
Reward stats updated: mean -0.0006 -> 0.0018, std: 0.1016
Collected 42 transitions for RL
tensor([ 0.0212,  0.6397,  0.4821,  0.3956, -0.1008,  0.5199,  0.8932,  0.9928,
         1.2717,  0.1190,  0.3642,  0.9953,  0.0069, -0.0025, -0.1458, -0.6105],
       device='cuda:0')
Original likelihood: -20.129549026489258
Adjusted likelihood: -20.129549026489258
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7342032349843066
Current ori: tensor([ 0.0069, -0.0025, -0.1458], device='cuda:0')
Middle force: tensor([0.5009, 0.5505, 0.6873, 1.6632, 0.5072, 0.6192, 0.5433, 0.5990, 0.5811,
        0.5744], device='cuda:0')
Thumb force: tensor([0.5870, 0.5938, 0.5717, 1.4985, 0.5513, 1.2089, 0.8979, 0.9350, 0.6511,
        0.5528], device='cuda:0')
Index force: tensor([1.1111, 0.5754, 0.5163, 0.5563, 0.6504, 0.6820, 0.5022, 0.5478, 0.5682,
        0.5841], device='cuda:0')
Storing NORMAL transition: reward=-0.0255 (scaled=-0.0255), steps=1
Reward stats updated: mean 0.0018 -> 0.0012, std: 0.1005
Collected 43 transitions for RL
tensor([ 0.0488,  0.6211,  0.5330,  0.4134, -0.0800,  0.5338,  0.9108,  0.9938,
         1.1618,  0.2472,  0.3932,  0.8796,  0.0127, -0.0227, -0.1210, -0.5720],
       device='cuda:0')
Original likelihood: -28.156009674072266
Adjusted likelihood: -28.156009674072266
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8428)
Solve time for step 4 2.5832453010079917
Current ori: tensor([ 0.0127, -0.0227, -0.1210], device='cuda:0')
Middle force: tensor([0.5214, 0.5157, 0.5737, 0.5051, 0.6594, 0.5575, 0.5689, 0.5590, 0.5593],
       device='cuda:0')
Thumb force: tensor([0.6981, 0.5367, 0.8624, 0.7443, 0.9162, 0.5879, 0.5721, 0.5131, 0.5212],
       device='cuda:0')
Index force: tensor([0.7412, 0.5899, 0.5749, 0.5086, 0.5069, 0.5640, 0.6254, 0.7301, 0.5772],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0286 (scaled=-0.0286), steps=1
Reward stats updated: mean 0.0012 -> 0.0005, std: 0.0995
Collected 44 transitions for RL
tensor([ 0.0537,  0.6311,  0.5189,  0.4186, -0.0790,  0.5499,  0.9064,  0.9625,
         1.2172,  0.1999,  0.3643,  0.9415,  0.0106, -0.0247, -0.0924, -0.6109],
       device='cuda:0')
Original likelihood: -23.341289520263672
Adjusted likelihood: -23.341289520263672
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 5 2.4908316860091873
Current ori: tensor([ 0.0106, -0.0247, -0.0924], device='cuda:0')
Middle force: tensor([0.5156, 0.5733, 0.5052, 0.6615, 0.5555, 0.5681, 0.5621, 0.5580],
       device='cuda:0')
Thumb force: tensor([0.5337, 0.8518, 0.7354, 0.9072, 0.5843, 0.5685, 0.5119, 0.5203],
       device='cuda:0')
Index force: tensor([0.5835, 0.5714, 0.5073, 0.5060, 0.5623, 0.6206, 0.7173, 0.5745],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0765 (scaled=-0.0765), steps=1
Reward stats updated: mean 0.0005 -> -0.0012, std: 0.0990
Collected 45 transitions for RL
tensor([ 4.4431e-03,  6.3977e-01,  4.4663e-01,  4.5023e-01, -1.0912e-01,
         5.6309e-01,  8.9579e-01,  8.4697e-01,  1.1626e+00,  1.6742e-01,
         2.8130e-01,  9.6165e-01,  9.5905e-03,  5.8350e-04, -1.5224e-02,
        -7.3186e-01], device='cuda:0')
Original likelihood: -24.31522560119629
Adjusted likelihood: -24.31522560119629
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9990)
Solve time for step 6 2.405584527994506
Current ori: tensor([ 0.0096,  0.0006, -0.0152], device='cuda:0')
Middle force: tensor([0.5697, 0.5048, 0.6567, 0.5535, 0.5669, 0.5629, 0.5565],
       device='cuda:0')
Thumb force: tensor([0.8408, 0.7325, 0.9015, 0.5812, 0.5652, 0.5111, 0.5196],
       device='cuda:0')
Index force: tensor([0.5685, 0.5067, 0.5055, 0.5612, 0.6175, 0.7092, 0.5721],
       device='cuda:0')
Storing NORMAL transition: reward=0.0064 (scaled=0.0064), steps=1
Reward stats updated: mean -0.0012 -> -0.0010, std: 0.0979
Collected 46 transitions for RL
tensor([ 0.0496,  0.6281,  0.4826,  0.4710, -0.1083,  0.6491,  0.9777,  0.8977,
         1.2057,  0.2390,  0.2374,  1.0115, -0.0077, -0.0689, -0.0261, -0.0689],
       device='cuda:0')
Original likelihood: -28.698528289794922
Adjusted likelihood: -28.698528289794922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7612)
Solve time for step 7 2.252374276984483
Current ori: tensor([-0.0077, -0.0689, -0.0261], device='cuda:0')
Middle force: tensor([0.5056, 0.6791, 0.5526, 0.5695, 0.5767, 0.5568], device='cuda:0')
Thumb force: tensor([0.7207, 0.8875, 0.5784, 0.5620, 0.5101, 0.5184], device='cuda:0')
Index force: tensor([0.5051, 0.5043, 0.5584, 0.6078, 0.6791, 0.5686], device='cuda:0')
Storing NORMAL transition: reward=-0.0275 (scaled=-0.0275), steps=1
Reward stats updated: mean -0.0010 -> -0.0016, std: 0.0970
Collected 47 transitions for RL
tensor([ 0.0936,  0.6028,  0.4669,  0.3983, -0.0744,  0.7001,  0.9052,  0.9950,
         1.1488,  0.1603,  0.2668,  1.0495,  0.0095, -0.0978, -0.0027,  0.4050],
       device='cuda:0')
Original likelihood: -35.691688537597656
Adjusted likelihood: -35.691688537597656
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0009)
State is out of distribution
Projection step: 0, Loss: 35.657440185546875
Projection step: 1, Loss: 33.32387924194336
Projection step: 2, Loss: 33.57294845581055
Projection step: 3, Loss: 29.971038818359375
Projection step: 4, Loss: 28.59658432006836
Projection step: 5, Loss: 28.072172164916992
Projection step: 6, Loss: 32.313175201416016
Projection step: 7, Loss: 27.775957107543945
Projection step: 8, Loss: 27.36300277709961
Projection step: 9, Loss: 26.27666664123535
Projection step: 10, Loss: 24.974334716796875
Projection step: 11, Loss: 25.082252502441406
Projection step: 12, Loss: 24.68141746520996
Projection step: 13, Loss: 23.94163703918457
Projection step: 14, Loss: 22.69820785522461
Final likelihood: tensor([-21.6572, -24.3200, -20.8915, -19.4601, -22.1204, -22.9541, -22.9590,
        -22.6492, -20.4656, -24.1732, -21.0187, -27.1215, -23.1277, -19.7152,
        -23.0697, -22.3705])
Final projection likelihood: -22.3796
1 mode projection succeeded
New goal: tensor([ 0.0978,  0.5451,  0.5847,  0.6065,  0.0042,  0.6209,  0.8287,  0.7982,
         1.3203,  0.2362,  0.2040,  0.9748,  0.0025, -0.0738, -1.0916],
       device='cuda:0')
tensor([[0.0020]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0103]], device='cuda:0')
Original likelihood: -32.91196060180664
Adjusted likelihood: -32.91196060180664
Likelihood residual: 0.0
{'index': 32.91196060180664, 'thumb_middle': inf}
Current yaw: tensor([ 0.0095, -0.0978, -0.0027], device='cuda:0')
2 index
tensor([ 0.0936,  0.6028,  0.4669,  0.3983, -0.0744,  0.7001,  0.9052,  0.9950,
         1.1488,  0.1603,  0.2668,  1.0495,  0.0095, -0.0978, -0.0027,  0.4050],
       device='cuda:0')
Solve time for step 1 10.49616119498387
Current ori: tensor([ 0.0095, -0.0978, -0.0027], device='cuda:0')
Middle force: tensor([0.5924, 0.5552, 0.5461, 0.5437], device='cuda:0')
Thumb force: tensor([0.5791, 0.5660, 0.5784, 0.5560], device='cuda:0')
tensor([ 0.1181,  0.5217,  0.5206,  0.5373, -0.0663,  0.7156,  0.9257,  0.8933,
         1.1891,  0.1152,  0.2544,  0.9810, -0.0170, -0.1034, -0.0103,  0.7551],
       device='cuda:0')
Solve time for step 2 2.3147995799954515
Current ori: tensor([-0.0170, -0.1034, -0.0103], device='cuda:0')
Middle force: tensor([0.5512, 0.5449, 0.5422], device='cuda:0')
Thumb force: tensor([0.5651, 0.5759, 0.5540], device='cuda:0')
tensor([ 0.1192,  0.5142,  0.5355,  0.5678, -0.0714,  0.7238,  0.9308,  0.8721,
         1.1953,  0.1117,  0.2574,  0.9485, -0.0276, -0.1043, -0.0179,  1.2953],
       device='cuda:0')
Solve time for step 3 2.0820010410097893
Current ori: tensor([-0.0276, -0.1043, -0.0179], device='cuda:0')
Middle force: tensor([0.5408, 0.5404], device='cuda:0')
Thumb force: tensor([0.5748, 0.5516], device='cuda:0')
tensor([ 0.1178,  0.5148,  0.5417,  0.5733, -0.0654,  0.7281,  0.9320,  0.8688,
         1.1846,  0.1259,  0.2512,  0.9503, -0.0292, -0.1094, -0.0262,  2.1552],
       device='cuda:0')
Solve time for step 4 2.0589562930108514
Current ori: tensor([-0.0292, -0.1094, -0.0262], device='cuda:0')
Middle force: tensor([0.5893], device='cuda:0')
Thumb force: tensor([0.5841], device='cuda:0')
Storing RECOVERY transition: reward=0.0235 (scaled=0.0034), steps=7
Reward stats updated: mean -0.0016 -> -0.0015, std: 0.0959
Collected 48 transitions for RL
Original likelihood: -36.22749328613281
Adjusted likelihood: -36.22749328613281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0003)
State is out of distribution
Projection step: 0, Loss: 36.86150360107422
Projection step: 1, Loss: 34.40857696533203
Projection step: 2, Loss: 33.52772521972656
Projection step: 3, Loss: 32.08576202392578
Projection step: 4, Loss: 31.95557403564453
Projection step: 5, Loss: 29.294103622436523
Projection step: 6, Loss: 32.14479064941406
Projection step: 7, Loss: 31.385894775390625
Projection step: 8, Loss: 27.877403259277344
Projection step: 9, Loss: 27.71733856201172
Projection step: 10, Loss: 26.677745819091797
Projection step: 11, Loss: 28.236467361450195
Projection step: 12, Loss: 27.6234188079834
Projection step: 13, Loss: 26.92749786376953
Projection step: 14, Loss: 25.631717681884766
Final likelihood: tensor([-23.2981, -22.6656, -23.3186, -33.7593, -24.3672, -21.7176, -23.5221,
        -28.7192, -40.3575, -31.9247, -32.3131, -22.0999, -22.8742, -23.2108,
        -24.7000, -23.0239])
Final projection likelihood: -26.3670
1 mode projection succeeded
New goal: tensor([ 0.1193,  0.4908,  0.6705,  0.6111, -0.0172,  0.6840,  0.8889,  0.7832,
         1.3503,  0.2647,  0.1292,  0.9001, -0.0335, -0.1014, -0.7389],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0020]], device='cuda:0')
Original likelihood: -28.420520782470703
Adjusted likelihood: -28.420520782470703
Likelihood residual: 0.0
Original likelihood: -45.39406967163086
Adjusted likelihood: -45.39406967163086
Likelihood residual: 0.0
{'index': 45.39406967163086, 'thumb_middle': 28.420520782470703}
Current yaw: tensor([-0.0441, -0.1203, -0.0331], device='cuda:0')
3 thumb_middle
tensor([ 0.0851,  0.5734,  0.5872,  0.5986, -0.0717,  0.7517,  0.9407,  0.8667,
         1.1954,  0.1103,  0.2213,  0.9447, -0.0441, -0.1203, -0.0331,  1.7626],
       device='cuda:0')
Solve time for step 1 8.965037525020307
Current ori: tensor([-0.0441, -0.1203, -0.0331], device='cuda:0')
Index force: tensor([0.5826, 0.5937, 0.6002, 0.5974], device='cuda:0')
tensor([ 0.0705,  0.5662,  0.7096,  0.6251, -0.0813,  0.6914,  0.8845,  0.7851,
         1.2441,  0.2110,  0.0155,  0.8451, -0.1000, -0.2125, -0.0408,  2.2556],
       device='cuda:0')
Solve time for step 2 2.1309257120010443
Current ori: tensor([-0.1000, -0.2125, -0.0408], device='cuda:0')
Index force: tensor([0.5833, 0.5957, 0.5911], device='cuda:0')
tensor([ 0.0319,  0.5965,  0.7394,  0.6565, -0.0598,  0.7195,  0.8955,  0.7860,
         1.2381,  0.2237, -0.0687,  0.8036, -0.1440, -0.2703, -0.0305,  3.2684],
       device='cuda:0')
Solve time for step 3 1.9949314029945526
Current ori: tensor([-0.1440, -0.2703, -0.0305], device='cuda:0')
Index force: tensor([0.5358, 0.5479], device='cuda:0')
tensor([-0.0049,  0.6341,  0.7921,  0.6688, -0.0568,  0.7593,  0.9082,  0.7909,
         1.2364,  0.2214, -0.1276,  0.7871, -0.1731, -0.3076,  0.0070,  3.4533],
       device='cuda:0')
Solve time for step 4 1.8031395449943375
Current ori: tensor([-0.1731, -0.3076,  0.0070], device='cuda:0')
Index force: tensor([0.5376], device='cuda:0')
Storing RECOVERY transition: reward=-0.1338 (scaled=-0.0191), steps=7
Reward stats updated: mean -0.0015 -> -0.0018, std: 0.0950
Collected 49 transitions for RL
Original likelihood: -208.82591247558594
Adjusted likelihood: -208.82591247558594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 220.8329620361328
Projection step: 1, Loss: 214.66302490234375
Projection step: 2, Loss: 233.82394409179688
Projection step: 3, Loss: 228.45663452148438
Projection step: 4, Loss: 212.66822814941406
Projection step: 5, Loss: 221.61566162109375
Projection step: 6, Loss: 225.70449829101562
Projection step: 7, Loss: 223.25582885742188
Projection step: 8, Loss: 223.4007568359375
Projection step: 9, Loss: 213.46551513671875
Projection step: 10, Loss: 221.5032196044922
Projection step: 11, Loss: 217.78164672851562
Projection step: 12, Loss: 223.40284729003906
Projection step: 13, Loss: 215.41595458984375
Projection step: 14, Loss: 226.09523010253906
Final likelihood: tensor([-130.8775, -243.1706, -214.4733, -227.3017, -240.8570, -218.2010,
        -215.4284, -221.8684, -216.4639, -243.8185, -219.8023, -190.4294,
        -229.1223, -210.8218, -235.9666, -245.4185])
Final projection likelihood: -219.0013
1 mode projection failed, trying anyway
New goal: tensor([-0.0159,  0.6998,  0.8126,  0.7162,  0.0572,  0.8567,  0.9404,  0.7968,
         1.2333,  0.2552, -0.1078,  0.8356, -0.1911, -0.2772,  0.1620],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0113]], device='cuda:0') tensor([[0.0134]], device='cuda:0')
Original likelihood: -223.46240234375
Adjusted likelihood: -223.46240234375
Likelihood residual: 0.0
Original likelihood: -165.16529846191406
Adjusted likelihood: -165.16529846191406
Likelihood residual: 0.0
{'index': 165.16529846191406, 'thumb_middle': 223.46240234375}
Current yaw: tensor([-0.1934, -0.2780,  0.0516], device='cuda:0')
4 index
tensor([-0.0336,  0.7078,  0.8211,  0.6963,  0.0694,  0.8835,  0.9222,  0.7639,
         1.2451,  0.2362, -0.1047,  0.7973, -0.1934, -0.2780,  0.0516,  2.7715],
       device='cuda:0')
Solve time for step 1 10.376842581987148
Current ori: tensor([-0.1934, -0.2780,  0.0516], device='cuda:0')
Middle force: tensor([0.5718, 0.5597, 0.5303, 0.5096], device='cuda:0')
Thumb force: tensor([0.5697, 0.5175, 0.5609, 0.5787], device='cuda:0')
tensor([-0.0709,  0.6818,  0.8007,  0.7044,  0.0955,  0.9660,  0.9248,  0.7446,
         1.2314,  0.2632, -0.1207,  0.8375, -0.2006, -0.2794,  0.1449,  2.3320],
       device='cuda:0')
Solve time for step 2 2.269927133980673
Current ori: tensor([-0.2006, -0.2794,  0.1449], device='cuda:0')
Middle force: tensor([0.5515, 0.5279, 0.5079], device='cuda:0')
Thumb force: tensor([0.5176, 0.5596, 0.5782], device='cuda:0')
tensor([-0.0569,  0.7202,  0.8198,  0.7116,  0.0932,  1.0418,  0.9416,  0.7430,
         1.2347,  0.2607, -0.1599,  0.8015, -0.2413, -0.3083,  0.2396,  2.5202],
       device='cuda:0')
Solve time for step 3 2.2533787229913287
Current ori: tensor([-0.2413, -0.3083,  0.2396], device='cuda:0')
Middle force: tensor([0.5242, 0.5061], device='cuda:0')
Thumb force: tensor([0.5548, 0.5782], device='cuda:0')
tensor([-0.0512,  0.7669,  0.8213,  0.7033,  0.0934,  1.0940,  0.9437,  0.7398,
         1.2551,  0.2176, -0.1647,  0.7058, -0.3129, -0.3267,  0.3651,  2.5446],
       device='cuda:0')
Solve time for step 4 2.0940456239914056
Current ori: tensor([-0.3129, -0.3267,  0.3651], device='cuda:0')
Middle force: tensor([0.5040], device='cuda:0')
Thumb force: tensor([0.5752], device='cuda:0')
Storing RECOVERY transition: reward=-0.6914 (scaled=-0.0988), steps=7
Reward stats updated: mean -0.0018 -> -0.0038, std: 0.0950
Collected 50 transitions for RL
Original likelihood: -440.7535095214844
Adjusted likelihood: -440.7535095214844
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 4
Loaded trajectory sampler
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:0')
Current yaw: tensor([-0.0011,  0.0145, -0.0305], device='cuda:0')
1 turn
Sampling time 3.910455690987874
tensor([ 1.0985e-01,  6.3268e-01,  5.3615e-01,  5.2828e-01, -1.0033e-01,
         5.5535e-01,  8.5900e-01,  8.9148e-01,  1.2380e+00,  3.0683e-01,
         2.2876e-01,  1.1836e+00, -1.1403e-03,  1.4469e-02, -3.0450e-02,
         5.5898e-02], device='cuda:0')
Original likelihood: -15.65234661102295
Adjusted likelihood: -15.65234661102295
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.733662354992703
Current ori: tensor([-0.0011,  0.0145, -0.0305], device='cuda:0')
Middle force: tensor([0.5208, 0.4966, 1.2606, 1.2722, 0.5822, 0.5357, 0.5043, 0.5752, 0.5590,
        0.5731, 0.6016, 0.6102], device='cuda:0')
Thumb force: tensor([0.7172, 0.5880, 1.1813, 1.0875, 0.6756, 0.8587, 0.5272, 1.1801, 0.6434,
        0.5909, 0.6044, 0.6064], device='cuda:0')
Index force: tensor([0.5091, 0.6681, 0.5827, 0.5351, 0.9045, 0.5433, 0.5886, 0.4978, 0.5228,
        0.6052, 0.6100, 0.6081], device='cuda:0')
Storing NORMAL transition: reward=-0.0400 (scaled=-0.0400), steps=1
Reward stats updated: mean -0.0038 -> -0.0045, std: 0.0942
Collected 51 transitions for RL
tensor([ 0.1506,  0.6813,  0.5439,  0.4423, -0.1105,  0.4929,  0.8650,  1.0080,
         1.3196,  0.1820,  0.1553,  1.2535, -0.0071,  0.0049,  0.0097, -0.4035],
       device='cuda:0')
Original likelihood: -21.27909278869629
Adjusted likelihood: -21.27909278869629
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.09136345598381
Current ori: tensor([-0.0071,  0.0049,  0.0097], device='cuda:0')
Middle force: tensor([0.5006, 1.2428, 1.2642, 0.5631, 0.5325, 0.5036, 0.5696, 0.5552, 0.5677,
        0.5925, 0.6069], device='cuda:0')
Thumb force: tensor([0.5829, 1.1621, 1.0675, 0.6876, 0.8521, 0.5305, 1.1677, 0.6394, 0.5907,
        0.6061, 0.6038], device='cuda:0')
Index force: tensor([0.6588, 0.5798, 0.5329, 0.9031, 0.5430, 0.5822, 0.5004, 0.5214, 0.6015,
        0.6082, 0.6046], device='cuda:0')
Storing NORMAL transition: reward=-0.0584 (scaled=-0.0584), steps=1
Reward stats updated: mean -0.0045 -> -0.0055, std: 0.0936
Collected 52 transitions for RL
tensor([ 1.4185e-01,  6.5802e-01,  5.6324e-01,  4.6736e-01, -9.8395e-02,
         5.1354e-01,  8.6042e-01,  1.0058e+00,  1.2183e+00,  2.8186e-01,
         2.5421e-01,  1.2208e+00, -9.7635e-05,  6.4721e-03,  6.8092e-02,
        -3.6467e-01], device='cuda:0')
Original likelihood: -17.37194061279297
Adjusted likelihood: -17.37194061279297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 3 2.7908382150053512
Current ori: tensor([-9.7635e-05,  6.4721e-03,  6.8092e-02], device='cuda:0')
Middle force: tensor([1.2258, 1.2586, 0.5504, 0.5308, 0.5033, 0.5670, 0.5522, 0.5645, 0.5886,
        0.6041], device='cuda:0')
Thumb force: tensor([1.1361, 1.0458, 0.6910, 0.8425, 0.5293, 1.1523, 0.6352, 0.5880, 0.6029,
        0.6003], device='cuda:0')
Index force: tensor([0.5748, 0.5299, 0.9062, 0.5418, 0.5792, 0.5003, 0.5202, 0.5986, 0.6061,
        0.6015], device='cuda:0')
Storing NORMAL transition: reward=-0.0962 (scaled=-0.0962), steps=1
Reward stats updated: mean -0.0055 -> -0.0072, std: 0.0935
Collected 53 transitions for RL
tensor([ 0.0854,  0.6853,  0.4393,  0.4964, -0.2038,  0.4503,  0.8866,  1.0308,
         1.3113,  0.2016,  0.3091,  1.2593,  0.0331,  0.0645,  0.1607, -1.4600],
       device='cuda:0')
Original likelihood: -33.86119842529297
Adjusted likelihood: -33.86119842529297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0176)
State is out of distribution
Projection step: 0, Loss: 33.386146545410156
Projection step: 1, Loss: 29.587425231933594
Projection step: 2, Loss: 27.414215087890625
Projection step: 3, Loss: 26.236778259277344
Projection step: 4, Loss: 25.28759002685547
Projection step: 5, Loss: 25.687732696533203
Projection step: 6, Loss: 23.676010131835938
Projection step: 7, Loss: 23.31537628173828
Projection step: 8, Loss: 22.347347259521484
Projection step: 9, Loss: 21.026424407958984
Projection step: 10, Loss: 20.536039352416992
Projection step: 11, Loss: 20.581087112426758
Projection step: 12, Loss: 18.10441017150879
Projection step: 13, Loss: 18.743688583374023
Projection step: 14, Loss: 18.419296264648438
Final likelihood: tensor([-17.6277, -16.5774, -14.5251, -14.3401, -13.5232, -17.5451, -19.7091,
        -15.1559, -19.6445, -16.4822, -17.0426, -15.7288, -19.9198, -14.1963,
        -17.6624, -19.2068])
Final projection likelihood: -16.8054
1 mode projection succeeded
New goal: tensor([ 0.0641,  0.6574,  0.4473,  0.5370, -0.1190,  0.4453,  0.8472,  0.9125,
         1.3200,  0.1666,  0.2128,  1.1458,  0.0344,  0.0314, -2.1623],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0025]], device='cuda:0')
Original likelihood: -27.96064567565918
Adjusted likelihood: -27.96064567565918
Likelihood residual: 0.0
Original likelihood: -30.750675201416016
Adjusted likelihood: -30.750675201416016
Likelihood residual: 0.0
{'index': 30.750675201416016, 'thumb_middle': 27.96064567565918}
Current yaw: tensor([0.0331, 0.0645, 0.1607], device='cuda:0')
2 thumb_middle
tensor([ 0.0854,  0.6853,  0.4393,  0.4964, -0.2038,  0.4503,  0.8866,  1.0308,
         1.3113,  0.2016,  0.3091,  1.2593,  0.0331,  0.0645,  0.1607, -1.4600],
       device='cuda:0')
Solve time for step 1 9.140009733993793
Current ori: tensor([0.0331, 0.0645, 0.1607], device='cuda:0')
Index force: tensor([0.5469, 0.5799, 0.5891, 0.5843], device='cuda:0')
tensor([ 0.1032,  0.7026,  0.4333,  0.4971, -0.2224,  0.4313,  0.8356,  0.9241,
         1.3089,  0.1586,  0.1767,  1.1439,  0.0279,  0.0545,  0.1607, -1.4277],
       device='cuda:0')
Solve time for step 2 2.1243577800050844
Current ori: tensor([0.0279, 0.0545, 0.1607], device='cuda:0')
Index force: tensor([0.5750, 0.5859, 0.5813], device='cuda:0')
tensor([ 0.1079,  0.7033,  0.4391,  0.4934, -0.2192,  0.4421,  0.8405,  0.9063,
         1.3286,  0.1594,  0.1512,  1.1239,  0.0272,  0.0518,  0.1607, -1.4241],
       device='cuda:0')
Solve time for step 3 1.972358658007579
Current ori: tensor([0.0272, 0.0518, 0.1607], device='cuda:0')
Index force: tensor([0.5812, 0.5777], device='cuda:0')
tensor([ 0.0971,  0.7063,  0.4245,  0.4909, -0.2241,  0.4437,  0.8385,  0.9024,
         1.3374,  0.1596,  0.1486,  1.1257,  0.0275,  0.0573,  0.1607, -1.4454],
       device='cuda:0')
Solve time for step 4 1.785473046998959
Current ori: tensor([0.0275, 0.0573, 0.1607], device='cuda:0')
Index force: tensor([0.5684], device='cuda:0')
Storing RECOVERY transition: reward=0.0004 (scaled=0.0001), steps=3
Reward stats updated: mean -0.0072 -> -0.0071, std: 0.0927
Collected 54 transitions for RL
Original likelihood: -27.279434204101562
Adjusted likelihood: -27.279434204101562
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9312)
Current yaw: tensor([0.0315, 0.0531, 0.1613], device='cuda:0')
3 turn
Sampling time 3.8658785019943025
tensor([ 0.0974,  0.6943,  0.4365,  0.5028, -0.1632,  0.4791,  0.8713,  0.9214,
         1.3972,  0.1902,  0.1962,  1.1647,  0.0315,  0.0531,  0.1613, -1.5550],
       device='cuda:0')
Original likelihood: -27.9627685546875
Adjusted likelihood: -27.9627685546875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8669)
Solve time for step 1 14.588311970990617
Current ori: tensor([0.0315, 0.0531, 0.1613], device='cuda:0')
Middle force: tensor([0.6866, 0.7220, 0.4932, 0.5893, 1.4907, 0.4777, 0.4310, 0.4764, 0.5731,
        0.6920, 0.5266, 0.4538], device='cuda:0')
Thumb force: tensor([1.7145, 0.5372, 1.3070, 3.0723, 1.1917, 0.5117, 0.7942, 0.5222, 0.5328,
        0.5151, 1.6127, 0.6076], device='cuda:0')
Index force: tensor([0.5053, 0.5123, 0.7429, 0.7741, 0.6636, 0.6328, 0.6655, 0.5205, 0.5454,
        0.5271, 0.5624, 0.5602], device='cuda:0')
Storing NORMAL transition: reward=0.0280 (scaled=0.0280), steps=1
Reward stats updated: mean -0.0071 -> -0.0065, std: 0.0919
Collected 55 transitions for RL
tensor([ 0.1235,  0.8041,  0.2961,  0.4410, -0.1867,  0.3930,  0.9343,  1.1414,
         1.3377,  0.5140,  0.2780,  0.8703,  0.0040,  0.0483,  0.1346, -1.4444],
       device='cuda:0')
Original likelihood: -40.175201416015625
Adjusted likelihood: -40.175201416015625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 42.69850540161133
Projection step: 1, Loss: 35.7834587097168
Projection step: 2, Loss: 34.13372802734375
Projection step: 3, Loss: 29.36545181274414
Projection step: 4, Loss: 27.930870056152344
Projection step: 5, Loss: 24.206645965576172
Projection step: 6, Loss: 21.778152465820312
Projection step: 7, Loss: 19.553993225097656
Projection step: 8, Loss: 17.91434097290039
Projection step: 9, Loss: 17.018123626708984
Projection step: 10, Loss: 15.702469825744629
Projection step: 11, Loss: 14.700859069824219
Final likelihood: tensor([-17.4113, -11.1854, -15.1739, -16.4639, -14.2214, -13.2862, -14.4578,
        -14.7260, -13.3695, -14.2718, -13.0517, -15.0612, -17.0872, -15.7085,
        -12.7429, -16.9948])
Final projection likelihood: -14.7009
1 mode projection succeeded
New goal: tensor([ 0.0996,  0.7263,  0.3805,  0.4473, -0.1044,  0.3698,  0.7286,  1.1489,
         1.3058,  0.3276,  0.1500,  1.0777, -0.0038,  0.0202, -2.8388],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0043]], device='cuda:0') tensor([[0.0033]], device='cuda:0')
Original likelihood: -29.06077766418457
Adjusted likelihood: -29.06077766418457
Likelihood residual: 0.0
Original likelihood: -19.21828842163086
Adjusted likelihood: -19.21828842163086
Likelihood residual: 0.0
{'index': 19.21828842163086, 'thumb_middle': 29.06077766418457}
Current yaw: tensor([0.0040, 0.0483, 0.1346], device='cuda:0')
4 index
tensor([ 0.1235,  0.8041,  0.2961,  0.4410, -0.1867,  0.3930,  0.9343,  1.1414,
         1.3377,  0.5140,  0.2780,  0.8703,  0.0040,  0.0483,  0.1346, -1.4444],
       device='cuda:0')
Solve time for step 1 10.278831862000516
Current ori: tensor([0.0040, 0.0483, 0.1346], device='cuda:0')
Middle force: tensor([0.5789, 0.5938, 0.5488, 0.5348], device='cuda:0')
Thumb force: tensor([0.5535, 0.5237, 0.5428, 0.5941], device='cuda:0')
tensor([ 0.1572,  0.6664,  0.3195,  0.4401, -0.1409,  0.4574,  0.8742,  1.2093,
         1.4043,  0.3986,  0.1480,  0.9757,  0.0039,  0.0262,  0.1257, -1.9139],
       device='cuda:0')
Solve time for step 2 2.265999709983589
Current ori: tensor([0.0039, 0.0262, 0.1257], device='cuda:0')
Middle force: tensor([0.5904, 0.5035, 0.5955], device='cuda:0')
Thumb force: tensor([0.5701, 0.5271, 0.5384], device='cuda:0')
tensor([ 1.5348e-01,  6.6359e-01,  3.3557e-01,  4.4120e-01, -1.2235e-01,
         4.7686e-01,  8.5870e-01,  1.2170e+00,  1.4154e+00,  3.7412e-01,
         1.0872e-01,  1.0047e+00, -7.4865e-05,  1.5093e-02,  1.2130e-01,
        -2.0825e+00], device='cuda:0')
Solve time for step 3 2.187594780989457
Current ori: tensor([-7.4865e-05,  1.5093e-02,  1.2130e-01], device='cuda:0')
Middle force: tensor([0.5300, 0.5710], device='cuda:0')
Thumb force: tensor([0.6004, 0.5843], device='cuda:0')
tensor([ 0.1468,  0.6616,  0.3413,  0.4404, -0.1113,  0.4886,  0.8523,  1.2129,
         1.4174,  0.3750,  0.0886,  1.0139, -0.0055,  0.0092,  0.1121, -2.1254],
       device='cuda:0')
Solve time for step 4 2.1592039150127675
Current ori: tensor([-0.0055,  0.0092,  0.1121], device='cuda:0')
Middle force: tensor([0.5899], device='cuda:0')
Thumb force: tensor([0.5340], device='cuda:0')
Storing RECOVERY transition: reward=0.0061 (scaled=0.0061), steps=1
Reward stats updated: mean -0.0065 -> -0.0062, std: 0.0911
Collected 56 transitions for RL
Original likelihood: -19.52094841003418
Adjusted likelihood: -19.52094841003418
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([-0.0094,  0.0070,  0.1307], device='cuda:0')
5 turn
Sampling time 3.6668707790086046
tensor([ 0.0942,  0.7392,  0.3843,  0.4526, -0.1080,  0.4998,  0.8423,  1.2013,
         1.4165,  0.3739,  0.0825,  1.0176, -0.0094,  0.0070,  0.1307, -2.1538],
       device='cuda:0')
Original likelihood: -19.027751922607422
Adjusted likelihood: -19.027751922607422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.2409039720078
Current ori: tensor([-0.0094,  0.0070,  0.1307], device='cuda:0')
Middle force: tensor([0.5960, 0.5621, 1.1686, 0.5820, 1.2512, 0.6450, 0.5500, 0.5472, 0.5220,
        0.8984, 0.7378, 0.6595], device='cuda:0')
Thumb force: tensor([0.9266, 0.8468, 0.7749, 1.0452, 0.8389, 0.6239, 0.5210, 0.9202, 0.5398,
        0.5220, 0.6751, 0.5874], device='cuda:0')
Index force: tensor([0.5904, 0.6056, 0.5740, 0.5837, 0.8111, 0.5210, 0.9996, 0.9261, 0.5866,
        0.5893, 0.7341, 0.5772], device='cuda:0')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0062 -> -0.0059, std: 0.0904
Collected 57 transitions for RL
tensor([ 0.0939,  0.7401,  0.3881,  0.4198, -0.1158,  0.4023,  0.7914,  1.2694,
         1.4245,  0.4466,  0.0304,  1.0695, -0.0119,  0.0090,  0.1174, -2.1425],
       device='cuda:0')
Original likelihood: -18.787456512451172
Adjusted likelihood: -18.787456512451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 3.1469882329984102
Current ori: tensor([-0.0119,  0.0090,  0.1174], device='cuda:0')
Middle force: tensor([0.5600, 1.1577, 0.5801, 1.2418, 0.6380, 0.5511, 0.5442, 0.5212, 0.8884,
        0.7294, 0.6549], device='cuda:0')
Thumb force: tensor([0.8357, 0.7676, 1.0333, 0.8260, 0.6241, 0.5188, 0.9154, 0.5377, 0.5208,
        0.6726, 0.5853], device='cuda:0')
Index force: tensor([0.5999, 0.5740, 0.5813, 0.8121, 0.5206, 0.9891, 0.9242, 0.5847, 0.5904,
        0.7322, 0.5770], device='cuda:0')
Storing NORMAL transition: reward=0.0793 (scaled=0.0793), steps=1
Reward stats updated: mean -0.0059 -> -0.0044, std: 0.0903
Collected 58 transitions for RL
tensor([ 0.1283,  0.7419,  0.4226,  0.4458, -0.0807,  0.3866,  1.0606,  1.2506,
         1.4332,  0.4296,  0.0202,  1.0458, -0.0100, -0.0065,  0.0381, -1.8706],
       device='cuda:0')
Original likelihood: -23.920928955078125
Adjusted likelihood: -23.920928955078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9995)
Solve time for step 3 2.789158111991128
Current ori: tensor([-0.0100, -0.0065,  0.0381], device='cuda:0')
Middle force: tensor([1.1494, 0.5812, 1.2604, 0.6295, 0.5551, 0.5426, 0.5194, 0.8981, 0.7191,
        0.6604], device='cuda:0')
Thumb force: tensor([0.7553, 1.0198, 0.7953, 0.6272, 0.5170, 0.9147, 0.5386, 0.5180, 0.6784,
        0.5799], device='cuda:0')
Index force: tensor([0.5696, 0.5772, 0.8067, 0.5196, 0.9736, 0.9120, 0.5804, 0.5877, 0.7238,
        0.5738], device='cuda:0')
Storing NORMAL transition: reward=-0.0149 (scaled=-0.0149), steps=1
Reward stats updated: mean -0.0044 -> -0.0046, std: 0.0895
Collected 59 transitions for RL
tensor([-0.0352,  0.5830,  0.4899,  0.4772, -0.1547,  0.3407,  1.0735,  1.2635,
         1.4963,  0.4322, -0.0486,  0.9028,  0.0048,  0.0349,  0.0518, -2.5379],
       device='cuda:0')
Original likelihood: -33.05419921875
Adjusted likelihood: -33.05419921875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.0478)
Solve time for step 4 2.7161257670086343
Current ori: tensor([0.0048, 0.0349, 0.0518], device='cuda:0')
Middle force: tensor([1.4043, 0.5693, 0.5012, 0.7351, 0.5015, 0.9441, 0.6932, 0.5831, 0.6750],
       device='cuda:0')
Thumb force: tensor([0.9051, 1.7125, 0.5002, 0.8725, 0.5418, 0.6004, 0.9902, 0.5386, 0.5615],
       device='cuda:0')
Index force: tensor([0.8694, 0.6084, 0.7729, 0.5440, 0.7384, 0.8970, 0.5262, 0.6009, 0.5564],
       device='cuda:0')
Storing NORMAL transition: reward=0.0207 (scaled=0.0207), steps=1
Reward stats updated: mean -0.0046 -> -0.0042, std: 0.0888
Collected 60 transitions for RL
tensor([-4.9784e-04,  5.9604e-01,  4.9423e-01,  4.8392e-01, -1.1315e-01,
         3.7431e-01,  1.0665e+00,  1.2428e+00,  1.5000e+00,  3.7763e-01,
        -2.0677e-02,  9.3125e-01, -9.6329e-03,  1.1439e-02,  3.2224e-02,
        -2.5552e+00], device='cuda:0')
Original likelihood: -25.430377960205078
Adjusted likelihood: -25.430377960205078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9937)
Solve time for step 5 2.6624379949935246
Current ori: tensor([-0.0096,  0.0114,  0.0322], device='cuda:0')
Middle force: tensor([0.5668, 0.5010, 0.7366, 0.5019, 0.9752, 0.6984, 0.5818, 0.6774],
       device='cuda:0')
Thumb force: tensor([1.6819, 0.5001, 0.8612, 0.5352, 0.5756, 0.9723, 0.5363, 0.5582],
       device='cuda:0')
Index force: tensor([0.6027, 0.7849, 0.5412, 0.7232, 0.8916, 0.5247, 0.5976, 0.5531],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0138 (scaled=-0.0138), steps=1
Reward stats updated: mean -0.0042 -> -0.0043, std: 0.0881
Collected 61 transitions for RL
tensor([ 0.0281,  0.5788,  0.4932,  0.5976, -0.0368,  0.3799,  1.0026,  1.2437,
         1.4912,  0.4472, -0.0610,  1.0410, -0.0216, -0.0065,  0.0457, -2.4805],
       device='cuda:0')
Original likelihood: -21.037921905517578
Adjusted likelihood: -21.037921905517578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 6 2.4039928620040882
Current ori: tensor([-0.0216, -0.0065,  0.0457], device='cuda:0')
Middle force: tensor([1.4822, 0.5417, 0.5989, 0.5341, 0.5277, 0.5190, 0.5845],
       device='cuda:0')
Thumb force: tensor([0.9502, 0.6872, 0.5061, 0.9200, 0.8115, 0.9659, 0.5846],
       device='cuda:0')
Index force: tensor([0.5154, 0.5060, 0.5336, 0.5229, 0.5450, 0.5160, 0.5995],
       device='cuda:0')
Storing NORMAL transition: reward=0.0013 (scaled=0.0013), steps=1
Reward stats updated: mean -0.0043 -> -0.0043, std: 0.0874
Collected 62 transitions for RL
tensor([ 0.0280,  0.5841,  0.4819,  0.6040, -0.0368,  0.4064,  0.9594,  1.2640,
         1.5000,  0.4166, -0.0533,  1.0095, -0.0289, -0.0061,  0.0440, -2.5051],
       device='cuda:0')
Original likelihood: -23.018217086791992
Adjusted likelihood: -23.018217086791992
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 7 2.4413963010010775
Current ori: tensor([-0.0289, -0.0061,  0.0440], device='cuda:0')
Middle force: tensor([0.5407, 0.6001, 0.5328, 0.5264, 0.5175, 0.5818], device='cuda:0')
Thumb force: tensor([0.6781, 0.5057, 0.9087, 0.8037, 0.9562, 0.5818], device='cuda:0')
Index force: tensor([0.5054, 0.5312, 0.5211, 0.5434, 0.5158, 0.5972], device='cuda:0')
Storing NORMAL transition: reward=-0.0080 (scaled=-0.0080), steps=1
Reward stats updated: mean -0.0043 -> -0.0043, std: 0.0867
Collected 63 transitions for RL
tensor([ 0.0294,  0.5809,  0.4838,  0.6117, -0.0368,  0.4163,  0.9371,  1.2836,
         1.5000,  0.4078, -0.0516,  1.0091, -0.0281, -0.0067,  0.0521, -2.5113],
       device='cuda:0')
Original likelihood: -21.53998565673828
Adjusted likelihood: -21.53998565673828
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 8 2.156224148988258
Current ori: tensor([-0.0281, -0.0067,  0.0521], device='cuda:0')
Middle force: tensor([0.5981, 0.5308, 0.5251, 0.5164, 0.5788], device='cuda:0')
Thumb force: tensor([0.5052, 0.8992, 0.7958, 0.9487, 0.5795], device='cuda:0')
Index force: tensor([0.5297, 0.5195, 0.5422, 0.5152, 0.5950], device='cuda:0')
Storing NORMAL transition: reward=-0.0237 (scaled=-0.0237), steps=1
Reward stats updated: mean -0.0043 -> -0.0046, std: 0.0860
Collected 64 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=1.0824, Q2 Loss=1.0824, Entropy=0.0783, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0143
SAC Update 2/5: Actor Loss=-0.0035, Q1 Loss=1.0786, Q2 Loss=1.0786, Entropy=0.3155, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0468
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.0730, Q2 Loss=1.0730, Entropy=0.0220, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0068
SAC Update 4/5: Actor Loss=-0.0034, Q1 Loss=1.0687, Q2 Loss=1.0687, Entropy=0.4367, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0166
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=1.0654, Q2 Loss=1.0654, Entropy=0.0163, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0553

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.3%)
Q1 update: 0.06s (24.3%)
Q2 update: 0.04s (16.6%)
Actor update: 0.08s (35.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001496
Q1 loss: 1.073624
Q2 loss: 1.073624
Current threshold: -30.0241
Global Scale Offset: 1.0449
Reward stats: mean=-0.0046, std=0.0860, count=64
----------------------------------------------
SAC Update - Actor Loss: -0.0015, Q1 Loss: 1.0736, Q2 Loss: 1.0736, Entropy: 0.1738, Mean TD Error: 0.0280, Threshold: -30.0241
tensor([ 0.0112,  0.5065,  0.5285,  0.6917, -0.0744,  0.4834,  0.7981,  1.2547,
         1.5000,  0.3434,  0.0221,  0.9301, -0.0393,  0.0164,  0.0748, -2.9485],
       device='cuda:0')
Original likelihood: -16.368247985839844
Adjusted likelihood: -16.368247985839844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 9 2.0577425599913113
Current ori: tensor([-0.0393,  0.0164,  0.0748], device='cuda:0')
Middle force: tensor([0.5296, 0.5234, 0.5155, 0.5784], device='cuda:0')
Thumb force: tensor([0.8837, 0.7921, 0.9387, 0.5766], device='cuda:0')
Index force: tensor([0.5178, 0.5417, 0.5149, 0.5917], device='cuda:0')
Storing NORMAL transition: reward=-0.1468 (scaled=-0.1468), steps=1
Reward stats updated: mean -0.0046 -> -0.0068, std: 0.0871
Collected 65 transitions for RL
SAC Update 1/5: Actor Loss=-0.0012, Q1 Loss=1.0599, Q2 Loss=1.0599, Entropy=0.1763, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0189
SAC Update 2/5: Actor Loss=-0.0018, Q1 Loss=1.0567, Q2 Loss=1.0567, Entropy=0.2234, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0609
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.0509, Q2 Loss=1.0509, Entropy=0.0236, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0071
SAC Update 4/5: Actor Loss=-0.0029, Q1 Loss=1.0465, Q2 Loss=1.0465, Entropy=0.2940, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0126
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=1.0425, Q2 Loss=1.0425, Entropy=0.1302, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0264

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (20.1%)
Actor update: 0.08s (38.9%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001303
Q1 loss: 1.051302
Q2 loss: 1.051303
Current threshold: -30.0292
Global Scale Offset: 1.0880
Reward stats: mean=-0.0068, std=0.0871, count=65
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.0513, Q2 Loss: 1.0513, Entropy: 0.1695, Mean TD Error: 0.0252, Threshold: -30.0292
tensor([-0.0183,  0.5195,  0.4745,  0.7215, -0.2265,  0.5130,  0.8220,  1.1355,
         1.4999,  0.3600,  0.0357,  1.0288, -0.0293,  0.0709,  0.2187, -3.4912],
       device='cuda:0')
Original likelihood: -28.364227294921875
Adjusted likelihood: -28.364227294921875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.8039)
State is out of distribution
Projection step: 0, Loss: 28.138681411743164
Projection step: 1, Loss: 28.221012115478516
Projection step: 2, Loss: 26.746501922607422
Projection step: 3, Loss: 25.336271286010742
Projection step: 4, Loss: 24.704593658447266
Projection step: 5, Loss: 24.483535766601562
Projection step: 6, Loss: 22.213150024414062
Projection step: 7, Loss: 22.08816909790039
Projection step: 8, Loss: 22.388269424438477
Projection step: 9, Loss: 20.53347396850586
Projection step: 10, Loss: 21.244979858398438
Projection step: 11, Loss: 20.250877380371094
Projection step: 12, Loss: 20.32944107055664
Projection step: 13, Loss: 19.06203842163086
Projection step: 14, Loss: 19.792701721191406
Final likelihood: tensor([-18.6074, -15.9718, -17.0258, -17.0948, -20.1121, -17.1405, -17.4257,
        -18.8260, -18.3725, -19.1751, -18.4451, -16.6858, -19.2928, -17.3938,
        -17.2807, -19.4388])
Final projection likelihood: -18.0180
1 mode projection succeeded
New goal: tensor([ 0.0126,  0.5738,  0.5026,  0.6305, -0.1326,  0.4744,  0.7731,  0.9669,
         1.4239,  0.2802,  0.0940,  1.1164, -0.0352,  0.0494, -0.3984],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -21.958465576171875
Adjusted likelihood: -21.958465576171875
Likelihood residual: 0.0
{'index': 21.958465576171875, 'thumb_middle': inf}
Current yaw: tensor([-0.0293,  0.0709,  0.2187], device='cuda:0')
6 index
tensor([-0.0183,  0.5195,  0.4745,  0.7215, -0.2265,  0.5130,  0.8220,  1.1355,
         1.4999,  0.3600,  0.0357,  1.0288, -0.0293,  0.0709,  0.2187, -3.4912],
       device='cuda:0')
Solve time for step 1 10.655754272011109
Current ori: tensor([-0.0293,  0.0709,  0.2187], device='cuda:0')
Middle force: tensor([0.5698, 0.5446, 0.5922, 0.5033], device='cuda:0')
Thumb force: tensor([0.5430, 0.5641, 0.5986, 0.5286], device='cuda:0')
tensor([ 0.0608,  0.4991,  0.4426,  0.6212, -0.2104,  0.5160,  0.8618,  1.0789,
         1.5000,  0.3480,  0.0089,  1.0457, -0.0381,  0.0593,  0.2438, -3.6298],
       device='cuda:0')
Solve time for step 2 2.290312619996257
Current ori: tensor([-0.0381,  0.0593,  0.2438], device='cuda:0')
Middle force: tensor([0.5435, 0.5890, 0.5029], device='cuda:0')
Thumb force: tensor([0.5613, 0.5969, 0.5278], device='cuda:0')
tensor([ 0.0682,  0.5115,  0.4483,  0.6079, -0.1922,  0.5286,  0.8692,  1.0499,
         1.4999,  0.3409, -0.0076,  1.0453, -0.0464,  0.0480,  0.2430, -4.0164],
       device='cuda:0')
Solve time for step 3 2.1917102120351046
Current ori: tensor([-0.0464,  0.0480,  0.2430], device='cuda:0')
Middle force: tensor([0.5358, 0.5347], device='cuda:0')
Thumb force: tensor([0.5841, 0.5676], device='cuda:0')
tensor([ 0.0710,  0.5161,  0.4517,  0.6029, -0.1763,  0.5444,  0.8659,  1.0328,
         1.4999,  0.3355, -0.0206,  1.0412, -0.0543,  0.0382,  0.2395, -4.5779],
       device='cuda:0')
Solve time for step 4 2.03545608301647
Current ori: tensor([-0.0543,  0.0382,  0.2395], device='cuda:0')
Middle force: tensor([0.5019], device='cuda:0')
Thumb force: tensor([0.5250], device='cuda:0')
Storing RECOVERY transition: reward=-0.0138 (scaled=-0.0015), steps=9
Reward stats updated: mean -0.0068 -> -0.0067, std: 0.0865
Collected 66 transitions for RL
SAC Update 1/5: Actor Loss=-0.0060, Q1 Loss=1.0389, Q2 Loss=1.0389, Entropy=0.3453, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0543
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=1.0353, Q2 Loss=1.0353, Entropy=0.0178, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0669
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.0286, Q2 Loss=1.0286, Entropy=0.0208, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0031
SAC Update 4/5: Actor Loss=-0.0054, Q1 Loss=1.0254, Q2 Loss=1.0254, Entropy=0.3395, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0436
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.0223, Q2 Loss=1.0223, Entropy=0.0203, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0811

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.2%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (41.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002307
Q1 loss: 1.030116
Q2 loss: 1.030116
Current threshold: -30.0214
Global Scale Offset: 1.1279
Reward stats: mean=-0.0067, std=0.0865, count=66
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 1.0301, Q2 Loss: 1.0301, Entropy: 0.1488, Mean TD Error: 0.0498, Threshold: -30.0214
Original likelihood: -24.691455841064453
Adjusted likelihood: -24.691455841064453
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9962)
Current yaw: tensor([-0.0556,  0.0309,  0.2341], device='cuda:0')
7 turn
Sampling time 3.934149619017262
tensor([ 0.0332,  0.5762,  0.4901,  0.6227, -0.1658,  0.5496,  0.8681,  1.0309,
         1.4999,  0.3304, -0.0323,  1.0478, -0.0556,  0.0309,  0.2341, -4.7186],
       device='cuda:0')
Original likelihood: -24.118614196777344
Adjusted likelihood: -24.118614196777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9984)
Solve time for step 1 14.435047196981031
Current ori: tensor([-0.0556,  0.0309,  0.2341], device='cuda:0')
Middle force: tensor([0.6124, 0.7396, 0.6685, 0.5985, 0.6307, 0.5990, 0.7660, 0.5860, 0.6643,
        0.5821, 0.5847, 0.6269], device='cuda:0')
Thumb force: tensor([0.6006, 2.2514, 1.7739, 0.7443, 1.5441, 0.5279, 0.6733, 0.5129, 0.6033,
        0.5947, 0.7716, 0.5912], device='cuda:0')
Index force: tensor([0.6081, 0.7225, 0.5358, 0.5681, 1.1616, 0.6249, 0.6165, 0.5463, 0.5159,
        0.6594, 0.6076, 0.5935], device='cuda:0')
Storing NORMAL transition: reward=-0.0195 (scaled=-0.0195), steps=1
Reward stats updated: mean -0.0067 -> -0.0069, std: 0.0859
Collected 67 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.6550, Q2 Loss=0.6550, Entropy=0.0050, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1065
SAC Update 2/5: Actor Loss=-0.0159, Q1 Loss=1.0108, Q2 Loss=1.0108, Entropy=0.2531, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0056
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=1.0360, Q2 Loss=1.0360, Entropy=0.0531, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2120
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=1.0065, Q2 Loss=1.0065, Entropy=0.0112, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0770
SAC Update 5/5: Actor Loss=-0.0168, Q1 Loss=0.8151, Q2 Loss=0.8151, Entropy=0.1253, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1152

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.7%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (38.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006578
Q1 loss: 0.904691
Q2 loss: 0.904691
Current threshold: -30.0318
Global Scale Offset: 1.1292
Reward stats: mean=-0.0069, std=0.0859, count=67
----------------------------------------------
SAC Update - Actor Loss: -0.0066, Q1 Loss: 0.9047, Q2 Loss: 0.9047, Entropy: 0.0895, Mean TD Error: 0.1033, Threshold: -30.0318
tensor([ 0.0290,  0.4650,  0.4020,  0.7367, -0.1417,  0.4708,  0.8937,  0.9411,
         1.4883,  0.3448, -0.0509,  1.0753, -0.1379,  0.0770,  0.2341,  6.0916],
       device='cuda:0')
Original likelihood: -33.455970764160156
Adjusted likelihood: -33.455970764160156
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0433)
State is out of distribution
Projection step: 0, Loss: 32.338218688964844
Projection step: 1, Loss: 31.57577896118164
Projection step: 2, Loss: 29.290634155273438
Projection step: 3, Loss: 28.709766387939453
Projection step: 4, Loss: 29.04327964782715
Projection step: 5, Loss: 30.644617080688477
Projection step: 6, Loss: 31.44383430480957
Projection step: 7, Loss: 30.380474090576172
Projection step: 8, Loss: 30.11587142944336
Projection step: 9, Loss: 30.1605167388916
Projection step: 10, Loss: 28.485015869140625
Projection step: 11, Loss: 29.25395965576172
Projection step: 12, Loss: 28.22627067565918
Projection step: 13, Loss: 27.90178680419922
Projection step: 14, Loss: 27.313854217529297
Final likelihood: tensor([-19.1984, -26.5309, -28.1929, -27.5487, -28.7328, -28.0968, -24.6789,
        -28.5068, -36.1164, -28.2577, -28.2944, -28.3671, -27.4732, -25.3068,
        -28.0504, -27.1855])
Final projection likelihood: -27.5336
1 mode projection succeeded
New goal: tensor([ 0.0396,  0.5568,  0.5032,  0.7010, -0.1001,  0.4179,  0.8557,  0.8276,
         1.4631,  0.2666,  0.0897,  1.0585, -0.1263,  0.0629, -0.1319],
       device='cuda:0')
tensor([[0.0048]], device='cuda:0') tensor([[0.0055]], device='cuda:0') tensor([[0.0155]], device='cuda:0')
Original likelihood: -29.544696807861328
Adjusted likelihood: -29.544696807861328
Likelihood residual: 0.0
Original likelihood: -27.359554290771484
Adjusted likelihood: -27.359554290771484
Likelihood residual: 0.0
{'index': 27.359554290771484, 'thumb_middle': 29.544696807861328}
Current yaw: tensor([-0.1379,  0.0770,  0.2341], device='cuda:0')
8 index
tensor([ 0.0290,  0.4650,  0.4020,  0.7367, -0.1417,  0.4708,  0.8937,  0.9411,
         1.4883,  0.3448, -0.0509,  1.0753, -0.1379,  0.0770,  0.2341,  6.0916],
       device='cuda:0')
Solve time for step 1 10.660248822008725
Current ori: tensor([-0.1379,  0.0770,  0.2341], device='cuda:0')
Middle force: tensor([0.5729, 0.5315, 0.5542, 0.5722], device='cuda:0')
Thumb force: tensor([0.5309, 0.5683, 0.5184, 0.5665], device='cuda:0')
tensor([ 8.0561e-02,  5.1193e-01,  4.5469e-01,  6.9233e-01, -1.3238e-01,
         5.0189e-01,  9.2228e-01,  8.8139e-01,  1.5000e+00,  3.1316e-01,
        -1.4449e-03,  1.0525e+00, -3.4537e-01,  1.9084e-01,  2.3408e-01,
         5.8546e+00], device='cuda:0')
Solve time for step 2 2.4146177569637075
Current ori: tensor([-0.3454,  0.1908,  0.2341], device='cuda:0')
Middle force: tensor([0.5315, 0.5533, 0.5681], device='cuda:0')
Thumb force: tensor([0.5617, 0.5176, 0.5654], device='cuda:0')
tensor([ 0.0261,  0.6008,  0.5038,  0.6958, -0.1200,  0.5622,  0.9295,  0.8535,
         1.5000,  0.3326,  0.0215,  1.0967, -0.8078,  0.4179,  0.2341, -4.8649],
       device='cuda:0')
Solve time for step 3 2.173955876030959
Current ori: tensor([-0.8078,  0.4179,  0.2341], device='cuda:0')
Middle force: tensor([0.5045, 0.5120], device='cuda:0')
Thumb force: tensor([0.5208, 0.6094], device='cuda:0')
tensor([-0.0960,  0.7265,  0.5123,  0.6667, -0.1850,  0.8445,  0.9936,  0.8234,
         1.5000,  0.3767, -0.0745,  1.2069, -1.5371,  0.6005,  0.2342, -4.2328],
       device='cuda:0')
Solve time for step 4 2.1492610099958256
Current ori: tensor([-1.5371,  0.6005,  0.2342], device='cuda:0')
Middle force: tensor([0.5131], device='cuda:0')
Thumb force: tensor([0.6057], device='cuda:0')
Storing RECOVERY transition: reward=-1.5477 (scaled=-1.5477), steps=1
Reward stats updated: mean -0.0069 -> -0.0296, std: 0.2041
Collected 68 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.9952, Q2 Loss=0.9952, Entropy=0.0283, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0562
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.9907, Q2 Loss=0.9907, Entropy=0.0613, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0498
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.8853, Q2 Loss=0.8853, Entropy=0.0360, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1936
SAC Update 4/5: Actor Loss=-0.0029, Q1 Loss=0.6456, Q2 Loss=0.6456, Entropy=0.2928, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0755
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7189, Q2 Loss=0.7189, Entropy=0.0010, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0487

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000678
Q1 loss: 0.847162
Q2 loss: 0.847162
Current threshold: -30.0292
Global Scale Offset: 1.1160
Reward stats: mean=-0.0296, std=0.2041, count=68
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 0.8472, Q2 Loss: 0.8472, Entropy: 0.0839, Mean TD Error: 0.0847, Threshold: -30.0292
Original likelihood: -1257.615478515625
Adjusted likelihood: -1257.615478515625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 5
Loaded trajectory sampler
Current yaw: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:0')
Current yaw: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:0')
1 turn
Sampling time 3.7447676140000112
tensor([ 1.1862e-01,  5.8357e-01,  5.5730e-01,  6.3811e-01, -1.4982e-01,
         5.6667e-01,  8.9692e-01,  9.4111e-01,  1.2318e+00,  2.8931e-01,
         2.2487e-01,  1.2394e+00,  3.7755e-04,  1.4106e-02, -4.7386e-02,
         4.7066e-01], device='cuda:0')
Original likelihood: -22.04679298400879
Adjusted likelihood: -22.04679298400879
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 15.073055556043983
Current ori: tensor([ 0.0004,  0.0141, -0.0474], device='cuda:0')
Middle force: tensor([0.7119, 0.7369, 0.5340, 0.5240, 0.6297, 0.9929, 0.9794, 0.5898, 0.5003,
        0.5926, 1.1975, 0.8369], device='cuda:0')
Thumb force: tensor([0.5656, 2.3532, 0.6302, 1.5267, 1.0500, 0.8617, 1.9689, 0.6001, 0.7159,
        0.6070, 0.6276, 1.4898], device='cuda:0')
Index force: tensor([0.6001, 0.5019, 0.6093, 0.5589, 0.5723, 0.5169, 0.5750, 0.6159, 0.7249,
        0.6300, 0.5521, 0.5614], device='cuda:0')
Storing NORMAL transition: reward=0.0193 (scaled=0.0193), steps=1
Reward stats updated: mean -0.0296 -> -0.0289, std: 0.2027
Collected 69 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.8743, Q2 Loss=0.8743, Entropy=0.0312, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2062
SAC Update 2/5: Actor Loss=-0.0016, Q1 Loss=0.9883, Q2 Loss=0.9883, Entropy=0.2103, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1703
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.9627, Q2 Loss=0.9627, Entropy=0.0076, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0101
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.9660, Q2 Loss=0.9660, Entropy=0.0227, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1259
SAC Update 5/5: Actor Loss=-0.0060, Q1 Loss=0.6487, Q2 Loss=0.6487, Entropy=0.3442, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0191

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (18.1%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (41.8%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001562
Q1 loss: 0.888019
Q2 loss: 0.888019
Current threshold: -30.0219
Global Scale Offset: 1.1140
Reward stats: mean=-0.0289, std=0.2027, count=69
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 0.8880, Q2 Loss: 0.8880, Entropy: 0.1232, Mean TD Error: 0.1063, Threshold: -30.0219
tensor([ 0.0871,  0.5119,  0.6275,  0.6353, -0.1828,  0.5494,  0.8304,  1.0720,
         1.2759,  0.2468,  0.2451,  1.2361,  0.0166,  0.0315, -0.0677,  0.5113],
       device='cuda:0')
Original likelihood: -28.7143497467041
Adjusted likelihood: -28.7143497467041
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7455)
Solve time for step 2 2.9844017539871857
Current ori: tensor([ 0.0166,  0.0315, -0.0677], device='cuda:0')
Middle force: tensor([0.5716, 1.2048, 0.5577, 1.1265, 0.6410, 0.5358, 0.5744, 0.5044, 0.8044,
        0.6138, 0.6039], device='cuda:0')
Thumb force: tensor([0.8670, 0.7925, 1.0611, 1.0943, 0.6560, 0.5330, 0.8312, 0.5253, 0.5554,
        0.6094, 0.5812], device='cuda:0')
Index force: tensor([0.5995, 0.5479, 0.5683, 0.8165, 0.5056, 1.0219, 0.9113, 0.5914, 0.5995,
        0.5409, 0.5927], device='cuda:0')
Storing NORMAL transition: reward=-0.0120 (scaled=-0.0120), steps=1
Reward stats updated: mean -0.0289 -> -0.0286, std: 0.2013
Collected 70 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.9497, Q2 Loss=0.9497, Entropy=0.0103, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0239
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8344, Q2 Loss=0.8344, Entropy=0.0297, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0930
SAC Update 3/5: Actor Loss=-0.0018, Q1 Loss=0.9404, Q2 Loss=0.9404, Entropy=0.2264, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0150
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=1.2069, Q2 Loss=1.2069, Entropy=0.0863, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9243
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.7914, Q2 Loss=0.7914, Entropy=0.0003, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1919

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (19.7%)
Actor update: 0.09s (40.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000448
Q1 loss: 0.944578
Q2 loss: 0.944578
Current threshold: -30.0141
Global Scale Offset: 1.1182
Reward stats: mean=-0.0286, std=0.2013, count=70
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 0.9446, Q2 Loss: 0.9446, Entropy: 0.0706, Mean TD Error: 0.2496, Threshold: -30.0141
tensor([ 0.0635,  0.5373,  0.5569,  0.6551, -0.2519,  0.6505,  0.7456,  1.0571,
         1.2650,  0.3515,  0.2134,  1.3137,  0.0083,  0.0548, -0.0574,  0.2827],
       device='cuda:0')
Original likelihood: -40.05778121948242
Adjusted likelihood: -40.05778121948242
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 40.51410675048828
Projection step: 1, Loss: 37.43949890136719
Projection step: 2, Loss: 34.31560516357422
Projection step: 3, Loss: 32.2720947265625
Projection step: 4, Loss: 29.146177291870117
Projection step: 5, Loss: 27.248554229736328
Projection step: 6, Loss: 28.468486785888672
Projection step: 7, Loss: 25.026599884033203
Projection step: 8, Loss: 23.776947021484375
Projection step: 9, Loss: 21.723190307617188
Projection step: 10, Loss: 19.715259552001953
Projection step: 11, Loss: 18.374561309814453
Projection step: 12, Loss: 16.42828941345215
Projection step: 13, Loss: 14.972879409790039
Final likelihood: tensor([-14.7841, -14.5378, -14.2946, -17.9289, -14.8341, -15.2297, -14.6153,
        -14.8022, -14.6608, -14.7744, -12.2935, -14.7071, -14.4751, -14.7946,
        -18.1929, -14.6412])
Final projection likelihood: -14.9729
1 mode projection succeeded
New goal: tensor([ 0.0712,  0.5345,  0.5719,  0.6685, -0.1187,  0.5805,  0.7803,  0.8766,
         1.2971,  0.2849,  0.1663,  1.1999, -0.0030,  0.0255, -0.6705],
       device='cuda:0')
tensor([[0.0030]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -24.498046875
Adjusted likelihood: -24.498046875
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 24.498046875}
Current yaw: tensor([ 0.0083,  0.0548, -0.0574], device='cuda:0')
2 thumb_middle
tensor([ 0.0635,  0.5373,  0.5569,  0.6551, -0.2519,  0.6505,  0.7456,  1.0571,
         1.2650,  0.3515,  0.2134,  1.3137,  0.0083,  0.0548, -0.0574,  0.2827],
       device='cuda:0')
Solve time for step 1 9.071778325014748
Current ori: tensor([ 0.0083,  0.0548, -0.0574], device='cuda:0')
Index force: tensor([0.5745, 0.5684, 0.5778, 0.6008], device='cuda:0')
tensor([ 0.0597,  0.5356,  0.5614,  0.6438, -0.2594,  0.5980,  0.7517,  0.8947,
         1.2700,  0.2913,  0.1319,  1.2113,  0.0083,  0.0567, -0.0574,  0.2840],
       device='cuda:0')
Solve time for step 2 1.979222631023731
Current ori: tensor([ 0.0083,  0.0567, -0.0574], device='cuda:0')
Index force: tensor([0.5632, 0.5728, 0.5967], device='cuda:0')
tensor([ 0.0753,  0.5444,  0.5618,  0.6492, -0.2455,  0.6072,  0.7671,  0.8736,
         1.2844,  0.2744,  0.1105,  1.1872,  0.0061,  0.0477, -0.0574,  0.3077],
       device='cuda:0')
Solve time for step 3 1.8912904360331595
Current ori: tensor([ 0.0061,  0.0477, -0.0574], device='cuda:0')
Index force: tensor([0.5655, 0.5892], device='cuda:0')
tensor([ 0.0920,  0.5526,  0.5632,  0.6562, -0.2315,  0.6098,  0.7671,  0.8581,
         1.2861,  0.2735,  0.0944,  1.1767,  0.0043,  0.0382, -0.0574,  0.3326],
       device='cuda:0')
Solve time for step 4 1.9071795369964093
Current ori: tensor([ 0.0043,  0.0382, -0.0574], device='cuda:0')
Index force: tensor([0.5655], device='cuda:0')
Storing RECOVERY transition: reward=0.0024 (scaled=0.0012), steps=2
Reward stats updated: mean -0.0286 -> -0.0282, std: 0.1999
Collected 71 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.9283, Q2 Loss=0.9283, Entropy=0.0245, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0308
SAC Update 2/5: Actor Loss=-0.0057, Q1 Loss=0.9235, Q2 Loss=0.9235, Entropy=0.5616, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0015
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8664, Q2 Loss=0.8664, Entropy=0.0020, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0965
SAC Update 4/5: Actor Loss=-0.0054, Q1 Loss=0.9162, Q2 Loss=0.9162, Entropy=0.3585, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0460
SAC Update 5/5: Actor Loss=-0.0011, Q1 Loss=0.6563, Q2 Loss=0.6563, Entropy=0.2784, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0430

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.7%)
Q1 update: 0.06s (20.0%)
Q2 update: 0.05s (19.8%)
Actor update: 0.12s (42.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002471
Q1 loss: 0.858124
Q2 loss: 0.858124
Current threshold: -30.0075
Global Scale Offset: 1.1307
Reward stats: mean=-0.0282, std=0.1999, count=71
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 0.8581, Q2 Loss: 0.8581, Entropy: 0.2450, Mean TD Error: 0.0436, Threshold: -30.0075
Original likelihood: -25.918514251708984
Adjusted likelihood: -25.918514251708984
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9795)
Current yaw: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:0')
3 turn
Sampling time 3.7098555410047993
tensor([ 0.0854,  0.5580,  0.5512,  0.6530, -0.1777,  0.6301,  0.7858,  0.8670,
         1.3605,  0.2975,  0.1305,  1.2016,  0.0045,  0.0380, -0.0583,  0.3594],
       device='cuda:0')
Original likelihood: -29.604450225830078
Adjusted likelihood: -29.604450225830078
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5798)
State is out of distribution
Projection step: 0, Loss: 28.766324996948242
Projection step: 1, Loss: 27.382972717285156
Projection step: 2, Loss: 26.164113998413086
Projection step: 3, Loss: 24.97966766357422
Projection step: 4, Loss: 21.51034927368164
Projection step: 5, Loss: 20.810766220092773
Projection step: 6, Loss: 17.198556900024414
Projection step: 7, Loss: 15.160356521606445
Projection step: 8, Loss: 12.26500415802002
Final likelihood: tensor([-12.0674, -16.5613,  -9.1639, -13.1694,  -9.7232, -12.3798, -21.9395,
         -9.5255,  -8.9851, -11.4697, -14.7414,  -8.9153, -16.4319,  -9.6413,
         -9.2115, -12.3139])
Final projection likelihood: -12.2650
1 mode projection succeeded
New goal: tensor([ 0.0835,  0.5591,  0.5657,  0.6296, -0.0918,  0.5988,  0.8113,  0.8004,
         1.3023,  0.3185,  0.1835,  1.1923,  0.0017,  0.0176, -0.8986],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -19.324491500854492
Adjusted likelihood: -19.324491500854492
Likelihood residual: 0.0
Original likelihood: -19.966533660888672
Adjusted likelihood: -19.966533660888672
Likelihood residual: 0.0
{'index': 19.966533660888672, 'thumb_middle': 19.324491500854492}
Current yaw: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:0')
4 thumb_middle
tensor([ 0.0854,  0.5580,  0.5512,  0.6530, -0.1777,  0.6301,  0.7858,  0.8670,
         1.3605,  0.2975,  0.1305,  1.2016,  0.0045,  0.0380, -0.0583,  0.3594],
       device='cuda:0')
Solve time for step 1 9.008760465017986
Current ori: tensor([ 0.0045,  0.0380, -0.0583], device='cuda:0')
Index force: tensor([0.5566, 0.5845, 0.5824, 0.5693], device='cuda:0')
tensor([ 0.0825,  0.5546,  0.5606,  0.6370, -0.2269,  0.5985,  0.7650,  0.7922,
         1.2826,  0.3186,  0.0999,  1.1561,  0.0039,  0.0407, -0.0582,  0.3211],
       device='cuda:0')
Solve time for step 2 2.0574603989953175
Current ori: tensor([ 0.0039,  0.0407, -0.0582], device='cuda:0')
Index force: tensor([0.5791, 0.5780, 0.5653], device='cuda:0')
tensor([ 0.0995,  0.5567,  0.5840,  0.6191, -0.2091,  0.5928,  0.7784,  0.7812,
         1.2670,  0.2961,  0.1043,  1.1633,  0.0015,  0.0307, -0.0582,  0.3433],
       device='cuda:0')
Solve time for step 3 1.8888771390193142
Current ori: tensor([ 0.0015,  0.0307, -0.0582], device='cuda:0')
Index force: tensor([0.5712, 0.5835], device='cuda:0')
tensor([ 1.0104e-01,  5.6556e-01,  5.7172e-01,  6.2228e-01, -2.1018e-01,
         5.9547e-01,  7.7978e-01,  7.7966e-01,  1.2707e+00,  2.9440e-01,
         9.5246e-02,  1.1644e+00, -2.6768e-04,  2.9610e-02, -5.8194e-02,
         3.4546e-01], device='cuda:0')
Solve time for step 4 1.8279502209625207
Current ori: tensor([-0.0003,  0.0296, -0.0582], device='cuda:0')
Index force: tensor([0.5563], device='cuda:0')
Storing RECOVERY transition: reward=0.0082 (scaled=0.0082), steps=0
Reward stats updated: mean -0.0282 -> -0.0277, std: 0.1985
Collected 72 transitions for RL
SAC Update 1/5: Actor Loss=-0.0030, Q1 Loss=0.6091, Q2 Loss=0.6091, Entropy=0.3599, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0366
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.6534, Q2 Loss=0.6534, Entropy=0.2262, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0856
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6459, Q2 Loss=0.6459, Entropy=0.0000, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0748
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7744, Q2 Loss=0.7744, Entropy=0.0004, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1528
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=1.1011, Q2 Loss=1.1011, Entropy=0.0899, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9243

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (40.2%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000823
Q1 loss: 0.756793
Q2 loss: 0.756793
Current threshold: -30.0095
Global Scale Offset: 1.1441
Reward stats: mean=-0.0277, std=0.1985, count=72
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.7568, Q2 Loss: 0.7568, Entropy: 0.1353, Mean TD Error: 0.2548, Threshold: -30.0095
Original likelihood: -23.811656951904297
Adjusted likelihood: -23.811656951904297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9989)
Current yaw: tensor([-0.0002,  0.0198, -0.0655], device='cuda:0')
5 turn
Sampling time 3.7692155260010622
tensor([ 1.1561e-01,  5.7158e-01,  5.7363e-01,  6.3138e-01, -1.4479e-01,
         6.4165e-01,  8.1408e-01,  7.9200e-01,  1.3349e+00,  3.3087e-01,
         1.2893e-01,  1.1770e+00, -2.0352e-04,  1.9776e-02, -6.5467e-02,
         4.3854e-01], device='cuda:0')
Original likelihood: -20.09916877746582
Adjusted likelihood: -20.09916877746582
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.592090613034088
Current ori: tensor([-0.0002,  0.0198, -0.0655], device='cuda:0')
Middle force: tensor([0.5175, 0.6713, 0.5564, 0.5037, 0.7699, 1.0816, 0.5875, 0.5622, 0.5414,
        0.5585, 0.6147, 0.5900], device='cuda:0')
Thumb force: tensor([0.8690, 0.6713, 1.6177, 2.4745, 0.8789, 1.7510, 0.5940, 0.7061, 0.5664,
        1.6251, 0.5385, 0.5704], device='cuda:0')
Index force: tensor([0.5038, 0.8620, 0.5953, 0.6056, 0.5845, 0.5852, 0.5875, 0.5166, 0.4904,
        0.8261, 0.7435, 0.5397], device='cuda:0')
Storing NORMAL transition: reward=-0.0964 (scaled=-0.0964), steps=1
Reward stats updated: mean -0.0277 -> -0.0286, std: 0.1973
Collected 73 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.8675, Q2 Loss=0.8675, Entropy=0.0207, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0865
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7080, Q2 Loss=0.7080, Entropy=0.0025, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1077
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.7514, Q2 Loss=0.7514, Entropy=0.0338, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2344
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.9946, Q2 Loss=0.9946, Entropy=0.0936, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8679
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.6501, Q2 Loss=0.6501, Entropy=0.1084, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7734

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.8%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.06s (20.5%)
Actor update: 0.12s (42.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000116
Q1 loss: 0.794304
Q2 loss: 0.794304
Current threshold: -30.0116
Global Scale Offset: 1.1560
Reward stats: mean=-0.0286, std=0.1973, count=73
----------------------------------------------
SAC Update - Actor Loss: -0.0001, Q1 Loss: 0.7943, Q2 Loss: 0.7943, Entropy: 0.0518, Mean TD Error: 0.4140, Threshold: -30.0116
tensor([ 0.0858,  0.5186,  0.6071,  0.6515, -0.1180,  0.6718,  0.7751,  0.8271,
         1.2250,  0.4341,  0.1723,  1.2538,  0.0125,  0.0033,  0.0312,  1.0702],
       device='cuda:0')
Original likelihood: -23.491607666015625
Adjusted likelihood: -23.491607666015625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9993)
Solve time for step 2 2.9501390689983964
Current ori: tensor([0.0125, 0.0033, 0.0312], device='cuda:0')
Middle force: tensor([0.6807, 0.5548, 0.5047, 0.7655, 1.0669, 0.5951, 0.5650, 0.5454, 0.5940,
        0.6313, 0.5894], device='cuda:0')
Thumb force: tensor([0.6368, 1.5843, 2.4064, 0.8637, 1.7144, 0.5794, 0.6880, 0.5554, 1.5553,
        0.5248, 0.5670], device='cuda:0')
Index force: tensor([0.8580, 0.5915, 0.5948, 0.5813, 0.5822, 0.5859, 0.5162, 0.5024, 0.7829,
        0.7570, 0.5378], device='cuda:0')
Storing NORMAL transition: reward=0.0110 (scaled=0.0110), steps=1
Reward stats updated: mean -0.0286 -> -0.0281, std: 0.1960
Collected 74 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.7409, Q2 Loss=0.7409, Entropy=0.0373, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1918
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=1.3784, Q2 Loss=1.3784, Entropy=0.1790, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8038
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6673, Q2 Loss=0.6673, Entropy=0.0314, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0536
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.7171, Q2 Loss=0.7171, Entropy=0.3089, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0457
SAC Update 5/5: Actor Loss=-0.0015, Q1 Loss=0.6866, Q2 Loss=0.6866, Entropy=0.2880, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7785

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.05s (18.8%)
Actor update: 0.12s (40.2%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001125
Q1 loss: 0.838043
Q2 loss: 0.838043
Current threshold: -30.0141
Global Scale Offset: 1.1737
Reward stats: mean=-0.0281, std=0.1960, count=74
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 0.8380, Q2 Loss: 0.8380, Entropy: 0.1689, Mean TD Error: 0.3747, Threshold: -30.0141
tensor([ 0.0786,  0.5412,  0.5839,  0.6229, -0.1220,  0.6854,  0.7516,  0.8238,
         1.2570,  0.3985,  0.1522,  1.2395,  0.0043,  0.0064,  0.0202,  1.0468],
       device='cuda:0')
Original likelihood: -23.495243072509766
Adjusted likelihood: -23.495243072509766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9992)
Solve time for step 3 2.8532107579521835
Current ori: tensor([0.0043, 0.0064, 0.0202], device='cuda:0')
Middle force: tensor([0.5531, 0.5053, 0.7596, 1.0521, 0.5979, 0.5646, 0.5472, 0.6048, 0.6417,
        0.5877], device='cuda:0')
Thumb force: tensor([1.5493, 2.3461, 0.8498, 1.6792, 0.5720, 0.6800, 0.5493, 1.5155, 0.5190,
        0.5643], device='cuda:0')
Index force: tensor([0.5865, 0.5836, 0.5783, 0.5792, 0.5823, 0.5155, 0.5022, 0.7626, 0.7561,
        0.5361], device='cuda:0')
Storing NORMAL transition: reward=0.0151 (scaled=0.0151), steps=1
Reward stats updated: mean -0.0281 -> -0.0275, std: 0.1948
Collected 75 transitions for RL
SAC Update 1/5: Actor Loss=-0.0156, Q1 Loss=0.6620, Q2 Loss=0.6620, Entropy=0.2807, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0512
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=1.1511, Q2 Loss=1.1511, Entropy=0.1317, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9581
SAC Update 3/5: Actor Loss=-0.0054, Q1 Loss=0.7742, Q2 Loss=0.7742, Entropy=0.3401, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0298
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6896, Q2 Loss=0.6896, Entropy=0.0036, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1598
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.8255, Q2 Loss=0.8255, Entropy=0.1204, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8080

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.7%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.04s (18.8%)
Actor update: 0.10s (42.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004349
Q1 loss: 0.820490
Q2 loss: 0.820490
Current threshold: -30.0340
Global Scale Offset: 1.1794
Reward stats: mean=-0.0275, std=0.1948, count=75
----------------------------------------------
SAC Update - Actor Loss: -0.0043, Q1 Loss: 0.8205, Q2 Loss: 0.8205, Entropy: 0.1753, Mean TD Error: 0.4014, Threshold: -30.0340
tensor([ 0.1979,  0.5433,  0.6130,  0.7863, -0.0669,  0.6477,  0.7141,  0.7510,
         1.2797,  0.4390,  0.0787,  1.3586,  0.0116,  0.0185,  0.0047,  1.3116],
       device='cuda:0')
Original likelihood: -25.721298217773438
Adjusted likelihood: -25.721298217773438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9817)
Solve time for step 4 2.634577795979567
Current ori: tensor([0.0116, 0.0185, 0.0047], device='cuda:0')
Middle force: tensor([0.5042, 0.7414, 1.0284, 0.5728, 0.5519, 0.5326, 0.5212, 0.5963, 0.5804],
       device='cuda:0')
Thumb force: tensor([2.3056, 0.8475, 1.6520, 0.5903, 0.7039, 0.5697, 1.5818, 0.5380, 0.5642],
       device='cuda:0')
Index force: tensor([0.5873, 0.5770, 0.5761, 0.5801, 0.5143, 0.5023, 0.8587, 0.7243, 0.5361],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0311 (scaled=-0.0311), steps=1
Reward stats updated: mean -0.0275 -> -0.0276, std: 0.1935
Collected 76 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.5453, Q2 Loss=0.5453, Entropy=0.0501, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0352
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.6678, Q2 Loss=0.6678, Entropy=0.0381, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2153
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=0.8264, Q2 Loss=0.8264, Entropy=0.1133, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0514
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.7318, Q2 Loss=0.7318, Entropy=0.0029, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1356
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=0.6771, Q2 Loss=0.6771, Entropy=0.1116, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0591

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.2%)
Q1 update: 0.04s (19.5%)
Q2 update: 0.04s (19.3%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000257
Q1 loss: 0.689681
Q2 loss: 0.689681
Current threshold: -30.0489
Global Scale Offset: 1.1892
Reward stats: mean=-0.0276, std=0.1935, count=76
----------------------------------------------
SAC Update - Actor Loss: -0.0003, Q1 Loss: 0.6897, Q2 Loss: 0.6897, Entropy: 0.0632, Mean TD Error: 0.0993, Threshold: -30.0489
tensor([ 0.2775,  0.6641,  0.6794,  0.7451, -0.1102,  0.6516,  0.5985,  0.7660,
         1.3308,  0.4064,  0.0838,  1.3866,  0.0205,  0.0636,  0.0327, -0.3627],
       device='cuda:0')
Original likelihood: -47.03728103637695
Adjusted likelihood: -47.03728103637695
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 45.79708480834961
Projection step: 1, Loss: 39.544612884521484
Projection step: 2, Loss: 37.34223556518555
Projection step: 3, Loss: 34.108619689941406
Projection step: 4, Loss: 32.237091064453125
Projection step: 5, Loss: 30.644744873046875
Projection step: 6, Loss: 28.299041748046875
Projection step: 7, Loss: 27.631298065185547
Projection step: 8, Loss: 25.402244567871094
Projection step: 9, Loss: 25.022811889648438
Projection step: 10, Loss: 22.22777557373047
Projection step: 11, Loss: 22.367420196533203
Projection step: 12, Loss: 21.31842803955078
Projection step: 13, Loss: 19.955347061157227
Projection step: 14, Loss: 17.9100341796875
Final likelihood: tensor([-14.5556, -14.5062, -17.3840, -15.3583, -17.0567, -19.3132, -15.9535,
        -18.9364, -15.8516, -16.2157, -26.2601, -27.0896, -21.6307, -15.7131,
        -21.0785, -17.7657])
Final projection likelihood: -18.4168
1 mode projection succeeded
New goal: tensor([ 0.1624,  0.6280,  0.6479,  0.6496, -0.0411,  0.6058,  0.6669,  0.8084,
         1.2916,  0.2633,  0.2654,  1.0960,  0.0282,  0.0295,  1.4556],
       device='cuda:0')
tensor([[0.0028]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0033]], device='cuda:0')
Original likelihood: -35.43546676635742
Adjusted likelihood: -35.43546676635742
Likelihood residual: 0.0
{'index': 35.43546676635742, 'thumb_middle': inf}
Current yaw: tensor([0.0205, 0.0636, 0.0327], device='cuda:0')
6 index
tensor([ 0.2775,  0.6641,  0.6794,  0.7451, -0.1102,  0.6516,  0.5985,  0.7660,
         1.3308,  0.4064,  0.0838,  1.3866,  0.0205,  0.0636,  0.0327, -0.3627],
       device='cuda:0')
Solve time for step 1 10.605777752003632
Current ori: tensor([0.0205, 0.0636, 0.0327], device='cuda:0')
Middle force: tensor([0.5222, 0.5251, 0.5259, 0.6053], device='cuda:0')
Thumb force: tensor([0.5832, 0.6289, 0.5639, 0.5870], device='cuda:0')
tensor([ 2.7011e-01,  5.4992e-01,  5.7749e-01,  6.3592e-01, -1.2245e-01,
         6.3695e-01,  6.2118e-01,  7.6220e-01,  1.3314e+00,  4.2555e-01,
         1.0395e-01,  1.3425e+00,  1.8313e-02,  6.8612e-02,  4.8965e-04,
        -5.0823e-01], device='cuda:0')
Solve time for step 2 2.19140149501618
Current ori: tensor([0.0183, 0.0686, 0.0005], device='cuda:0')
Middle force: tensor([0.5243, 0.5252, 0.6031], device='cuda:0')
Thumb force: tensor([0.6255, 0.5623, 0.5856], device='cuda:0')
tensor([ 0.2406,  0.5468,  0.5708,  0.6143, -0.1227,  0.6485,  0.6111,  0.7393,
         1.3344,  0.4281,  0.1104,  1.3113,  0.0089,  0.0695, -0.0203, -0.3925],
       device='cuda:0')
Solve time for step 3 2.2972880680463277
Current ori: tensor([ 0.0089,  0.0695, -0.0203], device='cuda:0')
Middle force: tensor([0.5011, 0.5005], device='cuda:0')
Thumb force: tensor([0.5342, 0.5029], device='cuda:0')
tensor([ 0.2362,  0.5487,  0.5687,  0.6126, -0.1256,  0.6386,  0.6177,  0.7552,
         1.3279,  0.4397,  0.1194,  1.3090,  0.0119,  0.0709, -0.0345, -0.1241],
       device='cuda:0')
Solve time for step 4 2.2634416899527423
Current ori: tensor([ 0.0119,  0.0709, -0.0345], device='cuda:0')
Middle force: tensor([0.5239], device='cuda:0')
Thumb force: tensor([0.5647], device='cuda:0')
Storing RECOVERY transition: reward=0.0786 (scaled=0.0196), steps=4
Reward stats updated: mean -0.0276 -> -0.0270, std: 0.1923
Collected 77 transitions for RL
SAC Update 1/5: Actor Loss=-0.0018, Q1 Loss=0.5690, Q2 Loss=0.5690, Entropy=0.2270, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0571
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=0.6686, Q2 Loss=0.6686, Entropy=0.3361, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7782
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.6779, Q2 Loss=0.6779, Entropy=0.0289, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1217
SAC Update 4/5: Actor Loss=-0.0001, Q1 Loss=0.6745, Q2 Loss=0.6745, Entropy=0.0293, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1217
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5969, Q2 Loss=0.5969, Entropy=0.0067, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1035

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.6%)
Q1 update: 0.04s (18.3%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (41.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000832
Q1 loss: 0.637355
Q2 loss: 0.637355
Current threshold: -30.0533
Global Scale Offset: 1.2080
Reward stats: mean=-0.0270, std=0.1923, count=77
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.6374, Q2 Loss: 0.6374, Entropy: 0.1256, Mean TD Error: 0.2365, Threshold: -30.0533
Original likelihood: -41.03282165527344
Adjusted likelihood: -41.03282165527344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 41.25262451171875
Projection step: 1, Loss: 39.13014221191406
Projection step: 2, Loss: 39.3917121887207
Projection step: 3, Loss: 37.11122131347656
Projection step: 4, Loss: 37.2869873046875
Projection step: 5, Loss: 35.360496520996094
Projection step: 6, Loss: 34.47090530395508
Projection step: 7, Loss: 33.645057678222656
Projection step: 8, Loss: 31.691394805908203
Projection step: 9, Loss: 32.503334045410156
Projection step: 10, Loss: 30.54273796081543
Projection step: 11, Loss: 29.181140899658203
Projection step: 12, Loss: 26.507884979248047
Projection step: 13, Loss: 24.495336532592773
Projection step: 14, Loss: 23.92270851135254
Final likelihood: tensor([-26.8569, -18.8028, -20.5441, -25.4169, -20.8384, -28.6782, -18.3183,
        -21.2733, -20.7429, -21.5871, -28.4827, -26.6146, -21.7928, -28.6615,
        -20.2529, -19.9940])
Final projection likelihood: -23.0536
1 mode projection succeeded
New goal: tensor([ 0.0786,  0.5875,  0.5638,  0.6641, -0.0631,  0.6427,  0.6128,  0.7850,
         1.2969,  0.2414,  0.2261,  1.1797, -0.0051,  0.0379,  1.4649],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -34.386436462402344
Adjusted likelihood: -34.386436462402344
Likelihood residual: 0.0
Original likelihood: -32.447391510009766
Adjusted likelihood: -32.447391510009766
Likelihood residual: 0.0
{'index': 32.447391510009766, 'thumb_middle': 34.386436462402344}
Current yaw: tensor([ 0.0120,  0.0726, -0.0473], device='cuda:0')
7 index
tensor([ 0.1825,  0.5928,  0.6055,  0.6311, -0.1283,  0.6341,  0.6204,  0.7596,
         1.3287,  0.4441,  0.1175,  1.3127,  0.0120,  0.0726, -0.0473, -0.0381],
       device='cuda:0')
Solve time for step 1 10.203807708981913
Current ori: tensor([ 0.0120,  0.0726, -0.0473], device='cuda:0')
Middle force: tensor([0.5625, 0.5885, 0.5523, 0.5395], device='cuda:0')
Thumb force: tensor([0.5204, 0.5624, 0.5932, 0.5748], device='cuda:0')
tensor([ 0.1482,  0.5110,  0.5107,  0.6279, -0.1403,  0.6428,  0.6137,  0.7817,
         1.3602,  0.4123,  0.0939,  1.3022,  0.0091,  0.0742, -0.0553,  3.5541],
       device='cuda:0')
Solve time for step 2 2.3761962610296905
Current ori: tensor([ 0.0091,  0.0742, -0.0553], device='cuda:0')
Middle force: tensor([0.5888, 0.5502, 0.5384], device='cuda:0')
Thumb force: tensor([0.5571, 0.5913, 0.5724], device='cuda:0')
tensor([ 1.3276e-01,  5.1551e-01,  5.0074e-01,  6.2630e-01, -1.4206e-01,
         6.5738e-01,  5.9572e-01,  7.6323e-01,  1.3778e+00,  3.9389e-01,
         8.8851e-02,  1.2746e+00, -6.7516e-04,  7.6190e-02, -7.4747e-02,
         5.8531e+00], device='cuda:0')
Solve time for step 3 2.156556350993924
Current ori: tensor([-0.0007,  0.0762, -0.0747], device='cuda:0')
Middle force: tensor([0.5173, 0.5253], device='cuda:0')
Thumb force: tensor([0.6159, 0.5308], device='cuda:0')
tensor([ 0.1277,  0.5142,  0.5014,  0.6264, -0.1487,  0.6652,  0.5823,  0.7518,
         1.3891,  0.3826,  0.0914,  1.2568, -0.0054,  0.0809, -0.0787, -5.1183],
       device='cuda:0')
Solve time for step 4 2.077023472986184
Current ori: tensor([-0.0054,  0.0809, -0.0787], device='cuda:0')
Middle force: tensor([0.5054], device='cuda:0')
Thumb force: tensor([0.5823], device='cuda:0')
Storing RECOVERY transition: reward=0.1395 (scaled=0.0349), steps=4
Reward stats updated: mean -0.0270 -> -0.0262, std: 0.1912
Collected 78 transitions for RL
SAC Update 1/5: Actor Loss=-0.0068, Q1 Loss=0.6810, Q2 Loss=0.6810, Entropy=0.5607, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0223
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.7405, Q2 Loss=0.7405, Entropy=0.0062, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1273
SAC Update 3/5: Actor Loss=-0.0019, Q1 Loss=0.7863, Q2 Loss=0.7863, Entropy=0.2418, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0964
SAC Update 4/5: Actor Loss=-0.0061, Q1 Loss=0.7165, Q2 Loss=0.7165, Entropy=0.4490, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7878
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.6664, Q2 Loss=0.6664, Entropy=0.0435, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2342

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.6%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.4%)
Actor update: 0.12s (43.3%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002990
Q1 loss: 0.718139
Q2 loss: 0.718139
Current threshold: -30.0554
Global Scale Offset: 1.2312
Reward stats: mean=-0.0262, std=0.1912, count=78
----------------------------------------------
SAC Update - Actor Loss: -0.0030, Q1 Loss: 0.7181, Q2 Loss: 0.7181, Entropy: 0.2602, Mean TD Error: 0.2536, Threshold: -30.0554
Original likelihood: -36.6815299987793
Adjusted likelihood: -36.6815299987793
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0009)
State is out of distribution
Projection step: 0, Loss: 33.43932342529297
Projection step: 1, Loss: 34.038856506347656
Projection step: 2, Loss: 33.76802444458008
Projection step: 3, Loss: 32.943359375
Projection step: 4, Loss: 31.60259246826172
Projection step: 5, Loss: 32.15339660644531
Projection step: 6, Loss: 32.51292419433594
Projection step: 7, Loss: 29.716001510620117
Projection step: 8, Loss: 29.688297271728516
Projection step: 9, Loss: 28.78410530090332
Projection step: 10, Loss: 27.82025718688965
Projection step: 11, Loss: 27.05736541748047
Projection step: 12, Loss: 25.181123733520508
Projection step: 13, Loss: 25.214242935180664
Projection step: 14, Loss: 24.261873245239258
Final likelihood: tensor([-21.7481, -26.4314, -23.8857, -21.5114, -21.4198, -24.0280, -23.4483,
        -23.2321, -24.7363, -23.8155, -21.5915, -21.4820, -24.4471, -20.6438,
        -25.0177, -23.2508])
Final projection likelihood: -23.1681
1 mode projection succeeded
New goal: tensor([ 0.0434,  0.5876,  0.5231,  0.6297, -0.1053,  0.6814,  0.5256,  0.8648,
         1.3505,  0.2953,  0.0967,  1.1984, -0.0241,  0.0510, -0.7689],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -25.661888122558594
Adjusted likelihood: -25.661888122558594
Likelihood residual: 0.0
Original likelihood: -28.219247817993164
Adjusted likelihood: -28.219247817993164
Likelihood residual: 0.0
{'index': 28.219247817993164, 'thumb_middle': 25.661888122558594}
Current yaw: tensor([-0.0030,  0.0808, -0.1100], device='cuda:0')
8 thumb_middle
tensor([ 8.2110e-02,  5.6211e-01,  5.3879e-01,  6.4780e-01, -1.5078e-01,
         6.5198e-01,  5.9415e-01,  7.7577e-01,  1.3903e+00,  4.0014e-01,
         7.7657e-02,  1.2691e+00, -3.0151e-03,  8.0778e-02, -1.0997e-01,
        -4.8089e+00], device='cuda:0')
Solve time for step 1 9.339413976005744
Current ori: tensor([-0.0030,  0.0808, -0.1100], device='cuda:0')
Index force: tensor([0.5777, 0.5981, 0.5777, 0.5780], device='cuda:0')
tensor([ 7.4963e-02,  5.6538e-01,  5.2621e-01,  6.4701e-01, -2.0639e-01,
         6.6286e-01,  4.9353e-01,  8.2437e-01,  1.3632e+00,  2.9810e-01,
         4.6424e-02,  1.2012e+00, -1.9304e-04,  8.8931e-02, -1.0995e-01,
        -4.8838e+00], device='cuda:0')
Solve time for step 2 1.994624548999127
Current ori: tensor([-0.0002,  0.0889, -0.1100], device='cuda:0')
Index force: tensor([0.5920, 0.5731, 0.5726], device='cuda:0')
tensor([ 0.0902,  0.5754,  0.5351,  0.6323, -0.2034,  0.6798,  0.5028,  0.8189,
         1.3594,  0.2822,  0.0455,  1.1973, -0.0051,  0.0795, -0.1100, -4.8585],
       device='cuda:0')
Solve time for step 3 1.812479785992764
Current ori: tensor([-0.0051,  0.0795, -0.1100], device='cuda:0')
Index force: tensor([0.5676, 0.5673], device='cuda:0')
tensor([ 0.1060,  0.5899,  0.5284,  0.6373, -0.1970,  0.6815,  0.4992,  0.8469,
         1.3478,  0.2939,  0.0483,  1.1812, -0.0092,  0.0698, -0.1100, -4.8353],
       device='cuda:0')
Solve time for step 4 1.7986666989745572
Current ori: tensor([-0.0092,  0.0698, -0.1100], device='cuda:0')
Index force: tensor([0.5674], device='cuda:0')
Storing RECOVERY transition: reward=0.1439 (scaled=0.0360), steps=4
Reward stats updated: mean -0.0262 -> -0.0254, std: 0.1901
Collected 79 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=1.0871, Q2 Loss=1.0871, Entropy=0.1071, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9239
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.8226, Q2 Loss=0.8226, Entropy=0.1092, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8138
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.6498, Q2 Loss=0.6498, Entropy=0.1373, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7785
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5326, Q2 Loss=0.5326, Entropy=0.0006, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0683
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.6170, Q2 Loss=0.6170, Entropy=0.0036, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0448

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.7%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (19.4%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000156
Q1 loss: 0.741807
Q2 loss: 0.741807
Current threshold: -30.0534
Global Scale Offset: 1.2532
Reward stats: mean=-0.0254, std=0.1901, count=79
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.7418, Q2 Loss: 0.7418, Entropy: 0.0716, Mean TD Error: 0.5259, Threshold: -30.0534
Original likelihood: -32.718788146972656
Adjusted likelihood: -32.718788146972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.1080)
Current yaw: tensor([-0.0083,  0.0808, -0.1145], device='cuda:0')
9 turn
Sampling time 3.701475393027067
tensor([ 0.0750,  0.5828,  0.5247,  0.6071, -0.1735,  0.7136,  0.5077,  0.8787,
         1.4242,  0.2982,  0.1020,  1.2104, -0.0083,  0.0808, -0.1145, -4.7620],
       device='cuda:0')
Original likelihood: -32.027767181396484
Adjusted likelihood: -32.027767181396484
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1797)
State is out of distribution
Projection step: 0, Loss: 33.26559066772461
Projection step: 1, Loss: 32.301109313964844
Projection step: 2, Loss: 30.73636245727539
Projection step: 3, Loss: 31.510082244873047
Projection step: 4, Loss: 29.953128814697266
Projection step: 5, Loss: 28.96884536743164
Projection step: 6, Loss: 29.417938232421875
Projection step: 7, Loss: 28.490381240844727
Projection step: 8, Loss: 27.518083572387695
Projection step: 9, Loss: 26.316144943237305
Projection step: 10, Loss: 26.03505516052246
Projection step: 11, Loss: 25.784225463867188
Projection step: 12, Loss: 25.491676330566406
Projection step: 13, Loss: 24.104812622070312
Projection step: 14, Loss: 23.12638282775879
Final likelihood: tensor([-24.6172, -25.0255, -24.1322, -25.2114, -23.0340, -21.4533, -28.3448,
        -25.3966, -24.6837, -28.1465, -20.5019, -21.5023, -24.0826, -22.3025,
        -24.5856, -24.4972])
Final projection likelihood: -24.2198
1 mode projection succeeded
New goal: tensor([ 0.0363,  0.5908,  0.5311,  0.5981, -0.1089,  0.6990,  0.4871,  0.8696,
         1.3737,  0.2246,  0.1052,  1.1857, -0.0262,  0.0533, -0.9080],
       device='cuda:0')
tensor([[0.0020]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -27.340959548950195
Adjusted likelihood: -27.340959548950195
Likelihood residual: 0.0
Original likelihood: -24.9483699798584
Adjusted likelihood: -24.9483699798584
Likelihood residual: 0.0
{'index': 24.9483699798584, 'thumb_middle': 27.340959548950195}
Current yaw: tensor([-0.0083,  0.0808, -0.1145], device='cuda:0')
10 index
tensor([ 0.0750,  0.5828,  0.5247,  0.6071, -0.1735,  0.7136,  0.5077,  0.8787,
         1.4242,  0.2982,  0.1020,  1.2104, -0.0083,  0.0808, -0.1145, -4.7620],
       device='cuda:0')
Solve time for step 1 11.03919802501332
Current ori: tensor([-0.0083,  0.0808, -0.1145], device='cuda:0')
Middle force: tensor([0.5262, 0.5552, 0.5628, 0.5854], device='cuda:0')
Thumb force: tensor([0.5121, 0.6123, 0.5212, 0.5987], device='cuda:0')
tensor([ 0.0888,  0.5117,  0.4700,  0.5706, -0.1812,  0.7159,  0.5049,  0.8812,
         1.4585,  0.2472,  0.0864,  1.1989, -0.0117,  0.0840, -0.1284, -2.7647],
       device='cuda:0')
Solve time for step 2 2.3105096739600413
Current ori: tensor([-0.0117,  0.0840, -0.1284], device='cuda:0')
Middle force: tensor([0.5536, 0.5613, 0.5826], device='cuda:0')
Thumb force: tensor([0.6073, 0.5197, 0.5963], device='cuda:0')
tensor([ 0.0861,  0.5222,  0.4663,  0.5668, -0.1637,  0.7415,  0.4854,  0.8594,
         1.4556,  0.2438,  0.0700,  1.1990, -0.0215,  0.0741, -0.1224, -1.6065],
       device='cuda:0')
Solve time for step 3 2.110077556979377
Current ori: tensor([-0.0215,  0.0741, -0.1224], device='cuda:0')
Middle force: tensor([0.5072, 0.5056], device='cuda:0')
Thumb force: tensor([0.5855, 0.5902], device='cuda:0')
tensor([ 0.0867,  0.5245,  0.4696,  0.5659, -0.1598,  0.7400,  0.4895,  0.8632,
         1.4400,  0.2837,  0.0707,  1.1949, -0.0224,  0.0713, -0.1374, -0.6096],
       device='cuda:0')
Solve time for step 4 2.085055595031008
Current ori: tensor([-0.0224,  0.0713, -0.1374], device='cuda:0')
Middle force: tensor([0.5269], device='cuda:0')
Thumb force: tensor([0.5807], device='cuda:0')
Storing RECOVERY transition: reward=0.0107 (scaled=0.0107), steps=0
Reward stats updated: mean -0.0254 -> -0.0249, std: 0.1890
Collected 80 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=1.1514, Q2 Loss=1.1514, Entropy=0.1557, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9576
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.5098, Q2 Loss=0.5098, Entropy=0.2670, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0478
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.4416, Q2 Loss=0.4416, Entropy=0.0786, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0193
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.5844, Q2 Loss=0.5844, Entropy=0.0478, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0207
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=1.1520, Q2 Loss=1.1520, Entropy=0.1605, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9576

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.04s (18.4%)
Q2 update: 0.04s (17.9%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000497
Q1 loss: 0.767842
Q2 loss: 0.767842
Current threshold: -30.0549
Global Scale Offset: 1.2771
Reward stats: mean=-0.0249, std=0.1890, count=80
----------------------------------------------
SAC Update - Actor Loss: -0.0005, Q1 Loss: 0.7678, Q2 Loss: 0.7678, Entropy: 0.1419, Mean TD Error: 0.4006, Threshold: -30.0549
Original likelihood: -29.726451873779297
Adjusted likelihood: -29.726451873779297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5598)
Current yaw: tensor([-0.0258,  0.0789, -0.1256], device='cuda:0')
11 turn
Sampling time 3.6599048119969666
tensor([ 0.0315,  0.5804,  0.5048,  0.5816, -0.1708,  0.7472,  0.4787,  0.8440,
         1.4690,  0.2518,  0.0554,  1.1866, -0.0258,  0.0789, -0.1256, -0.3701],
       device='cuda:0')
Original likelihood: -29.278501510620117
Adjusted likelihood: -29.278501510620117
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6389)
State is out of distribution
Projection step: 0, Loss: 29.56389617919922
Projection step: 1, Loss: 29.830810546875
Projection step: 2, Loss: 30.731149673461914
Projection step: 3, Loss: 28.58568572998047
Projection step: 4, Loss: 27.69013214111328
Projection step: 5, Loss: 28.427928924560547
Projection step: 6, Loss: 27.422077178955078
Projection step: 7, Loss: 27.109092712402344
Projection step: 8, Loss: 26.726261138916016
Projection step: 9, Loss: 25.558679580688477
Projection step: 10, Loss: 25.5457706451416
Projection step: 11, Loss: 24.776588439941406
Projection step: 12, Loss: 25.772113800048828
Projection step: 13, Loss: 24.641433715820312
Projection step: 14, Loss: 24.781150817871094
Final likelihood: tensor([-20.7163, -20.2896, -20.2858, -21.0749, -20.9625, -24.5424, -24.0802,
        -23.5249, -21.5419, -24.0084, -21.4379, -20.3662, -23.9884, -21.3222,
        -22.6306, -24.0631])
Final projection likelihood: -22.1772
1 mode projection succeeded
New goal: tensor([ 0.0373,  0.5867,  0.5274,  0.6140, -0.1063,  0.6893,  0.4798,  0.8829,
         1.4071,  0.2249,  0.0995,  1.1504, -0.0330,  0.0557, -0.6771],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0025]], device='cuda:0')
Original likelihood: -25.024795532226562
Adjusted likelihood: -25.024795532226562
Likelihood residual: 0.0
Original likelihood: -24.423948287963867
Adjusted likelihood: -24.423948287963867
Likelihood residual: 0.0
{'index': 24.423948287963867, 'thumb_middle': 25.024795532226562}
Current yaw: tensor([-0.0258,  0.0789, -0.1256], device='cuda:0')
12 index
tensor([ 0.0315,  0.5804,  0.5048,  0.5816, -0.1708,  0.7472,  0.4787,  0.8440,
         1.4690,  0.2518,  0.0554,  1.1866, -0.0258,  0.0789, -0.1256, -0.3701],
       device='cuda:0')
Solve time for step 1 11.047354648995679
Current ori: tensor([-0.0258,  0.0789, -0.1256], device='cuda:0')
Middle force: tensor([0.5105, 0.5410, 0.5569, 0.5471], device='cuda:0')
Thumb force: tensor([0.5957, 0.5441, 0.6376, 0.6356], device='cuda:0')
tensor([ 0.0838,  0.5123,  0.4630,  0.5768, -0.1684,  0.7377,  0.4842,  0.8735,
         1.4659,  0.2549,  0.0536,  1.1922, -0.0212,  0.0764, -0.1440, -0.2383],
       device='cuda:0')
Solve time for step 2 2.382572650036309
Current ori: tensor([-0.0212,  0.0764, -0.1440], device='cuda:0')
Middle force: tensor([0.5840, 0.5494, 0.5442], device='cuda:0')
Thumb force: tensor([0.5751, 0.5795, 0.5668], device='cuda:0')
tensor([ 0.0817,  0.5211,  0.4594,  0.5837, -0.1731,  0.7434,  0.4814,  0.8670,
         1.4646,  0.2589,  0.0577,  1.1873, -0.0237,  0.0781, -0.1344,  0.1539],
       device='cuda:0')
Solve time for step 3 2.343601669999771
Current ori: tensor([-0.0237,  0.0781, -0.1344], device='cuda:0')
Middle force: tensor([0.5536, 0.5018], device='cuda:0')
Thumb force: tensor([0.5648, 0.5919], device='cuda:0')
tensor([ 0.0809,  0.5224,  0.4607,  0.5874, -0.1625,  0.7576,  0.4724,  0.8517,
         1.4678,  0.2481,  0.0447,  1.1852, -0.0302,  0.0720, -0.1357,  0.6338],
       device='cuda:0')
Solve time for step 4 1.8951491960324347
Current ori: tensor([-0.0302,  0.0720, -0.1357], device='cuda:0')
Middle force: tensor([0.5014], device='cuda:0')
Thumb force: tensor([0.5824], device='cuda:0')
Storing RECOVERY transition: reward=0.0217 (scaled=0.0217), steps=0
Reward stats updated: mean -0.0249 -> -0.0244, std: 0.1879
Collected 81 transitions for RL
SAC Update 1/5: Actor Loss=-0.0070, Q1 Loss=0.6664, Q2 Loss=0.6664, Entropy=0.3597, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0146
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=0.6653, Q2 Loss=0.6653, Entropy=0.2404, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7829
SAC Update 3/5: Actor Loss=-0.0037, Q1 Loss=0.4960, Q2 Loss=0.4960, Entropy=0.3608, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0551
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=1.0854, Q2 Loss=1.0854, Entropy=0.1166, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9238
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.5937, Q2 Loss=0.5937, Entropy=0.0348, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0432

------ SAC Update Summary (5 iterations) ------
Total time: 0.33s, Avg iteration: 0.07s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.2%)
Q1 update: 0.07s (20.1%)
Q2 update: 0.06s (19.3%)
Actor update: 0.13s (41.3%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002402
Q1 loss: 0.701353
Q2 loss: 0.701353
Current threshold: -30.0695
Global Scale Offset: 1.2995
Reward stats: mean=-0.0244, std=0.1879, count=81
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 0.7014, Q2 Loss: 0.7014, Entropy: 0.2224, Mean TD Error: 0.3639, Threshold: -30.0695
Original likelihood: -29.565500259399414
Adjusted likelihood: -29.565500259399414
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.5902)
State is out of distribution
Projection step: 0, Loss: 28.845489501953125
Projection step: 1, Loss: 28.271533966064453
Projection step: 2, Loss: 28.34674644470215
Projection step: 3, Loss: 26.782737731933594
Projection step: 4, Loss: 27.48028564453125
Projection step: 5, Loss: 26.20978355407715
Projection step: 6, Loss: 25.895648956298828
Projection step: 7, Loss: 26.33550262451172
Projection step: 8, Loss: 25.27570343017578
Projection step: 9, Loss: 24.82526397705078
Projection step: 10, Loss: 23.994922637939453
Projection step: 11, Loss: 23.522130966186523
Projection step: 12, Loss: 22.938610076904297
Projection step: 13, Loss: 21.74787139892578
Projection step: 14, Loss: 22.573673248291016
Final likelihood: tensor([-19.7952, -20.4592, -23.2865, -18.6724, -21.9439, -23.3422, -23.4574,
        -21.2506, -22.4112, -22.6329, -22.6850, -23.2643, -22.8371, -23.5093,
        -24.7294, -24.4666])
Final projection likelihood: -22.4215
1 mode projection succeeded
New goal: tensor([ 0.0398,  0.5829,  0.5141,  0.6290, -0.0992,  0.6810,  0.4978,  0.8965,
         1.4093,  0.2121,  0.0956,  1.1513, -0.0332,  0.0503, -0.6874],
       device='cuda:0')
tensor([[0.0022]], device='cuda:0') tensor([[0.0023]], device='cuda:0') tensor([[0.0027]], device='cuda:0')
Original likelihood: -21.48856544494629
Adjusted likelihood: -21.48856544494629
Likelihood residual: 0.0
Original likelihood: -25.639055252075195
Adjusted likelihood: -25.639055252075195
Likelihood residual: 0.0
{'index': 25.639055252075195, 'thumb_middle': 21.48856544494629}
Current yaw: tensor([-0.0264,  0.0733, -0.1468], device='cuda:0')
13 thumb_middle
tensor([ 0.0352,  0.5743,  0.5055,  0.6041, -0.1653,  0.7474,  0.4796,  0.8678,
         1.4672,  0.2651,  0.0362,  1.1965, -0.0264,  0.0733, -0.1468,  0.7536],
       device='cuda:0')
Solve time for step 1 9.289155868988018
Current ori: tensor([-0.0264,  0.0733, -0.1468], device='cuda:0')
Index force: tensor([0.5898, 0.5850, 0.5818, 0.5649], device='cuda:0')
tensor([ 0.0403,  0.5976,  0.4865,  0.5864, -0.2009,  0.6970,  0.4741,  0.8724,
         1.3895,  0.2102,  0.0298,  1.1408, -0.0328,  0.0711, -0.1468,  0.7366],
       device='cuda:0')
Solve time for step 2 2.0666031900327653
Current ori: tensor([-0.0328,  0.0711, -0.1468], device='cuda:0')
Index force: tensor([0.5822, 0.5804, 0.5636], device='cuda:0')
tensor([ 0.0513,  0.6064,  0.4883,  0.5788, -0.1973,  0.7060,  0.4779,  0.8750,
         1.3943,  0.1943,  0.0238,  1.1331, -0.0361,  0.0643, -0.1468,  0.7484],
       device='cuda:0')
Solve time for step 3 1.9436744549893774
Current ori: tensor([-0.0361,  0.0643, -0.1468], device='cuda:0')
Index force: tensor([0.5767, 0.5612], device='cuda:0')
tensor([ 0.0516,  0.5947,  0.4945,  0.5990, -0.1980,  0.7065,  0.4799,  0.8746,
         1.3987,  0.1930,  0.0215,  1.1305, -0.0320,  0.0643, -0.1468,  0.7564],
       device='cuda:0')
Solve time for step 4 1.9209432950010523
Current ori: tensor([-0.0320,  0.0643, -0.1468], device='cuda:0')
Index force: tensor([0.5475], device='cuda:0')
Storing RECOVERY transition: reward=0.0238 (scaled=0.0238), steps=0
Reward stats updated: mean -0.0244 -> -0.0238, std: 0.1868
Collected 82 transitions for RL
SAC Update 1/5: Actor Loss=-0.0035, Q1 Loss=0.4899, Q2 Loss=0.4899, Entropy=0.3313, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0565
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.6084, Q2 Loss=0.6084, Entropy=0.0057, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1904
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=0.6814, Q2 Loss=0.6814, Entropy=0.3755, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0175
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.7362, Q2 Loss=0.7362, Entropy=0.2234, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7974
SAC Update 5/5: Actor Loss=-0.0028, Q1 Loss=0.6621, Q2 Loss=0.6621, Entropy=0.3127, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0119

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.1%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.05s (19.3%)
Actor update: 0.10s (39.7%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003010
Q1 loss: 0.635615
Q2 loss: 0.635615
Current threshold: -30.0886
Global Scale Offset: 1.3158
Reward stats: mean=-0.0238, std=0.1868, count=82
----------------------------------------------
SAC Update - Actor Loss: -0.0030, Q1 Loss: 0.6356, Q2 Loss: 0.6356, Entropy: 0.2497, Mean TD Error: 0.2147, Threshold: -30.0886
Original likelihood: -26.225662231445312
Adjusted likelihood: -26.225662231445312
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9583)
Current yaw: tensor([-0.0286,  0.0565, -0.1469], device='cuda:0')
14 turn
Sampling time 3.823432659963146
tensor([ 0.0599,  0.5751,  0.5172,  0.6241, -0.1380,  0.7302,  0.5090,  0.8740,
         1.4541,  0.2277,  0.0625,  1.1581, -0.0286,  0.0565, -0.1469,  0.8182],
       device='cuda:0')
Original likelihood: -24.676931381225586
Adjusted likelihood: -24.676931381225586
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9924)
Solve time for step 1 14.720747479994316
Current ori: tensor([-0.0286,  0.0565, -0.1469], device='cuda:0')
Middle force: tensor([0.5296, 0.6461, 0.5591, 0.5041, 0.6879, 0.9265, 0.5922, 0.5790, 0.8327,
        0.5254, 1.0281, 0.6536], device='cuda:0')
Thumb force: tensor([0.8443, 0.7415, 1.4663, 2.2634, 0.8174, 1.6056, 0.6066, 0.5038, 0.5891,
        1.0549, 0.5665, 0.7551], device='cuda:0')
Index force: tensor([0.5338, 0.8928, 0.6173, 0.6195, 0.6056, 0.5995, 0.5911, 0.5816, 0.6366,
        0.5307, 0.5123, 0.7313], device='cuda:0')
Storing NORMAL transition: reward=0.0262 (scaled=0.0262), steps=1
Reward stats updated: mean -0.0238 -> -0.0232, std: 0.1858
Collected 83 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.7867, Q2 Loss=0.7867, Entropy=0.1258, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8096
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.5371, Q2 Loss=0.5371, Entropy=0.0565, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0537
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.6559, Q2 Loss=0.6559, Entropy=0.0012, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2256
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.7834, Q2 Loss=0.7834, Entropy=0.1284, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8096
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.4753, Q2 Loss=0.4753, Entropy=0.0626, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0607

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.2%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.5%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000171
Q1 loss: 0.647666
Q2 loss: 0.647666
Current threshold: -30.1009
Global Scale Offset: 1.3364
Reward stats: mean=-0.0232, std=0.1858, count=83
----------------------------------------------
SAC Update - Actor Loss: -0.0002, Q1 Loss: 0.6477, Q2 Loss: 0.6477, Entropy: 0.0749, Mean TD Error: 0.3918, Threshold: -30.1009
tensor([ 0.0790,  0.5451,  0.5663,  0.6448, -0.1288,  0.6824,  0.6033,  0.8476,
         1.4151,  0.3020,  0.0766,  1.1582, -0.0201,  0.0472, -0.1718,  0.8698],
       device='cuda:0')
Original likelihood: -26.026817321777344
Adjusted likelihood: -26.026817321777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9646)
Solve time for step 2 3.1659710980020463
Current ori: tensor([-0.0201,  0.0472, -0.1718], device='cuda:0')
Middle force: tensor([0.6370, 0.5570, 0.5035, 0.6809, 0.9097, 0.5882, 0.5760, 0.8217, 0.5237,
        1.0167, 0.6482], device='cuda:0')
Thumb force: tensor([0.7319, 1.4258, 2.2075, 0.8067, 1.5668, 0.6034, 0.5032, 0.5860, 1.0532,
        0.5638, 0.7500], device='cuda:0')
Index force: tensor([0.8803, 0.6150, 0.6144, 0.6013, 0.5955, 0.5885, 0.5798, 0.6339, 0.5271,
        0.5113, 0.7257], device='cuda:0')
Storing NORMAL transition: reward=0.0657 (scaled=0.0657), steps=1
Reward stats updated: mean -0.0232 -> -0.0221, std: 0.1849
Collected 84 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.8145, Q2 Loss=0.8145, Entropy=0.1645, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8185
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.4263, Q2 Loss=0.4263, Entropy=0.0771, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0471
SAC Update 3/5: Actor Loss=-0.0104, Q1 Loss=0.6447, Q2 Loss=0.6447, Entropy=0.3667, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0434
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.6414, Q2 Loss=0.6414, Entropy=0.0411, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1206
SAC Update 5/5: Actor Loss=-0.0060, Q1 Loss=0.6710, Q2 Loss=0.6710, Entropy=0.4708, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7874

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.9%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003420
Q1 loss: 0.639570
Q2 loss: 0.639570
Current threshold: -30.1153
Global Scale Offset: 1.3531
Reward stats: mean=-0.0221, std=0.1849, count=84
----------------------------------------------
SAC Update - Actor Loss: -0.0034, Q1 Loss: 0.6396, Q2 Loss: 0.6396, Entropy: 0.2240, Mean TD Error: 0.3634, Threshold: -30.1153
tensor([ 0.0922,  0.4874,  0.5873,  0.7860, -0.1734,  0.6350,  0.7520,  0.8795,
         1.3949,  0.4119,  0.0552,  1.1797,  0.0025,  0.0410, -0.2368,  1.0130],
       device='cuda:0')
Original likelihood: -29.469680786132812
Adjusted likelihood: -29.469680786132812
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6117)
Solve time for step 3 2.6836169229936786
Current ori: tensor([ 0.0025,  0.0410, -0.2368], device='cuda:0')
Middle force: tensor([0.5546, 0.5034, 0.6753, 0.8962, 0.5852, 0.5751, 0.8183, 0.5221, 1.0101,
        0.6465], device='cuda:0')
Thumb force: tensor([1.3859, 2.1494, 0.7963, 1.5301, 0.6004, 0.5027, 0.5829, 1.0564, 0.5619,
        0.7468], device='cuda:0')
Index force: tensor([0.6096, 0.6057, 0.5979, 0.5920, 0.5854, 0.5770, 0.6276, 0.5230, 0.5099,
        0.7148], device='cuda:0')
Storing NORMAL transition: reward=0.0018 (scaled=0.0018), steps=1
Reward stats updated: mean -0.0221 -> -0.0218, std: 0.1838
Collected 85 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.5968, Q2 Loss=0.5968, Entropy=0.4464, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0368
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.6046, Q2 Loss=0.6046, Entropy=0.0422, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1101
SAC Update 3/5: Actor Loss=-0.0031, Q1 Loss=0.5828, Q2 Loss=0.5828, Entropy=0.3948, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1932
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.5762, Q2 Loss=0.5762, Entropy=0.0015, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2004
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=0.9555, Q2 Loss=0.9555, Entropy=0.1370, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8671

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.05s (20.2%)
Q2 update: 0.05s (19.0%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002601
Q1 loss: 0.663186
Q2 loss: 0.663186
Current threshold: -30.1293
Global Scale Offset: 1.3687
Reward stats: mean=-0.0218, std=0.1838, count=85
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 0.6632, Q2 Loss: 0.6632, Entropy: 0.2044, Mean TD Error: 0.2815, Threshold: -30.1293
tensor([ 0.1338,  0.4909,  0.6116,  0.8101, -0.2423,  0.6261,  0.8022,  0.8555,
         1.3189,  0.5764,  0.0737,  1.1631,  0.0040,  0.0175, -0.2370,  1.0688],
       device='cuda:0')
Original likelihood: -34.456336975097656
Adjusted likelihood: -34.456336975097656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.0297)
Solve time for step 4 2.6382518660393544
Current ori: tensor([ 0.0040,  0.0175, -0.2370], device='cuda:0')
Middle force: tensor([0.5031, 0.6711, 0.8849, 0.5826, 0.5744, 0.8153, 0.5207, 1.0034, 0.6448],
       device='cuda:0')
Thumb force: tensor([2.1002, 0.7871, 1.4962, 0.5976, 0.5023, 0.5804, 1.0592, 0.5608, 0.7465],
       device='cuda:0')
Index force: tensor([0.6007, 0.5948, 0.5885, 0.5824, 0.5737, 0.6212, 0.5195, 0.5086, 0.7020],
       device='cuda:0')
Storing NORMAL transition: reward=0.0956 (scaled=0.0956), steps=1
Reward stats updated: mean -0.0218 -> -0.0205, std: 0.1832
Collected 86 transitions for RL
SAC Update 1/5: Actor Loss=-0.0024, Q1 Loss=0.5881, Q2 Loss=0.5881, Entropy=0.2968, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0320
SAC Update 2/5: Actor Loss=-0.0020, Q1 Loss=0.5908, Q2 Loss=0.5908, Entropy=0.3613, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7784
SAC Update 3/5: Actor Loss=-0.0149, Q1 Loss=0.4700, Q2 Loss=0.4700, Entropy=0.0797, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1282
SAC Update 4/5: Actor Loss=-0.0247, Q1 Loss=0.5618, Q2 Loss=0.5618, Entropy=0.4317, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0461
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=0.8034, Q2 Loss=0.8034, Entropy=0.1754, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8185

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.008887
Q1 loss: 0.602812
Q2 loss: 0.602812
Current threshold: -30.1314
Global Scale Offset: 1.3595
Reward stats: mean=-0.0205, std=0.1832, count=86
----------------------------------------------
SAC Update - Actor Loss: -0.0089, Q1 Loss: 0.6028, Q2 Loss: 0.6028, Entropy: 0.2690, Mean TD Error: 0.3607, Threshold: -30.1314
tensor([ 8.0647e-02,  3.4613e-01,  6.9591e-01,  7.6829e-01, -7.8808e-02,
         6.5214e-01,  8.9160e-01,  8.3113e-01,  1.3440e+00,  5.6863e-01,
         1.5778e-03,  1.1532e+00,  7.0432e-04, -4.7797e-02, -3.3567e-01,
         7.1943e-01], device='cuda:0')
Original likelihood: -29.25591468811035
Adjusted likelihood: -29.25591468811035
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6493)
State is out of distribution
Projection step: 0, Loss: 38.39354705810547
Projection step: 1, Loss: 23.859575271606445
Projection step: 2, Loss: 23.507736206054688
Projection step: 3, Loss: 22.79886817932129
Projection step: 4, Loss: 27.83688735961914
Projection step: 5, Loss: 21.7982177734375
Projection step: 6, Loss: 18.515907287597656
Projection step: 7, Loss: 16.46761131286621
Projection step: 8, Loss: 13.608561515808105
Final likelihood: tensor([-17.9415, -17.0150, -15.4278, -10.8083, -10.7943, -10.5412, -16.3937,
        -11.2265, -13.2640, -19.5016, -16.8898, -11.9478, -12.1318, -11.8648,
        -10.9678, -11.0210])
Final projection likelihood: -13.6086
1 mode projection succeeded
New goal: tensor([ 9.2103e-02,  4.0923e-01,  6.9665e-01,  8.2538e-01, -2.3547e-02,
         5.8492e-01,  8.3599e-01,  8.1766e-01,  1.3542e+00,  3.6820e-01,
         1.1359e-01,  1.0191e+00, -8.8162e-04, -3.8912e-02, -1.0363e+00],
       device='cuda:0')
tensor([[0.0023]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0064]], device='cuda:0')
Original likelihood: -27.078594207763672
Adjusted likelihood: -27.078594207763672
Likelihood residual: 0.0
{'index': 27.078594207763672, 'thumb_middle': inf}
Current yaw: tensor([ 0.0007, -0.0478, -0.3357], device='cuda:0')
15 index
tensor([ 8.0647e-02,  3.4613e-01,  6.9591e-01,  7.6829e-01, -7.8808e-02,
         6.5214e-01,  8.9160e-01,  8.3113e-01,  1.3440e+00,  5.6863e-01,
         1.5778e-03,  1.1532e+00,  7.0432e-04, -4.7797e-02, -3.3567e-01,
         7.1943e-01], device='cuda:0')
Solve time for step 1 10.870272885018494
Current ori: tensor([ 0.0007, -0.0478, -0.3357], device='cuda:0')
Middle force: tensor([0.5177, 0.5311, 0.5328, 0.5497], device='cuda:0')
Thumb force: tensor([0.5455, 0.6601, 0.5665, 0.6166], device='cuda:0')
tensor([ 0.1380,  0.3423,  0.6350,  0.7779, -0.0924,  0.6854,  0.8958,  0.8323,
         1.3794,  0.5151, -0.0348,  1.1325, -0.0090, -0.0563, -0.3821, -4.3478],
       device='cuda:0')
Solve time for step 2 2.3175468239933252
Current ori: tensor([-0.0090, -0.0563, -0.3821], device='cuda:0')
Middle force: tensor([0.5295, 0.5310, 0.5472], device='cuda:0')
Thumb force: tensor([0.6582, 0.5652, 0.6147], device='cuda:0')
tensor([ 0.1410,  0.3563,  0.6321,  0.7787, -0.1074,  0.6976,  0.8877,  0.8302,
         1.3988,  0.4821, -0.0373,  1.1182, -0.0076, -0.0515, -0.4131,  0.2114],
       device='cuda:0')
Solve time for step 3 2.2486349379760213
Current ori: tensor([-0.0076, -0.0515, -0.4131], device='cuda:0')
Middle force: tensor([0.5291, 0.5446], device='cuda:0')
Thumb force: tensor([0.5626, 0.6132], device='cuda:0')
tensor([ 0.1393,  0.3590,  0.6314,  0.7801, -0.1209,  0.7308,  0.8950,  0.8165,
         1.4091,  0.4693, -0.0569,  1.1207, -0.0080, -0.0599, -0.4512,  2.9934],
       device='cuda:0')
Solve time for step 4 2.0922866910113953
Current ori: tensor([-0.0080, -0.0599, -0.4512], device='cuda:0')
Middle force: tensor([0.5000], device='cuda:0')
Thumb force: tensor([0.5823], device='cuda:0')
Storing RECOVERY transition: reward=0.1025 (scaled=0.0256), steps=4
Reward stats updated: mean -0.0205 -> -0.0199, std: 0.1822
Collected 87 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.6559, Q2 Loss=0.6559, Entropy=0.1733, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7868
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.9735, Q2 Loss=0.9735, Entropy=0.1391, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8737
SAC Update 3/5: Actor Loss=-0.0030, Q1 Loss=0.3975, Q2 Loss=0.3975, Entropy=0.3655, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0409
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.6341, Q2 Loss=0.6341, Entropy=0.0099, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1524
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5381, Q2 Loss=0.5381, Entropy=0.0102, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0080

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.9%)
Q1 update: 0.06s (20.2%)
Q2 update: 0.06s (20.1%)
Actor update: 0.12s (41.9%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000756
Q1 loss: 0.639826
Q2 loss: 0.639826
Current threshold: -30.1266
Global Scale Offset: 1.3339
Reward stats: mean=-0.0199, std=0.1822, count=87
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 0.6398, Q2 Loss: 0.6398, Entropy: 0.1396, Mean TD Error: 0.3723, Threshold: -30.1266
Original likelihood: -33.61072540283203
Adjusted likelihood: -33.61072540283203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0609)
State is out of distribution
Projection step: 0, Loss: 31.380678176879883
Projection step: 1, Loss: 28.986129760742188
Projection step: 2, Loss: 27.815828323364258
Projection step: 3, Loss: 26.249675750732422
Projection step: 4, Loss: 24.335235595703125
Projection step: 5, Loss: 23.42859649658203
Projection step: 6, Loss: 23.494029998779297
Projection step: 7, Loss: 25.529144287109375
Projection step: 8, Loss: 22.991222381591797
Projection step: 9, Loss: 22.975101470947266
Projection step: 10, Loss: 18.702594757080078
Projection step: 11, Loss: 20.10958480834961
Projection step: 12, Loss: 17.654224395751953
Projection step: 13, Loss: 16.423255920410156
Projection step: 14, Loss: 16.183029174804688
Final likelihood: tensor([-22.4905, -20.0077, -17.7493, -12.4248, -12.1932, -17.1032, -19.3250,
        -12.4771, -18.0932, -21.8266, -17.1119, -19.7936, -17.8274, -18.1549,
        -11.7384, -12.4017])
Final projection likelihood: -16.9199
1 mode projection succeeded
New goal: tensor([ 0.1255,  0.4364,  0.6683,  0.8468, -0.0165,  0.6336,  0.8469,  0.8081,
         1.4059,  0.2836,  0.1036,  0.9636, -0.0110, -0.0509, -1.7540],
       device='cuda:0')
tensor([[0.0023]], device='cuda:0') tensor([[0.0023]], device='cuda:0') tensor([[0.0027]], device='cuda:0')
Original likelihood: -21.353343963623047
Adjusted likelihood: -21.353343963623047
Likelihood residual: 0.0
Original likelihood: -25.61994743347168
Adjusted likelihood: -25.61994743347168
Likelihood residual: 0.0
{'index': 25.61994743347168, 'thumb_middle': 21.353343963623047}
Current yaw: tensor([-0.0028, -0.0645, -0.4438], device='cuda:0')
16 thumb_middle
tensor([ 9.7714e-02,  4.0684e-01,  6.7575e-01,  8.0933e-01, -1.1723e-01,
         7.3527e-01,  8.9621e-01,  8.1876e-01,  1.3995e+00,  4.8812e-01,
        -8.0677e-02,  1.1716e+00, -2.7860e-03, -6.4468e-02, -4.4377e-01,
         3.5481e+00], device='cuda:0')
Solve time for step 1 9.062783017987385
Current ori: tensor([-0.0028, -0.0645, -0.4438], device='cuda:0')
Index force: tensor([0.5282, 0.5003, 0.5816, 0.5722], device='cuda:0')
tensor([ 0.0951,  0.4075,  0.6578,  0.8411, -0.1198,  0.6558,  0.8098,  0.7947,
         1.3479,  0.3176, -0.0157,  0.9653,  0.0113, -0.0659, -0.4437,  3.6418],
       device='cuda:0')
Solve time for step 2 2.0354498630040325
Current ori: tensor([ 0.0113, -0.0659, -0.4437], device='cuda:0')
Index force: tensor([0.5002, 0.5686, 0.5428], device='cuda:0')
tensor([ 0.0966,  0.4185,  0.6499,  0.8310, -0.1162,  0.6545,  0.8214,  0.7952,
         1.3466,  0.2754,  0.0127,  0.9306,  0.0264, -0.0707, -0.4437,  3.8164],
       device='cuda:0')
Solve time for step 3 1.9184472470078617
Current ori: tensor([ 0.0264, -0.0707, -0.4437], device='cuda:0')
Index force: tensor([0.5665, 0.5597], device='cuda:0')
tensor([ 0.0868,  0.4155,  0.6469,  0.8317, -0.1167,  0.6565,  0.8218,  0.7923,
         1.3623,  0.2941,  0.0051,  0.9258,  0.0396, -0.0631, -0.4437,  3.9433],
       device='cuda:0')
Solve time for step 4 1.868482424004469
Current ori: tensor([ 0.0396, -0.0631, -0.4437], device='cuda:0')
Index force: tensor([0.5562], device='cuda:0')
Storing RECOVERY transition: reward=0.0898 (scaled=0.0225), steps=4
Reward stats updated: mean -0.0199 -> -0.0195, std: 0.1812
Collected 88 transitions for RL
SAC Update 1/5: Actor Loss=-0.0019, Q1 Loss=0.5108, Q2 Loss=0.5108, Entropy=0.2483, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0860
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.4302, Q2 Loss=0.4302, Entropy=0.0087, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0998
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=0.7042, Q2 Loss=0.7042, Entropy=0.2295, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7972
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.7977, Q2 Loss=0.7977, Entropy=0.1652, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8185
SAC Update 5/5: Actor Loss=-0.0037, Q1 Loss=0.4110, Q2 Loss=0.4110, Entropy=0.3246, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0685

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.3%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (18.8%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001356
Q1 loss: 0.570779
Q2 loss: 0.570779
Current threshold: -30.1224
Global Scale Offset: 1.3273
Reward stats: mean=-0.0195, std=0.1812, count=88
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 0.5708, Q2 Loss: 0.5708, Entropy: 0.1953, Mean TD Error: 0.3740, Threshold: -30.1224
Original likelihood: -31.1456298828125
Adjusted likelihood: -31.1456298828125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.3242)
Current yaw: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:0')
17 turn
Sampling time 3.936572165985126
tensor([ 0.0770,  0.4154,  0.6387,  0.8273, -0.0530,  0.7051,  0.8714,  0.8053,
         1.4303,  0.2692,  0.0798,  0.9891,  0.0531, -0.0618, -0.4358,  4.1426],
       device='cuda:0')
Original likelihood: -31.424076080322266
Adjusted likelihood: -31.424076080322266
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2810)
State is out of distribution
Projection step: 0, Loss: 32.057655334472656
Projection step: 1, Loss: 29.748050689697266
Projection step: 2, Loss: 29.048614501953125
Projection step: 3, Loss: 31.108379364013672
Projection step: 4, Loss: 28.02730941772461
Projection step: 5, Loss: 27.01410675048828
Projection step: 6, Loss: 27.669986724853516
Projection step: 7, Loss: 25.761695861816406
Projection step: 8, Loss: 25.497196197509766
Projection step: 9, Loss: 24.292530059814453
Projection step: 10, Loss: 23.699602127075195
Projection step: 11, Loss: 23.8857479095459
Projection step: 12, Loss: 22.770450592041016
Projection step: 13, Loss: 22.604957580566406
Projection step: 14, Loss: 24.081748962402344
Final likelihood: tensor([-23.8511, -24.7534, -23.9777, -23.7814, -21.2859, -23.8883, -21.1434,
        -21.3014, -25.6533, -23.6743, -20.8467, -19.9083, -21.7305, -24.2596,
        -20.5401, -20.8597])
Final projection likelihood: -22.5909
1 mode projection succeeded
New goal: tensor([ 0.0796,  0.4411,  0.6306,  0.8331, -0.0155,  0.5688,  0.7926,  0.8779,
         1.3781,  0.1232,  0.1653,  1.0187,  0.0452, -0.0457, -1.6852],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -29.90496826171875
Adjusted likelihood: -29.90496826171875
Likelihood residual: 0.0
Original likelihood: -29.783342361450195
Adjusted likelihood: -29.783342361450195
Likelihood residual: 0.0
{'index': 29.783342361450195, 'thumb_middle': 29.90496826171875}
Current yaw: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:0')
18 index
tensor([ 0.0770,  0.4154,  0.6387,  0.8273, -0.0530,  0.7051,  0.8714,  0.8053,
         1.4303,  0.2692,  0.0798,  0.9891,  0.0531, -0.0618, -0.4358,  4.1426],
       device='cuda:0')
Solve time for step 1 10.39402509201318
Current ori: tensor([ 0.0531, -0.0618, -0.4358], device='cuda:0')
Middle force: tensor([0.5786, 0.5878, 0.5002, 0.5484], device='cuda:0')
Thumb force: tensor([0.6225, 0.5417, 0.6711, 0.5921], device='cuda:0')
tensor([ 0.1384,  0.3865,  0.5787,  0.7994, -0.0726,  0.7264,  0.8644,  0.8659,
         1.4668,  0.1948,  0.0768,  1.0080,  0.0793, -0.0632, -0.5091,  5.2785],
       device='cuda:0')
Solve time for step 2 2.284462795010768
Current ori: tensor([ 0.0793, -0.0632, -0.5091], device='cuda:0')
Middle force: tensor([0.5287, 0.5498, 0.5553], device='cuda:0')
Thumb force: tensor([0.6273, 0.5586, 0.5143], device='cuda:0')
tensor([ 0.1393,  0.3972,  0.5797,  0.7987, -0.0903,  0.7659,  0.8742,  0.8780,
         1.5000,  0.2001,  0.1020,  1.0150,  0.1791, -0.0860, -0.5433,  5.7812],
       device='cuda:0')
Solve time for step 3 2.0739472520072013
Current ori: tensor([ 0.1791, -0.0860, -0.5433], device='cuda:0')
Middle force: tensor([0.5485, 0.5529], device='cuda:0')
Thumb force: tensor([0.5554, 0.5139], device='cuda:0')
tensor([ 0.1358,  0.3943,  0.5767,  0.7974, -0.0872,  0.8174,  0.8847,  0.8678,
         1.5000,  0.2089,  0.1401,  1.0020,  0.3549, -0.2381, -0.5338, -5.6625],
       device='cuda:0')
Solve time for step 4 2.058361928036902
Current ori: tensor([ 0.3549, -0.2381, -0.5338], device='cuda:0')
Middle force: tensor([0.5501], device='cuda:0')
Thumb force: tensor([0.5128], device='cuda:0')
Storing RECOVERY transition: reward=-0.0853 (scaled=-0.0853), steps=0
Reward stats updated: mean -0.0195 -> -0.0202, std: 0.1803
Collected 89 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.4380, Q2 Loss=0.4380, Entropy=0.0578, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1976
SAC Update 2/5: Actor Loss=-0.0024, Q1 Loss=0.3542, Q2 Loss=0.3542, Entropy=0.5203, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0439
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.5339, Q2 Loss=0.5339, Entropy=0.0298, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0288
SAC Update 4/5: Actor Loss=-0.0040, Q1 Loss=0.5664, Q2 Loss=0.5664, Entropy=0.3330, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0171
SAC Update 5/5: Actor Loss=-0.0038, Q1 Loss=0.4930, Q2 Loss=0.4930, Entropy=0.5052, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0419

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (17.0%)
Q1 update: 0.06s (20.5%)
Q2 update: 0.05s (19.0%)
Actor update: 0.12s (40.6%)
Target update: 0.00s (1.1%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002094
Q1 loss: 0.477075
Q2 loss: 0.477075
Current threshold: -30.1287
Global Scale Offset: 1.3336
Reward stats: mean=-0.0202, std=0.1803, count=89
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 0.4771, Q2 Loss: 0.4771, Entropy: 0.2892, Mean TD Error: 0.0658, Threshold: -30.1287
Original likelihood: -140.80587768554688
Adjusted likelihood: -140.80587768554688
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 145.72457885742188
Projection step: 1, Loss: 151.5804443359375
Projection step: 2, Loss: 142.0841064453125
Projection step: 3, Loss: 126.47792053222656
Projection step: 4, Loss: 146.00772094726562
Projection step: 5, Loss: 159.45899963378906
Projection step: 6, Loss: 138.83468627929688
Projection step: 7, Loss: 130.99090576171875
Projection step: 8, Loss: 127.83878326416016
Projection step: 9, Loss: 138.35040283203125
Projection step: 10, Loss: 136.6075897216797
Projection step: 11, Loss: 142.45840454101562
Projection step: 12, Loss: 122.89604187011719
Projection step: 13, Loss: 144.81658935546875
Projection step: 14, Loss: 153.27420043945312
Final likelihood: tensor([-140.3564, -178.8408,  -82.3420, -178.4984, -206.0172, -123.9068,
         -90.0331,  -88.6029,  -80.5595, -103.8876, -123.9157, -127.2570,
         -85.9272, -132.3414, -101.1331, -103.9276])
Final projection likelihood: -121.7217
1 mode projection failed, trying anyway
New goal: tensor([ 0.2219,  0.6035,  0.8102,  0.9971, -0.0838,  0.8784,  1.0574,  1.1294,
         1.4328,  0.2167,  0.1545,  1.0867,  0.3528, -0.2440, -0.6778],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0131]], device='cuda:0') tensor([[0.0039]], device='cuda:0')
Original likelihood: -129.3427734375
Adjusted likelihood: -129.3427734375
Likelihood residual: 0.0
Original likelihood: -162.24855041503906
Adjusted likelihood: -162.24855041503906
Likelihood residual: 0.0
{'index': 162.24855041503906, 'thumb_middle': 129.3427734375}
Current yaw: tensor([ 0.3545, -0.2465, -0.5213], device='cuda:0')
19 thumb_middle
tensor([ 0.2068,  0.6122,  0.9012,  1.0363, -0.1093,  0.9347,  1.0485,  0.9727,
         1.4975,  0.2161,  0.1834,  1.0800,  0.3545, -0.2465, -0.5213, -4.9915],
       device='cuda:0')
Solve time for step 1 9.355262750992551
Current ori: tensor([ 0.3545, -0.2465, -0.5213], device='cuda:0')
Index force: tensor([0.5713, 0.5695, 0.5783, 0.5757], device='cuda:0')
tensor([ 0.1566,  0.6781,  0.8314,  0.9987, -0.0635,  0.9102,  1.0253,  1.0813,
         1.3555,  0.2408,  0.0385,  1.0852,  0.3678, -0.3149, -0.4033, -5.9140],
       device='cuda:0')
Solve time for step 2 1.9768944020033814
Current ori: tensor([ 0.3678, -0.3149, -0.4033], device='cuda:0')
Index force: tensor([0.5872, 0.5861, 0.5362], device='cuda:0')
tensor([ 0.1133,  0.7491,  0.8244,  1.0003, -0.0692,  0.9151,  1.0287,  1.0973,
         1.3312,  0.2530, -0.0185,  1.0799,  0.3733, -0.3320, -0.3774,  4.2558],
       device='cuda:0')
Solve time for step 3 1.8167395089985803
Current ori: tensor([ 0.3733, -0.3320, -0.3774], device='cuda:0')
Index force: tensor([0.5804, 0.5328], device='cuda:0')
tensor([ 4.0193e-02,  7.3533e-01,  8.3145e-01,  1.0001e+00, -6.0047e-02,
         9.4290e-01,  1.0471e+00,  1.1099e+00,  1.3311e+00,  2.4544e-01,
         2.8767e-03,  1.0827e+00,  3.7251e-01, -3.2937e-01, -3.9063e-01,
         3.6048e+00], device='cuda:0')
Solve time for step 4 1.8193041799822822
Current ori: tensor([ 0.3725, -0.3294, -0.3906], device='cuda:0')
Index force: tensor([0.5271], device='cuda:0')
Storing RECOVERY transition: reward=-0.1335 (scaled=-0.1335), steps=0
Reward stats updated: mean -0.0202 -> -0.0215, std: 0.1797
Collected 90 transitions for RL
SAC Update 1/5: Actor Loss=-0.0060, Q1 Loss=0.5914, Q2 Loss=0.5914, Entropy=0.4701, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7812
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.3724, Q2 Loss=0.3724, Entropy=0.0591, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1863
SAC Update 3/5: Actor Loss=-0.0043, Q1 Loss=0.4349, Q2 Loss=0.4349, Entropy=0.3240, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0832
SAC Update 4/5: Actor Loss=0.0000, Q1 Loss=0.5519, Q2 Loss=0.5519, Entropy=0.0000, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0374
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=0.3459, Q2 Loss=0.3459, Entropy=0.3418, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0764

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.0%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (18.6%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002276
Q1 loss: 0.459280
Q2 loss: 0.459280
Current threshold: -30.1467
Global Scale Offset: 1.3518
Reward stats: mean=-0.0215, std=0.1797, count=90
----------------------------------------------
SAC Update - Actor Loss: -0.0023, Q1 Loss: 0.4593, Q2 Loss: 0.4593, Entropy: 0.2390, Mean TD Error: 0.2329, Threshold: -30.1467
Original likelihood: -251.4168701171875
Adjusted likelihood: -251.4168701171875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 261.9917907714844
Projection step: 1, Loss: 257.3747253417969
Projection step: 2, Loss: 262.4371337890625
Projection step: 3, Loss: 268.9215087890625
Projection step: 4, Loss: 266.2644348144531
Projection step: 5, Loss: 267.0500793457031
Projection step: 6, Loss: 255.0829620361328
Projection step: 7, Loss: 256.066162109375
Projection step: 8, Loss: 267.22698974609375
Projection step: 9, Loss: 262.9731140136719
Projection step: 10, Loss: 264.887451171875
Projection step: 11, Loss: 260.18572998046875
Projection step: 12, Loss: 266.8400573730469
Projection step: 13, Loss: 260.22979736328125
Projection step: 14, Loss: 247.1296844482422
Final likelihood: tensor([-259.2088, -287.0862, -267.4745, -277.0126, -294.6457, -307.8029,
        -288.9540, -216.7143, -251.4799, -291.2364, -251.6089, -220.9162,
        -316.7063, -258.6685, -233.4395, -285.5615])
Final projection likelihood: -269.2823
1 mode projection failed, trying anyway
New goal: tensor([ 0.0063,  0.7095,  0.8531,  1.0062, -0.0366,  1.0158,  1.0909,  1.1589,
         1.3358,  0.2358,  0.0881,  1.0907,  0.3643, -0.3031, -0.4561],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0044]], device='cuda:0')
Original likelihood: -286.8419189453125
Adjusted likelihood: -286.8419189453125
Likelihood residual: 0.0
{'index': 286.8419189453125, 'thumb_middle': inf}
Current yaw: tensor([ 0.3639, -0.3013, -0.4937], device='cuda:0')
20 index
tensor([-0.0171,  0.7078,  0.8341,  1.0004, -0.0342,  1.0180,  1.1054,  1.1318,
         1.3651,  0.2192,  0.0889,  1.0742,  0.3639, -0.3013, -0.4937,  5.1589],
       device='cuda:0')
Solve time for step 1 10.513202522997744
Current ori: tensor([ 0.3639, -0.3013, -0.4937], device='cuda:0')
Middle force: tensor([0.5375, 0.5972, 0.7561, 0.6556], device='cuda:0')
Thumb force: tensor([0.6056, 0.5629, 0.6847, 0.6688], device='cuda:0')
tensor([ 0.2125,  0.8002,  0.8882,  1.0114,  0.0167,  1.0654,  1.0662,  1.0705,
         1.3562,  0.2649,  0.0698,  1.0862,  0.3674, -0.3114, -0.4744,  5.4796],
       device='cuda:0')
Solve time for step 2 2.2116040650289506
Current ori: tensor([ 0.3674, -0.3114, -0.4744], device='cuda:0')
Middle force: tensor([0.5974, 0.7656, 0.6569], device='cuda:0')
Thumb force: tensor([0.5603, 0.6891, 0.6761], device='cuda:0')
tensor([ 0.2074,  0.8227,  0.8928,  1.0147,  0.0324,  1.0885,  1.0392,  1.0442,
         1.3502,  0.2864,  0.1029,  1.0850,  0.3671, -0.3106, -0.4783,  4.5382],
       device='cuda:0')
Solve time for step 3 2.3693819049512967
Current ori: tensor([ 0.3671, -0.3106, -0.4783], device='cuda:0')
Middle force: tensor([0.5449, 0.7513], device='cuda:0')
Thumb force: tensor([0.5011, 0.7319], device='cuda:0')
tensor([ 0.1467,  0.8375,  0.8964,  1.0163,  0.0437,  1.1025,  1.0484,  0.9850,
         1.3471,  0.3066,  0.1099,  1.0870,  0.3677, -0.3125, -0.4675,  4.4936],
       device='cuda:0')
Solve time for step 4 2.3490042840130627
Current ori: tensor([ 0.3677, -0.3125, -0.4675], device='cuda:0')
Middle force: tensor([0.7353], device='cuda:0')
Thumb force: tensor([0.7193], device='cuda:0')
Storing RECOVERY transition: reward=-0.1050 (scaled=-0.1050), steps=0
Reward stats updated: mean -0.0215 -> -0.0224, std: 0.1789
Collected 91 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.9815, Q2 Loss=0.9815, Entropy=0.1402, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8736
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=1.1226, Q2 Loss=1.1226, Entropy=0.1326, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9235
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=1.2119, Q2 Loss=1.2119, Entropy=0.1948, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9569
SAC Update 4/5: Actor Loss=-0.0021, Q1 Loss=0.5225, Q2 Loss=0.5225, Entropy=0.3125, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0815
SAC Update 5/5: Actor Loss=-0.0065, Q1 Loss=0.3362, Q2 Loss=0.3362, Entropy=0.6438, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0626

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.5%)
Actor update: 0.10s (39.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002024
Q1 loss: 0.834937
Q2 loss: 0.834937
Current threshold: -30.1597
Global Scale Offset: 1.3761
Reward stats: mean=-0.0224, std=0.1789, count=91
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 0.8349, Q2 Loss: 0.8349, Entropy: 0.2848, Mean TD Error: 0.5796, Threshold: -30.1597
Original likelihood: -256.0112609863281
Adjusted likelihood: -256.0112609863281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 244.74966430664062
Projection step: 1, Loss: 260.1533203125
Projection step: 2, Loss: 252.63577270507812
Projection step: 3, Loss: 260.64556884765625
Projection step: 4, Loss: 222.92385864257812
Projection step: 5, Loss: 227.28598022460938
Projection step: 6, Loss: 254.71034240722656
Projection step: 7, Loss: 250.38455200195312
Projection step: 8, Loss: 244.6908721923828
Projection step: 9, Loss: 271.9207458496094
Projection step: 10, Loss: 269.43365478515625
Projection step: 11, Loss: 261.5471496582031
Projection step: 12, Loss: 236.15342712402344
Projection step: 13, Loss: 236.4338836669922
Projection step: 14, Loss: 245.71958923339844
Final likelihood: tensor([-207.0230, -160.5325, -272.2800, -214.9737, -324.7193, -174.2272,
        -308.4478, -321.1648, -237.7814, -223.6480, -233.1326, -307.2557,
        -310.1527, -319.3407, -280.9267, -267.5866])
Final projection likelihood: -260.1996
1 mode projection failed, trying anyway
New goal: tensor([ 0.0113,  0.8324,  0.9158,  1.0232, -0.0085,  1.0585,  1.0291,  1.1351,
         1.3173,  0.2768,  0.1727,  1.1081,  0.3624, -0.2989, -0.5259],
       device='cuda:0')
Marked last transition as done (final step)
{}

Trial 6
Loaded trajectory sampler
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:0')
Current yaw: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:0')
1 turn
Sampling time 3.6603897669701837
tensor([ 1.4334e-01,  5.6925e-01,  6.0823e-01,  6.2445e-01, -1.1775e-01,
         5.3601e-01,  9.1375e-01,  8.7344e-01,  1.2355e+00,  2.8775e-01,
         2.7602e-01,  1.1182e+00,  5.8629e-04,  1.4505e-02, -4.4825e-02,
         4.1213e-02], device='cuda:0')
Original likelihood: -20.801170349121094
Adjusted likelihood: -20.801170349121094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.53256420296384
Current ori: tensor([ 0.0006,  0.0145, -0.0448], device='cuda:0')
Middle force: tensor([0.7039, 0.7984, 0.5282, 0.5222, 0.6304, 0.9772, 1.0235, 0.5884, 0.5007,
        0.5004, 0.5692, 0.5525], device='cuda:0')
Thumb force: tensor([0.6108, 2.3932, 0.6417, 1.5203, 1.0503, 0.9016, 1.9556, 0.6022, 0.7502,
        0.6399, 0.6001, 0.6562], device='cuda:0')
Index force: tensor([0.5836, 0.5029, 0.5938, 0.5637, 0.5761, 0.5189, 0.5891, 0.6169, 0.7193,
        0.7069, 0.6308, 0.5515], device='cuda:0')
Storing NORMAL transition: reward=0.0132 (scaled=0.0132), steps=1
Reward stats updated: mean -0.0224 -> -0.0220, std: 0.1780
Collected 92 transitions for RL
SAC Update 1/5: Actor Loss=-0.0036, Q1 Loss=0.5410, Q2 Loss=0.5410, Entropy=0.3475, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0762
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3994, Q2 Loss=0.3994, Entropy=0.0183, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0867
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.5357, Q2 Loss=0.5357, Entropy=0.0472, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0777
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4695, Q2 Loss=0.4695, Entropy=0.0112, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1420
SAC Update 5/5: Actor Loss=-0.0092, Q1 Loss=0.3853, Q2 Loss=0.3853, Entropy=0.4056, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1963

------ SAC Update Summary (5 iterations) ------
Total time: 0.29s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (16.9%)
Q1 update: 0.06s (19.6%)
Q2 update: 0.05s (19.0%)
Actor update: 0.12s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002606
Q1 loss: 0.466171
Q2 loss: 0.466171
Current threshold: -30.1695
Global Scale Offset: 1.4052
Reward stats: mean=-0.0220, std=0.1780, count=92
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 0.4662, Q2 Loss: 0.4662, Entropy: 0.1659, Mean TD Error: 0.1158, Threshold: -30.1695
tensor([ 0.1104,  0.5885,  0.5389,  0.6443, -0.1253,  0.6029,  0.8045,  0.8885,
         1.3444,  0.1579,  0.2419,  1.0549, -0.0198,  0.0150, -0.0584,  0.8222],
       device='cuda:0')
Original likelihood: -19.763938903808594
Adjusted likelihood: -19.763938903808594
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.858858001010958
Current ori: tensor([-0.0198,  0.0150, -0.0584], device='cuda:0')
Middle force: tensor([0.6388, 0.5006, 1.6263, 0.5107, 0.5020, 0.5311, 0.5074, 0.9283, 1.5655,
        0.5613, 0.5239], device='cuda:0')
Thumb force: tensor([1.7074, 0.7068, 0.9878, 0.5926, 0.5273, 0.8771, 1.0811, 0.7182, 0.9261,
        0.5728, 0.6268], device='cuda:0')
Index force: tensor([0.6993, 0.6982, 0.5112, 0.5206, 0.7871, 0.5995, 0.5479, 0.5631, 0.5184,
        0.5724, 0.6373], device='cuda:0')
Storing NORMAL transition: reward=-0.1434 (scaled=-0.1434), steps=1
Reward stats updated: mean -0.0220 -> -0.0233, std: 0.1775
Collected 93 transitions for RL
SAC Update 1/5: Actor Loss=-0.0024, Q1 Loss=0.4335, Q2 Loss=0.4335, Entropy=0.2657, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0486
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.7878, Q2 Loss=0.7878, Entropy=0.1901, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8184
SAC Update 3/5: Actor Loss=-0.0035, Q1 Loss=0.4988, Q2 Loss=0.4988, Entropy=0.3550, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0834
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.4868, Q2 Loss=0.4868, Entropy=0.3100, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1027
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.3906, Q2 Loss=0.3906, Entropy=0.0019, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1702

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.1%)
Q1 update: 0.05s (20.3%)
Q2 update: 0.05s (19.8%)
Actor update: 0.11s (41.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001892
Q1 loss: 0.519499
Q2 loss: 0.519499
Current threshold: -30.1918
Global Scale Offset: 1.4353
Reward stats: mean=-0.0233, std=0.1775, count=93
----------------------------------------------
SAC Update - Actor Loss: -0.0019, Q1 Loss: 0.5195, Q2 Loss: 0.5195, Entropy: 0.2245, Mean TD Error: 0.2447, Threshold: -30.1918
tensor([ 0.1065,  0.4899,  0.6138,  0.7515, -0.1661,  0.6362,  0.7949,  0.7874,
         1.3334,  0.1593,  0.2720,  1.1483,  0.0048,  0.0391,  0.0844,  0.5771],
       device='cuda:0')
Original likelihood: -29.069351196289062
Adjusted likelihood: -29.069351196289062
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6817)
Solve time for step 3 2.7427222109981813
Current ori: tensor([0.0048, 0.0391, 0.0844], device='cuda:0')
Middle force: tensor([0.5010, 1.6158, 0.5095, 0.5018, 0.5294, 0.5067, 0.9253, 1.5535, 0.5601,
        0.5210], device='cuda:0')
Thumb force: tensor([0.7351, 0.9777, 0.6031, 0.5412, 0.8778, 1.0842, 0.7146, 0.9225, 0.5715,
        0.6367], device='cuda:0')
Index force: tensor([0.6994, 0.5113, 0.5181, 0.7798, 0.5957, 0.5458, 0.5608, 0.5176, 0.5709,
        0.6331], device='cuda:0')
Storing NORMAL transition: reward=0.0263 (scaled=0.0263), steps=1
Reward stats updated: mean -0.0233 -> -0.0228, std: 0.1766
Collected 94 transitions for RL
SAC Update 1/5: Actor Loss=-0.0014, Q1 Loss=0.3287, Q2 Loss=0.3287, Entropy=0.3657, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0575
SAC Update 2/5: Actor Loss=-0.0135, Q1 Loss=0.4557, Q2 Loss=0.4557, Entropy=0.6516, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0276
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.7960, Q2 Loss=0.7960, Entropy=0.1772, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8197
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4708, Q2 Loss=0.4708, Entropy=0.0017, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1242
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.4898, Q2 Loss=0.4898, Entropy=0.0083, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1691

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.6%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (18.7%)
Actor update: 0.10s (40.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003060
Q1 loss: 0.508187
Q2 loss: 0.508187
Current threshold: -30.2196
Global Scale Offset: 1.4613
Reward stats: mean=-0.0228, std=0.1766, count=94
----------------------------------------------
SAC Update - Actor Loss: -0.0031, Q1 Loss: 0.5082, Q2 Loss: 0.5082, Entropy: 0.2409, Mean TD Error: 0.2396, Threshold: -30.2196
tensor([ 0.1230,  0.4862,  0.6164,  0.7730, -0.2637,  0.6396,  0.8378,  0.6192,
         1.2593,  0.3279,  0.3241,  1.0807, -0.0205,  0.0565,  0.0565,  1.1188],
       device='cuda:0')
Original likelihood: -33.87950134277344
Adjusted likelihood: -33.87950134277344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0642)
State is out of distribution
Projection step: 0, Loss: 35.68170928955078
Projection step: 1, Loss: 32.45433807373047
Projection step: 2, Loss: 29.865875244140625
Projection step: 3, Loss: 27.131492614746094
Projection step: 4, Loss: 25.831462860107422
Projection step: 5, Loss: 24.121803283691406
Projection step: 6, Loss: 23.25824737548828
Projection step: 7, Loss: 23.19424819946289
Projection step: 8, Loss: 22.473400115966797
Projection step: 9, Loss: 21.141326904296875
Projection step: 10, Loss: 19.79559326171875
Projection step: 11, Loss: 20.30338478088379
Projection step: 12, Loss: 18.940786361694336
Projection step: 13, Loss: 19.05742645263672
Projection step: 14, Loss: 18.443531036376953
Final likelihood: tensor([-18.0796, -21.3037, -18.5499, -21.7683, -17.6946, -20.6624, -15.7822,
        -20.1512, -18.6264, -18.2798, -19.3429, -20.6627, -17.6120, -18.7766,
        -15.9468, -16.5416])
Final projection likelihood: -18.7363
1 mode projection succeeded
New goal: tensor([ 0.0755,  0.5143,  0.6023,  0.6371, -0.1167,  0.5976,  0.8182,  0.7491,
         1.3394,  0.2259,  0.2341,  1.1397, -0.0282,  0.0374,  1.0120],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[0.0089]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -22.775609970092773
Adjusted likelihood: -22.775609970092773
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.775609970092773}
Current yaw: tensor([-0.0205,  0.0565,  0.0565], device='cuda:0')
2 thumb_middle
tensor([ 0.1230,  0.4862,  0.6164,  0.7730, -0.2637,  0.6396,  0.8378,  0.6192,
         1.2593,  0.3279,  0.3241,  1.0807, -0.0205,  0.0565,  0.0565,  1.1188],
       device='cuda:0')
Solve time for step 1 9.029575249005575
Current ori: tensor([-0.0205,  0.0565,  0.0565], device='cuda:0')
Index force: tensor([0.5999, 0.5883, 0.5712, 0.6055], device='cuda:0')
tensor([ 0.1059,  0.5149,  0.6112,  0.6737, -0.2424,  0.6055,  0.8031,  0.7018,
         1.2862,  0.2235,  0.1847,  1.1001, -0.0317,  0.0672,  0.0564,  1.0347],
       device='cuda:0')
Solve time for step 2 1.9525084189954214
Current ori: tensor([-0.0317,  0.0672,  0.0564], device='cuda:0')
Index force: tensor([0.5842, 0.5684, 0.6028], device='cuda:0')
tensor([ 0.1080,  0.5383,  0.6030,  0.6308, -0.2380,  0.6139,  0.8008,  0.7187,
         1.3093,  0.2062,  0.1569,  1.1033, -0.0378,  0.0675,  0.0564,  0.9980],
       device='cuda:0')
Solve time for step 3 1.7694465219974518
Current ori: tensor([-0.0378,  0.0675,  0.0564], device='cuda:0')
Index force: tensor([0.5650, 0.5999], device='cuda:0')
tensor([ 0.1134,  0.5416,  0.6046,  0.6296, -0.2381,  0.6166,  0.8012,  0.7252,
         1.3179,  0.2046,  0.1445,  1.1034, -0.0409,  0.0623,  0.0564,  1.0363],
       device='cuda:0')
Solve time for step 4 1.6631222190335393
Current ori: tensor([-0.0409,  0.0623,  0.0564], device='cuda:0')
Index force: tensor([0.5915], device='cuda:0')
Storing RECOVERY transition: reward=0.0214 (scaled=0.0071), steps=3
Reward stats updated: mean -0.0228 -> -0.0224, std: 0.1757
Collected 95 transitions for RL
SAC Update 1/5: Actor Loss=-0.0009, Q1 Loss=1.9289, Q2 Loss=1.9289, Entropy=0.1506, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8426
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.3099, Q2 Loss=0.3099, Entropy=0.0578, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0433
SAC Update 3/5: Actor Loss=-0.0019, Q1 Loss=0.3514, Q2 Loss=0.3514, Entropy=0.3492, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0506
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.3422, Q2 Loss=0.3422, Entropy=0.1364, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0849
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.4620, Q2 Loss=0.4620, Entropy=0.0335, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0187

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (16.8%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.1%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000712
Q1 loss: 0.678904
Q2 loss: 0.678904
Current threshold: -30.2427
Global Scale Offset: 1.4882
Reward stats: mean=-0.0224, std=0.1757, count=95
----------------------------------------------
SAC Update - Actor Loss: -0.0007, Q1 Loss: 0.6789, Q2 Loss: 0.6789, Entropy: 0.1455, Mean TD Error: 0.2080, Threshold: -30.2427
Original likelihood: -25.230144500732422
Adjusted likelihood: -25.230144500732422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9801)
Current yaw: tensor([-0.0446,  0.0507,  0.0342], device='cuda:0')
3 turn
Sampling time 3.764236561022699
tensor([ 0.1086,  0.5273,  0.6128,  0.6457, -0.1888,  0.6376,  0.8199,  0.7399,
         1.3766,  0.2279,  0.1787,  1.1211, -0.0446,  0.0507,  0.0342,  1.2117],
       device='cuda:0')
Original likelihood: -26.269283294677734
Adjusted likelihood: -26.269283294677734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9484)
Solve time for step 1 14.714500732021406
Current ori: tensor([-0.0446,  0.0507,  0.0342], device='cuda:0')
Middle force: tensor([0.5628, 0.5881, 0.5218, 0.5351, 0.5930, 1.3518, 0.5462, 0.5561, 0.5230,
        0.5439, 0.5272, 0.7262], device='cuda:0')
Thumb force: tensor([0.5948, 0.5738, 0.8458, 0.8802, 0.5824, 0.8760, 1.3477, 0.8393, 0.6300,
        1.0541, 0.6242, 1.1471], device='cuda:0')
Index force: tensor([0.6033, 0.5243, 0.5648, 0.5749, 0.5870, 0.5015, 0.6051, 0.5621, 0.6036,
        0.5663, 0.5731, 0.5209], device='cuda:0')
Storing NORMAL transition: reward=0.0634 (scaled=0.0634), steps=1
Reward stats updated: mean -0.0224 -> -0.0216, std: 0.1750
Collected 96 transitions for RL
SAC Update 1/5: Actor Loss=-0.0008, Q1 Loss=0.3265, Q2 Loss=0.3265, Entropy=0.2064, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1913
SAC Update 2/5: Actor Loss=-0.0032, Q1 Loss=0.7116, Q2 Loss=0.7116, Entropy=0.4388, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8036
SAC Update 3/5: Actor Loss=-0.0003, Q1 Loss=0.4036, Q2 Loss=0.4036, Entropy=0.1052, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1860
SAC Update 4/5: Actor Loss=-0.0000, Q1 Loss=0.4505, Q2 Loss=0.4505, Entropy=0.0063, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0901
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.4117, Q2 Loss=0.4117, Entropy=0.0864, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2334

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000909
Q1 loss: 0.460771
Q2 loss: 0.460771
Current threshold: -30.2628
Global Scale Offset: 1.5211
Reward stats: mean=-0.0216, std=0.1750, count=96
----------------------------------------------
SAC Update - Actor Loss: -0.0009, Q1 Loss: 0.4608, Q2 Loss: 0.4608, Entropy: 0.1686, Mean TD Error: 0.3008, Threshold: -30.2628
tensor([ 0.1246,  0.5137,  0.6221,  0.6951, -0.1807,  0.6042,  0.8605,  0.8261,
         1.3861,  0.2121,  0.1631,  1.0996, -0.0407,  0.0376, -0.0282,  1.3595],
       device='cuda:0')
Original likelihood: -22.855815887451172
Adjusted likelihood: -22.855815887451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9986)
Solve time for step 2 2.957110996998381
Current ori: tensor([-0.0407,  0.0376, -0.0282], device='cuda:0')
Middle force: tensor([0.5817, 0.5194, 0.5344, 0.5896, 1.3393, 0.5443, 0.5526, 0.5218, 0.5413,
        0.5266, 0.7201], device='cuda:0')
Thumb force: tensor([0.5631, 0.8362, 0.8668, 0.5779, 0.8640, 1.3320, 0.8306, 0.6244, 1.0423,
        0.6159, 1.1402], device='cuda:0')
Index force: tensor([0.5224, 0.5628, 0.5726, 0.5833, 0.5011, 0.6029, 0.5605, 0.6010, 0.5638,
        0.5710, 0.5196], device='cuda:0')
Storing NORMAL transition: reward=-0.0003 (scaled=-0.0003), steps=1
Reward stats updated: mean -0.0216 -> -0.0213, std: 0.1741
Collected 97 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.2939, Q2 Loss=0.2939, Entropy=0.0119, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0420
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.3535, Q2 Loss=0.3535, Entropy=0.1054, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0818
SAC Update 3/5: Actor Loss=-0.0041, Q1 Loss=0.3824, Q2 Loss=0.3824, Entropy=0.4029, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2215
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.3778, Q2 Loss=0.3778, Entropy=0.0536, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0693
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.3724, Q2 Loss=0.3724, Entropy=0.0398, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0686

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.1%)
Q1 update: 0.06s (19.9%)
Q2 update: 0.06s (20.6%)
Actor update: 0.12s (42.6%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000962
Q1 loss: 0.355998
Q2 loss: 0.355998
Current threshold: -30.2786
Global Scale Offset: 1.5537
Reward stats: mean=-0.0213, std=0.1741, count=97
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 0.3560, Q2 Loss: 0.3560, Entropy: 0.1227, Mean TD Error: 0.0967, Threshold: -30.2786
tensor([ 0.1000,  0.5022,  0.5620,  0.8029, -0.2214,  0.5466,  0.9231,  0.7749,
         1.3256,  0.2533,  0.1940,  1.0762, -0.0278,  0.0511, -0.0282,  1.3657],
       device='cuda:0')
Original likelihood: -29.165691375732422
Adjusted likelihood: -29.165691375732422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6709)
Solve time for step 3 2.697689299006015
Current ori: tensor([-0.0278,  0.0511, -0.0282], device='cuda:0')
Middle force: tensor([0.5171, 0.5354, 0.5888, 1.3254, 0.5433, 0.5494, 0.5209, 0.5390, 0.5258,
        0.7156], device='cuda:0')
Thumb force: tensor([0.8091, 0.8482, 0.5732, 0.8556, 1.3168, 0.8209, 0.6168, 1.0301, 0.6095,
        1.1308], device='cuda:0')
Index force: tensor([0.5663, 0.5770, 0.5865, 0.5007, 0.6004, 0.5589, 0.5998, 0.5617, 0.5691,
        0.5186], device='cuda:0')
Storing NORMAL transition: reward=0.1229 (scaled=0.1229), steps=1
Reward stats updated: mean -0.0213 -> -0.0199, std: 0.1738
Collected 98 transitions for RL
SAC Update 1/5: Actor Loss=-0.0039, Q1 Loss=0.3856, Q2 Loss=0.3856, Entropy=0.3182, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1985
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.3455, Q2 Loss=0.3455, Entropy=0.0185, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0915
SAC Update 3/5: Actor Loss=-0.0035, Q1 Loss=0.3781, Q2 Loss=0.3781, Entropy=0.3868, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0730
SAC Update 4/5: Actor Loss=-0.0015, Q1 Loss=0.2703, Q2 Loss=0.2703, Entropy=0.3887, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1078
SAC Update 5/5: Actor Loss=-0.0011, Q1 Loss=0.3796, Q2 Loss=0.3796, Entropy=0.1646, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0814

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002015
Q1 loss: 0.351823
Q2 loss: 0.351823
Current threshold: -30.2977
Global Scale Offset: 1.5924
Reward stats: mean=-0.0199, std=0.1738, count=98
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 0.3518, Q2 Loss: 0.3518, Entropy: 0.2553, Mean TD Error: 0.1104, Threshold: -30.2977
tensor([ 0.0748,  0.4825,  0.5892,  0.7506, -0.2416,  0.5115,  0.9279,  0.9462,
         1.4162,  0.3469,  0.1533,  1.0172, -0.0261,  0.0693, -0.1556,  1.4527],
       device='cuda:0')
Original likelihood: -31.810470581054688
Adjusted likelihood: -31.810470581054688
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2774)
Solve time for step 4 2.5896285389899276
Current ori: tensor([-0.0261,  0.0693, -0.1556], device='cuda:0')
Middle force: tensor([0.5334, 0.5866, 1.3068, 0.5427, 0.5452, 0.5199, 0.5370, 0.5263, 0.7031],
       device='cuda:0')
Thumb force: tensor([0.8343, 0.5688, 0.8436, 1.3041, 0.8196, 0.6198, 1.0242, 0.6013, 1.1472],
       device='cuda:0')
Index force: tensor([0.5774, 0.5880, 0.5006, 0.5977, 0.5560, 0.5912, 0.5583, 0.5666, 0.5156],
       device='cuda:0')
Storing NORMAL transition: reward=0.1672 (scaled=0.1672), steps=1
Reward stats updated: mean -0.0199 -> -0.0180, std: 0.1740
Collected 99 transitions for RL
SAC Update 1/5: Actor Loss=-0.0000, Q1 Loss=0.3355, Q2 Loss=0.3355, Entropy=0.0067, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0066
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.4631, Q2 Loss=0.4631, Entropy=0.2009, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7742
SAC Update 3/5: Actor Loss=-0.0052, Q1 Loss=0.5393, Q2 Loss=0.5393, Entropy=0.5093, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7805
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.8146, Q2 Loss=0.8146, Entropy=0.1787, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8213
SAC Update 5/5: Actor Loss=-0.0066, Q1 Loss=0.3764, Q2 Loss=0.3764, Entropy=0.3708, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0191

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.5%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002495
Q1 loss: 0.505778
Q2 loss: 0.505778
Current threshold: -30.3173
Global Scale Offset: 1.6319
Reward stats: mean=-0.0180, std=0.1740, count=99
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 0.5058, Q2 Loss: 0.5058, Entropy: 0.2533, Mean TD Error: 0.4803, Threshold: -30.3173
tensor([ 0.1475,  0.5466,  0.5919,  0.7102, -0.1777,  0.6077,  0.8105,  1.0355,
         1.4626,  0.2603,  0.0972,  0.9182, -0.0573,  0.0257, -0.3264,  1.8873],
       device='cuda:0')
Original likelihood: -26.110210418701172
Adjusted likelihood: -26.110210418701172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9467)
Solve time for step 5 2.481318823003676
Current ori: tensor([-0.0573,  0.0257, -0.3264], device='cuda:0')
Middle force: tensor([0.5018, 0.7523, 0.6175, 0.6425, 0.6917, 1.9985, 0.6218, 0.5010],
       device='cuda:0')
Thumb force: tensor([0.5169, 0.6628, 1.4146, 0.8737, 0.6737, 1.3446, 1.4312, 0.5276],
       device='cuda:0')
Index force: tensor([0.6054, 0.6662, 0.9728, 0.5274, 0.6913, 0.9428, 0.7148, 0.6635],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0045 (scaled=-0.0045), steps=1
Reward stats updated: mean -0.0180 -> -0.0178, std: 0.1731
Collected 100 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.5944, Q2 Loss=0.5944, Entropy=0.0276, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5979
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.3265, Q2 Loss=0.3265, Entropy=0.1367, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2423
SAC Update 3/5: Actor Loss=-0.0110, Q1 Loss=1.6012, Q2 Loss=1.6012, Entropy=0.4262, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1580
SAC Update 4/5: Actor Loss=-0.0046, Q1 Loss=1.1451, Q2 Loss=1.1451, Entropy=0.3387, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9802
SAC Update 5/5: Actor Loss=-0.0022, Q1 Loss=0.5192, Q2 Loss=0.5192, Entropy=0.2606, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3384

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (15.9%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (19.7%)
Actor update: 0.11s (42.0%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003629
Q1 loss: 0.837271
Q2 loss: 0.837271
Current threshold: -30.3393
Global Scale Offset: 1.6588
Reward stats: mean=-0.0178, std=0.1731, count=100
----------------------------------------------
SAC Update - Actor Loss: -0.0036, Q1 Loss: 0.8373, Q2 Loss: 0.8373, Entropy: 0.2380, Mean TD Error: 0.6634, Threshold: -30.3393
tensor([ 0.1167,  0.5146,  0.5776,  0.7650, -0.2632,  0.6527,  0.9656,  1.0363,
         1.4314,  0.3430, -0.0187,  0.8755, -0.0536,  0.0178, -0.3194,  2.0827],
       device='cuda:0')
Original likelihood: -33.44108200073242
Adjusted likelihood: -33.44108200073242
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1198)
State is out of distribution
Projection step: 0, Loss: 30.947595596313477
Projection step: 1, Loss: 32.2514762878418
Projection step: 2, Loss: 30.388893127441406
Projection step: 3, Loss: 29.04608917236328
Projection step: 4, Loss: 26.93030548095703
Projection step: 5, Loss: 25.156301498413086
Projection step: 6, Loss: 22.88422393798828
Projection step: 7, Loss: 21.760156631469727
Projection step: 8, Loss: 21.45447540283203
Projection step: 9, Loss: 19.495370864868164
Projection step: 10, Loss: 19.00483512878418
Projection step: 11, Loss: 19.143735885620117
Projection step: 12, Loss: 17.077392578125
Projection step: 13, Loss: 16.339582443237305
Projection step: 14, Loss: 16.08873748779297
Final likelihood: tensor([-16.5163, -15.6969, -18.8512, -21.6795, -14.8475, -17.2337, -20.9239,
        -15.2461, -17.1839, -17.6378, -18.1103, -13.8977, -16.5737, -18.4025,
        -13.4329, -17.3726])
Final projection likelihood: -17.1004
1 mode projection succeeded
New goal: tensor([ 0.0897,  0.5308,  0.5202,  0.8165, -0.0689,  0.6306,  0.7459,  0.8997,
         1.4468,  0.2017,  0.1194,  0.9728, -0.0546,  0.0137,  0.3562],
       device='cuda:0')
tensor([[0.0147]], device='cuda:0') tensor([[0.0022]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -18.768985748291016
Adjusted likelihood: -18.768985748291016
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.768985748291016}
Current yaw: tensor([-0.0536,  0.0178, -0.3194], device='cuda:0')
4 thumb_middle
tensor([ 0.1167,  0.5146,  0.5776,  0.7650, -0.2632,  0.6527,  0.9656,  1.0363,
         1.4314,  0.3430, -0.0187,  0.8755, -0.0536,  0.0178, -0.3194,  2.0827],
       device='cuda:0')
Solve time for step 1 9.041871754976455
Current ori: tensor([-0.0536,  0.0178, -0.3194], device='cuda:0')
Index force: tensor([0.5891, 0.5816, 0.5856, 0.5692], device='cuda:0')
tensor([ 0.1159,  0.5295,  0.5417,  0.7923, -0.2220,  0.6110,  0.7372,  0.9071,
         1.4036,  0.2030,  0.0267,  0.9344, -0.0547,  0.0217, -0.3182,  2.0350],
       device='cuda:0')
Solve time for step 2 1.9825320350355469
Current ori: tensor([-0.0547,  0.0217, -0.3182], device='cuda:0')
Index force: tensor([0.5754, 0.5801, 0.5645], device='cuda:0')
tensor([ 0.1171,  0.5290,  0.5290,  0.8227, -0.2075,  0.6208,  0.7096,  0.8840,
         1.4114,  0.1821,  0.0291,  0.9350, -0.0515,  0.0211, -0.3182,  2.0364],
       device='cuda:0')
Solve time for step 3 1.9200289040454663
Current ori: tensor([-0.0515,  0.0211, -0.3182], device='cuda:0')
Index force: tensor([0.5782, 0.5811], device='cuda:0')
tensor([ 0.1233,  0.5279,  0.5292,  0.8376, -0.2020,  0.6318,  0.6913,  0.8934,
         1.4123,  0.1631,  0.0249,  0.9476, -0.0497,  0.0172, -0.3182,  2.0468],
       device='cuda:0')
Solve time for step 4 1.8118451740010642
Current ori: tensor([-0.0497,  0.0172, -0.3182], device='cuda:0')
Index force: tensor([0.5703], device='cuda:0')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0003), steps=5
Reward stats updated: mean -0.0178 -> -0.0177, std: 0.1722
Collected 101 transitions for RL
SAC Update 1/5: Actor Loss=-0.0011, Q1 Loss=50.5244, Q2 Loss=50.5244, Entropy=0.1963, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9435
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=7.1028, Q2 Loss=7.1028, Entropy=0.1844, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5563
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.5544, Q2 Loss=0.5544, Entropy=0.1912, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3625
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=8.7267, Q2 Loss=8.7267, Entropy=0.1887, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7844
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=7.6918, Q2 Loss=7.6918, Entropy=0.1854, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7196

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.05s (20.4%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.000439
Q1 loss: 14.920006
Q2 loss: 14.920006
Current threshold: -30.3533
Global Scale Offset: 1.6870
Reward stats: mean=-0.0177, std=0.1722, count=101
----------------------------------------------
SAC Update - Actor Loss: -0.0004, Q1 Loss: 14.9200, Q2 Loss: 14.9200, Entropy: 0.1892, Mean TD Error: 3.8733, Threshold: -30.3533
Original likelihood: -20.657955169677734
Adjusted likelihood: -20.657955169677734
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Current yaw: tensor([-0.0528,  0.0239, -0.3215], device='cuda:0')
5 turn
Sampling time 3.736425875045825
tensor([ 0.0814,  0.5234,  0.5088,  0.8097, -0.1503,  0.6684,  0.7385,  0.8810,
         1.4737,  0.1945,  0.0773,  0.9686, -0.0528,  0.0239, -0.3215,  2.1973],
       device='cuda:0')
Original likelihood: -19.568397521972656
Adjusted likelihood: -19.568397521972656
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 1 14.645982261979952
Current ori: tensor([-0.0528,  0.0239, -0.3215], device='cuda:0')
Middle force: tensor([0.5831, 2.1879, 0.5098, 0.5539, 0.5904, 0.5899, 0.5687, 0.5463, 0.6967,
        0.5884, 0.8037, 0.5768], device='cuda:0')
Thumb force: tensor([0.6110, 0.5869, 1.8072, 0.5086, 0.8952, 0.6032, 1.3433, 0.6206, 0.5204,
        0.5385, 0.5992, 0.6205], device='cuda:0')
Index force: tensor([0.6085, 1.2568, 0.5421, 0.6756, 0.5915, 0.6175, 0.5831, 0.6398, 0.5792,
        0.6026, 0.5301, 0.6305], device='cuda:0')
Storing NORMAL transition: reward=-0.0704 (scaled=-0.0704), steps=1
Reward stats updated: mean -0.0177 -> -0.0182, std: 0.1715
Collected 102 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=3.3084, Q2 Loss=3.3084, Entropy=0.1114, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1871
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=16.5171, Q2 Loss=16.5171, Entropy=0.1869, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7407
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=0.2433, Q2 Loss=0.2433, Entropy=0.3016, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1115
SAC Update 4/5: Actor Loss=-0.0043, Q1 Loss=2.2310, Q2 Loss=2.2310, Entropy=0.3279, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2705
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=0.4307, Q2 Loss=0.4307, Entropy=0.2003, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3673

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.4%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (19.2%)
Actor update: 0.08s (41.0%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001356
Q1 loss: 4.546080
Q2 loss: 4.546080
Current threshold: -30.3667
Global Scale Offset: 1.7212
Reward stats: mean=-0.0182, std=0.1715, count=102
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 4.5461, Q2 Loss: 4.5461, Entropy: 0.2256, Mean TD Error: 1.5354, Threshold: -30.3667
tensor([ 0.0580,  0.4265,  0.5560,  0.9482, -0.1131,  0.6301,  0.7317,  0.8477,
         1.4357,  0.1223,  0.1082,  1.1207, -0.0131,  0.0228, -0.2485,  2.3633],
       device='cuda:0')
Original likelihood: -19.32400894165039
Adjusted likelihood: -19.32400894165039
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Solve time for step 2 2.910259047988802
Current ori: tensor([-0.0131,  0.0228, -0.2485], device='cuda:0')
Middle force: tensor([2.1624, 0.5097, 0.5547, 0.5890, 0.5936, 0.5643, 0.5453, 0.6898, 0.5870,
        0.7942, 0.5753], device='cuda:0')
Thumb force: tensor([0.5829, 1.7776, 0.5074, 0.8866, 0.5914, 1.3322, 0.6096, 0.5195, 0.5356,
        0.5978, 0.6119], device='cuda:0')
Index force: tensor([1.2340, 0.5427, 0.6725, 0.5888, 0.6188, 0.5809, 0.6424, 0.5773, 0.6007,
        0.5293, 0.6327], device='cuda:0')
Storing NORMAL transition: reward=0.0139 (scaled=0.0139), steps=1
Reward stats updated: mean -0.0182 -> -0.0179, std: 0.1707
Collected 103 transitions for RL
SAC Update 1/5: Actor Loss=-0.0073, Q1 Loss=0.3257, Q2 Loss=0.3257, Entropy=0.5380, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0998
SAC Update 2/5: Actor Loss=-0.0000, Q1 Loss=0.3572, Q2 Loss=0.3572, Entropy=0.0061, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2276
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=2.6003, Q2 Loss=2.6003, Entropy=0.0060, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0371
SAC Update 4/5: Actor Loss=-0.0014, Q1 Loss=29.1288, Q2 Loss=29.1288, Entropy=0.3125, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5184
SAC Update 5/5: Actor Loss=-0.0054, Q1 Loss=4.0738, Q2 Loss=4.0738, Entropy=0.5332, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.5573

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.9%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (18.4%)
Actor update: 0.08s (39.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002823
Q1 loss: 7.297179
Q2 loss: 7.297179
Current threshold: -30.3872
Global Scale Offset: 1.7612
Reward stats: mean=-0.0179, std=0.1707, count=103
----------------------------------------------
SAC Update - Actor Loss: -0.0028, Q1 Loss: 7.2972, Q2 Loss: 7.2972, Entropy: 0.2792, Mean TD Error: 2.2880, Threshold: -30.3872
tensor([ 0.0128,  0.4355,  0.5427,  0.8727, -0.1197,  0.5687,  0.7475,  0.9459,
         1.3357,  0.2262,  0.2216,  1.0520, -0.0089,  0.0345, -0.2629,  3.0475],
       device='cuda:0')
Original likelihood: -22.534061431884766
Adjusted likelihood: -22.534061431884766
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9978)
Solve time for step 3 2.8303389239590615
Current ori: tensor([-0.0089,  0.0345, -0.2629], device='cuda:0')
Middle force: tensor([0.5090, 0.5629, 0.5890, 0.6045, 0.5606, 0.5521, 0.6956, 0.5858, 0.7992,
        0.5752], device='cuda:0')
Thumb force: tensor([1.7504, 0.5057, 0.8783, 0.5758, 1.3182, 0.5888, 0.5161, 0.5333, 0.5850,
        0.6035], device='cuda:0')
Index force: tensor([0.5421, 0.6675, 0.5875, 0.6199, 0.5804, 0.6426, 0.5770, 0.5971, 0.5301,
        0.6341], device='cuda:0')
Storing NORMAL transition: reward=0.0398 (scaled=0.0398), steps=1
Reward stats updated: mean -0.0179 -> -0.0173, std: 0.1699
Collected 104 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.6100, Q2 Loss=0.6100, Entropy=0.0733, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5438
SAC Update 2/5: Actor Loss=-0.0040, Q1 Loss=0.2727, Q2 Loss=0.2727, Entropy=0.3255, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2350
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=15.3295, Q2 Loss=15.3295, Entropy=0.2967, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8246
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=6.7771, Q2 Loss=6.7771, Entropy=0.2647, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7373
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=0.5874, Q2 Loss=0.5874, Entropy=0.1066, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3718

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (19.6%)
Actor update: 0.09s (41.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001249
Q1 loss: 4.715344
Q2 loss: 4.715344
Current threshold: -30.4099
Global Scale Offset: 1.8100
Reward stats: mean=-0.0173, std=0.1699, count=104
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 4.7153, Q2 Loss: 4.7153, Entropy: 0.2134, Mean TD Error: 2.1425, Threshold: -30.4099
tensor([ 0.0329,  0.4288,  0.5763,  0.8513, -0.1558,  0.6017,  0.7459,  0.9070,
         1.4738,  0.0332,  0.2580,  0.8854, -0.0239,  0.0456, -0.3040,  2.2500],
       device='cuda:0')
Original likelihood: -27.00912857055664
Adjusted likelihood: -27.00912857055664
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8868)
Solve time for step 4 2.623690894979518
Current ori: tensor([-0.0239,  0.0456, -0.3040], device='cuda:0')
Middle force: tensor([0.5578, 0.5891, 0.5922, 0.5581, 0.5426, 0.6898, 0.5832, 0.7918, 0.5717],
       device='cuda:0')
Thumb force: tensor([0.5054, 0.8697, 0.5839, 1.3028, 0.5978, 0.5160, 0.5321, 0.5896, 0.6020],
       device='cuda:0')
Index force: tensor([0.6671, 0.5930, 0.6173, 0.5818, 0.6404, 0.5720, 0.5943, 0.5269, 0.6339],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0047 (scaled=-0.0047), steps=1
Reward stats updated: mean -0.0173 -> -0.0172, std: 0.1691
Collected 105 transitions for RL
SAC Update 1/5: Actor Loss=-0.0005, Q1 Loss=0.7378, Q2 Loss=0.7378, Entropy=0.2049, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4575
SAC Update 2/5: Actor Loss=-0.0123, Q1 Loss=2.9917, Q2 Loss=2.9917, Entropy=0.4388, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.6029
SAC Update 3/5: Actor Loss=-0.0044, Q1 Loss=0.7447, Q2 Loss=0.7447, Entropy=0.4700, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5317
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=12.4359, Q2 Loss=12.4359, Entropy=0.2748, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7604
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=0.7542, Q2 Loss=0.7542, Entropy=0.0400, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5859

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.3%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.0%)
Actor update: 0.08s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003594
Q1 loss: 3.532855
Q2 loss: 3.532855
Current threshold: -30.4198
Global Scale Offset: 1.8543
Reward stats: mean=-0.0172, std=0.1691, count=105
----------------------------------------------
SAC Update - Actor Loss: -0.0036, Q1 Loss: 3.5329, Q2 Loss: 3.5329, Entropy: 0.2857, Mean TD Error: 1.5877, Threshold: -30.4198
tensor([ 0.0901,  0.4991,  0.4966,  0.9198, -0.1611,  0.6384,  0.8093,  0.8589,
         1.4369,  0.0260,  0.2626,  0.8926, -0.0362,  0.0200, -0.2984,  2.0543],
       device='cuda:0')
Original likelihood: -24.54458999633789
Adjusted likelihood: -24.54458999633789
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9800)
Solve time for step 5 2.4751387739670463
Current ori: tensor([-0.0362,  0.0200, -0.2984], device='cuda:0')
Middle force: tensor([0.5877, 0.5837, 0.5551, 0.5365, 0.6840, 0.5806, 0.7877, 0.5689],
       device='cuda:0')
Thumb force: tensor([0.8612, 0.5875, 1.2914, 0.6032, 0.5155, 0.5307, 0.5895, 0.6014],
       device='cuda:0')
Index force: tensor([0.5916, 0.6173, 0.5809, 0.6389, 0.5701, 0.5913, 0.5251, 0.6313],
       device='cuda:0')
Storing NORMAL transition: reward=0.0226 (scaled=0.0226), steps=1
Reward stats updated: mean -0.0172 -> -0.0168, std: 0.1684
Collected 106 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.7489, Q2 Loss=0.7489, Entropy=0.0797, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5383
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=0.6062, Q2 Loss=0.6062, Entropy=0.1627, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3939
SAC Update 3/5: Actor Loss=-0.0042, Q1 Loss=0.5155, Q2 Loss=0.5155, Entropy=0.3278, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1732
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=23.8344, Q2 Loss=23.8344, Entropy=0.2179, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4959
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=5.6641, Q2 Loss=5.6641, Entropy=0.3219, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8237

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.1%)
Q1 update: 0.04s (19.4%)
Q2 update: 0.04s (19.5%)
Actor update: 0.09s (41.8%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001325
Q1 loss: 6.273841
Q2 loss: 6.273841
Current threshold: -30.4293
Global Scale Offset: 1.9044
Reward stats: mean=-0.0168, std=0.1684, count=106
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 6.2738, Q2 Loss: 6.2738, Entropy: 0.2220, Mean TD Error: 2.2850, Threshold: -30.4293
tensor([ 0.0938,  0.4502,  0.6060,  0.8420, -0.1543,  0.6443,  0.7910,  0.9189,
         1.3181,  0.2155,  0.3179,  0.8706, -0.0323,  0.0142, -0.3207,  2.2032],
       device='cuda:0')
Original likelihood: -21.189117431640625
Adjusted likelihood: -21.189117431640625
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9992)
Solve time for step 6 2.3898063579690643
Current ori: tensor([-0.0323,  0.0142, -0.3207], device='cuda:0')
Middle force: tensor([0.5784, 0.5523, 0.5356, 0.6809, 0.5794, 0.7864, 0.5672],
       device='cuda:0')
Thumb force: tensor([0.5869, 1.2800, 0.5994, 0.5147, 0.5292, 0.5869, 0.5990],
       device='cuda:0')
Index force: tensor([0.6176, 0.5810, 0.6373, 0.5692, 0.5886, 0.5239, 0.6297],
       device='cuda:0')
Storing NORMAL transition: reward=0.0756 (scaled=0.0756), steps=1
Reward stats updated: mean -0.0168 -> -0.0160, std: 0.1678
Collected 107 transitions for RL
SAC Update 1/5: Actor Loss=-0.0006, Q1 Loss=0.4788, Q2 Loss=0.4788, Entropy=0.1161, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5437
SAC Update 2/5: Actor Loss=-0.0105, Q1 Loss=1.5120, Q2 Loss=1.5120, Entropy=0.3694, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0001
SAC Update 3/5: Actor Loss=-0.0005, Q1 Loss=1.8716, Q2 Loss=1.8716, Entropy=0.1408, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3472
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=5.7989, Q2 Loss=5.7989, Entropy=0.2135, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7985
SAC Update 5/5: Actor Loss=-0.0000, Q1 Loss=0.5301, Q2 Loss=0.5301, Entropy=0.0254, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6783

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.9%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002371
Q1 loss: 2.038277
Q2 loss: 2.038277
Current threshold: -30.4324
Global Scale Offset: 1.9457
Reward stats: mean=-0.0160, std=0.1678, count=107
----------------------------------------------
SAC Update - Actor Loss: -0.0024, Q1 Loss: 2.0383, Q2 Loss: 2.0383, Entropy: 0.1731, Mean TD Error: 1.6736, Threshold: -30.4324
tensor([ 0.1033,  0.4337,  0.6085,  0.9002, -0.1518,  0.6219,  0.8070,  0.9725,
         1.3841,  0.1114,  0.2846,  0.8585, -0.0221,  0.0094, -0.3957,  2.2682],
       device='cuda:0')
Original likelihood: -22.61855125427246
Adjusted likelihood: -22.61855125427246
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9958)
Solve time for step 7 2.219194096978754
Current ori: tensor([-0.0221,  0.0094, -0.3957], device='cuda:0')
Middle force: tensor([1.2893, 0.6809, 0.8125, 0.5291, 0.5215, 0.5512], device='cuda:0')
Thumb force: tensor([0.5441, 0.7032, 0.5481, 0.5145, 0.5849, 0.5612], device='cuda:0')
Index force: tensor([0.5351, 0.5248, 0.5313, 0.5592, 0.6010, 0.5571], device='cuda:0')
Storing NORMAL transition: reward=0.0780 (scaled=0.0780), steps=1
Reward stats updated: mean -0.0160 -> -0.0151, std: 0.1673
Collected 108 transitions for RL
SAC Update 1/5: Actor Loss=-0.0002, Q1 Loss=0.7989, Q2 Loss=0.7989, Entropy=0.0495, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7065
SAC Update 2/5: Actor Loss=-0.0035, Q1 Loss=0.5295, Q2 Loss=0.5295, Entropy=0.4138, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3107
SAC Update 3/5: Actor Loss=-0.0028, Q1 Loss=11.1557, Q2 Loss=11.1557, Entropy=0.4748, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8360
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.3727, Q2 Loss=0.3727, Entropy=0.1452, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1332
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=10.8752, Q2 Loss=10.8752, Entropy=0.3018, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8251

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.2%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.05s (19.9%)
Actor update: 0.10s (42.1%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001621
Q1 loss: 4.746393
Q2 loss: 4.746393
Current threshold: -30.4334
Global Scale Offset: 1.9959
Reward stats: mean=-0.0151, std=0.1673, count=108
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 4.7464, Q2 Loss: 4.7464, Entropy: 0.2770, Mean TD Error: 2.1623, Threshold: -30.4334
tensor([ 0.1095,  0.4156,  0.6174,  0.9466, -0.1499,  0.5987,  0.8288,  1.0355,
         1.3922,  0.0967,  0.2821,  0.8514, -0.0118,  0.0037, -0.4733,  2.4347],
       device='cuda:0')
Original likelihood: -21.98615837097168
Adjusted likelihood: -21.98615837097168
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9974)
Solve time for step 8 2.2158639559638686
Current ori: tensor([-0.0118,  0.0037, -0.4733], device='cuda:0')
Middle force: tensor([0.6694, 0.8041, 0.5271, 0.5238, 0.5502], device='cuda:0')
Thumb force: tensor([0.6947, 0.5450, 0.5130, 0.5748, 0.5575], device='cuda:0')
Index force: tensor([0.5230, 0.5294, 0.5566, 0.5946, 0.5545], device='cuda:0')
Storing NORMAL transition: reward=0.0229 (scaled=0.0229), steps=1
Reward stats updated: mean -0.0151 -> -0.0147, std: 0.1666
Collected 109 transitions for RL
SAC Update 1/5: Actor Loss=-0.0095, Q1 Loss=1.1926, Q2 Loss=1.1926, Entropy=0.4370, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8775
SAC Update 2/5: Actor Loss=-0.0057, Q1 Loss=0.5956, Q2 Loss=0.5956, Entropy=0.4528, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1333
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=0.6354, Q2 Loss=0.6354, Entropy=0.1850, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4384
SAC Update 4/5: Actor Loss=-0.0009, Q1 Loss=14.3081, Q2 Loss=14.3081, Entropy=0.2860, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0457
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.6183, Q2 Loss=0.6183, Entropy=0.0634, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3580

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003423
Q1 loss: 3.470005
Q2 loss: 3.470005
Current threshold: -30.4232
Global Scale Offset: 2.0534
Reward stats: mean=-0.0147, std=0.1666, count=109
----------------------------------------------
SAC Update - Actor Loss: -0.0034, Q1 Loss: 3.4700, Q2 Loss: 3.4700, Entropy: 0.2849, Mean TD Error: 1.3706, Threshold: -30.4232
tensor([ 0.0737,  0.3986,  0.5535,  1.0431, -0.1120,  0.6063,  0.8234,  1.1147,
         1.3840,  0.0284,  0.3208,  0.7881,  0.0045, -0.0270, -0.4970,  2.8693],
       device='cuda:0')
Original likelihood: -22.37079620361328
Adjusted likelihood: -22.37079620361328
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9955)
Solve time for step 9 2.0296314180013724
Current ori: tensor([ 0.0045, -0.0270, -0.4970], device='cuda:0')
Middle force: tensor([0.5630, 1.0611, 0.5528, 0.5020], device='cuda:0')
Thumb force: tensor([0.5006, 1.2859, 0.5416, 0.5599], device='cuda:0')
Index force: tensor([0.5916, 0.5264, 0.5350, 0.5594], device='cuda:0')
Storing NORMAL transition: reward=-0.0034 (scaled=-0.0034), steps=1
Reward stats updated: mean -0.0147 -> -0.0146, std: 0.1658
Collected 110 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.8258, Q2 Loss=0.8258, Entropy=0.1281, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6682
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.5119, Q2 Loss=0.5119, Entropy=0.1494, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3066
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.5321, Q2 Loss=0.5321, Entropy=0.1442, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3139
SAC Update 4/5: Actor Loss=-0.0044, Q1 Loss=0.5868, Q2 Loss=0.5868, Entropy=0.3256, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1464
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.4942, Q2 Loss=0.4942, Entropy=0.1508, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4180

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.8%)
Q1 update: 0.04s (19.7%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (39.9%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001370
Q1 loss: 0.590162
Q2 loss: 0.590162
Current threshold: -30.4194
Global Scale Offset: 2.1178
Reward stats: mean=-0.0146, std=0.1658, count=110
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 0.5902, Q2 Loss: 0.5902, Entropy: 0.1796, Mean TD Error: 0.3706, Threshold: -30.4194
tensor([ 7.5032e-02,  3.2158e-01,  6.3937e-01,  1.0602e+00, -1.0729e-01,
         5.5151e-01,  9.0828e-01,  1.2119e+00,  1.2516e+00, -5.8849e-04,
         3.2693e-01,  8.5151e-01,  5.3503e-02, -4.3559e-02, -4.9932e-01,
         3.1377e+00], device='cuda:0')
Original likelihood: -31.02983856201172
Adjusted likelihood: -31.02983856201172
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4233)
State is out of distribution
Projection step: 0, Loss: 31.950477600097656
Projection step: 1, Loss: 30.597335815429688
Projection step: 2, Loss: 26.973217010498047
Projection step: 3, Loss: 26.709449768066406
Projection step: 4, Loss: 25.407073974609375
Projection step: 5, Loss: 23.635234832763672
Projection step: 6, Loss: 23.13979721069336
Projection step: 7, Loss: 23.293724060058594
Projection step: 8, Loss: 22.321338653564453
Projection step: 9, Loss: 21.457294464111328
Projection step: 10, Loss: 21.72982406616211
Projection step: 11, Loss: 20.735383987426758
Projection step: 12, Loss: 20.09845733642578
Projection step: 13, Loss: 21.077163696289062
Projection step: 14, Loss: 20.062564849853516
Final likelihood: tensor([-21.0990, -17.2132, -17.5122, -22.6660, -25.0046, -23.6436, -18.0624,
        -17.0831, -26.0280, -23.6572, -25.2392, -18.5541, -18.0785, -22.5619,
        -17.1380, -17.7401])
Final projection likelihood: -20.7051
1 mode projection succeeded
New goal: tensor([ 0.0399,  0.3926,  0.6053,  0.9771, -0.0331,  0.5333,  0.7906,  1.0441,
         1.3692,  0.0753,  0.2561,  0.8060,  0.0455, -0.0312, -1.2769],
       device='cuda:0')
tensor([[0.0127]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -20.428760528564453
Adjusted likelihood: -20.428760528564453
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 20.428760528564453}
Current yaw: tensor([ 0.0535, -0.0436, -0.4993], device='cuda:0')
6 thumb_middle
tensor([ 7.5032e-02,  3.2158e-01,  6.3937e-01,  1.0602e+00, -1.0729e-01,
         5.5151e-01,  9.0828e-01,  1.2119e+00,  1.2516e+00, -5.8849e-04,
         3.2693e-01,  8.5151e-01,  5.3503e-02, -4.3559e-02, -4.9932e-01,
         3.1377e+00], device='cuda:0')
Solve time for step 1 8.891737947007641
Current ori: tensor([ 0.0535, -0.0436, -0.4993], device='cuda:0')
Index force: tensor([0.6004, 0.5999, 0.5969, 0.6056], device='cuda:0')
tensor([ 0.0445,  0.3591,  0.6021,  0.9918, -0.1363,  0.5295,  0.7780,  1.0544,
         1.3256,  0.0433,  0.2304,  0.8054,  0.0455, -0.0359, -0.4993,  3.2048],
       device='cuda:0')
Solve time for step 2 1.921224377991166
Current ori: tensor([ 0.0455, -0.0359, -0.4993], device='cuda:0')
Index force: tensor([0.5947, 0.5940, 0.6007], device='cuda:0')
tensor([ 0.0429,  0.3752,  0.5931,  0.9663, -0.1334,  0.5563,  0.7686,  1.0266,
         1.3484,  0.0582,  0.2042,  0.7903,  0.0422, -0.0373, -0.4993,  3.2253],
       device='cuda:0')
Solve time for step 3 1.84923448698828
Current ori: tensor([ 0.0422, -0.0373, -0.4993], device='cuda:0')
Index force: tensor([0.5886, 0.5960], device='cuda:0')
tensor([ 0.0430,  0.3672,  0.6010,  0.9708, -0.1295,  0.5647,  0.7665,  1.0224,
         1.3564,  0.0557,  0.1971,  0.7943,  0.0448, -0.0371, -0.4993,  3.2267],
       device='cuda:0')
Solve time for step 4 1.737732067995239
Current ori: tensor([ 0.0448, -0.0371, -0.4993], device='cuda:0')
Index force: tensor([0.5876], device='cuda:0')
Storing RECOVERY transition: reward=-0.0122 (scaled=-0.0014), steps=9
Reward stats updated: mean -0.0146 -> -0.0145, std: 0.1651
Collected 111 transitions for RL
SAC Update 1/5: Actor Loss=-0.0022, Q1 Loss=0.4887, Q2 Loss=0.4887, Entropy=0.3195, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1654
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=0.6231, Q2 Loss=0.6231, Entropy=0.1470, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4301
SAC Update 3/5: Actor Loss=-0.0019, Q1 Loss=39.9032, Q2 Loss=39.9032, Entropy=0.2412, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.7534
SAC Update 4/5: Actor Loss=-0.0022, Q1 Loss=0.5269, Q2 Loss=0.5269, Entropy=0.4770, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3182
SAC Update 5/5: Actor Loss=-0.0055, Q1 Loss=0.6552, Q2 Loss=0.6552, Entropy=0.3417, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1738

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.1%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (40.5%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002452
Q1 loss: 8.439435
Q2 loss: 8.439435
Current threshold: -30.4186
Global Scale Offset: 2.1917
Reward stats: mean=-0.0145, std=0.1651, count=111
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 8.4394, Q2 Loss: 8.4394, Entropy: 0.3053, Mean TD Error: 1.1682, Threshold: -30.4186
Original likelihood: -27.62156105041504
Adjusted likelihood: -27.62156105041504
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8063)
Current yaw: tensor([ 0.0498, -0.0230, -0.4845], device='cuda:0')
7 turn
Sampling time 3.753717433020938
tensor([ 0.0060,  0.3550,  0.5931,  0.9579, -0.0849,  0.6048,  0.8039,  1.0444,
         1.4237,  0.0838,  0.2758,  0.8423,  0.0498, -0.0230, -0.4845,  3.2241],
       device='cuda:0')
Original likelihood: -26.906089782714844
Adjusted likelihood: -26.906089782714844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8612)
Solve time for step 1 14.213156970974524
Current ori: tensor([ 0.0498, -0.0230, -0.4845], device='cuda:0')
Middle force: tensor([1.0394, 0.6463, 0.7097, 0.5182, 1.0315, 0.7044, 0.8846, 1.1713, 0.9611,
        0.6211, 0.5814, 0.5365], device='cuda:0')
Thumb force: tensor([0.6424, 0.5756, 0.5313, 0.4984, 0.5778, 1.2696, 1.2366, 0.5631, 0.5628,
        0.5371, 0.6206, 0.5893], device='cuda:0')
Index force: tensor([0.9795, 0.5499, 0.6126, 0.6176, 0.7621, 0.5271, 0.7258, 0.5316, 0.5162,
        0.5496, 0.5880, 0.6423], device='cuda:0')
Storing NORMAL transition: reward=0.0907 (scaled=0.0907), steps=1
Reward stats updated: mean -0.0145 -> -0.0136, std: 0.1646
Collected 112 transitions for RL
SAC Update 1/5: Actor Loss=-0.0026, Q1 Loss=0.6053, Q2 Loss=0.6053, Entropy=0.3511, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3410
SAC Update 2/5: Actor Loss=-0.0012, Q1 Loss=0.5851, Q2 Loss=0.5851, Entropy=0.3428, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5994
SAC Update 3/5: Actor Loss=-0.0006, Q1 Loss=0.7202, Q2 Loss=0.7202, Entropy=0.1650, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5725
SAC Update 4/5: Actor Loss=-0.0049, Q1 Loss=0.4619, Q2 Loss=0.4619, Entropy=0.3764, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5939
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=9.6354, Q2 Loss=9.6354, Entropy=0.2351, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9061

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.6%)
Actor update: 0.11s (40.8%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001972
Q1 loss: 2.401576
Q2 loss: 2.401576
Current threshold: -30.4116
Global Scale Offset: 2.2758
Reward stats: mean=-0.0136, std=0.1646, count=112
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 2.4016, Q2 Loss: 2.4016, Entropy: 0.2941, Mean TD Error: 1.4026, Threshold: -30.4116
tensor([-0.0036,  0.3292,  0.6609,  0.8844, -0.2012,  0.6402,  0.8875,  1.0691,
         1.3703,  0.2768,  0.2956,  0.8159,  0.0524, -0.0119, -0.5756,  3.3612],
       device='cuda:0')
Original likelihood: -32.378135681152344
Adjusted likelihood: -32.378135681152344
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2773)
State is out of distribution
Projection step: 0, Loss: 32.543155670166016
Projection step: 1, Loss: 29.560583114624023
Projection step: 2, Loss: 28.960765838623047
Projection step: 3, Loss: 26.916709899902344
Projection step: 4, Loss: 25.878215789794922
Projection step: 5, Loss: 23.03164291381836
Projection step: 6, Loss: 23.02325439453125
Projection step: 7, Loss: 21.941499710083008
Projection step: 8, Loss: 20.59259033203125
Projection step: 9, Loss: 21.241504669189453
Projection step: 10, Loss: 20.19687271118164
Projection step: 11, Loss: 19.11502456665039
Projection step: 12, Loss: 18.260906219482422
Projection step: 13, Loss: 18.50098419189453
Projection step: 14, Loss: 17.500530242919922
Final likelihood: tensor([-16.8523, -19.2197, -16.2816, -14.2495, -17.5379, -16.2799, -16.2615,
        -19.6580, -18.2359, -16.3635, -14.7893, -17.2771, -17.8564, -19.6660,
        -19.5556, -16.5063])
Final projection likelihood: -17.2869
1 mode projection succeeded
New goal: tensor([ 0.0081,  0.4259,  0.5773,  0.8993, -0.0752,  0.5306,  0.7862,  0.9765,
         1.3049,  0.1737,  0.2299,  0.9156,  0.0402, -0.0113, -1.5280],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0027]], device='cuda:0')
Original likelihood: -20.854307174682617
Adjusted likelihood: -20.854307174682617
Likelihood residual: 0.0
Original likelihood: -31.089069366455078
Adjusted likelihood: -31.089069366455078
Likelihood residual: 0.0
{'index': 31.089069366455078, 'thumb_middle': 20.854307174682617}
Current yaw: tensor([ 0.0524, -0.0119, -0.5756], device='cuda:0')
8 thumb_middle
tensor([-0.0036,  0.3292,  0.6609,  0.8844, -0.2012,  0.6402,  0.8875,  1.0691,
         1.3703,  0.2768,  0.2956,  0.8159,  0.0524, -0.0119, -0.5756,  3.3612],
       device='cuda:0')
Solve time for step 1 8.893450219999067
Current ori: tensor([ 0.0524, -0.0119, -0.5756], device='cuda:0')
Index force: tensor([0.5840, 0.5946, 0.6068, 0.6011], device='cuda:0')
tensor([ 8.4655e-04,  3.7766e-01,  6.0207e-01,  8.8122e-01, -1.6129e-01,
         5.5904e-01,  7.7077e-01,  9.6637e-01,  1.2882e+00,  1.9045e-01,
         2.1044e-01,  8.8910e-01,  4.8981e-02, -1.6180e-02, -5.7557e-01,
         3.4005e+00], device='cuda:0')
Solve time for step 2 1.8653256589896046
Current ori: tensor([ 0.0490, -0.0162, -0.5756], device='cuda:0')
Index force: tensor([0.5885, 0.6023, 0.5956], device='cuda:0')
tensor([ 0.0123,  0.3905,  0.5799,  0.9074, -0.1432,  0.5684,  0.7733,  0.9540,
         1.2922,  0.1717,  0.1947,  0.9045,  0.0492, -0.0215, -0.5756,  3.4183],
       device='cuda:0')
Solve time for step 3 1.7321951760095544
Current ori: tensor([ 0.0492, -0.0215, -0.5756], device='cuda:0')
Index force: tensor([0.5959, 0.5900], device='cuda:0')
tensor([-0.0056,  0.4079,  0.5505,  0.8876, -0.1498,  0.5699,  0.7534,  0.9457,
         1.3106,  0.1650,  0.1951,  0.8918,  0.0653, -0.0153, -0.5756,  3.6302],
       device='cuda:0')
Solve time for step 4 1.7461379599990323
Current ori: tensor([ 0.0653, -0.0153, -0.5756], device='cuda:0')
Index force: tensor([0.5778], device='cuda:0')
Storing RECOVERY transition: reward=-0.0240 (scaled=-0.0240), steps=1
Reward stats updated: mean -0.0136 -> -0.0137, std: 0.1639
Collected 113 transitions for RL
SAC Update 1/5: Actor Loss=-0.0009, Q1 Loss=0.4765, Q2 Loss=0.4765, Entropy=0.3309, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2400
SAC Update 2/5: Actor Loss=-0.0033, Q1 Loss=9.8353, Q2 Loss=9.8353, Entropy=0.5129, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9444
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=1.7027, Q2 Loss=1.7027, Entropy=0.2016, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3755
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=9.4996, Q2 Loss=9.4996, Entropy=0.2389, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9273
SAC Update 5/5: Actor Loss=-0.0014, Q1 Loss=9.6286, Q2 Loss=9.6286, Entropy=0.3904, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9391

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (19.8%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (39.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001357
Q1 loss: 6.228542
Q2 loss: 6.228542
Current threshold: -30.4046
Global Scale Offset: 2.3636
Reward stats: mean=-0.0137, std=0.1639, count=113
----------------------------------------------
SAC Update - Actor Loss: -0.0014, Q1 Loss: 6.2285, Q2 Loss: 6.2285, Entropy: 0.3349, Mean TD Error: 3.2852, Threshold: -30.4046
Original likelihood: -29.80963897705078
Adjusted likelihood: -29.80963897705078
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5690)
Current yaw: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:0')
9 turn
Sampling time 3.687505659996532
tensor([-0.0423,  0.3884,  0.5474,  0.8876, -0.0652,  0.6050,  0.7792,  0.9438,
         1.3720,  0.1884,  0.2644,  0.9729,  0.0711, -0.0050, -0.5538,  3.5317],
       device='cuda:0')
Original likelihood: -31.179811477661133
Adjusted likelihood: -31.179811477661133
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4104)
State is out of distribution
Projection step: 0, Loss: 31.705272674560547
Projection step: 1, Loss: 27.466955184936523
Projection step: 2, Loss: 27.20793914794922
Projection step: 3, Loss: 25.099300384521484
Projection step: 4, Loss: 24.665884017944336
Projection step: 5, Loss: 23.266925811767578
Projection step: 6, Loss: 22.266277313232422
Projection step: 7, Loss: 21.909976959228516
Projection step: 8, Loss: 21.527462005615234
Projection step: 9, Loss: 21.612689971923828
Projection step: 10, Loss: 20.81258201599121
Projection step: 11, Loss: 20.756513595581055
Projection step: 12, Loss: 20.26268768310547
Projection step: 13, Loss: 20.381927490234375
Projection step: 14, Loss: 19.684803009033203
Final likelihood: tensor([-21.8171, -21.4760, -20.2846, -22.1918, -19.2524, -19.3489, -21.8207,
        -15.6613, -21.5972, -16.0477, -21.8461, -14.5737, -19.4084, -21.3888,
        -21.0513, -19.2699])
Final projection likelihood: -19.8147
1 mode projection succeeded
New goal: tensor([ 0.0211,  0.4459,  0.5475,  0.8511, -0.0584,  0.5188,  0.7992,  0.9335,
         1.3252,  0.1694,  0.2247,  1.1007,  0.0555, -0.0125, -1.8538],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0024]], device='cuda:0')
Original likelihood: -24.169052124023438
Adjusted likelihood: -24.169052124023438
Likelihood residual: 0.0
Original likelihood: -31.08992576599121
Adjusted likelihood: -31.08992576599121
Likelihood residual: 0.0
{'index': 31.08992576599121, 'thumb_middle': 24.169052124023438}
Current yaw: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:0')
10 thumb_middle
tensor([-0.0423,  0.3884,  0.5474,  0.8876, -0.0652,  0.6050,  0.7792,  0.9438,
         1.3720,  0.1884,  0.2644,  0.9729,  0.0711, -0.0050, -0.5538,  3.5317],
       device='cuda:0')
Solve time for step 1 9.02860011998564
Current ori: tensor([ 0.0711, -0.0050, -0.5538], device='cuda:0')
Index force: tensor([0.5879, 0.5909, 0.5976, 0.5889], device='cuda:0')
tensor([-0.0390,  0.4147,  0.5365,  0.8370, -0.1405,  0.5480,  0.7614,  0.9101,
         1.2859,  0.1414,  0.1663,  1.0517,  0.1160,  0.0219, -0.5538,  4.1038],
       device='cuda:0')
Solve time for step 2 1.9602510369732045
Current ori: tensor([ 0.1160,  0.0219, -0.5538], device='cuda:0')
Index force: tensor([0.5864, 0.5935, 0.5857], device='cuda:0')
tensor([-0.0219,  0.4217,  0.5392,  0.8393, -0.1497,  0.5530,  0.7635,  0.9041,
         1.3009,  0.1500,  0.1658,  1.0810,  0.1302,  0.0666, -0.5538,  4.7209],
       device='cuda:0')
Solve time for step 3 1.8329585270257667
Current ori: tensor([ 0.1302,  0.0666, -0.5538], device='cuda:0')
Index force: tensor([0.5904, 0.5803], device='cuda:0')
tensor([-0.0109,  0.4324,  0.5355,  0.8361, -0.1937,  0.5315,  0.7471,  0.8910,
         1.3275,  0.1578,  0.1950,  1.1010,  0.1354,  0.1016, -0.5537,  5.0581],
       device='cuda:0')
Solve time for step 4 1.7717108660144731
Current ori: tensor([ 0.1354,  0.1016, -0.5537], device='cuda:0')
Index force: tensor([0.5897], device='cuda:0')
Storing RECOVERY transition: reward=-0.0503 (scaled=-0.0503), steps=0
Reward stats updated: mean -0.0137 -> -0.0140, std: 0.1632
Collected 114 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.4282, Q2 Loss=0.4282, Entropy=0.3866, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2951
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=1.2828, Q2 Loss=1.2828, Entropy=0.1814, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2716
SAC Update 3/5: Actor Loss=-0.0114, Q1 Loss=0.6465, Q2 Loss=0.6465, Entropy=0.6817, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0874
SAC Update 4/5: Actor Loss=-0.0040, Q1 Loss=0.4337, Q2 Loss=0.4337, Entropy=0.3307, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3293
SAC Update 5/5: Actor Loss=-0.0239, Q1 Loss=0.8258, Q2 Loss=0.8258, Entropy=0.4891, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4046

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (18.6%)
Q1 update: 0.04s (19.8%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (39.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008114
Q1 loss: 0.723398
Q2 loss: 0.723398
Current threshold: -30.4034
Global Scale Offset: 2.4335
Reward stats: mean=-0.0140, std=0.1632, count=114
----------------------------------------------
SAC Update - Actor Loss: -0.0081, Q1 Loss: 0.7234, Q2 Loss: 0.7234, Entropy: 0.4139, Mean TD Error: 0.4776, Threshold: -30.4034
Original likelihood: -14.584827423095703
Adjusted likelihood: -14.584827423095703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=1.0000)
Current yaw: tensor([ 0.1446,  0.0701, -0.5214], device='cuda:0')
11 turn
Sampling time 3.7023935820325278
tensor([-1.1657e-03,  4.4718e-01,  5.3040e-01,  8.2734e-01, -1.3575e-01,
         5.5642e-01,  7.7600e-01,  9.0432e-01,  1.4128e+00,  1.9317e-01,
         2.9409e-01,  1.1532e+00,  1.4464e-01,  7.0098e-02, -5.2144e-01,
         4.5785e+00], device='cuda:0')
Original likelihood: -23.137542724609375
Adjusted likelihood: -23.137542724609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9811)
Solve time for step 1 14.417483124998398
Current ori: tensor([ 0.1446,  0.0701, -0.5214], device='cuda:0')
Middle force: tensor([0.7922, 1.2294, 0.8746, 1.3565, 0.6182, 0.5419, 0.5430, 0.7769, 0.5528,
        0.6007, 1.2996, 1.1684], device='cuda:0')
Thumb force: tensor([0.6962, 3.4091, 1.1300, 1.9742, 0.5874, 0.8296, 1.4691, 0.6183, 0.5598,
        1.2851, 1.4392, 1.0633], device='cuda:0')
Index force: tensor([0.8885, 0.7810, 0.9690, 0.7112, 0.5262, 0.5632, 0.5845, 0.7229, 0.5717,
        0.5572, 0.5435, 0.5648], device='cuda:0')
Storing NORMAL transition: reward=-0.0048 (scaled=-0.0048), steps=1
Reward stats updated: mean -0.0140 -> -0.0139, std: 0.1625
Collected 115 transitions for RL
SAC Update 1/5: Actor Loss=-0.0011, Q1 Loss=0.5377, Q2 Loss=0.5377, Entropy=0.2047, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2956
SAC Update 2/5: Actor Loss=-0.0051, Q1 Loss=1.2037, Q2 Loss=1.2037, Entropy=0.3883, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9079
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=1.2104, Q2 Loss=1.2104, Entropy=0.0331, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1538
SAC Update 4/5: Actor Loss=-0.0074, Q1 Loss=0.5689, Q2 Loss=0.5689, Entropy=0.3462, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5425
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=0.7296, Q2 Loss=0.7296, Entropy=0.1587, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4203

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (19.7%)
Q2 update: 0.05s (19.1%)
Actor update: 0.09s (38.3%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002875
Q1 loss: 0.850041
Q2 loss: 0.850041
Current threshold: -30.4026
Global Scale Offset: 2.4480
Reward stats: mean=-0.0139, std=0.1625, count=115
----------------------------------------------
SAC Update - Actor Loss: -0.0029, Q1 Loss: 0.8500, Q2 Loss: 0.8500, Entropy: 0.2262, Mean TD Error: 0.6640, Threshold: -30.4026
tensor([ 0.0427,  0.5127,  0.4851,  0.8418, -0.0223,  0.5205,  0.7992,  1.0954,
         1.4768,  0.1367,  0.2442,  1.1414,  0.2099,  0.0383, -0.5353,  3.8431],
       device='cuda:0')
Original likelihood: -34.505332946777344
Adjusted likelihood: -34.505332946777344
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.1215)
Solve time for step 2 2.8566067430074327
Current ori: tensor([ 0.2099,  0.0383, -0.5353], device='cuda:0')
Middle force: tensor([1.2242, 0.8508, 1.3338, 0.6096, 0.5371, 0.5422, 0.7569, 0.5518, 0.5928,
        1.2582, 1.1483], device='cuda:0')
Thumb force: tensor([3.3630, 1.1814, 1.9893, 0.5919, 0.8205, 1.4527, 0.6244, 0.5594, 1.2899,
        1.4520, 1.0638], device='cuda:0')
Index force: tensor([0.7804, 0.9782, 0.7027, 0.5271, 0.5701, 0.5827, 0.7273, 0.5704, 0.5559,
        0.5455, 0.5663], device='cuda:0')
Storing NORMAL transition: reward=0.0239 (scaled=0.0239), steps=1
Reward stats updated: mean -0.0139 -> -0.0136, std: 0.1618
Collected 116 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=11.7843, Q2 Loss=11.7843, Entropy=0.3155, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1814
SAC Update 2/5: Actor Loss=-0.0022, Q1 Loss=0.4608, Q2 Loss=0.4608, Entropy=0.4554, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6306
SAC Update 3/5: Actor Loss=-0.0019, Q1 Loss=0.7518, Q2 Loss=0.7518, Entropy=0.2562, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0147
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.7318, Q2 Loss=0.7318, Entropy=0.1602, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4200
SAC Update 5/5: Actor Loss=-0.0189, Q1 Loss=0.9594, Q2 Loss=0.9594, Entropy=0.1918, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6282

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.04s (17.5%)
Actor update: 0.10s (40.3%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004946
Q1 loss: 2.937625
Q2 loss: 2.937625
Current threshold: -30.3990
Global Scale Offset: 2.4666
Reward stats: mean=-0.0136, std=0.1618, count=116
----------------------------------------------
SAC Update - Actor Loss: -0.0049, Q1 Loss: 2.9376, Q2 Loss: 2.9376, Entropy: 0.2758, Mean TD Error: 1.5750, Threshold: -30.3990
tensor([ 0.0972,  0.4986,  0.5589,  0.8766,  0.0429,  0.5514,  0.8438,  1.0817,
         1.4880,  0.2967,  0.2545,  1.1393,  0.2442,  0.0275, -0.5769,  3.5544],
       device='cuda:0')
Original likelihood: -46.221946716308594
Adjusted likelihood: -46.221946716308594
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 44.38255310058594
Projection step: 1, Loss: 47.20683288574219
Projection step: 2, Loss: 43.881404876708984
Projection step: 3, Loss: 47.18025207519531
Projection step: 4, Loss: 44.2370719909668
Projection step: 5, Loss: 41.9002685546875
Projection step: 6, Loss: 43.22075271606445
Projection step: 7, Loss: 40.077369689941406
Projection step: 8, Loss: 41.584686279296875
Projection step: 9, Loss: 40.814186096191406
Projection step: 10, Loss: 41.38356018066406
Projection step: 11, Loss: 39.18837356567383
Projection step: 12, Loss: 39.747650146484375
Projection step: 13, Loss: 39.323516845703125
Projection step: 14, Loss: 37.92919921875
Final likelihood: tensor([-33.5777, -40.2987, -51.2824, -39.4140, -35.5630, -49.2177, -52.0370,
        -35.6176, -38.5915, -36.7101, -40.6092, -55.1310, -39.4564, -37.5438,
        -39.2696, -38.5444])
Final projection likelihood: -41.4290
1 mode projection failed, trying anyway
New goal: tensor([8.5368e-02, 4.2706e-01, 6.0817e-01, 9.3072e-01, 4.1272e-04, 4.7153e-01,
        8.7928e-01, 1.1595e+00, 1.4440e+00, 1.8025e-01, 3.1133e-01, 9.2332e-01,
        2.3092e-01, 2.6897e-02, 2.1979e-01], device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0011]], device='cuda:0')
Original likelihood: -41.55663299560547
Adjusted likelihood: -41.55663299560547
Likelihood residual: 0.0
Original likelihood: -44.44532012939453
Adjusted likelihood: -44.44532012939453
Likelihood residual: 0.0
{'index': 44.44532012939453, 'thumb_middle': 41.55663299560547}
Current yaw: tensor([ 0.2442,  0.0275, -0.5769], device='cuda:0')
12 thumb_middle
tensor([ 0.0972,  0.4986,  0.5589,  0.8766,  0.0429,  0.5514,  0.8438,  1.0817,
         1.4880,  0.2967,  0.2545,  1.1393,  0.2442,  0.0275, -0.5769,  3.5544],
       device='cuda:0')
Solve time for step 1 8.890940307988785
Current ori: tensor([ 0.2442,  0.0275, -0.5769], device='cuda:0')
Index force: tensor([0.5641, 0.5433, 0.5779, 0.5831], device='cuda:0')
tensor([ 0.1011,  0.5009,  0.6317,  0.8944, -0.1418,  0.4235,  0.8163,  1.1126,
         1.4529,  0.1789,  0.2728,  0.9813,  0.2438,  0.0282, -0.5907,  3.4809],
       device='cuda:0')
Solve time for step 2 1.9380332179716788
Current ori: tensor([ 0.2438,  0.0282, -0.5907], device='cuda:0')
Index force: tensor([0.5412, 0.5752, 0.5815], device='cuda:0')
tensor([ 0.1019,  0.5009,  0.6355,  0.9201, -0.1436,  0.4184,  0.8042,  1.1114,
         1.4650,  0.1915,  0.2778,  0.9445,  0.2441,  0.0305, -0.6036,  3.4729],
       device='cuda:0')
Solve time for step 3 1.8603044360061176
Current ori: tensor([ 0.2441,  0.0305, -0.6036], device='cuda:0')
Index force: tensor([0.5701, 0.5768], device='cuda:0')
tensor([ 0.1082,  0.5054,  0.6389,  0.9315, -0.1403,  0.4447,  0.8233,  1.1189,
         1.4705,  0.1916,  0.2748,  0.9252,  0.2425,  0.0244, -0.6101,  3.5274],
       device='cuda:0')
Solve time for step 4 1.822279941989109
Current ori: tensor([ 0.2425,  0.0244, -0.6101], device='cuda:0')
Index force: tensor([0.5693], device='cuda:0')
Storing RECOVERY transition: reward=0.0212 (scaled=0.0106), steps=2
Reward stats updated: mean -0.0136 -> -0.0134, std: 0.1612
Collected 117 transitions for RL
SAC Update 1/5: Actor Loss=-0.0053, Q1 Loss=0.5686, Q2 Loss=0.5686, Entropy=0.1883, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4069
SAC Update 2/5: Actor Loss=-0.0108, Q1 Loss=2.2749, Q2 Loss=2.2749, Entropy=0.3518, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5531
SAC Update 3/5: Actor Loss=-0.0041, Q1 Loss=0.9170, Q2 Loss=0.9170, Entropy=0.3336, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6231
SAC Update 4/5: Actor Loss=-0.0027, Q1 Loss=0.7496, Q2 Loss=0.7496, Entropy=0.2779, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2835
SAC Update 5/5: Actor Loss=-0.0068, Q1 Loss=0.4687, Q2 Loss=0.4687, Entropy=0.3504, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2442

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (15.3%)
Q1 update: 0.05s (17.2%)
Q2 update: 0.05s (16.1%)
Actor update: 0.10s (33.4%)
Target update: 0.05s (16.1%)
Priority update: 0.00s (0.2%)
Actor loss: -0.005922
Q1 loss: 0.995751
Q2 loss: 0.995751
Current threshold: -30.3819
Global Scale Offset: 2.4214
Reward stats: mean=-0.0134, std=0.1612, count=117
----------------------------------------------
SAC Update - Actor Loss: -0.0059, Q1 Loss: 0.9958, Q2 Loss: 0.9958, Entropy: 0.3004, Mean TD Error: 0.6222, Threshold: -30.3819
Original likelihood: -45.16588592529297
Adjusted likelihood: -45.16588592529297
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 45.44044494628906
Projection step: 1, Loss: 45.207496643066406
Projection step: 2, Loss: 46.40431594848633
Projection step: 3, Loss: 42.581016540527344
Projection step: 4, Loss: 41.959293365478516
Projection step: 5, Loss: 42.86892318725586
Projection step: 6, Loss: 42.242225646972656
Projection step: 7, Loss: 41.211544036865234
Projection step: 8, Loss: 39.92814636230469
Projection step: 9, Loss: 41.53227615356445
Projection step: 10, Loss: 39.58577346801758
Projection step: 11, Loss: 38.84568786621094
Projection step: 12, Loss: 40.406070709228516
Projection step: 13, Loss: 39.041343688964844
Projection step: 14, Loss: 37.977882385253906
Final likelihood: tensor([-35.1891, -37.5237, -39.3544, -36.7172, -34.7039, -34.1039, -34.6996,
        -43.8094, -37.9055, -40.5441, -36.7379, -40.3587, -32.0943, -37.7741,
        -37.9884, -39.0413])
Final projection likelihood: -37.4091
1 mode projection failed, trying anyway
New goal: tensor([ 0.0769,  0.4001,  0.6293,  0.9496, -0.0268,  0.4759,  0.8946,  1.2004,
         1.4661,  0.1172,  0.3783,  0.7760,  0.2326,  0.0247,  0.2818],
       device='cuda:0')
tensor([[0.0049]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0008]], device='cuda:0')
Original likelihood: -45.33116149902344
Adjusted likelihood: -45.33116149902344
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 45.33116149902344}
Current yaw: tensor([ 0.2455,  0.0241, -0.6015], device='cuda:0')
13 thumb_middle
tensor([ 0.0751,  0.4952,  0.6520,  0.9451, -0.0256,  0.5314,  0.8784,  1.1729,
         1.5000,  0.2369,  0.3450,  0.9499,  0.2455,  0.0241, -0.6015,  3.5966],
       device='cuda:0')
Solve time for step 1 9.123382302001119
Current ori: tensor([ 0.2455,  0.0241, -0.6015], device='cuda:0')
Index force: tensor([0.5947, 0.5145, 0.5985, 0.6029], device='cuda:0')
tensor([ 0.0734,  0.4919,  0.6091,  1.1883, -0.1496,  0.4332,  0.8190,  1.1423,
         1.4431,  0.1153,  0.3746,  0.8652,  0.2480,  0.0387, -0.6201,  3.3705],
       device='cuda:0')
Solve time for step 2 2.06244146899553
Current ori: tensor([ 0.2480,  0.0387, -0.6201], device='cuda:0')
Index force: tensor([0.5136, 0.5941, 0.5961], device='cuda:0')
tensor([ 0.0618,  0.4770,  0.6946,  1.0787, -0.1737,  0.4285,  0.8157,  1.1416,
         1.4572,  0.0993,  0.3879,  0.8477,  0.2516,  0.0458, -0.6464,  3.5737],
       device='cuda:0')
Solve time for step 3 1.850406594981905
Current ori: tensor([ 0.2516,  0.0458, -0.6464], device='cuda:0')
Index force: tensor([0.5899, 0.5917], device='cuda:0')
tensor([ 0.0397,  0.4844,  0.7237,  1.0335, -0.1959,  0.4096,  0.8175,  1.1469,
         1.4568,  0.0940,  0.4012,  0.8473,  0.2547,  0.0582, -0.6607,  3.9681],
       device='cuda:0')
Solve time for step 4 1.8266322730341926
Current ori: tensor([ 0.2547,  0.0582, -0.6607], device='cuda:0')
Index force: tensor([0.5666], device='cuda:0')
Storing RECOVERY transition: reward=0.0429 (scaled=0.0214), steps=2
Reward stats updated: mean -0.0134 -> -0.0131, std: 0.1605
Collected 118 transitions for RL
SAC Update 1/5: Actor Loss=-0.0021, Q1 Loss=36.3211, Q2 Loss=36.3211, Entropy=0.2424, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8497
SAC Update 2/5: Actor Loss=-0.0056, Q1 Loss=0.4412, Q2 Loss=0.4412, Entropy=0.3001, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1722
SAC Update 3/5: Actor Loss=-0.0217, Q1 Loss=5.9574, Q2 Loss=5.9574, Entropy=0.4230, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8946
SAC Update 4/5: Actor Loss=-0.0021, Q1 Loss=35.2602, Q2 Loss=35.2602, Entropy=0.2406, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.8835
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.0801, Q2 Loss=1.0801, Entropy=0.1561, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7387

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.2%)
Q1 update: 0.04s (18.0%)
Q2 update: 0.04s (18.1%)
Actor update: 0.10s (43.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006487
Q1 loss: 15.812014
Q2 loss: 15.812014
Current threshold: -30.3691
Global Scale Offset: 2.3704
Reward stats: mean=-0.0131, std=0.1605, count=118
----------------------------------------------
SAC Update - Actor Loss: -0.0065, Q1 Loss: 15.8120, Q2 Loss: 15.8120, Entropy: 0.2724, Mean TD Error: 3.1077, Threshold: -30.3691
Original likelihood: -56.83538055419922
Adjusted likelihood: -56.83538055419922
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 62.46647262573242
Projection step: 1, Loss: 61.80360412597656
Projection step: 2, Loss: 56.05412673950195
Projection step: 3, Loss: 57.315345764160156
Projection step: 4, Loss: 58.99363708496094
Projection step: 5, Loss: 57.53682327270508
Projection step: 6, Loss: 58.46842575073242
Projection step: 7, Loss: 55.39852523803711
Projection step: 8, Loss: 56.12024688720703
Projection step: 9, Loss: 53.44200134277344
Projection step: 10, Loss: 52.12311553955078
Projection step: 11, Loss: 53.62644958496094
Projection step: 12, Loss: 47.924407958984375
Projection step: 13, Loss: 49.400146484375
Projection step: 14, Loss: 47.279727935791016
Final likelihood: tensor([-54.7023, -49.5653, -47.0666, -51.7399, -46.8652, -63.5031, -36.7734,
        -49.1010, -70.2241, -52.6436, -39.2844, -46.7203, -36.6545, -44.5168,
        -41.6162, -53.3881])
Final projection likelihood: -49.0228
1 mode projection failed, trying anyway
New goal: tensor([ 0.0329,  0.3587,  0.6603,  0.9599, -0.0828,  0.4732,  0.8762,  1.1795,
         1.4712,  0.0233,  0.5176,  0.7033,  0.2437,  0.0562, -0.1252],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0002]], device='cuda:0')
Original likelihood: -63.606292724609375
Adjusted likelihood: -63.606292724609375
Likelihood residual: 0.0
Original likelihood: -64.2793960571289
Adjusted likelihood: -64.2793960571289
Likelihood residual: 0.0
{'index': 64.2793960571289, 'thumb_middle': 63.606292724609375}
Current yaw: tensor([ 0.2559,  0.0583, -0.6362], device='cuda:0')
14 thumb_middle
tensor([ 0.0190,  0.4929,  0.7168,  0.9898, -0.0874,  0.4997,  0.8750,  1.1887,
         1.5000,  0.1138,  0.4908,  0.9453,  0.2559,  0.0583, -0.6362,  3.9141],
       device='cuda:0')
Solve time for step 1 8.3912025350146
Current ori: tensor([ 0.2559,  0.0583, -0.6362], device='cuda:0')
Index force: tensor([0.5832, 0.5839, 0.5833, 0.5865], device='cuda:0')
tensor([ 0.0090,  0.4821,  0.6738,  1.1874, -0.2199,  0.2677,  0.8619,  1.1676,
         1.4430,  0.0044,  0.5226,  0.8280,  0.2667,  0.0769, -0.6484,  4.0765],
       device='cuda:0')
Solve time for step 2 1.924459903035313
Current ori: tensor([ 0.2667,  0.0769, -0.6484], device='cuda:0')
Index force: tensor([0.5785, 0.5767, 0.5796], device='cuda:0')
tensor([ 1.5661e-03,  4.5592e-01,  7.1399e-01,  1.1762e+00, -2.0882e-01,
         3.3018e-01,  8.7844e-01,  1.1834e+00,  1.4852e+00,  1.6776e-02,
         5.2985e-01,  7.6057e-01,  2.7021e-01,  7.9635e-02, -6.3992e-01,
         4.0929e+00], device='cuda:0')
Solve time for step 3 1.8802953190170228
Current ori: tensor([ 0.2702,  0.0796, -0.6399], device='cuda:0')
Index force: tensor([0.5550, 0.5809], device='cuda:0')
tensor([-0.0200,  0.4625,  0.7773,  1.0388, -0.2250,  0.4244,  0.8554,  1.1784,
         1.4812,  0.0062,  0.5511,  0.7353,  0.2773,  0.0919, -0.6475,  4.2261],
       device='cuda:0')
Solve time for step 4 1.8019606749876402
Current ori: tensor([ 0.2773,  0.0919, -0.6475], device='cuda:0')
Index force: tensor([0.5724], device='cuda:0')
Storing RECOVERY transition: reward=0.0415 (scaled=0.0208), steps=2
Reward stats updated: mean -0.0131 -> -0.0128, std: 0.1599
Collected 119 transitions for RL
SAC Update 1/5: Actor Loss=-0.0015, Q1 Loss=9.4998, Q2 Loss=9.4998, Entropy=0.3898, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1293
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=0.4094, Q2 Loss=0.4094, Entropy=0.1133, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1577
SAC Update 3/5: Actor Loss=-0.0015, Q1 Loss=9.2536, Q2 Loss=9.2536, Entropy=0.3877, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1293
SAC Update 4/5: Actor Loss=-0.0013, Q1 Loss=0.9499, Q2 Loss=0.9499, Entropy=0.2300, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7032
SAC Update 5/5: Actor Loss=-0.0033, Q1 Loss=0.6249, Q2 Loss=0.6249, Entropy=0.3021, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4712

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.1%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.04s (17.8%)
Actor update: 0.10s (40.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001635
Q1 loss: 4.147534
Q2 loss: 4.147534
Current threshold: -30.3635
Global Scale Offset: 2.3578
Reward stats: mean=-0.0128, std=0.1599, count=119
----------------------------------------------
SAC Update - Actor Loss: -0.0016, Q1 Loss: 4.1475, Q2 Loss: 4.1475, Entropy: 0.2846, Mean TD Error: 2.3181, Threshold: -30.3635
Original likelihood: -81.37447357177734
Adjusted likelihood: -81.37447357177734
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 76.01062774658203
Projection step: 1, Loss: 76.41940307617188
Projection step: 2, Loss: 72.49710083007812
Projection step: 3, Loss: 73.88279724121094
Projection step: 4, Loss: 75.6622314453125
Projection step: 5, Loss: 74.47982788085938
Projection step: 6, Loss: 74.10478973388672
Projection step: 7, Loss: 73.34873962402344
Projection step: 8, Loss: 69.58503723144531
Projection step: 9, Loss: 70.64511108398438
Projection step: 10, Loss: 69.81036376953125
Projection step: 11, Loss: 69.94357299804688
Projection step: 12, Loss: 67.79283142089844
Projection step: 13, Loss: 70.04660034179688
Projection step: 14, Loss: 66.51412963867188
Final likelihood: tensor([-61.4230, -83.2785, -62.6451, -70.1385, -64.8637, -74.4148, -85.0284,
        -59.8697, -67.9088, -60.5957, -61.4625, -68.6415, -57.2231, -88.1445,
        -87.4099, -55.1025])
Final projection likelihood: -69.2594
1 mode projection failed, trying anyway
New goal: tensor([ 0.0588,  0.3306,  0.7719,  0.9805, -0.1461,  0.4577,  0.9252,  1.1669,
         1.4025,  0.0679,  0.7398,  0.5392,  0.2617,  0.0885, -0.2992],
       device='cuda:0')
tensor([[0.0032]], device='cuda:0') tensor([[0.0019]], device='cuda:0') tensor([[0.0004]], device='cuda:0')
Original likelihood: -83.39778137207031
Adjusted likelihood: -83.39778137207031
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 83.39778137207031}
Current yaw: tensor([ 0.2690,  0.0812, -0.6471], device='cuda:0')
15 thumb_middle
tensor([ 0.0277,  0.4787,  0.7992,  1.0095, -0.1688,  0.4463,  0.8554,  1.1371,
         1.5000,  0.0301,  0.6830,  0.7702,  0.2690,  0.0812, -0.6471,  4.1432],
       device='cuda:0')
Solve time for step 1 8.899200003012083
Current ori: tensor([ 0.2690,  0.0812, -0.6471], device='cuda:0')
Index force: tensor([0.5354, 0.5924, 0.5635, 0.5897], device='cuda:0')
tensor([ 0.0213,  0.4927,  0.7233,  1.3180, -0.2820,  0.2142,  0.9029,  1.1768,
         1.3848,  0.0052,  0.7366,  0.6261,  0.2943,  0.1089, -0.6738,  4.0488],
       device='cuda:0')
Solve time for step 2 2.0613446600036696
Current ori: tensor([ 0.2943,  0.1089, -0.6738], device='cuda:0')
Index force: tensor([0.5333, 0.5779, 0.5951], device='cuda:0')
tensor([ 0.0237,  0.4523,  0.8811,  1.1903, -0.2327,  0.1765,  0.9342,  1.1815,
         1.3846,  0.0173,  0.7556,  0.5895,  0.2936,  0.1068, -0.6693,  4.1694],
       device='cuda:0')
Solve time for step 3 1.8847551440121606
Current ori: tensor([ 0.2936,  0.1068, -0.6693], device='cuda:0')
Index force: tensor([0.5728, 0.5932], device='cuda:0')
tensor([ 0.0135,  0.4262,  0.8566,  1.2789, -0.2565,  0.2014,  0.8950,  1.1687,
         1.3866,  0.0173,  0.7841,  0.5974,  0.2975,  0.1096, -0.6673,  4.2519],
       device='cuda:0')
Solve time for step 4 1.7364831699524075
Current ori: tensor([ 0.2975,  0.1096, -0.6673], device='cuda:0')
Index force: tensor([0.5852], device='cuda:0')
Storing RECOVERY transition: reward=0.0170 (scaled=0.0085), steps=2
Reward stats updated: mean -0.0128 -> -0.0126, std: 0.1592
Collected 120 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.7046, Q2 Loss=0.7046, Entropy=0.1708, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3973
SAC Update 2/5: Actor Loss=-0.0010, Q1 Loss=0.5146, Q2 Loss=0.5146, Entropy=0.2739, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0772
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=1.0620, Q2 Loss=1.0620, Entropy=0.1747, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2377
SAC Update 4/5: Actor Loss=-0.0070, Q1 Loss=0.6998, Q2 Loss=0.6998, Entropy=0.6194, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3918
SAC Update 5/5: Actor Loss=-0.0096, Q1 Loss=0.6954, Q2 Loss=0.6954, Entropy=0.6607, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6391

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.5%)
Q1 update: 0.04s (19.9%)
Q2 update: 0.04s (19.5%)
Actor update: 0.08s (38.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003725
Q1 loss: 0.735250
Q2 loss: 0.735250
Current threshold: -30.3643
Global Scale Offset: 2.3856
Reward stats: mean=-0.0126, std=0.1592, count=120
----------------------------------------------
SAC Update - Actor Loss: -0.0037, Q1 Loss: 0.7352, Q2 Loss: 0.7352, Entropy: 0.3799, Mean TD Error: 0.5486, Threshold: -30.3643
Original likelihood: -80.0724868774414
Adjusted likelihood: -80.0724868774414
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 82.38965606689453
Projection step: 1, Loss: 83.83944702148438
Projection step: 2, Loss: 87.78413391113281
Projection step: 3, Loss: 78.02588653564453
Projection step: 4, Loss: 80.30076599121094
Projection step: 5, Loss: 75.72239685058594
Projection step: 6, Loss: 83.32660675048828
Projection step: 7, Loss: 81.93560791015625
Projection step: 8, Loss: 80.40226745605469
Projection step: 9, Loss: 74.67533874511719
Projection step: 10, Loss: 83.27326965332031
Projection step: 11, Loss: 74.64192199707031
Projection step: 12, Loss: 78.67515563964844
Projection step: 13, Loss: 83.43365478515625
Projection step: 14, Loss: 70.67670440673828
Final likelihood: tensor([-82.0144, -78.2570, -71.1668, -81.6287, -75.1254, -77.1994, -83.6517,
        -97.6966, -63.0919, -96.5795, -75.8943, -82.1088, -86.1831, -58.9967,
        -61.4297, -80.2447])
Final projection likelihood: -78.2043
1 mode projection failed, trying anyway
New goal: tensor([ 0.0697,  0.3298,  0.8294,  1.0353, -0.1045,  0.3501,  1.0015,  1.1861,
         1.3293,  0.0660,  0.9045,  0.5058,  0.2713,  0.0993, -0.7297],
       device='cuda:0')
tensor([[0.0028]], device='cuda:0') tensor([[0.0030]], device='cuda:0') tensor([[0.0005]], device='cuda:0')
Original likelihood: -76.07490539550781
Adjusted likelihood: -76.07490539550781
Likelihood residual: 0.0
Original likelihood: -75.4072036743164
Adjusted likelihood: -75.4072036743164
Likelihood residual: 0.0
{'index': 75.4072036743164, 'thumb_middle': 76.07490539550781}
Current yaw: tensor([ 0.2779,  0.0906, -0.6250], device='cuda:0')
16 index
tensor([ 0.0395,  0.4428,  0.8850,  1.0392, -0.1287,  0.2683,  0.8737,  1.1313,
         1.4011,  0.0087,  0.8820,  0.6598,  0.2779,  0.0906, -0.6250,  4.3507],
       device='cuda:0')
Solve time for step 1 10.574730987020303
Current ori: tensor([ 0.2779,  0.0906, -0.6250], device='cuda:0')
Middle force: tensor([0.5910, 0.5171, 0.5128, 0.5026], device='cuda:0')
Thumb force: tensor([0.5690, 0.6367, 0.6761, 0.5938], device='cuda:0')
tensor([ 0.0458,  0.1481,  0.7854,  0.9925, -0.1288,  0.2718,  0.8712,  1.3212,
         1.3775,  0.0449,  0.9358,  0.5336,  0.2735,  0.0915, -0.6640,  2.6463],
       device='cuda:0')
Solve time for step 2 2.3340548050473444
Current ori: tensor([ 0.2735,  0.0915, -0.6640], device='cuda:0')
Middle force: tensor([0.5171, 0.5129, 0.5024], device='cuda:0')
Thumb force: tensor([0.6289, 0.6642, 0.5900], device='cuda:0')
tensor([ 0.0365,  0.0702,  0.8024,  0.9980, -0.1109,  0.2548,  0.9274,  1.2410,
         1.3896,  0.0481,  0.9361,  0.5026,  0.2745,  0.0879, -0.6579,  1.2113],
       device='cuda:0')
Solve time for step 3 2.1883793929591775
Current ori: tensor([ 0.2745,  0.0879, -0.6579], device='cuda:0')
Middle force: tensor([0.5124, 0.5022], device='cuda:0')
Thumb force: tensor([0.6530, 0.5864], device='cuda:0')
tensor([ 0.0406,  0.0326,  0.7968,  1.0021, -0.0941,  0.2539,  0.9512,  1.1948,
         1.3924,  0.0493,  0.9426,  0.4701,  0.2731,  0.0853, -0.6754, -0.7524],
       device='cuda:0')
Solve time for step 4 2.132921456010081
Current ori: tensor([ 0.2731,  0.0853, -0.6754], device='cuda:0')
Middle force: tensor([0.5021], device='cuda:0')
Thumb force: tensor([0.5843], device='cuda:0')
Storing RECOVERY transition: reward=0.0341 (scaled=0.0171), steps=2
Reward stats updated: mean -0.0126 -> -0.0124, std: 0.1586
Collected 121 transitions for RL
SAC Update 1/5: Actor Loss=-0.0174, Q1 Loss=0.8524, Q2 Loss=0.8524, Entropy=0.3331, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5459
SAC Update 2/5: Actor Loss=-0.0005, Q1 Loss=7.9822, Q2 Loss=7.9822, Entropy=0.2518, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1142
SAC Update 3/5: Actor Loss=-0.0002, Q1 Loss=0.5113, Q2 Loss=0.5113, Entropy=0.0503, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2669
SAC Update 4/5: Actor Loss=-0.0039, Q1 Loss=0.6738, Q2 Loss=0.6738, Entropy=0.3152, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1576
SAC Update 5/5: Actor Loss=-0.0015, Q1 Loss=8.6322, Q2 Loss=8.6322, Entropy=0.3899, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1711

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.9%)
Target Q: 0.04s (16.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.05s (20.8%)
Actor update: 0.11s (39.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004695
Q1 loss: 3.730391
Q2 loss: 3.730391
Current threshold: -30.3621
Global Scale Offset: 2.3799
Reward stats: mean=-0.0124, std=0.1586, count=121
----------------------------------------------
SAC Update - Actor Loss: -0.0047, Q1 Loss: 3.7304, Q2 Loss: 3.7304, Entropy: 0.2681, Mean TD Error: 2.2511, Threshold: -30.3621
Original likelihood: -81.42859649658203
Adjusted likelihood: -81.42859649658203
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 89.20860290527344
Projection step: 1, Loss: 90.64408874511719
Projection step: 2, Loss: 90.66358947753906
Projection step: 3, Loss: 79.57886505126953
Projection step: 4, Loss: 91.1375732421875
Projection step: 5, Loss: 88.70362854003906
Projection step: 6, Loss: 81.77017211914062
Projection step: 7, Loss: 86.57734680175781
Projection step: 8, Loss: 88.83897399902344
Projection step: 9, Loss: 87.51036071777344
Projection step: 10, Loss: 89.10214233398438
Projection step: 11, Loss: 81.1311264038086
Projection step: 12, Loss: 78.92239379882812
Projection step: 13, Loss: 77.1080322265625
Projection step: 14, Loss: 80.37710571289062
Final likelihood: tensor([ -83.5979,  -98.5184,  -75.3749,  -63.6393,  -65.0477, -130.3933,
         -81.5244,  -76.2885, -101.6061,  -95.1618, -111.8527,  -64.1272,
         -76.5270,  -79.7168,  -56.3355,  -81.7516])
Final projection likelihood: -83.8414
1 mode projection failed, trying anyway
New goal: tensor([ 0.0063,  0.1690,  0.8870,  1.0293, -0.0861,  0.3225,  1.1233,  1.2252,
         1.3469,  0.1459,  0.9232,  0.3572,  0.2853,  0.0853, -0.8770],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0029]], device='cuda:0') tensor([[0.0024]], device='cuda:0')
Original likelihood: -88.43696594238281
Adjusted likelihood: -88.43696594238281
Likelihood residual: 0.0
Original likelihood: -82.72432708740234
Adjusted likelihood: -82.72432708740234
Likelihood residual: 0.0
{'index': 82.72432708740234, 'thumb_middle': 88.43696594238281}
Current yaw: tensor([ 0.2918,  0.0772, -0.6533], device='cuda:0')
17 index
tensor([-0.0124,  0.2391,  0.8994,  1.0736, -0.0874,  0.2623,  0.9858,  1.1748,
         1.3986,  0.0726,  0.9334,  0.4764,  0.2918,  0.0772, -0.6533, -1.1731],
       device='cuda:0')
Solve time for step 1 10.968441864009947
Current ori: tensor([ 0.2918,  0.0772, -0.6533], device='cuda:0')
Middle force: tensor([0.5825, 0.5478, 0.5986, 0.5153], device='cuda:0')
Thumb force: tensor([0.5733, 0.5548, 0.5535, 0.5151], device='cuda:0')
tensor([-0.0247, -0.0593,  0.8536,  0.9957, -0.0744,  0.2757,  0.9685,  1.1657,
         1.3801,  0.1039,  0.9772,  0.3572,  0.2851,  0.0761, -0.6864,  2.3850],
       device='cuda:0')
Solve time for step 2 2.2576733080204576
Current ori: tensor([ 0.2851,  0.0761, -0.6864], device='cuda:0')
Middle force: tensor([0.5455, 0.5940, 0.5142], device='cuda:0')
Thumb force: tensor([0.5520, 0.5522, 0.5140], device='cuda:0')
tensor([-0.0147, -0.0605,  0.8549,  0.9975, -0.0610,  0.2835,  0.9653,  1.1360,
         1.3943,  0.0920,  0.9762,  0.3334,  0.2812,  0.0744, -0.7078,  4.2445],
       device='cuda:0')
Solve time for step 3 2.2073584340396337
Current ori: tensor([ 0.2812,  0.0744, -0.7078], device='cuda:0')
Middle force: tensor([0.5888, 0.5126], device='cuda:0')
Thumb force: tensor([0.5494, 0.5126], device='cuda:0')
tensor([-0.0078, -0.0592,  0.8590,  0.9940, -0.0547,  0.2993,  0.9385,  1.2092,
         1.4026,  0.0847,  0.9750,  0.3135,  0.2761,  0.0740, -0.7117, -6.1437],
       device='cuda:0')
Solve time for step 4 2.0515594690223224
Current ori: tensor([ 0.2761,  0.0740, -0.7117], device='cuda:0')
Middle force: tensor([0.5118], device='cuda:0')
Thumb force: tensor([0.5114], device='cuda:0')
Storing RECOVERY transition: reward=0.0504 (scaled=0.0252), steps=2
Reward stats updated: mean -0.0124 -> -0.0121, std: 0.1579
Collected 122 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=1.0812, Q2 Loss=1.0812, Entropy=0.3212, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8633
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=4.9385, Q2 Loss=4.9385, Entropy=0.2389, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9625
SAC Update 3/5: Actor Loss=-0.0046, Q1 Loss=1.0840, Q2 Loss=1.0840, Entropy=0.3551, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4360
SAC Update 4/5: Actor Loss=-0.0009, Q1 Loss=0.5741, Q2 Loss=0.5741, Entropy=0.1514, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3864
SAC Update 5/5: Actor Loss=-0.0153, Q1 Loss=0.4259, Q2 Loss=0.4259, Entropy=0.2616, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2010

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.4%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.05s (21.0%)
Actor update: 0.09s (40.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005745
Q1 loss: 1.620749
Q2 loss: 1.620749
Current threshold: -30.3543
Global Scale Offset: 2.3806
Reward stats: mean=-0.0121, std=0.1579, count=122
----------------------------------------------
SAC Update - Actor Loss: -0.0057, Q1 Loss: 1.6207, Q2 Loss: 1.6207, Entropy: 0.2656, Mean TD Error: 1.5699, Threshold: -30.3543
Original likelihood: -90.8331298828125
Adjusted likelihood: -90.8331298828125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 98.27711486816406
Projection step: 1, Loss: 103.98452758789062
Projection step: 2, Loss: 98.20414733886719
Projection step: 3, Loss: 95.07901763916016
Projection step: 4, Loss: 104.66526794433594
Projection step: 5, Loss: 97.20820617675781
Projection step: 6, Loss: 98.41464233398438
Projection step: 7, Loss: 88.93635559082031
Projection step: 8, Loss: 95.81151580810547
Projection step: 9, Loss: 95.83599853515625
Projection step: 10, Loss: 104.25198364257812
Projection step: 11, Loss: 91.27215576171875
Projection step: 12, Loss: 87.49568176269531
Projection step: 13, Loss: 91.43659973144531
Projection step: 14, Loss: 99.22639465332031
Final likelihood: tensor([ -87.4916,  -68.6637, -120.7030,  -88.5951,  -81.2208, -106.2915,
        -107.4381, -103.3922,  -67.9690,  -84.3357,  -88.7643, -166.9923,
         -69.5989, -123.9363,  -87.0266,  -74.2149])
Final projection likelihood: -95.4146
1 mode projection failed, trying anyway
New goal: tensor([-0.0287,  0.1162,  0.9468,  1.0171, -0.0520,  0.3383,  1.1603,  1.2199,
         1.3464,  0.1885,  0.9427,  0.2616,  0.3021,  0.0748, -0.6706],
       device='cuda:0')
tensor([[0.0023]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0017]], device='cuda:0')
Original likelihood: -83.74297332763672
Adjusted likelihood: -83.74297332763672
Likelihood residual: 0.0
Original likelihood: -119.23893737792969
Adjusted likelihood: -119.23893737792969
Likelihood residual: 0.0
{'index': 119.23893737792969, 'thumb_middle': 83.74297332763672}
Current yaw: tensor([ 0.3081,  0.0654, -0.6851], device='cuda:0')
18 thumb_middle
tensor([-0.0354,  0.1643,  0.9680,  1.0505, -0.0470,  0.2983,  0.9769,  1.1873,
         1.4032,  0.1305,  0.9720,  0.3363,  0.3081,  0.0654, -0.6851, -5.0221],
       device='cuda:0')
Solve time for step 1 9.209874799009413
Current ori: tensor([ 0.3081,  0.0654, -0.6851], device='cuda:0')
Index force: tensor([0.5574, 0.5199, 0.5223, 0.5504], device='cuda:0')
tensor([-0.0354,  0.1542,  1.0114,  1.0365, -0.1712,  0.0953,  1.0574,  1.1571,
         1.3222,  0.1584,  0.9091,  0.2510,  0.3099,  0.0662, -0.6885, -5.0070],
       device='cuda:0')
Solve time for step 2 1.979968463012483
Current ori: tensor([ 0.3099,  0.0662, -0.6885], device='cuda:0')
Index force: tensor([0.5179, 0.5172, 0.5444], device='cuda:0')
tensor([-0.0300,  0.1203,  1.0528,  1.0553, -0.1456,  0.2102,  1.1134,  1.1713,
         1.3192,  0.1705,  0.9140,  0.2491,  0.3211,  0.0781, -0.7807, -5.1145],
       device='cuda:0')
Solve time for step 3 1.8514616989996284
Current ori: tensor([ 0.3211,  0.0781, -0.7807], device='cuda:0')
Index force: tensor([0.5161, 0.5408], device='cuda:0')
tensor([-0.0403,  0.1180,  1.0674,  1.0417, -0.1503,  0.2325,  1.0893,  1.1557,
         1.3326,  0.1724,  0.9113,  0.2653,  0.3225,  0.0790, -0.7841, -5.1044],
       device='cuda:0')
Solve time for step 4 1.757166182040237
Current ori: tensor([ 0.3225,  0.0790, -0.7841], device='cuda:0')
Index force: tensor([0.5357], device='cuda:0')
Storing RECOVERY transition: reward=0.0871 (scaled=0.0435), steps=2
Reward stats updated: mean -0.0121 -> -0.0116, std: 0.1574
Collected 123 transitions for RL
SAC Update 1/5: Actor Loss=-0.0020, Q1 Loss=32.3667, Q2 Loss=32.3667, Entropy=0.2386, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0506
SAC Update 2/5: Actor Loss=-0.0116, Q1 Loss=0.6292, Q2 Loss=0.6292, Entropy=0.6298, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1721
SAC Update 3/5: Actor Loss=-0.0220, Q1 Loss=1.1348, Q2 Loss=1.1348, Entropy=0.2759, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8090
SAC Update 4/5: Actor Loss=-0.0109, Q1 Loss=1.6199, Q2 Loss=1.6199, Entropy=0.3706, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1461
SAC Update 5/5: Actor Loss=-0.0054, Q1 Loss=1.0963, Q2 Loss=1.0963, Entropy=0.4785, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7151

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (40.4%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.010378
Q1 loss: 7.369377
Q2 loss: 7.369377
Current threshold: -30.3411
Global Scale Offset: 2.3333
Reward stats: mean=-0.0116, std=0.1574, count=123
----------------------------------------------
SAC Update - Actor Loss: -0.0104, Q1 Loss: 7.3694, Q2 Loss: 7.3694, Entropy: 0.3987, Mean TD Error: 1.5786, Threshold: -30.3411
Original likelihood: -117.79182434082031
Adjusted likelihood: -117.79182434082031
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 132.51077270507812
Projection step: 1, Loss: 134.89682006835938
Projection step: 2, Loss: 130.44168090820312
Projection step: 3, Loss: 126.17057800292969
Projection step: 4, Loss: 118.61515808105469
Projection step: 5, Loss: 123.63984680175781
Projection step: 6, Loss: 123.865966796875
Projection step: 7, Loss: 136.9986572265625
Projection step: 8, Loss: 119.1837387084961
Projection step: 9, Loss: 129.01910400390625
Projection step: 10, Loss: 126.61884307861328
Projection step: 11, Loss: 130.66578674316406
Projection step: 12, Loss: 123.52294921875
Projection step: 13, Loss: 127.5507583618164
Projection step: 14, Loss: 104.54121398925781
Final likelihood: tensor([-145.4359,  -98.3314, -129.7607, -118.4701, -138.7618, -119.5479,
        -133.6178, -136.8819, -178.4006,  -75.3962, -140.4579, -101.8165,
        -123.4975, -106.8976,  -78.4839, -134.2373])
Final projection likelihood: -122.4997
1 mode projection failed, trying anyway
New goal: tensor([-0.0757,  0.0864,  1.0632,  1.0239, -0.1288,  0.2849,  1.2611,  1.1716,
         1.3263,  0.2469,  0.9667,  0.2813,  0.3177,  0.0817, -0.4925],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0003]], device='cuda:0') tensor([[0.0023]], device='cuda:0')
Original likelihood: -124.77194213867188
Adjusted likelihood: -124.77194213867188
Likelihood residual: 0.0
Original likelihood: -128.3272247314453
Adjusted likelihood: -128.3272247314453
Likelihood residual: 0.0
{'index': 128.3272247314453, 'thumb_middle': 124.77194213867188}
Current yaw: tensor([ 0.3223,  0.0745, -0.7524], device='cuda:0')
19 thumb_middle
tensor([-0.0501,  0.1128,  1.0564,  1.0278, -0.1266,  0.2696,  1.0739,  1.1494,
         1.3929,  0.2054,  0.9974,  0.2825,  0.3223,  0.0745, -0.7524, -5.3085],
       device='cuda:0')
Solve time for step 1 8.994021230028011
Current ori: tensor([ 0.3223,  0.0745, -0.7524], device='cuda:0')
Index force: tensor([0.5731, 0.5352, 0.5244, 0.5906], device='cuda:0')
tensor([-0.0496,  0.1332,  1.0283,  1.2121, -0.1459, -0.0241,  1.1393,  1.0958,
         1.2998,  0.2111,  0.9387,  0.2621,  0.3360,  0.1039, -0.8579, -5.6933],
       device='cuda:0')
Solve time for step 2 1.929688566015102
Current ori: tensor([ 0.3360,  0.1039, -0.8579], device='cuda:0')
Index force: tensor([0.5330, 0.5209, 0.5855], device='cuda:0')
tensor([-0.0592,  0.1427,  1.0657,  1.2129, -0.1755, -0.0264,  1.1466,  1.0978,
         1.3168,  0.2287,  0.9507,  0.2711,  0.3580,  0.1246, -0.8643, -5.8727],
       device='cuda:0')
Solve time for step 3 1.8516360489884391
Current ori: tensor([ 0.3580,  0.1246, -0.8643], device='cuda:0')
Index force: tensor([0.5195, 0.5796], device='cuda:0')
tensor([-0.0772,  0.1871,  1.1432,  1.1199, -0.1913, -0.0301,  1.1616,  1.1209,
         1.3167,  0.2431,  0.9496,  0.2720,  0.3484,  0.1240, -0.8802, -6.0048],
       device='cuda:0')
Solve time for step 4 1.765803368005436
Current ori: tensor([ 0.3484,  0.1240, -0.8802], device='cuda:0')
Index force: tensor([0.5439], device='cuda:0')
Storing RECOVERY transition: reward=0.1131 (scaled=0.0565), steps=2
Reward stats updated: mean -0.0116 -> -0.0111, std: 0.1569
Collected 124 transitions for RL
SAC Update 1/5: Actor Loss=-0.0037, Q1 Loss=0.4899, Q2 Loss=0.4899, Entropy=0.6167, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4128
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=0.5680, Q2 Loss=0.5680, Entropy=0.3675, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3091
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.8274, Q2 Loss=0.8274, Entropy=0.0067, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2984
SAC Update 4/5: Actor Loss=-0.0068, Q1 Loss=2.7583, Q2 Loss=2.7583, Entropy=0.5798, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9175
SAC Update 5/5: Actor Loss=-0.0037, Q1 Loss=0.5205, Q2 Loss=0.5205, Entropy=0.3719, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5441

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (18.9%)
Actor update: 0.10s (39.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003273
Q1 loss: 1.032812
Q2 loss: 1.032812
Current threshold: -30.3301
Global Scale Offset: 2.3112
Reward stats: mean=-0.0111, std=0.1569, count=124
----------------------------------------------
SAC Update - Actor Loss: -0.0033, Q1 Loss: 1.0328, Q2 Loss: 1.0328, Entropy: 0.3885, Mean TD Error: 1.2964, Threshold: -30.3301
Original likelihood: -203.01370239257812
Adjusted likelihood: -203.01370239257812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 194.1336669921875
Projection step: 1, Loss: 206.79000854492188
Projection step: 2, Loss: 196.1195526123047
Projection step: 3, Loss: 202.693603515625
Projection step: 4, Loss: 183.95751953125
Projection step: 5, Loss: 199.36563110351562
Projection step: 6, Loss: 200.19964599609375
Projection step: 7, Loss: 183.35797119140625
Projection step: 8, Loss: 199.54701232910156
Projection step: 9, Loss: 222.3443603515625
Projection step: 10, Loss: 205.78558349609375
Projection step: 11, Loss: 206.31288146972656
Projection step: 12, Loss: 207.8224334716797
Projection step: 13, Loss: 200.1529083251953
Projection step: 14, Loss: 197.9678497314453
Final likelihood: tensor([-179.7190, -228.9034, -227.5756, -188.4241, -185.4113, -214.0910,
        -147.8715, -249.6256, -158.9624, -168.6294, -197.9083, -161.8648,
        -182.3288, -163.1945, -187.0749, -202.1644])
Final projection likelihood: -190.2343
1 mode projection failed, trying anyway
New goal: tensor([-0.1266,  0.1898,  1.1562,  1.1272, -0.1838, -0.0046,  1.2305,  1.1788,
         1.3116,  0.2950,  1.0389,  0.4059,  0.3458,  0.1267, -0.6134],
       device='cuda:0')
tensor([[0.0023]], device='cuda:0') tensor([[-1.8902e-05]], device='cuda:0') tensor([[0.0015]], device='cuda:0')
Original likelihood: -194.49624633789062
Adjusted likelihood: -194.49624633789062
Likelihood residual: 0.0
Original likelihood: -199.899169921875
Adjusted likelihood: -199.899169921875
Likelihood residual: 0.0
{'index': 199.899169921875, 'thumb_middle': 194.49624633789062}
Current yaw: tensor([ 0.3451,  0.1246, -0.8498], device='cuda:0')
20 thumb_middle
tensor([-0.1011,  0.1913,  1.1466,  1.0965, -0.1815, -0.0113,  1.1312,  1.1462,
         1.3868,  0.2787,  1.0356,  0.3171,  0.3451,  0.1246, -0.8498, -6.0582],
       device='cuda:0')
Solve time for step 1 9.163964191975538
Current ori: tensor([ 0.3451,  0.1246, -0.8498], device='cuda:0')
Index force: tensor([0.5907, 0.6003, 0.5793, 0.5904], device='cuda:0')
tensor([-0.1654,  0.2623,  1.0784,  1.2065, -0.1561, -0.1960,  0.9724,  1.0118,
         1.2784,  0.2613,  0.9855,  0.3570,  0.4145,  0.2060, -0.9316,  6.2648],
       device='cuda:0')
Solve time for step 2 1.9491347819566727
Current ori: tensor([ 0.4145,  0.2060, -0.9316], device='cuda:0')
Index force: tensor([0.5944, 0.5744, 0.5864], device='cuda:0')
tensor([-0.2360,  0.2774,  1.0847,  1.1749, -0.1650, -0.1960,  0.9566,  0.9944,
         1.2988,  0.2949,  0.9821,  0.3782,  0.4149,  0.2062, -0.9282, -6.1605],
       device='cuda:0')
Solve time for step 3 1.7942651110352017
Current ori: tensor([ 0.4149,  0.2062, -0.9282], device='cuda:0')
Index force: tensor([0.5808, 0.5872], device='cuda:0')
tensor([-0.2954,  0.2877,  1.0868,  1.1542, -0.1361, -0.1960,  0.9650,  0.9969,
         1.3210,  0.3178,  0.9841,  0.3915,  0.4143,  0.2065, -0.9329, -6.0969],
       device='cuda:0')
Solve time for step 4 1.7180267869844101
Current ori: tensor([ 0.4143,  0.2065, -0.9329], device='cuda:0')
Index force: tensor([0.5762], device='cuda:0')
Storing RECOVERY transition: reward=0.0510 (scaled=0.0255), steps=2
Reward stats updated: mean -0.0111 -> -0.0108, std: 0.1563
Collected 125 transitions for RL
SAC Update 1/5: Actor Loss=-0.0009, Q1 Loss=0.5876, Q2 Loss=0.5876, Entropy=0.1440, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3909
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=0.9065, Q2 Loss=0.9065, Entropy=0.2548, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5627
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.7266, Q2 Loss=0.7266, Entropy=0.2329, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4427
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.6346, Q2 Loss=0.6346, Entropy=0.3377, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1140
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=4.5075, Q2 Loss=4.5075, Entropy=0.2337, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0159

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.0%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (38.5%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001342
Q1 loss: 1.472580
Q2 loss: 1.472580
Current threshold: -30.3271
Global Scale Offset: 2.3295
Reward stats: mean=-0.0108, std=0.1563, count=125
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 1.4726, Q2 Loss: 1.4726, Entropy: 0.2406, Mean TD Error: 1.3053, Threshold: -30.3271
Original likelihood: -341.8682861328125
Adjusted likelihood: -341.8682861328125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 7
Loaded trajectory sampler
Current yaw: tensor([ 0.0006,  0.0140, -0.0470], device='cuda:0')
Current yaw: tensor([ 0.0006,  0.0140, -0.0470], device='cuda:0')
1 turn
Sampling time 3.6863558450131677
tensor([ 1.3770e-01,  6.1973e-01,  5.6278e-01,  5.6608e-01, -9.0984e-02,
         4.6614e-01,  9.5832e-01,  9.1234e-01,  1.2281e+00,  3.1708e-01,
         2.1708e-01,  1.2261e+00,  6.4031e-04,  1.4024e-02, -4.7042e-02,
         2.3351e-01], device='cuda:0')
Original likelihood: -17.44002914428711
Adjusted likelihood: -17.44002914428711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9999)
Solve time for step 1 14.319443130982108
Current ori: tensor([ 0.0006,  0.0140, -0.0470], device='cuda:0')
Middle force: tensor([2.6237, 0.5032, 0.5395, 0.5143, 0.5146, 0.5873, 0.5031, 0.5422, 0.8748,
        0.5800, 0.5679, 0.5622], device='cuda:0')
Thumb force: tensor([2.5565, 0.6284, 0.6027, 0.7909, 0.5622, 0.9399, 0.7839, 1.0922, 0.6721,
        0.5071, 0.5958, 0.5710], device='cuda:0')
Index force: tensor([0.5456, 0.7757, 0.6238, 0.8033, 0.6086, 0.5745, 0.5069, 0.5381, 0.5556,
        0.5883, 0.5993, 0.5922], device='cuda:0')
Storing NORMAL transition: reward=0.1869 (scaled=0.1869), steps=1
Reward stats updated: mean -0.0108 -> -0.0092, std: 0.1566
Collected 126 transitions for RL
SAC Update 1/5: Actor Loss=-0.0024, Q1 Loss=0.6254, Q2 Loss=0.6254, Entropy=0.3803, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3043
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.8378, Q2 Loss=0.8378, Entropy=0.0510, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7228
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.6974, Q2 Loss=0.6974, Entropy=0.1470, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9049
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.7337, Q2 Loss=0.7337, Entropy=0.1171, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5621
SAC Update 5/5: Actor Loss=-0.0013, Q1 Loss=6.9586, Q2 Loss=6.9586, Entropy=0.3838, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1679

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.2%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.5%)
Actor update: 0.08s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001002
Q1 loss: 1.970591
Q2 loss: 1.970591
Current threshold: -30.3272
Global Scale Offset: 2.3707
Reward stats: mean=-0.0092, std=0.1566, count=126
----------------------------------------------
SAC Update - Actor Loss: -0.0010, Q1 Loss: 1.9706, Q2 Loss: 1.9706, Entropy: 0.2158, Mean TD Error: 1.5324, Threshold: -30.3272
tensor([ 0.0354,  0.5358,  0.6235,  0.4780, -0.1454,  0.3464,  1.0311,  1.0614,
         1.3892,  0.1437,  0.2095,  1.1339,  0.0198,  0.0370, -0.2363,  1.0642],
       device='cuda:0')
Original likelihood: -26.971349716186523
Adjusted likelihood: -26.971349716186523
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.8359)
State is out of distribution
Projection step: 0, Loss: 24.884845733642578
Projection step: 1, Loss: 22.874454498291016
Projection step: 2, Loss: 21.10980224609375
Projection step: 3, Loss: 18.112323760986328
Projection step: 4, Loss: 15.936628341674805
Projection step: 5, Loss: 13.128091812133789
Final likelihood: tensor([-13.6102, -11.5020, -11.5845, -15.3711, -14.4192, -13.6096, -11.3157,
        -11.2065, -13.3402, -12.7424, -13.3759, -12.1596, -12.0723, -12.7618,
        -17.2585, -13.7200])
Final projection likelihood: -13.1281
1 mode projection succeeded
New goal: tensor([ 0.0312,  0.5695,  0.5595,  0.5817, -0.1022,  0.3989,  0.9663,  0.8739,
         1.3530,  0.1780,  0.2004,  1.1425,  0.0208,  0.0261,  0.2712],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0026]], device='cuda:0')
Original likelihood: -18.116008758544922
Adjusted likelihood: -18.116008758544922
Likelihood residual: 0.0
Original likelihood: -19.747940063476562
Adjusted likelihood: -19.747940063476562
Likelihood residual: 0.0
{'index': 19.747940063476562, 'thumb_middle': 18.116008758544922}
Current yaw: tensor([ 0.0198,  0.0370, -0.2363], device='cuda:0')
2 thumb_middle
tensor([ 0.0354,  0.5358,  0.6235,  0.4780, -0.1454,  0.3464,  1.0311,  1.0614,
         1.3892,  0.1437,  0.2095,  1.1339,  0.0198,  0.0370, -0.2363,  1.0642],
       device='cuda:0')
Solve time for step 1 8.851328876975458
Current ori: tensor([ 0.0198,  0.0370, -0.2363], device='cuda:0')
Index force: tensor([0.5340, 0.5004, 0.5874, 0.5966], device='cuda:0')
tensor([ 0.0301,  0.5617,  0.5412,  0.5580, -0.2304,  0.3742,  0.9451,  0.9038,
         1.3240,  0.1472,  0.1481,  1.1201,  0.0204,  0.0407, -0.2363,  1.0706],
       device='cuda:0')
Solve time for step 2 1.9151192730059847
Current ori: tensor([ 0.0204,  0.0407, -0.2363], device='cuda:0')
Index force: tensor([0.5004, 0.5840, 0.5935], device='cuda:0')
tensor([ 0.0305,  0.5640,  0.5363,  0.5622, -0.2252,  0.3957,  0.9359,  0.8635,
         1.3329,  0.1516,  0.1283,  1.1294,  0.0202,  0.0405, -0.2363,  1.0717],
       device='cuda:0')
Solve time for step 3 1.9086953499936499
Current ori: tensor([ 0.0202,  0.0405, -0.2363], device='cuda:0')
Index force: tensor([0.5798, 0.5910], device='cuda:0')
tensor([ 0.0462,  0.5585,  0.5494,  0.5807, -0.2179,  0.3986,  0.9609,  0.8605,
         1.3387,  0.1438,  0.1132,  1.1117,  0.0227,  0.0326, -0.2363,  1.0978],
       device='cuda:0')
Solve time for step 4 1.879214147978928
Current ori: tensor([ 0.0227,  0.0326, -0.2363], device='cuda:0')
Index force: tensor([0.5825], device='cuda:0')
Storing RECOVERY transition: reward=-0.0109 (scaled=-0.0109), steps=1
Reward stats updated: mean -0.0092 -> -0.0092, std: 0.1560
Collected 127 transitions for RL
SAC Update 1/5: Actor Loss=-0.0039, Q1 Loss=3.7775, Q2 Loss=3.7775, Entropy=0.5460, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=4.9957
SAC Update 2/5: Actor Loss=-0.0020, Q1 Loss=0.8985, Q2 Loss=0.8985, Entropy=0.3310, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8325
SAC Update 3/5: Actor Loss=-0.0051, Q1 Loss=1.2844, Q2 Loss=1.2844, Entropy=0.4275, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8912
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=0.6223, Q2 Loss=0.6223, Entropy=0.2105, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3118
SAC Update 5/5: Actor Loss=-0.0007, Q1 Loss=0.7843, Q2 Loss=0.7843, Entropy=0.1526, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4118

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.1%)
Q1 update: 0.04s (19.8%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (40.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002586
Q1 loss: 1.473380
Q2 loss: 1.473380
Current threshold: -30.3317
Global Scale Offset: 2.4287
Reward stats: mean=-0.0092, std=0.1560, count=127
----------------------------------------------
SAC Update - Actor Loss: -0.0026, Q1 Loss: 1.4734, Q2 Loss: 1.4734, Entropy: 0.3335, Mean TD Error: 1.4886, Threshold: -30.3317
Original likelihood: -18.525678634643555
Adjusted likelihood: -18.525678634643555
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9996)
Current yaw: tensor([ 0.0265,  0.0350, -0.2256], device='cuda:0')
3 turn
Sampling time 3.694078836007975
tensor([ 0.0398,  0.5483,  0.5507,  0.5941, -0.1447,  0.4510,  0.9714,  0.8717,
         1.3985,  0.1797,  0.1664,  1.1502,  0.0265,  0.0350, -0.2256,  1.0953],
       device='cuda:0')
Original likelihood: -19.532604217529297
Adjusted likelihood: -19.532604217529297
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9990)
Solve time for step 1 14.756473452027421
Current ori: tensor([ 0.0265,  0.0350, -0.2256], device='cuda:0')
Middle force: tensor([0.5285, 0.4978, 1.2177, 1.3195, 0.6388, 0.5345, 0.5243, 0.5802, 0.5941,
        0.5600, 0.5888, 0.5665], device='cuda:0')
Thumb force: tensor([0.7135, 0.5392, 1.1873, 1.0052, 0.5818, 0.8037, 0.5421, 0.6183, 0.6027,
        0.9365, 0.6139, 0.7059], device='cuda:0')
Index force: tensor([0.5208, 0.6753, 0.5962, 0.5204, 0.9019, 0.5244, 0.5643, 0.5954, 0.6027,
        0.5889, 0.5907, 0.5243], device='cuda:0')
Storing NORMAL transition: reward=0.0634 (scaled=0.0634), steps=1
Reward stats updated: mean -0.0092 -> -0.0086, std: 0.1555
Collected 128 transitions for RL
SAC Update 1/5: Actor Loss=-0.0062, Q1 Loss=0.4486, Q2 Loss=0.4486, Entropy=0.5528, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0474
SAC Update 2/5: Actor Loss=-0.0021, Q1 Loss=31.0134, Q2 Loss=31.0134, Entropy=0.2449, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1744
SAC Update 3/5: Actor Loss=-0.0040, Q1 Loss=0.6527, Q2 Loss=0.6527, Entropy=0.3172, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3770
SAC Update 4/5: Actor Loss=-0.0047, Q1 Loss=1.6766, Q2 Loss=1.6766, Entropy=0.3612, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4363
SAC Update 5/5: Actor Loss=-0.0053, Q1 Loss=8.1981, Q2 Loss=8.1981, Entropy=0.5754, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3375

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.2%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.5%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004454
Q1 loss: 8.397876
Q2 loss: 8.397876
Current threshold: -30.3432
Global Scale Offset: 2.4961
Reward stats: mean=-0.0086, std=0.1555, count=128
----------------------------------------------
SAC Update - Actor Loss: -0.0045, Q1 Loss: 8.3979, Q2 Loss: 8.3979, Entropy: 0.4103, Mean TD Error: 2.4745, Threshold: -30.3432
tensor([ 0.0408,  0.5416,  0.5689,  0.5783, -0.1514,  0.4584,  0.9247,  0.9675,
         1.4949,  0.0424,  0.1232,  1.1180,  0.0262,  0.0360, -0.2893,  1.1443],
       device='cuda:0')
Original likelihood: -22.533397674560547
Adjusted likelihood: -22.533397674560547
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9857)
Solve time for step 2 3.016181871003937
Current ori: tensor([ 0.0262,  0.0360, -0.2893], device='cuda:0')
Middle force: tensor([0.5004, 1.1891, 1.3001, 0.6212, 0.5323, 0.5220, 0.5745, 0.5912, 0.5570,
        0.5852, 0.5641], device='cuda:0')
Thumb force: tensor([0.5359, 1.1783, 0.9843, 0.5841, 0.7911, 0.5414, 0.6175, 0.5987, 0.9238,
        0.6070, 0.7000], device='cuda:0')
Index force: tensor([0.6648, 0.5926, 0.5186, 0.8910, 0.5234, 0.5628, 0.5919, 0.5986, 0.5855,
        0.5878, 0.5225], device='cuda:0')
Storing NORMAL transition: reward=-0.0169 (scaled=-0.0169), steps=1
Reward stats updated: mean -0.0086 -> -0.0087, std: 0.1549
Collected 129 transitions for RL
SAC Update 1/5: Actor Loss=-0.0001, Q1 Loss=0.5403, Q2 Loss=0.5403, Entropy=0.0212, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6791
SAC Update 2/5: Actor Loss=-0.0010, Q1 Loss=0.6083, Q2 Loss=0.6083, Entropy=0.1607, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4913
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7641, Q2 Loss=0.7641, Entropy=0.0392, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4711
SAC Update 4/5: Actor Loss=-0.0051, Q1 Loss=1.2751, Q2 Loss=1.2751, Entropy=0.3961, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9859
SAC Update 5/5: Actor Loss=-0.0029, Q1 Loss=1.0848, Q2 Loss=1.0848, Entropy=0.3930, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6558

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.4%)
Q1 update: 0.04s (18.9%)
Q2 update: 0.04s (18.7%)
Actor update: 0.09s (42.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001829
Q1 loss: 0.854516
Q2 loss: 0.854516
Current threshold: -30.3555
Global Scale Offset: 2.5677
Reward stats: mean=-0.0087, std=0.1549, count=129
----------------------------------------------
SAC Update - Actor Loss: -0.0018, Q1 Loss: 0.8545, Q2 Loss: 0.8545, Entropy: 0.2020, Mean TD Error: 0.6567, Threshold: -30.3555
tensor([ 1.3631e-01,  5.5122e-01,  5.4118e-01,  4.1363e-01, -9.8883e-02,
         5.2378e-01,  8.7883e-01,  9.8074e-01,  1.3257e+00,  1.7854e-01,
         1.6058e-01,  1.0803e+00,  1.9016e-02, -2.1471e-04, -2.7064e-01,
         1.5798e+00], device='cuda:0')
Original likelihood: -23.55902099609375
Adjusted likelihood: -23.55902099609375
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9688)
Solve time for step 3 2.6780164390220307
Current ori: tensor([ 1.9016e-02, -2.1471e-04, -2.7064e-01], device='cuda:0')
Middle force: tensor([1.1667, 1.2805, 0.6105, 0.5294, 0.5206, 0.5710, 0.5885, 0.5531, 0.5816,
        0.5622], device='cuda:0')
Thumb force: tensor([1.1403, 0.9663, 0.5802, 0.7795, 0.5394, 0.6134, 0.5952, 0.9155, 0.6000,
        0.6935], device='cuda:0')
Index force: tensor([0.5840, 0.5170, 0.8847, 0.5233, 0.5621, 0.5905, 0.5951, 0.5827, 0.5877,
        0.5212], device='cuda:0')
Storing NORMAL transition: reward=0.1027 (scaled=0.1027), steps=1
Reward stats updated: mean -0.0087 -> -0.0079, std: 0.1546
Collected 130 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=1.8606, Q2 Loss=1.8606, Entropy=0.1057, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3689
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=10.4607, Q2 Loss=10.4607, Entropy=0.2505, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6033
SAC Update 3/5: Actor Loss=-0.0000, Q1 Loss=0.7507, Q2 Loss=0.7507, Entropy=0.0034, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3889
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.9302, Q2 Loss=0.9302, Entropy=0.2626, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2549
SAC Update 5/5: Actor Loss=-0.0090, Q1 Loss=0.5380, Q2 Loss=0.5380, Entropy=0.5103, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2513

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (16.4%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.05s (21.1%)
Actor update: 0.09s (40.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002126
Q1 loss: 2.908054
Q2 loss: 2.908054
Current threshold: -30.3663
Global Scale Offset: 2.6397
Reward stats: mean=-0.0079, std=0.1546, count=130
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 2.9081, Q2 Loss: 2.9081, Entropy: 0.2265, Mean TD Error: 1.7735, Threshold: -30.3663
tensor([ 0.1036,  0.6663,  0.5150,  0.4459, -0.0650,  0.4929,  0.9424,  1.0212,
         1.2514,  0.2568,  0.2669,  0.9272,  0.0262, -0.0273, -0.3748,  1.7368],
       device='cuda:0')
Original likelihood: -23.533550262451172
Adjusted likelihood: -23.533550262451172
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9666)
Solve time for step 4 2.66267843300011
Current ori: tensor([ 0.0262, -0.0273, -0.3748], device='cuda:0')
Middle force: tensor([1.2479, 0.6403, 0.5267, 0.5221, 0.5743, 0.5874, 0.5527, 0.5820, 0.5609],
       device='cuda:0')
Thumb force: tensor([0.9415, 0.5491, 0.7711, 0.5352, 0.6034, 0.5914, 0.9023, 0.5917, 0.6873],
       device='cuda:0')
Index force: tensor([0.5165, 0.8849, 0.5235, 0.5594, 0.5877, 0.5919, 0.5797, 0.5856, 0.5201],
       device='cuda:0')
Storing NORMAL transition: reward=-0.0100 (scaled=-0.0100), steps=1
Reward stats updated: mean -0.0079 -> -0.0079, std: 0.1541
Collected 131 transitions for RL
SAC Update 1/5: Actor Loss=-0.0025, Q1 Loss=7.1122, Q2 Loss=7.1122, Entropy=0.4857, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3171
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.6031, Q2 Loss=0.6031, Entropy=0.0778, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2887
SAC Update 3/5: Actor Loss=-0.0013, Q1 Loss=2.7622, Q2 Loss=2.7622, Entropy=0.4250, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0649
SAC Update 4/5: Actor Loss=-0.0023, Q1 Loss=0.6519, Q2 Loss=0.6519, Entropy=0.2994, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5052
SAC Update 5/5: Actor Loss=-0.0003, Q1 Loss=0.9785, Q2 Loss=0.9785, Entropy=0.0687, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4777

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (19.6%)
Actor update: 0.11s (41.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001290
Q1 loss: 2.421582
Q2 loss: 2.421582
Current threshold: -30.3762
Global Scale Offset: 2.7099
Reward stats: mean=-0.0079, std=0.1541, count=131
----------------------------------------------
SAC Update - Actor Loss: -0.0013, Q1 Loss: 2.4216, Q2 Loss: 2.4216, Entropy: 0.2713, Mean TD Error: 2.3307, Threshold: -30.3762
tensor([ 0.0370,  0.5927,  0.4886,  0.5206,  0.0727,  0.3696,  0.9731,  1.0339,
         1.3141,  0.0791,  0.2386,  0.9678,  0.0677, -0.0808, -0.3776,  0.1909],
       device='cuda:0')
Original likelihood: -37.10858154296875
Adjusted likelihood: -37.10858154296875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0383)
State is out of distribution
Projection step: 0, Loss: 35.52816390991211
Projection step: 1, Loss: 34.58066940307617
Projection step: 2, Loss: 33.812538146972656
Projection step: 3, Loss: 33.508636474609375
Projection step: 4, Loss: 31.853981018066406
Projection step: 5, Loss: 30.125164031982422
Projection step: 6, Loss: 29.344398498535156
Projection step: 7, Loss: 28.46505355834961
Projection step: 8, Loss: 27.99582290649414
Projection step: 9, Loss: 27.56509780883789
Projection step: 10, Loss: 26.53607177734375
Projection step: 11, Loss: 26.297664642333984
Projection step: 12, Loss: 26.062606811523438
Projection step: 13, Loss: 25.31444549560547
Projection step: 14, Loss: 24.67184829711914
Final likelihood: tensor([-25.3652, -21.7955, -29.9044, -29.3664, -22.2326, -22.5822, -21.7987,
        -22.8955, -21.7286, -22.1052, -21.7674, -29.1531, -29.2074, -21.8560,
        -21.8047, -27.4295])
Final projection likelihood: -24.4370
1 mode projection succeeded
New goal: tensor([ 0.0672,  0.4885,  0.6081,  0.6499,  0.0433,  0.5180,  0.9109,  0.8509,
         1.4320,  0.0611,  0.2795,  1.0777,  0.0605, -0.0621, -0.0113],
       device='cuda:0')
tensor([[0.0035]], device='cuda:0') tensor([[0.0080]], device='cuda:0') tensor([[0.0050]], device='cuda:0')
Original likelihood: -32.57246398925781
Adjusted likelihood: -32.57246398925781
Likelihood residual: 0.0
Original likelihood: -34.559600830078125
Adjusted likelihood: -34.559600830078125
Likelihood residual: 0.0
{'index': 34.559600830078125, 'thumb_middle': 32.57246398925781}
Current yaw: tensor([ 0.0677, -0.0808, -0.3776], device='cuda:0')
4 thumb_middle
tensor([ 0.0370,  0.5927,  0.4886,  0.5206,  0.0727,  0.3696,  0.9731,  1.0339,
         1.3141,  0.0791,  0.2386,  0.9678,  0.0677, -0.0808, -0.3776,  0.1909],
       device='cuda:0')
Solve time for step 1 9.26948022498982
Current ori: tensor([ 0.0677, -0.0808, -0.3776], device='cuda:0')
Index force: tensor([0.6035, 0.5016, 0.5557, 0.5884], device='cuda:0')
tensor([-0.0238,  0.5360,  0.6613,  0.6500, -0.0218,  0.4874,  0.8771,  0.8650,
         1.3305,  0.0307,  0.1467,  1.0086,  0.1705, -0.2039, -0.3776, -1.2850],
       device='cuda:0')
Solve time for step 2 1.9780281470157206
Current ori: tensor([ 0.1705, -0.2039, -0.3776], device='cuda:0')
Index force: tensor([0.5014, 0.5509, 0.5808], device='cuda:0')
tensor([-0.0696,  0.6524,  0.6808,  0.7002,  0.0206,  0.5652,  0.9205,  0.8628,
         1.3467,  0.0204,  0.1177,  0.9962,  0.2766, -0.3040, -0.4531, -2.3631],
       device='cuda:0')
Solve time for step 3 1.8807102229911834
Current ori: tensor([ 0.2766, -0.3040, -0.4531], device='cuda:0')
Index force: tensor([0.5002, 0.5010], device='cuda:0')
tensor([-0.0497,  0.6890,  0.9955,  0.8880,  0.0719,  0.6131,  0.9799,  0.8799,
         1.3453,  0.0203,  0.1088,  1.0082,  0.3359, -0.3003, -0.6293, -1.6885],
       device='cuda:0')
Solve time for step 4 1.7817530760075897
Current ori: tensor([ 0.3359, -0.3003, -0.6293], device='cuda:0')
Index force: tensor([0.5012], device='cuda:0')
Storing RECOVERY transition: reward=-0.0863 (scaled=-0.0216), steps=4
Reward stats updated: mean -0.0079 -> -0.0080, std: 0.1535
Collected 132 transitions for RL
SAC Update 1/5: Actor Loss=-0.0069, Q1 Loss=1.0393, Q2 Loss=1.0393, Entropy=0.6230, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7387
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.5768, Q2 Loss=0.5768, Entropy=0.1456, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2896
SAC Update 3/5: Actor Loss=-0.0080, Q1 Loss=1.1832, Q2 Loss=1.1832, Entropy=0.3665, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9352
SAC Update 4/5: Actor Loss=-0.0199, Q1 Loss=7.1423, Q2 Loss=7.1423, Entropy=0.4650, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3527
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.7413, Q2 Loss=0.7413, Entropy=0.2192, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3529

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.0%)
Q1 update: 0.04s (18.8%)
Q2 update: 0.04s (18.2%)
Actor update: 0.08s (39.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.007204
Q1 loss: 2.136584
Q2 loss: 2.136584
Current threshold: -30.3682
Global Scale Offset: 2.7563
Reward stats: mean=-0.0080, std=0.1535, count=132
----------------------------------------------
SAC Update - Actor Loss: -0.0072, Q1 Loss: 2.1366, Q2 Loss: 2.1366, Entropy: 0.3638, Mean TD Error: 1.5338, Threshold: -30.3682
Original likelihood: -228.91506958007812
Adjusted likelihood: -228.91506958007812
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 209.74911499023438
Projection step: 1, Loss: 193.35635375976562
Projection step: 2, Loss: 209.57034301757812
Projection step: 3, Loss: 205.75778198242188
Projection step: 4, Loss: 225.0852813720703
Projection step: 5, Loss: 206.81423950195312
Projection step: 6, Loss: 222.5945587158203
Projection step: 7, Loss: 222.40994262695312
Projection step: 8, Loss: 199.71324157714844
Projection step: 9, Loss: 206.72679138183594
Projection step: 10, Loss: 200.38589477539062
Projection step: 11, Loss: 228.76382446289062
Projection step: 12, Loss: 233.23828125
Projection step: 13, Loss: 199.61874389648438
Projection step: 14, Loss: 211.50698852539062
Final likelihood: tensor([-165.7368, -188.0850, -171.7943, -224.7498, -157.4012, -258.9571,
        -183.9584, -307.1259, -173.2262, -242.7402, -288.6381, -159.1546,
        -250.0779, -273.5037, -209.2412, -230.5208])
Final projection likelihood: -217.8069
1 mode projection failed, trying anyway
New goal: tensor([ 0.0325,  0.7857,  0.9965,  0.8915,  0.1210,  0.7043,  0.9922,  0.9456,
         1.3212,  0.0378,  0.1328,  1.1030,  0.3586, -0.2899, -0.5587],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[0.0291]], device='cuda:0') tensor([[0.0045]], device='cuda:0')
Original likelihood: -179.10317993164062
Adjusted likelihood: -179.10317993164062
Likelihood residual: 0.0
Original likelihood: -174.12355041503906
Adjusted likelihood: -174.12355041503906
Likelihood residual: 0.0
{'index': 174.12355041503906, 'thumb_middle': 179.10317993164062}
Current yaw: tensor([ 0.3586, -0.2881, -0.6408], device='cuda:0')
5 index
tensor([-0.0061,  0.7955,  0.9948,  0.8950,  0.1302,  0.7141,  0.9894,  0.8766,
         1.3566,  0.0040,  0.1313,  1.0913,  0.3586, -0.2881, -0.6408, -0.7710],
       device='cuda:0')
Solve time for step 1 10.91523473901907
Current ori: tensor([ 0.3586, -0.2881, -0.6408], device='cuda:0')
Middle force: tensor([0.5246, 0.5163, 0.5180, 0.5285], device='cuda:0')
Thumb force: tensor([0.5080, 0.5163, 0.5172, 0.5186], device='cuda:0')
tensor([-0.1150,  0.5158,  1.0838,  0.9242, -0.1971,  0.7446,  0.9969,  0.9283,
         1.3919, -0.1027,  0.2985,  1.3445,  0.3543, -0.2465, -0.8203, -0.8692],
       device='cuda:0')
Solve time for step 2 2.1259512610267848
Current ori: tensor([ 0.3543, -0.2465, -0.8203], device='cuda:0')
Middle force: tensor([0.5011, 0.5118, 0.5559], device='cuda:0')
Thumb force: tensor([0.5324, 0.5254, 0.5151], device='cuda:0')
tensor([-0.1138,  0.5219,  1.1200,  0.9424, -0.2529,  0.9670,  1.1924,  1.0337,
         1.4189, -0.1050,  0.2296,  1.4071,  0.3522, -0.2421, -0.8593, -1.2585],
       device='cuda:0')
Solve time for step 3 2.3023672780254856
Current ori: tensor([ 0.3522, -0.2421, -0.8593], device='cuda:0')
Middle force: tensor([0.5118, 0.5615], device='cuda:0')
Thumb force: tensor([0.5252, 0.5137], device='cuda:0')
tensor([ 0.0117,  0.6382,  1.1149,  0.9301, -0.1967,  0.9953,  1.1723,  0.9880,
         1.3352,  0.0058,  0.1269,  1.5070,  0.3606, -0.2976, -0.6228, -1.3084],
       device='cuda:0')
Solve time for step 4 2.1423195700044744
Current ori: tensor([ 0.3606, -0.2976, -0.6228], device='cuda:0')
Middle force: tensor([0.5591], device='cuda:0')
Thumb force: tensor([0.5132], device='cuda:0')
Storing RECOVERY transition: reward=-0.1160 (scaled=-0.0290), steps=4
Reward stats updated: mean -0.0080 -> -0.0081, std: 0.1529
Collected 133 transitions for RL
SAC Update 1/5: Actor Loss=-0.0017, Q1 Loss=0.9188, Q2 Loss=0.9188, Entropy=0.2265, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3902
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=3.8606, Q2 Loss=3.8606, Entropy=0.2580, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1238
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=0.5182, Q2 Loss=0.5182, Entropy=0.3409, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4732
SAC Update 4/5: Actor Loss=-0.0028, Q1 Loss=29.3601, Q2 Loss=29.3601, Entropy=0.3424, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0958
SAC Update 5/5: Actor Loss=-0.0005, Q1 Loss=5.9793, Q2 Loss=5.9793, Entropy=0.2599, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3173

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.8%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (19.1%)
Actor update: 0.10s (38.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001173
Q1 loss: 8.127407
Q2 loss: 8.127407
Current threshold: -30.3571
Global Scale Offset: 2.7783
Reward stats: mean=-0.0081, std=0.1529, count=133
----------------------------------------------
SAC Update - Actor Loss: -0.0012, Q1 Loss: 8.1274, Q2 Loss: 8.1274, Entropy: 0.2855, Mean TD Error: 3.2801, Threshold: -30.3571
Original likelihood: -273.1590270996094
Adjusted likelihood: -273.1590270996094
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 282.6267395019531
Projection step: 1, Loss: 302.0849304199219
Projection step: 2, Loss: 279.10150146484375
Projection step: 3, Loss: 277.7557373046875
Projection step: 4, Loss: 306.5303649902344
Projection step: 5, Loss: 286.54229736328125
Projection step: 6, Loss: 280.2186279296875
Projection step: 7, Loss: 281.39874267578125
Projection step: 8, Loss: 282.0955810546875
Projection step: 9, Loss: 283.19647216796875
Projection step: 10, Loss: 281.45660400390625
Projection step: 11, Loss: 283.0319519042969
Projection step: 12, Loss: 295.2422180175781
Projection step: 13, Loss: 280.76617431640625
Projection step: 14, Loss: 276.118408203125
Final likelihood: tensor([-279.4278, -318.8997, -310.3589, -341.5310, -279.6529, -271.8574,
        -311.4952, -268.7234, -229.7254, -283.5783, -233.8658, -274.4414,
        -233.2924, -257.4427, -359.7740, -294.2989])
Final projection likelihood: -284.2728
1 mode projection failed, trying anyway
New goal: tensor([ 0.1311,  0.6578,  1.1197,  0.9278, -0.2104,  1.0312,  1.1723,  1.0072,
         1.2739,  0.1172,  0.1840,  1.4773,  0.3640, -0.3084, -0.5551],
       device='cuda:0')
tensor([[0.0023]], device='cuda:0') tensor([[0.0041]], device='cuda:0') tensor([[0.0061]], device='cuda:0')
Original likelihood: -221.76480102539062
Adjusted likelihood: -221.76480102539062
Likelihood residual: 0.0
Original likelihood: -306.8149108886719
Adjusted likelihood: -306.8149108886719
Likelihood residual: 0.0
{'index': 306.8149108886719, 'thumb_middle': 221.76480102539062}
Current yaw: tensor([ 0.3640, -0.3072, -0.5896], device='cuda:0')
6 thumb_middle
tensor([ 0.1183,  0.6589,  1.1062,  0.9251, -0.2118,  1.0317,  1.1840,  0.9935,
         1.2992,  0.1076,  0.1875,  1.4669,  0.3640, -0.3072, -0.5896, -1.2077],
       device='cuda:0')
Solve time for step 1 9.405217680032365
Current ori: tensor([ 0.3640, -0.3072, -0.5896], device='cuda:0')
Index force: tensor([0.5661, 0.5995, 0.6014, 0.5820], device='cuda:0')
tensor([ 0.0258,  0.6862,  1.1321,  0.9288, -0.2051,  0.9799,  1.0977,  0.9592,
         1.2309,  0.1308,  0.0239,  1.4526,  0.3812, -0.3520, -0.4842, -1.5000],
       device='cuda:0')
Solve time for step 2 1.8952169109834358
Current ori: tensor([ 0.3812, -0.3520, -0.4842], device='cuda:0')
Index force: tensor([0.5944, 0.5969, 0.5782], device='cuda:0')
tensor([-0.0457,  0.6998,  1.1320,  0.9294, -0.2100,  1.0061,  1.0988,  0.9701,
         1.2306,  0.1328,  0.0310,  1.4761,  0.3811, -0.3516, -0.4854, -1.5764],
       device='cuda:0')
Solve time for step 3 1.9078201969969086
Current ori: tensor([ 0.3811, -0.3516, -0.4854], device='cuda:0')
Index force: tensor([0.5923, 0.5933], device='cuda:0')
tensor([-0.1067,  0.7173,  1.1366,  0.9300, -0.2035,  1.0224,  1.1120,  0.9717,
         1.2289,  0.1333,  0.0616,  1.5046,  0.3801, -0.3491, -0.4911, -1.4300],
       device='cuda:0')
Solve time for step 4 1.9169986909837462
Current ori: tensor([ 0.3801, -0.3491, -0.4911], device='cuda:0')
Index force: tensor([0.5862], device='cuda:0')
Storing RECOVERY transition: reward=-0.1780 (scaled=-0.0445), steps=4
Reward stats updated: mean -0.0081 -> -0.0084, std: 0.1524
Collected 134 transitions for RL
SAC Update 1/5: Actor Loss=-0.0166, Q1 Loss=0.5050, Q2 Loss=0.5050, Entropy=0.3230, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6037
SAC Update 2/5: Actor Loss=-0.0013, Q1 Loss=0.5214, Q2 Loss=0.5214, Entropy=0.2345, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3019
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.7426, Q2 Loss=0.7426, Entropy=0.1965, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0683
SAC Update 4/5: Actor Loss=-0.0198, Q1 Loss=3.9280, Q2 Loss=3.9280, Entropy=0.4627, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1561
SAC Update 5/5: Actor Loss=-0.0051, Q1 Loss=1.3383, Q2 Loss=1.3383, Entropy=0.4094, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0380

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (17.5%)
Q1 update: 0.05s (19.1%)
Q2 update: 0.05s (18.3%)
Actor update: 0.11s (41.1%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008710
Q1 loss: 1.407056
Q2 loss: 1.407056
Current threshold: -30.3575
Global Scale Offset: 2.7523
Reward stats: mean=-0.0084, std=0.1524, count=134
----------------------------------------------
SAC Update - Actor Loss: -0.0087, Q1 Loss: 1.4071, Q2 Loss: 1.4071, Entropy: 0.3252, Mean TD Error: 1.4336, Threshold: -30.3575
Original likelihood: -328.3671875
Adjusted likelihood: -328.3671875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 8
Loaded trajectory sampler
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:0')
Current yaw: tensor([-0.0009,  0.0148, -0.0289], device='cuda:0')
1 turn
Sampling time 3.817600566020701
tensor([ 1.2665e-01,  6.0175e-01,  5.8337e-01,  5.5295e-01, -1.4164e-01,
         5.2733e-01,  9.1725e-01,  9.9572e-01,  1.1919e+00,  3.5608e-01,
         2.7989e-01,  1.1511e+00, -9.3357e-04,  1.4822e-02, -2.8876e-02,
         2.6114e-01], device='cuda:0')
Original likelihood: -24.03573226928711
Adjusted likelihood: -24.03573226928711
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9498)
Solve time for step 1 14.65686096099671
Current ori: tensor([-0.0009,  0.0148, -0.0289], device='cuda:0')
Middle force: tensor([1.2891, 1.2203, 0.6469, 0.7615, 0.7547, 0.7621, 0.9456, 0.4980, 1.2058,
        0.6171, 1.3417, 0.5718], device='cuda:0')
Thumb force: tensor([1.2196, 1.3023, 1.2502, 1.2116, 0.5879, 0.9177, 1.1447, 0.6158, 0.9437,
        0.6021, 0.5554, 0.5835], device='cuda:0')
Index force: tensor([1.6053, 0.5478, 0.5675, 0.6877, 0.6123, 1.0867, 1.3959, 0.7402, 0.5058,
        0.5696, 0.5653, 0.5888], device='cuda:0')
Storing NORMAL transition: reward=0.1195 (scaled=0.1195), steps=1
Reward stats updated: mean -0.0084 -> -0.0075, std: 0.1522
Collected 135 transitions for RL
SAC Update 1/5: Actor Loss=-0.0031, Q1 Loss=0.8701, Q2 Loss=0.8701, Entropy=0.2902, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2897
SAC Update 2/5: Actor Loss=-0.0055, Q1 Loss=7.3518, Q2 Loss=7.3518, Entropy=0.5913, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4624
SAC Update 3/5: Actor Loss=-0.0050, Q1 Loss=1.0284, Q2 Loss=1.0284, Entropy=0.5296, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3167
SAC Update 4/5: Actor Loss=-0.0087, Q1 Loss=0.4976, Q2 Loss=0.4976, Entropy=0.4398, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4773
SAC Update 5/5: Actor Loss=-0.0015, Q1 Loss=0.5492, Q2 Loss=0.5492, Entropy=0.4031, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1346

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.3%)
Q1 update: 0.05s (19.3%)
Q2 update: 0.06s (21.0%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004764
Q1 loss: 2.059420
Q2 loss: 2.059420
Current threshold: -30.3512
Global Scale Offset: 2.7407
Reward stats: mean=-0.0075, std=0.1522, count=135
----------------------------------------------
SAC Update - Actor Loss: -0.0048, Q1 Loss: 2.0594, Q2 Loss: 2.0594, Entropy: 0.4508, Mean TD Error: 1.5362, Threshold: -30.3512
tensor([ 0.1487,  0.6593,  0.5869,  0.4123, -0.0644,  0.4527,  0.9468,  1.1024,
         1.3200,  0.1459,  0.2299,  1.0655, -0.0196, -0.0079, -0.1487,  0.2924],
       device='cuda:0')
Original likelihood: -24.310657501220703
Adjusted likelihood: -24.310657501220703
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9423)
Solve time for step 2 2.985659867990762
Current ori: tensor([-0.0196, -0.0079, -0.1487], device='cuda:0')
Middle force: tensor([1.2107, 0.6466, 0.7550, 0.7577, 0.7647, 0.9585, 0.5006, 1.1952, 0.6144,
        1.3261, 0.5704], device='cuda:0')
Thumb force: tensor([1.2858, 1.2327, 1.1963, 0.5787, 0.8872, 1.0845, 0.6107, 0.9366, 0.5977,
        0.5543, 0.5805], device='cuda:0')
Index force: tensor([0.5456, 0.5670, 0.6875, 0.6146, 1.0924, 1.4054, 0.7478, 0.5055, 0.5692,
        0.5646, 0.5872], device='cuda:0')
Storing NORMAL transition: reward=0.3338 (scaled=0.3338), steps=1
Reward stats updated: mean -0.0075 -> -0.0049, std: 0.1544
Collected 136 transitions for RL
SAC Update 1/5: Actor Loss=-0.0046, Q1 Loss=1.0111, Q2 Loss=1.0111, Entropy=0.4761, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7106
SAC Update 2/5: Actor Loss=-0.0033, Q1 Loss=0.8997, Q2 Loss=0.8997, Entropy=0.4046, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4126
SAC Update 3/5: Actor Loss=-0.0016, Q1 Loss=0.5963, Q2 Loss=0.5963, Entropy=0.3000, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4234
SAC Update 4/5: Actor Loss=-0.0199, Q1 Loss=6.3496, Q2 Loss=6.3496, Entropy=0.4625, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3201
SAC Update 5/5: Actor Loss=-0.0113, Q1 Loss=0.7983, Q2 Loss=0.7983, Entropy=0.3590, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1647

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (14.2%)
Q1 update: 0.05s (19.5%)
Q2 update: 0.05s (19.9%)
Actor update: 0.11s (43.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.008158
Q1 loss: 1.931004
Q2 loss: 1.931004
Current threshold: -30.3473
Global Scale Offset: 2.7383
Reward stats: mean=-0.0049, std=0.1544, count=136
----------------------------------------------
SAC Update - Actor Loss: -0.0082, Q1 Loss: 1.9310, Q2 Loss: 1.9310, Entropy: 0.4005, Mean TD Error: 1.6063, Threshold: -30.3473
tensor([ 0.2141,  0.6497,  0.6249,  0.5362,  0.0615,  0.3556,  1.1378,  1.2604,
         1.3920,  0.0303,  0.1923,  0.9033, -0.0130, -0.0540, -0.5959,  1.0307],
       device='cuda:0')
Original likelihood: -34.46254348754883
Adjusted likelihood: -34.46254348754883
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1415)
State is out of distribution
Projection step: 0, Loss: 35.19054412841797
Projection step: 1, Loss: 30.83700180053711
Projection step: 2, Loss: 26.89397430419922
Projection step: 3, Loss: 25.65593910217285
Projection step: 4, Loss: 24.025524139404297
Projection step: 5, Loss: 24.156858444213867
Projection step: 6, Loss: 23.014799118041992
Projection step: 7, Loss: 22.862146377563477
Projection step: 8, Loss: 22.973724365234375
Projection step: 9, Loss: 22.811708450317383
Projection step: 10, Loss: 23.03067970275879
Projection step: 11, Loss: 21.183034896850586
Projection step: 12, Loss: 21.871475219726562
Projection step: 13, Loss: 20.86427116394043
Projection step: 14, Loss: 20.115421295166016
Final likelihood: tensor([-19.4799, -18.7205, -17.1027, -19.6586, -19.0247, -20.9881, -21.6022,
        -18.9563, -19.9226, -21.5077, -18.8385, -19.7081, -19.9895, -19.3186,
        -21.9588, -18.2059])
Final projection likelihood: -19.6864
1 mode projection succeeded
New goal: tensor([ 0.1354,  0.5634,  0.5605,  0.7372,  0.0144,  0.4805,  0.7852,  1.0896,
         1.3465,  0.2163,  0.0530,  0.9613, -0.0147, -0.0414, -1.3509],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0029]], device='cuda:0') tensor([[0.0025]], device='cuda:0')
Original likelihood: -26.978654861450195
Adjusted likelihood: -26.978654861450195
Likelihood residual: 0.0
Original likelihood: -35.82317352294922
Adjusted likelihood: -35.82317352294922
Likelihood residual: 0.0
{'index': 35.82317352294922, 'thumb_middle': 26.978654861450195}
Current yaw: tensor([-0.0130, -0.0540, -0.5959], device='cuda:0')
2 thumb_middle
tensor([ 0.2141,  0.6497,  0.6249,  0.5362,  0.0615,  0.3556,  1.1378,  1.2604,
         1.3920,  0.0303,  0.1923,  0.9033, -0.0130, -0.0540, -0.5959,  1.0307],
       device='cuda:0')
Solve time for step 1 9.722944131994154
Current ori: tensor([-0.0130, -0.0540, -0.5959], device='cuda:0')
Index force: tensor([0.5917, 0.6078, 0.5018, 0.5928], device='cuda:0')
tensor([ 0.2076,  0.5990,  0.5954,  0.7105, -0.0661,  0.4345,  0.8362,  1.1014,
         1.3457,  0.1790,  0.0592,  0.9480,  0.0027, -0.0415, -0.5639,  1.1315],
       device='cuda:0')
Solve time for step 2 1.9539889830048196
Current ori: tensor([ 0.0027, -0.0415, -0.5639], device='cuda:0')
Index force: tensor([0.5961, 0.5005, 0.5883], device='cuda:0')
tensor([ 0.2102,  0.5645,  0.6036,  0.7925, -0.0776,  0.4792,  0.7843,  1.0794,
         1.3479,  0.2027,  0.0460,  0.9758,  0.0184, -0.0385, -0.5639,  1.1650],
       device='cuda:0')
Solve time for step 3 1.9348025749786757
Current ori: tensor([ 0.0184, -0.0385, -0.5639], device='cuda:0')
Index force: tensor([0.5004, 0.5805], device='cuda:0')
tensor([ 0.2085,  0.5717,  0.5983,  0.7786, -0.0878,  0.5004,  0.7607,  1.0702,
         1.3466,  0.1913,  0.0440,  0.9915,  0.0152, -0.0383, -0.5639,  1.1569],
       device='cuda:0')
Solve time for step 4 1.9545348130050115
Current ori: tensor([ 0.0152, -0.0383, -0.5639], device='cuda:0')
Index force: tensor([0.5791], device='cuda:0')
Storing RECOVERY transition: reward=0.0295 (scaled=0.0148), steps=2
Reward stats updated: mean -0.0049 -> -0.0048, std: 0.1539
Collected 137 transitions for RL
SAC Update 1/5: Actor Loss=-0.0049, Q1 Loss=0.9630, Q2 Loss=0.9630, Entropy=0.5248, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6546
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.8711, Q2 Loss=0.8711, Entropy=0.0828, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0963
SAC Update 3/5: Actor Loss=-0.0027, Q1 Loss=0.9619, Q2 Loss=0.9619, Entropy=0.3026, Time=0.09sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5369
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=2.2871, Q2 Loss=2.2871, Entropy=0.3360, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0619
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=1.0342, Q2 Loss=1.0342, Entropy=0.1109, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7033

------ SAC Update Summary (5 iterations) ------
Total time: 0.32s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (15.2%)
Q1 update: 0.06s (17.9%)
Q2 update: 0.05s (15.7%)
Actor update: 0.11s (33.8%)
Target update: 0.05s (15.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.001755
Q1 loss: 1.223461
Q2 loss: 1.223461
Current threshold: -30.3293
Global Scale Offset: 2.7266
Reward stats: mean=-0.0048, std=0.1539, count=137
----------------------------------------------
SAC Update - Actor Loss: -0.0018, Q1 Loss: 1.2235, Q2 Loss: 1.2235, Entropy: 0.2714, Mean TD Error: 1.6106, Threshold: -30.3293
Original likelihood: -25.35205078125
Adjusted likelihood: -25.35205078125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9036)
Current yaw: tensor([ 0.0045, -0.0345, -0.5742], device='cuda:0')
3 turn
Sampling time 3.7161412540008314
tensor([ 0.1937,  0.6030,  0.5651,  0.7291, -0.0331,  0.5574,  0.8058,  1.0743,
         1.4254,  0.2169,  0.0740,  1.0114,  0.0045, -0.0345, -0.5742,  1.1314],
       device='cuda:0')
Original likelihood: -24.656702041625977
Adjusted likelihood: -24.656702041625977
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.9312)
State is out of distribution
Projection step: 0, Loss: 24.676654815673828
Projection step: 1, Loss: 23.304588317871094
Projection step: 2, Loss: 21.617095947265625
Projection step: 3, Loss: 20.39409637451172
Projection step: 4, Loss: 19.7205810546875
Projection step: 5, Loss: 19.689868927001953
Projection step: 6, Loss: 17.467411041259766
Projection step: 7, Loss: 17.47654151916504
Projection step: 8, Loss: 17.581802368164062
Projection step: 9, Loss: 15.469865798950195
Projection step: 10, Loss: 15.560546875
Projection step: 11, Loss: 15.73160171508789
Projection step: 12, Loss: 15.493086814880371
Projection step: 13, Loss: 14.142772674560547
Final likelihood: tensor([-16.1542, -13.8168, -16.1305, -13.9008, -13.1266, -13.7891, -13.9598,
        -14.4996, -12.8112, -14.2802, -12.8148, -13.5913, -13.4073, -13.6933,
        -13.7344, -16.5744])
Final projection likelihood: -14.1428
1 mode projection succeeded
New goal: tensor([ 1.1122e-01,  5.2390e-01,  6.2761e-01,  6.8739e-01, -3.9921e-02,
         5.4518e-01,  8.7134e-01,  8.9373e-01,  1.3545e+00,  2.3673e-01,
         1.3517e-01,  1.0473e+00,  4.6274e-04, -2.4754e-02, -1.2070e+00],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -22.062828063964844
Adjusted likelihood: -22.062828063964844
Likelihood residual: 0.0
Original likelihood: -21.508344650268555
Adjusted likelihood: -21.508344650268555
Likelihood residual: 0.0
{'index': 21.508344650268555, 'thumb_middle': 22.062828063964844}
Current yaw: tensor([ 0.0045, -0.0345, -0.5742], device='cuda:0')
4 index
tensor([ 0.1937,  0.6030,  0.5651,  0.7291, -0.0331,  0.5574,  0.8058,  1.0743,
         1.4254,  0.2169,  0.0740,  1.0114,  0.0045, -0.0345, -0.5742,  1.1314],
       device='cuda:0')
Solve time for step 1 11.52932317298837
Current ori: tensor([ 0.0045, -0.0345, -0.5742], device='cuda:0')
Middle force: tensor([0.5966, 0.5783, 0.5543, 0.5485], device='cuda:0')
Thumb force: tensor([0.5659, 0.5171, 0.5492, 0.5723], device='cuda:0')
tensor([ 1.8539e-01,  4.9189e-01,  5.5510e-01,  6.6798e-01, -3.3194e-02,
         5.2858e-01,  8.8690e-01,  9.7665e-01,  1.4162e+00,  2.3698e-01,
         8.3635e-02,  9.9904e-01,  8.7542e-04, -3.3862e-02, -5.6821e-01,
         3.7142e+00], device='cuda:0')
Solve time for step 2 2.4405890419729985
Current ori: tensor([ 0.0009, -0.0339, -0.5682], device='cuda:0')
Middle force: tensor([0.5749, 0.5522, 0.5463], device='cuda:0')
Thumb force: tensor([0.5162, 0.5478, 0.5704], device='cuda:0')
tensor([ 1.7335e-01,  4.8482e-01,  5.6758e-01,  6.6022e-01, -3.8100e-02,
         5.3536e-01,  9.1413e-01,  9.5805e-01,  1.4081e+00,  2.4815e-01,
         7.9545e-02,  1.0004e+00, -1.1981e-03, -3.9795e-02, -5.7274e-01,
         5.3490e+00], device='cuda:0')
Solve time for step 3 2.3080597090302035
Current ori: tensor([-0.0012, -0.0398, -0.5727], device='cuda:0')
Middle force: tensor([0.5866, 0.5380], device='cuda:0')
Thumb force: tensor([0.5989, 0.6187], device='cuda:0')
tensor([ 1.6793e-01,  4.8097e-01,  5.7256e-01,  6.5758e-01, -4.7028e-02,
         5.4118e-01,  9.1941e-01,  9.4773e-01,  1.4139e+00,  2.3954e-01,
         8.0423e-02,  9.9019e-01, -4.1380e-03, -3.8225e-02, -5.7293e-01,
         6.1563e+00], device='cuda:0')
Solve time for step 4 2.313952218974009
Current ori: tensor([-0.0041, -0.0382, -0.5729], device='cuda:0')
Middle force: tensor([0.5345], device='cuda:0')
Thumb force: tensor([0.6141], device='cuda:0')
Storing RECOVERY transition: reward=-0.0110 (scaled=-0.0110), steps=0
Reward stats updated: mean -0.0048 -> -0.0048, std: 0.1533
Collected 138 transitions for RL
SAC Update 1/5: Actor Loss=-0.0054, Q1 Loss=0.4826, Q2 Loss=0.4826, Entropy=0.5408, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0963
SAC Update 2/5: Actor Loss=-0.0006, Q1 Loss=1.2045, Q2 Loss=1.2045, Entropy=0.2065, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4131
SAC Update 3/5: Actor Loss=-0.0007, Q1 Loss=1.3827, Q2 Loss=1.3827, Entropy=0.1265, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0810
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=0.9430, Q2 Loss=0.9430, Entropy=0.1756, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4536
SAC Update 5/5: Actor Loss=-0.0033, Q1 Loss=0.6463, Q2 Loss=0.6463, Entropy=0.3769, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4439

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.0%)
Q1 update: 0.05s (18.6%)
Q2 update: 0.06s (19.6%)
Actor update: 0.12s (41.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002212
Q1 loss: 0.931819
Q2 loss: 0.931819
Current threshold: -30.3131
Global Scale Offset: 2.7479
Reward stats: mean=-0.0048, std=0.1533, count=138
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 0.9318, Q2 Loss: 0.9318, Entropy: 0.2853, Mean TD Error: 0.6976, Threshold: -30.3131
Original likelihood: -17.98155975341797
Adjusted likelihood: -17.98155975341797
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9993)
Current yaw: tensor([-0.0038, -0.0361, -0.5633], device='cuda:0')
5 turn
Sampling time 3.8134576490265317
tensor([ 1.1707e-01,  5.2869e-01,  6.0909e-01,  6.7804e-01, -5.5728e-02,
         5.4551e-01,  9.2056e-01,  9.4671e-01,  1.4098e+00,  2.4831e-01,
         8.4949e-02,  9.9174e-01, -3.7922e-03, -3.6147e-02, -5.6328e-01,
         6.2589e+00], device='cuda:0')
Original likelihood: -19.876279830932617
Adjusted likelihood: -19.876279830932617
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9967)
Solve time for step 1 14.668535514036193
Current ori: tensor([-0.0038, -0.0361, -0.5633], device='cuda:0')
Middle force: tensor([0.9561, 1.0138, 1.2457, 0.5346, 0.8571, 0.7359, 0.5426, 0.5280, 0.5721,
        0.5671, 0.6976, 0.7705], device='cuda:0')
Thumb force: tensor([0.8014, 0.6655, 0.6021, 0.5125, 0.5811, 0.5907, 1.1000, 0.5447, 0.5649,
        0.8214, 0.5720, 0.5223], device='cuda:0')
Index force: tensor([0.5239, 1.0764, 0.9229, 0.5964, 0.5227, 0.5958, 0.6630, 0.5737, 0.5495,
        0.5709, 0.5712, 0.5337], device='cuda:0')
Storing NORMAL transition: reward=0.0218 (scaled=0.0218), steps=1
Reward stats updated: mean -0.0048 -> -0.0047, std: 0.1528
Collected 139 transitions for RL
SAC Update 1/5: Actor Loss=-0.0067, Q1 Loss=0.4881, Q2 Loss=0.4881, Entropy=0.3575, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1288
SAC Update 2/5: Actor Loss=-0.0049, Q1 Loss=0.7537, Q2 Loss=0.7537, Entropy=0.3804, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2697
SAC Update 3/5: Actor Loss=-0.0025, Q1 Loss=1.1938, Q2 Loss=1.1938, Entropy=0.3649, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3267
SAC Update 4/5: Actor Loss=-0.0077, Q1 Loss=0.8133, Q2 Loss=0.8133, Entropy=0.6519, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3077
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=0.7197, Q2 Loss=0.7197, Entropy=0.2579, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1390

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (19.3%)
Q1 update: 0.05s (18.8%)
Q2 update: 0.05s (18.1%)
Actor update: 0.10s (40.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004552
Q1 loss: 0.793701
Q2 loss: 0.793701
Current threshold: -30.3110
Global Scale Offset: 2.7956
Reward stats: mean=-0.0047, std=0.1528, count=139
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 0.7937, Q2 Loss: 0.7937, Entropy: 0.4025, Mean TD Error: 0.8344, Threshold: -30.3110
tensor([ 9.1594e-02,  5.2280e-01,  5.8648e-01,  6.8931e-01, -7.6274e-02,
         5.2687e-01,  9.2944e-01,  9.4154e-01,  1.4371e+00,  2.4184e-01,
         1.2084e-01,  9.0543e-01, -5.2572e-03, -2.0842e-02, -5.8428e-01,
         6.2566e+00], device='cuda:0')
Original likelihood: -16.94792938232422
Adjusted likelihood: -16.94792938232422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9997)
Solve time for step 2 3.0301373819820583
Current ori: tensor([-0.0053, -0.0208, -0.5843], device='cuda:0')
Middle force: tensor([0.6044, 0.7774, 0.6404, 0.9400, 0.5712, 0.5919, 0.5213, 0.6208, 0.5757,
        0.5515, 0.5437], device='cuda:0')
Thumb force: tensor([0.9629, 0.5013, 1.2091, 0.5318, 0.5860, 0.5770, 0.5112, 0.5518, 0.6814,
        0.5005, 0.9219], device='cuda:0')
Index force: tensor([0.5164, 0.8966, 0.7451, 0.7137, 0.6073, 0.5731, 0.5869, 0.5697, 0.5515,
        0.5601, 0.5488], device='cuda:0')
Storing NORMAL transition: reward=-0.0058 (scaled=-0.0058), steps=1
Reward stats updated: mean -0.0047 -> -0.0047, std: 0.1522
Collected 140 transitions for RL
SAC Update 1/5: Actor Loss=-0.0058, Q1 Loss=0.9054, Q2 Loss=0.9054, Entropy=0.4708, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2471
SAC Update 2/5: Actor Loss=-0.0127, Q1 Loss=2.1694, Q2 Loss=2.1694, Entropy=0.3343, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2264
SAC Update 3/5: Actor Loss=-0.0024, Q1 Loss=27.7168, Q2 Loss=27.7168, Entropy=0.2593, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.0671
SAC Update 4/5: Actor Loss=-0.0099, Q1 Loss=1.3555, Q2 Loss=1.3555, Entropy=0.4558, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0295
SAC Update 5/5: Actor Loss=-0.0056, Q1 Loss=0.6473, Q2 Loss=0.6473, Entropy=0.3435, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3183

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (13.2%)
Q1 update: 0.06s (19.4%)
Q2 update: 0.06s (21.0%)
Actor update: 0.12s (43.8%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007273
Q1 loss: 6.558901
Q2 loss: 6.558901
Current threshold: -30.3193
Global Scale Offset: 2.8341
Reward stats: mean=-0.0047, std=0.1522, count=140
----------------------------------------------
SAC Update - Actor Loss: -0.0073, Q1 Loss: 6.5589, Q2 Loss: 6.5589, Entropy: 0.3727, Mean TD Error: 1.5777, Threshold: -30.3193
tensor([ 1.7545e-01,  4.6997e-01,  7.5078e-01,  6.4907e-01,  2.1844e-02,
         6.2022e-01,  9.0137e-01,  9.7122e-01,  1.4126e+00,  1.1779e-01,
         1.0853e-01,  8.4706e-01, -5.5375e-03, -1.0069e-01, -5.8812e-01,
        -6.2174e+00], device='cuda:0')
Original likelihood: -28.057388305664062
Adjusted likelihood: -28.057388305664062
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7172)
State is out of distribution
Projection step: 0, Loss: 29.999771118164062
Projection step: 1, Loss: 28.435747146606445
Projection step: 2, Loss: 26.125446319580078
Projection step: 3, Loss: 25.212507247924805
Projection step: 4, Loss: 29.33649444580078
Projection step: 5, Loss: 26.578351974487305
Projection step: 6, Loss: 28.012248992919922
Projection step: 7, Loss: 26.028366088867188
Projection step: 8, Loss: 24.191856384277344
Projection step: 9, Loss: 22.981517791748047
Projection step: 10, Loss: 26.182750701904297
Projection step: 11, Loss: 23.184661865234375
Projection step: 12, Loss: 23.007326126098633
Projection step: 13, Loss: 24.516197204589844
Projection step: 14, Loss: 22.702566146850586
Final likelihood: tensor([-22.9195, -23.1901, -21.7385, -19.2431, -22.8747, -22.3588, -31.7615,
        -21.6301, -23.4329, -21.1230, -21.1936, -33.2587, -19.5522, -20.9766,
        -22.2921, -21.6754])
Final projection likelihood: -23.0763
1 mode projection succeeded
New goal: tensor([ 0.1342,  0.4336,  0.7179,  0.7537,  0.0218,  0.6382,  0.8329,  0.8190,
         1.4264,  0.0672,  0.1311,  0.8588, -0.0108, -0.0821, -1.2862],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0026]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -24.956851959228516
Adjusted likelihood: -24.956851959228516
Likelihood residual: 0.0
Original likelihood: -29.520122528076172
Adjusted likelihood: -29.520122528076172
Likelihood residual: 0.0
{'index': 29.520122528076172, 'thumb_middle': 24.956851959228516}
Current yaw: tensor([-0.0055, -0.1007, -0.5881], device='cuda:0')
6 thumb_middle
tensor([ 1.7545e-01,  4.6997e-01,  7.5078e-01,  6.4907e-01,  2.1844e-02,
         6.2022e-01,  9.0137e-01,  9.7122e-01,  1.4126e+00,  1.1779e-01,
         1.0853e-01,  8.4706e-01, -5.5375e-03, -1.0069e-01, -5.8812e-01,
        -6.2174e+00], device='cuda:0')
Solve time for step 1 9.026020460005384
Current ori: tensor([-0.0055, -0.1007, -0.5881], device='cuda:0')
Index force: tensor([0.5776, 0.5870, 0.5767, 0.5449], device='cuda:0')
tensor([ 0.1406,  0.4366,  0.7207,  0.7306, -0.0601,  0.6308,  0.8012,  0.8159,
         1.3849,  0.0643,  0.0535,  0.8252,  0.0158, -0.0819, -0.5881, -6.0983],
       device='cuda:0')
Solve time for step 2 1.9137517549679615
Current ori: tensor([ 0.0158, -0.0819, -0.5881], device='cuda:0')
Index force: tensor([0.5808, 0.5727, 0.5414], device='cuda:0')
tensor([ 0.1325,  0.4370,  0.7140,  0.7269, -0.0791,  0.6557,  0.8003,  0.8071,
         1.3902,  0.0525,  0.0551,  0.8307,  0.0144, -0.0772, -0.5881, -6.1048],
       device='cuda:0')
Solve time for step 3 1.8671339899883606
Current ori: tensor([ 0.0144, -0.0772, -0.5881], device='cuda:0')
Index force: tensor([0.5671, 0.5379], device='cuda:0')
tensor([ 0.1395,  0.4472,  0.7113,  0.7191, -0.0848,  0.6787,  0.7966,  0.8040,
         1.3912,  0.0627,  0.0453,  0.8239,  0.0109, -0.0816, -0.5881, -6.1134],
       device='cuda:0')
Solve time for step 4 1.8391036090324633
Current ori: tensor([ 0.0109, -0.0816, -0.5881], device='cuda:0')
Index force: tensor([0.5308], device='cuda:0')
Storing RECOVERY transition: reward=0.0049 (scaled=0.0024), steps=2
Reward stats updated: mean -0.0047 -> -0.0046, std: 0.1517
Collected 141 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.5833, Q2 Loss=0.5833, Entropy=0.3419, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3771
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=3.4359, Q2 Loss=3.4359, Entropy=0.2593, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1808
SAC Update 3/5: Actor Loss=-0.0009, Q1 Loss=0.6220, Q2 Loss=0.6220, Entropy=0.1584, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2460
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=0.9883, Q2 Loss=0.9883, Entropy=0.1939, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4798
SAC Update 5/5: Actor Loss=-0.0020, Q1 Loss=0.8933, Q2 Loss=0.8933, Entropy=0.2970, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1348

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.8%)
Q1 update: 0.05s (19.9%)
Q2 update: 0.05s (18.5%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002736
Q1 loss: 1.304561
Q2 loss: 1.304561
Current threshold: -30.3337
Global Scale Offset: 2.8620
Reward stats: mean=-0.0046, std=0.1517, count=141
----------------------------------------------
SAC Update - Actor Loss: -0.0027, Q1 Loss: 1.3046, Q2 Loss: 1.3046, Entropy: 0.2501, Mean TD Error: 1.2837, Threshold: -30.3337
Original likelihood: -23.649009704589844
Adjusted likelihood: -23.649009704589844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9540)
Current yaw: tensor([ 0.0101, -0.0661, -0.5873], device='cuda:0')
7 turn
Sampling time 3.6688625880051404
tensor([ 0.1041,  0.4477,  0.6756,  0.7199, -0.0474,  0.7047,  0.8343,  0.8282,
         1.4710,  0.0542,  0.1125,  0.8749,  0.0101, -0.0661, -0.5873, -6.0555],
       device='cuda:0')
Original likelihood: -22.952556610107422
Adjusted likelihood: -22.952556610107422
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9686)
Solve time for step 1 14.565070935990661
Current ori: tensor([ 0.0101, -0.0661, -0.5873], device='cuda:0')
Middle force: tensor([0.9777, 0.5528, 0.5435, 0.5459, 0.6624, 1.3489, 0.5451, 0.6100, 0.5939,
        0.5817, 0.5083, 0.7868], device='cuda:0')
Thumb force: tensor([0.5267, 1.2634, 0.6101, 0.5441, 0.5212, 0.5910, 0.6075, 0.5368, 0.5484,
        0.5410, 0.5840, 0.5136], device='cuda:0')
Index force: tensor([0.8297, 0.5255, 0.5385, 0.5338, 0.5982, 0.5453, 0.6461, 0.5632, 0.5527,
        0.6428, 0.5440, 0.7355], device='cuda:0')
Storing NORMAL transition: reward=0.0090 (scaled=0.0090), steps=1
Reward stats updated: mean -0.0046 -> -0.0045, std: 0.1511
Collected 142 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=0.7426, Q2 Loss=0.7426, Entropy=0.1847, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2362
SAC Update 2/5: Actor Loss=-0.0003, Q1 Loss=0.7464, Q2 Loss=0.7464, Entropy=0.1343, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5471
SAC Update 3/5: Actor Loss=-0.0028, Q1 Loss=27.2413, Q2 Loss=27.2413, Entropy=0.3326, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.1459
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=1.2030, Q2 Loss=1.2030, Entropy=0.0633, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8115
SAC Update 5/5: Actor Loss=-0.0014, Q1 Loss=1.0840, Q2 Loss=1.0840, Entropy=0.2454, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6652

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (20.6%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (17.8%)
Actor update: 0.09s (38.1%)
Target update: 0.00s (1.9%)
Priority update: 0.00s (0.2%)
Actor loss: -0.001096
Q1 loss: 6.203462
Q2 loss: 6.203462
Current threshold: -30.3459
Global Scale Offset: 2.9198
Reward stats: mean=-0.0045, std=0.1511, count=142
----------------------------------------------
SAC Update - Actor Loss: -0.0011, Q1 Loss: 6.2035, Q2 Loss: 6.2035, Entropy: 0.1921, Mean TD Error: 1.4812, Threshold: -30.3459
tensor([ 0.0700,  0.4369,  0.6661,  0.7033, -0.0674,  0.6580,  0.9001,  0.7928,
         1.3794,  0.3392,  0.1984,  0.8110,  0.0174, -0.0515, -0.5949, -5.9742],
       device='cuda:0')
Original likelihood: -25.21916389465332
Adjusted likelihood: -25.21916389465332
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8983)
Solve time for step 2 2.9756187049788423
Current ori: tensor([ 0.0174, -0.0515, -0.5949], device='cuda:0')
Middle force: tensor([0.5511, 0.5405, 0.5438, 0.6596, 1.3324, 0.5452, 0.6119, 0.5925, 0.5799,
        0.5079, 0.7887], device='cuda:0')
Thumb force: tensor([1.2523, 0.6086, 0.5418, 0.5196, 0.5883, 0.6041, 0.5348, 0.5465, 0.5394,
        0.5813, 0.5122], device='cuda:0')
Index force: tensor([0.5233, 0.5376, 0.5321, 0.5944, 0.5436, 0.6390, 0.5585, 0.5508, 0.6389,
        0.5416, 0.7268], device='cuda:0')
Storing NORMAL transition: reward=0.0254 (scaled=0.0254), steps=1
Reward stats updated: mean -0.0045 -> -0.0043, std: 0.1506
Collected 143 transitions for RL
SAC Update 1/5: Actor Loss=-0.0032, Q1 Loss=1.0543, Q2 Loss=1.0543, Entropy=0.3304, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5894
SAC Update 2/5: Actor Loss=-0.0095, Q1 Loss=0.9167, Q2 Loss=0.9167, Entropy=0.4597, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2175
SAC Update 3/5: Actor Loss=-0.0021, Q1 Loss=0.5197, Q2 Loss=0.5197, Entropy=0.4401, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1322
SAC Update 4/5: Actor Loss=-0.0026, Q1 Loss=0.5826, Q2 Loss=0.5826, Entropy=0.4283, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3206
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=0.7633, Q2 Loss=0.7633, Entropy=0.1093, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6086

------ SAC Update Summary (5 iterations) ------
Total time: 0.20s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (19.0%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.8%)
Actor update: 0.08s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003526
Q1 loss: 0.767339
Q2 loss: 0.767339
Current threshold: -30.3567
Global Scale Offset: 2.9872
Reward stats: mean=-0.0043, std=0.1506, count=143
----------------------------------------------
SAC Update - Actor Loss: -0.0035, Q1 Loss: 0.7673, Q2 Loss: 0.7673, Entropy: 0.3536, Mean TD Error: 0.5737, Threshold: -30.3567
tensor([ 0.0510,  0.4375,  0.6568,  0.6867, -0.0828,  0.6452,  0.9125,  0.7698,
         1.3767,  0.3601,  0.2486,  0.7285,  0.0110, -0.0400, -0.6192, -6.0088],
       device='cuda:0')
Original likelihood: -23.850679397583008
Adjusted likelihood: -23.850679397583008
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9436)
Solve time for step 3 2.7349360089865513
Current ori: tensor([ 0.0110, -0.0400, -0.6192], device='cuda:0')
Middle force: tensor([0.5389, 0.5416, 0.6512, 1.3176, 0.5442, 0.6095, 0.5892, 0.5768, 0.5074,
        0.7860], device='cuda:0')
Thumb force: tensor([0.6035, 0.5398, 0.5184, 0.5856, 0.6015, 0.5335, 0.5453, 0.5381, 0.5788,
        0.5111], device='cuda:0')
Index force: tensor([0.5356, 0.5307, 0.5935, 0.5416, 0.6344, 0.5561, 0.5496, 0.6365, 0.5401,
        0.7213], device='cuda:0')
Storing NORMAL transition: reward=0.0233 (scaled=0.0233), steps=1
Reward stats updated: mean -0.0043 -> -0.0041, std: 0.1501
Collected 144 transitions for RL
SAC Update 1/5: Actor Loss=-0.0035, Q1 Loss=0.4908, Q2 Loss=0.4908, Entropy=0.4118, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1470
SAC Update 2/5: Actor Loss=-0.0007, Q1 Loss=0.5499, Q2 Loss=0.5499, Entropy=0.1359, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5124
SAC Update 3/5: Actor Loss=-0.0190, Q1 Loss=1.1283, Q2 Loss=1.1283, Entropy=0.3634, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7996
SAC Update 4/5: Actor Loss=-0.0007, Q1 Loss=0.7423, Q2 Loss=0.7423, Entropy=0.1956, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3602
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.3543, Q2 Loss=1.3543, Entropy=0.2852, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5017

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.04s (18.7%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (41.2%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004986
Q1 loss: 0.853114
Q2 loss: 0.853114
Current threshold: -30.3548
Global Scale Offset: 3.0264
Reward stats: mean=-0.0041, std=0.1501, count=144
----------------------------------------------
SAC Update - Actor Loss: -0.0050, Q1 Loss: 0.8531, Q2 Loss: 0.8531, Entropy: 0.2784, Mean TD Error: 0.6642, Threshold: -30.3548
tensor([ 0.0366,  0.4297,  0.6556,  0.6857, -0.0943,  0.6298,  0.9258,  0.7662,
         1.3959,  0.3517,  0.2833,  0.6448,  0.0106, -0.0316, -0.6420, -6.0155],
       device='cuda:0')
Original likelihood: -23.62346839904785
Adjusted likelihood: -23.62346839904785
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9478)
Solve time for step 4 2.6453189229941927
Current ori: tensor([ 0.0106, -0.0316, -0.6420], device='cuda:0')
Middle force: tensor([0.5398, 0.6446, 1.3054, 0.5428, 0.6077, 0.5864, 0.5739, 0.5070, 0.7826],
       device='cuda:0')
Thumb force: tensor([0.5379, 0.5173, 0.5828, 0.5992, 0.5322, 0.5440, 0.5369, 0.5764, 0.5101],
       device='cuda:0')
Index force: tensor([0.5280, 0.5920, 0.5395, 0.6311, 0.5538, 0.5485, 0.6345, 0.5386, 0.7169],
       device='cuda:0')
Storing NORMAL transition: reward=0.0536 (scaled=0.0536), steps=1
Reward stats updated: mean -0.0041 -> -0.0037, std: 0.1497
Collected 145 transitions for RL
SAC Update 1/5: Actor Loss=-0.0019, Q1 Loss=1.0098, Q2 Loss=1.0098, Entropy=0.3141, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6700
SAC Update 2/5: Actor Loss=-0.0018, Q1 Loss=1.2748, Q2 Loss=1.2748, Entropy=0.3264, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4044
SAC Update 3/5: Actor Loss=-0.0028, Q1 Loss=0.5600, Q2 Loss=0.5600, Entropy=0.2927, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5429
SAC Update 4/5: Actor Loss=-0.0008, Q1 Loss=0.8490, Q2 Loss=0.8490, Entropy=0.2189, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7084
SAC Update 5/5: Actor Loss=-0.0038, Q1 Loss=1.3759, Q2 Loss=1.3759, Entropy=0.4347, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4575

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.0%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (17.5%)
Actor update: 0.10s (41.4%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002202
Q1 loss: 1.013920
Q2 loss: 1.013920
Current threshold: -30.3529
Global Scale Offset: 3.0843
Reward stats: mean=-0.0037, std=0.1497, count=145
----------------------------------------------
SAC Update - Actor Loss: -0.0022, Q1 Loss: 1.0139, Q2 Loss: 1.0139, Entropy: 0.3174, Mean TD Error: 0.9567, Threshold: -30.3529
tensor([-9.9124e-04,  4.3474e-01,  6.4898e-01,  6.2194e-01, -2.4195e-01,
         7.2245e-01,  9.1306e-01,  8.4761e-01,  1.4348e+00,  3.7110e-01,
         3.1100e-01,  5.3824e-01,  7.9625e-03, -1.1548e-02, -6.9465e-01,
        -5.9886e+00], device='cuda:0')
Original likelihood: -35.954864501953125
Adjusted likelihood: -35.954864501953125
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0915)
State is out of distribution
Projection step: 0, Loss: 35.925987243652344
Projection step: 1, Loss: 34.9627571105957
Projection step: 2, Loss: 31.16551971435547
Projection step: 3, Loss: 29.790199279785156
Projection step: 4, Loss: 27.49707794189453
Projection step: 5, Loss: 27.12578773498535
Projection step: 6, Loss: 24.586400985717773
Projection step: 7, Loss: 21.833484649658203
Projection step: 8, Loss: 20.644804000854492
Projection step: 9, Loss: 20.781078338623047
Projection step: 10, Loss: 20.68456268310547
Projection step: 11, Loss: 18.737380981445312
Projection step: 12, Loss: 17.74563217163086
Projection step: 13, Loss: 15.950157165527344
Projection step: 14, Loss: 11.357217788696289
Final likelihood: tensor([-10.7094, -11.0649, -10.4311, -10.6910, -12.3810, -10.5701, -13.9252,
        -12.4604, -10.9445, -10.4041, -12.0478, -10.9092, -10.1511, -10.6377,
        -12.3912, -11.9968])
Final projection likelihood: -11.3572
1 mode projection succeeded
New goal: tensor([ 0.0332,  0.4683,  0.6333,  0.6969, -0.0614,  0.5766,  0.8607,  0.8272,
         1.3620,  0.1904,  0.2733,  0.8741,  0.0024, -0.0073, -0.7358],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0033]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -22.781856536865234
Adjusted likelihood: -22.781856536865234
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 22.781856536865234}
Current yaw: tensor([ 0.0080, -0.0115, -0.6946], device='cuda:0')
8 thumb_middle
tensor([-9.9124e-04,  4.3474e-01,  6.4898e-01,  6.2194e-01, -2.4195e-01,
         7.2245e-01,  9.1306e-01,  8.4761e-01,  1.4348e+00,  3.7110e-01,
         3.1100e-01,  5.3824e-01,  7.9625e-03, -1.1548e-02, -6.9465e-01,
        -5.9886e+00], device='cuda:0')
Solve time for step 1 9.040146868035663
Current ori: tensor([ 0.0080, -0.0115, -0.6946], device='cuda:0')
Index force: tensor([0.5775, 0.5894, 0.5853, 0.5980], device='cuda:0')
tensor([-1.2691e-03,  4.4465e-01,  6.1451e-01,  6.6373e-01, -1.9258e-01,
         6.0221e-01,  8.2420e-01,  8.0192e-01,  1.3205e+00,  2.0265e-01,
         2.1935e-01,  7.7397e-01,  1.0293e-02, -1.1505e-02, -6.9462e-01,
        -5.9735e+00], device='cuda:0')
Solve time for step 2 1.9304242209764197
Current ori: tensor([ 0.0103, -0.0115, -0.6946], device='cuda:0')
Index force: tensor([0.5849, 0.5819, 0.5943], device='cuda:0')
tensor([ 0.0061,  0.4481,  0.6143,  0.6675, -0.1762,  0.5918,  0.8416,  0.7959,
         1.3208,  0.1753,  0.1954,  0.8139,  0.0101, -0.0156, -0.6946, -5.9649],
       device='cuda:0')
Solve time for step 3 1.8355053690029308
Current ori: tensor([ 0.0101, -0.0156, -0.6946], device='cuda:0')
Index force: tensor([0.5760, 0.5898], device='cuda:0')
tensor([ 0.0126,  0.4387,  0.6174,  0.6981, -0.1791,  0.6214,  0.8258,  0.7912,
         1.3117,  0.1743,  0.1933,  0.8293,  0.0168, -0.0193, -0.6946, -5.9435],
       device='cuda:0')
Solve time for step 4 1.7877359710400924
Current ori: tensor([ 0.0168, -0.0193, -0.6946], device='cuda:0')
Index force: tensor([0.5810], device='cuda:0')
Storing RECOVERY transition: reward=-0.0097 (scaled=-0.0024), steps=4
Reward stats updated: mean -0.0037 -> -0.0037, std: 0.1492
Collected 146 transitions for RL
SAC Update 1/5: Actor Loss=-0.0102, Q1 Loss=0.8262, Q2 Loss=0.8262, Entropy=0.5347, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3702
SAC Update 2/5: Actor Loss=-0.0002, Q1 Loss=0.6437, Q2 Loss=0.6437, Entropy=0.1579, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3173
SAC Update 3/5: Actor Loss=-0.0001, Q1 Loss=0.5745, Q2 Loss=0.5745, Entropy=0.0484, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1192
SAC Update 4/5: Actor Loss=-0.0002, Q1 Loss=0.7769, Q2 Loss=0.7769, Entropy=0.0886, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3499
SAC Update 5/5: Actor Loss=-0.0053, Q1 Loss=2.1643, Q2 Loss=2.1643, Entropy=0.6083, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5026

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (18.4%)
Q1 update: 0.04s (19.3%)
Q2 update: 0.04s (18.9%)
Actor update: 0.08s (39.6%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003205
Q1 loss: 0.997108
Q2 loss: 0.997108
Current threshold: -30.3577
Global Scale Offset: 3.1436
Reward stats: mean=-0.0037, std=0.1492, count=146
----------------------------------------------
SAC Update - Actor Loss: -0.0032, Q1 Loss: 0.9971, Q2 Loss: 0.9971, Entropy: 0.2876, Mean TD Error: 1.3318, Threshold: -30.3577
Original likelihood: -25.188995361328125
Adjusted likelihood: -25.188995361328125
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8870)
Current yaw: tensor([ 0.0230, -0.0087, -0.6854], device='cuda:0')
9 turn
Sampling time 3.8112827310105786
tensor([-0.0132,  0.4416,  0.6028,  0.6759, -0.1250,  0.6310,  0.8763,  0.8269,
         1.3854,  0.1895,  0.2451,  0.8891,  0.0230, -0.0087, -0.6854, -5.9086],
       device='cuda:0')
Original likelihood: -24.026409149169922
Adjusted likelihood: -24.026409149169922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9309)
Solve time for step 1 14.577146345051005
Current ori: tensor([ 0.0230, -0.0087, -0.6854], device='cuda:0')
Middle force: tensor([0.5879, 1.5841, 0.5636, 0.5313, 0.6363, 0.5282, 0.6226, 0.7343, 0.6379,
        0.5957, 0.5815, 0.5595], device='cuda:0')
Thumb force: tensor([0.6994, 1.4453, 0.5546, 0.8887, 0.5101, 0.5795, 0.5320, 0.5013, 0.6008,
        0.5950, 0.6458, 0.8203], device='cuda:0')
Index force: tensor([0.5566, 1.0359, 0.5128, 0.6835, 0.5591, 0.5599, 0.5893, 0.5216, 0.5921,
        0.5836, 0.5917, 0.6476], device='cuda:0')
Storing NORMAL transition: reward=-0.0480 (scaled=-0.0480), steps=1
Reward stats updated: mean -0.0037 -> -0.0040, std: 0.1487
Collected 147 transitions for RL
SAC Update 1/5: Actor Loss=-0.0029, Q1 Loss=1.1176, Q2 Loss=1.1176, Entropy=0.3766, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8404
SAC Update 2/5: Actor Loss=-0.0186, Q1 Loss=1.4708, Q2 Loss=1.4708, Entropy=0.4511, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.5781
SAC Update 3/5: Actor Loss=-0.0057, Q1 Loss=6.2992, Q2 Loss=6.2992, Entropy=0.6094, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6134
SAC Update 4/5: Actor Loss=-0.0057, Q1 Loss=6.4274, Q2 Loss=6.4274, Entropy=0.6095, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6134
SAC Update 5/5: Actor Loss=-0.0015, Q1 Loss=1.0513, Q2 Loss=1.0513, Entropy=0.2087, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9090

------ SAC Update Summary (5 iterations) ------
Total time: 0.31s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (14.5%)
Q1 update: 0.06s (18.9%)
Q2 update: 0.07s (21.1%)
Actor update: 0.13s (41.7%)
Target update: 0.01s (1.9%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006877
Q1 loss: 3.273282
Q2 loss: 3.273282
Current threshold: -30.3592
Global Scale Offset: 3.1754
Reward stats: mean=-0.0040, std=0.1487, count=147
----------------------------------------------
SAC Update - Actor Loss: -0.0069, Q1 Loss: 3.2733, Q2 Loss: 3.2733, Entropy: 0.4511, Mean TD Error: 2.9109, Threshold: -30.3592
tensor([-3.1294e-02,  4.2008e-01,  6.1843e-01,  6.7491e-01, -1.3569e-01,
         6.5354e-01,  8.2200e-01,  8.5361e-01,  1.3746e+00,  2.2535e-01,
         2.2113e-01,  9.5549e-01,  2.3993e-02,  8.8212e-04, -6.3732e-01,
        -6.0002e+00], device='cuda:0')
Original likelihood: -23.00177764892578
Adjusted likelihood: -23.00177764892578
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9563)
Solve time for step 2 2.9338700129883364
Current ori: tensor([ 0.0240,  0.0009, -0.6373], device='cuda:0')
Middle force: tensor([1.5757, 0.5615, 0.5306, 0.6330, 0.5276, 0.6198, 0.7293, 0.6350, 0.5933,
        0.5793, 0.5558], device='cuda:0')
Thumb force: tensor([1.4201, 0.5528, 0.8799, 0.5092, 0.5772, 0.5311, 0.5012, 0.5985, 0.5934,
        0.6437, 0.8159], device='cuda:0')
Index force: tensor([1.0215, 0.5121, 0.6786, 0.5568, 0.5576, 0.5869, 0.5210, 0.5901, 0.5816,
        0.5893, 0.6474], device='cuda:0')
Storing NORMAL transition: reward=-0.0889 (scaled=-0.0889), steps=1
Reward stats updated: mean -0.0040 -> -0.0046, std: 0.1484
Collected 148 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=0.6720, Q2 Loss=0.6720, Entropy=0.1390, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0477
SAC Update 2/5: Actor Loss=-0.0026, Q1 Loss=0.8100, Q2 Loss=0.8100, Entropy=0.4159, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4599
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.6978, Q2 Loss=0.6978, Entropy=0.1563, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6418
SAC Update 4/5: Actor Loss=-0.0056, Q1 Loss=4.7146, Q2 Loss=4.7146, Entropy=0.6113, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4600
SAC Update 5/5: Actor Loss=-0.0012, Q1 Loss=1.3160, Q2 Loss=1.3160, Entropy=0.2372, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0498

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (20.1%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002029
Q1 loss: 1.642093
Q2 loss: 1.642093
Current threshold: -30.3637
Global Scale Offset: 3.2289
Reward stats: mean=-0.0046, std=0.1484, count=148
----------------------------------------------
SAC Update - Actor Loss: -0.0020, Q1 Loss: 1.6421, Q2 Loss: 1.6421, Entropy: 0.3119, Mean TD Error: 1.7318, Threshold: -30.3637
tensor([-0.1532,  0.3327,  0.6606,  0.6566, -0.1502,  0.7511,  0.6986,  0.6845,
         1.4525,  0.1541,  0.2761,  0.7609, -0.0119,  0.0314, -0.5487,  6.0384],
       device='cuda:0')
Original likelihood: -39.781925201416016
Adjusted likelihood: -39.781925201416016
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0154)
State is out of distribution
Projection step: 0, Loss: 39.961029052734375
Projection step: 1, Loss: 33.817970275878906
Projection step: 2, Loss: 31.66305923461914
Projection step: 3, Loss: 28.35028839111328
Projection step: 4, Loss: 26.779321670532227
Projection step: 5, Loss: 24.044677734375
Projection step: 6, Loss: 23.504873275756836
Projection step: 7, Loss: 20.951217651367188
Projection step: 8, Loss: 21.028011322021484
Projection step: 9, Loss: 20.145835876464844
Projection step: 10, Loss: 19.454402923583984
Projection step: 11, Loss: 18.32778549194336
Projection step: 12, Loss: 18.637615203857422
Projection step: 13, Loss: 18.36154556274414
Projection step: 14, Loss: 18.267810821533203
Final likelihood: tensor([-16.6238, -13.6703, -15.0432, -16.2079, -18.4288, -15.9395, -21.7197,
        -21.7858, -14.2827, -14.7400, -26.4259, -15.5267, -16.7519, -17.8107,
        -17.8627, -13.8303])
Final projection likelihood: -17.2906
1 mode projection succeeded
New goal: tensor([-0.0236,  0.3945,  0.6062,  0.8516, -0.0960,  0.5923,  0.5971,  1.0207,
         1.3562,  0.0930,  0.1936,  0.8863, -0.0130,  0.0191, -1.0195],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0032]], device='cuda:0')
Original likelihood: -29.522216796875
Adjusted likelihood: -29.522216796875
Likelihood residual: 0.0
{'index': 29.522216796875, 'thumb_middle': inf}
Current yaw: tensor([-0.0119,  0.0314, -0.5487], device='cuda:0')
10 index
tensor([-0.1532,  0.3327,  0.6606,  0.6566, -0.1502,  0.7511,  0.6986,  0.6845,
         1.4525,  0.1541,  0.2761,  0.7609, -0.0119,  0.0314, -0.5487,  6.0384],
       device='cuda:0')
Solve time for step 1 10.787959705980029
Current ori: tensor([-0.0119,  0.0314, -0.5487], device='cuda:0')
Middle force: tensor([0.5853, 0.5552, 0.5249, 0.5184], device='cuda:0')
Thumb force: tensor([0.6099, 0.5466, 0.5273, 0.6458], device='cuda:0')
tensor([-0.0134,  0.3199,  0.5563,  0.7686, -0.1538,  0.7460,  0.6322,  0.9293,
         1.4577,  0.1386,  0.2177,  0.8908,  0.0178,  0.0218, -0.5756,  5.7711],
       device='cuda:0')
Solve time for step 2 2.2594728529802524
Current ori: tensor([ 0.0178,  0.0218, -0.5756], device='cuda:0')
Middle force: tensor([0.5538, 0.5239, 0.5176], device='cuda:0')
Thumb force: tensor([0.5440, 0.5261, 0.6435], device='cuda:0')
tensor([ 3.9532e-03,  3.3595e-01,  5.4232e-01,  7.9998e-01, -1.4484e-01,
         7.6107e-01,  6.0894e-01,  9.4815e-01,  1.4537e+00,  1.3679e-01,
         2.0433e-01,  9.0757e-01,  1.7241e-02,  1.5187e-02, -5.7018e-01,
         5.7051e+00], device='cuda:0')
Solve time for step 3 2.316430059960112
Current ori: tensor([ 0.0172,  0.0152, -0.5702], device='cuda:0')
Middle force: tensor([0.6033, 0.5535], device='cuda:0')
Thumb force: tensor([0.5993, 0.5876], device='cuda:0')
tensor([ 0.0064,  0.3416,  0.5421,  0.8054, -0.1557,  0.7604,  0.6151,  0.9692,
         1.4567,  0.1298,  0.2007,  0.9264,  0.0230,  0.0165, -0.5628,  5.7322],
       device='cuda:0')
Solve time for step 4 2.291820077050943
Current ori: tensor([ 0.0230,  0.0165, -0.5628], device='cuda:0')
Middle force: tensor([0.5457], device='cuda:0')
Thumb force: tensor([0.5254], device='cuda:0')
Storing RECOVERY transition: reward=-0.0077 (scaled=-0.0038), steps=2
Reward stats updated: mean -0.0046 -> -0.0046, std: 0.1479
Collected 149 transitions for RL
SAC Update 1/5: Actor Loss=-0.0045, Q1 Loss=0.6693, Q2 Loss=0.6693, Entropy=0.5674, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3799
SAC Update 2/5: Actor Loss=-0.0175, Q1 Loss=0.6705, Q2 Loss=0.6705, Entropy=0.2722, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3467
SAC Update 3/5: Actor Loss=-0.0093, Q1 Loss=2.8287, Q2 Loss=2.8287, Entropy=0.6125, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3148
SAC Update 4/5: Actor Loss=-0.0005, Q1 Loss=0.6894, Q2 Loss=0.6894, Entropy=0.2003, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5047
SAC Update 5/5: Actor Loss=-0.0001, Q1 Loss=1.1025, Q2 Loss=1.1025, Entropy=0.0299, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7906

------ SAC Update Summary (5 iterations) ------
Total time: 0.30s, Avg iteration: 0.06s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (15.7%)
Q1 update: 0.06s (21.1%)
Q2 update: 0.06s (19.7%)
Actor update: 0.12s (40.2%)
Target update: 0.00s (1.2%)
Priority update: 0.00s (0.1%)
Actor loss: -0.006370
Q1 loss: 1.192071
Q2 loss: 1.192071
Current threshold: -30.3600
Global Scale Offset: 3.2484
Reward stats: mean=-0.0046, std=0.1479, count=149
----------------------------------------------
SAC Update - Actor Loss: -0.0064, Q1 Loss: 1.1921, Q2 Loss: 1.1921, Entropy: 0.3365, Mean TD Error: 1.4673, Threshold: -30.3600
Original likelihood: -29.814912796020508
Adjusted likelihood: -29.814912796020508
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5495)
Current yaw: tensor([ 0.0198,  0.0116, -0.5406], device='cuda:0')
11 turn
Sampling time 3.6875041219755076
tensor([-0.0307,  0.3910,  0.5832,  0.8344, -0.1452,  0.7760,  0.6025,  0.9528,
         1.4522,  0.1368,  0.1944,  0.9247,  0.0198,  0.0116, -0.5406,  5.7147],
       device='cuda:0')
Original likelihood: -31.175199508666992
Adjusted likelihood: -31.175199508666992
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4262)
Solve time for step 1 14.556834701041225
Current ori: tensor([ 0.0198,  0.0116, -0.5406], device='cuda:0')
Middle force: tensor([0.5148, 0.5734, 0.6178, 0.9484, 1.1406, 0.7584, 0.5059, 0.5268, 0.5340,
        0.5351, 0.6177, 0.6637], device='cuda:0')
Thumb force: tensor([0.5678, 1.0614, 0.5154, 0.8802, 0.6331, 1.8787, 0.6490, 0.5553, 0.4960,
        0.5480, 0.7087, 0.5629], device='cuda:0')
Index force: tensor([0.5293, 0.6026, 0.6269, 0.5697, 1.0826, 0.5638, 0.5010, 0.5326, 0.5953,
        0.6129, 0.5802, 0.5392], device='cuda:0')
Storing NORMAL transition: reward=-0.0045 (scaled=-0.0045), steps=1
Reward stats updated: mean -0.0046 -> -0.0046, std: 0.1474
Collected 150 transitions for RL
SAC Update 1/5: Actor Loss=-0.0093, Q1 Loss=0.5836, Q2 Loss=0.5836, Entropy=0.4631, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6180
SAC Update 2/5: Actor Loss=-0.0099, Q1 Loss=0.6731, Q2 Loss=0.6731, Entropy=0.6768, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4894
SAC Update 3/5: Actor Loss=-0.0046, Q1 Loss=0.9181, Q2 Loss=0.9181, Entropy=0.3507, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6775
SAC Update 4/5: Actor Loss=-0.0029, Q1 Loss=5.3077, Q2 Loss=5.3077, Entropy=0.5359, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5579
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=0.6486, Q2 Loss=0.6486, Entropy=0.2649, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3322

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (19.5%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (17.7%)
Actor update: 0.08s (39.6%)
Target update: 0.00s (1.7%)
Priority update: 0.00s (0.2%)
Actor loss: -0.005494
Q1 loss: 1.626227
Q2 loss: 1.626227
Current threshold: -30.3682
Global Scale Offset: 3.2572
Reward stats: mean=-0.0046, std=0.1474, count=150
----------------------------------------------
SAC Update - Actor Loss: -0.0055, Q1 Loss: 1.6262, Q2 Loss: 1.6262, Entropy: 0.4583, Mean TD Error: 1.5350, Threshold: -30.3682
tensor([ 1.6073e-03,  3.5840e-01,  6.0328e-01,  8.2045e-01, -1.8803e-01,
         6.8777e-01,  7.4616e-01,  9.7954e-01,  1.3447e+00,  2.9052e-01,
         2.2595e-01,  9.0665e-01,  4.8485e-02,  2.0704e-02, -5.3822e-01,
         5.8819e+00], device='cuda:0')
Original likelihood: -32.015777587890625
Adjusted likelihood: -32.015777587890625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3538)
State is out of distribution
Projection step: 0, Loss: 32.296730041503906
Projection step: 1, Loss: 29.209049224853516
Projection step: 2, Loss: 27.3409366607666
Projection step: 3, Loss: 25.801589965820312
Projection step: 4, Loss: 25.391948699951172
Projection step: 5, Loss: 23.04638671875
Projection step: 6, Loss: 22.057106018066406
Projection step: 7, Loss: 20.909893035888672
Projection step: 8, Loss: 20.567623138427734
Projection step: 9, Loss: 18.929492950439453
Projection step: 10, Loss: 18.535396575927734
Projection step: 11, Loss: 18.39191436767578
Projection step: 12, Loss: 16.111373901367188
Projection step: 13, Loss: 16.412860870361328
Projection step: 14, Loss: 15.624307632446289
Final likelihood: tensor([-13.4075, -16.2788, -16.6805, -14.1846, -15.9014, -12.3051, -14.1122,
        -18.1294, -16.0535, -23.2175, -11.2026, -13.2868, -13.4248, -16.9478,
        -13.7481, -16.7226])
Final projection likelihood: -15.3502
1 mode projection succeeded
New goal: tensor([-0.0016,  0.4838,  0.5623,  0.7457, -0.0950,  0.5385,  0.7431,  0.9139,
         1.2933,  0.2597,  0.1942,  1.0730,  0.0324,  0.0147, -1.4994],
       device='cuda:0')
tensor([[0.0093]], device='cuda:0') tensor([[0.0028]], device='cuda:0') tensor([[0.0061]], device='cuda:0')
Original likelihood: -19.948291778564453
Adjusted likelihood: -19.948291778564453
Likelihood residual: 0.0
Original likelihood: -31.635643005371094
Adjusted likelihood: -31.635643005371094
Likelihood residual: 0.0
{'index': 31.635643005371094, 'thumb_middle': 19.948291778564453}
Current yaw: tensor([ 0.0485,  0.0207, -0.5382], device='cuda:0')
12 thumb_middle
tensor([ 1.6073e-03,  3.5840e-01,  6.0328e-01,  8.2045e-01, -1.8803e-01,
         6.8777e-01,  7.4616e-01,  9.7954e-01,  1.3447e+00,  2.9052e-01,
         2.2595e-01,  9.0665e-01,  4.8485e-02,  2.0704e-02, -5.3822e-01,
         5.8819e+00], device='cuda:0')
Solve time for step 1 8.901817274978384
Current ori: tensor([ 0.0485,  0.0207, -0.5382], device='cuda:0')
Index force: tensor([0.5872, 0.5964, 0.5978, 0.5930], device='cuda:0')
tensor([-0.0094,  0.4121,  0.5927,  0.8015, -0.1932,  0.5725,  0.7274,  0.8950,
         1.2761,  0.2482,  0.1629,  1.0452,  0.0591,  0.0274, -0.5382,  5.9322],
       device='cuda:0')
Solve time for step 2 1.8967983210459352
Current ori: tensor([ 0.0591,  0.0274, -0.5382], device='cuda:0')
Index force: tensor([0.5892, 0.5929, 0.5881], device='cuda:0')
tensor([-0.0077,  0.4417,  0.5726,  0.7622, -0.1944,  0.5855,  0.7072,  0.8895,
         1.2845,  0.2411,  0.1662,  1.0464,  0.0487,  0.0271, -0.5382,  5.9226],
       device='cuda:0')
Solve time for step 3 1.8146477739792317
Current ori: tensor([ 0.0487,  0.0271, -0.5382], device='cuda:0')
Index force: tensor([0.5870, 0.5833], device='cuda:0')
tensor([ 1.9834e-03,  4.6282e-01,  5.5652e-01,  7.5151e-01, -1.9230e-01,
         5.8232e-01,  7.2640e-01,  8.8098e-01,  1.2874e+00,  2.4739e-01,
         1.4991e-01,  1.0580e+00,  4.2014e-02,  2.2253e-02, -5.3823e-01,
         5.9258e+00], device='cuda:0')
Solve time for step 4 1.7799763759830967
Current ori: tensor([ 0.0420,  0.0223, -0.5382], device='cuda:0')
Index force: tensor([0.5752], device='cuda:0')
Storing RECOVERY transition: reward=-0.0075 (scaled=-0.0075), steps=1
Reward stats updated: mean -0.0046 -> -0.0046, std: 0.1469
Collected 151 transitions for RL
SAC Update 1/5: Actor Loss=-0.0113, Q1 Loss=27.0316, Q2 Loss=27.0316, Entropy=0.6173, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2540
SAC Update 2/5: Actor Loss=-0.0165, Q1 Loss=1.0468, Q2 Loss=1.0468, Entropy=0.4421, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6182
SAC Update 3/5: Actor Loss=-0.0008, Q1 Loss=0.8654, Q2 Loss=0.8654, Entropy=0.1462, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4311
SAC Update 4/5: Actor Loss=-0.0071, Q1 Loss=26.6017, Q2 Loss=26.6017, Entropy=0.6011, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2505
SAC Update 5/5: Actor Loss=-0.0020, Q1 Loss=1.3777, Q2 Loss=1.3777, Entropy=0.3539, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4901

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (18.4%)
Q1 update: 0.05s (19.8%)
Q2 update: 0.05s (19.2%)
Actor update: 0.10s (39.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.007530
Q1 loss: 11.384634
Q2 loss: 11.384634
Current threshold: -30.3684
Global Scale Offset: 3.2735
Reward stats: mean=-0.0046, std=0.1469, count=151
----------------------------------------------
SAC Update - Actor Loss: -0.0075, Q1 Loss: 11.3846, Q2 Loss: 11.3846, Entropy: 0.4321, Mean TD Error: 2.6088, Threshold: -30.3684
Original likelihood: -24.434959411621094
Adjusted likelihood: -24.434959411621094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9108)
Current yaw: tensor([ 0.0414,  0.0266, -0.5303], device='cuda:0')
13 turn
Sampling time 3.926170382008422
tensor([-0.0094,  0.4699,  0.5440,  0.7373, -0.1240,  0.6240,  0.7437,  0.9065,
         1.3514,  0.2660,  0.2043,  1.1071,  0.0414,  0.0266, -0.5303,  5.9160],
       device='cuda:0')
Original likelihood: -22.08777618408203
Adjusted likelihood: -22.08777618408203
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9698)
Solve time for step 1 14.254748760955408
Current ori: tensor([ 0.0414,  0.0266, -0.5303], device='cuda:0')
Middle force: tensor([0.6021, 0.6842, 1.6083, 0.7444, 0.5654, 0.5064, 0.6483, 0.6267, 0.5365,
        0.6050, 0.5310, 0.5804], device='cuda:0')
Thumb force: tensor([0.8790, 0.9266, 0.5856, 1.1749, 0.9256, 0.5227, 0.5509, 0.5753, 0.5944,
        0.5806, 0.5597, 0.6962], device='cuda:0')
Index force: tensor([0.6348, 0.6265, 0.6228, 0.5564, 0.6138, 0.5433, 0.5271, 0.5718, 0.6848,
        0.5942, 0.5466, 0.5741], device='cuda:0')
Storing NORMAL transition: reward=0.0214 (scaled=0.0214), steps=1
Reward stats updated: mean -0.0046 -> -0.0044, std: 0.1464
Collected 152 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=0.7154, Q2 Loss=0.7154, Entropy=0.2765, Time=0.08sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5578
SAC Update 2/5: Actor Loss=-0.0001, Q1 Loss=0.9870, Q2 Loss=0.9870, Entropy=0.0752, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2198
SAC Update 3/5: Actor Loss=-0.0076, Q1 Loss=1.0339, Q2 Loss=1.0339, Entropy=0.5408, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8571
SAC Update 4/5: Actor Loss=-0.0056, Q1 Loss=0.8860, Q2 Loss=0.8860, Entropy=0.5212, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0322
SAC Update 5/5: Actor Loss=-0.0008, Q1 Loss=7.6078, Q2 Loss=7.6078, Entropy=0.2846, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9177

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (17.9%)
Q1 update: 0.05s (19.0%)
Q2 update: 0.06s (21.8%)
Actor update: 0.10s (38.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003007
Q1 loss: 2.246020
Q2 loss: 2.246020
Current threshold: -30.3714
Global Scale Offset: 3.3249
Reward stats: mean=-0.0044, std=0.1464, count=152
----------------------------------------------
SAC Update - Actor Loss: -0.0030, Q1 Loss: 2.2460, Q2 Loss: 2.2460, Entropy: 0.3397, Mean TD Error: 1.7169, Threshold: -30.3714
tensor([ 0.0070,  0.4915,  0.4384,  0.9200, -0.1495,  0.7047,  0.7437,  0.8636,
         1.4765,  0.2604,  0.2035,  0.8321,  0.0437,  0.0173, -0.5516,  5.9633],
       device='cuda:0')
Original likelihood: -33.47768020629883
Adjusted likelihood: -33.47768020629883
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.2432)
Solve time for step 2 3.0100975960376672
Current ori: tensor([ 0.0437,  0.0173, -0.5516], device='cuda:0')
Middle force: tensor([0.6781, 1.5900, 0.7642, 0.5620, 0.5074, 0.6495, 0.6338, 0.5302, 0.6058,
        0.5367, 0.5708], device='cuda:0')
Thumb force: tensor([0.9204, 0.5821, 1.1556, 0.9236, 0.5216, 0.5488, 0.5693, 0.5992, 0.5771,
        0.5531, 0.7000], device='cuda:0')
Index force: tensor([0.6185, 0.6183, 0.5483, 0.6051, 0.5351, 0.5246, 0.5671, 0.6858, 0.5895,
        0.5394, 0.5743], device='cuda:0')
Storing NORMAL transition: reward=-0.0078 (scaled=-0.0078), steps=1
Reward stats updated: mean -0.0044 -> -0.0045, std: 0.1459
Collected 153 transitions for RL
SAC Update 1/5: Actor Loss=-0.0007, Q1 Loss=6.2238, Q2 Loss=6.2238, Entropy=0.3033, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7573
SAC Update 2/5: Actor Loss=-0.0004, Q1 Loss=0.9838, Q2 Loss=0.9838, Entropy=0.1366, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8726
SAC Update 3/5: Actor Loss=-0.0004, Q1 Loss=0.6988, Q2 Loss=0.6988, Entropy=0.1453, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4548
SAC Update 4/5: Actor Loss=-0.0076, Q1 Loss=2.0902, Q2 Loss=2.0902, Entropy=0.5121, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2667
SAC Update 5/5: Actor Loss=-0.0017, Q1 Loss=0.9252, Q2 Loss=0.9252, Entropy=0.3007, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4272

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (17.7%)
Q1 update: 0.05s (18.5%)
Q2 update: 0.05s (19.5%)
Actor update: 0.11s (40.7%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002145
Q1 loss: 2.184373
Q2 loss: 2.184373
Current threshold: -30.3733
Global Scale Offset: 3.3854
Reward stats: mean=-0.0045, std=0.1459, count=153
----------------------------------------------
SAC Update - Actor Loss: -0.0021, Q1 Loss: 2.1844, Q2 Loss: 2.1844, Entropy: 0.2796, Mean TD Error: 1.7557, Threshold: -30.3733
tensor([ 0.1380,  0.5234,  0.4086,  0.9734, -0.1178,  0.7669,  0.7360,  0.8679,
         1.4669,  0.3528,  0.1122,  0.9097,  0.0496, -0.0203, -0.5444, -4.5570],
       device='cuda:0')
Original likelihood: -34.33054733276367
Adjusted likelihood: -34.33054733276367
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.1910)
State is out of distribution
Projection step: 0, Loss: 34.571083068847656
Projection step: 1, Loss: 32.373779296875
Projection step: 2, Loss: 30.415443420410156
Projection step: 3, Loss: 29.77410125732422
Projection step: 4, Loss: 27.679290771484375
Projection step: 5, Loss: 27.206159591674805
Projection step: 6, Loss: 26.77442169189453
Projection step: 7, Loss: 25.56589126586914
Projection step: 8, Loss: 27.36374282836914
Projection step: 9, Loss: 23.443443298339844
Projection step: 10, Loss: 23.228267669677734
Projection step: 11, Loss: 21.60439109802246
Projection step: 12, Loss: 21.79150390625
Projection step: 13, Loss: 21.14887046813965
Projection step: 14, Loss: 21.36634063720703
Final likelihood: tensor([-17.6149, -21.3669, -18.9064, -17.3956, -19.3848, -19.8124, -19.9721,
        -17.2277, -20.0134, -19.7101, -21.7685, -21.0064, -20.6711, -16.1536,
        -22.2508, -22.7301])
Final projection likelihood: -19.7490
1 mode projection succeeded
New goal: tensor([ 0.0947,  0.5180,  0.5631,  0.8218, -0.0539,  0.5905,  0.8727,  0.8213,
         1.3512,  0.3239,  0.1418,  1.1831,  0.0394, -0.0130, -1.6055],
       device='cuda:0')
tensor([[0.0027]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0069]], device='cuda:0')
Original likelihood: -33.822425842285156
Adjusted likelihood: -33.822425842285156
Likelihood residual: 0.0
{'index': 33.822425842285156, 'thumb_middle': inf}
Current yaw: tensor([ 0.0496, -0.0203, -0.5444], device='cuda:0')
14 index
tensor([ 0.1380,  0.5234,  0.4086,  0.9734, -0.1178,  0.7669,  0.7360,  0.8679,
         1.4669,  0.3528,  0.1122,  0.9097,  0.0496, -0.0203, -0.5444, -4.5570],
       device='cuda:0')
Solve time for step 1 10.782439427042846
Current ori: tensor([ 0.0496, -0.0203, -0.5444], device='cuda:0')
Middle force: tensor([0.5562, 0.5144, 0.5806, 0.5365], device='cuda:0')
Thumb force: tensor([0.5122, 0.5258, 0.5936, 0.5708], device='cuda:0')
tensor([ 0.1663,  0.4670,  0.4864,  0.8317, -0.1305,  0.7325,  0.9022,  0.8541,
         1.4885,  0.3622,  0.0788,  1.0265,  0.1256, -0.0402, -0.5660, -3.2987],
       device='cuda:0')
Solve time for step 2 2.234874668007251
Current ori: tensor([ 0.1256, -0.0402, -0.5660], device='cuda:0')
Middle force: tensor([0.5137, 0.5783, 0.5349], device='cuda:0')
Thumb force: tensor([0.5246, 0.5912, 0.5688], device='cuda:0')
tensor([ 0.1635,  0.4662,  0.5040,  0.8009, -0.1406,  0.7806,  0.9402,  0.8402,
         1.5000,  0.3825,  0.0757,  1.0396,  0.2726, -0.1122, -0.5654, -1.7117],
       device='cuda:0')
Solve time for step 3 2.1129782799980603
Current ori: tensor([ 0.2726, -0.1122, -0.5654], device='cuda:0')
Middle force: tensor([0.5067, 0.5380], device='cuda:0')
Thumb force: tensor([0.6207, 0.5458], device='cuda:0')
tensor([ 0.1457,  0.4406,  0.5193,  0.7969, -0.1135,  0.8772,  0.9623,  0.7979,
         1.5000,  0.3767,  0.1211,  1.0109,  0.3580, -0.2703, -0.4305,  0.9061],
       device='cuda:0')
Solve time for step 4 2.0334442229941487
Current ori: tensor([ 0.3580, -0.2703, -0.4305], device='cuda:0')
Middle force: tensor([0.5862], device='cuda:0')
Thumb force: tensor([0.5434], device='cuda:0')
Storing RECOVERY transition: reward=-0.2445 (scaled=-0.1222), steps=2
Reward stats updated: mean -0.0045 -> -0.0052, std: 0.1458
Collected 154 transitions for RL
SAC Update 1/5: Actor Loss=-0.0010, Q1 Loss=4.4656, Q2 Loss=4.4656, Entropy=0.3819, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5702
SAC Update 2/5: Actor Loss=-0.0008, Q1 Loss=0.5820, Q2 Loss=0.5820, Entropy=0.3681, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5151
SAC Update 3/5: Actor Loss=-0.0013, Q1 Loss=3.0688, Q2 Loss=3.0688, Entropy=0.2347, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=2.2291
SAC Update 4/5: Actor Loss=-0.0004, Q1 Loss=0.8745, Q2 Loss=0.8745, Entropy=0.1051, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4226
SAC Update 5/5: Actor Loss=-0.0006, Q1 Loss=1.0336, Q2 Loss=1.0336, Entropy=0.2384, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4266

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.04s (19.1%)
Q1 update: 0.04s (19.7%)
Q2 update: 0.04s (18.3%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.2%)
Actor loss: -0.000790
Q1 loss: 2.004897
Q2 loss: 2.004897
Current threshold: -30.3722
Global Scale Offset: 3.4600
Reward stats: mean=-0.0052, std=0.1458, count=154
----------------------------------------------
SAC Update - Actor Loss: -0.0008, Q1 Loss: 2.0049, Q2 Loss: 2.0049, Entropy: 0.2656, Mean TD Error: 2.0327, Threshold: -30.3722
Original likelihood: -186.3797607421875
Adjusted likelihood: -186.3797607421875
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 211.55642700195312
Projection step: 1, Loss: 188.04202270507812
Projection step: 2, Loss: 196.73980712890625
Projection step: 3, Loss: 195.6421356201172
Projection step: 4, Loss: 191.01776123046875
Projection step: 5, Loss: 200.47357177734375
Projection step: 6, Loss: 207.46551513671875
Projection step: 7, Loss: 194.74525451660156
Projection step: 8, Loss: 177.1480712890625
Projection step: 9, Loss: 197.28550720214844
Projection step: 10, Loss: 206.05776977539062
Projection step: 11, Loss: 179.96376037597656
Projection step: 12, Loss: 200.3572235107422
Projection step: 13, Loss: 205.55465698242188
Projection step: 14, Loss: 222.4419708251953
Final likelihood: tensor([-162.1486, -185.3387, -229.6811, -143.4351, -185.0422, -157.6835,
        -191.2988, -228.5504, -218.7148, -120.5859, -115.4295, -302.8086,
        -177.5480, -157.8926, -219.9211, -259.4418])
Final projection likelihood: -190.9700
1 mode projection failed, trying anyway
New goal: tensor([ 0.2286,  0.7021,  0.7645,  0.9384, -0.1779,  0.9601,  1.0883,  0.9826,
         1.4356,  0.4012,  0.1397,  1.1594,  0.3573, -0.2680, -0.4599],
       device='cuda:0')
tensor([[0.0019]], device='cuda:0') tensor([[0.0102]], device='cuda:0') tensor([[0.0062]], device='cuda:0')
Original likelihood: -162.67930603027344
Adjusted likelihood: -162.67930603027344
Likelihood residual: 0.0
Original likelihood: -236.25567626953125
Adjusted likelihood: -236.25567626953125
Likelihood residual: 0.0
{'index': 236.25567626953125, 'thumb_middle': 162.67930603027344}
Current yaw: tensor([ 0.3572, -0.2678, -0.4427], device='cuda:0')
15 thumb_middle
tensor([ 0.2025,  0.6987,  0.7864,  0.9531, -0.1889,  0.9867,  1.1089,  0.8915,
         1.4999,  0.3842,  0.1351,  1.1273,  0.3572, -0.2678, -0.4427,  1.6402],
       device='cuda:0')
Solve time for step 1 9.113070504041389
Current ori: tensor([ 0.3572, -0.2678, -0.4427], device='cuda:0')
Index force: tensor([0.5994, 0.5953, 0.5697, 0.5997], device='cuda:0')
tensor([ 0.1897,  0.8359,  0.7828,  0.9438, -0.1767,  0.9644,  1.0538,  0.9335,
         1.3229,  0.4336, -0.0113,  1.1548,  0.3807, -0.3535, -0.2580,  1.7967],
       device='cuda:0')
Solve time for step 2 1.9569056460168213
Current ori: tensor([ 0.3807, -0.3535, -0.2580], device='cuda:0')
Index force: tensor([0.5971, 0.6001, 0.5984], device='cuda:0')
tensor([ 0.0881,  0.8922,  0.7837,  0.9403, -0.1708,  1.0014,  1.0687,  0.9555,
         1.3147,  0.4393, -0.0424,  1.1618,  0.3830, -0.3604, -0.2269,  3.0894],
       device='cuda:0')
Solve time for step 3 1.7962030330090784
Current ori: tensor([ 0.3830, -0.3604, -0.2269], device='cuda:0')
Index force: tensor([0.5951, 0.5934], device='cuda:0')
tensor([-0.0062,  0.8165,  0.7874,  0.9423, -0.1659,  1.0110,  1.0770,  0.9656,
         1.3161,  0.4316, -0.0429,  1.1456,  0.3826, -0.3591, -0.2315,  5.5330],
       device='cuda:0')
Solve time for step 4 1.7788511920371093
Current ori: tensor([ 0.3826, -0.3591, -0.2315], device='cuda:0')
Index force: tensor([0.5711], device='cuda:0')
Storing RECOVERY transition: reward=-0.3522 (scaled=-0.1761), steps=2
Reward stats updated: mean -0.0052 -> -0.0063, std: 0.1459
Collected 155 transitions for RL
SAC Update 1/5: Actor Loss=-0.0020, Q1 Loss=0.6224, Q2 Loss=0.6224, Entropy=0.4657, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7764
SAC Update 2/5: Actor Loss=-0.0020, Q1 Loss=0.6805, Q2 Loss=0.6805, Entropy=0.2387, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1773
SAC Update 3/5: Actor Loss=-0.0015, Q1 Loss=5.5185, Q2 Loss=5.5185, Entropy=0.4298, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.7090
SAC Update 4/5: Actor Loss=-0.0009, Q1 Loss=1.1654, Q2 Loss=1.1654, Entropy=0.1502, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3402
SAC Update 5/5: Actor Loss=-0.0099, Q1 Loss=0.7967, Q2 Loss=0.7967, Entropy=0.5599, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4598

------ SAC Update Summary (5 iterations) ------
Total time: 0.25s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (20.1%)
Q1 update: 0.05s (20.0%)
Q2 update: 0.04s (17.7%)
Actor update: 0.10s (38.9%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003241
Q1 loss: 1.756670
Q2 loss: 1.756670
Current threshold: -30.3722
Global Scale Offset: 3.5511
Reward stats: mean=-0.0063, std=0.1459, count=155
----------------------------------------------
SAC Update - Actor Loss: -0.0032, Q1 Loss: 1.7567, Q2 Loss: 1.7567, Entropy: 0.3689, Mean TD Error: 1.6925, Threshold: -30.3722
Original likelihood: -285.7771301269531
Adjusted likelihood: -285.7771301269531
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 316.3414611816406
Projection step: 1, Loss: 300.99053955078125
Projection step: 2, Loss: 273.626708984375
Projection step: 3, Loss: 301.05938720703125
Projection step: 4, Loss: 305.80096435546875
Projection step: 5, Loss: 295.305908203125
Projection step: 6, Loss: 308.2687683105469
Projection step: 7, Loss: 296.6670837402344
Projection step: 8, Loss: 306.81817626953125
Projection step: 9, Loss: 296.8794860839844
Projection step: 10, Loss: 309.86749267578125
Projection step: 11, Loss: 304.4851989746094
Projection step: 12, Loss: 286.7540588378906
Projection step: 13, Loss: 286.265625
Projection step: 14, Loss: 292.82427978515625
Final likelihood: tensor([-244.7127, -309.1106, -235.6633, -351.0746, -268.0759, -320.0788,
        -305.0797, -236.3354, -331.3612, -282.1595, -275.5679, -296.7122,
        -270.3237, -311.2778, -307.8430, -305.6631])
Final projection likelihood: -290.6900
1 mode projection failed, trying anyway
New goal: tensor([-0.0671,  0.8066,  0.7970,  0.9423, -0.1635,  1.0799,  1.1231,  1.0135,
         1.3724,  0.4077,  0.0403,  1.1343,  0.3680, -0.3185, -0.3037],
       device='cuda:0')
tensor([[0.0021]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0048]], device='cuda:0')
Original likelihood: -298.4128112792969
Adjusted likelihood: -298.4128112792969
Likelihood residual: 0.0
{'index': 298.4128112792969, 'thumb_middle': inf}
Current yaw: tensor([ 0.3678, -0.3171, -0.3386], device='cuda:0')
16 index
tensor([-0.0814,  0.8064,  0.7837,  0.9371, -0.1640,  1.0789,  1.1362,  0.9990,
         1.3955,  0.3964,  0.0443,  1.1240,  0.3678, -0.3171, -0.3386,  5.5064],
       device='cuda:0')
Solve time for step 1 10.474060793989338
Current ori: tensor([ 0.3678, -0.3171, -0.3386], device='cuda:0')
Middle force: tensor([0.6745, 0.5165, 0.6489, 0.5596], device='cuda:0')
Thumb force: tensor([0.5838, 0.5921, 0.6668, 0.5633], device='cuda:0')
tensor([ 0.0447,  0.8837,  0.8219,  0.9449, -0.1199,  1.1076,  1.1008,  0.9391,
         1.3842,  0.4407,  0.0444,  1.1320,  0.3482, -0.3313, -0.2343,  3.9391],
       device='cuda:0')
Solve time for step 2 2.222077618003823
Current ori: tensor([ 0.3482, -0.3313, -0.2343], device='cuda:0')
Middle force: tensor([0.6762, 0.6115, 0.5932], device='cuda:0')
Thumb force: tensor([0.6694, 0.5553, 0.5938], device='cuda:0')
tensor([ 0.0242,  0.9075,  0.8263,  0.9408, -0.1180,  1.1031,  1.0977,  0.9250,
         1.3770,  0.4754,  0.1148,  1.1353,  0.3462, -0.3219, -0.1821,  4.0460],
       device='cuda:0')
Solve time for step 3 2.099093033990357
Current ori: tensor([ 0.3462, -0.3219, -0.1821], device='cuda:0')
Middle force: tensor([0.6059, 0.5921], device='cuda:0')
Thumb force: tensor([0.5520, 0.5959], device='cuda:0')
tensor([-0.0142,  0.9164,  0.8316,  0.9508, -0.1048,  1.1080,  1.0927,  0.8812,
         1.3834,  0.4357,  0.1100,  1.1319,  0.3357, -0.3177, -0.1238,  4.8516],
       device='cuda:0')
Solve time for step 4 2.3081853150506504
Current ori: tensor([ 0.3357, -0.3177, -0.1238], device='cuda:0')
Middle force: tensor([0.7186], device='cuda:0')
Thumb force: tensor([0.7392], device='cuda:0')
Storing RECOVERY transition: reward=-0.4814 (scaled=-0.2407), steps=2
Reward stats updated: mean -0.0063 -> -0.0078, std: 0.1467
Collected 156 transitions for RL
SAC Update 1/5: Actor Loss=-0.0031, Q1 Loss=0.7853, Q2 Loss=0.7853, Entropy=0.4200, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3513
SAC Update 2/5: Actor Loss=-0.0024, Q1 Loss=0.7109, Q2 Loss=0.7109, Entropy=0.3891, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7515
SAC Update 3/5: Actor Loss=-0.0014, Q1 Loss=0.7779, Q2 Loss=0.7779, Entropy=0.3014, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7321
SAC Update 4/5: Actor Loss=-0.0053, Q1 Loss=25.1496, Q2 Loss=25.1496, Entropy=0.5385, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=6.0324
SAC Update 5/5: Actor Loss=-0.0060, Q1 Loss=1.2001, Q2 Loss=1.2001, Entropy=0.6303, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2724

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.3%)
Q1 update: 0.05s (19.4%)
Q2 update: 0.05s (18.2%)
Actor update: 0.10s (40.6%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003619
Q1 loss: 5.724744
Q2 loss: 5.724744
Current threshold: -30.3806
Global Scale Offset: 3.6588
Reward stats: mean=-0.0078, std=0.1467, count=156
----------------------------------------------
SAC Update - Actor Loss: -0.0036, Q1 Loss: 5.7247, Q2 Loss: 5.7247, Entropy: 0.4559, Mean TD Error: 2.6279, Threshold: -30.3806
Original likelihood: -255.91494750976562
Adjusted likelihood: -255.91494750976562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 274.6524658203125
Projection step: 1, Loss: 275.33587646484375
Projection step: 2, Loss: 253.7707061767578
Projection step: 3, Loss: 279.6163330078125
Projection step: 4, Loss: 278.0057067871094
Projection step: 5, Loss: 261.2098693847656
Projection step: 6, Loss: 265.63446044921875
Projection step: 7, Loss: 249.39251708984375
Projection step: 8, Loss: 278.7287292480469
Projection step: 9, Loss: 247.49856567382812
Projection step: 10, Loss: 262.62335205078125
Projection step: 11, Loss: 265.7139892578125
Projection step: 12, Loss: 274.85980224609375
Projection step: 13, Loss: 255.44161987304688
Projection step: 14, Loss: 278.6067199707031
Final likelihood: tensor([-220.6986, -334.7308, -299.2716, -229.0969, -239.4226, -326.2778,
        -304.0743, -261.4523, -295.0782, -224.2289, -202.2328, -279.2794,
        -323.3882, -235.0101, -236.5703, -246.6945])
Final projection likelihood: -266.0942
1 mode projection failed, trying anyway
New goal: tensor([-0.0781,  0.9113,  0.8527,  0.9581, -0.1777,  1.0678,  1.1097,  1.0619,
         1.3583,  0.4252,  0.1475,  1.1481,  0.3642, -0.3027, -0.1630],
       device='cuda:0')
tensor([[0.0020]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0038]], device='cuda:0')
Original likelihood: -275.85198974609375
Adjusted likelihood: -275.85198974609375
Likelihood residual: 0.0
{'index': 275.85198974609375, 'thumb_middle': inf}
Current yaw: tensor([ 0.3636, -0.3010, -0.1794], device='cuda:0')
17 index
tensor([-0.1043,  0.9142,  0.8346,  0.9513, -0.1790,  1.0675,  1.1225,  1.0302,
         1.3899,  0.4122,  0.1487,  1.1318,  0.3636, -0.3010, -0.1794,  4.7126],
       device='cuda:0')
Solve time for step 1 10.30564899201272
Current ori: tensor([ 0.3636, -0.3010, -0.1794], device='cuda:0')
Middle force: tensor([0.6167, 0.6177, 0.6546, 0.7583], device='cuda:0')
Thumb force: tensor([0.5742, 0.5349, 0.6864, 0.7501], device='cuda:0')
tensor([-0.0520,  0.9644,  0.8653,  0.9593, -0.1310,  1.1020,  1.0763,  0.9758,
         1.3788,  0.4665,  0.1720,  1.1454,  0.3513, -0.3092, -0.0864,  4.1714],
       device='cuda:0')
Solve time for step 2 2.134464474976994
Current ori: tensor([ 0.3513, -0.3092, -0.0864], device='cuda:0')
Middle force: tensor([0.6121, 0.6573, 0.7685], device='cuda:0')
Thumb force: tensor([0.5292, 0.6832, 0.7570], device='cuda:0')
tensor([-0.0751,  0.9700,  0.8754,  0.9633, -0.1243,  1.1131,  1.0548,  0.9704,
         1.3847,  0.4395,  0.1756,  1.1338,  0.3522, -0.3033, -0.0799,  4.3535],
       device='cuda:0')
Solve time for step 3 2.0717692050384358
Current ori: tensor([ 0.3522, -0.3033, -0.0799], device='cuda:0')
Middle force: tensor([0.5804, 0.6744], device='cuda:0')
Thumb force: tensor([0.6119, 0.5485], device='cuda:0')
tensor([-0.0454,  0.9607,  0.8795,  0.9626, -0.1130,  1.1139,  1.0703,  0.9226,
         1.3836,  0.4450,  0.1784,  1.1412,  0.3523, -0.3037, -0.0781,  4.5900],
       device='cuda:0')
Solve time for step 4 2.021160318981856
Current ori: tensor([ 0.3523, -0.3037, -0.0781], device='cuda:0')
Middle force: tensor([0.6341], device='cuda:0')
Thumb force: tensor([0.5664], device='cuda:0')
Storing RECOVERY transition: reward=-0.4660 (scaled=-0.2330), steps=2
Reward stats updated: mean -0.0078 -> -0.0093, std: 0.1473
Collected 157 transitions for RL
SAC Update 1/5: Actor Loss=-0.0053, Q1 Loss=24.6042, Q2 Loss=24.6042, Entropy=0.5417, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9708
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=1.0765, Q2 Loss=1.0765, Entropy=0.3882, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4487
SAC Update 3/5: Actor Loss=-0.0020, Q1 Loss=1.0529, Q2 Loss=1.0529, Entropy=0.2658, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4150
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=4.0119, Q2 Loss=4.0119, Entropy=0.3984, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5147
SAC Update 5/5: Actor Loss=-0.0061, Q1 Loss=1.3008, Q2 Loss=1.3008, Entropy=0.4940, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0767

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (17.7%)
Q1 update: 0.04s (19.1%)
Q2 update: 0.04s (18.6%)
Actor update: 0.09s (40.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003207
Q1 loss: 6.409288
Q2 loss: 6.409288
Current threshold: -30.3964
Global Scale Offset: 3.8044
Reward stats: mean=-0.0093, std=0.1473, count=157
----------------------------------------------
SAC Update - Actor Loss: -0.0032, Q1 Loss: 6.4093, Q2 Loss: 6.4093, Entropy: 0.4176, Mean TD Error: 2.8852, Threshold: -30.3964
Original likelihood: -224.35678100585938
Adjusted likelihood: -224.35678100585938
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Projection step: 0, Loss: 240.7802734375
Projection step: 1, Loss: 241.2160186767578
Projection step: 2, Loss: 242.64718627929688
Projection step: 3, Loss: 240.3238983154297
Projection step: 4, Loss: 235.97589111328125
Projection step: 5, Loss: 232.3115234375
Projection step: 6, Loss: 234.5732421875
Projection step: 7, Loss: 230.71104431152344
Projection step: 8, Loss: 250.9700927734375
Projection step: 9, Loss: 238.76541137695312
Projection step: 10, Loss: 242.46746826171875
Projection step: 11, Loss: 243.28175354003906
Projection step: 12, Loss: 228.23007202148438
Projection step: 13, Loss: 223.87173461914062
Projection step: 14, Loss: 261.465576171875
Final likelihood: tensor([-289.6130, -269.8791, -244.3988, -278.2910, -225.9405, -235.0163,
        -241.6448, -273.2212, -306.2225, -255.5630, -295.2151, -214.1150,
        -294.1400, -273.1443, -285.0966, -235.0480])
Final projection likelihood: -263.5343
1 mode projection failed, trying anyway
New goal: tensor([-0.0829,  0.9466,  0.8887,  0.9699, -0.1594,  1.0776,  1.0723,  1.0812,
         1.3605,  0.4820,  0.2204,  1.1613,  0.3606, -0.2907, -0.2281],
       device='cuda:0')
tensor([[0.0020]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0035]], device='cuda:0')
Original likelihood: -273.4287109375
Adjusted likelihood: -273.4287109375
Likelihood residual: 0.0
{'index': 273.4287109375, 'thumb_middle': inf}
Current yaw: tensor([ 0.3598, -0.2891, -0.1912], device='cuda:0')
18 index
tensor([-0.1182,  0.9576,  0.8828,  0.9675, -0.1632,  1.0819,  1.0744,  1.0279,
         1.3985,  0.4675,  0.2191,  1.1369,  0.3598, -0.2891, -0.1912,  4.5657],
       device='cuda:0')
Solve time for step 1 10.045593408984132
Current ori: tensor([ 0.3598, -0.2891, -0.1912], device='cuda:0')
Middle force: tensor([0.5392, 0.6013, 0.6006, 0.5990], device='cuda:0')
Thumb force: tensor([0.5589, 0.6008, 0.5987, 0.5470], device='cuda:0')
tensor([-0.0165,  0.9706,  0.9112,  0.9778, -0.1287,  1.1273,  1.0302,  0.9737,
         1.3956,  0.4670,  0.1705,  1.1540,  0.3636, -0.3005, -0.1612,  4.4326],
       device='cuda:0')
Solve time for step 2 2.1590986009687185
Current ori: tensor([ 0.3636, -0.3005, -0.1612], device='cuda:0')
Middle force: tensor([0.5968, 0.5996, 0.6007], device='cuda:0')
Thumb force: tensor([0.5950, 0.5939, 0.5497], device='cuda:0')
tensor([-0.0176,  0.9938,  0.9187,  0.9750, -0.1197,  1.1591,  1.0108,  0.9477,
         1.3872,  0.4761,  0.1547,  1.1553,  0.3660, -0.3077, -0.1498,  4.5148],
       device='cuda:0')
Solve time for step 3 2.2351229100022465
Current ori: tensor([ 0.3660, -0.3077, -0.1498], device='cuda:0')
Middle force: tensor([0.5633, 0.6751], device='cuda:0')
Thumb force: tensor([0.5259, 0.6460], device='cuda:0')
tensor([-0.0683,  1.0440,  0.9018,  0.9674, -0.1273,  1.1786,  1.0094,  0.9135,
         1.3759,  0.5158,  0.1559,  1.1516,  0.3689, -0.3158, -0.1511,  4.5543],
       device='cuda:0')
Solve time for step 4 2.120027497992851
Current ori: tensor([ 0.3689, -0.3158, -0.1511], device='cuda:0')
Middle force: tensor([0.6616], device='cuda:0')
Thumb force: tensor([0.6370], device='cuda:0')
Storing RECOVERY transition: reward=-0.4925 (scaled=-0.2462), steps=2
Reward stats updated: mean -0.0093 -> -0.0108, std: 0.1480
Collected 158 transitions for RL
SAC Update 1/5: Actor Loss=-0.0018, Q1 Loss=0.6476, Q2 Loss=0.6476, Entropy=0.4058, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1934
SAC Update 2/5: Actor Loss=-0.0056, Q1 Loss=23.5271, Q2 Loss=23.5271, Entropy=0.5527, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.9756
SAC Update 3/5: Actor Loss=-0.0127, Q1 Loss=0.7660, Q2 Loss=0.7660, Entropy=0.5670, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8577
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.5959, Q2 Loss=0.5959, Entropy=0.2649, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5292
SAC Update 5/5: Actor Loss=-0.0002, Q1 Loss=1.8358, Q2 Loss=1.8358, Entropy=0.2974, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.2504

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.7%)
Target Q: 0.05s (18.0%)
Q1 update: 0.05s (20.6%)
Q2 update: 0.05s (18.4%)
Actor update: 0.10s (39.6%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004104
Q1 loss: 5.474481
Q2 loss: 5.474481
Current threshold: -30.4069
Global Scale Offset: 3.9316
Reward stats: mean=-0.0108, std=0.1480, count=158
----------------------------------------------
SAC Update - Actor Loss: -0.0041, Q1 Loss: 5.4745, Q2 Loss: 5.4745, Entropy: 0.4175, Mean TD Error: 2.5613, Threshold: -30.4069
Original likelihood: -308.5913391113281
Adjusted likelihood: -308.5913391113281
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0000)
State is out of distribution
Probably dropped the object
Marked last transition as done (episode completed)
Marked last transition as done (final step)
{}

Trial 9
Loaded trajectory sampler
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:0')
Current yaw: tensor([-0.0019,  0.0146, -0.0309], device='cuda:0')
1 turn
Sampling time 3.8835484589799307
tensor([ 0.1338,  0.5654,  0.6012,  0.6304, -0.1291,  0.5611,  0.8831,  0.9109,
         1.2150,  0.3369,  0.2412,  1.1999, -0.0019,  0.0146, -0.0309,  0.2367],
       device='cuda:0')
Original likelihood: -19.430809020996094
Adjusted likelihood: -19.430809020996094
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9843)
Solve time for step 1 14.684274544997606
Current ori: tensor([-0.0019,  0.0146, -0.0309], device='cuda:0')
Middle force: tensor([0.5737, 0.6711, 0.8251, 1.3909, 0.5041, 0.6191, 0.4914, 0.5533, 0.6599,
        0.4975, 0.5779, 0.5946], device='cuda:0')
Thumb force: tensor([0.5733, 0.7062, 1.1354, 1.2704, 1.7991, 0.5983, 0.5726, 0.5336, 0.5925,
        0.9988, 0.5231, 0.5969], device='cuda:0')
Index force: tensor([0.6032, 0.5575, 0.5812, 0.8541, 0.6754, 0.5487, 0.7722, 0.5138, 0.5930,
        0.6795, 0.5896, 0.6273], device='cuda:0')
Storing NORMAL transition: reward=-0.0001 (scaled=-0.0001), steps=1
Reward stats updated: mean -0.0108 -> -0.0107, std: 0.1476
Collected 159 transitions for RL
SAC Update 1/5: Actor Loss=-0.0056, Q1 Loss=0.9744, Q2 Loss=0.9744, Entropy=0.5025, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6719
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=0.9413, Q2 Loss=0.9413, Entropy=0.1885, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6477
SAC Update 3/5: Actor Loss=-0.0055, Q1 Loss=1.2737, Q2 Loss=1.2737, Entropy=0.3512, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8702
SAC Update 4/5: Actor Loss=-0.0028, Q1 Loss=1.1277, Q2 Loss=1.1277, Entropy=0.3768, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5467
SAC Update 5/5: Actor Loss=-0.0009, Q1 Loss=0.7654, Q2 Loss=0.7654, Entropy=0.2724, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7661

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.5%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (19.2%)
Q2 update: 0.04s (19.0%)
Actor update: 0.09s (41.2%)
Target update: 0.00s (1.4%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003148
Q1 loss: 1.016516
Q2 loss: 1.016516
Current threshold: -30.4164
Global Scale Offset: 4.0523
Reward stats: mean=-0.0107, std=0.1476, count=159
----------------------------------------------
SAC Update - Actor Loss: -0.0031, Q1 Loss: 1.0165, Q2 Loss: 1.0165, Entropy: 0.3383, Mean TD Error: 0.7005, Threshold: -30.4164
tensor([ 0.1509,  0.4733,  0.7181,  0.6741, -0.1899,  0.5510,  0.8594,  0.9251,
         1.1471,  0.3544,  0.1386,  1.3094,  0.0166,  0.0053, -0.0309,  0.5724],
       device='cuda:0')
Original likelihood: -34.03105926513672
Adjusted likelihood: -34.03105926513672
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.2447)
State is out of distribution
Projection step: 0, Loss: 34.28520965576172
Projection step: 1, Loss: 32.39353942871094
Projection step: 2, Loss: 26.86557388305664
Projection step: 3, Loss: 22.918651580810547
Projection step: 4, Loss: 19.253982543945312
Projection step: 5, Loss: 17.26152992248535
Projection step: 6, Loss: 16.03272247314453
Projection step: 7, Loss: 14.959457397460938
Final likelihood: tensor([-11.5857,  -9.5802, -13.5076, -17.2767, -14.6353, -17.7657, -13.3805,
        -17.0037, -13.8274, -15.5297, -15.7777, -12.0576, -19.7181, -15.5627,
        -14.6565, -17.4862])
Final projection likelihood: -14.9595
1 mode projection succeeded
New goal: tensor([ 0.1005,  0.5058,  0.6243,  0.6695, -0.0726,  0.5552,  0.8852,  0.8536,
         1.2897,  0.3584,  0.2091,  1.1771,  0.0134,  0.0106,  0.1594],
       device='cuda:0')
tensor([[0.0125]], device='cuda:0') tensor([[0.0083]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -15.684659957885742
Adjusted likelihood: -15.684660911560059
Likelihood residual: -9.5367431640625e-07
{'index': inf, 'thumb_middle': 15.684660911560059}
Current yaw: tensor([ 0.0166,  0.0053, -0.0309], device='cuda:0')
2 thumb_middle
tensor([ 0.1509,  0.4733,  0.7181,  0.6741, -0.1899,  0.5510,  0.8594,  0.9251,
         1.1471,  0.3544,  0.1386,  1.3094,  0.0166,  0.0053, -0.0309,  0.5724],
       device='cuda:0')
Solve time for step 1 9.259620683034882
Current ori: tensor([ 0.0166,  0.0053, -0.0309], device='cuda:0')
Index force: tensor([0.5659, 0.5930, 0.5774, 0.5634], device='cuda:0')
tensor([ 0.1441,  0.4925,  0.6740,  0.6995, -0.1963,  0.5239,  0.8398,  0.8338,
         1.2185,  0.3486,  0.1075,  1.1742,  0.0139,  0.0086, -0.0309,  0.5680],
       device='cuda:0')
Solve time for step 2 1.9730156040168367
Current ori: tensor([ 0.0139,  0.0086, -0.0309], device='cuda:0')
Index force: tensor([0.5874, 0.5745, 0.5605], device='cuda:0')
tensor([ 0.1127,  0.5054,  0.6367,  0.6784, -0.2141,  0.5231,  0.8349,  0.8275,
         1.2568,  0.3355,  0.1081,  1.1399,  0.0087,  0.0252, -0.0309,  0.5180],
       device='cuda:0')
Solve time for step 3 1.8030771320336498
Current ori: tensor([ 0.0087,  0.0252, -0.0309], device='cuda:0')
Index force: tensor([0.5698, 0.5576], device='cuda:0')
tensor([ 0.1184,  0.5094,  0.6465,  0.6591, -0.2200,  0.5409,  0.8411,  0.8286,
         1.2610,  0.3306,  0.1063,  1.1223,  0.0062,  0.0217, -0.0309,  0.5191],
       device='cuda:0')
Solve time for step 4 1.8420533849857748
Current ori: tensor([ 0.0062,  0.0217, -0.0309], device='cuda:0')
Index force: tensor([0.5496], device='cuda:0')
Storing RECOVERY transition: reward=-0.0143 (scaled=-0.0143), steps=1
Reward stats updated: mean -0.0107 -> -0.0107, std: 0.1471
Collected 160 transitions for RL
SAC Update 1/5: Actor Loss=-0.0019, Q1 Loss=0.8207, Q2 Loss=0.8207, Entropy=0.3205, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4316
SAC Update 2/5: Actor Loss=-0.0046, Q1 Loss=0.9796, Q2 Loss=0.9796, Entropy=0.5506, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5536
SAC Update 3/5: Actor Loss=-0.0095, Q1 Loss=0.7792, Q2 Loss=0.7792, Entropy=0.6087, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8932
SAC Update 4/5: Actor Loss=-0.0003, Q1 Loss=0.5919, Q2 Loss=0.5919, Entropy=0.2838, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1656
SAC Update 5/5: Actor Loss=-0.0033, Q1 Loss=1.6576, Q2 Loss=1.6576, Entropy=0.4278, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3628

------ SAC Update Summary (5 iterations) ------
Total time: 0.28s, Avg iteration: 0.06s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.7%)
Q1 update: 0.06s (20.6%)
Q2 update: 0.06s (20.7%)
Actor update: 0.12s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003919
Q1 loss: 0.965800
Q2 loss: 0.965800
Current threshold: -30.4225
Global Scale Offset: 4.1829
Reward stats: mean=-0.0107, std=0.1471, count=160
----------------------------------------------
SAC Update - Actor Loss: -0.0039, Q1 Loss: 0.9658, Q2 Loss: 0.9658, Entropy: 0.4383, Mean TD Error: 0.6814, Threshold: -30.4225
Original likelihood: -24.988739013671875
Adjusted likelihood: -24.988739013671875
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8444)
Current yaw: tensor([ 0.0150,  0.0342, -0.0176], device='cuda:0')
3 turn
Sampling time 3.7181845390005037
tensor([ 0.0933,  0.4861,  0.6392,  0.6887, -0.1640,  0.5668,  0.8656,  0.8410,
         1.3273,  0.3519,  0.1648,  1.1676,  0.0150,  0.0342, -0.0176,  0.4308],
       device='cuda:0')
Original likelihood: -25.162395477294922
Adjusted likelihood: -25.162395477294922
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.8365)
Solve time for step 1 14.2111051089596
Current ori: tensor([ 0.0150,  0.0342, -0.0176], device='cuda:0')
Middle force: tensor([0.6441, 0.9084, 0.5780, 0.5017, 0.5099, 0.7370, 0.5038, 0.5031, 0.5989,
        0.5662, 0.5693, 0.5116], device='cuda:0')
Thumb force: tensor([1.3347, 1.7119, 0.6665, 0.7237, 0.8655, 1.9498, 0.7419, 0.5557, 1.1410,
        0.7249, 1.2376, 0.5740], device='cuda:0')
Index force: tensor([1.0693, 1.4732, 0.9082, 0.7943, 1.3367, 0.7969, 0.5105, 0.7192, 0.6670,
        0.5874, 0.6160, 0.5023], device='cuda:0')
Storing NORMAL transition: reward=-0.1182 (scaled=-0.1182), steps=1
Reward stats updated: mean -0.0107 -> -0.0114, std: 0.1469
Collected 161 transitions for RL
SAC Update 1/5: Actor Loss=-0.0153, Q1 Loss=2.2714, Q2 Loss=2.2714, Entropy=0.5648, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3486
SAC Update 2/5: Actor Loss=-0.0015, Q1 Loss=0.7988, Q2 Loss=0.7988, Entropy=0.2143, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5803
SAC Update 3/5: Actor Loss=-0.0026, Q1 Loss=0.6559, Q2 Loss=0.6559, Entropy=0.4791, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6266
SAC Update 4/5: Actor Loss=-0.0066, Q1 Loss=1.0460, Q2 Loss=1.0460, Entropy=0.5457, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7441
SAC Update 5/5: Actor Loss=-0.0004, Q1 Loss=0.9737, Q2 Loss=0.9737, Entropy=0.1978, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3399

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.4%)
Q1 update: 0.05s (18.9%)
Q2 update: 0.05s (19.4%)
Actor update: 0.09s (38.7%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.005255
Q1 loss: 1.149161
Q2 loss: 1.149161
Current threshold: -30.4203
Global Scale Offset: 4.2647
Reward stats: mean=-0.0114, std=0.1469, count=161
----------------------------------------------
SAC Update - Actor Loss: -0.0053, Q1 Loss: 1.1492, Q2 Loss: 1.1492, Entropy: 0.4003, Mean TD Error: 1.7279, Threshold: -30.4203
tensor([ 0.1325,  0.5226,  0.6155,  0.7206, -0.1030,  0.6436,  0.7925,  0.7599,
         1.3791,  0.1884,  0.1645,  1.0930,  0.0097,  0.0116,  0.1018,  0.3683],
       device='cuda:0')
Original likelihood: -21.03470230102539
Adjusted likelihood: -21.03470230102539
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9575)
Solve time for step 2 2.884482369001489
Current ori: tensor([0.0097, 0.0116, 0.1018], device='cuda:0')
Middle force: tensor([0.9115, 0.5738, 0.5013, 0.5089, 0.7335, 0.5036, 0.5023, 0.5995, 0.5656,
        0.5661, 0.5111], device='cuda:0')
Thumb force: tensor([1.6779, 0.6635, 0.7292, 0.8618, 1.9298, 0.7352, 0.5656, 1.1268, 0.7203,
        1.2273, 0.5739], device='cuda:0')
Index force: tensor([1.4662, 0.9099, 0.8008, 1.3349, 0.7923, 0.5104, 0.7415, 0.6660, 0.5860,
        0.6172, 0.5022], device='cuda:0')
Storing NORMAL transition: reward=-0.0133 (scaled=-0.0133), steps=1
Reward stats updated: mean -0.0114 -> -0.0114, std: 0.1464
Collected 162 transitions for RL
SAC Update 1/5: Actor Loss=-0.0027, Q1 Loss=0.7170, Q2 Loss=0.7170, Entropy=0.5250, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8438
SAC Update 2/5: Actor Loss=-0.0052, Q1 Loss=0.7503, Q2 Loss=0.7503, Entropy=0.6437, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5702
SAC Update 3/5: Actor Loss=-0.0022, Q1 Loss=0.8968, Q2 Loss=0.8968, Entropy=0.3715, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2140
SAC Update 4/5: Actor Loss=-0.0011, Q1 Loss=1.0204, Q2 Loss=1.0204, Entropy=0.2058, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.0559
SAC Update 5/5: Actor Loss=-0.0022, Q1 Loss=0.6967, Q2 Loss=0.6967, Entropy=0.4798, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3779

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.9%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (42.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002699
Q1 loss: 0.816227
Q2 loss: 0.816227
Current threshold: -30.4203
Global Scale Offset: 4.3941
Reward stats: mean=-0.0114, std=0.1464, count=162
----------------------------------------------
SAC Update - Actor Loss: -0.0027, Q1 Loss: 0.8162, Q2 Loss: 0.8162, Entropy: 0.4451, Mean TD Error: 0.4124, Threshold: -30.4203
tensor([ 0.1429,  0.5016,  0.6403,  0.7423, -0.0998,  0.6638,  0.7904,  0.7374,
         1.3645,  0.2108,  0.1618,  1.1124,  0.0153,  0.0078,  0.1151,  0.4180],
       device='cuda:0')
Original likelihood: -21.289413452148438
Adjusted likelihood: -21.289413452148438
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.9490)
Solve time for step 3 2.6850466940086335
Current ori: tensor([0.0153, 0.0078, 0.1151], device='cuda:0')
Middle force: tensor([0.5012, 0.5096, 0.5773, 0.5760, 1.0376, 0.7992, 0.7570, 0.5707, 0.5002,
        0.7416], device='cuda:0')
Thumb force: tensor([1.3993, 0.5366, 1.0855, 0.7953, 1.4212, 0.5680, 0.7516, 0.6485, 0.5795,
        0.5314], device='cuda:0')
Index force: tensor([0.9050, 0.6369, 0.5579, 0.5387, 0.5775, 0.5139, 0.5827, 0.5673, 0.5748,
        0.5396], device='cuda:0')
Storing NORMAL transition: reward=0.1004 (scaled=0.1004), steps=1
Reward stats updated: mean -0.0114 -> -0.0107, std: 0.1462
Collected 163 transitions for RL
SAC Update 1/5: Actor Loss=-0.0038, Q1 Loss=1.1864, Q2 Loss=1.1864, Entropy=0.4571, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.9682
SAC Update 2/5: Actor Loss=-0.0013, Q1 Loss=1.0800, Q2 Loss=1.0800, Entropy=0.2277, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4760
SAC Update 3/5: Actor Loss=-0.0057, Q1 Loss=0.6511, Q2 Loss=0.6511, Entropy=0.4456, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6300
SAC Update 4/5: Actor Loss=-0.0021, Q1 Loss=1.0971, Q2 Loss=1.0971, Entropy=0.4519, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.4594
SAC Update 5/5: Actor Loss=-0.0010, Q1 Loss=1.6079, Q2 Loss=1.6079, Entropy=0.2378, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0869

------ SAC Update Summary (5 iterations) ------
Total time: 0.27s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (13.7%)
Q1 update: 0.06s (20.8%)
Q2 update: 0.05s (19.9%)
Actor update: 0.12s (42.5%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.002787
Q1 loss: 1.124526
Q2 loss: 1.124526
Current threshold: -30.4158
Global Scale Offset: 4.5672
Reward stats: mean=-0.0107, std=0.1462, count=163
----------------------------------------------
SAC Update - Actor Loss: -0.0028, Q1 Loss: 1.1245, Q2 Loss: 1.1245, Entropy: 0.3641, Mean TD Error: 0.9241, Threshold: -30.4158
tensor([ 0.1560,  0.5075,  0.6142,  0.8089, -0.2354,  0.6933,  0.8113,  0.7789,
         1.3496,  0.7345,  0.1923,  0.9034,  0.0203,  0.0016,  0.0146,  0.5610],
       device='cuda:0')
Original likelihood: -39.21126174926758
Adjusted likelihood: -39.21126174926758
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.0635)
State is out of distribution
Projection step: 0, Loss: 37.66773986816406
Projection step: 1, Loss: 34.92693328857422
Projection step: 2, Loss: 32.28792190551758
Projection step: 3, Loss: 28.649192810058594
Projection step: 4, Loss: 26.210163116455078
Projection step: 5, Loss: 24.17573356628418
Projection step: 6, Loss: 21.887441635131836
Projection step: 7, Loss: 20.375011444091797
Projection step: 8, Loss: 19.448516845703125
Projection step: 9, Loss: 18.681983947753906
Projection step: 10, Loss: 17.048473358154297
Projection step: 11, Loss: 16.425533294677734
Projection step: 12, Loss: 16.660486221313477
Projection step: 13, Loss: 16.252368927001953
Projection step: 14, Loss: 17.17561149597168
Final likelihood: tensor([-14.4340, -14.3220, -13.2630, -18.0906, -14.2584, -15.2312, -12.3472,
        -18.9341, -14.7530, -14.4714, -13.9236, -16.2527, -14.1481, -16.3353,
        -15.2509, -18.3090])
Final projection likelihood: -15.2703
1 mode projection succeeded
New goal: tensor([ 0.1410,  0.4959,  0.6163,  0.7454, -0.0907,  0.5694,  0.9656,  0.8728,
         1.4143,  0.5139,  0.1697,  1.0487,  0.0074,  0.0137,  2.7342],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0096]], device='cuda:0') tensor([[0.0027]], device='cuda:0')
Original likelihood: -18.040420532226562
Adjusted likelihood: -18.040420532226562
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 18.040420532226562}
Current yaw: tensor([0.0203, 0.0016, 0.0146], device='cuda:0')
4 thumb_middle
tensor([ 0.1560,  0.5075,  0.6142,  0.8089, -0.2354,  0.6933,  0.8113,  0.7789,
         1.3496,  0.7345,  0.1923,  0.9034,  0.0203,  0.0016,  0.0146,  0.5610],
       device='cuda:0')
Solve time for step 1 8.909888576949015
Current ori: tensor([0.0203, 0.0016, 0.0146], device='cuda:0')
Index force: tensor([0.5797, 0.5733, 0.5662, 0.5018], device='cuda:0')
tensor([ 0.1540,  0.4944,  0.6403,  0.7840, -0.2223,  0.5501,  0.8788,  0.8064,
         1.3427,  0.5434,  0.0664,  0.9512,  0.0205,  0.0030,  0.0146,  0.5612],
       device='cuda:0')
Solve time for step 2 2.0709313320112415
Current ori: tensor([0.0205, 0.0030, 0.0146], device='cuda:0')
Index force: tensor([0.5674, 0.5603, 0.5003], device='cuda:0')
tensor([ 0.1428,  0.4960,  0.6390,  0.7601, -0.2270,  0.5451,  0.8906,  0.8154,
         1.3495,  0.5258,  0.0422,  0.9889,  0.0175,  0.0086,  0.0146,  0.5416],
       device='cuda:0')
Solve time for step 3 1.824506752018351
Current ori: tensor([0.0175, 0.0086, 0.0146], device='cuda:0')
Index force: tensor([0.5528, 0.5001], device='cuda:0')
tensor([ 0.1266,  0.4842,  0.6307,  0.7763, -0.2448,  0.5438,  0.8974,  0.8241,
         1.3564,  0.5134,  0.0483,  0.9890,  0.0215,  0.0181,  0.0146,  0.5292],
       device='cuda:0')
Solve time for step 4 1.7699105690116994
Current ori: tensor([0.0215, 0.0181, 0.0146], device='cuda:0')
Index force: tensor([0.5000], device='cuda:0')
Storing RECOVERY transition: reward=0.0063 (scaled=0.0021), steps=3
Reward stats updated: mean -0.0107 -> -0.0106, std: 0.1458
Collected 164 transitions for RL
SAC Update 1/5: Actor Loss=-0.0004, Q1 Loss=3.0444, Q2 Loss=3.0444, Entropy=0.3154, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4954
SAC Update 2/5: Actor Loss=-0.0059, Q1 Loss=1.1336, Q2 Loss=1.1336, Entropy=0.4097, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5043
SAC Update 3/5: Actor Loss=-0.0070, Q1 Loss=1.1472, Q2 Loss=1.1472, Entropy=0.5623, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8176
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.7683, Q2 Loss=0.7683, Entropy=0.4575, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.3047
SAC Update 5/5: Actor Loss=-0.0026, Q1 Loss=0.8600, Q2 Loss=0.8600, Entropy=0.5198, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.3679

------ SAC Update Summary (5 iterations) ------
Total time: 0.26s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (14.9%)
Q1 update: 0.05s (20.9%)
Q2 update: 0.05s (20.2%)
Actor update: 0.11s (40.9%)
Target update: 0.00s (1.3%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003806
Q1 loss: 1.390701
Q2 loss: 1.390701
Current threshold: -30.4175
Global Scale Offset: 4.7463
Reward stats: mean=-0.0106, std=0.1458, count=164
----------------------------------------------
SAC Update - Actor Loss: -0.0038, Q1 Loss: 1.3907, Q2 Loss: 1.3907, Entropy: 0.4529, Mean TD Error: 1.6980, Threshold: -30.4175
Original likelihood: -26.014759063720703
Adjusted likelihood: -26.014759063720703
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.7703)
State is out of distribution
Projection step: 0, Loss: 24.361736297607422
Projection step: 1, Loss: 22.423320770263672
Projection step: 2, Loss: 18.368518829345703
Projection step: 3, Loss: 16.685813903808594
Projection step: 4, Loss: 17.562318801879883
Projection step: 5, Loss: 16.296297073364258
Projection step: 6, Loss: 14.948341369628906
Final likelihood: tensor([-15.0304, -15.9079, -11.9059, -16.6019, -16.8651, -17.7896, -15.1017,
        -15.9238, -13.8274, -12.5774, -16.3178, -13.9159, -12.9952, -13.6876,
        -17.3974, -13.3284])
Final projection likelihood: -14.9483
1 mode projection succeeded
New goal: tensor([ 0.1323,  0.5044,  0.6020,  0.7428, -0.0867,  0.5639,  0.9542,  0.8787,
         1.4198,  0.4782,  0.1558,  1.0395,  0.0131,  0.0126, -0.7649],
       device='cuda:0')
tensor([[0.0024]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -20.013153076171875
Adjusted likelihood: -20.013153076171875
Likelihood residual: 0.0
Original likelihood: -22.987825393676758
Adjusted likelihood: -22.987825393676758
Likelihood residual: 0.0
{'index': 22.987825393676758, 'thumb_middle': 20.013153076171875}
Current yaw: tensor([0.0186, 0.0112, 0.0082], device='cuda:0')
5 thumb_middle
tensor([ 0.1308,  0.4964,  0.6309,  0.7508, -0.1638,  0.5850,  0.9270,  0.8291,
         1.4145,  0.5151,  0.0876,  1.0153,  0.0186,  0.0112,  0.0082,  0.4133],
       device='cuda:0')
Solve time for step 1 8.727119265007786
Current ori: tensor([0.0186, 0.0112, 0.0082], device='cuda:0')
Index force: tensor([0.5729, 0.5743, 0.5854, 0.5967], device='cuda:0')
tensor([ 0.1392,  0.5212,  0.6109,  0.7420, -0.2267,  0.5346,  0.8966,  0.8474,
         1.3595,  0.4543,  0.0394,  0.9651,  0.0120,  0.0055,  0.0082,  0.4249],
       device='cuda:0')
Solve time for step 2 1.9042935260222293
Current ori: tensor([0.0120, 0.0055, 0.0082], device='cuda:0')
Index force: tensor([0.5695, 0.5810, 0.5925], device='cuda:0')
tensor([ 0.1306,  0.5285,  0.6033,  0.7197, -0.2286,  0.5266,  0.9068,  0.8416,
         1.3740,  0.4717,  0.0218,  0.9686,  0.0082,  0.0097,  0.0082,  0.4044],
       device='cuda:0')
Solve time for step 3 1.774008412961848
Current ori: tensor([0.0082, 0.0097, 0.0082], device='cuda:0')
Index force: tensor([0.5752, 0.5875], device='cuda:0')
tensor([ 0.1177,  0.5234,  0.5989,  0.7164, -0.2418,  0.5295,  0.8969,  0.8557,
         1.3777,  0.4769,  0.0211,  0.9781,  0.0089,  0.0170,  0.0082,  0.3858],
       device='cuda:0')
Solve time for step 4 1.746187232027296
Current ori: tensor([0.0089, 0.0170, 0.0082], device='cuda:0')
Index force: tensor([0.5753], device='cuda:0')
Storing RECOVERY transition: reward=0.0016 (scaled=0.0005), steps=3
Reward stats updated: mean -0.0106 -> -0.0106, std: 0.1454
Collected 165 transitions for RL
SAC Update 1/5: Actor Loss=-0.0003, Q1 Loss=2.0035, Q2 Loss=2.0035, Entropy=0.3203, Time=0.06sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3763
SAC Update 2/5: Actor Loss=-0.0017, Q1 Loss=1.2390, Q2 Loss=1.2390, Entropy=0.3176, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0491
SAC Update 3/5: Actor Loss=-0.0038, Q1 Loss=5.5973, Q2 Loss=5.5973, Entropy=0.5939, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.8448
SAC Update 4/5: Actor Loss=-0.0139, Q1 Loss=0.7117, Q2 Loss=0.7117, Entropy=0.4143, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4115
SAC Update 5/5: Actor Loss=-0.0033, Q1 Loss=0.8656, Q2 Loss=0.8656, Entropy=0.4940, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4072

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.8%)
Target Q: 0.05s (19.8%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.04s (18.4%)
Actor update: 0.09s (38.4%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.004580
Q1 loss: 2.083421
Q2 loss: 2.083421
Current threshold: -30.4176
Global Scale Offset: 4.9135
Reward stats: mean=-0.0106, std=0.1454, count=165
----------------------------------------------
SAC Update - Actor Loss: -0.0046, Q1 Loss: 2.0834, Q2 Loss: 2.0834, Entropy: 0.4280, Mean TD Error: 2.6177, Threshold: -30.4176
Original likelihood: -27.16585922241211
Adjusted likelihood: -27.16585922241211
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.7023)
Current yaw: tensor([0.0200, 0.0301, 0.0122], device='cuda:0')
6 turn
Sampling time 3.725417011009995
tensor([ 0.0943,  0.4923,  0.5982,  0.7575, -0.1938,  0.5569,  0.9351,  0.8688,
         1.4409,  0.4788,  0.0895,  1.0029,  0.0200,  0.0301,  0.0122,  0.3440],
       device='cuda:0')
Original likelihood: -27.529922485351562
Adjusted likelihood: -27.529922485351562
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6814)
State is out of distribution
Projection step: 0, Loss: 27.065719604492188
Projection step: 1, Loss: 25.671707153320312
Projection step: 2, Loss: 22.885089874267578
Projection step: 3, Loss: 20.869295120239258
Projection step: 4, Loss: 19.704883575439453
Projection step: 5, Loss: 18.83795738220215
Projection step: 6, Loss: 16.87094497680664
Projection step: 7, Loss: 16.544170379638672
Projection step: 8, Loss: 15.290790557861328
Projection step: 9, Loss: 14.806856155395508
Final likelihood: tensor([-14.8054, -13.7035, -14.0249, -15.0580, -13.8551, -14.3167, -18.9771,
        -14.0402, -15.0984, -13.0788, -15.1329, -17.1496, -15.2689, -13.7021,
        -14.6634, -14.0348])
Final projection likelihood: -14.8069
1 mode projection succeeded
New goal: tensor([ 0.1036,  0.5165,  0.5770,  0.6861, -0.0844,  0.5402,  0.9144,  0.8465,
         1.4248,  0.4728,  0.1689,  1.0752,  0.0149,  0.0193, -1.9357],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0028]], device='cuda:0')
Original likelihood: -17.08192253112793
Adjusted likelihood: -17.08192253112793
Likelihood residual: 0.0
Original likelihood: -22.77882957458496
Adjusted likelihood: -22.77882957458496
Likelihood residual: 0.0
{'index': 22.77882957458496, 'thumb_middle': 17.08192253112793}
Current yaw: tensor([0.0200, 0.0301, 0.0122], device='cuda:0')
7 thumb_middle
tensor([ 0.0943,  0.4923,  0.5982,  0.7575, -0.1938,  0.5569,  0.9351,  0.8688,
         1.4409,  0.4788,  0.0895,  1.0029,  0.0200,  0.0301,  0.0122,  0.3440],
       device='cuda:0')
Solve time for step 1 9.27872128598392
Current ori: tensor([0.0200, 0.0301, 0.0122], device='cuda:0')
Index force: tensor([0.5811, 0.5911, 0.5862, 0.5886], device='cuda:0')
tensor([ 0.1021,  0.5152,  0.5909,  0.7245, -0.2116,  0.5069,  0.8553,  0.8240,
         1.3603,  0.4647,  0.0384,  1.0021,  0.0116,  0.0252,  0.0122,  0.3490],
       device='cuda:0')
Solve time for step 2 1.8662837370065972
Current ori: tensor([0.0116, 0.0252, 0.0122], device='cuda:0')
Index force: tensor([0.5856, 0.5824, 0.5845], device='cuda:0')
tensor([ 0.1043,  0.5255,  0.5937,  0.6949, -0.2159,  0.5122,  0.8751,  0.8164,
         1.3698,  0.4639,  0.0269,  0.9955,  0.0066,  0.0233,  0.0122,  0.3400],
       device='cuda:0')
Solve time for step 3 1.8762260979856364
Current ori: tensor([0.0066, 0.0233, 0.0122], device='cuda:0')
Index force: tensor([0.5765, 0.5798], device='cuda:0')
tensor([ 0.0964,  0.5233,  0.5795,  0.7139, -0.2239,  0.5219,  0.8689,  0.8157,
         1.3760,  0.4642,  0.0258,  0.9986,  0.0088,  0.0280,  0.0122,  0.3360],
       device='cuda:0')
Solve time for step 4 1.8641364380018786
Current ori: tensor([0.0088, 0.0280, 0.0122], device='cuda:0')
Index force: tensor([0.5693], device='cuda:0')
Storing RECOVERY transition: reward=-0.0035 (scaled=-0.0035), steps=0
Reward stats updated: mean -0.0106 -> -0.0105, std: 0.1449
Collected 166 transitions for RL
SAC Update 1/5: Actor Loss=-0.0015, Q1 Loss=0.9443, Q2 Loss=0.9443, Entropy=0.3239, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6681
SAC Update 2/5: Actor Loss=-0.0009, Q1 Loss=1.3892, Q2 Loss=1.3892, Entropy=0.4449, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.3379
SAC Update 3/5: Actor Loss=-0.0055, Q1 Loss=1.2274, Q2 Loss=1.2274, Entropy=0.5583, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7413
SAC Update 4/5: Actor Loss=-0.0012, Q1 Loss=0.8307, Q2 Loss=0.8307, Entropy=0.2491, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4073
SAC Update 5/5: Actor Loss=-0.0041, Q1 Loss=1.2628, Q2 Loss=1.2628, Entropy=0.4712, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.7561

------ SAC Update Summary (5 iterations) ------
Total time: 0.22s, Avg iteration: 0.04s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (16.8%)
Q1 update: 0.04s (20.5%)
Q2 update: 0.04s (19.1%)
Actor update: 0.09s (40.1%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002661
Q1 loss: 1.130875
Q2 loss: 1.130875
Current threshold: -30.4168
Global Scale Offset: 5.0928
Reward stats: mean=-0.0105, std=0.1449, count=166
----------------------------------------------
SAC Update - Actor Loss: -0.0027, Q1 Loss: 1.1309, Q2 Loss: 1.1309, Entropy: 0.4095, Mean TD Error: 1.5821, Threshold: -30.4168
Original likelihood: -29.18781852722168
Adjusted likelihood: -29.18781852722168
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.5772)
Current yaw: tensor([0.0129, 0.0352, 0.0156], device='cuda:0')
8 turn
Sampling time 3.839684506994672
tensor([ 0.0790,  0.5100,  0.5830,  0.7105, -0.1690,  0.5565,  0.8879,  0.8378,
         1.4267,  0.4831,  0.0891,  1.0311,  0.0129,  0.0352,  0.0156,  0.2471],
       device='cuda:0')
Original likelihood: -27.335777282714844
Adjusted likelihood: -27.335777282714844
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.6874)
Solve time for step 1 14.011139073991217
Current ori: tensor([0.0129, 0.0352, 0.0156], device='cuda:0')
Middle force: tensor([0.5701, 0.6182, 1.5923, 0.8157, 0.5442, 0.5091, 0.6160, 0.6502, 0.5157,
        0.5228, 0.5787, 0.6477], device='cuda:0')
Thumb force: tensor([0.9256, 0.9458, 0.6143, 1.2624, 1.0548, 0.5937, 0.5678, 0.5739, 0.6571,
        0.6362, 0.6793, 0.9066], device='cuda:0')
Index force: tensor([0.6349, 0.5878, 0.6564, 0.5533, 0.7134, 0.5774, 0.5320, 0.5799, 0.6416,
        0.6311, 0.5969, 0.5765], device='cuda:0')
Storing NORMAL transition: reward=0.0316 (scaled=0.0316), steps=1
Reward stats updated: mean -0.0105 -> -0.0103, std: 0.1445
Collected 167 transitions for RL
SAC Update 1/5: Actor Loss=-0.0014, Q1 Loss=0.7048, Q2 Loss=0.7048, Entropy=0.3436, Time=0.07sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.1619
SAC Update 2/5: Actor Loss=-0.0032, Q1 Loss=1.1268, Q2 Loss=1.1268, Entropy=0.3935, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6775
SAC Update 3/5: Actor Loss=-0.0054, Q1 Loss=0.7718, Q2 Loss=0.7718, Entropy=0.5646, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2738
SAC Update 4/5: Actor Loss=-0.0031, Q1 Loss=0.7174, Q2 Loss=0.7174, Entropy=0.5540, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8290
SAC Update 5/5: Actor Loss=-0.0044, Q1 Loss=1.1040, Q2 Loss=1.1040, Entropy=0.5698, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0975

------ SAC Update Summary (5 iterations) ------
Total time: 0.24s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.05s (19.2%)
Q1 update: 0.05s (19.6%)
Q2 update: 0.05s (18.6%)
Actor update: 0.09s (39.0%)
Target update: 0.00s (1.5%)
Priority update: 0.00s (0.1%)
Actor loss: -0.003477
Q1 loss: 0.884972
Q2 loss: 0.884972
Current threshold: -30.4207
Global Scale Offset: 5.3229
Reward stats: mean=-0.0103, std=0.1445, count=167
----------------------------------------------
SAC Update - Actor Loss: -0.0035, Q1 Loss: 0.8850, Q2 Loss: 0.8850, Entropy: 0.4851, Mean TD Error: 1.0079, Threshold: -30.4207
tensor([ 0.0578,  0.4943,  0.5718,  0.7355, -0.1851,  0.5075,  0.8879,  0.9892,
         1.5000,  0.3932, -0.0221,  0.8195,  0.0212,  0.0420, -0.0169,  0.1868],
       device='cuda:0')
Original likelihood: -33.36074447631836
Adjusted likelihood: -33.36074447631836
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.3266)
State is out of distribution
Projection step: 0, Loss: 33.171539306640625
Projection step: 1, Loss: 30.01679229736328
Projection step: 2, Loss: 27.784414291381836
Projection step: 3, Loss: 25.738510131835938
Projection step: 4, Loss: 22.835922241210938
Projection step: 5, Loss: 21.59107780456543
Projection step: 6, Loss: 19.172664642333984
Projection step: 7, Loss: 19.208454132080078
Projection step: 8, Loss: 17.632869720458984
Projection step: 9, Loss: 15.973910331726074
Projection step: 10, Loss: 16.213167190551758
Projection step: 11, Loss: 15.805232048034668
Projection step: 12, Loss: 15.989582061767578
Projection step: 13, Loss: 15.489608764648438
Projection step: 14, Loss: 14.51685905456543
Final likelihood: tensor([-13.6808, -15.7948, -14.8071, -14.7703, -17.9839, -16.0942, -16.4955,
        -15.3035, -11.6938, -13.2802, -15.0215, -14.4219, -13.6206, -12.3849,
        -12.1520, -14.7647])
Final projection likelihood: -14.5169
1 mode projection succeeded
New goal: tensor([ 0.0799,  0.5467,  0.5425,  0.6303, -0.0828,  0.4861,  0.8736,  0.8827,
         1.4621,  0.4691,  0.1393,  1.0595,  0.0180,  0.0209, -2.3449],
       device='cuda:0')
tensor([[0.0159]], device='cuda:0') tensor([[0.0025]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -16.059322357177734
Adjusted likelihood: -16.059322357177734
Likelihood residual: 0.0
{'index': inf, 'thumb_middle': 16.059322357177734}
Current yaw: tensor([ 0.0212,  0.0420, -0.0169], device='cuda:0')
9 thumb_middle
tensor([ 0.0578,  0.4943,  0.5718,  0.7355, -0.1851,  0.5075,  0.8879,  0.9892,
         1.5000,  0.3932, -0.0221,  0.8195,  0.0212,  0.0420, -0.0169,  0.1868],
       device='cuda:0')
Solve time for step 1 9.702016543014906
Current ori: tensor([ 0.0212,  0.0420, -0.0169], device='cuda:0')
Index force: tensor([0.5740, 0.6202, 0.6084, 0.6094], device='cuda:0')
tensor([ 0.0544,  0.4885,  0.5873,  0.7148, -0.2197,  0.4651,  0.8358,  0.8828,
         1.4235,  0.4410,  0.0185,  0.9555,  0.0206,  0.0439, -0.0169,  0.1770],
       device='cuda:0')
Solve time for step 2 1.9575727509800345
Current ori: tensor([ 0.0206,  0.0439, -0.0169], device='cuda:0')
Index force: tensor([0.6143, 0.6050, 0.6062], device='cuda:0')
tensor([ 0.0495,  0.5249,  0.5654,  0.6503, -0.2159,  0.4735,  0.8407,  0.8649,
         1.4132,  0.4497,  0.0096,  0.9804,  0.0064,  0.0455, -0.0169,  0.1441],
       device='cuda:0')
Solve time for step 3 1.9393976500141434
Current ori: tensor([ 0.0064,  0.0455, -0.0169], device='cuda:0')
Index force: tensor([0.6002, 0.6030], device='cuda:0')
tensor([ 5.7407e-02,  5.4660e-01,  5.5380e-01,  6.2852e-01, -2.1163e-01,
         4.7934e-01,  8.4236e-01,  8.6051e-01,  1.4096e+00,  4.5050e-01,
         3.6511e-03,  9.8233e-01, -6.4239e-04,  4.0573e-02, -1.6878e-02,
         1.4196e-01], device='cuda:0')
Solve time for step 4 1.81924981798511
Current ori: tensor([-0.0006,  0.0406, -0.0169], device='cuda:0')
Index force: tensor([0.5926], device='cuda:0')
Storing RECOVERY transition: reward=0.0015 (scaled=0.0015), steps=1
Reward stats updated: mean -0.0103 -> -0.0102, std: 0.1441
Collected 168 transitions for RL
SAC Update 1/5: Actor Loss=-0.0077, Q1 Loss=23.0238, Q2 Loss=23.0238, Entropy=0.6269, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.4797
SAC Update 2/5: Actor Loss=-0.0020, Q1 Loss=1.0078, Q2 Loss=1.0078, Entropy=0.3033, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1440
SAC Update 3/5: Actor Loss=-0.0010, Q1 Loss=3.3316, Q2 Loss=3.3316, Entropy=0.4155, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.5857
SAC Update 4/5: Actor Loss=-0.0037, Q1 Loss=0.6154, Q2 Loss=0.6154, Entropy=0.6134, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.2533
SAC Update 5/5: Actor Loss=-0.0072, Q1 Loss=1.9222, Q2 Loss=1.9222, Entropy=0.6109, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.2852

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (17.3%)
Q1 update: 0.04s (18.1%)
Q2 update: 0.04s (19.2%)
Actor update: 0.09s (41.6%)
Target update: 0.00s (1.8%)
Priority update: 0.00s (0.2%)
Actor loss: -0.004312
Q1 loss: 5.980164
Q2 loss: 5.980164
Current threshold: -30.4277
Global Scale Offset: 5.5857
Reward stats: mean=-0.0102, std=0.1441, count=168
----------------------------------------------
SAC Update - Actor Loss: -0.0043, Q1 Loss: 5.9802, Q2 Loss: 5.9802, Entropy: 0.5140, Mean TD Error: 2.5496, Threshold: -30.4277
Original likelihood: -31.434038162231445
Adjusted likelihood: -31.434038162231445
Likelihood residual: 0.0
Stochastic decision: ID (sampled from p=0.4413)
Current yaw: tensor([ 0.0049,  0.0419, -0.0180], device='cuda:0')
10 turn
Sampling time 3.6652263440191746
tensor([ 0.0541,  0.5319,  0.5598,  0.6508, -0.1529,  0.5162,  0.8738,  0.8794,
         1.4645,  0.4631,  0.0543,  1.0201,  0.0049,  0.0419, -0.0180,  0.1426],
       device='cuda:0')
Original likelihood: -31.407176971435547
Adjusted likelihood: -31.407176971435547
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4429)
State is out of distribution
Projection step: 0, Loss: 31.065624237060547
Projection step: 1, Loss: 26.785816192626953
Projection step: 2, Loss: 23.586483001708984
Projection step: 3, Loss: 21.5777587890625
Projection step: 4, Loss: 19.75649642944336
Projection step: 5, Loss: 19.976877212524414
Projection step: 6, Loss: 17.46880340576172
Projection step: 7, Loss: 15.887395858764648
Projection step: 8, Loss: 14.929590225219727
Final likelihood: tensor([-13.3473, -13.1414, -15.4613, -14.8640, -14.8241, -16.8181, -11.4239,
        -16.0509, -15.4392, -13.6675, -14.3782, -17.4234, -14.3459, -16.1153,
        -17.1782, -14.3946])
Final projection likelihood: -14.9296
1 mode projection succeeded
New goal: tensor([ 7.6103e-02,  5.4048e-01,  5.5937e-01,  6.7207e-01, -8.4155e-02,
         5.1093e-01,  8.9087e-01,  8.3995e-01,  1.4097e+00,  4.8024e-01,
         1.3303e-01,  1.0988e+00,  5.2419e-04,  2.1085e-02, -2.4428e+00],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0024]], device='cuda:0') tensor([[0.0030]], device='cuda:0')
Original likelihood: -16.745054244995117
Adjusted likelihood: -16.745054244995117
Likelihood residual: 0.0
Original likelihood: -17.226545333862305
Adjusted likelihood: -17.226545333862305
Likelihood residual: 0.0
{'index': 17.226545333862305, 'thumb_middle': 16.745054244995117}
Current yaw: tensor([ 0.0049,  0.0419, -0.0180], device='cuda:0')
11 thumb_middle
tensor([ 0.0541,  0.5319,  0.5598,  0.6508, -0.1529,  0.5162,  0.8738,  0.8794,
         1.4645,  0.4631,  0.0543,  1.0201,  0.0049,  0.0419, -0.0180,  0.1426],
       device='cuda:0')
Solve time for step 1 9.44887847197242
Current ori: tensor([ 0.0049,  0.0419, -0.0180], device='cuda:0')
Index force: tensor([0.5869, 0.6071, 0.5943, 0.5979], device='cuda:0')
tensor([ 0.0765,  0.5406,  0.5647,  0.6590, -0.2001,  0.4818,  0.8524,  0.8258,
         1.3652,  0.4642,  0.0189,  1.0262,  0.0032,  0.0297, -0.0179,  0.1645],
       device='cuda:0')
Solve time for step 2 2.0942030689911917
Current ori: tensor([ 0.0032,  0.0297, -0.0179], device='cuda:0')
Index force: tensor([0.6029, 0.5914, 0.5954], device='cuda:0')
tensor([ 0.0824,  0.5422,  0.5638,  0.6676, -0.1985,  0.4966,  0.8547,  0.8185,
         1.3659,  0.4647,  0.0104,  1.0332,  0.0035,  0.0264, -0.0179,  0.1742],
       device='cuda:0')
Solve time for step 3 1.8857551790424623
Current ori: tensor([ 0.0035,  0.0264, -0.0179], device='cuda:0')
Index force: tensor([0.5819, 0.5878], device='cuda:0')
tensor([ 0.0675,  0.5332,  0.5574,  0.6766, -0.2088,  0.4920,  0.8528,  0.8158,
         1.3732,  0.4713,  0.0131,  1.0350,  0.0066,  0.0350, -0.0179,  0.1564],
       device='cuda:0')
Solve time for step 4 1.9286298310034908
Current ori: tensor([ 0.0066,  0.0350, -0.0179], device='cuda:0')
Index force: tensor([0.5518], device='cuda:0')
Storing RECOVERY transition: reward=0.0034 (scaled=0.0034), steps=0
Reward stats updated: mean -0.0102 -> -0.0101, std: 0.1437
Collected 169 transitions for RL
SAC Update 1/5: Actor Loss=-0.0025, Q1 Loss=0.5515, Q2 Loss=0.5515, Entropy=0.5977, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1014
SAC Update 2/5: Actor Loss=-0.0031, Q1 Loss=0.9947, Q2 Loss=0.9947, Entropy=0.5110, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0233
SAC Update 3/5: Actor Loss=-0.0047, Q1 Loss=1.2361, Q2 Loss=1.2361, Entropy=0.5281, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=1.0583
SAC Update 4/5: Actor Loss=-0.0010, Q1 Loss=0.5630, Q2 Loss=0.5630, Entropy=0.4442, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.8580
SAC Update 5/5: Actor Loss=-0.0011, Q1 Loss=3.2811, Q2 Loss=3.2811, Entropy=0.4327, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=5.6024

------ SAC Update Summary (5 iterations) ------
Total time: 0.23s, Avg iteration: 0.05s
Sampling: 0.00s (0.6%)
Target Q: 0.04s (18.7%)
Q1 update: 0.04s (19.0%)
Q2 update: 0.04s (18.8%)
Actor update: 0.09s (39.8%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.002471
Q1 loss: 1.325280
Q2 loss: 1.325280
Current threshold: -30.4331
Global Scale Offset: 5.8547
Reward stats: mean=-0.0101, std=0.1437, count=169
----------------------------------------------
SAC Update - Actor Loss: -0.0025, Q1 Loss: 1.3253, Q2 Loss: 1.3253, Entropy: 0.5027, Mean TD Error: 1.7287, Threshold: -30.4331
Original likelihood: -27.22265625
Adjusted likelihood: -27.22265625
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.6747)
State is out of distribution
Projection step: 0, Loss: 26.90660285949707
Projection step: 1, Loss: 22.21484375
Projection step: 2, Loss: 21.823074340820312
Projection step: 3, Loss: 20.273059844970703
Projection step: 4, Loss: 17.335132598876953
Projection step: 5, Loss: 15.989717483520508
Projection step: 6, Loss: 13.640073776245117
Final likelihood: tensor([-11.7766, -13.5138, -12.1669, -15.6904, -11.5604, -15.9699, -13.3148,
        -13.3774, -15.7874, -12.8000, -15.5403, -14.5527, -11.4938, -10.0024,
        -15.6444, -15.0499])
Final projection likelihood: -13.6401
1 mode projection succeeded
New goal: tensor([ 0.0760,  0.5456,  0.5470,  0.6985, -0.0839,  0.5407,  0.8727,  0.8252,
         1.3950,  0.4783,  0.1394,  1.1279,  0.0021,  0.0211, -1.7999],
       device='cuda:0')
tensor([[0.0025]], device='cuda:0') tensor([[0.0027]], device='cuda:0') tensor([[0.0026]], device='cuda:0')
Original likelihood: -15.465600967407227
Adjusted likelihood: -15.465600967407227
Likelihood residual: 0.0
Original likelihood: -17.759193420410156
Adjusted likelihood: -17.759193420410156
Likelihood residual: 0.0
{'index': 17.759193420410156, 'thumb_middle': 15.465600967407227}
Current yaw: tensor([ 0.0050,  0.0365, -0.0210], device='cuda:0')
12 thumb_middle
tensor([ 0.0634,  0.5476,  0.5263,  0.6911, -0.1505,  0.5414,  0.8756,  0.8288,
         1.4276,  0.4798,  0.0550,  1.0789,  0.0050,  0.0365, -0.0210,  0.1778],
       device='cuda:0')
Solve time for step 1 9.412091108039021
Current ori: tensor([ 0.0050,  0.0365, -0.0210], device='cuda:0')
Index force: tensor([0.5863, 0.5930, 0.5927, 0.5964], device='cuda:0')
tensor([ 0.0597,  0.5440,  0.5317,  0.6827, -0.2120,  0.5071,  0.8313,  0.7983,
         1.3511,  0.4638,  0.0274,  1.0669,  0.0049,  0.0390, -0.0209,  0.1618],
       device='cuda:0')
Solve time for step 2 1.9337151580257341
Current ori: tensor([ 0.0049,  0.0390, -0.0209], device='cuda:0')
Index force: tensor([0.5001, 0.5840, 0.5902], device='cuda:0')
tensor([ 0.0609,  0.5457,  0.5320,  0.6796, -0.2131,  0.5138,  0.8347,  0.7889,
         1.3577,  0.4698,  0.0228,  1.0620,  0.0042,  0.0382, -0.0209,  0.1626],
       device='cuda:0')
Solve time for step 3 1.9269284750334918
Current ori: tensor([ 0.0042,  0.0382, -0.0209], device='cuda:0')
Index force: tensor([0.5791, 0.5867], device='cuda:0')
tensor([ 0.0780,  0.5466,  0.5348,  0.7045, -0.2091,  0.5258,  0.8399,  0.7905,
         1.3589,  0.4715,  0.0076,  1.0625,  0.0060,  0.0289, -0.0209,  0.1915],
       device='cuda:0')
Solve time for step 4 1.8396011170116253
Current ori: tensor([ 0.0060,  0.0289, -0.0209], device='cuda:0')
Index force: tensor([0.5828], device='cuda:0')
Storing RECOVERY transition: reward=0.0081 (scaled=0.0081), steps=0
Reward stats updated: mean -0.0101 -> -0.0100, std: 0.1433
Collected 170 transitions for RL
SAC Update 1/5: Actor Loss=-0.0016, Q1 Loss=0.6861, Q2 Loss=0.6861, Entropy=0.4061, Time=0.05sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.5012
SAC Update 2/5: Actor Loss=-0.0030, Q1 Loss=1.0135, Q2 Loss=1.0135, Entropy=0.4466, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.6254
SAC Update 3/5: Actor Loss=-0.0078, Q1 Loss=0.8407, Q2 Loss=0.8407, Entropy=0.6706, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4534
SAC Update 4/5: Actor Loss=-0.0020, Q1 Loss=0.7876, Q2 Loss=0.7876, Entropy=0.3687, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.4306
SAC Update 5/5: Actor Loss=-0.0027, Q1 Loss=0.5537, Q2 Loss=0.5537, Entropy=0.6088, Time=0.04sActor IP Change=0.00000000, Critic IP Change 1=0.00000000, Critic IP Change 2=0.00000000, Mean TD Error=0.1176

------ SAC Update Summary (5 iterations) ------
Total time: 0.21s, Avg iteration: 0.04s
Sampling: 0.00s (0.7%)
Target Q: 0.04s (20.2%)
Q1 update: 0.04s (18.6%)
Q2 update: 0.04s (18.2%)
Actor update: 0.08s (39.1%)
Target update: 0.00s (1.6%)
Priority update: 0.00s (0.2%)
Actor loss: -0.003431
Q1 loss: 0.776330
Q2 loss: 0.776330
Current threshold: -30.4309
Global Scale Offset: 6.1376
Reward stats: mean=-0.0100, std=0.1433, count=170
----------------------------------------------
SAC Update - Actor Loss: -0.0034, Q1 Loss: 0.7763, Q2 Loss: 0.7763, Entropy: 0.5001, Mean TD Error: 0.4256, Threshold: -30.4309
Original likelihood: -31.19876480102539
Adjusted likelihood: -31.19876480102539
Likelihood residual: 0.0
Stochastic decision: OOD (sampled from p=0.4586)
State is out of distribution
Projection step: 0, Loss: 33.17576217651367
Projection step: 1, Loss: 28.774539947509766
Projection step: 2, Loss: 25.348285675048828
Projection step: 3, Loss: 23.559568405151367
Projection step: 4, Loss: 20.729576110839844
Projection step: 5, Loss: 19.231243133544922
Projection step: 6, Loss: 16.932958602905273
Projection step: 7, Loss: 14.851129531860352
Final likelihood: tensor([-13.7036, -12.8586, -13.8618, -16.1727, -17.9364, -14.2022, -18.8669,
        -15.7229, -16.5502, -13.8905, -14.5743, -14.0369, -14.3120, -13.4190,
        -13.3953, -14.1148])
Final projection likelihood: -14.8511
1 mode projection succeeded
New goal: tensor([ 0.0722,  0.5354,  0.5454,  0.7120, -0.0925,  0.5508,  0.8586,  0.8197,
         1.3802,  0.4572,  0.1410,  1.1416,  0.0080,  0.0225, -1.8510],
       device='cuda:0')
tensor([[0.0026]], device='cuda:0') tensor([[0.0029]], device='cuda:0') tensor([[0.0029]], device='cuda:0')
Original likelihood: -20.847660064697266
Adjusted likelihood: -20.847660064697266
Likelihood residual: 0.0
[1;34mwandb[0m:  View run [33mallegro_screwdriver_recovery_data_sac_bernoulli_likelihood_64_orig_lower_critic_lr_lower_alpha_more_inducing_pts_reward_norm_2025-03-17-14-40-27[0m at: [34mhttps://wandb.ai/abhinavk99/ccai-screwdriver/runs/r65xorx6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250317_144028-r65xorx6/logs[0m
